{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "import sympy as sym\n",
    "from sympy import Symbol, sympify, lambdify, abc, SympifyError\n",
    "\n",
    "from gplearn.genetic import SymbolicClassifier\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from sympy import *\n",
    "\n",
    "import types\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun True if GridSearch is to be performed. Otherwise false if already saved\n",
    "rerun = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protected division - if the denominator lies between -0.001 and 0.001, returns 1.0\n",
    "def protected_div(x, y):\n",
    "    try:\n",
    "        if -0.001 <= y <= 0.001:\n",
    "            return 1.0\n",
    "    except TypeError:\n",
    "        return x/y\n",
    "    else:\n",
    "        return x/y\n",
    "\n",
    "# Protected square root - returns the square root of the absolute value of the argument\n",
    "def protected_sqrt(x):\n",
    "    return sym.sqrt(sym.Abs(x))\n",
    "\n",
    "# Protected log - returns the logarithm of the absolute value of the argument, or for very small values less than 0.001, it returns 0.0\n",
    "def protected_log(x):\n",
    "    try:\n",
    "        if -0.001 <= x <= 0.001:\n",
    "            return 0.0\n",
    "    except TypeError:\n",
    "        return sym.log(sym.Abs(x))\n",
    "    else:\n",
    "        return sym.log(sym.Abs(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = {\n",
    "        'add': lambda x, y : x + y,\n",
    "        'sub': lambda x, y : x - y,\n",
    "        'mul': lambda x, y : x*y,\n",
    "        'div': lambda x, y : protected_div(x,y),\n",
    "        'sqrt': lambda x : protected_sqrt(x),\n",
    "        'log': lambda x : protected_log(x),\n",
    "        'abs': lambda x : sym.Abs(x),\n",
    "        'neg': lambda x : -x,\n",
    "        'max': lambda x, y : sym.Max(x, y),\n",
    "        'min': lambda x, y : sym.Min(x, y),\n",
    "        'sin': lambda x : sym.sin(x),\n",
    "        'cos': lambda x : sym.cos(x),\n",
    "        'tan': lambda x : sym.tan(x),\n",
    "        #'inv': lambda x :,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26381042, 5)\n"
     ]
    }
   ],
   "source": [
    "#path = \"./data/replica_pump_data.csv\"\n",
    "path = \"./data/replica_pump_data.csv\" #replica_pump_data_numerical\n",
    "pump_data_replica = pd.read_csv(path)\n",
    "print(pump_data_replica.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_norm_log</th>\n",
       "      <th>temperature_diff</th>\n",
       "      <th>rms_norm_log</th>\n",
       "      <th>details_ratedhead</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.642337</td>\n",
       "      <td>-0.585072</td>\n",
       "      <td>-2.831278</td>\n",
       "      <td>47.369469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.384410</td>\n",
       "      <td>-2.051363</td>\n",
       "      <td>-2.900545</td>\n",
       "      <td>120.240341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.047895</td>\n",
       "      <td>2.104730</td>\n",
       "      <td>-2.742720</td>\n",
       "      <td>92.577971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.962318</td>\n",
       "      <td>0.375291</td>\n",
       "      <td>-2.975236</td>\n",
       "      <td>75.714544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.082340</td>\n",
       "      <td>-1.878716</td>\n",
       "      <td>-2.900094</td>\n",
       "      <td>19.732252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   energy_norm_log  temperature_diff  rms_norm_log  details_ratedhead  state\n",
       "0        -4.642337         -0.585072     -2.831278          47.369469      1\n",
       "1        -4.384410         -2.051363     -2.900545         120.240341      1\n",
       "2        -5.047895          2.104730     -2.742720          92.577971      1\n",
       "3        -4.962318          0.375291     -2.975236          75.714544      1\n",
       "4        -5.082340         -1.878716     -2.900094          19.732252      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pump_data_replica.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pump_data_replica.sample(n=100_000)\n",
    "\n",
    "X_data = data.drop(['state'], axis=1).values\n",
    "y_data = data[['state']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25, random_state=42)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/randForestBest_20201002.pkl\", 'rb') as f:\n",
    "    random_forest_model = joblib.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest: 0.90676\n"
     ]
    }
   ],
   "source": [
    "y_test_random_forest = random_forest_model.predict(X_test)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_test_random_forest)\n",
    "print('Accuracy Random Forest: '+ str(accuracy_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Random Forest Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rf_pred = random_forest_model.predict(X_train).ravel()\n",
    "y_test_rf_pred = random_forest_model.predict(X_test).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Symbolic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_gp = SymbolicClassifier(random_state=0,\n",
    "                                       verbose=1,\n",
    "                                       population_size=5000,\n",
    "                                       tournament_size=1000,\n",
    "                                       generations=15,\n",
    "                                       function_set=('add', 'sub', 'mul', 'div'),\n",
    "                                       parsimony_coefficient=0.1,\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    31.03          9.36953        3         0.149061              N/A     13.23m\n",
      "   1     3.03         0.277928       15         0.146434              N/A     13.41m\n",
      "   2     1.05         0.209687        3         0.163423              N/A     14.77m\n",
      "   3     1.07         0.242119        3         0.149588              N/A     13.55m\n",
      "   4     1.05         0.247765        1         0.171285              N/A     12.31m\n",
      "   5     1.03          0.22856        1         0.171285              N/A     11.07m\n",
      "   6     1.05         0.241441        1         0.171285              N/A      9.89m\n",
      "   7     1.03         0.227525        1         0.171285              N/A      8.61m\n",
      "   8     1.06         0.246238        1         0.171285              N/A      7.46m\n",
      "   9     1.03         0.234014        3         0.171238              N/A      4.62m\n",
      "  10     1.08         0.250529        3         0.158746              N/A      3.01m\n",
      "  11     1.09         0.250565        5         0.153712              N/A      3.77m\n",
      "  12     1.05         0.217753        3         0.154049              N/A      2.30m\n",
      "  13     1.03         0.218232        3         0.154049              N/A     44.15s\n",
      "  14     1.05         0.253695        1         0.171285              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SymbolicClassifier(generations=15, parsimony_coefficient=0.1,\n",
       "                   population_size=5000, random_state=0, tournament_size=1000,\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_gp.fit(X_train, y_train_rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9156571166102084\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = est_gp.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0}$"
      ],
      "text/plain": [
       "X0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_class = simplify(sympify(str(est_gp._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'const_range': (-1.0, 1.0),\n",
       " 'feature_names': None,\n",
       " 'function_set': ('add', 'sub', 'mul', 'div'),\n",
       " 'generations': 15,\n",
       " 'init_depth': (2, 6),\n",
       " 'init_method': 'half and half',\n",
       " 'low_memory': False,\n",
       " 'max_samples': 1.0,\n",
       " 'metric': 'log loss',\n",
       " 'n_jobs': 1,\n",
       " 'p_crossover': 0.9,\n",
       " 'p_hoist_mutation': 0.01,\n",
       " 'p_point_mutation': 0.01,\n",
       " 'p_point_replace': 0.05,\n",
       " 'p_subtree_mutation': 0.01,\n",
       " 'parsimony_coefficient': 0.1,\n",
       " 'population_size': 5000,\n",
       " 'random_state': 0,\n",
       " 'stopping_criteria': 0.0,\n",
       " 'tournament_size': 1000,\n",
       " 'transformer': 'sigmoid',\n",
       " 'verbose': 1,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_gp.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_0 = {'function_set': [('add', 'sub', 'mul', 'div')],\n",
    "              'parsimony_coefficient': [0.1]},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_0 = GridSearchCV(estimator=est_gp,\n",
    "                            param_grid=param_grid_0,\n",
    "                            scoring='f1',\n",
    "                            cv=3,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    31.03          9.36953        3         0.149061              N/A     13.47m\n",
      "   1     3.03         0.277928       15         0.146434              N/A      9.30m\n",
      "   2     1.05         0.209687        3         0.163423              N/A      8.49m\n",
      "   3     1.07         0.242119        3         0.149588              N/A      7.85m\n",
      "   4     1.05         0.247765        1         0.171285              N/A      7.05m\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    31.03           9.3638        7         0.146015              N/A     10.18m\n",
      "   1     3.03           0.2655       15         0.143357              N/A      7.48m\n",
      "   2     1.05         0.207444        3         0.159161              N/A      6.62m\n",
      "   3     1.07         0.239909        3         0.146078              N/A      6.55m\n",
      "   4     1.05         0.245493        1           0.1691              N/A      5.74m\n",
      "   5     1.03         0.226307        1           0.1691              N/A      5.37m\n",
      "   6     1.05         0.239215        1           0.1691              N/A      4.52m\n",
      "   7     1.03         0.225243        1           0.1691              N/A      3.95m\n",
      "   8     1.06         0.244015        1           0.1691              N/A      3.40m\n",
      "   9     1.03         0.231765        3         0.169054              N/A      2.79m\n",
      "  10     1.08          0.24827        3           0.1547              N/A      2.26m\n",
      "  11     1.09         0.248289        5         0.150691              N/A      1.69m\n",
      "  12     1.05         0.215492        3         0.150871              N/A      1.13m\n",
      "  13     1.03         0.216008        3         0.150871              N/A     33.30s\n",
      "  14     1.05         0.251441        1           0.1691              N/A      0.00s\n",
      "   5     1.03          0.22856        1         0.171285              N/A      6.37m\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    31.03          9.36894        3         0.150906              N/A     11.96m\n",
      "   1     3.03         0.279852       15          0.14841              N/A      7.85m\n",
      "   2     1.05         0.211145        3         0.166354              N/A      6.84m\n",
      "   3     1.07         0.243552        3         0.151986              N/A      6.33m\n",
      "   4     1.05         0.249202        1         0.172717              N/A      6.00m\n",
      "   5     1.03         0.229992        1         0.172717              N/A      5.54m\n",
      "   6     1.05         0.242852        1         0.172717              N/A      4.85m\n",
      "   7     1.03         0.228975        1         0.172717              N/A      4.23m\n",
      "   8     1.06         0.247654        1         0.172717              N/A      3.70m\n",
      "   9     1.03         0.235437        3         0.172668              N/A      3.03m\n",
      "  10     1.08         0.251941        3         0.161525              N/A      2.47m\n",
      "  11     1.09         0.252031        5         0.155435              N/A      1.86m\n",
      "  12     1.05          0.21922        3         0.155827              N/A      1.21m\n",
      "  13     1.03         0.219667        3         0.155827              N/A     35.98s\n",
      "  14     1.05         0.255118        1         0.172717              N/A      0.00s\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    31.03          9.37584        3         0.149967              N/A     11.97m\n",
      "   1     3.03         0.279025       15         0.147533              N/A      7.82m\n",
      "   2     1.05         0.210473        3         0.164754              N/A      6.81m\n",
      "   3     1.07         0.242895        3         0.150702              N/A      6.86m\n",
      "   4     1.05         0.248599        1         0.172039              N/A      6.04m\n",
      "   5     1.03         0.229383        1         0.172039              N/A      5.64m\n",
      "   6     1.05         0.242255        1         0.172039              N/A      4.97m\n",
      "   7     1.03         0.228356        1         0.172039              N/A      4.27m\n",
      "   8     1.06         0.247045        1         0.172039              N/A      3.67m\n",
      "   9     1.03         0.234841        3         0.171992              N/A      3.11m\n",
      "  10     1.08         0.251376        3         0.160013              N/A      2.48m\n",
      "  11     1.09         0.251375        5         0.155009              N/A      1.85m\n",
      "  12     1.05         0.218545        3         0.155447              N/A      1.22m\n",
      "  13     1.03         0.219021        3         0.155447              N/A     37.13s\n",
      "  14     1.05         0.254525        1         0.172039              N/A      0.00s\n",
      "   6     1.05         0.241441        1         0.171285              N/A      5.67m\n",
      "   7     1.03         0.227525        1         0.171285              N/A      4.98m\n",
      "   8     1.06         0.246238        1         0.171285              N/A      4.29m\n",
      "   9     1.03         0.234014        3         0.171238              N/A      3.58m\n",
      "  10     1.08         0.250529        3         0.158746              N/A      2.86m\n",
      "  11     1.09         0.250565        5         0.153712              N/A      2.15m\n",
      "  12     1.05         0.217753        3         0.154049              N/A      1.42m\n",
      "  13     1.03         0.218232        3         0.154049              N/A     42.64s\n",
      "  14     1.05         0.253695        1         0.171285              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=SymbolicClassifier(generations=15,\n",
       "                                          parsimony_coefficient=0.1,\n",
       "                                          population_size=5000, random_state=0,\n",
       "                                          tournament_size=1000, verbose=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid=({'function_set': [('add', 'sub', 'mul', 'div')],\n",
       "                          'parsimony_coefficient': [0.1]},),\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_0.fit(X_train, y_train_rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0}$"
      ],
      "text/plain": [
       "X0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_class = simplify(sympify(str(results_0.best_estimator_._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9156571166102084\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = results_0.best_estimator_.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_function_set</th>\n",
       "      <th>param_parsimony_coefficient</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548.315259</td>\n",
       "      <td>18.950967</td>\n",
       "      <td>0.011705</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>(add, sub, mul, div)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'function_set': ('add', 'sub', 'mul', 'div'),...</td>\n",
       "      <td>0.918834</td>\n",
       "      <td>0.915608</td>\n",
       "      <td>0.909406</td>\n",
       "      <td>0.914616</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     548.315259     18.950967         0.011705        0.000815   \n",
       "\n",
       "     param_function_set param_parsimony_coefficient  \\\n",
       "0  (add, sub, mul, div)                         0.1   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'function_set': ('add', 'sub', 'mul', 'div'),...           0.918834   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.915608           0.909406         0.914616        0.003913   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_0 = pd.DataFrame(results_0.cv_results_)\n",
    "df_results_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator_sc = SymbolicClassifier(random_state=0,\n",
    "                                       verbose=1,\n",
    "                                       population_size=5000,\n",
    "                                       tournament_size=1000,\n",
    "                                       generations=15,#1000\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_1 = {'function_set': [('add', 'sub', 'mul', 'div'),('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan')],\n",
    "              'init_depth': [(2, 6),(4, 10)],\n",
    "              'init_method': ['half and half'],\n",
    "              'parsimony_coefficient': [0.0001, 0.001]},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = GridSearchCV(estimator=base_estimator_sc,\n",
    "                            param_grid=param_grid_1,\n",
    "                            scoring='f1',\n",
    "                            cv=3,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO RESULTS SAVED\n"
     ]
    }
   ],
   "source": [
    "if rerun:\n",
    "    results_1.fit(X_train, y_train_rf_pred)\n",
    "    df_results_1 = pd.DataFrame(results_1.cv_results_)\n",
    "    df_results_1 = df_results_1[['param_function_set','param_init_depth','param_init_method','param_parsimony_coefficient','mean_test_score','rank_test_score']]\n",
    "    df_results_1.to_csv('df_results_1.csv')\n",
    "    grid_results_calculated = True\n",
    "else:\n",
    "    try:\n",
    "        df_results_1 = pd.read_csv('df_results_1.csv') \n",
    "        grid_results_calculated = True\n",
    "    except:\n",
    "        print('NO RESULTS SAVED')\n",
    "        grid_results_calculated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_help = None\n",
    "if grid_results_calculated:\n",
    "    print_help = df_results_1\n",
    "print_help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate best Estimator on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_results_calculated:\n",
    "    print(results_1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_results_calculated:\n",
    "    saved_best_estimator = {\n",
    "        'function_set': ('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "        'init_depth': (4, 10)\n",
    "    }\n",
    "    print(str(results_1.best_estimator_._program))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_help = None\n",
    "if grid_results_calculated:\n",
    "    sym_class = simplify(sympify(str(results_1.best_estimator_._program), locals=converter))\n",
    "    sym_class\n",
    "print_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_results_calculated:\n",
    "    y_test_symbolic_clas = results_1.best_estimator_.predict(X_test)\n",
    "    f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "    print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_2 = {\n",
    "    'p_crossover': [0.1,0.2,0.3,0.5],\n",
    "    'p_subtree_mutation': [0.1,0.2,0.3,0.5],\n",
    "    'p_hoist_mutation': [0.1,0.2,0.3,0.5],\n",
    "    'p_point_mutation': [0.1,0.2,0.3,0.5],\n",
    "    'p_point_replace': [0.1,0.2,0.3,0.5],\n",
    "    'parsimony_coefficient': [0.0001],\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_results_calculated:\n",
    "    results_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_results_calculated:\n",
    "    base_estimator_sc.set_params(**saved_best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_results_calculated:\n",
    "    results_2 = GridSearchCV(estimator=base_estimator_sc,\n",
    "                                param_grid=param_grid_2,\n",
    "                                scoring='f1',\n",
    "                                cv=3,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO RESULTS SAVED\n"
     ]
    }
   ],
   "source": [
    "if rerun:\n",
    "    results_2.fit(X_train, y_train_rf_pred)\n",
    "    df_results_2 = pd.DataFrame(results_2.cv_results_)\n",
    "    df_results_2 = df_results_2[['param_parsimony_coefficient','param_p_crossover','param_p_hoist_mutation','param_p_point_mutation','param_p_point_replace','param_p_subtree_mutation', 'mean_test_score','rank_test_score']]\n",
    "    df_results_2.to_csv('df_results_2.csv')\n",
    "    grid_results_calculated = True\n",
    "else:\n",
    "    try:\n",
    "        df_results_2 = pd.read_csv('df_results_2.csv', index_col=0) \n",
    "        grid_results_calculated = True\n",
    "    except:\n",
    "        grid_results_calculated = False\n",
    "        print('NO RESULTS SAVED')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_help = None\n",
    "if grid_results_calculated:\n",
    "    df_results_2_sorted = df_results_2.sort_values(by=['rank_test_score'])\n",
    "    df_results_2_sorted.columns = ['parsimony_coefficient', 'p_crossover', 'p_hoist_mutation', 'p_point_mutation', 'p_point_replace', 'p_subtree_mutation', 'mean_test_score', 'rank_test_score']\n",
    "    print_help = df_results_2_sorted.head(10)   \n",
    "print_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_help = None\n",
    "if grid_results_calculated:\n",
    "    df_results_2_sorted[df_results_2_sorted['parsimony_coefficient']==0.001].head(10)\n",
    "print_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_help = None\n",
    "if grid_results_calculated:\n",
    "    df_results_2_sorted[df_results_2_sorted['parsimony_coefficient']==0.01].head(10)\n",
    "print_help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.01,\n",
    "                            p_crossover=0.7,\n",
    "                            p_hoist_mutation=0.01,\n",
    "                            p_point_mutation=0.01,\n",
    "                            p_point_replace=0.01,\n",
    "                            p_subtree_mutation=0.05,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    40.09          2.56286        3         0.154049              N/A      3.78m\n",
      "   1     5.21         0.915605        7         0.147526              N/A      2.79m\n",
      "   2     3.08         0.298357        5         0.140337              N/A      2.95m\n",
      "   3     3.27         0.280103        3         0.149588              N/A      2.74m\n",
      "   4     3.19         0.300289        5         0.144887              N/A      2.57m\n",
      "   5     3.27         0.333431        3         0.149588              N/A      2.36m\n",
      "   6     3.27         0.312924        3         0.149588              N/A      2.07m\n",
      "   7     3.24         0.308719        5         0.140454              N/A      1.78m\n",
      "   8     3.25         0.312715        3         0.149588              N/A      1.52m\n",
      "   9     3.15         0.285291        9         0.144058              N/A      1.32m\n",
      "  10     3.22         0.291895        3         0.149588              N/A      1.01m\n",
      "  11     3.20         0.252072        3         0.149588              N/A     45.70s\n",
      "  12     3.25         0.287022        3         0.149588              N/A     30.41s\n",
      "  13     3.25         0.330377        8         0.140466              N/A     15.18s\n",
      "  14     3.24         0.286323        3         0.149588              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2 X_{0}$"
      ],
      "text/plain": [
       "2*X0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.fit(X_train, y_train_rf_pred)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_1._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9156571166102084\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_1.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Real Data: 0.8840531190715322\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_1.predict(X_test)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Real Data:', f1_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Symbolic Classification - Random Forest Model: 0.94124\n",
      "Accuracy Symbolic Classification - Real Data: 0.91688\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_1.predict(X_test)\n",
    "print('Accuracy Symbolic Classification - Random Forest Model:', accuracy_score(y_test_rf_pred, y_test_symbolic_clas))\n",
    "print('Accuracy Symbolic Classification - Real Data:', accuracy_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add(X0, X0)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_1._program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.001,\n",
    "                            p_crossover=0.3,\n",
    "                            p_hoist_mutation=0.1,\n",
    "                            p_point_mutation=0.5,\n",
    "                            p_point_replace=0.5,\n",
    "                            p_subtree_mutation=0.1,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    40.09          2.56286        3         0.154049              N/A      3.18m\n",
      "   1     7.86          2.19521        6         0.144051              N/A      3.05m\n",
      "   2     4.52          2.42639        8         0.134788              N/A      3.30m\n",
      "   3     7.60          2.37262       10         0.123729              N/A      2.91m\n",
      "   4     8.94          2.47722       10         0.119612              N/A      2.79m\n",
      "   5     9.93          2.56264       10         0.118321              N/A      2.56m\n",
      "   6     9.95          2.62249       17         0.118316              N/A      2.41m\n",
      "   7     9.84          2.51737       11         0.118107              N/A      2.05m\n",
      "   8     9.95          2.62694       10         0.114593              N/A      1.78m\n",
      "   9     9.94          2.73509       19         0.107838              N/A      1.52m\n",
      "  10     9.91          2.68093       19         0.107169              N/A      1.26m\n",
      "  11     9.96          2.55751       19         0.107169              N/A     52.36s\n",
      "  12    10.01          2.49706       19         0.107169              N/A     36.81s\n",
      "  13     9.90          2.52486       19         0.107169              N/A     18.19s\n",
      "  14     9.91          2.51696       19         0.107169              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0} + \\min\\left(X_{0} + \\min\\left(X_{0} + 0.774, \\max\\left(-0.87, X_{1}\\right)\\right) + 0.774, \\max\\left(-0.87, X_{1}\\right)\\right)$"
      ],
      "text/plain": [
       "X0 + Min(X0 + Min(X0 + 0.774, Max(-0.87, X1)) + 0.774, Max(-0.87, X1))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2.fit(X_train, y_train_rf_pred)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_2._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9330287497214175\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_2.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Real Data: 0.8809407684387363\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_2.predict(X_test)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Real Data:', f1_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Symbolic Classification - Random Forest Model: 0.95192\n",
      "Accuracy Symbolic Classification - Real Data: 0.91212\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_2.predict(X_test)\n",
    "print('Accuracy Symbolic Classification - Random Forest Model:', accuracy_score(y_test_rf_pred, y_test_symbolic_clas))\n",
    "print('Accuracy Symbolic Classification - Real Data:', accuracy_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub(X0, neg(min(sub(sub(X0, neg(min(sub(X0, -0.774), max(X1, -0.870)))), -0.774), max(X1, -0.870))))'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_2._program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2b = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.001,\n",
    "                            p_crossover=0.3,\n",
    "                            p_hoist_mutation=0.0,\n",
    "                            p_point_mutation=0.7,\n",
    "                            p_point_replace=0.5,\n",
    "                            p_subtree_mutation=0.0,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    40.09          2.56286        3         0.154049              N/A      3.12m\n",
      "   1     7.62          2.54846        6         0.144051              N/A      2.96m\n",
      "   2     4.09          2.79399        8         0.134788              N/A      3.34m\n",
      "   3     7.55          2.81962       10         0.123729              N/A      2.94m\n",
      "   4     8.86          2.90121       10         0.120653              N/A      2.86m\n",
      "   5    10.00          2.99952       16         0.119101              N/A      2.64m\n",
      "   6     9.98          2.92056       10         0.119267              N/A      2.54m\n",
      "   7     9.94          2.83569       10         0.118644              N/A      2.13m\n",
      "   8    10.00          3.06199       10         0.114593              N/A      1.82m\n",
      "   9     9.99          3.25883       19         0.107571              N/A      1.52m\n",
      "  10    10.18          3.27393       19         0.107169              N/A      1.24m\n",
      "  11     9.99          3.12041       19         0.107169              N/A     54.07s\n",
      "  12    10.01          3.12951       19         0.107169              N/A     39.69s\n",
      "  13     9.98          3.07852       19         0.107169              N/A     19.03s\n",
      "  14    10.02          3.09555       19         0.107169              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0} + \\min\\left(X_{0} + \\min\\left(X_{0} + 0.774, \\max\\left(-0.87, X_{1}\\right)\\right) + 0.774, \\max\\left(-0.87, X_{1}\\right)\\right)$"
      ],
      "text/plain": [
       "X0 + Min(X0 + Min(X0 + 0.774, Max(-0.87, X1)) + 0.774, Max(-0.87, X1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2b.fit(X_train, y_train_rf_pred)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_2b._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9330287497214175\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_2b.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub(X0, neg(min(sub(sub(X0, neg(min(sub(X0, -0.774), max(X1, -0.870)))), -0.774), max(X1, -0.870))))'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_2b._program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2c = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.01,\n",
    "                            p_crossover=0.3,\n",
    "                            p_hoist_mutation=0.1,\n",
    "                            p_point_mutation=0.5,\n",
    "                            p_point_replace=0.5,\n",
    "                            p_subtree_mutation=0.1,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    40.09          2.56286        3         0.154049              N/A      3.08m\n",
      "   1     5.29          2.13342        6         0.145236              N/A      2.91m\n",
      "   2     3.49            2.151        3         0.146636              N/A      3.06m\n",
      "   3     3.46          1.93993        3         0.146593              N/A      2.94m\n",
      "   4     3.42           1.9348        3         0.146582              N/A      2.57m\n",
      "   5     3.42          1.85273        3         0.146582              N/A      2.33m\n",
      "   6     3.44          1.80738        3         0.146582              N/A      2.05m\n",
      "   7     3.37          1.91699        3         0.146582              N/A      1.78m\n",
      "   8     3.42          1.83549        3         0.146582              N/A      1.54m\n",
      "   9     3.40          1.83509        7         0.121014              N/A      1.29m\n",
      "  10     3.39          1.91045        3         0.146582              N/A      1.08m\n",
      "  11     3.43          1.74417        3         0.146582              N/A     45.88s\n",
      "  12     3.46          1.82585        3         0.146582              N/A     30.27s\n",
      "  13     3.38          1.86314        3         0.146582              N/A     15.35s\n",
      "  14     3.38          1.81132        3         0.146582              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.65837479270315 X_{0}$"
      ],
      "text/plain": [
       "1.65837479270315*X0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2c.fit(X_train, y_train_rf_pred)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_2c._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9156571166102084\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_2c.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2d = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.001,\n",
    "                            p_crossover=0.3,\n",
    "                            p_hoist_mutation=0.1,\n",
    "                            p_point_mutation=0.5,\n",
    "                            p_point_replace=0.5,\n",
    "                            p_subtree_mutation=0.1,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    40.09          2.54557        3         0.210364              N/A      3.33m\n",
      "   1     6.88          2.12375       13         0.210024              N/A      3.02m\n",
      "   2     3.49          2.21788        3         0.210364              N/A      3.21m\n",
      "   3     3.46          2.32488        5         0.210353              N/A      2.76m\n",
      "   4     3.42          2.34944        3         0.210364              N/A      2.74m\n",
      "   5     3.42          2.23475        3         0.210364              N/A      2.32m\n",
      "   6     3.44          2.18755        3         0.210364              N/A      2.08m\n",
      "   7     3.37          2.23939        3         0.210364              N/A      1.82m\n",
      "   8     3.42           2.2219        3         0.210364              N/A      1.54m\n",
      "   9     3.40          2.25725        3         0.210364              N/A      1.28m\n",
      "  10     3.39          2.26536        3         0.210364              N/A      1.03m\n",
      "  11     3.43          2.11249        3         0.210364              N/A     46.69s\n",
      "  12     3.46          2.25536        3         0.210364              N/A     33.01s\n",
      "  13     3.38          2.21002        3         0.210364              N/A     15.70s\n",
      "  14     3.38          2.18233        5         0.209186              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0} + \\min\\left(0.524, X_{2}\\right)$"
      ],
      "text/plain": [
       "X0 + Min(0.524, X2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2d.fit(X_train, y_train)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_2d._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.8813540448750069\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_2d.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2e = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.01,\n",
    "                            p_crossover=0.1,\n",
    "                            p_hoist_mutation=0.1,\n",
    "                            p_point_mutation=0.7,\n",
    "                            p_point_replace=0.5,\n",
    "                            p_subtree_mutation=0.1,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    40.09          2.56286        3         0.154049              N/A      3.14m\n",
      "   1     5.39          2.52534        6         0.145236              N/A      3.00m\n",
      "   2     3.39          2.84142        5         0.144887              N/A      3.17m\n",
      "   3     3.43          2.49049        3         0.146593              N/A      2.83m\n",
      "   4     3.49          2.47801        3         0.146582              N/A      2.50m\n",
      "   5     3.39          2.31539        3         0.146582              N/A      2.29m\n",
      "   6     3.48          2.43888       11         0.133917              N/A      2.21m\n",
      "   7     3.36          2.52184        3         0.146582              N/A      1.76m\n",
      "   8     3.49          2.46607        3         0.146582              N/A      1.52m\n",
      "   9     3.47           2.2634        3         0.146582              N/A      1.28m\n",
      "  10     3.44          2.41056        3         0.146582              N/A      1.03m\n",
      "  11     3.41          2.35204        3         0.146582              N/A     47.04s\n",
      "  12     3.43          2.25628        3         0.146582              N/A     31.28s\n",
      "  13     3.43          2.35602        3         0.146582              N/A     15.27s\n",
      "  14     3.43          2.29556        3         0.146582              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.65837479270315 X_{0}$"
      ],
      "text/plain": [
       "1.65837479270315*X0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2e.fit(X_train, y_train_rf_pred)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_2e._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9156571166102084\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_2e.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_function_values_from_sympy(function, data_points, variable_names=None):\n",
    "    \n",
    "    if variable_names is None:\n",
    "        variable_names = ['X' + str(i) for i in range(data_points.shape[1])]\n",
    "    \n",
    "    if function is None:\n",
    "        return np.array([np.nan for i in range(data_points.shape[0])])\n",
    "    try:\n",
    "        if variable_names == None:\n",
    "            function_vars = function.atoms(Symbol)\n",
    "        else:\n",
    "            function_vars = [sym.symbols(variable_name) for variable_name in variable_names]\n",
    "        #print('function_vars', function_vars)\n",
    "        lambda_function = lambdify([function_vars], function, modules=[\"scipy\", \"numpy\"])\n",
    "        #print('lambda_function', lambda_function)\n",
    "        #print('data_points[0]', data_points[0])\n",
    "        if len(function_vars) >= 1:\n",
    "            function_values = [lambda_function(data_point) for data_point in data_points]\n",
    "            \n",
    "        else:\n",
    "            function_values = [lambda_function() for i in range(data_points.shape[0])]\n",
    "    except (NameError, KeyError) as e:\n",
    "        #print(e)\n",
    "        function_values = []\n",
    "        for data_point in data_points:\n",
    "            function_value = function.evalf(subs={var: data_point[index] for index, var in enumerate(list(function_vars))})\n",
    "            try:\n",
    "                function_value = float(function_value)\n",
    "            except TypeError as te:\n",
    "                #print(te)\n",
    "                #print(function_value)\n",
    "                function_value = np.inf\n",
    "            function_values.append(function_value)\n",
    "    function_values = np.nan_to_num(function_values).ravel()\n",
    "                \n",
    "    return function_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'add(min(add(min(div(sin(max(X0, X1)), log(0.203)), add(add(cos(log(neg(sqrt(X3)))), X0), X0)), sub(add(add(X0, cos(log(neg(sqrt(X3))))), cos(log(neg(sqrt(X3))))), neg(log(max(log(tan(log(neg(sqrt(X3))))), X1))))), add(add(cos(log(neg(sqrt(X3)))), X0), X0)), sub(add(X0, cos(log(neg(sqrt(X3))))), neg(log(max(log(tan(log(neg(sqrt(X3))))), X1)))))'\n",
    "b = 'add(X0, X0)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_symbolic_clas = np.where(calculate_function_values_from_sympy(b, X_test) > 0, 1, 0).astype(np.int64).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9156571166102084\n"
     ]
    }
   ],
   "source": [
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_results_calculated:\n",
    "    df_results_2_variety = pd.read_csv('df_results_2_variety.csv', index_col=0) \n",
    "    print(df_results_2_variety.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_help = None\n",
    "if grid_results_calculated:\n",
    "    df_results_2_variety_sorted = df_results_2_variety.sort_values(by=['rank_test_score'])\n",
    "    df_results_2_variety_sorted.columns = ['parsimony_coefficient', 'p_crossover', 'p_hoist_mutation', 'p_point_mutation', 'p_point_replace', 'p_subtree_mutation', 'mean_test_score', 'rank_test_score']\n",
    "    print_help = df_results_2_variety_sorted.head(10)\n",
    "print_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_best = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.0001,\n",
    "                            p_crossover=0.3,\n",
    "                            p_hoist_mutation=0.1,\n",
    "                            p_point_mutation=0.5,\n",
    "                            p_point_replace=0.5,\n",
    "                            p_subtree_mutation=0.1,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    40.09          2.56286        3         0.154049              N/A      3.21m\n",
      "   1    10.34          2.21897       34          0.14427              N/A      3.41m\n",
      "   2    11.09           2.3366       37          0.13087              N/A      3.56m\n",
      "   3    19.18           2.4224       37          0.10899              N/A      3.52m\n",
      "   4    34.79          2.41125       34          0.10581              N/A      4.00m\n",
      "   5    33.78          2.27695       53         0.103599              N/A      4.09m\n",
      "   6    29.03          2.24381       34         0.098155              N/A      3.40m\n",
      "   7    29.95          2.23126       29        0.0889579              N/A      2.85m\n",
      "   8    31.54          2.61263       29        0.0811824              N/A      2.58m\n",
      "   9    29.93          2.89933       53         0.079717              N/A      2.01m\n",
      "  10    27.30          2.86721       39        0.0786728              N/A      1.59m\n",
      "  11    28.06           2.8729       40        0.0773491              N/A      1.18m\n",
      "  12    38.65          2.92694       41        0.0773281              N/A     49.16s\n",
      "  13    37.01          2.84841       75        0.0762927              N/A     26.51s\n",
      "  14    35.65          3.06359       48        0.0764189              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0} + \\log{\\left(\\max\\left(0.052, 19.2307692307692 \\left|{\\frac{X_{1}}{\\log{\\left(\\left|{\\frac{X_{1}}{X_{3} \\left(0.719424460431655 X_{3} + \\log{\\left(\\left|{\\frac{X_{1}}{X_{3}}}\\right| \\right)}\\right)}}\\right| \\right)} + 0.719424460431655 \\max\\left(X_{2}, X_{3}\\right)}}\\right|\\right) \\right)} + \\min\\left(2 X_{0}, \\frac{X_{3} \\left|{\\frac{X_{1}}{X_{3}}}\\right|}{X_{1}}\\right)$"
      ],
      "text/plain": [
       "X0 + log(Max(0.052, 19.2307692307692*Abs(X1/(log(Abs(X1/(X3*(0.719424460431655*X3 + log(Abs(X1/X3)))))) + 0.719424460431655*Max(X2, X3))))) + Min(2*X0, X3*Abs(X1/X3)/X1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_best.fit(X_train, y_train_rf_pred)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_best._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9550568149697553\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_best.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Real Data: 0.8806199846103111\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_best.predict(X_test)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Real Data:', f1_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Symbolic Classification - Random Forest Model: 0.9682\n",
      "Accuracy Symbolic Classification - Real Data: 0.91312\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_best.predict(X_test)\n",
    "print('Accuracy Symbolic Classification - Random Forest Model:', accuracy_score(y_test_rf_pred, y_test_symbolic_clas))\n",
    "print('Accuracy Symbolic Classification - Real Data:', accuracy_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add(min(div(abs(div(X1, X3)), div(X1, X3)), add(X0, X0)), add(X0, log(max(div(abs(div(X1, sub(log(div(div(X1, sub(log(div(X1, X3)), div(X3, add(-0.860, -0.530)))), X3)), div(max(X3, X2), add(-0.860, -0.530))))), abs(0.052)), abs(0.052)))))'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_best._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_best_simple = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.0001,\n",
    "                            p_crossover=0.3,\n",
    "                            p_hoist_mutation=0.1,\n",
    "                            p_point_mutation=0.5,\n",
    "                            p_point_replace=0.5,\n",
    "                            p_subtree_mutation=0.1,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   312.71          10.9626        3         0.146581              N/A      9.53m\n",
      "   1     6.74          3.50669        3         0.146581              N/A      2.99m\n",
      "   2     3.78          2.27965        3         0.146581              N/A      2.93m\n",
      "   3     3.63          2.39299        3         0.146581              N/A      2.62m\n",
      "   4     4.04          2.34165        3         0.146581              N/A      2.37m\n",
      "   5     3.59           2.2648        3         0.146581              N/A      2.16m\n",
      "   6     3.47          2.25826        3         0.146581              N/A      1.89m\n",
      "   7     3.68          2.31025        3         0.146581              N/A      1.67m\n",
      "   8     3.84          2.20586        3         0.146581              N/A      1.44m\n",
      "   9     3.74          2.27312        3         0.146581              N/A      1.22m\n",
      "  10     3.73          2.31145        3         0.146581              N/A     58.98s\n",
      "  11     3.53          2.14311        3         0.146581              N/A     43.78s\n",
      "  12     3.64          2.22763        3         0.146581              N/A     29.21s\n",
      "  13     3.67          2.26062        3         0.146581              N/A     14.63s\n",
      "  14     3.67            2.252        3         0.146581              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.66112956810631 X_{0}$"
      ],
      "text/plain": [
       "1.66112956810631*X0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_best_simple.fit(X_train, y_train_rf_pred)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_best_simple._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.9156571166102084\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_best_simple.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_rf_pred, y_test_symbolic_clas)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'div(X0, 0.602)'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_best_simple._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Real Data: 0.8840531190715322\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_best_simple.predict(X_test)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Real Data:', f1_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Symbolic Classification - Random Forest Model: 0.94124\n",
      "Accuracy Symbolic Classification - Real Data: 0.91688\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_best_simple.predict(X_test)\n",
    "print('Accuracy Symbolic Classification - Random Forest Model:', accuracy_score(y_test_rf_pred, y_test_symbolic_clas))\n",
    "print('Accuracy Symbolic Classification - Real Data:', accuracy_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_best_original = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.0001,\n",
    "                            p_crossover=0.3,\n",
    "                            p_hoist_mutation=0.1,\n",
    "                            p_point_mutation=0.5,\n",
    "                            p_point_replace=0.5,\n",
    "                            p_subtree_mutation=0.1,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    40.09          2.54557        3         0.210364              N/A      3.16m\n",
      "   1     8.26          2.21927       13         0.210024              N/A      3.03m\n",
      "   2     3.49          2.21836        3         0.210364              N/A      3.29m\n",
      "   3     3.46          2.32463        5         0.210353              N/A      2.87m\n",
      "   4     3.42          2.34999        3         0.210364              N/A      2.57m\n",
      "   5     3.42          2.23614        3         0.210364              N/A      2.27m\n",
      "   6     3.44          2.18848        3         0.210364              N/A      2.03m\n",
      "   7     3.37          2.23944        3         0.210364              N/A      1.97m\n",
      "   8     3.42          2.22263        3         0.210364              N/A      1.54m\n",
      "   9     3.40          2.25695        3         0.210364              N/A      1.29m\n",
      "  10     3.39          2.26441        3         0.210364              N/A      1.03m\n",
      "  11     3.43          2.11149        3         0.210364              N/A     46.34s\n",
      "  12     3.46          2.25538        3         0.210364              N/A     30.61s\n",
      "  13     3.38          2.21006        3         0.210364              N/A     15.27s\n",
      "  14     3.38          2.18069        5         0.209186              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0} + \\min\\left(0.524, X_{2}\\right)$"
      ],
      "text/plain": [
       "X0 + Min(0.524, X2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_best_original.fit(X_train, y_train)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_best_original._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Random Forest Model: 0.8813540448750069\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_best_original.predict(X_test)\n",
    "f1_fidelity = f1_score(y_test_symbolic_clas, y_test)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Random Forest Model:', f1_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9156571166102084"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_symbolic_clas = np.where(calculate_function_values_from_sympy(simplify(sympify('mul(2,X0)', locals=converter)), X_test) > 0, 1, 0).astype(np.int64).reshape(-1,1)\n",
    "accuracy_symbolic_class_performance = f1_score(y_test_symbolic_clas, y_test_rf_pred) \n",
    "accuracy_symbolic_class_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub(X0, neg(min(sub(sub(X0, neg(min(sub(X0, -0.774), max(X1, -0.870)))), -0.774), max(X1, -0.870))))'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_2b._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9330287497214175"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_symbolic_clas = np.where(calculate_function_values_from_sympy(simplify(sympify('sub(X0, neg(min(sub(sub(X0, neg(min(sub(X0, -0.774), max(X1, -0.870)))), -0.774), max(X1, -0.870))))', locals=converter)), X_test) > 0, 1, 0).astype(np.int64).reshape(-1,1)\n",
    "accuracy_symbolic_class_performance = f1_score(y_test_symbolic_clas, y_test_rf_pred) \n",
    "accuracy_symbolic_class_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8706221901537438"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF F1 Score\n",
    "f1_score(y_test_rf_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using y_train instead of y_train_rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_original_data = SymbolicClassifier(random_state=0,\n",
    "                                        verbose=1,\n",
    "                                        population_size=5000,\n",
    "                                        tournament_size=1000,\n",
    "                                        generations=15,\n",
    "                                        function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                                        init_depth=(4, 10),\n",
    "                                        init_method= 'half and half',\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'p_crossover': [0.0,0.1],\n",
    "    'p_subtree_mutation': [0.2,0.8],\n",
    "    'p_hoist_mutation': [0.0,0.2],\n",
    "    'p_point_mutation': [0.0,0.2],\n",
    "    'parsimony_coefficient': [0.0001],\n",
    "    'population_size':[5000,10000],\n",
    "    'init_method':['half and half','grow'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_orig = GridSearchCV(estimator=base_original_data,\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='f1',\n",
    "                            cv=3,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if rerun:\n",
    "    results_orig.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_help = None\n",
    "if rerun:\n",
    "    df_results_orig = pd.DataFrame(results_orig.cv_results_)\n",
    "    #df_results_orig = df_results_orig[['param_p_crossover','param_p_hoist_mutation','param_p_point_mutation','param_p_subtree_mutation', 'mean_test_score','rank_test_score']]\n",
    "    df_results_orig_sorted = df_results_orig.sort_values(by=['rank_test_score'])\n",
    "    print_help = df_results_orig_sorted.head(60)\n",
    "print_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results_orig.to_csv('df_results_original_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results_orig = pd.read_csv('df_results_original.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results_orig_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.0001,\n",
    "                            p_crossover=0.1,\n",
    "                            p_hoist_mutation=0.0,\n",
    "                            p_point_mutation=0.1,\n",
    "                            p_subtree_mutation=0.8,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    40.09          2.54557        3         0.210364              N/A      3.15m\n",
      "   1    10.92          1.83203        5         0.207675              N/A      3.06m\n",
      "   2     7.46          2.29661        7         0.204533              N/A      3.05m\n",
      "   3     9.77          1.67307       20         0.201294              N/A      2.95m\n",
      "   4    11.59          1.05335       18         0.198833              N/A      2.70m\n",
      "   5    18.65          0.60065       20         0.197088              N/A      2.63m\n",
      "   6    18.62          0.61157       20         0.193403              N/A      2.39m\n",
      "   7    19.15         0.591841       23         0.191467              N/A      2.19m\n",
      "   8    22.38         0.563481       22         0.190306              N/A      1.95m\n",
      "   9    22.06         0.560187       24         0.189244              N/A      1.62m\n",
      "  10    22.56         0.539468       26         0.188126              N/A      1.28m\n",
      "  11    23.14         0.542549       28         0.186334              N/A      1.00m\n",
      "  12    24.71         0.475519       42         0.184982              N/A     38.92s\n",
      "  13    25.89         0.481274       46          0.18494              N/A     19.47s\n",
      "  14    24.62         0.486199       41         0.184481              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0} + \\tan{\\left(\\cos{\\left(\\cos{\\left(\\log{\\left(\\left|{X_{1}}\\right| \\right)} - 0.840388697975154 \\right)} + \\max\\left(- 1.50829562594268 X_{2}, \\frac{\\sqrt{\\left|{\\max\\left(X_{0}, X_{1}\\right)}\\right|}}{X_{1}}, \\sin{\\left(0.616 X_{0} - X_{2} \\right)}, \\sin{\\left(\\cos{\\left(X_{1} - \\frac{\\log{\\left(2 \\right)}}{2} \\right)} \\right)}\\right) \\right)} \\right)}$"
      ],
      "text/plain": [
       "X0 + tan(cos(cos(log(Abs(X1)) - 0.840388697975154) + Max(-1.50829562594268*X2, sqrt(Abs(Max(X0, X1)))/X1, sin(0.616*X0 - X2), sin(cos(X1 - log(2)/2)))))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_orig.fit(X_train, y_train)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_orig._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add(tan(cos(add(cos(add(log(X1), sin(-0.998))), max(max(max(div(X2, -0.663), sin(cos(neg(sub(X1, log(sqrt(div(add(X2, X2), X2)))))))), sin(sub(mul(X0, 0.616), X2))), div(sqrt(max(X1, X0)), X1))))), X0)'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_orig._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Real Data: 0.9026548672566371\n",
      "Accuracy Symbolic Classification - Real Data: 0.9274\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_orig.predict(X_test)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Real Data:', f1_score(y_test, y_test_symbolic_clas))\n",
    "print('Accuracy Symbolic Classification - Real Data:', accuracy_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.001,\n",
    "                            p_crossover=0.1,\n",
    "                            p_hoist_mutation=0.0,\n",
    "                            p_point_mutation=0.1,\n",
    "                            p_subtree_mutation=0.8,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    40.09          2.54557        3         0.210364              N/A      3.11m\n",
      "   1     9.78          1.95088        8         0.204802              N/A      3.09m\n",
      "   2     7.55          2.47733       14         0.203334              N/A      3.09m\n",
      "   3    10.29          2.32396       27         0.200053              N/A      2.91m\n",
      "   4    10.17          2.35613       10         0.199608              N/A      2.67m\n",
      "   5    10.80          2.25032       11         0.197199              N/A      2.47m\n",
      "   6    12.16          2.05454       14         0.195476              N/A      2.11m\n",
      "   7    11.65          2.08978       11         0.194258              N/A      1.81m\n",
      "   8    12.98          1.94013       20         0.191312              N/A      1.60m\n",
      "   9    12.80          1.88161       13          0.19314              N/A      1.34m\n",
      "  10    13.01          1.95872       13         0.189744              N/A      1.07m\n",
      "  11    13.34          1.83741       13         0.189744              N/A     57.19s\n",
      "  12    14.85          1.71816       13         0.189586              N/A     33.46s\n",
      "  13    14.55          1.74273       13         0.189586              N/A     16.16s\n",
      "  14    14.49           1.6549       18         0.188662              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0} + X_{2} - \\sqrt{\\left|{\\max\\left(X_{0}, X_{2}\\right)}\\right|} + 0.469041575982343 \\sqrt{\\left|{\\min\\left(- X_{1} + X_{2}, \\left|{X_{3}}\\right|\\right)}\\right|}$"
      ],
      "text/plain": [
       "X0 + X2 - sqrt(Abs(Max(X0, X2))) + 0.469041575982343*sqrt(Abs(Min(-X1 + X2, Abs(X3))))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_orig.fit(X_train, y_train)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_orig._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub(add(sqrt(mul(min(sub(X2, X1), abs(X3)), -0.220)), add(X2, X0)), sqrt(max(X0, X2)))'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_orig._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Real Data: 0.895045285029302\n",
      "Accuracy Symbolic Classification - Real Data: 0.9212\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_orig.predict(X_test)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Real Data:', f1_score(y_test, y_test_symbolic_clas))\n",
    "print('Accuracy Symbolic Classification - Real Data:', accuracy_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'max', 'min', 'sin', 'cos', 'tan'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.01,\n",
    "                            p_crossover=0.1,\n",
    "                            p_hoist_mutation=0.0,\n",
    "                            p_point_mutation=0.1,\n",
    "                            p_subtree_mutation=0.8,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    40.09          2.54557        3         0.210364              N/A      3.14m\n",
      "   1     8.30          2.20707        8         0.204802              N/A      3.07m\n",
      "   2     6.17          2.58511        3         0.210364              N/A      3.08m\n",
      "   3     6.02          2.54064        3         0.210364              N/A      2.82m\n",
      "   4     5.84          2.55141        3         0.210364              N/A      2.52m\n",
      "   5     5.97           2.6554        3         0.210364              N/A      2.30m\n",
      "   6     6.17          2.51415        5         0.210364              N/A      2.00m\n",
      "   7     5.80          2.62823        3         0.210364              N/A      1.77m\n",
      "   8     5.92          2.55441        3         0.210364              N/A      1.74m\n",
      "   9     5.79          2.45672        6         0.207473              N/A      1.28m\n",
      "  10     6.10          2.47437        7         0.207279              N/A     59.95s\n",
      "  11     6.03           2.4628        3         0.210364              N/A     45.16s\n",
      "  12     6.00          2.52748        3         0.210364              N/A     30.51s\n",
      "  13     5.76          2.51158        3         0.210364              N/A     15.05s\n",
      "  14     5.79           2.4611        3         0.210364              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0} + X_{2}$"
      ],
      "text/plain": [
       "X0 + X2"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_orig.fit(X_train, y_train)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_orig._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Real Data: 0.8807105190119346\n",
      "Accuracy Symbolic Classification - Real Data: 0.91404\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_orig.predict(X_test)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Real Data:', f1_score(y_test, y_test_symbolic_clas))\n",
    "print('Accuracy Symbolic Classification - Real Data:', accuracy_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add(X2, X0)'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_orig._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8840531190715322\n",
      "Accuracy: 0.91688\n"
     ]
    }
   ],
   "source": [
    "y_testtt = np.where(calculate_function_values_from_sympy(simplify(sympify('X0', locals=converter)), X_test) > 0, 1, 0).astype(np.int64).reshape(-1,1)\n",
    "print('F1 Score:', f1_score(y_testtt, y_test))\n",
    "print('Accuracy:', accuracy_score(y_testtt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig = SymbolicClassifier(random_state=0,\n",
    "                            verbose=1,\n",
    "                            population_size=5000,\n",
    "                            tournament_size=1000,\n",
    "                            generations=15,\n",
    "                            function_set=('add', 'sub', 'mul', 'div'),\n",
    "                            init_depth=(4, 10),\n",
    "                            parsimony_coefficient=0.001,\n",
    "                            p_crossover=0.1,\n",
    "                            p_hoist_mutation=0.0,\n",
    "                            p_point_mutation=0.1,\n",
    "                            p_subtree_mutation=0.8,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   312.71          10.9753        3         0.210364              N/A      9.57m\n",
      "   1     9.20          5.57088        5          0.20686              N/A      3.18m\n",
      "   2     9.64          5.46863        5         0.206856              N/A      2.89m\n",
      "   3    10.01          5.58965        7         0.205152              N/A      2.69m\n",
      "   4    10.25           5.5983        7         0.205728              N/A      2.38m\n",
      "   5     9.71          5.61043        7         0.205209              N/A      2.17m\n",
      "   6    10.47          5.41544        5         0.206856              N/A      1.96m\n",
      "   7    10.65          5.22883        7         0.205484              N/A      1.77m\n",
      "   8    10.38          5.45987        7         0.197903              N/A      1.70m\n",
      "   9     9.84          5.30361        9         0.196378              N/A      1.22m\n",
      "  10    11.46          5.39867        9         0.196299              N/A     57.77s\n",
      "  11    11.14           5.2044       13         0.196477              N/A     45.07s\n",
      "  12    10.72          5.39044        9         0.197034              N/A     30.07s\n",
      "  13    11.92          5.34489        9          0.19739              N/A     15.20s\n",
      "  14    10.96           5.0771       13          0.19739              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle X_{0} + 0.052 X_{1} + 0.948 X_{2}$"
      ],
      "text/plain": [
       "X0 + 0.052*X1 + 0.948*X2"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_orig.fit(X_train, y_train)\n",
    "\n",
    "sym_class = simplify(sympify(str(test_orig._program), locals=converter))\n",
    "sym_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity (F1 Score) Symbolic Classification - Real Data: 0.8906571397639926\n",
      "Accuracy Symbolic Classification - Real Data: 0.9192\n"
     ]
    }
   ],
   "source": [
    "y_test_symbolic_clas = test_orig.predict(X_test)\n",
    "print('Fidelity (F1 Score) Symbolic Classification - Real Data:', f1_score(y_test, y_test_symbolic_clas))\n",
    "print('Accuracy Symbolic Classification - Real Data:', accuracy_score(y_test, y_test_symbolic_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
