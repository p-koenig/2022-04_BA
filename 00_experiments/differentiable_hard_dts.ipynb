{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ab8be2-1b4c-4370-a837-9176d15bea41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T10:53:47.463192Z",
     "iopub.status.busy": "2022-06-03T10:53:47.463001Z",
     "iopub.status.idle": "2022-06-03T10:53:51.850122Z",
     "shell.execute_reply": "2022-06-03T10:53:51.848765Z",
     "shell.execute_reply.started": "2022-06-03T10:53:47.463147Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = '' #'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa08eca3-ed45-4eca-bd81-d8d679cb13bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T10:53:51.852574Z",
     "iopub.status.busy": "2022-06-03T10:53:51.852293Z",
     "iopub.status.idle": "2022-06-03T10:53:51.856584Z",
     "shell.execute_reply": "2022-06-03T10:53:51.856003Z",
     "shell.execute_reply.started": "2022-06-03T10:53:51.852550Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f2e596-9bb2-4026-890e-7b42365e81f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T10:53:51.858028Z",
     "iopub.status.busy": "2022-06-03T10:53:51.857911Z",
     "iopub.status.idle": "2022-06-03T10:53:51.932669Z",
     "shell.execute_reply": "2022-06-03T10:53:51.932060Z",
     "shell.execute_reply.started": "2022-06-03T10:53:51.858015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DHDT(tf.Module):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            depth=3,\n",
    "            function_representation_type = 3,\n",
    "            number_of_variables = 5,\n",
    "            learning_rate=1e-2,\n",
    "            loss='binary_crossentropy',\n",
    "            random_seed=42,\n",
    "            verbosity=1):    \n",
    "        \n",
    "        \n",
    "        self.depth = depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = tf.keras.losses.get(loss)\n",
    "        self.seed = random_seed\n",
    "        self.verbosity = verbosity\n",
    "        self.function_representation_type = function_representation_type\n",
    "        self.number_of_variables = number_of_variables\n",
    "        \n",
    "        tf.random.set_seed(self.seed)\n",
    "        \n",
    "        function_representation_length = ( \n",
    "          (2 ** self.depth - 1) * 2 + (2 ** self.depth)  if self.function_representation_type == 1 \n",
    "          else (2 ** self.depth - 1) + ((2 ** self.depth - 1) * self.number_of_variables) + (2 ** self.depth) if self.function_representation_type == 2 \n",
    "          else ((2 ** self.depth - 1) * self.number_of_variables * 2) + (2 ** self.depth)  if self.function_representation_type >= 3 \n",
    "          else None\n",
    "                                      )        \n",
    "        \n",
    "        self.dt_params =  tf.Variable(tf.keras.initializers.GlorotUniform(seed=self.seed)(shape=(function_representation_length,)),\n",
    "                                      trainable=True,\n",
    "                                      name='dt_params')\n",
    "        \n",
    "        print(self.dt_params.shape)\n",
    "        self.internal_nodes, self.leaf_nodes = self.get_shaped_parameters_for_decision_tree()\n",
    "            \n",
    "        \n",
    "    def fit(self, X, y, batch_size=32, epochs=100, early_stopping_epochs=5):\n",
    "        \n",
    "        \n",
    "        for current_epoch in range(epochs):\n",
    "            tf.random.set_seed(self.seed + current_epoch)\n",
    "            X = tf.random.shuffle(X, seed=self.seed + current_epoch)\n",
    "            tf.random.set_seed(self.seed + current_epoch)\n",
    "            y = tf.random.shuffle(y, seed=self.seed + current_epoch)\n",
    "            \n",
    "            for index, (X_batch, y_batch) in enumerate(zip(make_batch(X, batch_size), make_batch(y, batch_size))):\n",
    "                current_loss = self.backward(X_batch, y_batch)\n",
    "                loss_list.append(float(current_loss))\n",
    "                \n",
    "                if self.verbosity > 2:\n",
    "                    batch_idx = (index+1)*batch_size\n",
    "                    msg = \"Epoch: {:02d} | Batch: {:03d} | Loss: {:.5f} |\"\n",
    "                    print(msg.format(epoch, batch_idx, current_loss))                   \n",
    "                          \n",
    "            msg = \"Epoch: {:02d} | Loss: {:.5f} |\"\n",
    "            print(msg.format(epoch, np.mean(loss_list)))       \n",
    "                          \n",
    "    def forward(self, X):\n",
    "        X = tf.dtypes.cast(tf.convert_to_tensor(X), tf.float32)       \n",
    "\n",
    "        maximum_depth = self.depth\n",
    "        leaf_node_num_ = 2 ** maximum_depth\n",
    "        internal_node_num_ = 2 ** maximum_depth - 1\n",
    "\n",
    "        function_values_dhdt = tf.vectorized_map(self.calculate_function_value_from_vanilla_decision_tree_parameter_single_sample_wrapper(leaf_node_num_, \n",
    "                                                                                                                                       internal_node_num_, \n",
    "                                                                                                                                       maximum_depth,\n",
    "                                                                                                                                       self.number_of_variables), \n",
    "                                                                                                                                       X)\n",
    "\n",
    "        return function_values_dhdt  \n",
    "           \n",
    "    def predict(self, X):\n",
    "        return forward(X)\n",
    "        \n",
    "    def backward(self, x,y):\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)#tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        with tf.GradientTape() as tape:\n",
    "            predicted = self.forward(x)\n",
    "            current_loss = self.loss(y, predicted)\n",
    "            \n",
    "        print('current_loss', current_loss)\n",
    "        print('self.dt_params', self.dt_params)\n",
    "        grads = tape.gradient(current_loss, self.dt_params)\n",
    "        #optimizer.apply_gradients(zip(grads, self.dt_params),\n",
    "        #                          global_step=tf.compat.v1.train.get_or_create_global_step())     \n",
    "        \n",
    "        print('grads', grads)\n",
    "        print('self.dt_params', self.dt_params)\n",
    "        optimizer.apply_gradients(zip(grads, self.dt_params))\n",
    "        self.internal_nodes, self.leaf_nodes = self.get_shaped_parameters_for_decision_tree()\n",
    "                  \n",
    "        return current_loss\n",
    "        \n",
    "    \n",
    "    def get_shaped_parameters_for_decision_tree(self):\n",
    "\n",
    "        internal_node_num_ = 2 ** self.depth - 1 \n",
    "        leaf_node_num_ = 2 ** self.depth\n",
    "\n",
    "        if self.function_representation_type == 1:\n",
    "\n",
    "            splits_coeff = self.dt_params[:internal_node_num_]\n",
    "            splits_coeff = tf.clip_by_value(splits_coeff, clip_value_min=0, clip_value_max=1)\n",
    "            splits_coeff_list = tf.split(splits_coeff, internal_node_num_)\n",
    "            splits_index = tf.cast(tf.clip_by_value(tf.round(self.dt_params[internal_node_num_:internal_node_num_*2]), clip_value_min=0, clip_value_max=self.number_of_variables-1), tf.int64)\n",
    "            splits_index_list = tf.split(splits_index, internal_node_num_)\n",
    "\n",
    "            splits_list = []\n",
    "            for values_node, indices_node in zip(splits_coeff_list, splits_index_list):\n",
    "                sparse_tensor = tf.sparse.SparseTensor(indices=tf.expand_dims(indices_node, axis=1), values=values_node, dense_shape=[self.number_of_variables])\n",
    "                dense_tensor = tf.sparse.to_dense(sparse_tensor)\n",
    "                splits_list.append(dense_tensor)             \n",
    "\n",
    "            splits = tf.stack(splits_list)            \n",
    "\n",
    "            leaf_classes = self.dt_params[internal_node_num_*2:]  \n",
    "            leaf_classes = tf.clip_by_value(leaf_classes, clip_value_min=0, clip_value_max=1)\n",
    "\n",
    "        elif self.function_representation_type == 2:\n",
    "\n",
    "            split_values_num_params = internal_node_num_ \n",
    "            split_index_num_params = self.number_of_variables * internal_node_num_\n",
    "            leaf_classes_num_params = leaf_node_num_ \n",
    "\n",
    "            split_values = self.dt_params[:split_values_num_params]\n",
    "            split_values_list_by_internal_node = tf.split(split_values, internal_node_num_)\n",
    "\n",
    "            split_index_array = self.dt_params[split_values_num_params:split_values_num_params+split_index_num_params]    \n",
    "            split_index_list_by_internal_node = tf.split(split_index_array, internal_node_num_)\n",
    "            split_index_list_by_internal_node_by_decision_sparsity = []\n",
    "            for tensor in split_index_list_by_internal_node:\n",
    "                split_index_list_by_internal_node_by_decision_sparsity.append(split_tensor)\n",
    "            split_index_list_by_internal_node_by_decision_sparsity_argmax = tf.split(tf.argmax(split_index_list_by_internal_node_by_decision_sparsity, axis=2), internal_node_num_)\n",
    "            split_index_list_by_internal_node_by_decision_sparsity_argmax_new = []\n",
    "            for tensor in split_index_list_by_internal_node_by_decision_sparsity_argmax:\n",
    "                tensor_squeeze = tf.squeeze(tensor, axis=0)\n",
    "                split_index_list_by_internal_node_by_decision_sparsity_argmax_new.append(tensor_squeeze)\n",
    "            split_index_list_by_internal_node_by_decision_sparsity_argmax = split_index_list_by_internal_node_by_decision_sparsity_argmax_new    \n",
    "            dense_tensor_list = []\n",
    "            for indices_node, values_node in zip(split_index_list_by_internal_node_by_decision_sparsity_argmax,  split_values_list_by_internal_node):\n",
    "                sparse_tensor = tf.sparse.SparseTensor(indices=tf.expand_dims(indices_node, axis=1), values=values_node, dense_shape=[self.number_of_variables])\n",
    "                dense_tensor = tf.sparse.to_dense(sparse_tensor)\n",
    "                dense_tensor_list.append(dense_tensor) \n",
    "            splits = tf.stack(dense_tensor_list)\n",
    "\n",
    "            leaf_classes_array = self.dt_params[split_values_num_params+split_index_num_params:]  \n",
    "            split_index_list_by_leaf_node = tf.split(leaf_classes_array, leaf_node_num_)\n",
    "\n",
    "            leaf_classes = tf.squeeze(tf.stack(split_index_list_by_leaf_node))\n",
    "\n",
    "        elif self.function_representation_type >= 3:\n",
    "\n",
    "            split_values_num_params = self.number_of_variables * internal_node_num_\n",
    "            split_index_num_params = self.number_of_variables * internal_node_num_\n",
    "            leaf_classes_num_params = leaf_node_num_ \n",
    "\n",
    "            split_values = self.dt_params[:split_values_num_params]\n",
    "            split_values_list_by_internal_node = tf.split(split_values, internal_node_num_)\n",
    "\n",
    "            split_index_array = self.dt_params[split_values_num_params:split_values_num_params+split_index_num_params]    \n",
    "            split_index_list_by_internal_node = tf.split(split_index_array, internal_node_num_)         \n",
    "\n",
    "            split_index_list_by_internal_node_max = tfa.seq2seq.hardmax(split_index_list_by_internal_node)\n",
    "\n",
    "            splits = tf.stack(tf.multiply(split_values_list_by_internal_node, split_index_list_by_internal_node_max))\n",
    "\n",
    "            leaf_classes_array = self.dt_params[split_values_num_params+split_index_num_params:]  \n",
    "            split_index_list_by_leaf_node = tf.split(leaf_classes_array, leaf_node_num_)\n",
    "\n",
    "            leaf_classes = tf.squeeze(tf.stack(split_index_list_by_leaf_node))\n",
    "\n",
    "\n",
    "\n",
    "        return splits, leaf_classes\n",
    "\n",
    "\n",
    "    def calculate_function_value_from_vanilla_decision_tree_parameter_single_sample_wrapper(self, leaf_node_num_, internal_node_num_, maximum_depth, number_of_variables):\n",
    "\n",
    "        #self.internal_nodes = tf.cast(self.internal_nodes, tf.float32)\n",
    "        #self.leaf_nodes = tf.cast(self.leaf_nodes, tf.float32)   \n",
    "\n",
    "        def calculate_function_value_from_vanilla_decision_tree_parameter_single_sample(x):\n",
    "\n",
    "            x = tf.cast(x, tf.float32)\n",
    "\n",
    "            internal_nodes_split = tf.split(self.internal_nodes, internal_node_num_)\n",
    "            internal_nodes_split_new = [[] for _ in range(maximum_depth)]\n",
    "            for i, tensor in enumerate(internal_nodes_split):\n",
    "                current_depth = np.ceil(np.log2((i+1)+1)).astype(np.int32)\n",
    "\n",
    "                internal_nodes_split_new[current_depth-1].append(tf.squeeze(tensor, axis=0))\n",
    "\n",
    "            internal_nodes_split = internal_nodes_split_new\n",
    "\n",
    "            split_value_list = []\n",
    "            for i in range(maximum_depth):\n",
    "                current_depth = i+1\n",
    "                num_nodes_current_layer = 2**current_depth - 1 - (2**(current_depth-1) - 1)\n",
    "                split_value_list_per_depth = []\n",
    "                for j in range(num_nodes_current_layer):\n",
    "                    zero_identifier = tf.not_equal(internal_nodes_split[i][j], tf.zeros_like(internal_nodes_split[i][j]))\n",
    "                    split_complete = tf.greater(x, internal_nodes_split[i][j])\n",
    "                    split_value = tf.reduce_any(tf.logical_and(zero_identifier, split_complete))\n",
    "                    split_value_filled = tf.fill( [2**(maximum_depth-current_depth)] , split_value)\n",
    "                    split_value_neg_filled = tf.fill([2**(maximum_depth-current_depth)], tf.logical_not(split_value))\n",
    "                    split_value_list_per_depth.append(tf.keras.backend.flatten(tf.stack([split_value_neg_filled, split_value_filled])))        \n",
    "                split_value_list.append(tf.keras.backend.flatten(tf.stack(split_value_list_per_depth)))\n",
    "\n",
    "            split_values = tf.cast(tf.reduce_all(tf.stack(split_value_list), axis=0), tf.float32)    \n",
    "            leaf_classes = tf.cast(self.leaf_nodes, tf.float32)\n",
    "            final_class_probability = 1-tf.reduce_max(tf.multiply(leaf_classes, split_values))                                                                                                                                            \n",
    "            return final_class_probability\n",
    "\n",
    "        return calculate_function_value_from_vanilla_decision_tree_parameter_single_sample\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7298793a-3131-489d-88c2-8c9da85d6db3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T10:53:51.933537Z",
     "iopub.status.busy": "2022-06-03T10:53:51.933421Z",
     "iopub.status.idle": "2022-06-03T10:53:52.002096Z",
     "shell.execute_reply": "2022-06-03T10:53:52.001524Z",
     "shell.execute_reply.started": "2022-06-03T10:53:51.933524Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=10_000, n_features=5, n_informative=2, n_redundant=2, random_state=42\n",
    ")\n",
    "\n",
    "train_samples = 100  # Samples used for training the models\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    shuffle=False,\n",
    "    test_size=10_000 - train_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4680db-14cd-4ecb-87f3-c649cdc7a855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T10:53:52.003103Z",
     "iopub.status.busy": "2022-06-03T10:53:52.002971Z",
     "iopub.status.idle": "2022-06-03T10:53:52.923248Z",
     "shell.execute_reply": "2022-06-03T10:53:52.922617Z",
     "shell.execute_reply.started": "2022-06-03T10:53:52.003085Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 12:53:52.305833: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-03 12:53:52.305886: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: dws-15\n",
      "2022-06-03 12:53:52.305894: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: dws-15\n",
      "2022-06-03 12:53:52.306093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.60.2\n",
      "2022-06-03 12:53:52.306120: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.60.2\n",
      "2022-06-03 12:53:52.306126: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.60.2\n",
      "2022-06-03 12:53:52.306689: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78,)\n",
      "current_loss tf.Tensor(4.7070003, shape=(), dtype=float32)\n",
      "self.dt_params <tf.Variable 'dt_params:0' shape=(78,) dtype=float32, numpy=\n",
      "array([-0.03282875, -0.09076975, -0.00796892, -0.0531195 ,  0.17835249,\n",
      "        0.17331357,  0.04504158, -0.05553168,  0.03671388, -0.11158578,\n",
      "       -0.16573708,  0.03106995, -0.08166121, -0.09131939, -0.05094133,\n",
      "        0.08476271, -0.01616873, -0.14997172, -0.11345824,  0.01733561,\n",
      "        0.19211806, -0.04551519, -0.17774567,  0.14585008, -0.09459972,\n",
      "        0.14635558,  0.05765201, -0.03145219, -0.10139881, -0.15865773,\n",
      "        0.18908806, -0.1345275 , -0.07853737, -0.05179307,  0.17468913,\n",
      "       -0.15274787,  0.00897281,  0.12965007, -0.1953034 ,  0.18019284,\n",
      "        0.13975246, -0.04140022, -0.10971177,  0.06693865, -0.18875885,\n",
      "       -0.00762086,  0.03739753,  0.07245822, -0.12163537, -0.14712685,\n",
      "       -0.06302536,  0.01606283,  0.03367572,  0.18798922, -0.19577129,\n",
      "        0.13074069,  0.02864893, -0.13725558, -0.15141842,  0.18969049,\n",
      "        0.16344936, -0.03035007, -0.11956195, -0.1848833 , -0.04252163,\n",
      "       -0.16404866, -0.04262766, -0.19477722,  0.07560502,  0.10877915,\n",
      "       -0.16373233,  0.0828013 , -0.11574418,  0.05377953,  0.09195851,\n",
      "        0.02228324,  0.15656795, -0.06251724], dtype=float32)>\n",
      "grads None\n",
      "self.dt_params <tf.Variable 'dt_params:0' shape=(78,) dtype=float32, numpy=\n",
      "array([-0.03282875, -0.09076975, -0.00796892, -0.0531195 ,  0.17835249,\n",
      "        0.17331357,  0.04504158, -0.05553168,  0.03671388, -0.11158578,\n",
      "       -0.16573708,  0.03106995, -0.08166121, -0.09131939, -0.05094133,\n",
      "        0.08476271, -0.01616873, -0.14997172, -0.11345824,  0.01733561,\n",
      "        0.19211806, -0.04551519, -0.17774567,  0.14585008, -0.09459972,\n",
      "        0.14635558,  0.05765201, -0.03145219, -0.10139881, -0.15865773,\n",
      "        0.18908806, -0.1345275 , -0.07853737, -0.05179307,  0.17468913,\n",
      "       -0.15274787,  0.00897281,  0.12965007, -0.1953034 ,  0.18019284,\n",
      "        0.13975246, -0.04140022, -0.10971177,  0.06693865, -0.18875885,\n",
      "       -0.00762086,  0.03739753,  0.07245822, -0.12163537, -0.14712685,\n",
      "       -0.06302536,  0.01606283,  0.03367572,  0.18798922, -0.19577129,\n",
      "        0.13074069,  0.02864893, -0.13725558, -0.15141842,  0.18969049,\n",
      "        0.16344936, -0.03035007, -0.11956195, -0.1848833 , -0.04252163,\n",
      "       -0.16404866, -0.04262766, -0.19477722,  0.07560502,  0.10877915,\n",
      "       -0.16373233,  0.0828013 , -0.11574418,  0.05377953,  0.09195851,\n",
      "        0.02228324,  0.15656795, -0.06251724], dtype=float32)>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2391057/3390335065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDHDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2391057/2420616714.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, batch_size, epochs, early_stopping_epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2391057/2420616714.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grads'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'self.dt_params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaf_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shaped_parameters_for_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "model = DHDT()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, early_stopping_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e91f27-cabd-4170-b779-652bfe83a43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
