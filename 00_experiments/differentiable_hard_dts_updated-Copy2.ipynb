{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c3b444-064b-4639-983d-238b3da68ad9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6531aaa-2c26-40f5-8078-d754aceda153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:56:34.795721Z",
     "iopub.status.busy": "2022-06-08T15:56:34.795512Z",
     "iopub.status.idle": "2022-06-08T15:56:34.802205Z",
     "shell.execute_reply": "2022-06-08T15:56:34.801791Z",
     "shell.execute_reply.started": "2022-06-08T15:56:34.795674Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dhdt': {\n",
    "        'depth': 3,\n",
    "        'learning_rate': 1e-3,\n",
    "        \n",
    "        'initializer': 'RandomNormal', #GlorotUniform\n",
    "        \n",
    "        'loss': 'binary_crossentropy',#'mae',\n",
    "        'optimizer': 'adam',        \n",
    "        \n",
    "        'beta_1': 10,\n",
    "        'beta_2': 20,\n",
    "        \n",
    "        'squeeze_factor': 1,\n",
    "        \n",
    "        'batch_size': 512,\n",
    "        'epochs': 1_000,\n",
    "        'early_stopping_epochs': 20,\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'make_classification': {\n",
    "        'number_of_variables': 5,\n",
    "        'n_samples': 5_000,\n",
    "    },\n",
    "\n",
    "    'computation': {\n",
    "        'random_seed': 42,\n",
    "        'num_eval': 10,\n",
    "        'trials': 5,\n",
    "        'n_jobs': 10,\n",
    "        'verbosity': 0,\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ab8be2-1b4c-4370-a837-9176d15bea41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:56:34.803094Z",
     "iopub.status.busy": "2022-06-08T15:56:34.802918Z",
     "iopub.status.idle": "2022-06-08T15:56:39.947573Z",
     "shell.execute_reply": "2022-06-08T15:56:39.946581Z",
     "shell.execute_reply.started": "2022-06-08T15:56:34.803078Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = '' #'true'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from utilities.utilities_updated import *\n",
    "from utilities.DHDT_updated import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2397843-32d2-4579-b197-0686f4a99b54",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e7da9-12bb-467f-919f-4fd510ce6463",
   "metadata": {},
   "source": [
    "## make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c428696c-bdf8-44bc-9b27-51e273efc345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:56:39.949883Z",
     "iopub.status.busy": "2022-06-08T15:56:39.949430Z",
     "iopub.status.idle": "2022-06-08T15:56:58.342099Z",
     "shell.execute_reply": "2022-06-08T15:56:58.340577Z",
     "shell.execute_reply.started": "2022-06-08T15:56:39.949849Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape (selected):  (10, 5)\n",
      "Original Data Shape (encoded):  (10, 5)\n",
      "Original Data Class Distribution:  5  (true) / 5  (false)\n",
      "(7, 5) (7,)\n",
      "(1, 5) (1,)\n",
      "(2, 5) (2,)\n",
      "True Ratio:  0.7142857142857143\n",
      "self.split_values [[0.065743871 -0.00771078421 0.0455693901 -0.0399572067 -0.00543764746]\n",
      " [0.0142183928 0.038308125 -0.031056447 0.04987159 0.0109796291]\n",
      " [-0.0539933406 -0.0993741602 0.078018479 -0.00845473818 -0.0689024329]\n",
      " ...\n",
      " [0.00476824213 -0.00533769093 -0.0891963765 0.0857295766 -0.058807075]\n",
      " [0.0574447289 0.0225268863 -0.0408620276 0.0475969873 0.0695651695]\n",
      " [0.00793114118 0.00524403714 0.0572558306 -0.0523975156 0.0107290065]]\n",
      "self.split_index_array [[0.10033574 0.0463655479 0.0578611679 -0.0509978496 -0.0239130612]\n",
      " [-0.0859791562 -0.0126337279 -0.00267067342 0.0417807 0.0724836886]\n",
      " [0.082272552 -0.0294264 0.0323567949 0.0398773625 -0.0173112955]\n",
      " ...\n",
      " [0.0392855071 0.0456922874 -0.00315807085 0.0829349756 -0.0471349768]\n",
      " [-0.00194597186 0.00211207 -0.0201334618 -0.135878325 0.0213194937]\n",
      " [-0.0222547 0.0323078483 0.131382421 -0.0228863284 -0.0624823682]]\n",
      "self.leaf_classes_array [0.0318823233 -0.000560745306 0.0930417 ... 0.00059879123 0.0275781211 0.0469635539]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c605596337d84d7c8fc413eac5aa49da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "XLA compilation requires a fixed tensor list size. Set the max number of elements. This could also happen if you're using a TensorArray in a while loop that does not have its maximum_iteration set, you can fix this by setting maximum_iteration to a suitable value.\n\nStack trace for op definition: \nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/runpy.py\", line 192, in _run_module_as_main\n  return _run_code(code, main_globals, None,\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/runpy.py\", line 85, in _run_code\n  exec(code, run_globals)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n  app.launch_new_instance()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n  app.start()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n  self.io_loop.start()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n  self.asyncio_loop.run_forever()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/asyncio/base_events.py\", line 563, in run_forever\n  self._run_once()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/asyncio/base_events.py\", line 1844, in _run_once\n  handle._run()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/asyncio/events.py\", line 81, in _run\n  self._context.run(self._callback, *self._args)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n  await self.process_one()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n  await dispatch(*args)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n  await result\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n  reply_content = await reply_content\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n  res = shell.run_cell(code, store_history=store_history, silent=silent)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n  return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n  result = self._run_cell(\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n  return runner(coro)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n  coro.send(None)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n  if (await self.run_code(code, result,  async_=asy)):\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n  exec(code_obj, self.user_global_ns, self.user_ns)\nFile \"tmp/ipykernel_782889/1363387808.py\", line 44, in <module>\n  scores_dict['history'] = model_dict['DHDT'].fit(dataset_dict['X_train'],\nFile \"ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated.py\", line 160, in fit\n  current_loss = self.backward(X_batch, y_batch)\nFile \"ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated.py\", line 412, in backward\n  predicted = self.forward(x)\nFile \"ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated.py\", line 279, in forward\n  function_values_dhdt = tf.vectorized_map(process_wrapper(X), tf.constant([0,1,2,3,4,5,6]))\n\n\t [[{{function_node __forward_cflow_gradient_wrapper_15189}}{{node loop_body/TopKV2_1/pfor/while/ExpandDims_0/accumulator}}]] [Op:__forward_forward_47851]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_782889/1363387808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m scores_dict['history'] = model_dict['DHDT'].fit(dataset_dict['X_train'], \n\u001b[0m\u001b[1;32m     45\u001b[0m                                               \u001b[0mdataset_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dhdt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, batch_size, epochs, early_stopping_epochs, valid_data)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m#optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)#tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m  \u001b[0;34m==\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: XLA compilation requires a fixed tensor list size. Set the max number of elements. This could also happen if you're using a TensorArray in a while loop that does not have its maximum_iteration set, you can fix this by setting maximum_iteration to a suitable value.\n\nStack trace for op definition: \nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/runpy.py\", line 192, in _run_module_as_main\n  return _run_code(code, main_globals, None,\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/runpy.py\", line 85, in _run_code\n  exec(code, run_globals)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n  app.launch_new_instance()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n  app.start()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n  self.io_loop.start()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n  self.asyncio_loop.run_forever()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/asyncio/base_events.py\", line 563, in run_forever\n  self._run_once()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/asyncio/base_events.py\", line 1844, in _run_once\n  handle._run()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/asyncio/events.py\", line 81, in _run\n  self._context.run(self._callback, *self._args)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n  await self.process_one()\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n  await dispatch(*args)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n  await result\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n  reply_content = await reply_content\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n  res = shell.run_cell(code, store_history=store_history, silent=silent)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n  return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n  result = self._run_cell(\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n  return runner(coro)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n  coro.send(None)\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n  if (await self.run_code(code, result,  async_=asy)):\nFile \"home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n  exec(code_obj, self.user_global_ns, self.user_ns)\nFile \"tmp/ipykernel_782889/1363387808.py\", line 44, in <module>\n  scores_dict['history'] = model_dict['DHDT'].fit(dataset_dict['X_train'],\nFile \"ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated.py\", line 160, in fit\n  current_loss = self.backward(X_batch, y_batch)\nFile \"ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated.py\", line 412, in backward\n  predicted = self.forward(x)\nFile \"ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated.py\", line 279, in forward\n  function_values_dhdt = tf.vectorized_map(process_wrapper(X), tf.constant([0,1,2,3,4,5,6]))\n\n\t [[{{function_node __forward_cflow_gradient_wrapper_15189}}{{node loop_body/TopKV2_1/pfor/while/ExpandDims_0/accumulator}}]] [Op:__forward_forward_47851]"
     ]
    }
   ],
   "source": [
    "config_test = deepcopy(config)\n",
    "config_test['make_classification']['n_samples'] = 10#10_000\n",
    "config_test['dhdt']['epochs'] = 10\n",
    "\n",
    "dataset_dict = {}\n",
    "model_dict = {}\n",
    "\n",
    "scores_dict = {'sklearn': {},\n",
    "               'DHDT': {}}\n",
    "\n",
    "dataset_dict = get_preprocessed_dataset('make_classification',\n",
    "                                        random_seed=config_test['computation']['random_seed'],\n",
    "                                        config=config_test['make_classification'],\n",
    "                                        verbosity=1)\n",
    "\n",
    "model_dict['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                               random_state=config_test['computation']['random_seed'])\n",
    "\n",
    "model_dict['sklearn'].fit(dataset_dict['X_train'], \n",
    "                          dataset_dict['y_train'])\n",
    "\n",
    "\n",
    "\n",
    "model_dict['DHDT'] = DHDT(dataset_dict['X_train'].shape[1],\n",
    "\n",
    "                            depth = config_test['dhdt']['depth'],\n",
    "\n",
    "                            learning_rate = config_test['dhdt']['learning_rate'],\n",
    "                            optimizer = config_test['dhdt']['optimizer'],\n",
    "                          \n",
    "                            initializer = config_test['dhdt']['initializer'],\n",
    "\n",
    "                            beta_1 = config_test['dhdt']['beta_1'],\n",
    "                            beta_2 = config_test['dhdt']['beta_2'],\n",
    "\n",
    "                            squeeze_factor = config_test['dhdt']['squeeze_factor'],\n",
    "\n",
    "                            loss = config_test['dhdt']['loss'],#'mae',\n",
    "\n",
    "                            random_seed = config_test['computation']['random_seed'],\n",
    "                            verbosity = 2)        \n",
    "\n",
    "\n",
    "scores_dict['history'] = model_dict['DHDT'].fit(dataset_dict['X_train'], \n",
    "                                              dataset_dict['y_train'], \n",
    "                                              batch_size=config_test['dhdt']['batch_size'], \n",
    "                                              epochs=config_test['dhdt']['epochs'], \n",
    "                                              early_stopping_epochs=config_test['dhdt']['early_stopping_epochs'], \n",
    "                                              valid_data=(dataset_dict['X_valid'], dataset_dict['y_valid']))\n",
    "\n",
    "\n",
    "\n",
    "scores_dict['sklearn']['accuracy_test'] = model_dict['sklearn'].score(dataset_dict['X_test'], \n",
    "                                                                 dataset_dict['y_test'])\n",
    "\n",
    "\n",
    "dataset_dict['y_test_dhdt'] = model_dict['DHDT'].predict(dataset_dict['X_test'])\n",
    "scores_dict['DHDT']['accuracy_test'] = accuracy_score(dataset_dict['y_test'], np.round(dataset_dict['y_test_dhdt']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368f40c-ada4-49c5-a8f3-b2b703a4b6b1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.342873Z",
     "iopub.status.idle": "2022-06-08T15:56:58.343253Z",
     "shell.execute_reply": "2022-06-08T15:56:58.343163Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.343151Z"
    }
   },
   "outputs": [],
   "source": [
    "function_values_dhdt = tf.reshape(tf.constant([], dtype=tf.int32),[0,])\n",
    "function_values_dhdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c28d2-fc01-40c8-9b0a-0b2e0966cb83",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.344227Z",
     "iopub.status.idle": "2022-06-08T15:56:58.344385Z",
     "shell.execute_reply": "2022-06-08T15:56:58.344308Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.344299Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "function_values_dhdt = tf.reshape(tf.constant([], dtype=tf.int32),[0,])\n",
    "function_values_dhdt = tf.concat([function_values_dhdt, [0]], axis=0)\n",
    "function_values_dhdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04ea73-302c-4f95-a52f-6f26af69f4a8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.345145Z",
     "iopub.status.idle": "2022-06-08T15:56:58.345304Z",
     "shell.execute_reply": "2022-06-08T15:56:58.345224Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.345216Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.reshape([1,2,3], [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26155540-e4e4-4ab1-8603-3b91142ccf06",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.346010Z",
     "iopub.status.idle": "2022-06-08T15:56:58.346168Z",
     "shell.execute_reply": "2022-06-08T15:56:58.346087Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.346079Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.reshape(tf.constant([[0],[1],[3]]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62c153-b736-4fe2-a3b7-c7a4e0d1c553",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.346740Z",
     "iopub.status.idle": "2022-06-08T15:56:58.346890Z",
     "shell.execute_reply": "2022-06-08T15:56:58.346816Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.346808Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reshape([[0],[1],[3]], [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f074cf-77bf-4aa2-95f6-4aee41bce92a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.347678Z",
     "iopub.status.idle": "2022-06-08T15:56:58.347984Z",
     "shell.execute_reply": "2022-06-08T15:56:58.347896Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.347886Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.squeeze(tf.where(True, 0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa194e81-ace2-4072-97c0-a44c2f4d7cd9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.348576Z",
     "iopub.status.idle": "2022-06-08T15:56:58.348852Z",
     "shell.execute_reply": "2022-06-08T15:56:58.348767Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.348758Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.concat([, tf.constant([1])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e202ec0-b279-4e23-a32d-7284d9c12540",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.349496Z",
     "iopub.status.idle": "2022-06-08T15:56:58.349807Z",
     "shell.execute_reply": "2022-06-08T15:56:58.349719Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.349709Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.ensure_shape([[0,1,1], [0,1,1]], [None,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd5ea4-9eb9-4511-a5ae-89093679900b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.350340Z",
     "iopub.status.idle": "2022-06-08T15:56:58.350640Z",
     "shell.execute_reply": "2022-06-08T15:56:58.350554Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.350544Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.reshape(tf.constant([1,2,3]), [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb3f0b-2764-4c9b-9f1d-542b0806fa66",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.351217Z",
     "iopub.status.idle": "2022-06-08T15:56:58.351569Z",
     "shell.execute_reply": "2022-06-08T15:56:58.351482Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.351471Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reduce_sum([[0,1,1], [0,1,1]], axis=None, keepdims=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e62970-7acd-49c1-9f32-041283ef96c2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.352151Z",
     "iopub.status.idle": "2022-06-08T15:56:58.352303Z",
     "shell.execute_reply": "2022-06-08T15:56:58.352225Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.352217Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.ensure_shape(tf.reduce_sum([[0,1,1], [0,1,1]], axis=None, keepdims=False), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61c55a-ffd3-43da-a3f2-1cc77dff47bb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.352874Z",
     "iopub.status.idle": "2022-06-08T15:56:58.353018Z",
     "shell.execute_reply": "2022-06-08T15:56:58.352948Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.352940Z"
    }
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a13b2a-ca9d-44de-9a52-b8ca61808093",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.353745Z",
     "iopub.status.idle": "2022-06-08T15:56:58.354079Z",
     "shell.execute_reply": "2022-06-08T15:56:58.353993Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.353983Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    parallel_eval_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_synthetic = parallel_eval_synthetic(delayed(evaluate_synthetic_parallel)(index = index,\n",
    "                                                                                                random_seed_data = config['computation']['random_seed']+index,\n",
    "                                                                                                random_seed_model = config['computation']['random_seed'],#+random_seed_model,\n",
    "                                                                                                config = config,\n",
    "                                                                                                verbosity = -1) for index in range(config['computation']['num_eval']))\n",
    "\n",
    "    for i, synthetic_result in enumerate(evaluation_results_synthetic):\n",
    "        if i == 0:\n",
    "            model_dict_synthetic = synthetic_result[0]\n",
    "            scores_dict_synthetic = synthetic_result[1]\n",
    "            dataset_dict_synthetic = synthetic_result[2]\n",
    "        else: \n",
    "            model_dict_synthetic = mergeDict(model_dict_synthetic, synthetic_result[0])\n",
    "            scores_dict_synthetic = mergeDict(scores_dict_synthetic, synthetic_result[1])\n",
    "            dataset_dict_synthetic = mergeDict(dataset_dict_synthetic, synthetic_result[2])\n",
    "\n",
    "\n",
    "    metrics = ['accuracy_test']\n",
    "    index = [i for i in range(config['computation']['num_eval'])]\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "    scores_DHDT = [scores_dict_synthetic[i]['DHDT'][metrics[0]] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "    scores_sklearn = [scores_dict_synthetic[i]['sklearn'][metrics[0]] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "\n",
    "    scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['num_eval'])\n",
    "    scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['num_eval'])\n",
    "\n",
    "    results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "    results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "\n",
    "    scores_dataframe_synthetic = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "    display(scores_dataframe_synthetic)\n",
    "    display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[1::3]])\n",
    "    display(scores_dataframe_synthetic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2b804-f2e3-4ec9-9c06-1334d7449519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f856c6c9-368b-4b75-b0d8-6e7a28e4267c",
   "metadata": {},
   "source": [
    "## Real-World Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9eca0-b6be-4389-960f-857e68e6b197",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.354598Z",
     "iopub.status.idle": "2022-06-08T15:56:58.354744Z",
     "shell.execute_reply": "2022-06-08T15:56:58.354671Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.354663Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    identifier_list = [\n",
    "                        'Adult',#: 32,\n",
    "                        'Bank Marketing',#: 32,\n",
    "                        'Loan Credit',#: 32,\n",
    "\n",
    "                        'Credit Card',#: 23, \n",
    "                        'Car',#: 21,\n",
    "\n",
    "\n",
    "                        'Absenteeism',#: 15,\n",
    "                        'Loan House',#: 15,\n",
    "                        'Cervical Cancer',#: 15,\n",
    "\n",
    "                        'Heart Disease',#: 13,           \n",
    "\n",
    "                        'Titanic',#: 10,\n",
    "                        'Medical Insurance',#: 10,\n",
    "                        'Wisconsin Breast Cancer Original',#: 10,\n",
    "                        'Wisconsin Diagnostic Breast Cancer',#: 10,\n",
    "                        'Wisconsin Prognostic Breast Cancer',#: 10,\n",
    "                        'Abalone',#: 10,\n",
    "\n",
    "                        'Habermans Survival',#: 3, \n",
    "                      ]\n",
    "\n",
    "    #identifier_list = ['Habermans Survival']\n",
    "\n",
    "    parallel_eval_real_world = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_real_world = parallel_eval_real_world(delayed(evaluate_real_world_parallel)(identifier_list=identifier_list, \n",
    "                                                                                                   random_seed_model=config['computation']['random_seed']+i,\n",
    "                                                                                                   config = config,\n",
    "                                                                                                   verbosity = -1) for i in range(config['computation']['trials']))\n",
    "\n",
    "\n",
    "    for i, real_world_result in enumerate(evaluation_results_real_world):\n",
    "        if i == 0:\n",
    "            model_dict_real_world = real_world_result[0]\n",
    "            scores_dict_real_world = real_world_result[1]\n",
    "            dataset_dict_real_world = real_world_result[2]\n",
    "        else: \n",
    "            model_dict_real_world = mergeDict(model_dict_real_world, real_world_result[0])\n",
    "            scores_dict_real_world = mergeDict(scores_dict_real_world, real_world_result[1])\n",
    "            dataset_dict_real_world = mergeDict(dataset_dict_real_world, real_world_result[2])\n",
    "\n",
    "    metrics = ['accuracy_test']\n",
    "    index = identifier_list\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "    scores_DHDT = [scores_dict_real_world[identifier]['DHDT'][metrics[0]] for identifier in identifier_list]\n",
    "\n",
    "    scores_sklearn = [scores_dict_real_world[identifier]['sklearn'][metrics[0]] for identifier in identifier_list]\n",
    "\n",
    "    scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "    scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "\n",
    "    results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "    results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "\n",
    "    scores_dataframe_real_world = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "    display(scores_dataframe_real_world)\n",
    "    display(scores_dataframe_real_world[scores_dataframe_real_world.columns[1::3]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c55370-5fa9-4f3c-a1a8-be597467f808",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.355367Z",
     "iopub.status.idle": "2022-06-08T15:56:58.355693Z",
     "shell.execute_reply": "2022-06-08T15:56:58.355604Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.355594Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    identifier = identifier_list[0]#\"Absenteeism\"\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict_real_world[identifier]['DHDT'].plot(normalizer_list=dataset_dict_real_world[identifier]['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict_real_world[identifier]['sklearn'], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fbd88-44c9-4d7f-b58d-def1eeb6d434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84e73582-0f9e-4522-9a94-dc59f4e566e9",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09315b63-50a1-4b2c-bfa9-d7b6d961de34",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.356506Z",
     "iopub.status.idle": "2022-06-08T15:56:58.356720Z",
     "shell.execute_reply": "2022-06-08T15:56:58.356619Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.356607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "        'depth': [3],\n",
    "        'learning_rate': [0.05, 0.01, 0.005, 0.001, 0.0005],#[0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "        \n",
    "        'loss': ['binary_crossentropy'],#['binary_crossentropy', 'rmse'],#'mae',\n",
    "        'optimizer': ['adam', 'sgd'],#['adam', 'sgd'],        \n",
    "        \n",
    "        'beta_1': [10, 50],#[10, 50, 100],\n",
    "        'beta_2': [10, 50],#[10, 50, 100],\n",
    "        \n",
    "        'squeeze_factor': [0.2, 0.5, 1, 2, 5],#[0.2, 0.5, 1, 2, 5],    \n",
    "}\n",
    "\n",
    "parameter_grid = ParameterGrid(parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952be342-9751-474b-8780-f185b3f9c29d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.357398Z",
     "iopub.status.idle": "2022-06-08T15:56:58.357620Z",
     "shell.execute_reply": "2022-06-08T15:56:58.357525Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.357513Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    parallel_hpo_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_hpo_synthetic = parallel_hpo_synthetic(delayed(evaluate_parameter_setting_synthetic)(parameter_setting) for parameter_setting in parameter_grid)\n",
    "\n",
    "    sorted_evaluation_results_hpo_synthetic = sorted(evaluation_results_hpo_synthetic, key=lambda x: x[0], reverse=True)\n",
    "    print(sorted_evaluation_results_hpo_synthetic[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af8512c-cb73-43ac-811a-d7d334db97ee",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T15:56:58.358240Z",
     "iopub.status.idle": "2022-06-08T15:56:58.358425Z",
     "shell.execute_reply": "2022-06-08T15:56:58.358334Z",
     "shell.execute_reply.started": "2022-06-08T15:56:58.358324Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    identifier_list = [\n",
    "                        'Titanic',\n",
    "                        'Absenteeism',\n",
    "                        #'Adult',\n",
    "                      ]\n",
    "\n",
    "    sorted_evaluation_results_hpo_real_dict = {}\n",
    "\n",
    "    for identifier in identifier_list:\n",
    "        parallel_hpo_real = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "        evaluation_results_hpo_real = parallel_hpo_real(delayed(evaluate_parameter_setting_real_world)(parameter_setting, identifier) for parameter_setting in parameter_grid)\n",
    "\n",
    "        sorted_evaluation_results_hpo_real = sorted(evaluation_results_hpo_real, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        sorted_evaluation_results_hpo_real_dict[identifier] = sorted_evaluation_results_hpo_real\n",
    "\n",
    "        print(sorted_evaluation_results_hpo_real[:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40147db1-760f-432d-ac2c-0267a8256f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358c9e7-58be-4006-b120-6b14f8364122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
