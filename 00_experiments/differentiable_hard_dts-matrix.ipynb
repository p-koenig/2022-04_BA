{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c3b444-064b-4639-983d-238b3da68ad9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6531aaa-2c26-40f5-8078-d754aceda153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:19:49.173379Z",
     "iopub.status.busy": "2022-06-07T12:19:49.173239Z",
     "iopub.status.idle": "2022-06-07T12:19:49.179548Z",
     "shell.execute_reply": "2022-06-07T12:19:49.179231Z",
     "shell.execute_reply.started": "2022-06-07T12:19:49.173337Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dhdt': {\n",
    "        'depth': 3,\n",
    "        'learning_rate': 1e-3,\n",
    "        \n",
    "        'loss': 'binary_crossentropy',#'mae',\n",
    "        'optimizer': 'adam',        \n",
    "        \n",
    "        'beta_1': 100,\n",
    "        'beta_2': 100,\n",
    "        \n",
    "        'squeeze_factor': 1,\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'make_classification': {\n",
    "        'number_of_variables': 5,\n",
    "        'n_samples': 10_000,\n",
    "    },\n",
    "\n",
    "    'computation': {\n",
    "        'random_seed': 42,\n",
    "        'num_eval': 20,\n",
    "        'trials': 5,\n",
    "        'n_jobs': 60,\n",
    "        'verbosity': 0,\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ab8be2-1b4c-4370-a837-9176d15bea41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:19:49.180146Z",
     "iopub.status.busy": "2022-06-07T12:19:49.180013Z",
     "iopub.status.idle": "2022-06-07T12:20:44.417895Z",
     "shell.execute_reply": "2022-06-07T12:20:44.417366Z",
     "shell.execute_reply.started": "2022-06-07T12:19:49.180131Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = '' #'true'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from utilities.utilities import *\n",
    "from utilities.DHDT import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2397843-32d2-4579-b197-0686f4a99b54",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e7da9-12bb-467f-919f-4fd510ce6463",
   "metadata": {},
   "source": [
    "## make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a13b2a-ca9d-44de-9a52-b8ca61808093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:20:44.419243Z",
     "iopub.status.busy": "2022-06-07T12:20:44.419096Z",
     "iopub.status.idle": "2022-06-07T12:37:53.729659Z",
     "shell.execute_reply": "2022-06-07T12:37:53.729124Z",
     "shell.execute_reply.started": "2022-06-07T12:20:44.419219Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend LokyBackend with 60 concurrent workers.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f13e412df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f2de07adf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f3b904aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f5b1842ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f0c505adf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f81c04aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Parallel(n_jobs=60)]: Done   6 out of  20 | elapsed: 12.0min remaining: 27.9min\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7fe23c1eef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f9f98430f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f7bc006ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f88a40eef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f69642eef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f705c1aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f6f2806ff70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Parallel(n_jobs=60)]: Done  13 out of  20 | elapsed: 14.6min remaining:  7.9min\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f18abd6df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f668422ff70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7fd11056ff70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f141c4aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f28c40eff70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f712056ff70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7fef3836ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Parallel(n_jobs=60)]: Done  20 out of  20 | elapsed: 17.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=60)]: Done  20 out of  20 | elapsed: 17.2min finished\n"
     ]
    }
   ],
   "source": [
    "#model_seed_list = [i for i in range(config['computation']['trials'])]\n",
    "#data_seed_list = [i for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "#combined_seed_list = list(product(model_seed_list, data_seed_list))\n",
    "\n",
    "parallel_eval_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_synthetic = parallel_eval_synthetic(delayed(evaluate_synthetic_parallel)(index = index,\n",
    "                                                                                            random_seed_data = config['computation']['random_seed']+index,\n",
    "                                                                                            random_seed_model = config['computation']['random_seed'],#+random_seed_model,\n",
    "                                                                                            trials = config['computation']['trials'],\n",
    "                                                                                            config = config['make_classification'],\n",
    "                                                                                            verbosity = -1) for index in range(config['computation']['num_eval']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe87d5f-06be-4f12-b65c-de1828a6f3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:37:53.732656Z",
     "iopub.status.busy": "2022-06-07T12:37:53.730486Z",
     "iopub.status.idle": "2022-06-07T12:37:53.737187Z",
     "shell.execute_reply": "2022-06-07T12:37:53.736711Z",
     "shell.execute_reply.started": "2022-06-07T12:37:53.732636Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, synthetic_result in enumerate(evaluation_results_synthetic):\n",
    "    if i == 0:\n",
    "        model_dict_synthetic = synthetic_result[0]\n",
    "        scores_dict_synthetic = synthetic_result[1]\n",
    "        dataset_dict_synthetic = synthetic_result[2]\n",
    "    else: \n",
    "        model_dict_synthetic = mergeDict(model_dict_synthetic, synthetic_result[0])\n",
    "        scores_dict_synthetic = mergeDict(scores_dict_synthetic, synthetic_result[1])\n",
    "        dataset_dict_synthetic = mergeDict(dataset_dict_synthetic, synthetic_result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eb2b804-f2e3-4ec9-9c06-1334d7449519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T13:23:43.062005Z",
     "iopub.status.busy": "2022-06-07T13:23:43.061627Z",
     "iopub.status.idle": "2022-06-07T13:23:43.104691Z",
     "shell.execute_reply": "2022-06-07T13:23:43.104023Z",
     "shell.execute_reply.started": "2022-06-07T13:23:43.061978Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHDT accuracy_mean</th>\n",
       "      <th>DHDT accuracy_max</th>\n",
       "      <th>DHDT accuracy_std</th>\n",
       "      <th>sklearn accuracy_mean</th>\n",
       "      <th>sklearn accuracy_max</th>\n",
       "      <th>sklearn accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.073941</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.078356</td>\n",
       "      <td>0.9353</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.9355</td>\n",
       "      <td>0.049970</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>0.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.7485</td>\n",
       "      <td>0.050682</td>\n",
       "      <td>0.7786</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>0.0172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6952</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.021695</td>\n",
       "      <td>0.8268</td>\n",
       "      <td>0.8580</td>\n",
       "      <td>0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7606</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0.069899</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7280</td>\n",
       "      <td>0.8620</td>\n",
       "      <td>0.153225</td>\n",
       "      <td>0.8479</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.0452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>0.098916</td>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.114639</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.0786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7491</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8001</td>\n",
       "      <td>0.8115</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.6499</td>\n",
       "      <td>0.6890</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>0.102543</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.8885</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.7141</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.133160</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.7580</td>\n",
       "      <td>0.042921</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.8515</td>\n",
       "      <td>0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.040899</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5878</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.073431</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.0794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.069792</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.6655</td>\n",
       "      <td>0.071457</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.068026</td>\n",
       "      <td>0.8661</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DHDT accuracy_mean  DHDT accuracy_max  DHDT accuracy_std  \\\n",
       "0               0.6131             0.7140           0.073941   \n",
       "1               0.8465             0.8935           0.078356   \n",
       "2               0.8814             0.9355           0.049970   \n",
       "3               0.6747             0.7485           0.050682   \n",
       "4               0.6952             0.7155           0.021695   \n",
       "5               0.7606             0.8180           0.069899   \n",
       "6               0.7280             0.8620           0.153225   \n",
       "7               0.7161             0.8575           0.098916   \n",
       "8               0.8593             0.9235           0.114639   \n",
       "9               0.7491             0.8100           0.044152   \n",
       "10              0.8001             0.8115           0.017104   \n",
       "11              0.6499             0.6890           0.021388   \n",
       "12              0.6847             0.8130           0.102543   \n",
       "13              0.7141             0.8400           0.133160   \n",
       "14              0.6786             0.7580           0.042921   \n",
       "15              0.7045             0.7775           0.040899   \n",
       "16              0.5878             0.6980           0.073431   \n",
       "17              0.6970             0.7840           0.069792   \n",
       "18              0.5620             0.6655           0.071457   \n",
       "19              0.7550             0.8085           0.068026   \n",
       "\n",
       "    sklearn accuracy_mean  sklearn accuracy_max  sklearn accuracy_std  \n",
       "0                  0.8364                0.8820                0.0228  \n",
       "1                  0.9353                0.9385                0.0016  \n",
       "2                  0.9231                0.9345                0.0228  \n",
       "3                  0.7786                0.8130                0.0172  \n",
       "4                  0.8268                0.8580                0.0156  \n",
       "5                  0.8609                0.9185                0.0288  \n",
       "6                  0.8479                0.8705                0.0452  \n",
       "7                  0.8278                0.8415                0.0274  \n",
       "8                  0.9002                0.9395                0.0786  \n",
       "9                  0.8275                0.8755                0.0240  \n",
       "10                 0.8990                0.8990                0.0000  \n",
       "11                 0.7576                0.7680                0.0052  \n",
       "12                 0.8865                0.8885                0.0010  \n",
       "13                 0.9337                0.9605                0.0134  \n",
       "14                 0.8459                0.8515                0.0112  \n",
       "15                 0.7825                0.7825                0.0000  \n",
       "16                 0.8082                0.9670                0.0794  \n",
       "17                 0.7784                0.7855                0.0142  \n",
       "18                 0.8375                0.8375                0.0000  \n",
       "19                 0.8661                0.8705                0.0022  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHDT accuracy_max</th>\n",
       "      <th>sklearn accuracy_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.8820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.9385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9355</td>\n",
       "      <td>0.9345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7485</td>\n",
       "      <td>0.8130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8180</td>\n",
       "      <td>0.9185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8620</td>\n",
       "      <td>0.8705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8575</td>\n",
       "      <td>0.8415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.9395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.8755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8115</td>\n",
       "      <td>0.8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.6890</td>\n",
       "      <td>0.7680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8130</td>\n",
       "      <td>0.8885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7580</td>\n",
       "      <td>0.8515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.7855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.6655</td>\n",
       "      <td>0.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.8705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DHDT accuracy_max  sklearn accuracy_max\n",
       "0              0.7140                0.8820\n",
       "1              0.8935                0.9385\n",
       "2              0.9355                0.9345\n",
       "3              0.7485                0.8130\n",
       "4              0.7155                0.8580\n",
       "5              0.8180                0.9185\n",
       "6              0.8620                0.8705\n",
       "7              0.8575                0.8415\n",
       "8              0.9235                0.9395\n",
       "9              0.8100                0.8755\n",
       "10             0.8115                0.8990\n",
       "11             0.6890                0.7680\n",
       "12             0.8130                0.8885\n",
       "13             0.8400                0.9605\n",
       "14             0.7580                0.8515\n",
       "15             0.7775                0.7825\n",
       "16             0.6980                0.9670\n",
       "17             0.7840                0.7855\n",
       "18             0.6655                0.8375\n",
       "19             0.8085                0.8705"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHDT accuracy_mean</th>\n",
       "      <th>DHDT accuracy_max</th>\n",
       "      <th>DHDT accuracy_std</th>\n",
       "      <th>sklearn accuracy_mean</th>\n",
       "      <th>sklearn accuracy_max</th>\n",
       "      <th>sklearn accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.717885</td>\n",
       "      <td>0.796150</td>\n",
       "      <td>0.069810</td>\n",
       "      <td>0.847995</td>\n",
       "      <td>0.874100</td>\n",
       "      <td>0.020530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.076824</td>\n",
       "      <td>0.036579</td>\n",
       "      <td>0.052886</td>\n",
       "      <td>0.058696</td>\n",
       "      <td>0.023365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.562000</td>\n",
       "      <td>0.665500</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.757600</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.677625</td>\n",
       "      <td>0.740250</td>\n",
       "      <td>0.043845</td>\n",
       "      <td>0.822150</td>\n",
       "      <td>0.840500</td>\n",
       "      <td>0.002050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.709300</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>0.069846</td>\n",
       "      <td>0.841700</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.756400</td>\n",
       "      <td>0.844375</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.024850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.881400</td>\n",
       "      <td>0.935500</td>\n",
       "      <td>0.153225</td>\n",
       "      <td>0.935300</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>0.079400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DHDT accuracy_mean  DHDT accuracy_max  DHDT accuracy_std  \\\n",
       "count           20.000000          20.000000          20.000000   \n",
       "mean             0.717885           0.796150           0.069810   \n",
       "std              0.084852           0.076824           0.036579   \n",
       "min              0.562000           0.665500           0.017104   \n",
       "25%              0.677625           0.740250           0.043845   \n",
       "50%              0.709300           0.809250           0.069846   \n",
       "75%              0.756400           0.844375           0.083496   \n",
       "max              0.881400           0.935500           0.153225   \n",
       "\n",
       "       sklearn accuracy_mean  sklearn accuracy_max  sklearn accuracy_std  \n",
       "count              20.000000             20.000000             20.000000  \n",
       "mean                0.847995              0.874100              0.020530  \n",
       "std                 0.052886              0.058696              0.023365  \n",
       "min                 0.757600              0.768000              0.000000  \n",
       "25%                 0.822150              0.840500              0.002050  \n",
       "50%                 0.841700              0.873000              0.014900  \n",
       "75%                 0.889625              0.922500              0.024850  \n",
       "max                 0.935300              0.967000              0.079400  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = ['accuracy']\n",
    "index = [i for i in range(config['computation']['num_eval'])]\n",
    "columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "scores_DHDT = [scores_dict_synthetic[i]['DHDT']['accuracy'] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "scores_sklearn = [scores_dict_synthetic[i]['sklearn']['accuracy'] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "\n",
    "scores_DHDT_mean = np.mean(scores_DHDT, axis=1)\n",
    "scores_sklearn_mean = np.mean(scores_sklearn, axis=1)\n",
    "                        \n",
    "scores_DHDT_max = np.max(scores_DHDT, axis=1)\n",
    "scores_sklearn_max = np.max(scores_sklearn, axis=1)\n",
    "                        \n",
    "scores_DHDT_std = np.std(scores_DHDT, axis=1)\n",
    "scores_sklearn_std = np.std(scores_sklearn, axis=1)\n",
    "\n",
    "results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "\n",
    "scores_dataframe_synthetic = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "display(scores_dataframe_synthetic)\n",
    "display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[1::3]])\n",
    "display(scores_dataframe_synthetic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb9eca0-b6be-4389-960f-857e68e6b197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:37:53.910463Z",
     "iopub.status.busy": "2022-06-07T12:37:53.910281Z",
     "iopub.status.idle": "2022-06-07T12:57:28.822590Z",
     "shell.execute_reply": "2022-06-07T12:57:28.821992Z",
     "shell.execute_reply.started": "2022-06-07T12:37:53.910445Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend LokyBackend with 60 concurrent workers.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7fe2807c0f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7f9ff0170f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7f7ca0277f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7f88ec5a0f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7f69a46c6f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Parallel(n_jobs=60)]: Done   2 out of   5 | elapsed:  2.7min remaining:  4.0min\n",
      "[Parallel(n_jobs=60)]: Done   5 out of   5 | elapsed: 19.6min finished\n"
     ]
    }
   ],
   "source": [
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "parallel_eval_real_world = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_real_world = parallel_eval_real_world(delayed(evaluate_real_world_parallel)(identifier_list=identifier_list, \n",
    "                                                                                               random_seed_model=config['computation']['random_seed']+i,\n",
    "                                                                                               verbosity = -1) for i in range(config['computation']['trials']))\n",
    "\n",
    "\n",
    "for i, real_world_result in enumerate(evaluation_results_real_world):\n",
    "    if i == 0:\n",
    "        model_dict_real_world = real_world_result[0]\n",
    "        scores_dict_real_world = real_world_result[1]\n",
    "        dataset_dict_real_world = real_world_result[2]\n",
    "    else: \n",
    "        model_dict_real_world = mergeDict(model_dict_real_world, real_world_result[0])\n",
    "        scores_dict_real_world = mergeDict(scores_dict_real_world, real_world_result[1])\n",
    "        dataset_dict_real_world = mergeDict(dataset_dict_real_world, real_world_result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c55370-5fa9-4f3c-a1a8-be597467f808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:57:28.824058Z",
     "iopub.status.busy": "2022-06-07T12:57:28.823874Z",
     "iopub.status.idle": "2022-06-07T12:57:28.846025Z",
     "shell.execute_reply": "2022-06-07T12:57:28.845371Z",
     "shell.execute_reply.started": "2022-06-07T12:57:28.824035Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHDT accuracy_mean</th>\n",
       "      <th>DHDT accuracy_std</th>\n",
       "      <th>sklearn accuracy_mean</th>\n",
       "      <th>sklearn accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cervical Cancer</th>\n",
       "      <td>0.341520</td>\n",
       "      <td>0.247738</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit Card</th>\n",
       "      <td>0.512833</td>\n",
       "      <td>0.252194</td>\n",
       "      <td>0.776167</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DHDT accuracy_mean  DHDT accuracy_std  sklearn accuracy_mean  \\\n",
       "Cervical Cancer            0.341520           0.247738               0.467836   \n",
       "Credit Card                0.512833           0.252194               0.776167   \n",
       "\n",
       "                 sklearn accuracy_std  \n",
       "Cervical Cancer                   0.0  \n",
       "Credit Card                       0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['accuracy']\n",
    "index = identifier_list\n",
    "columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "scores_DHDT = [scores_dict_real_world[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict_real_world[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "\n",
    "scores_DHDT_mean = np.mean(scores_DHDT, axis=1)\n",
    "scores_sklearn_mean = np.mean(scores_sklearn, axis=1)\n",
    "\n",
    "scores_DHDT_std = np.std(scores_DHDT, axis=1)\n",
    "scores_sklearn_std = np.std(scores_sklearn, axis=1)\n",
    "\n",
    "results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_std])\n",
    "results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_std])\n",
    "\n",
    "\n",
    "scores_dataframe_real_world = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "scores_dataframe_real_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb85a81-881b-47be-96d8-6c6d0578b810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:57:28.847157Z",
     "iopub.status.busy": "2022-06-07T12:57:28.847016Z",
     "iopub.status.idle": "2022-06-07T12:57:29.196052Z",
     "shell.execute_reply": "2022-06-07T12:57:29.195498Z",
     "shell.execute_reply.started": "2022-06-07T12:57:28.847139Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cervical Cancer': {'sklearn': {'accuracy': [0.4678362573099415,\n",
       "    0.4678362573099415,\n",
       "    0.4678362573099415,\n",
       "    0.4678362573099415,\n",
       "    0.4678362573099415]},\n",
       "  'DHDT': {'accuracy': [0.17543859649122806,\n",
       "    0.06432748538011696,\n",
       "    0.6374269005847953,\n",
       "    0.6432748538011696,\n",
       "    0.1871345029239766]},\n",
       "  'history': [None, None, None, None, None]},\n",
       " 'Credit Card': {'sklearn': {'accuracy': [0.7761666666666667,\n",
       "    0.7761666666666667,\n",
       "    0.7761666666666667,\n",
       "    0.7761666666666667,\n",
       "    0.7761666666666667]},\n",
       "  'DHDT': {'accuracy': [0.21883333333333332,\n",
       "    0.21916666666666668,\n",
       "    0.7766666666666666,\n",
       "    0.5668333333333333,\n",
       "    0.7826666666666666]},\n",
       "  'history': [None, None, None, None, None]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dict_real_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d69a94-8df3-4133-9e78-239bf0fcec79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:57:29.197128Z",
     "iopub.status.busy": "2022-06-07T12:57:29.196991Z",
     "iopub.status.idle": "2022-06-07T12:57:29.325871Z",
     "shell.execute_reply": "2022-06-07T12:57:29.325217Z",
     "shell.execute_reply.started": "2022-06-07T12:57:29.197109Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict_real_world[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict_real_world[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b0c3f97-e5ab-4b06-9a17-1c23448800fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:57:29.329482Z",
     "iopub.status.busy": "2022-06-07T12:57:29.329314Z",
     "iopub.status.idle": "2022-06-07T12:57:29.454896Z",
     "shell.execute_reply": "2022-06-07T12:57:29.454578Z",
     "shell.execute_reply.started": "2022-06-07T12:57:29.329461Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34152047, 0.51283333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores_DHDT, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ec52977-11ff-467a-82e5-89856a10293d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:57:29.456529Z",
     "iopub.status.busy": "2022-06-07T12:57:29.456193Z",
     "iopub.status.idle": "2022-06-07T12:57:32.785290Z",
     "shell.execute_reply": "2022-06-07T12:57:32.784575Z",
     "shell.execute_reply.started": "2022-06-07T12:57:29.456506Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (5, 4), indices imply (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3154941/286638212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores_sklearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscores_dict_real_world\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sklearn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midentifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midentifier_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscores_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscores_DHDT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_sklearn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'DHDT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sklearn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscores_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 )\n\u001b[1;32m    671\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    673\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5, 4), indices imply (2, 2)"
     ]
    }
   ],
   "source": [
    "scores_DHDT = [scores_dict_real_world[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict_real_world[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d00d23-cea4-4946-9495-93a9578c7939",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.786040Z",
     "iopub.status.idle": "2022-06-07T12:57:32.786221Z",
     "shell.execute_reply": "2022-06-07T12:57:32.786139Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.786128Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73bba7-c127-4e07-939e-72a1417d27cd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.787565Z",
     "iopub.status.idle": "2022-06-07T12:57:32.787759Z",
     "shell.execute_reply": "2022-06-07T12:57:32.787657Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.787647Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09315b63-50a1-4b2c-bfa9-d7b6d961de34",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.788822Z",
     "iopub.status.idle": "2022-06-07T12:57:32.789021Z",
     "shell.execute_reply": "2022-06-07T12:57:32.788914Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.788906Z"
    }
   },
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "        'depth': 3,\n",
    "        'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "        \n",
    "        'loss': ['binary_crossentropy', 'rmse'],#'mae',\n",
    "        'optimizer': ['adam', 'sgd'],        \n",
    "        \n",
    "        'beta_1': [10, 50, 100],\n",
    "        'beta_2': [10, 50, 100],\n",
    "        \n",
    "        'squeeze_factor': [0.2, 0.5, 1, 2, 5],    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e9145-2b47-467f-96df-d3bb0f83226a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.789874Z",
     "iopub.status.idle": "2022-06-07T12:57:32.790043Z",
     "shell.execute_reply": "2022-06-07T12:57:32.789962Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.789953Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_DHDT_make_class = [scores_dict_make_class[identifier]['DHDT']['accuracy'] for identifier in range(num_make_class_eval)]\n",
    "\n",
    "scores_sklearn_make_class = [scores_dict_make_class[identifier]['sklearn']['accuracy'] for identifier in range(num_make_class_eval)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db42a3-560d-4f55-b2d3-ee52da3cb7f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## real-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ca2d2-73a1-4675-8d6e-4f75d096fb4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05f2f8-19b1-4800-b9ae-85c0599f0425",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.791031Z",
     "iopub.status.idle": "2022-06-07T12:57:32.791222Z",
     "shell.execute_reply": "2022-06-07T12:57:32.791120Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.791110Z"
    }
   },
   "outputs": [],
   "source": [
    "--> put eval in function \n",
    "    --> make parallel execution with different seeds / splits, etcs \n",
    "        --> compare (save all values and generate mean+std df, but keep all values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafb753-2e3d-4480-9998-659ff6034a78",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.791803Z",
     "iopub.status.idle": "2022-06-07T12:57:32.791965Z",
     "shell.execute_reply": "2022-06-07T12:57:32.791886Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.791877Z"
    }
   },
   "outputs": [],
   "source": [
    "config['n_samples'] = 10_000\n",
    "config['number_of_variables'] = 5\n",
    "random_seed = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab170fa2-c32f-402e-8b60-38b542ae3840",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.793089Z",
     "iopub.status.idle": "2022-06-07T12:57:32.793283Z",
     "shell.execute_reply": "2022-06-07T12:57:32.793179Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.793171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_jobs = 20\n",
    "\n",
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "parallel_real_world_eval = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_by_dataset = parallel_real_world_eval(delayed(evaluate_dhdt)(identifier) for identifier in identifier_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c7b89-7752-49a8-9424-306b2d1d172d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.794200Z",
     "iopub.status.idle": "2022-06-07T12:57:32.794374Z",
     "shell.execute_reply": "2022-06-07T12:57:32.794288Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.794279Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "trials = 20\n",
    "n_jobs = 20\n",
    "random_seed = 42\n",
    "\n",
    "parallel_real_world_eval = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_by_dataset = parallel_real_world_eval(delayed(evaluate_all_parallel)(identifier_list=identifier_list, \n",
    "                                                                               random_seed=random_seed+i) for i in range(trials))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3fdc5-9ae2-47ba-b4db-b2ef5988d1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf508df-fa1a-4c9a-9495-4adfac6c8478",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.795165Z",
     "iopub.status.idle": "2022-06-07T12:57:32.795331Z",
     "shell.execute_reply": "2022-06-07T12:57:32.795250Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.795241Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "evaluate_all_real_world(identifier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142651c4-44b3-4598-acc2-d71f8980849c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.796328Z",
     "iopub.status.idle": "2022-06-07T12:57:32.796636Z",
     "shell.execute_reply": "2022-06-07T12:57:32.796465Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.796450Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_all_real_world(identifier_list):\n",
    "    \n",
    "    identifier_list = ['Cervical Cancer',\n",
    "                       'Credit Card',\n",
    "                       'Absenteeism']\n",
    "\n",
    "    dataset_dict = {}\n",
    "    model_dict = {}\n",
    "\n",
    "    scores_dict = {}\n",
    "\n",
    "    for identifier in tqdm(identifier_list, desc='dataset loop'):\n",
    "\n",
    "        print('_________________________________________________________________________________________________________________')   \n",
    "\n",
    "        dataset_dict[identifier] = {}\n",
    "        model_dict[identifier] = {}\n",
    "\n",
    "        scores_dict[identifier] = {'sklearn': {},\n",
    "                                   'DHDT': {}}\n",
    "\n",
    "        dataset_dict[identifier] = get_preprocessed_dataset(identifier)    \n",
    "\n",
    "        model_dict[identifier]['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                                                   random_state=42)\n",
    "\n",
    "        model_dict[identifier]['sklearn'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                              dataset_dict[identifier]['y_train'])\n",
    "\n",
    "        scores_dict[identifier]['sklearn']['accuracy'] = model_dict[identifier]['sklearn'].score(dataset_dict[identifier]['X_test'], \n",
    "                                                                                                 dataset_dict[identifier]['y_test'])\n",
    "\n",
    "\n",
    "\n",
    "        model_dict[identifier]['DHDT'] = DHDT(depth=3,\n",
    "                                                 number_of_variables = dataset_dict[identifier]['X_train'].shape[1],\n",
    "                                                 learning_rate=1e-3,\n",
    "                                                 squeeze_factor = 1,\n",
    "                                                 loss='binary_crossentropy',#'binary_crossentropy',\n",
    "                                                 optimizer='rmsprop',\n",
    "                                                 random_seed=40,\n",
    "                                                 verbosity=0)\n",
    "\n",
    "        scores_dict[identifier]['history'] = model_dict[identifier]['DHDT'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                                                              dataset_dict[identifier]['y_train'], \n",
    "                                                                              batch_size=512, \n",
    "                                                                              epochs=1_000, \n",
    "                                                                              early_stopping_epochs=50, \n",
    "                                                                              valid_data=(dataset_dict[identifier]['X_valid'], dataset_dict[identifier]['y_valid']))\n",
    "\n",
    "        dataset_dict[identifier]['y_test_dhdt'] = model_dict[identifier]['DHDT'].predict(dataset_dict[identifier]['X_test'])\n",
    "        scores_dict[identifier]['DHDT']['accuracy'] = accuracy_score(dataset_dict[identifier]['y_test'], np.round(dataset_dict[identifier]['y_test_dhdt']))\n",
    "\n",
    "        print('Test Accuracy Sklearn (' + identifier + ')', scores_dict[identifier]['sklearn']['accuracy'])\n",
    "        print('Test Accuracy DHDT (' + identifier + ')', scores_dict[identifier]['DHDT']['accuracy'])   \n",
    "        print('_________________________________________________________________________________________________________________')   \n",
    "\n",
    "    return   model_dict, scores_dict, dataset_dit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773d8d6-ba4e-42b5-b981-2edd4a323fc9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.797595Z",
     "iopub.status.idle": "2022-06-07T12:57:32.797851Z",
     "shell.execute_reply": "2022-06-07T12:57:32.797710Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.797699Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = ['Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   'Absenteeism']\n",
    "\n",
    "dataset_dict = {}\n",
    "model_dict = {}\n",
    "\n",
    "scores_dict = {}\n",
    "\n",
    "for identifier in tqdm(identifier_list, desc='dataset loop'):\n",
    "    \n",
    "    print('_________________________________________________________________________________________________________________')   \n",
    "    \n",
    "    dataset_dict[identifier] = {}\n",
    "    model_dict[identifier] = {}\n",
    "\n",
    "    scores_dict[identifier] = {'sklearn': {},\n",
    "                               'DHDT': {}}\n",
    "    \n",
    "    dataset_dict[identifier] = get_preprocessed_dataset(identifier)    \n",
    "\n",
    "    model_dict[identifier]['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                                               random_state=42)\n",
    "\n",
    "    model_dict[identifier]['sklearn'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                          dataset_dict[identifier]['y_train'])\n",
    "\n",
    "    scores_dict[identifier]['sklearn']['accuracy'] = model_dict[identifier]['sklearn'].score(dataset_dict[identifier]['X_test'], \n",
    "                                                                                             dataset_dict[identifier]['y_test'])\n",
    "\n",
    "\n",
    "\n",
    "    model_dict[identifier]['DHDT'] = DHDT(depth=3,\n",
    "                                             number_of_variables = dataset_dict[identifier]['X_train'].shape[1],\n",
    "                                             learning_rate=1e-3,\n",
    "                                             squeeze_factor = 1,\n",
    "                                             loss='binary_crossentropy',#'binary_crossentropy',\n",
    "                                             optimizer='rmsprop',\n",
    "                                             random_seed=40,\n",
    "                                             verbosity=0)\n",
    "\n",
    "    scores_dict[identifier]['history'] = model_dict[identifier]['DHDT'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                                                          dataset_dict[identifier]['y_train'], \n",
    "                                                                          batch_size=512, \n",
    "                                                                          epochs=1_000, \n",
    "                                                                          early_stopping_epochs=50, \n",
    "                                                                          valid_data=(dataset_dict[identifier]['X_valid'], dataset_dict[identifier]['y_valid']))\n",
    "\n",
    "    dataset_dict[identifier]['y_test_dhdt'] = model_dict[identifier]['DHDT'].predict(dataset_dict[identifier]['X_test'])\n",
    "    scores_dict[identifier]['DHDT']['accuracy'] = accuracy_score(dataset_dict[identifier]['y_test'], np.round(dataset_dict[identifier]['y_test_dhdt']))\n",
    "    \n",
    "    print('Test Accuracy Sklearn (' + identifier + ')', scores_dict[identifier]['sklearn']['accuracy'])\n",
    "    print('Test Accuracy DHDT (' + identifier + ')', scores_dict[identifier]['DHDT']['accuracy'])   \n",
    "    print('_________________________________________________________________________________________________________________')   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901c3fe-2a4d-4efa-9864-a2e488ce9292",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.798559Z",
     "iopub.status.idle": "2022-06-07T12:57:32.798814Z",
     "shell.execute_reply": "2022-06-07T12:57:32.798677Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.798663Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d34810-8e9f-418d-a2aa-caf80458179a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:57:32.800123Z",
     "iopub.status.idle": "2022-06-07T12:57:32.800382Z",
     "shell.execute_reply": "2022-06-07T12:57:32.800245Z",
     "shell.execute_reply.started": "2022-06-07T12:57:32.800233Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = \"Absenteeism\"\n",
    "plt.figure(figsize=(15,8))\n",
    "image = model_dict[identifier]['DHDT'].plot(normalizer_list=dataset_dict['normalizer_list'][identifier])\n",
    "display(image)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plot_tree(model_dict[identifier]['sklearn'], fontsize=10) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a512e12-0fc0-4e43-912a-d01d2b28c7c8",
   "metadata": {},
   "source": [
    "## Absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32042bc9-1008-4311-8d2d-7896db8a3a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc04fcc-841d-4cdb-84ed-8e241db6ba63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
