{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c3b444-064b-4639-983d-238b3da68ad9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6531aaa-2c26-40f5-8078-d754aceda153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:20:10.983273Z",
     "iopub.status.busy": "2022-06-07T12:20:10.983102Z",
     "iopub.status.idle": "2022-06-07T12:20:10.990178Z",
     "shell.execute_reply": "2022-06-07T12:20:10.989856Z",
     "shell.execute_reply.started": "2022-06-07T12:20:10.983226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dhdt': {\n",
    "        'depth': 3,\n",
    "        'learning_rate': 1e-3,\n",
    "        \n",
    "        'loss': 'binary_crossentropy',#'mae',\n",
    "        'optimizer': 'adam',        \n",
    "        \n",
    "        'beta_1': 100,\n",
    "        'beta_2': 100,\n",
    "        \n",
    "        'squeeze_factor': 1,\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'make_classification': {\n",
    "        'number_of_variables': 10,\n",
    "        'n_samples': 10_000,\n",
    "    },\n",
    "\n",
    "    'computation': {\n",
    "        'random_seed': 42,\n",
    "        'num_eval': 10,\n",
    "        'trials': 5,\n",
    "        'n_jobs': 60,\n",
    "        'verbosity': 0,\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ab8be2-1b4c-4370-a837-9176d15bea41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:20:10.990977Z",
     "iopub.status.busy": "2022-06-07T12:20:10.990843Z",
     "iopub.status.idle": "2022-06-07T12:20:44.414958Z",
     "shell.execute_reply": "2022-06-07T12:20:44.414520Z",
     "shell.execute_reply.started": "2022-06-07T12:20:10.990961Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = '' #'true'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from utilities.utilities import *\n",
    "from utilities.DHDT import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2397843-32d2-4579-b197-0686f4a99b54",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e7da9-12bb-467f-919f-4fd510ce6463",
   "metadata": {},
   "source": [
    "## make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a13b2a-ca9d-44de-9a52-b8ca61808093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:20:44.415635Z",
     "iopub.status.busy": "2022-06-07T12:20:44.415486Z",
     "iopub.status.idle": "2022-06-07T12:36:49.350202Z",
     "shell.execute_reply": "2022-06-07T12:36:49.349753Z",
     "shell.execute_reply.started": "2022-06-07T12:20:44.415617Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend LokyBackend with 60 concurrent workers.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7ff3cc372f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7fa46c0f3f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f105c1f4f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Parallel(n_jobs=60)]: Done   3 out of  10 | elapsed: 11.9min remaining: 27.8min\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f31ec1b3f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f7170572f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7ff7205b2f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7fa8606b3f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Parallel(n_jobs=60)]: Done   7 out of  10 | elapsed: 12.4min remaining:  5.3min\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f512c473f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7fa58c2b3f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DHDT.forward_hard at 0x7f236c634f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Parallel(n_jobs=60)]: Done  10 out of  10 | elapsed: 16.1min finished\n"
     ]
    }
   ],
   "source": [
    "#model_seed_list = [i for i in range(config['computation']['trials'])]\n",
    "#data_seed_list = [i for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "#combined_seed_list = list(product(model_seed_list, data_seed_list))\n",
    "\n",
    "parallel_eval_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_synthetic = parallel_eval_synthetic(delayed(evaluate_synthetic_parallel)(index = index,\n",
    "                                                                                            random_seed_data = config['computation']['random_seed']+index,\n",
    "                                                                                            random_seed_model = config['computation']['random_seed'],#+random_seed_model,\n",
    "                                                                                            trials = config['computation']['trials'],\n",
    "                                                                                            config = config['make_classification'],\n",
    "                                                                                            verbosity = -1) for index in range(config['computation']['num_eval']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe87d5f-06be-4f12-b65c-de1828a6f3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:36:49.351657Z",
     "iopub.status.busy": "2022-06-07T12:36:49.351467Z",
     "iopub.status.idle": "2022-06-07T12:36:49.354944Z",
     "shell.execute_reply": "2022-06-07T12:36:49.354637Z",
     "shell.execute_reply.started": "2022-06-07T12:36:49.351637Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, synthetic_result in enumerate(evaluation_results_synthetic):\n",
    "    if i == 0:\n",
    "        model_dict_synthetic = synthetic_result[0]\n",
    "        scores_dict_synthetic = synthetic_result[1]\n",
    "        dataset_dict_synthetic = synthetic_result[2]\n",
    "    else: \n",
    "        model_dict_synthetic = mergeDict(model_dict_synthetic, synthetic_result[0])\n",
    "        scores_dict_synthetic = mergeDict(scores_dict_synthetic, synthetic_result[1])\n",
    "        dataset_dict_synthetic = mergeDict(dataset_dict_synthetic, synthetic_result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb2b804-f2e3-4ec9-9c06-1334d7449519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T13:24:17.360429Z",
     "iopub.status.busy": "2022-06-07T13:24:17.360243Z",
     "iopub.status.idle": "2022-06-07T13:24:17.393154Z",
     "shell.execute_reply": "2022-06-07T13:24:17.392723Z",
     "shell.execute_reply.started": "2022-06-07T13:24:17.360409Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHDT accuracy_mean</th>\n",
       "      <th>DHDT accuracy_max</th>\n",
       "      <th>DHDT accuracy_std</th>\n",
       "      <th>sklearn accuracy_mean</th>\n",
       "      <th>sklearn accuracy_max</th>\n",
       "      <th>sklearn accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.028104</td>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6284</td>\n",
       "      <td>0.7205</td>\n",
       "      <td>0.081748</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.8430</td>\n",
       "      <td>1.900000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.094602</td>\n",
       "      <td>0.7421</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>3.620000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6927</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>0.060004</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>1.040000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5487</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>0.036228</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>7.380000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7264</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.104745</td>\n",
       "      <td>0.8373</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>1.260000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6390</td>\n",
       "      <td>0.6965</td>\n",
       "      <td>0.061970</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>3.000000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6877</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.087444</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>1.110223e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7993</td>\n",
       "      <td>0.8445</td>\n",
       "      <td>0.038413</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>8.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5831</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.063506</td>\n",
       "      <td>0.8498</td>\n",
       "      <td>0.8535</td>\n",
       "      <td>7.400000e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DHDT accuracy_mean  DHDT accuracy_max  DHDT accuracy_std  \\\n",
       "0              0.6156             0.6560           0.028104   \n",
       "1              0.6284             0.7205           0.081748   \n",
       "2              0.6188             0.7325           0.094602   \n",
       "3              0.6927             0.7460           0.060004   \n",
       "4              0.5487             0.6040           0.036228   \n",
       "5              0.7264             0.7850           0.104745   \n",
       "6              0.6390             0.6965           0.061970   \n",
       "7              0.6877             0.7800           0.087444   \n",
       "8              0.7993             0.8445           0.038413   \n",
       "9              0.5831             0.6560           0.063506   \n",
       "\n",
       "   sklearn accuracy_mean  sklearn accuracy_max  sklearn accuracy_std  \n",
       "0                 0.7070                0.7070          0.000000e+00  \n",
       "1                 0.8050                0.8430          1.900000e-02  \n",
       "2                 0.7421                0.8145          3.620000e-02  \n",
       "3                 0.7982                0.8190          1.040000e-02  \n",
       "4                 0.6919                0.8395          7.380000e-02  \n",
       "5                 0.8373                0.8625          1.260000e-02  \n",
       "6                 0.7600                0.7660          3.000000e-03  \n",
       "7                 0.9040                0.9040          1.110223e-16  \n",
       "8                 0.8924                0.8940          8.000000e-04  \n",
       "9                 0.8498                0.8535          7.400000e-03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHDT accuracy_max</th>\n",
       "      <th>sklearn accuracy_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.7070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7205</td>\n",
       "      <td>0.8430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.8145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7460</td>\n",
       "      <td>0.8190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6040</td>\n",
       "      <td>0.8395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6965</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.9040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8445</td>\n",
       "      <td>0.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.8535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DHDT accuracy_max  sklearn accuracy_max\n",
       "0             0.6560                0.7070\n",
       "1             0.7205                0.8430\n",
       "2             0.7325                0.8145\n",
       "3             0.7460                0.8190\n",
       "4             0.6040                0.8395\n",
       "5             0.7850                0.8625\n",
       "6             0.6965                0.7660\n",
       "7             0.7800                0.9040\n",
       "8             0.8445                0.8940\n",
       "9             0.6560                0.8535"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHDT accuracy_mean</th>\n",
       "      <th>DHDT accuracy_max</th>\n",
       "      <th>DHDT accuracy_std</th>\n",
       "      <th>sklearn accuracy_mean</th>\n",
       "      <th>sklearn accuracy_max</th>\n",
       "      <th>sklearn accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.653970</td>\n",
       "      <td>0.722100</td>\n",
       "      <td>0.065676</td>\n",
       "      <td>0.798770</td>\n",
       "      <td>0.830300</td>\n",
       "      <td>0.01632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.073557</td>\n",
       "      <td>0.071736</td>\n",
       "      <td>0.026179</td>\n",
       "      <td>0.073428</td>\n",
       "      <td>0.058713</td>\n",
       "      <td>0.02306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.548700</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.028104</td>\n",
       "      <td>0.691900</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.616400</td>\n",
       "      <td>0.666125</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.746575</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.00135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.633700</td>\n",
       "      <td>0.726500</td>\n",
       "      <td>0.062738</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.841250</td>\n",
       "      <td>0.00890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.691450</td>\n",
       "      <td>0.771500</td>\n",
       "      <td>0.086020</td>\n",
       "      <td>0.846675</td>\n",
       "      <td>0.860250</td>\n",
       "      <td>0.01740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.799300</td>\n",
       "      <td>0.844500</td>\n",
       "      <td>0.104745</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.07380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DHDT accuracy_mean  DHDT accuracy_max  DHDT accuracy_std  \\\n",
       "count           10.000000          10.000000          10.000000   \n",
       "mean             0.653970           0.722100           0.065676   \n",
       "std              0.073557           0.071736           0.026179   \n",
       "min              0.548700           0.604000           0.028104   \n",
       "25%              0.616400           0.666125           0.043811   \n",
       "50%              0.633700           0.726500           0.062738   \n",
       "75%              0.691450           0.771500           0.086020   \n",
       "max              0.799300           0.844500           0.104745   \n",
       "\n",
       "       sklearn accuracy_mean  sklearn accuracy_max  sklearn accuracy_std  \n",
       "count              10.000000             10.000000              10.00000  \n",
       "mean                0.798770              0.830300               0.01632  \n",
       "std                 0.073428              0.058713               0.02306  \n",
       "min                 0.691900              0.707000               0.00000  \n",
       "25%                 0.746575              0.815625               0.00135  \n",
       "50%                 0.801600              0.841250               0.00890  \n",
       "75%                 0.846675              0.860250               0.01740  \n",
       "max                 0.904000              0.904000               0.07380  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = ['accuracy']\n",
    "index = [i for i in range(config['computation']['num_eval'])]\n",
    "columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "scores_DHDT = [scores_dict_synthetic[i]['DHDT']['accuracy'] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "scores_sklearn = [scores_dict_synthetic[i]['sklearn']['accuracy'] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "\n",
    "scores_DHDT_mean = np.mean(scores_DHDT, axis=1)\n",
    "scores_sklearn_mean = np.mean(scores_sklearn, axis=1)\n",
    "                        \n",
    "scores_DHDT_max = np.max(scores_DHDT, axis=1)\n",
    "scores_sklearn_max = np.max(scores_sklearn, axis=1)\n",
    "                        \n",
    "scores_DHDT_std = np.std(scores_DHDT, axis=1)\n",
    "scores_sklearn_std = np.std(scores_sklearn, axis=1)\n",
    "\n",
    "results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "\n",
    "scores_dataframe_synthetic = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "display(scores_dataframe_synthetic)\n",
    "display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[1::3]])\n",
    "display(scores_dataframe_synthetic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb9eca0-b6be-4389-960f-857e68e6b197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:36:50.102135Z",
     "iopub.status.busy": "2022-06-07T12:36:50.101989Z",
     "iopub.status.idle": "2022-06-07T12:56:07.735737Z",
     "shell.execute_reply": "2022-06-07T12:56:07.735271Z",
     "shell.execute_reply.started": "2022-06-07T12:36:50.102115Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend LokyBackend with 60 concurrent workers.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7f1094165f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7f3224766f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7f71b0508f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7ff760530f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DHDT.forward_hard at 0x7fa8a044cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Parallel(n_jobs=60)]: Done   2 out of   5 | elapsed:  2.7min remaining:  4.1min\n",
      "[Parallel(n_jobs=60)]: Done   5 out of   5 | elapsed: 19.3min finished\n"
     ]
    }
   ],
   "source": [
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "parallel_eval_real_world = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_real_world = parallel_eval_real_world(delayed(evaluate_real_world_parallel)(identifier_list=identifier_list, \n",
    "                                                                                               random_seed_model=config['computation']['random_seed']+i,\n",
    "                                                                                               verbosity = -1) for i in range(config['computation']['trials']))\n",
    "\n",
    "\n",
    "for i, real_world_result in enumerate(evaluation_results_real_world):\n",
    "    if i == 0:\n",
    "        model_dict_real_world = real_world_result[0]\n",
    "        scores_dict_real_world = real_world_result[1]\n",
    "        dataset_dict_real_world = real_world_result[2]\n",
    "    else: \n",
    "        model_dict_real_world = mergeDict(model_dict_real_world, real_world_result[0])\n",
    "        scores_dict_real_world = mergeDict(scores_dict_real_world, real_world_result[1])\n",
    "        dataset_dict_real_world = mergeDict(dataset_dict_real_world, real_world_result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c55370-5fa9-4f3c-a1a8-be597467f808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:56:07.736613Z",
     "iopub.status.busy": "2022-06-07T12:56:07.736477Z",
     "iopub.status.idle": "2022-06-07T12:56:07.749434Z",
     "shell.execute_reply": "2022-06-07T12:56:07.748974Z",
     "shell.execute_reply.started": "2022-06-07T12:56:07.736594Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHDT accuracy_mean</th>\n",
       "      <th>DHDT accuracy_std</th>\n",
       "      <th>sklearn accuracy_mean</th>\n",
       "      <th>sklearn accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cervical Cancer</th>\n",
       "      <td>0.341520</td>\n",
       "      <td>0.247738</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit Card</th>\n",
       "      <td>0.512833</td>\n",
       "      <td>0.252194</td>\n",
       "      <td>0.776167</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DHDT accuracy_mean  DHDT accuracy_std  sklearn accuracy_mean  \\\n",
       "Cervical Cancer            0.341520           0.247738               0.467836   \n",
       "Credit Card                0.512833           0.252194               0.776167   \n",
       "\n",
       "                 sklearn accuracy_std  \n",
       "Cervical Cancer                   0.0  \n",
       "Credit Card                       0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['accuracy']\n",
    "index = identifier_list\n",
    "columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "scores_DHDT = [scores_dict_real_world[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict_real_world[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "\n",
    "scores_DHDT_mean = np.mean(scores_DHDT, axis=1)\n",
    "scores_sklearn_mean = np.mean(scores_sklearn, axis=1)\n",
    "\n",
    "scores_DHDT_std = np.std(scores_DHDT, axis=1)\n",
    "scores_sklearn_std = np.std(scores_sklearn, axis=1)\n",
    "\n",
    "results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_std])\n",
    "results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_std])\n",
    "\n",
    "\n",
    "scores_dataframe_real_world = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "scores_dataframe_real_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb85a81-881b-47be-96d8-6c6d0578b810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:56:07.750111Z",
     "iopub.status.busy": "2022-06-07T12:56:07.749993Z",
     "iopub.status.idle": "2022-06-07T12:56:08.352131Z",
     "shell.execute_reply": "2022-06-07T12:56:08.351807Z",
     "shell.execute_reply.started": "2022-06-07T12:56:07.750095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cervical Cancer': {'sklearn': {'accuracy': [0.4678362573099415,\n",
       "    0.4678362573099415,\n",
       "    0.4678362573099415,\n",
       "    0.4678362573099415,\n",
       "    0.4678362573099415]},\n",
       "  'DHDT': {'accuracy': [0.17543859649122806,\n",
       "    0.06432748538011696,\n",
       "    0.6374269005847953,\n",
       "    0.6432748538011696,\n",
       "    0.1871345029239766]},\n",
       "  'history': [None, None, None, None, None]},\n",
       " 'Credit Card': {'sklearn': {'accuracy': [0.7761666666666667,\n",
       "    0.7761666666666667,\n",
       "    0.7761666666666667,\n",
       "    0.7761666666666667,\n",
       "    0.7761666666666667]},\n",
       "  'DHDT': {'accuracy': [0.21883333333333332,\n",
       "    0.21916666666666668,\n",
       "    0.7766666666666666,\n",
       "    0.5668333333333333,\n",
       "    0.7826666666666666]},\n",
       "  'history': [None, None, None, None, None]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dict_real_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d69a94-8df3-4133-9e78-239bf0fcec79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:56:08.352817Z",
     "iopub.status.busy": "2022-06-07T12:56:08.352686Z",
     "iopub.status.idle": "2022-06-07T12:56:08.506039Z",
     "shell.execute_reply": "2022-06-07T12:56:08.505626Z",
     "shell.execute_reply.started": "2022-06-07T12:56:08.352802Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict_real_world[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict_real_world[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b0c3f97-e5ab-4b06-9a17-1c23448800fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:56:08.507635Z",
     "iopub.status.busy": "2022-06-07T12:56:08.507509Z",
     "iopub.status.idle": "2022-06-07T12:56:08.542060Z",
     "shell.execute_reply": "2022-06-07T12:56:08.541740Z",
     "shell.execute_reply.started": "2022-06-07T12:56:08.507619Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34152047, 0.51283333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores_DHDT, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ec52977-11ff-467a-82e5-89856a10293d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T12:56:08.542715Z",
     "iopub.status.busy": "2022-06-07T12:56:08.542551Z",
     "iopub.status.idle": "2022-06-07T12:56:27.616546Z",
     "shell.execute_reply": "2022-06-07T12:56:27.615917Z",
     "shell.execute_reply.started": "2022-06-07T12:56:08.542694Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (5, 4), indices imply (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1979523/286638212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores_sklearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscores_dict_real_world\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sklearn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midentifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midentifier_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscores_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscores_DHDT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_sklearn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'DHDT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sklearn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscores_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 )\n\u001b[1;32m    671\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    673\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5, 4), indices imply (2, 2)"
     ]
    }
   ],
   "source": [
    "scores_DHDT = [scores_dict_real_world[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict_real_world[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d00d23-cea4-4946-9495-93a9578c7939",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.617167Z",
     "iopub.status.idle": "2022-06-07T12:56:27.617388Z",
     "shell.execute_reply": "2022-06-07T12:56:27.617280Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.617268Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73bba7-c127-4e07-939e-72a1417d27cd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.618062Z",
     "iopub.status.idle": "2022-06-07T12:56:27.618257Z",
     "shell.execute_reply": "2022-06-07T12:56:27.618161Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.618151Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09315b63-50a1-4b2c-bfa9-d7b6d961de34",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.619111Z",
     "iopub.status.idle": "2022-06-07T12:56:27.619309Z",
     "shell.execute_reply": "2022-06-07T12:56:27.619208Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.619198Z"
    }
   },
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "        'depth': 3,\n",
    "        'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "        \n",
    "        'loss': ['binary_crossentropy', 'rmse'],#'mae',\n",
    "        'optimizer': ['adam', 'sgd'],        \n",
    "        \n",
    "        'beta_1': [10, 50, 100],\n",
    "        'beta_2': [10, 50, 100],\n",
    "        \n",
    "        'squeeze_factor': [0.2, 0.5, 1, 2, 5],    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e9145-2b47-467f-96df-d3bb0f83226a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.619924Z",
     "iopub.status.idle": "2022-06-07T12:56:27.620113Z",
     "shell.execute_reply": "2022-06-07T12:56:27.620017Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.620006Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_DHDT_make_class = [scores_dict_make_class[identifier]['DHDT']['accuracy'] for identifier in range(num_make_class_eval)]\n",
    "\n",
    "scores_sklearn_make_class = [scores_dict_make_class[identifier]['sklearn']['accuracy'] for identifier in range(num_make_class_eval)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db42a3-560d-4f55-b2d3-ee52da3cb7f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## real-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ca2d2-73a1-4675-8d6e-4f75d096fb4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05f2f8-19b1-4800-b9ae-85c0599f0425",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.620853Z",
     "iopub.status.idle": "2022-06-07T12:56:27.621048Z",
     "shell.execute_reply": "2022-06-07T12:56:27.620949Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.620938Z"
    }
   },
   "outputs": [],
   "source": [
    "--> put eval in function \n",
    "    --> make parallel execution with different seeds / splits, etcs \n",
    "        --> compare (save all values and generate mean+std df, but keep all values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafb753-2e3d-4480-9998-659ff6034a78",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.621529Z",
     "iopub.status.idle": "2022-06-07T12:56:27.621715Z",
     "shell.execute_reply": "2022-06-07T12:56:27.621623Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.621613Z"
    }
   },
   "outputs": [],
   "source": [
    "config['n_samples'] = 10_000\n",
    "config['number_of_variables'] = 5\n",
    "random_seed = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab170fa2-c32f-402e-8b60-38b542ae3840",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.622464Z",
     "iopub.status.idle": "2022-06-07T12:56:27.622663Z",
     "shell.execute_reply": "2022-06-07T12:56:27.622559Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.622549Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_jobs = 20\n",
    "\n",
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "parallel_real_world_eval = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_by_dataset = parallel_real_world_eval(delayed(evaluate_dhdt)(identifier) for identifier in identifier_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c7b89-7752-49a8-9424-306b2d1d172d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.623214Z",
     "iopub.status.idle": "2022-06-07T12:56:27.623406Z",
     "shell.execute_reply": "2022-06-07T12:56:27.623308Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.623298Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "trials = 20\n",
    "n_jobs = 20\n",
    "random_seed = 42\n",
    "\n",
    "parallel_real_world_eval = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_by_dataset = parallel_real_world_eval(delayed(evaluate_all_parallel)(identifier_list=identifier_list, \n",
    "                                                                               random_seed=random_seed+i) for i in range(trials))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3fdc5-9ae2-47ba-b4db-b2ef5988d1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf508df-fa1a-4c9a-9495-4adfac6c8478",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.624036Z",
     "iopub.status.idle": "2022-06-07T12:56:27.624220Z",
     "shell.execute_reply": "2022-06-07T12:56:27.624129Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.624119Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "evaluate_all_real_world(identifier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142651c4-44b3-4598-acc2-d71f8980849c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.624873Z",
     "iopub.status.idle": "2022-06-07T12:56:27.625058Z",
     "shell.execute_reply": "2022-06-07T12:56:27.624965Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.624954Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_all_real_world(identifier_list):\n",
    "    \n",
    "    identifier_list = ['Cervical Cancer',\n",
    "                       'Credit Card',\n",
    "                       'Absenteeism']\n",
    "\n",
    "    dataset_dict = {}\n",
    "    model_dict = {}\n",
    "\n",
    "    scores_dict = {}\n",
    "\n",
    "    for identifier in tqdm(identifier_list, desc='dataset loop'):\n",
    "\n",
    "        print('_________________________________________________________________________________________________________________')   \n",
    "\n",
    "        dataset_dict[identifier] = {}\n",
    "        model_dict[identifier] = {}\n",
    "\n",
    "        scores_dict[identifier] = {'sklearn': {},\n",
    "                                   'DHDT': {}}\n",
    "\n",
    "        dataset_dict[identifier] = get_preprocessed_dataset(identifier)    \n",
    "\n",
    "        model_dict[identifier]['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                                                   random_state=42)\n",
    "\n",
    "        model_dict[identifier]['sklearn'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                              dataset_dict[identifier]['y_train'])\n",
    "\n",
    "        scores_dict[identifier]['sklearn']['accuracy'] = model_dict[identifier]['sklearn'].score(dataset_dict[identifier]['X_test'], \n",
    "                                                                                                 dataset_dict[identifier]['y_test'])\n",
    "\n",
    "\n",
    "\n",
    "        model_dict[identifier]['DHDT'] = DHDT(depth=3,\n",
    "                                                 number_of_variables = dataset_dict[identifier]['X_train'].shape[1],\n",
    "                                                 learning_rate=1e-3,\n",
    "                                                 squeeze_factor = 1,\n",
    "                                                 loss='binary_crossentropy',#'binary_crossentropy',\n",
    "                                                 optimizer='rmsprop',\n",
    "                                                 random_seed=40,\n",
    "                                                 verbosity=0)\n",
    "\n",
    "        scores_dict[identifier]['history'] = model_dict[identifier]['DHDT'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                                                              dataset_dict[identifier]['y_train'], \n",
    "                                                                              batch_size=512, \n",
    "                                                                              epochs=1_000, \n",
    "                                                                              early_stopping_epochs=50, \n",
    "                                                                              valid_data=(dataset_dict[identifier]['X_valid'], dataset_dict[identifier]['y_valid']))\n",
    "\n",
    "        dataset_dict[identifier]['y_test_dhdt'] = model_dict[identifier]['DHDT'].predict(dataset_dict[identifier]['X_test'])\n",
    "        scores_dict[identifier]['DHDT']['accuracy'] = accuracy_score(dataset_dict[identifier]['y_test'], np.round(dataset_dict[identifier]['y_test_dhdt']))\n",
    "\n",
    "        print('Test Accuracy Sklearn (' + identifier + ')', scores_dict[identifier]['sklearn']['accuracy'])\n",
    "        print('Test Accuracy DHDT (' + identifier + ')', scores_dict[identifier]['DHDT']['accuracy'])   \n",
    "        print('_________________________________________________________________________________________________________________')   \n",
    "\n",
    "    return   model_dict, scores_dict, dataset_dit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773d8d6-ba4e-42b5-b981-2edd4a323fc9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.625752Z",
     "iopub.status.idle": "2022-06-07T12:56:27.626063Z",
     "shell.execute_reply": "2022-06-07T12:56:27.625958Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.625946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = ['Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   'Absenteeism']\n",
    "\n",
    "dataset_dict = {}\n",
    "model_dict = {}\n",
    "\n",
    "scores_dict = {}\n",
    "\n",
    "for identifier in tqdm(identifier_list, desc='dataset loop'):\n",
    "    \n",
    "    print('_________________________________________________________________________________________________________________')   \n",
    "    \n",
    "    dataset_dict[identifier] = {}\n",
    "    model_dict[identifier] = {}\n",
    "\n",
    "    scores_dict[identifier] = {'sklearn': {},\n",
    "                               'DHDT': {}}\n",
    "    \n",
    "    dataset_dict[identifier] = get_preprocessed_dataset(identifier)    \n",
    "\n",
    "    model_dict[identifier]['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                                               random_state=42)\n",
    "\n",
    "    model_dict[identifier]['sklearn'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                          dataset_dict[identifier]['y_train'])\n",
    "\n",
    "    scores_dict[identifier]['sklearn']['accuracy'] = model_dict[identifier]['sklearn'].score(dataset_dict[identifier]['X_test'], \n",
    "                                                                                             dataset_dict[identifier]['y_test'])\n",
    "\n",
    "\n",
    "\n",
    "    model_dict[identifier]['DHDT'] = DHDT(depth=3,\n",
    "                                             number_of_variables = dataset_dict[identifier]['X_train'].shape[1],\n",
    "                                             learning_rate=1e-3,\n",
    "                                             squeeze_factor = 1,\n",
    "                                             loss='binary_crossentropy',#'binary_crossentropy',\n",
    "                                             optimizer='rmsprop',\n",
    "                                             random_seed=40,\n",
    "                                             verbosity=0)\n",
    "\n",
    "    scores_dict[identifier]['history'] = model_dict[identifier]['DHDT'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                                                          dataset_dict[identifier]['y_train'], \n",
    "                                                                          batch_size=512, \n",
    "                                                                          epochs=1_000, \n",
    "                                                                          early_stopping_epochs=50, \n",
    "                                                                          valid_data=(dataset_dict[identifier]['X_valid'], dataset_dict[identifier]['y_valid']))\n",
    "\n",
    "    dataset_dict[identifier]['y_test_dhdt'] = model_dict[identifier]['DHDT'].predict(dataset_dict[identifier]['X_test'])\n",
    "    scores_dict[identifier]['DHDT']['accuracy'] = accuracy_score(dataset_dict[identifier]['y_test'], np.round(dataset_dict[identifier]['y_test_dhdt']))\n",
    "    \n",
    "    print('Test Accuracy Sklearn (' + identifier + ')', scores_dict[identifier]['sklearn']['accuracy'])\n",
    "    print('Test Accuracy DHDT (' + identifier + ')', scores_dict[identifier]['DHDT']['accuracy'])   \n",
    "    print('_________________________________________________________________________________________________________________')   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901c3fe-2a4d-4efa-9864-a2e488ce9292",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.626600Z",
     "iopub.status.idle": "2022-06-07T12:56:27.626783Z",
     "shell.execute_reply": "2022-06-07T12:56:27.626692Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.626682Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d34810-8e9f-418d-a2aa-caf80458179a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T12:56:27.627392Z",
     "iopub.status.idle": "2022-06-07T12:56:27.627583Z",
     "shell.execute_reply": "2022-06-07T12:56:27.627485Z",
     "shell.execute_reply.started": "2022-06-07T12:56:27.627474Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = \"Absenteeism\"\n",
    "plt.figure(figsize=(15,8))\n",
    "image = model_dict[identifier]['DHDT'].plot(normalizer_list=dataset_dict['normalizer_list'][identifier])\n",
    "display(image)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plot_tree(model_dict[identifier]['sklearn'], fontsize=10) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a512e12-0fc0-4e43-912a-d01d2b28c7c8",
   "metadata": {},
   "source": [
    "## Absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32042bc9-1008-4311-8d2d-7896db8a3a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc04fcc-841d-4cdb-84ed-8e241db6ba63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
