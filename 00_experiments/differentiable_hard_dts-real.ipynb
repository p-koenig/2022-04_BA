{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c3b444-064b-4639-983d-238b3da68ad9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6531aaa-2c26-40f5-8078-d754aceda153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:33.481261Z",
     "iopub.status.busy": "2022-06-08T06:40:33.480836Z",
     "iopub.status.idle": "2022-06-08T06:40:33.492430Z",
     "shell.execute_reply": "2022-06-08T06:40:33.491773Z",
     "shell.execute_reply.started": "2022-06-08T06:40:33.481178Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dhdt': {\n",
    "        'depth': 3,\n",
    "        'learning_rate': 1e-3,\n",
    "        \n",
    "        'loss': 'binary_crossentropy',#'mae',\n",
    "        'optimizer': 'adam',        \n",
    "        \n",
    "        'beta_1': 100,\n",
    "        'beta_2': 100,\n",
    "        \n",
    "        'squeeze_factor': 1,\n",
    "        \n",
    "        'batch_size': 512,\n",
    "        'epochs': 1_000,\n",
    "        'early_stopping_epochs': 20,\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'make_classification': {\n",
    "        'number_of_variables': 5,\n",
    "        'n_samples': 5_000,\n",
    "    },\n",
    "\n",
    "    'computation': {\n",
    "        'random_seed': 42,\n",
    "        'num_eval': 10,\n",
    "        'trials': 5,\n",
    "        'n_jobs': 60,\n",
    "        'verbosity': 0,\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ab8be2-1b4c-4370-a837-9176d15bea41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:33.493913Z",
     "iopub.status.busy": "2022-06-08T06:40:33.493653Z",
     "iopub.status.idle": "2022-06-08T06:40:37.597326Z",
     "shell.execute_reply": "2022-06-08T06:40:37.596833Z",
     "shell.execute_reply.started": "2022-06-08T06:40:33.493882Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = '' #'true'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from utilities.utilities import *\n",
    "from utilities.DHDT import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2397843-32d2-4579-b197-0686f4a99b54",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e7da9-12bb-467f-919f-4fd510ce6463",
   "metadata": {},
   "source": [
    "## make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a13b2a-ca9d-44de-9a52-b8ca61808093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:37.598237Z",
     "iopub.status.busy": "2022-06-08T06:40:37.598126Z",
     "iopub.status.idle": "2022-06-08T06:40:37.606275Z",
     "shell.execute_reply": "2022-06-08T06:40:37.605973Z",
     "shell.execute_reply.started": "2022-06-08T06:40:37.598222Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    parallel_eval_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_synthetic = parallel_eval_synthetic(delayed(evaluate_synthetic_parallel)(index = index,\n",
    "                                                                                                random_seed_data = config['computation']['random_seed']+index,\n",
    "                                                                                                random_seed_model = config['computation']['random_seed'],#+random_seed_model,\n",
    "                                                                                                config = config,\n",
    "                                                                                                verbosity = -1) for index in range(config['computation']['num_eval']))\n",
    "\n",
    "    for i, synthetic_result in enumerate(evaluation_results_synthetic):\n",
    "        if i == 0:\n",
    "            model_dict_synthetic = synthetic_result[0]\n",
    "            scores_dict_synthetic = synthetic_result[1]\n",
    "            dataset_dict_synthetic = synthetic_result[2]\n",
    "        else: \n",
    "            model_dict_synthetic = mergeDict(model_dict_synthetic, synthetic_result[0])\n",
    "            scores_dict_synthetic = mergeDict(scores_dict_synthetic, synthetic_result[1])\n",
    "            dataset_dict_synthetic = mergeDict(dataset_dict_synthetic, synthetic_result[2])\n",
    "\n",
    "\n",
    "    metrics = ['accuracy_test']\n",
    "    index = [i for i in range(config['computation']['num_eval'])]\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "    scores_DHDT = [scores_dict_synthetic[i]['DHDT'][metrics[0]] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "    scores_sklearn = [scores_dict_synthetic[i]['sklearn'][metrics[0]] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "\n",
    "    scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['num_eval'])\n",
    "    scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['num_eval'])\n",
    "\n",
    "    results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "    results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "\n",
    "    scores_dataframe_synthetic = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "    display(scores_dataframe_synthetic)\n",
    "    display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[1::3]])\n",
    "    display(scores_dataframe_synthetic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2b804-f2e3-4ec9-9c06-1334d7449519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f856c6c9-368b-4b75-b0d8-6e7a28e4267c",
   "metadata": {},
   "source": [
    "## Real-World Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb9eca0-b6be-4389-960f-857e68e6b197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:37.606876Z",
     "iopub.status.busy": "2022-06-08T06:40:37.606755Z",
     "iopub.status.idle": "2022-06-08T06:40:37.658975Z",
     "shell.execute_reply": "2022-06-08T06:40:37.658626Z",
     "shell.execute_reply.started": "2022-06-08T06:40:37.606862Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    identifier_list = [\n",
    "                        'Adult',#: 32,\n",
    "                        'Bank Marketing',#: 32,\n",
    "                        'Loan Credit',#: 32,\n",
    "\n",
    "                        'Credit Card',#: 23, \n",
    "                        'Car',#: 21,\n",
    "\n",
    "\n",
    "                        'Absenteeism',#: 15,\n",
    "                        'Loan House',#: 15,\n",
    "                        'Cervical Cancer',#: 15,\n",
    "\n",
    "                        'Heart Disease',#: 13,           \n",
    "\n",
    "                        'Titanic',#: 10,\n",
    "                        'Medical Insurance',#: 10,\n",
    "                        'Wisconsin Breast Cancer Original',#: 10,\n",
    "                        'Wisconsin Diagnostic Breast Cancer',#: 10,\n",
    "                        'Wisconsin Prognostic Breast Cancer',#: 10,\n",
    "                        'Abalone',#: 10,\n",
    "\n",
    "                        'Habermans Survival',#: 3, \n",
    "                      ]\n",
    "\n",
    "    #identifier_list = ['Habermans Survival']\n",
    "\n",
    "    parallel_eval_real_world = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_real_world = parallel_eval_real_world(delayed(evaluate_real_world_parallel)(identifier_list=identifier_list, \n",
    "                                                                                                   random_seed_model=config['computation']['random_seed']+i,\n",
    "                                                                                                   config = config,\n",
    "                                                                                                   verbosity = -1) for i in range(config['computation']['trials']))\n",
    "\n",
    "\n",
    "    for i, real_world_result in enumerate(evaluation_results_real_world):\n",
    "        if i == 0:\n",
    "            model_dict_real_world = real_world_result[0]\n",
    "            scores_dict_real_world = real_world_result[1]\n",
    "            dataset_dict_real_world = real_world_result[2]\n",
    "        else: \n",
    "            model_dict_real_world = mergeDict(model_dict_real_world, real_world_result[0])\n",
    "            scores_dict_real_world = mergeDict(scores_dict_real_world, real_world_result[1])\n",
    "            dataset_dict_real_world = mergeDict(dataset_dict_real_world, real_world_result[2])\n",
    "\n",
    "    metrics = ['accuracy_test']\n",
    "    index = identifier_list\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "    scores_DHDT = [scores_dict_real_world[identifier]['DHDT'][metrics[0]] for identifier in identifier_list]\n",
    "\n",
    "    scores_sklearn = [scores_dict_real_world[identifier]['sklearn'][metrics[0]] for identifier in identifier_list]\n",
    "\n",
    "    scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "    scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "\n",
    "    results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "    results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "\n",
    "    scores_dataframe_real_world = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "    display(scores_dataframe_real_world)\n",
    "    display(scores_dataframe_real_world[scores_dataframe_real_world.columns[1::3]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c55370-5fa9-4f3c-a1a8-be597467f808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:37.659782Z",
     "iopub.status.busy": "2022-06-08T06:40:37.659687Z",
     "iopub.status.idle": "2022-06-08T06:40:37.697009Z",
     "shell.execute_reply": "2022-06-08T06:40:37.696725Z",
     "shell.execute_reply.started": "2022-06-08T06:40:37.659770Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    identifier = identifier_list[0]#\"Absenteeism\"\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict_real_world[identifier]['DHDT'].plot(normalizer_list=dataset_dict_real_world[identifier]['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict_real_world[identifier]['sklearn'], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fbd88-44c9-4d7f-b58d-def1eeb6d434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84e73582-0f9e-4522-9a94-dc59f4e566e9",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09315b63-50a1-4b2c-bfa9-d7b6d961de34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:37.697553Z",
     "iopub.status.busy": "2022-06-08T06:40:37.697404Z",
     "iopub.status.idle": "2022-06-08T06:40:37.755686Z",
     "shell.execute_reply": "2022-06-08T06:40:37.755352Z",
     "shell.execute_reply.started": "2022-06-08T06:40:37.697540Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "        'depth': [3],\n",
    "        'learning_rate': [0.05, 0.01, 0.005, 0.001, 0.0005],#[0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "        \n",
    "        'loss': ['binary_crossentropy'],#['binary_crossentropy', 'rmse'],#'mae',\n",
    "        'optimizer': ['adam', 'sgd'],#['adam', 'sgd'],        \n",
    "        \n",
    "        'beta_1': [10, 50],#[10, 50, 100],\n",
    "        'beta_2': [10, 50],#[10, 50, 100],\n",
    "        \n",
    "        'squeeze_factor': [0.2, 0.5, 1, 2, 5],#[0.2, 0.5, 1, 2, 5],    \n",
    "}\n",
    "\n",
    "parameter_grid = ParameterGrid(parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32042bc9-1008-4311-8d2d-7896db8a3a12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:37.756257Z",
     "iopub.status.busy": "2022-06-08T06:40:37.756134Z",
     "iopub.status.idle": "2022-06-08T06:40:37.835130Z",
     "shell.execute_reply": "2022-06-08T06:40:37.834791Z",
     "shell.execute_reply.started": "2022-06-08T06:40:37.756244Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_parameter_setting_synthetic(parameter_setting):\n",
    "    \n",
    "    config_parameter_setting = deepcopy(config)\n",
    "    \n",
    "    \n",
    "    for key, value in parameter_setting.items():\n",
    "        config_parameter_setting['dhdt'][key] = value\n",
    "    \n",
    "    \n",
    "    evaluation_results_synthetic = []\n",
    "    for index in range(config['computation']['num_eval']):\n",
    "        evaluation_result = evaluate_synthetic_parallel(index = index,\n",
    "                                                        random_seed_data = config['computation']['random_seed']+index,\n",
    "                                                        random_seed_model = config['computation']['random_seed'],#+random_seed_model,\n",
    "                                                        config = config_parameter_setting,\n",
    "                                                        verbosity = -1)\n",
    "        evaluation_results_synthetic.append(evaluation_result)\n",
    "    \n",
    "    #parallel_eval_synthetic = Parallel(n_jobs=1, verbose=0, backend='sequential') #loky #sequential multiprocessing\n",
    "    #evaluation_results_synthetic = parallel_eval_synthetic(delayed(evaluate_synthetic_parallel)(index = index,\n",
    "    #                                                                                            random_seed_data = config['computation']['random_seed']+index,\n",
    "    #                                                                                            random_seed_model = config['computation']['random_seed'],#+random_seed_model,\n",
    "    #                                                                                            config = config_parameter_setting,\n",
    "    #                                                                                            verbosity = -1) for index in range(config['computation']['num_eval']))\n",
    "\n",
    "    \n",
    "    for i, synthetic_result in enumerate(evaluation_results_synthetic):\n",
    "        if i == 0:\n",
    "            model_dict_synthetic = synthetic_result[0]\n",
    "            scores_dict_synthetic = synthetic_result[1]\n",
    "            dataset_dict_synthetic = synthetic_result[2]\n",
    "        else: \n",
    "            model_dict_synthetic = mergeDict(model_dict_synthetic, synthetic_result[0])\n",
    "            scores_dict_synthetic = mergeDict(scores_dict_synthetic, synthetic_result[1])\n",
    "            dataset_dict_synthetic = mergeDict(dataset_dict_synthetic, synthetic_result[2])    \n",
    "    \n",
    "    del model_dict_synthetic, scores_dict_synthetic, dataset_dict_synthetic\n",
    "    del evaluation_results_synthetic\n",
    "    \n",
    "    metrics = ['accuracy_valid']\n",
    "    index = [i for i in range(config['computation']['num_eval'])]\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "    scores_DHDT = [scores_dict_synthetic[i]['DHDT'][metrics[0]] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "    scores_sklearn = [scores_dict_synthetic[i]['sklearn'][metrics[0]] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "    scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['num_eval'])\n",
    "    scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['num_eval'])\n",
    "\n",
    "    results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "    results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "\n",
    "    scores_dataframe_synthetic = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "    #display(scores_dataframe_synthetic)\n",
    "    #display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[1::3]])\n",
    "    #display(scores_dataframe_synthetic.describe())    \n",
    "    \n",
    "    del model_dict, scores_dict, dataset_dict\n",
    "    \n",
    "    return np.mean(scores_DHDT_mean), np.mean(scores_sklearn_mean), parameter_setting\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfabd18f-ef51-4b91-afe7-fa187338d4ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:37.835656Z",
     "iopub.status.busy": "2022-06-08T06:40:37.835563Z",
     "iopub.status.idle": "2022-06-08T06:40:37.891380Z",
     "shell.execute_reply": "2022-06-08T06:40:37.891040Z",
     "shell.execute_reply.started": "2022-06-08T06:40:37.835643Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_parameter_setting_real_world(parameter_setting, identifier):\n",
    "    \n",
    "    config_parameter_setting = deepcopy(config)\n",
    "    \n",
    "    \n",
    "    for key, value in parameter_setting.items():\n",
    "        config_parameter_setting['dhdt'][key] = value\n",
    "    \n",
    "    \n",
    "    evaluation_results_real_world = []\n",
    "    for i in range(config['computation']['trials']):\n",
    "        evaluation_result = evaluate_real_world_parallel(identifier_list=[identifier], \n",
    "                                                           random_seed_model=config['computation']['random_seed']+i,\n",
    "                                                           config = config_parameter_setting,\n",
    "                                                           verbosity = -1)\n",
    "        evaluation_results_real_world.append(evaluation_result)\n",
    "        \n",
    "    del evaluation_result\n",
    "    #parallel_eval_real_world = Parallel(n_jobs=1, verbose=0, backend='sequential') #loky #sequential multiprocessing\n",
    "    #evaluation_results_real_world = parallel_eval_real_world(delayed(evaluate_real_world_parallel)(identifier_list=[identifier], \n",
    "    #                                                                                               random_seed_model=config['computation']['random_seed']+i,\n",
    "    #                                                                                               config = config_parameter_setting,\n",
    "    #                                                                                               verbosity = -1) for i in range(config['computation']['trials']))\n",
    "\n",
    "\n",
    "    \n",
    "    for i, real_world_result in enumerate(evaluation_results_real_world):\n",
    "        if i == 0:\n",
    "            model_dict_real_world = real_world_result[0]\n",
    "            scores_dict_real_world = real_world_result[1]\n",
    "            dataset_dict_real_world = real_world_result[2]\n",
    "        else: \n",
    "            model_dict_real_world = mergeDict(model_dict_real_world, real_world_result[0])\n",
    "            scores_dict_real_world = mergeDict(scores_dict_real_world, real_world_result[1])\n",
    "            dataset_dict_real_world = mergeDict(dataset_dict_real_world, real_world_result[2])    \n",
    "    \n",
    "    del model_dict_real_world, scores_dict_real_world, dataset_dict_real_world\n",
    "    del evaluation_results_real_world\n",
    "    \n",
    "    metrics = ['accuracy_valid']\n",
    "    index = [identifier]\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "    scores_DHDT = [scores_dict_real_world[identifier]['DHDT'][metrics[0]] for identifier in [identifier]]\n",
    "\n",
    "    scores_sklearn = [scores_dict_real_world[identifier]['sklearn'][metrics[0]] for identifier in [identifier]]\n",
    "\n",
    "    scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "    scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "    scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "    scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "    \n",
    "    results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "    results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "    scores_dataframe_real_world = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "    #display(scores_dataframe_real_world)\n",
    "    #display(scores_dataframe_real_world[scores_dataframe_real_world.columns[1::3]])    \n",
    "    \n",
    "    del model_dict, scores_dict, dataset_dict\n",
    "    \n",
    "    return np.mean(scores_DHDT_mean), np.mean(scores_sklearn_mean), parameter_setting\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "952be342-9751-474b-8780-f185b3f9c29d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:37.892028Z",
     "iopub.status.busy": "2022-06-08T06:40:37.891894Z",
     "iopub.status.idle": "2022-06-08T06:40:37.966568Z",
     "shell.execute_reply": "2022-06-08T06:40:37.965962Z",
     "shell.execute_reply.started": "2022-06-08T06:40:37.892012Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    parallel_hpo_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_hpo_synthetic = parallel_hpo_synthetic(delayed(evaluate_parameter_setting_synthetic)(parameter_setting) for parameter_setting in parameter_grid)\n",
    "\n",
    "    sorted_evaluation_results_hpo_synthetic = sorted(evaluation_results_hpo_synthetic, key=lambda x: x[0], reverse=True)\n",
    "    print(sorted_evaluation_results_hpo_synthetic[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ea5ad2-2138-4cb5-9cac-3e00f87d9a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:40:37.967738Z",
     "iopub.status.busy": "2022-06-08T06:40:37.967513Z",
     "iopub.status.idle": "2022-06-08T06:48:20.168189Z",
     "shell.execute_reply": "2022-06-08T06:48:20.167696Z",
     "shell.execute_reply.started": "2022-06-08T06:40:37.967705Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend LokyBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done   8 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=60)]: Done  52 out of 128 | elapsed:  3.4min remaining:  5.0min\n",
      "[Parallel(n_jobs=60)]: Done  95 out of 128 | elapsed:  6.0min remaining:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7101123595505617, 0.7640449438202247, {'beta_1': 10, 'beta_2': 50, 'depth': 3, 'learning_rate': 0.001, 'loss': 'binary_crossentropy', 'optimizer': 'adam', 'squeeze_factor': 2}), (0.7011235955056179, 0.7640449438202247, {'beta_1': 10, 'beta_2': 10, 'depth': 3, 'learning_rate': 0.05, 'loss': 'binary_crossentropy', 'optimizer': 'adam', 'squeeze_factor': 0.5}), (0.7011235955056179, 0.7640449438202247, {'beta_1': 10, 'beta_2': 10, 'depth': 3, 'learning_rate': 0.05, 'loss': 'binary_crossentropy', 'optimizer': 'adam', 'squeeze_factor': 1}), (0.698876404494382, 0.7640449438202247, {'beta_1': 10, 'beta_2': 10, 'depth': 3, 'learning_rate': 0.05, 'loss': 'binary_crossentropy', 'optimizer': 'adam', 'squeeze_factor': 0.2}), (0.6966292134831461, 0.7640449438202247, {'beta_1': 10, 'beta_2': 10, 'depth': 3, 'learning_rate': 0.05, 'loss': 'binary_crossentropy', 'optimizer': 'adam', 'squeeze_factor': 2})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Done 128 out of 128 | elapsed:  7.7min finished\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    identifier = 'Titanic'\n",
    "\n",
    "    parallel_hpo_real = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_hpo_real = parallel_hpo_real(delayed(evaluate_parameter_setting_real_world)(parameter_setting, identifier) for parameter_setting in parameter_grid)\n",
    "\n",
    "    sorted_evaluation_results_hpo_real = sorted(evaluation_results_hpo_real, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    print(sorted_evaluation_results_hpo_real[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30cc32-2eed-4185-b073-6a0b48707897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T06:48:20.169754Z",
     "iopub.status.busy": "2022-06-08T06:48:20.169609Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend LokyBackend with 60 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    identifier = 'Absenteeism'\n",
    "\n",
    "    parallel_hpo_real = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_hpo_real = parallel_hpo_real(delayed(evaluate_parameter_setting_real_world)(parameter_setting, identifier) for parameter_setting in parameter_grid)\n",
    "\n",
    "    sorted_evaluation_results_hpo_real = sorted(evaluation_results_hpo_real, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    print(sorted_evaluation_results_hpo_real[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f49cf7-d803-49de-8432-83aa4786fa78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    identifier = 'Adult'\n",
    "\n",
    "    parallel_hpo_real = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_hpo_real = parallel_hpo_real(delayed(evaluate_parameter_setting_real_world)(parameter_setting, identifier) for parameter_setting in parameter_grid)\n",
    "\n",
    "    sorted_evaluation_results_hpo_real = sorted(evaluation_results_hpo_real, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    print(sorted_evaluation_results_hpo_real[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40147db1-760f-432d-ac2c-0267a8256f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358c9e7-58be-4006-b120-6b14f8364122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
