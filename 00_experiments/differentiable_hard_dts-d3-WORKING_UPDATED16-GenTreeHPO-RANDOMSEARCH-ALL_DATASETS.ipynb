{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c3b444-064b-4639-983d-238b3da68ad9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6531aaa-2c26-40f5-8078-d754aceda153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:03.826290Z",
     "iopub.status.busy": "2022-07-01T12:43:03.825999Z",
     "iopub.status.idle": "2022-07-01T12:43:03.835007Z",
     "shell.execute_reply": "2022-07-01T12:43:03.834699Z",
     "shell.execute_reply.started": "2022-07-01T12:43:03.826242Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dhdt': {\n",
    "        'depth': 3,\n",
    "        'learning_rate': 0.25,#1e-3,\n",
    "        \n",
    "        'initializer': 'GlorotUniform', #GlorotUniform\n",
    "        'initializer_index': 'GlorotUniform', #GlorotUniform\n",
    "        \n",
    "        \n",
    "        'loss': 'mse',#'mae',\n",
    "        'optimizer': 'rmsprop',        \n",
    "        \n",
    "        'beta_1': 10,\n",
    "        'beta_2': 10,\n",
    "        \n",
    "        'sparse_activation_1': 'entmax', #softmax, entmax, sparsemax \n",
    "        'sparse_activation_2': 'entmax', #sigmoid, entmax, sparsemax \n",
    "        \n",
    "        'activation': 'tanh', #sigmoid\n",
    "        'squeeze_factor': 1,\n",
    "        \n",
    "        'batch_size': 512,\n",
    "        'epochs': 10_000,\n",
    "        'early_stopping_epochs': 50,\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'make_classification': {\n",
    "        'number_of_variables': 10,\n",
    "        'n_samples': 10_000,\n",
    "        'num_eval': 10,\n",
    "        \n",
    "        'noise': 0.1,\n",
    "    },\n",
    "\n",
    "    'computation': {\n",
    "        'random_seed': 42,\n",
    "        'trials': 3,\n",
    "        'n_jobs': 60,\n",
    "        'verbosity': 0,\n",
    "        \n",
    "        'search_iterations': 100,\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ab8be2-1b4c-4370-a837-9176d15bea41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:03.835814Z",
     "iopub.status.busy": "2022-07-01T12:43:03.835702Z",
     "iopub.status.idle": "2022-07-01T12:43:09.015884Z",
     "shell.execute_reply": "2022-07-01T12:43:09.014653Z",
     "shell.execute_reply.started": "2022-07-01T12:43:03.835799Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, ParameterSampler, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = '' #'true'\n",
    "\n",
    "#os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit\" \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from utilities.utilities_updated16 import *\n",
    "from utilities.DHDT_updated16 import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "tf.random.set_seed(config['computation']['random_seed'])\n",
    "np.random.seed(config['computation']['random_seed'])\n",
    "random.seed(config['computation']['random_seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2397843-32d2-4579-b197-0686f4a99b54",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e7da9-12bb-467f-919f-4fd510ce6463",
   "metadata": {},
   "source": [
    "## make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ac1bc7-e904-4b1d-8bc5-1108b386003a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:09.017835Z",
     "iopub.status.busy": "2022-07-01T12:43:09.017424Z",
     "iopub.status.idle": "2022-07-01T12:43:09.131560Z",
     "shell.execute_reply": "2022-07-01T12:43:09.130465Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.017796Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512, 10), dtype=float32, numpy=\n",
       "array([[0.6645621 , 0.44100678, 0.3528825 , ..., 0.8724445 , 0.22632635,\n",
       "        0.22319686],\n",
       "       [0.3103881 , 0.7223358 , 0.13318717, ..., 0.5212307 , 0.6345445 ,\n",
       "        0.1993283 ],\n",
       "       [0.72942245, 0.54583454, 0.10756552, ..., 0.21062577, 0.8527372 ,\n",
       "        0.44062173],\n",
       "       ...,\n",
       "       [0.35890555, 0.27476323, 0.9093468 , ..., 0.02406609, 0.15381753,\n",
       "        0.52061427],\n",
       "       [0.18050718, 0.72601223, 0.46687126, ..., 0.20896721, 0.11046493,\n",
       "        0.8955517 ],\n",
       "       [0.26526177, 0.9374975 , 0.5160142 , ..., 0.19101524, 0.33028102,\n",
       "        0.5746336 ]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = tf.random.uniform((512,10))\n",
    "t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33928188-c869-4156-8ad7-9b323486fac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:09.133274Z",
     "iopub.status.busy": "2022-07-01T12:43:09.133008Z",
     "iopub.status.idle": "2022-07-01T12:43:09.191272Z",
     "shell.execute_reply": "2022-07-01T12:43:09.190516Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.133240Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(t1, [0, 1, 0], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9d6742-c3c6-48fc-a4f4-0ee654f5a78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:09.193979Z",
     "iopub.status.busy": "2022-07-01T12:43:09.193731Z",
     "iopub.status.idle": "2022-07-01T12:43:09.257022Z",
     "shell.execute_reply": "2022-07-01T12:43:09.256177Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.193950Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 10), dtype=float32, numpy=\n",
       "array([[0.68789124, 0.48447883, 0.9309944 , 0.252187  , 0.73115396,\n",
       "        0.89256823, 0.94674826, 0.7493341 , 0.34925628, 0.54718256],\n",
       "       [0.26160395, 0.69734323, 0.11962581, 0.53484344, 0.7148968 ,\n",
       "        0.87501776, 0.33967495, 0.17377627, 0.4418521 , 0.9008261 ],\n",
       "       [0.13803864, 0.12217975, 0.5754491 , 0.9417181 , 0.9186585 ,\n",
       "        0.59708476, 0.6109482 , 0.82086265, 0.83269787, 0.8915849 ],\n",
       "       [0.01377225, 0.49807465, 0.57503664, 0.6856195 , 0.75972784,\n",
       "        0.908944  , 0.40900218, 0.8765154 , 0.53890026, 0.42733097],\n",
       "       [0.401173  , 0.66623247, 0.16348064, 0.18220246, 0.97040176,\n",
       "        0.06139731, 0.53034747, 0.9869994 , 0.4746945 , 0.8646754 ],\n",
       "       [0.20301068, 0.11448455, 0.35100245, 0.68227184, 0.18108869,\n",
       "        0.8163481 , 0.65651655, 0.9258256 , 0.2391715 , 0.8365958 ],\n",
       "       [0.04765272, 0.8007157 , 0.8299267 , 0.14328372, 0.8616878 ,\n",
       "        0.9707202 , 0.6779593 , 0.5641242 , 0.62537   , 0.8653159 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = tf.random.uniform((7,10))\n",
    "t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07c67fa-aa38-49a0-af53-70aa9e8b2406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:09.258376Z",
     "iopub.status.busy": "2022-07-01T12:43:09.258137Z",
     "iopub.status.idle": "2022-07-01T12:43:09.330337Z",
     "shell.execute_reply": "2022-07-01T12:43:09.329559Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.258346Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 10, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(t1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575c93a3-289d-4f96-b5e3-92e45786a8f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:09.331956Z",
     "iopub.status.busy": "2022-07-01T12:43:09.331711Z",
     "iopub.status.idle": "2022-07-01T12:43:09.388168Z",
     "shell.execute_reply": "2022-07-01T12:43:09.387392Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.331927Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims([0, 1, 0, 1, 0, 0, 1], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c94d4d-8659-4c5a-a83c-7eaa6eaf2ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:09.389661Z",
     "iopub.status.busy": "2022-07-01T12:43:09.389419Z",
     "iopub.status.idle": "2022-07-01T12:43:09.463190Z",
     "shell.execute_reply": "2022-07-01T12:43:09.462404Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.389632Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(t1, tf.transpose(tf.stack([[i for i in range(7)], [0, 1, 0, 1, 0, 0, 1]]))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a29f01-c188-4d45-add5-9be1480b696a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:09.464538Z",
     "iopub.status.busy": "2022-07-01T12:43:09.464305Z",
     "iopub.status.idle": "2022-07-01T12:43:09.513207Z",
     "shell.execute_reply": "2022-07-01T12:43:09.512420Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.464509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 1, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(t1, tf.expand_dims([0, 1, 0, 1, 0, 0, 1], 0), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e73a63cb-2107-41ac-9b65-8b39c98ba3e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:09.514556Z",
     "iopub.status.busy": "2022-07-01T12:43:09.514321Z",
     "iopub.status.idle": "2022-07-01T12:43:09.526334Z",
     "shell.execute_reply": "2022-07-01T12:43:09.525559Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.514529Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 7, 10, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(tf.expand_dims(t1, 2), tf.expand_dims([0, 1, 0, 1, 0, 0, 1], 0), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24357a9-fcca-422c-bfb2-b9f4c06058ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9999f1bd-d478-48c3-9935-dd7690cbf45e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:43:09.527860Z",
     "iopub.status.busy": "2022-07-01T12:43:09.527526Z",
     "iopub.status.idle": "2022-07-01T12:43:09.913332Z",
     "shell.execute_reply": "2022-07-01T12:43:09.912027Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.527826Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape (selected):  (10000, 10)\n",
      "Original Data Shape (encoded):  (10000, 10)\n",
      "Original Data Class Distribution:  4970  (true) / 5030  (false)\n",
      "(7000, 10) (7000,)\n",
      "(1000, 10) (1000,)\n",
      "(2000, 10) (2000,)\n",
      "True Ratio:  0.49442857142857144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc24a223ace44cf4b2b5fcd175c46fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads leaf_classes_array array([-0.20379, -0.     , -0.     , -0.     , -0.     , -0.     ,\n",
      "       -0.     , -0.     ], dtype=float32)\n",
      "grads split_values array([[0.00566, 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
      "        0.     , 0.     , 0.     ],\n",
      "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.08961,\n",
      "        0.     , 0.     , 0.     ],\n",
      "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
      "        0.     , 0.     , 0.     ],\n",
      "       [0.     , 0.03254, 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
      "        0.     , 0.     , 0.     ],\n",
      "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
      "        0.     , 0.     , 0.     ],\n",
      "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
      "        0.     , 0.     , 0.     ],\n",
      "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
      "        0.     , 0.     , 0.     ]], dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: (['split_index_array:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'split_index_array:0' shape=(7, 10) dtype=float32, numpy=\narray([[ 0.37544608, -0.29371867, -0.5906499 , -0.48526052,  0.28223038,\n        -0.29994667,  0.06242931, -0.49367943,  0.03558689,  0.2202838 ],\n       [ 0.22721106, -0.56934077,  0.542374  , -0.06449348,  0.28349537,\n        -0.39251846,  0.58211887, -0.3384545 , -0.2206845 , -0.191425  ],\n       [ 0.39547426, -0.02676082, -0.33537054, -0.20770332, -0.48054087,\n        -0.29484373, -0.49992228, -0.32385367, -0.27351788,  0.16347325],\n       [-0.0291568 ,  0.35967314, -0.40947214,  0.04607409,  0.26076162,\n         0.3229952 , -0.19925156,  0.2722258 , -0.43306243, -0.45824605],\n       [-0.2960005 ,  0.3118412 ,  0.30681413,  0.0606336 ,  0.5301775 ,\n         0.47626913,  0.30814773, -0.3977276 ,  0.00200945,  0.07006592],\n       [ 0.55999017, -0.01045215, -0.4206128 ,  0.40113342, -0.11888885,\n        -0.3420161 ,  0.0298503 , -0.17081556,  0.1842606 ,  0.28462625],\n       [ 0.49227834, -0.19435316,  0.37118465,  0.10449535,  0.11204809,\n         0.10816699, -0.4236087 ,  0.31352234,  0.50361705,  0.02319527]],\n      dtype=float32)>),).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2442460/444477644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     scores_dict['history'] = model_dict['DHDT'].fit(dataset_dict['X_train'][:1], \n\u001b[0m\u001b[1;32m     56\u001b[0m                                                   \u001b[0mdataset_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dhdt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated16.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, batch_size, epochs, early_stopping_epochs, valid_data)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m                 \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/smarton/InES_XAI/00_experiments/utilities/DHDT_updated16.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_index_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_index_array\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbosity\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grads split_index_array'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \"\"\"\n\u001b[0;32m--> 640\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[1;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['split_index_array:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'split_index_array:0' shape=(7, 10) dtype=float32, numpy=\narray([[ 0.37544608, -0.29371867, -0.5906499 , -0.48526052,  0.28223038,\n        -0.29994667,  0.06242931, -0.49367943,  0.03558689,  0.2202838 ],\n       [ 0.22721106, -0.56934077,  0.542374  , -0.06449348,  0.28349537,\n        -0.39251846,  0.58211887, -0.3384545 , -0.2206845 , -0.191425  ],\n       [ 0.39547426, -0.02676082, -0.33537054, -0.20770332, -0.48054087,\n        -0.29484373, -0.49992228, -0.32385367, -0.27351788,  0.16347325],\n       [-0.0291568 ,  0.35967314, -0.40947214,  0.04607409,  0.26076162,\n         0.3229952 , -0.19925156,  0.2722258 , -0.43306243, -0.45824605],\n       [-0.2960005 ,  0.3118412 ,  0.30681413,  0.0606336 ,  0.5301775 ,\n         0.47626913,  0.30814773, -0.3977276 ,  0.00200945,  0.07006592],\n       [ 0.55999017, -0.01045215, -0.4206128 ,  0.40113342, -0.11888885,\n        -0.3420161 ,  0.0298503 , -0.17081556,  0.1842606 ,  0.28462625],\n       [ 0.49227834, -0.19435316,  0.37118465,  0.10449535,  0.11204809,\n         0.10816699, -0.4236087 ,  0.31352234,  0.50361705,  0.02319527]],\n      dtype=float32)>),)."
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    tf.random.set_seed(config['computation']['random_seed'])\n",
    "    np.random.seed(config['computation']['random_seed'])\n",
    "    random.seed(config['computation']['random_seed'])  \n",
    "    \n",
    "    metrics = ['accuracy', 'f1']\n",
    "    \n",
    "    config_test = deepcopy(config)\n",
    "    #config_test['make_classification']['n_samples'] = 10_000\n",
    "    config_test['dhdt']['epochs'] = 5#00\n",
    "    #config_test['dhdt']['initializer_index'] = 'he_normal'#'ones', #GlorotUniform\n",
    "    #config_test['dhdt']['activation'] = 'sigmoid'\n",
    "\n",
    "    dataset_dict = {}\n",
    "    model_dict = {}\n",
    "\n",
    "    scores_dict = {'sklearn': {},\n",
    "                   'DHDT': {}}\n",
    "    \n",
    "    dataset_dict = get_preprocessed_dataset('make_classification',\n",
    "                                            random_seed=config_test['computation']['random_seed'],\n",
    "                                            config=config_test['make_classification'],\n",
    "                                            verbosity=2)\n",
    "\n",
    "    model_dict['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                                   random_state=config_test['computation']['random_seed'])\n",
    "\n",
    "    model_dict['sklearn'].fit(dataset_dict['X_train'], \n",
    "                              dataset_dict['y_train'])\n",
    "\n",
    "\n",
    "\n",
    "    model_dict['DHDT'] = DHDT(dataset_dict['X_train'].shape[1],\n",
    "\n",
    "                                depth = config_test['dhdt']['depth'],\n",
    "\n",
    "                                learning_rate = config_test['dhdt']['learning_rate'],\n",
    "                                optimizer = config_test['dhdt']['optimizer'],\n",
    "                              \n",
    "                                initializer = config_test['dhdt']['initializer'],\n",
    "                                initializer_index = config_test['dhdt']['initializer_index'],\n",
    "                              \n",
    "                                beta_1 = config_test['dhdt']['beta_1'],\n",
    "                                beta_2 = config_test['dhdt']['beta_2'],\n",
    "\n",
    "                                activation = config_test['dhdt']['activation'],\n",
    "                                squeeze_factor = config_test['dhdt']['squeeze_factor'],\n",
    "\n",
    "                                loss = config_test['dhdt']['loss'],#'mae',\n",
    "\n",
    "                                random_seed = config_test['computation']['random_seed'],\n",
    "                                verbosity = 5)#5        \n",
    "\n",
    "\n",
    "    scores_dict['history'] = model_dict['DHDT'].fit(dataset_dict['X_train'][:1], \n",
    "                                                  dataset_dict['y_train'][:1], \n",
    "                                                  batch_size=config_test['dhdt']['batch_size'], \n",
    "                                                  epochs=config_test['dhdt']['epochs'], \n",
    "                                                  early_stopping_epochs=config_test['dhdt']['early_stopping_epochs'], \n",
    "                                                  valid_data=(dataset_dict['X_valid'], dataset_dict['y_valid']))\n",
    "\n",
    "\n",
    "    dataset_dict['y_test_dhdt'] = model_dict['DHDT'].predict(dataset_dict['X_test'])\n",
    "    dataset_dict['y_valid_dhdt'] = model_dict['DHDT'].predict(dataset_dict['X_valid'])\n",
    "\n",
    "    dataset_dict['y_test_sklearn'] = model_dict['sklearn'].predict(dataset_dict['X_test'])\n",
    "    dataset_dict['y_valid_sklearn'] = model_dict['sklearn'].predict(dataset_dict['X_valid'])     \n",
    "    \n",
    "    for metric in metrics:\n",
    "        \n",
    "        if metric in ['accuracy', 'f1']:\n",
    "            y_test_dhdt = np.round(dataset_dict['y_test_dhdt'])\n",
    "            y_valid_dhdt = np.round(dataset_dict['y_valid_dhdt'])\n",
    "            y_test_sklearn = np.round(dataset_dict['y_test_sklearn'])\n",
    "            y_valid_sklearn = np.round(dataset_dict['y_valid_sklearn'])         \n",
    "        else:\n",
    "            y_test_dhdt = dataset_dict['y_test_dhdt']\n",
    "            y_valid_dhdt = dataset_dict['y_valid_dhdt']\n",
    "            y_test_sklearn = dataset_dict['y_test_sklearn']\n",
    "            y_valid_sklearn =    dataset_dict['y_valid_sklearn']                \n",
    "        \n",
    "        scores_dict['sklearn'][metric + '_test'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_test'], y_test_sklearn)\n",
    "        scores_dict['DHDT'][metric + '_test'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_test'], y_test_dhdt)\n",
    "\n",
    "        scores_dict['sklearn'][metric + '_valid'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_valid'], y_valid_sklearn)   \n",
    "        scores_dict['DHDT'][metric + '_valid'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_valid'], y_valid_dhdt)\n",
    "\n",
    "        print('Test ' + metric + ' Sklearn (' + str(0) + ')', scores_dict['sklearn'][metric + '_test'])\n",
    "        print('Test ' + metric + ' DHDT (' + str(0) + ')', scores_dict['DHDT'][metric + '_test'])   \n",
    "        print('________________________________________________________________________________________________________')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d22db-7bfe-402f-9999-ec03c964421b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.914180Z",
     "iopub.status.idle": "2022-07-01T12:43:09.914385Z",
     "shell.execute_reply": "2022-07-01T12:43:09.914278Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.914268Z"
    }
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b39a4-6180-411e-b3cd-805bf290a1f7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.915231Z",
     "iopub.status.idle": "2022-07-01T12:43:09.915399Z",
     "shell.execute_reply": "2022-07-01T12:43:09.915318Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.915310Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    tf.random.set_seed(config['computation']['random_seed'])\n",
    "    np.random.seed(config['computation']['random_seed'])\n",
    "    random.seed(config['computation']['random_seed'])  \n",
    "    \n",
    "    metrics = ['accuracy', 'f1']\n",
    "    \n",
    "    config_test = deepcopy(config)\n",
    "    #config_test['make_classification']['n_samples'] = 10_000\n",
    "    config_test['dhdt']['epochs'] = 500\n",
    "    #config_test['dhdt']['initializer_index'] = 'he_normal'#'ones', #GlorotUniform\n",
    "    #config_test['dhdt']['activation'] = 'sigmoid'\n",
    "\n",
    "    dataset_dict = {}\n",
    "    model_dict = {}\n",
    "\n",
    "    scores_dict = {'sklearn': {},\n",
    "                   'DHDT': {}}\n",
    "    \n",
    "    dataset_dict = get_preprocessed_dataset('Titanic',\n",
    "                                            random_seed=config_test['computation']['random_seed'],\n",
    "                                            config=config_test['make_classification'],\n",
    "                                            verbosity=2)\n",
    "\n",
    "    model_dict['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                                   random_state=config_test['computation']['random_seed'])\n",
    "\n",
    "    model_dict['sklearn'].fit(dataset_dict['X_train'], \n",
    "                              dataset_dict['y_train'])\n",
    "\n",
    "\n",
    "\n",
    "    model_dict['DHDT'] = DHDT(dataset_dict['X_train'].shape[1],\n",
    "\n",
    "                                depth = config_test['dhdt']['depth'],\n",
    "\n",
    "                                learning_rate = config_test['dhdt']['learning_rate'],\n",
    "                                optimizer = config_test['dhdt']['optimizer'],\n",
    "                              \n",
    "                                initializer = config_test['dhdt']['initializer'],\n",
    "                                initializer_index = config_test['dhdt']['initializer_index'],\n",
    "                              \n",
    "                                beta_1 = config_test['dhdt']['beta_1'],\n",
    "                                beta_2 = config_test['dhdt']['beta_2'],\n",
    "\n",
    "                                activation = config_test['dhdt']['activation'],\n",
    "                                squeeze_factor = config_test['dhdt']['squeeze_factor'],\n",
    "\n",
    "                                loss = config_test['dhdt']['loss'],#'mae',\n",
    "\n",
    "                                random_seed = config_test['computation']['random_seed'],\n",
    "                                verbosity = 1)#5        \n",
    "\n",
    "\n",
    "    scores_dict['history'] = model_dict['DHDT'].fit(dataset_dict['X_train'], \n",
    "                                                  dataset_dict['y_train'], \n",
    "                                                  batch_size=config_test['dhdt']['batch_size'], \n",
    "                                                  epochs=config_test['dhdt']['epochs'], \n",
    "                                                  early_stopping_epochs=config_test['dhdt']['early_stopping_epochs'], \n",
    "                                                  valid_data=(dataset_dict['X_valid'], dataset_dict['y_valid']))\n",
    "\n",
    "\n",
    "    dataset_dict['y_test_dhdt'] = model_dict['DHDT'].predict(dataset_dict['X_test'])\n",
    "    dataset_dict['y_valid_dhdt'] = model_dict['DHDT'].predict(dataset_dict['X_valid'])\n",
    "\n",
    "    dataset_dict['y_test_sklearn'] = model_dict['sklearn'].predict(dataset_dict['X_test'])\n",
    "    dataset_dict['y_valid_sklearn'] = model_dict['sklearn'].predict(dataset_dict['X_valid'])     \n",
    "    \n",
    "    for metric in metrics:\n",
    "        \n",
    "        if metric in ['accuracy', 'f1']:\n",
    "            y_test_dhdt = np.round(dataset_dict['y_test_dhdt'])\n",
    "            y_valid_dhdt = np.round(dataset_dict['y_valid_dhdt'])\n",
    "            y_test_sklearn = np.round(dataset_dict['y_test_sklearn'])\n",
    "            y_valid_sklearn = np.round(dataset_dict['y_valid_sklearn'])         \n",
    "        else:\n",
    "            y_test_dhdt = dataset_dict['y_test_dhdt']\n",
    "            y_valid_dhdt = dataset_dict['y_valid_dhdt']\n",
    "            y_test_sklearn = dataset_dict['y_test_sklearn']\n",
    "            y_valid_sklearn =    dataset_dict['y_valid_sklearn']                \n",
    "        \n",
    "        scores_dict['sklearn'][metric + '_test'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_test'], y_test_sklearn)\n",
    "        scores_dict['DHDT'][metric + '_test'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_test'], y_test_dhdt)\n",
    "\n",
    "        scores_dict['sklearn'][metric + '_valid'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_valid'], y_valid_sklearn)   \n",
    "        scores_dict['DHDT'][metric + '_valid'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_valid'], y_valid_dhdt)\n",
    "\n",
    "        print('Test ' + metric + ' Sklearn (' + str(0) + ')', scores_dict['sklearn'][metric + '_test'])\n",
    "        print('Test ' + metric + ' DHDT (' + str(0) + ')', scores_dict['DHDT'][metric + '_test'])   \n",
    "        print('________________________________________________________________________________________________________')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56673688-f8dd-4bdb-a894-4ddec8e1ad08",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.916100Z",
     "iopub.status.idle": "2022-07-01T12:43:09.916262Z",
     "shell.execute_reply": "2022-07-01T12:43:09.916183Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.916174Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dict['X_train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68804337-eada-4203-a431-518b208486ef",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.917368Z",
     "iopub.status.idle": "2022-07-01T12:43:09.917565Z",
     "shell.execute_reply": "2022-07-01T12:43:09.917458Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.917449Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:   \n",
    "    normalizer_list = dataset_dict['normalizer_list']\n",
    "    if normalizer_list is not None: \n",
    "        transpose_normalized = []\n",
    "        for i, column_name in enumerate(dataset_dict['X_train']):\n",
    "            column = deepcopy(dataset_dict['X_train'][column_name])\n",
    "            column_new = column\n",
    "            if len(column_new[column_new != 0]) != 0:\n",
    "                column_new[column_new != 0] = normalizer_list[i].inverse_transform([column[column != 0]])\n",
    "                #column_new = normalizer_list[i].inverse_transform(column.reshape(-1, 1)).ravel()\n",
    "            transpose_normalized.append(column_new)\n",
    "        data = pd.DataFrame(np.array(transpose_normalized).transpose(), columns=dataset_dict['X_train'].columns).round(1)\n",
    "        display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa666bc-4b6d-4b03-829f-eb6d7e6bd6e9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.918517Z",
     "iopub.status.idle": "2022-07-01T12:43:09.918721Z",
     "shell.execute_reply": "2022-07-01T12:43:09.918613Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.918604Z"
    }
   },
   "outputs": [],
   "source": [
    "if True:    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict['DHDT'].plot()\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict['sklearn'], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3355ff7-56c4-47d8-ac04-eb71ffa13343",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.919513Z",
     "iopub.status.idle": "2022-07-01T12:43:09.920024Z",
     "shell.execute_reply": "2022-07-01T12:43:09.919893Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.919879Z"
    }
   },
   "outputs": [],
   "source": [
    "if True:    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict['DHDT'].plot(normalizer_list=dataset_dict['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict['sklearn'], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a6ed9-7217-4311-9c3a-1ce460912c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2b5ca-5a93-4147-a09b-82a070ff9f98",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.920604Z",
     "iopub.status.idle": "2022-07-01T12:43:09.921019Z",
     "shell.execute_reply": "2022-07-01T12:43:09.920896Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.920881Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict['DHDT'].plot()\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict['sklearn'], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c279e-92db-4aa6-91e9-895b1b38378a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.921780Z",
     "iopub.status.idle": "2022-07-01T12:43:09.922254Z",
     "shell.execute_reply": "2022-07-01T12:43:09.922125Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.922109Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict['DHDT'].plot(normalizer_list=dataset_dict['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict['sklearn'], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a13b2a-ca9d-44de-9a52-b8ca61808093",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.922859Z",
     "iopub.status.idle": "2022-07-01T12:43:09.923303Z",
     "shell.execute_reply": "2022-07-01T12:43:09.923175Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.923158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    parallel_eval_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_synthetic = parallel_eval_synthetic(delayed(evaluate_synthetic_parallel)(index = index,\n",
    "                                                                                                random_seed_data = config['computation']['random_seed']+index,\n",
    "                                                                                                random_seed_model = config['computation']['random_seed'],#+random_seed_model,\n",
    "                                                                                                config = config,\n",
    "                                                                                                verbosity = -1) for index in range(config['make_classification']['num_eval']))\n",
    "\n",
    "    for i, synthetic_result in enumerate(evaluation_results_synthetic):\n",
    "        if i == 0:\n",
    "            model_dict_synthetic = synthetic_result[0]\n",
    "            scores_dict_synthetic = synthetic_result[1]\n",
    "            dataset_dict_synthetic = synthetic_result[2]\n",
    "        else: \n",
    "            model_dict_synthetic = mergeDict(model_dict_synthetic, synthetic_result[0])\n",
    "            scores_dict_synthetic = mergeDict(scores_dict_synthetic, synthetic_result[1])\n",
    "            dataset_dict_synthetic = mergeDict(dataset_dict_synthetic, synthetic_result[2])        \n",
    "    \n",
    "    metric_identifer = '_test'\n",
    "    metrics = ['accuracy', 'f1']\n",
    "    index = [i for i in range(config['make_classification']['num_eval'])]\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "\n",
    "    results_DHDT = None\n",
    "    results_sklearn = None\n",
    "    for metric in metrics:\n",
    "        scores_DHDT = [scores_dict_synthetic[i]['DHDT'][metric + metric_identifer] for i in range(config['make_classification']['num_eval'])]\n",
    "\n",
    "        scores_sklearn = [scores_dict_synthetic[i]['sklearn'][metric + metric_identifer] for i in range(config['make_classification']['num_eval'])]\n",
    "\n",
    "        scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "        scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "        scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "        scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "        scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "        scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "\n",
    "        results_DHDT_by_metric = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "        results_sklearn_by_metric = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "        if results_DHDT is None and results_sklearn is None:\n",
    "            results_DHDT = results_DHDT_by_metric\n",
    "            results_sklearn = results_sklearn_by_metric\n",
    "        else:\n",
    "            results_DHDT = np.vstack([results_DHDT, results_DHDT_by_metric])\n",
    "            results_sklearn = np.vstack([results_sklearn, results_sklearn_by_metric])\n",
    "\n",
    "    scores_dataframe_synthetic = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)    \n",
    "        \n",
    "    index = [index_name.split(' ')[1] for index_name in scores_dataframe_synthetic.mean()[scores_dataframe_synthetic.shape[1]//2:].index]\n",
    "    mean_result_dataframe_synthetic = np.round(pd.DataFrame(data=np.vstack([scores_dataframe_synthetic.mean()[:scores_dataframe_synthetic.shape[1]//2], scores_dataframe_synthetic.mean()[scores_dataframe_synthetic.shape[1]//2:]]).T, index=index, columns=['DHDT', 'sklearn']), 3)\n",
    "\n",
    "        \n",
    "    display(scores_dataframe_synthetic.head(5))\n",
    "    display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[0::3]].iloc[:,[0,2,1,3]].head(5))\n",
    "    display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[1::3]].iloc[:,[0,2,1,3]].head(5))\n",
    "    display(mean_result_dataframe_synthetic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac02543-800f-46d8-be6b-96aa36cac58e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.923991Z",
     "iopub.status.idle": "2022-07-01T12:43:09.924154Z",
     "shell.execute_reply": "2022-07-01T12:43:09.924074Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.924065Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_index = 0\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict_synthetic[1]['DHDT'][plot_index].plot(normalizer_list=dataset_dict_synthetic[1]['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict_synthetic[1]['sklearn'][plot_index], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856c6c9-368b-4b75-b0d8-6e7a28e4267c",
   "metadata": {},
   "source": [
    "## Real-World Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9eca0-b6be-4389-960f-857e68e6b197",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.925027Z",
     "iopub.status.idle": "2022-07-01T12:43:09.925501Z",
     "shell.execute_reply": "2022-07-01T12:43:09.925374Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.925359Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    identifier_list = [\n",
    "                        'Adult',#: 32,\n",
    "                        'Bank Marketing',#: 32,\n",
    "                        'Loan Credit',#: 32,\n",
    "\n",
    "                        'Credit Card',#: 23, \n",
    "                        'Car',#: 21,\n",
    "\n",
    "\n",
    "                        'Absenteeism',#: 15,\n",
    "                        'Loan House',#: 15,\n",
    "                        'Cervical Cancer',#: 15,\n",
    "\n",
    "                        'Heart Disease',#: 13,           \n",
    "\n",
    "                        'Titanic',#: 10,\n",
    "                        'Medical Insurance',#: 10,\n",
    "                        'Wisconsin Breast Cancer Original',#: 10,\n",
    "                        'Wisconsin Diagnostic Breast Cancer',#: 10,\n",
    "                        'Wisconsin Prognostic Breast Cancer',#: 10,\n",
    "                        'Abalone',#: 10,\n",
    "\n",
    "                        'Habermans Survival',#: 3, \n",
    "                      ]\n",
    "    \n",
    "    parallel_eval_real_world = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_real_world = parallel_eval_real_world(delayed(evaluate_real_world_parallel)(identifier_list=identifier_list, \n",
    "                                                                                                   random_seed_model=config['computation']['random_seed']+i,\n",
    "                                                                                                   config = config,\n",
    "                                                                                                   verbosity = -1) for i in range(config['computation']['trials']))\n",
    "\n",
    "\n",
    "    for i, real_world_result in enumerate(evaluation_results_real_world):\n",
    "        if i == 0:\n",
    "            model_dict_real_world = real_world_result[0]\n",
    "            scores_dict_real_world = real_world_result[1]\n",
    "            dataset_dict_real_world = real_world_result[2]\n",
    "        else: \n",
    "            model_dict_real_world = mergeDict(model_dict_real_world, real_world_result[0])\n",
    "            scores_dict_real_world = mergeDict(scores_dict_real_world, real_world_result[1])\n",
    "            dataset_dict_real_world = mergeDict(dataset_dict_real_world, real_world_result[2])    \n",
    "\n",
    "    metric_identifer = '_test'\n",
    "    metrics = ['accuracy', 'f1']\n",
    "    index = identifier_list\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "\n",
    "    results_DHDT = None\n",
    "    results_sklearn = None\n",
    "    for metric in metrics:\n",
    "        scores_DHDT = [scores_dict_real_world[identifier]['DHDT'][metric + metric_identifer] for identifier in identifier_list]\n",
    "\n",
    "        scores_sklearn = [scores_dict_real_world[identifier]['sklearn'][metric + metric_identifer] for identifier in identifier_list]    \n",
    "\n",
    "        scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "        scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "        scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "        scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "        scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "        scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "\n",
    "        results_DHDT_by_metric = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "        results_sklearn_by_metric = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "        if results_DHDT is None and results_sklearn is None:\n",
    "            results_DHDT = results_DHDT_by_metric\n",
    "            results_sklearn = results_sklearn_by_metric\n",
    "        else:\n",
    "            results_DHDT = np.vstack([results_DHDT, results_DHDT_by_metric])\n",
    "            results_sklearn = np.vstack([results_sklearn, results_sklearn_by_metric])\n",
    "            \n",
    "    scores_dataframe_real_world = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "            \n",
    "    index = [index_name.split(' ')[1] for index_name in scores_dataframe_real_world.mean()[scores_dataframe_real_world.shape[1]//2:].index]\n",
    "    mean_result_dataframe_real_world = np.round(pd.DataFrame(data=np.vstack([scores_dataframe_real_world.mean()[:scores_dataframe_real_world.shape[1]//2], scores_dataframe_real_world.mean()[scores_dataframe_real_world.shape[1]//2:]]).T, index=index, columns=['DHDT', 'sklearn']), 3)\n",
    "                \n",
    "    display(scores_dataframe_real_world)\n",
    "    display(scores_dataframe_real_world[scores_dataframe_real_world.columns[0::3]].iloc[:,[0,2,1,3]])    \n",
    "    display(scores_dataframe_real_world[scores_dataframe_real_world.columns[1::3]].iloc[:,[0,2,1,3]])    \n",
    "\n",
    "    display(mean_result_dataframe_real_world)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c55370-5fa9-4f3c-a1a8-be597467f808",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.926077Z",
     "iopub.status.idle": "2022-07-01T12:43:09.926491Z",
     "shell.execute_reply": "2022-07-01T12:43:09.926371Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.926356Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_index = 0\n",
    "    \n",
    "    identifier = identifier_list[0]#\"Absenteeism\"\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict_real_world[identifier]['DHDT'][plot_index].plot(normalizer_list=dataset_dict_real_world[identifier]['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict_real_world[identifier]['sklearn'][plot_index], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e73582-0f9e-4522-9a94-dc59f4e566e9",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09315b63-50a1-4b2c-bfa9-d7b6d961de34",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.927165Z",
     "iopub.status.idle": "2022-07-01T12:43:09.927562Z",
     "shell.execute_reply": "2022-07-01T12:43:09.927439Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.927424Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "        'depth': [config['dhdt']['depth']],\n",
    "        'learning_rate': [0.001, 0.025, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25], #[0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "        \n",
    "        'loss': ['binary_crossentropy', 'mse'], #['binary_crossentropy', 'rmse'], #'mae',\n",
    "        'optimizer': ['adam', 'sgd', 'rmsprop'], #['adam'], #['adam', 'sgd', 'rmsprop'],        \n",
    "        \n",
    "        'initializer': ['GlorotUniform', 'GlorotNormal', 'HeUniform', 'HeNormal', 'LecunUniform', 'LecunNormal', 'RandomNormal', 'RandomUniform', 'Zeros', 'Ones'],#'GlorotUniform', 'GlorotNormal',  #['GlorotUniform', 'GlorotNormal', 'HeUniform', 'HeNormal', 'LecunUniform', 'LecunNormal', 'RandomNormal', 'RandomUniform'], #RandomNormal, RandomUniform\n",
    "        'initializer_index': ['GlorotUniform', 'GlorotNormal', 'HeUniform', 'HeNormal', 'LecunUniform', 'LecunNormal', 'RandomNormal', 'RandomUniform', 'Zeros', 'Ones'],#['GlorotUniform', 'GlorotNormal', 'HeUniform', 'HeNormal', 'LecunUniform', 'LecunNormal', 'RandomNormal', 'RandomUniform', 'Zeros', 'Ones'], #RandomNormal, RandomUniform\n",
    "\n",
    "        'beta_1': [1, 5, 10, 20, 50], #[10, 50, 100],\n",
    "        'beta_2': [1, 5, 10, 20, 50], #[10, 50, 100],\n",
    "    \n",
    "        'sparse_activation_1': ['softmax', 'entmax', 'sparsemax'], #softmax, entmax, sparsemax \n",
    "        'sparse_activation_2': ['sigmoid', 'entmax', 'sparsemax'], #sigmoid, entmax, sparsemax     \n",
    "        \n",
    "        'activation': ['tanh'], #'sigmoid'\n",
    "        #'squeeze_factor': [1],#[0.2, 0.5, 1, 2, 5], #[0.2, 0.5, 1, 2, 5],    \n",
    "}\n",
    "\n",
    "#parameter_grid = ParameterGrid(parameter_dict)\n",
    "parameter_grid = ParameterSampler(n_iter = config['computation']['search_iterations'],\n",
    "                                  param_distributions = parameter_dict,\n",
    "                                  random_state = config['computation']['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952be342-9751-474b-8780-f185b3f9c29d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.928373Z",
     "iopub.status.idle": "2022-07-01T12:43:09.928662Z",
     "shell.execute_reply": "2022-07-01T12:43:09.928542Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.928530Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:   \n",
    "    print('Number of Trials: ' + str(len(parameter_grid)))\n",
    "    \n",
    "    parallel_hpo_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_hpo_synthetic = parallel_hpo_synthetic(delayed(evaluate_parameter_setting_synthetic)(parameter_setting, config, metrics= ['accuracy', 'f1']) for parameter_setting in parameter_grid)\n",
    "\n",
    "    comparator_metric = 'f1'\n",
    "\n",
    "    dhdt_mean_list_unsorted = [np.mean(evaluation_results_hpo_synthetic[i][0]['DHDT ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "    dhdt_mean_list = sorted(dhdt_mean_list_unsorted, reverse=True)\n",
    "\n",
    "    dhdt_max_mean_list_unsorted = [np.mean(evaluation_results_hpo_synthetic[i][0]['DHDT ' + comparator_metric + '_max']) for i in range(len(parameter_grid))]\n",
    "    dhdt_max_mean_list = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted, dhdt_max_mean_list_unsorted), key=lambda pair: pair[0], reverse=True)]\n",
    "    #[x for _, x in sorted(zip(dhdt_mean_list, dhdt_max_mean_list), reverse=True)]\n",
    "\n",
    "    sklearn_mean_list_unsorted = [np.mean(evaluation_results_hpo_synthetic[i][0]['sklearn ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "    sklearn_mean_list = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted, sklearn_mean_list_unsorted), key=lambda pair: pair[0], reverse=True)]\n",
    "    #[x for _, x in sorted(zip(dhdt_mean_list, sklearn_mean_list), reverse=True)]\n",
    "\n",
    "    parameter_setting_list_unsorted = [evaluation_results_hpo_synthetic[i][1] for i in range(len(parameter_grid))]\n",
    "    parameter_setting_list = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted, parameter_setting_list_unsorted), key=lambda pair: pair[0], reverse=True)]\n",
    "    #[x for _, x in sorted(zip(dhdt_mean_list, parameter_setting_list), reverse=True)]\n",
    "\n",
    "    hpo_results_synthetic = []\n",
    "    for i, (dhdt_mean, dhdt_max_mean, sklearn_mean, parameter_setting) in enumerate(zip(dhdt_mean_list, dhdt_max_mean_list, sklearn_mean_list, parameter_setting_list)):\n",
    "        result_dict = {\n",
    "                             'DHDT mean (mean)': dhdt_mean,\n",
    "                             'DHDT max (mean)': dhdt_max_mean,\n",
    "                             'sklearn mean': sklearn_mean,\n",
    "                             'parameters': parameter_setting\n",
    "                            }\n",
    "\n",
    "        hpo_results_synthetic.append(result_dict)\n",
    "\n",
    "    display(hpo_results_synthetic[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cda720-28ef-4630-b714-48114e994d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d60153-e7dc-4272-861e-575091d2b039",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.929534Z",
     "iopub.status.idle": "2022-07-01T12:43:09.929909Z",
     "shell.execute_reply": "2022-07-01T12:43:09.929778Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.929764Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_parameter_setting_gen(parameter_setting, dataset_dict):    \n",
    "    base_model_gen = GeneticTree()\n",
    "    base_model_gen.set_params(**parameter_setting)\n",
    "\n",
    "    base_model_gen.fit(dataset_dict['X_train'].values, dataset_dict['y_train'].values)\n",
    "\n",
    "    base_model_gen_pred = base_model_gen.predict(dataset_dict['X_valid'].values)\n",
    "\n",
    "    f1_score_base_model_gen = f1_score(dataset_dict['y_valid'].values, np.round(base_model_gen_pred), average='weighted')\n",
    "\n",
    "    return (f1_score_base_model_gen, parameter_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a2cfa-65d2-4cde-9440-f6b1c6a926dc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.930837Z",
     "iopub.status.idle": "2022-07-01T12:43:09.931070Z",
     "shell.execute_reply": "2022-07-01T12:43:09.930931Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.930922Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    identifier_list = [\n",
    "                        'Adult',#: 32, 100 random 7.4min\n",
    "                        'Bank Marketing',#: 32, 100 random 8.0min\n",
    "                        'Loan Credit',#: 32, 100 random 11.0min\n",
    "\n",
    "                        'Credit Card',#: 23, 100 random 9.7min\n",
    "                        'Car',#: 21, 100 random 4.1min\n",
    "\n",
    "\n",
    "                        'Absenteeism',#: 15, 100 random 2.9min\n",
    "                        'Loan House',#: 15,  100 random 2.6min\n",
    "                        'Cervical Cancer',#: 15, 100 random 1.4min\n",
    "\n",
    "                        'Heart Disease',#: 13, 100 random 1.7min       \n",
    "\n",
    "                        'Titanic',#: 10, 100 random 2.9min\n",
    "                        'Medical Insurance',#: 10, 100 random 3.0min\n",
    "                        'Wisconsin Breast Cancer Original',#: 10, 100 random 2.5min\n",
    "                        'Wisconsin Diagnostic Breast Cancer',#: 10, 100 random 1.4min\n",
    "                        'Wisconsin Prognostic Breast Cancer',#: 10, 100 random 1.4min\n",
    "                        'Abalone',#: 10, 100 random 2.6min\n",
    "\n",
    "                        'Habermans Survival',#: 3, 100 random 1.4min\n",
    "                      ]\n",
    "\n",
    "    hpo_results_real_world_valid = {}\n",
    "    hpo_results_real_world_unsorted_valid = {}\n",
    "    hpo_results_real_world_test = {}\n",
    "    hpo_results_real_world_unsorted_test = {}\n",
    "        \n",
    "    print('___________________________________________________________________________')\n",
    "    \n",
    "    for identifier in identifier_list:\n",
    "        print(identifier)\n",
    "        \n",
    "        dataset_dict = get_preprocessed_dataset(identifier,\n",
    "                                                random_seed=config['computation']['random_seed'],\n",
    "                                                config=config['make_classification'],\n",
    "                                                verbosity=0)  \n",
    "\n",
    "        base_model = DecisionTreeClassifier()\n",
    "\n",
    "        parameter_dict_sklearn = {\n",
    "                'max_depth': [config['dhdt']['depth']],\n",
    "                'random_state': [config['computation']['random_seed']],\n",
    "                'criterion': ['gini', 'entropy', 'log_loss'], \n",
    "                'min_samples_split': [0, 2, 5, 10, 50], \n",
    "                'min_samples_leaf': [0, 2, 5, 10, 50], \n",
    "                'min_weight_fraction_leaf': [0.0, 0.1, 0.5, 0.8], \n",
    "                'max_features': ['auto', 'sqrt', 'log2', None], \n",
    "                'max_leaf_nodes': [0,1,2,5,10,None], \n",
    "                'min_impurity_decrease': [0.0, 0.1, 0.5, 0.8], \n",
    "                'ccp_alpha': [0.0, 0.1, 0.5, 0.8],    \n",
    "        }\n",
    "\n",
    "\n",
    "        clf_sklearn = RandomizedSearchCV(n_iter=config['computation']['search_iterations'],\n",
    "                                         estimator = base_model, \n",
    "                                         param_distributions = parameter_dict_sklearn,\n",
    "                                         scoring=make_scorer(f1_score, average='weighted'),\n",
    "                                         cv=2,\n",
    "                                         verbose=1)\n",
    "        \n",
    "        \n",
    "        clf_sklearn.fit(dataset_dict['X_train'], dataset_dict['y_train'])\n",
    "\n",
    "        sklearn_params = clf_sklearn.best_params_\n",
    "        \n",
    "        display(sklearn_params)           \n",
    "        \n",
    "        base_model = DecisionTreeClassifier()\n",
    "        base_model.set_params(**sklearn_params)\n",
    "\n",
    "        start_sklearn = timeit.default_timer()\n",
    "\n",
    "        base_model.fit(dataset_dict['X_train'], \n",
    "                       dataset_dict['y_train'])    \n",
    "\n",
    "\n",
    "        end_sklearn = timeit.default_timer()  \n",
    "        runtime_sklearn = end_sklearn - start_sklearn        \n",
    "        \n",
    "        \n",
    "                \n",
    "        parameter_dict_gen = {\n",
    "                'n_thresholds': [5, 10, 20],\n",
    "            \n",
    "                'n_trees': [50, 100, 250, 500],\n",
    "                'max_iter': [10, 50, 100, 250, 500],\n",
    "                'cross_prob': [0.2, 0.4, 0.6, 0.8],\n",
    "                'mutation_prob': [0.2, 0.4, 0.6, 0.8],\n",
    "            \n",
    "                'early_stopping': [True],\n",
    "            \n",
    "                'max_depth': [config['dhdt']['depth']],\n",
    "                'random_state': [config['computation']['random_seed']],\n",
    "                'n_jobs': [1],    \n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "        #parameter_grid_gen = ParameterGrid(parameter_dict_gen)\n",
    "        parameter_grid_gen = ParameterSampler(n_iter = config['computation']['search_iterations'],\n",
    "                                           param_distributions = parameter_dict_gen,\n",
    "                                           random_state = config['computation']['random_seed'])\n",
    "        \n",
    "        print('Number of Trials GenTree: ' + str(len(parameter_grid_gen)))\n",
    "        \n",
    "        parallel_hpo_gen = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "        grid_search_results = parallel_hpo_gen(delayed(evaluate_parameter_setting_gen)(parameter_setting, dataset_dict) for parameter_setting in parameter_grid_gen)           \n",
    "\n",
    "        grid_search_results_sorted = sorted(grid_search_results, key=lambda tup: tup[0], reverse=True) \n",
    "            \n",
    "        gen_params = grid_search_results_sorted[0][1]\n",
    "        \n",
    "        \n",
    "        base_model_gen = GeneticTree()\n",
    "        base_model_gen.set_params(**gen_params)\n",
    "        \n",
    "        start_gen = timeit.default_timer()\n",
    "        base_model_gen.fit(dataset_dict['X_train'].values, dataset_dict['y_train'].values)       \n",
    "        end_gen = timeit.default_timer()  \n",
    "        runtime_gen = end_gen - start_gen \n",
    "        \n",
    "        display(grid_search_results_sorted[0])\n",
    "\n",
    "        display(gen_params)   \n",
    "        \n",
    "        print('Number of Trials DHDT: ' + str(len(parameter_grid)))\n",
    "    \n",
    "        parallel_hpo_real = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "        evaluation_results_hpo_real = parallel_hpo_real(delayed(evaluate_parameter_setting_real_world)(parameter_setting, \n",
    "                                                                                                       identifier, \n",
    "                                                                                                       config, \n",
    "                                                                                                       sklearn_params = (runtime_sklearn, clf_sklearn.best_estimator_),#sklearn_params,\n",
    "                                                                                                       gen_params = (runtime_gen, base_model_gen),#gen_params,\n",
    "                                                                                                       metrics = ['accuracy', 'f1']) for parameter_setting in parameter_grid)\n",
    "\n",
    "        comparator_metric = 'f1'        \n",
    "        \n",
    "        dhdt_mean_list_unsorted_valid = [np.mean(evaluation_results_hpo_real[i][0]['valid']['DHDT ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        dhdt_mean_list_valid = sorted(dhdt_mean_list_unsorted_valid, reverse=True)\n",
    "        dhdt_mean_list_unsorted_test = [np.mean(evaluation_results_hpo_real[i][0]['test']['DHDT ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        dhdt_mean_list_test = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, dhdt_mean_list_unsorted_test), key=lambda pair: pair[0], reverse=True)]\n",
    "        \n",
    "        \n",
    "        dhdt_max_mean_list_unsorted_valid = [np.mean(evaluation_results_hpo_real[i][0]['valid']['DHDT ' + comparator_metric + '_max']) for i in range(len(parameter_grid))]\n",
    "        dhdt_max_mean_list_valid = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, dhdt_max_mean_list_unsorted_valid), key=lambda pair: pair[0], reverse=True)]\n",
    "        dhdt_max_mean_list_unsorted_test = [np.mean(evaluation_results_hpo_real[i][0]['test']['DHDT ' + comparator_metric + '_max']) for i in range(len(parameter_grid))]\n",
    "        dhdt_max_mean_list_test = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, dhdt_max_mean_list_unsorted_test), key=lambda pair: pair[0], reverse=True)]\n",
    "        \n",
    "        sklearn_mean_list_unsorted_valid = [np.mean(evaluation_results_hpo_real[i][0]['valid']['sklearn ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        sklearn_mean_list_valid = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, sklearn_mean_list_unsorted_valid), key=lambda pair: pair[0], reverse=True)]\n",
    "        sklearn_mean_list_unsorted_test = [np.mean(evaluation_results_hpo_real[i][0]['test']['sklearn ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        sklearn_mean_list_test = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, sklearn_mean_list_unsorted_test), key=lambda pair: pair[0], reverse=True)]\n",
    "       \n",
    "        xgb_mean_list_unsorted_valid = [np.mean(evaluation_results_hpo_real[i][0]['valid']['XGB ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        xgb_mean_list_valid = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, xgb_mean_list_unsorted_valid), key=lambda pair: pair[0], reverse=True)]\n",
    "        xgb_mean_list_unsorted_test = [np.mean(evaluation_results_hpo_real[i][0]['test']['XGB ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        xgb_mean_list_test = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, xgb_mean_list_unsorted_test), key=lambda pair: pair[0], reverse=True)]    \n",
    "        \n",
    "        gentree_mean_list_unsorted_valid = [np.mean(evaluation_results_hpo_real[i][0]['valid']['GeneticTree ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        gentree_mean_list_valid = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, gentree_mean_list_unsorted_valid), key=lambda pair: pair[0], reverse=True)]\n",
    "        gentree_mean_list_unsorted_test = [np.mean(evaluation_results_hpo_real[i][0]['test']['GeneticTree ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        gentree_mean_list_test = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, gentree_mean_list_unsorted_test), key=lambda pair: pair[0], reverse=True)]    \n",
    "            \n",
    "        dhdt_runtime_mean_list_unsorted = [np.mean(evaluation_results_hpo_real[i][0]['valid']['DHDT mean runtime'].iloc[:,1]) for i in range(len(parameter_grid))]\n",
    "        dhdt_runtime_mean_list = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, dhdt_runtime_mean_list_unsorted), key=lambda pair: pair[0], reverse=True)]\n",
    "       \n",
    "        sklearn_runtime_mean_list_unsorted = [np.mean(evaluation_results_hpo_real[i][0]['valid']['sklearn mean runtime'].iloc[:,1]) for i in range(len(parameter_grid))]\n",
    "        sklearn_runtime_mean_list = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, sklearn_runtime_mean_list_unsorted), key=lambda pair: pair[0], reverse=True)]        \n",
    "        \n",
    "        xgb_runtime_mean_list_unsorted = [np.mean(evaluation_results_hpo_real[i][0]['valid']['XGB mean runtime'].iloc[:,1]) for i in range(len(parameter_grid))]\n",
    "        xgb_runtime_mean_list = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, xgb_runtime_mean_list_unsorted), key=lambda pair: pair[0], reverse=True)]\n",
    "            \n",
    "        gentree_runtime_mean_list_unsorted = [np.mean(evaluation_results_hpo_real[i][0]['valid']['GeneticTree mean runtime'].iloc[:,1]) for i in range(len(parameter_grid))]\n",
    "        gentree_runtime_mean_list = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, gentree_runtime_mean_list_unsorted), key=lambda pair: pair[0], reverse=True)]\n",
    "                     \n",
    "        parameter_setting_list_unsorted = [evaluation_results_hpo_real[i][1] for i in range(len(parameter_grid))]\n",
    "        parameter_setting_list = [x for (y,x) in sorted(zip(dhdt_mean_list_unsorted_valid, parameter_setting_list_unsorted), key=lambda pair: pair[0], reverse=True)]\n",
    "\n",
    "        hpo_results_real_world_by_identifer = []\n",
    "        for i, (dhdt_mean, \n",
    "                dhdt_max_mean, \n",
    "                sklearn_mean, \n",
    "                xgb_mean, \n",
    "                gentree_mean, \n",
    "                dhdt_runtime_mean, \n",
    "                sklearn_runtime_mean, \n",
    "                xgb_runtime_mean, \n",
    "                gentree_runtime_mean, \n",
    "                parameter_setting) in enumerate(zip(dhdt_mean_list_valid, \n",
    "                                                    dhdt_max_mean_list_valid, \n",
    "                                                    sklearn_mean_list_valid, \n",
    "                                                    xgb_mean_list_valid, \n",
    "                                                    gentree_mean_list_valid, \n",
    "                                                    dhdt_runtime_mean_list, \n",
    "                                                    sklearn_runtime_mean_list, \n",
    "                                                    xgb_runtime_mean_list, \n",
    "                                                    gentree_runtime_mean_list, \n",
    "                                                    parameter_setting_list)):\n",
    "            result_dict = {\n",
    "                                 'DHDT mean (mean)': dhdt_mean,\n",
    "                                 'DHDT max (mean)': dhdt_max_mean,\n",
    "                                 'sklearn mean': sklearn_mean,\n",
    "                                 'XGB mean': xgb_mean,\n",
    "                                 'GeneticTree mean': gentree_mean,\n",
    "                \n",
    "                                 'DHDT runtime mean': dhdt_runtime_mean,\n",
    "                                 'sklearn runtime mean': sklearn_runtime_mean,\n",
    "                                 'XGB runtime mean': xgb_runtime_mean,  \n",
    "                                 'GeneticTree runtime mean': gentree_runtime_mean,                \n",
    "                \n",
    "                                 'parameters': parameter_setting\n",
    "                                }\n",
    "\n",
    "            hpo_results_real_world_by_identifer.append(result_dict)\n",
    "\n",
    "        hpo_results_real_world_valid[identifier] = hpo_results_real_world_by_identifer\n",
    "        \n",
    "        hpo_results_real_world_by_identifer_unsorted = []\n",
    "        for i, (dhdt_mean, \n",
    "                dhdt_max_mean, \n",
    "                sklearn_mean, \n",
    "                xgb_mean, \n",
    "                gentree_mean, \n",
    "                dhdt_runtime_mean, \n",
    "                sklearn_runtime_mean, \n",
    "                xgb_runtime_mean, \n",
    "                gentree_runtime_mean, \n",
    "                parameter_setting) in enumerate(zip(dhdt_mean_list_unsorted_valid, \n",
    "                                                    dhdt_max_mean_list_unsorted_valid, \n",
    "                                                    sklearn_mean_list_unsorted_valid, \n",
    "                                                    xgb_mean_list_unsorted_valid, \n",
    "                                                    gentree_mean_list_unsorted_valid, \n",
    "                                                    dhdt_runtime_mean_list_unsorted, \n",
    "                                                    sklearn_runtime_mean_list_unsorted, \n",
    "                                                    xgb_runtime_mean_list_unsorted, \n",
    "                                                    gentree_runtime_mean_list_unsorted, \n",
    "                                                    parameter_setting_list_unsorted)):\n",
    "            result_dict_unsorted = {\n",
    "                                 'DHDT mean (mean)': dhdt_mean,\n",
    "                                 'DHDT max (mean)': dhdt_max_mean,\n",
    "                                 'sklearn mean': sklearn_mean,\n",
    "                                 'XGB mean': xgb_mean,\n",
    "                                 'GeneticTree mean': gentree_mean,\n",
    "                \n",
    "                                 'DHDT runtime mean': dhdt_runtime_mean,\n",
    "                                 'sklearn runtime mean': sklearn_runtime_mean,\n",
    "                                 'XGB runtime mean': xgb_runtime_mean,  \n",
    "                                 'GeneticTree runtime mean': gentree_runtime_mean,  \n",
    "                \n",
    "                                 'parameters': parameter_setting\n",
    "                                }\n",
    "\n",
    "            hpo_results_real_world_by_identifer_unsorted.append(result_dict_unsorted)\n",
    "\n",
    "        hpo_results_real_world_unsorted_valid[identifier] = hpo_results_real_world_by_identifer_unsorted      \n",
    "        \n",
    "\n",
    "        \n",
    "        hpo_results_real_world_by_identifer = []\n",
    "        for i, (dhdt_mean, \n",
    "                dhdt_max_mean, \n",
    "                sklearn_mean, \n",
    "                xgb_mean, \n",
    "                gentree_mean, \n",
    "                dhdt_runtime_mean, \n",
    "                sklearn_runtime_mean, \n",
    "                xgb_runtime_mean, \n",
    "                gentree_runtime_mean, \n",
    "                parameter_setting) in enumerate(zip(dhdt_mean_list_test, \n",
    "                                                    dhdt_max_mean_list_test, \n",
    "                                                    sklearn_mean_list_test, \n",
    "                                                    xgb_mean_list_test, \n",
    "                                                    gentree_mean_list_test, \n",
    "                                                    dhdt_runtime_mean_list, \n",
    "                                                    sklearn_runtime_mean_list, \n",
    "                                                    xgb_runtime_mean_list, \n",
    "                                                    gentree_runtime_mean_list, \n",
    "                                                    parameter_setting_list)):\n",
    "            result_dict = {\n",
    "                                 'DHDT mean (mean)': dhdt_mean,\n",
    "                                 'DHDT max (mean)': dhdt_max_mean,\n",
    "                                 'sklearn mean': sklearn_mean,\n",
    "                                 'XGB mean': xgb_mean,\n",
    "                                 'GeneticTree mean': gentree_mean,\n",
    "                \n",
    "                                 'DHDT runtime mean': dhdt_runtime_mean,\n",
    "                                 'sklearn runtime mean': sklearn_runtime_mean,\n",
    "                                 'XGB runtime mean': xgb_runtime_mean,  \n",
    "                                 'GeneticTree runtime mean': gentree_runtime_mean,                \n",
    "                \n",
    "                                 'parameters': parameter_setting\n",
    "                                }\n",
    "\n",
    "            hpo_results_real_world_by_identifer.append(result_dict)\n",
    "\n",
    "        hpo_results_real_world_test[identifier] = hpo_results_real_world_by_identifer\n",
    "        \n",
    "        hpo_results_real_world_by_identifer_unsorted = []\n",
    "        for i, (dhdt_mean, \n",
    "                dhdt_max_mean, \n",
    "                sklearn_mean, \n",
    "                xgb_mean, \n",
    "                gentree_mean, \n",
    "                dhdt_runtime_mean, \n",
    "                sklearn_runtime_mean, \n",
    "                xgb_runtime_mean, \n",
    "                gentree_runtime_mean, \n",
    "                parameter_setting) in enumerate(zip(dhdt_mean_list_unsorted_test, \n",
    "                                                    dhdt_max_mean_list_unsorted_test, \n",
    "                                                    sklearn_mean_list_unsorted_test, \n",
    "                                                    xgb_mean_list_unsorted_test, \n",
    "                                                    gentree_mean_list_unsorted_test, \n",
    "                                                    dhdt_runtime_mean_list_unsorted, \n",
    "                                                    sklearn_runtime_mean_list_unsorted, \n",
    "                                                    xgb_runtime_mean_list_unsorted, \n",
    "                                                    gentree_runtime_mean_list_unsorted, \n",
    "                                                    parameter_setting_list_unsorted)):\n",
    "            result_dict_unsorted = {\n",
    "                                 'DHDT mean (mean)': dhdt_mean,\n",
    "                                 'DHDT max (mean)': dhdt_max_mean,\n",
    "                                 'sklearn mean': sklearn_mean,\n",
    "                                 'XGB mean': xgb_mean,\n",
    "                                 'GeneticTree mean': gentree_mean,\n",
    "                \n",
    "                                 'DHDT runtime mean': dhdt_runtime_mean,\n",
    "                                 'sklearn runtime mean': sklearn_runtime_mean,\n",
    "                                 'XGB runtime mean': xgb_runtime_mean,  \n",
    "                                 'GeneticTree runtime mean': gentree_runtime_mean,  \n",
    "                \n",
    "                                 'parameters': parameter_setting\n",
    "                                }\n",
    "\n",
    "            hpo_results_real_world_by_identifer_unsorted.append(result_dict_unsorted)\n",
    "\n",
    "        hpo_results_real_world_unsorted_test[identifier] = hpo_results_real_world_by_identifer_unsorted              \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        print('')\n",
    "        #display(hpo_results_real_world_by_identifer[:1])\n",
    "        print('___________________________________________________________________________')\n",
    "        \n",
    "    best_scores_DHDT_valid = [hpo_results_real_world_valid[key][0]['DHDT mean (mean)'] for key in hpo_results_real_world_valid.keys()]\n",
    "    scores_sklearn_valid = [hpo_results_real_world_valid[key][0]['sklearn mean'] for key in hpo_results_real_world_valid.keys()]\n",
    "    scores_xgb_valid = [hpo_results_real_world_valid[key][0]['XGB mean'] for key in hpo_results_real_world_valid.keys()]\n",
    "    scores_gentree_valid = [hpo_results_real_world_valid[key][0]['GeneticTree mean'] for key in hpo_results_real_world_valid.keys()]\n",
    "    \n",
    "    runtime_DHDT_valid = [hpo_results_real_world_valid[key][0]['DHDT runtime mean'] for key in hpo_results_real_world_valid.keys()]\n",
    "    runtime_sklearn_valid = [hpo_results_real_world_valid[key][0]['sklearn runtime mean'] for key in hpo_results_real_world_valid.keys()]\n",
    "    runtime_xgb_valid = [hpo_results_real_world_valid[key][0]['XGB runtime mean'] for key in hpo_results_real_world_valid.keys()]\n",
    "    runtime_gentree_valid = [hpo_results_real_world_valid[key][0]['GeneticTree runtime mean'] for key in hpo_results_real_world_valid.keys()]\n",
    "        \n",
    "    real_world_best_results_valid = pd.DataFrame(data=np.vstack([best_scores_DHDT_valid, \n",
    "                                                                 scores_sklearn_valid, \n",
    "                                                                 scores_xgb_valid, \n",
    "                                                                 scores_gentree_valid, \n",
    "                                                                 runtime_DHDT_valid, \n",
    "                                                                 runtime_sklearn_valid, \n",
    "                                                                 runtime_xgb_valid, \n",
    "                                                                 runtime_gentree_valid]).T, index=list(hpo_results_real_world_valid.keys()), columns=['DHDT (mean)', \n",
    "                                                                                                                                                      'sklearn (mean)', \n",
    "                                                                                                                                                      'XGB (mean)',\n",
    "                                                                                                                                                      'GeneticTree (mean)',\n",
    "                                                                                                                                                      'DHDT (runtime)', \n",
    "                                                                                                                                                      'sklearn (runtime)', \n",
    "                                                                                                                                                      'XGB (runtime)', \n",
    "                                                                                                                                                      'GeneticTree (runtime)'])\n",
    "    real_world_best_results_mean_valid = real_world_best_results_valid.mean()\n",
    "    real_world_best_results_mean_valid.name = 'MEAN'\n",
    "\n",
    "    real_world_best_results_valid = real_world_best_results_valid.append(real_world_best_results_mean_valid)    \n",
    "    display(real_world_best_results_valid)\n",
    "        \n",
    "        \n",
    "    best_scores_DHDT_test = [hpo_results_real_world_test[key][0]['DHDT mean (mean)'] for key in hpo_results_real_world_test.keys()]\n",
    "    scores_sklearn_test = [hpo_results_real_world_test[key][0]['sklearn mean'] for key in hpo_results_real_world_test.keys()]\n",
    "    scores_xgb_test = [hpo_results_real_world_test[key][0]['XGB mean'] for key in hpo_results_real_world_test.keys()]\n",
    "    scores_gentree_test = [hpo_results_real_world_test[key][0]['GeneticTree mean'] for key in hpo_results_real_world_test.keys()]\n",
    "    \n",
    "    runtime_DHDT_test = [hpo_results_real_world_test[key][0]['DHDT runtime mean'] for key in hpo_results_real_world_test.keys()]\n",
    "    runtime_sklearn_test = [hpo_results_real_world_test[key][0]['sklearn runtime mean'] for key in hpo_results_real_world_test.keys()]\n",
    "    runtime_xgb_test = [hpo_results_real_world_test[key][0]['XGB runtime mean'] for key in hpo_results_real_world_test.keys()]       \n",
    "    runtime_gentree_test = [hpo_results_real_world_test[key][0]['GeneticTree runtime mean'] for key in hpo_results_real_world_test.keys()]       \n",
    "        \n",
    "    real_world_best_results_test = pd.DataFrame(data=np.vstack([best_scores_DHDT_test, \n",
    "                                                                scores_sklearn_test, \n",
    "                                                                scores_xgb_test, \n",
    "                                                                scores_gentree_test, \n",
    "                                                                runtime_DHDT_test, \n",
    "                                                                runtime_sklearn_test, \n",
    "                                                                runtime_xgb_test, \n",
    "                                                                runtime_gentree_test]).T, index=list(hpo_results_real_world_test.keys()), columns=['DHDT (mean)', \n",
    "                                                                                                                                                   'sklearn (mean)', \n",
    "                                                                                                                                                   'XGB (mean)', \n",
    "                                                                                                                                                   'GeneticTree (mean)', \n",
    "                                                                                                                                                   'DHDT (runtime)', \n",
    "                                                                                                                                                   'sklearn (runtime)', \n",
    "                                                                                                                                                   'XGB (runtime)', \n",
    "                                                                                                                                                   'GeneticTree (runtime)'])\n",
    "    real_world_best_results_mean_test = real_world_best_results_test.mean()\n",
    "    real_world_best_results_mean_test.name = 'MEAN'\n",
    "\n",
    "    real_world_best_results_test = real_world_best_results_test.append(real_world_best_results_mean_test)    \n",
    "    display(real_world_best_results_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40147db1-760f-432d-ac2c-0267a8256f8a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.931609Z",
     "iopub.status.idle": "2022-07-01T12:43:09.931765Z",
     "shell.execute_reply": "2022-07-01T12:43:09.931691Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.931683Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, value in hpo_results_real_world_valid.items():\n",
    "    print('___________________________________________________________________________')\n",
    "    print(key)\n",
    "    display(value[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25363527-e144-49ed-9eb8-a85d4ee08fbb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-01T12:43:09.932844Z",
     "iopub.status.idle": "2022-07-01T12:43:09.933040Z",
     "shell.execute_reply": "2022-07-01T12:43:09.932936Z",
     "shell.execute_reply.started": "2022-07-01T12:43:09.932927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_index = 0\n",
    "    \n",
    "    identifier = identifier_list[0]#\"Absenteeism\"\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict_real_world[identifier]['DHDT'][plot_index].plot(normalizer_list=dataset_dict_real_world[identifier]['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict_real_world[identifier]['sklearn'][plot_index], fontsize=10) \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
