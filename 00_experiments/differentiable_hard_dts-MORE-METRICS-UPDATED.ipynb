{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c3b444-064b-4639-983d-238b3da68ad9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6531aaa-2c26-40f5-8078-d754aceda153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:39:44.163444Z",
     "iopub.status.busy": "2022-06-09T09:39:44.163243Z",
     "iopub.status.idle": "2022-06-09T09:39:44.171545Z",
     "shell.execute_reply": "2022-06-09T09:39:44.171174Z",
     "shell.execute_reply.started": "2022-06-09T09:39:44.163388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dhdt': {\n",
    "        'depth': 3,\n",
    "        'learning_rate': 0.01,#1e-3,\n",
    "        \n",
    "        'initializer': 'he_normal', #GlorotUniform\n",
    "        \n",
    "        'loss': 'binary_crossentropy',#'mae',\n",
    "        'optimizer': 'adam',        \n",
    "        \n",
    "        'beta_1': 10,\n",
    "        'beta_2': 50,\n",
    "        \n",
    "        'squeeze_factor': 1,\n",
    "        \n",
    "        'batch_size': 512,\n",
    "        'epochs': 2,#1_000,\n",
    "        'early_stopping_epochs': 50,\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'make_classification': {\n",
    "        'number_of_variables': 5,\n",
    "        'n_samples': 5_000,\n",
    "        'num_eval': 10,\n",
    "    },\n",
    "\n",
    "    'computation': {\n",
    "        'random_seed': 42,\n",
    "        'trials': 5,\n",
    "        'n_jobs': 50,\n",
    "        'verbosity': 0,\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ab8be2-1b4c-4370-a837-9176d15bea41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:39:44.172218Z",
     "iopub.status.busy": "2022-06-09T09:39:44.172078Z",
     "iopub.status.idle": "2022-06-09T09:39:49.278118Z",
     "shell.execute_reply": "2022-06-09T09:39:49.277547Z",
     "shell.execute_reply.started": "2022-06-09T09:39:44.172202Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = '' #'true'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from utilities.utilities import *\n",
    "from utilities.DHDT import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2397843-32d2-4579-b197-0686f4a99b54",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e7da9-12bb-467f-919f-4fd510ce6463",
   "metadata": {},
   "source": [
    "## make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e8a1baf-79d0-4959-8376-fc6a5446a229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:39:49.279837Z",
     "iopub.status.busy": "2022-06-09T09:39:49.279637Z",
     "iopub.status.idle": "2022-06-09T09:39:49.290655Z",
     "shell.execute_reply": "2022-06-09T09:39:49.289961Z",
     "shell.execute_reply.started": "2022-06-09T09:39:49.279815Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    metrics = ['accuracy', 'f1']\n",
    "    \n",
    "    config_test = deepcopy(config)\n",
    "    config_test['make_classification']['n_samples'] = 10_000\n",
    "    config_test['dhdt']['epochs'] = 100\n",
    "\n",
    "    dataset_dict = {}\n",
    "    model_dict = {}\n",
    "\n",
    "    scores_dict = {'sklearn': {},\n",
    "                   'DHDT': {}}\n",
    "\n",
    "    dataset_dict = get_preprocessed_dataset('make_classification',\n",
    "                                            random_seed=config_test['computation']['random_seed'],\n",
    "                                            config=config_test['make_classification'],\n",
    "                                            verbosity=1)\n",
    "\n",
    "    model_dict['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                                   random_state=config_test['computation']['random_seed'])\n",
    "\n",
    "    model_dict['sklearn'].fit(dataset_dict['X_train'], \n",
    "                              dataset_dict['y_train'])\n",
    "\n",
    "\n",
    "\n",
    "    model_dict['DHDT'] = DHDT(dataset_dict['X_train'].shape[1],\n",
    "\n",
    "                                depth = config_test['dhdt']['depth'],\n",
    "\n",
    "                                learning_rate = config_test['dhdt']['learning_rate'],\n",
    "                                optimizer = config_test['dhdt']['optimizer'],\n",
    "\n",
    "                                beta_1 = config_test['dhdt']['beta_1'],\n",
    "                                beta_2 = config_test['dhdt']['beta_2'],\n",
    "\n",
    "                                squeeze_factor = config_test['dhdt']['squeeze_factor'],\n",
    "\n",
    "                                loss = config_test['dhdt']['loss'],#'mae',\n",
    "\n",
    "                                random_seed = config_test['computation']['random_seed'],\n",
    "                                verbosity = 2)        \n",
    "\n",
    "\n",
    "    scores_dict['history'] = model_dict['DHDT'].fit(dataset_dict['X_train'], \n",
    "                                                  dataset_dict['y_train'], \n",
    "                                                  batch_size=config_test['dhdt']['batch_size'], \n",
    "                                                  epochs=config_test['dhdt']['epochs'], \n",
    "                                                  early_stopping_epochs=config_test['dhdt']['early_stopping_epochs'], \n",
    "                                                  valid_data=(dataset_dict['X_valid'], dataset_dict['y_valid']))\n",
    "\n",
    "\n",
    "\n",
    "    dataset_dict['y_test_dhdt'] = model_dict['DHDT'].predict(dataset_dict['X_test'])\n",
    "    dataset_dict['y_valid_dhdt'] = model_dict['DHDT'].predict(dataset_dict['X_valid'])\n",
    "\n",
    "    dataset_dict['y_test_sklearn'] = model_dict['sklearn'].predict(dataset_dict['X_test'])\n",
    "    dataset_dict['y_valid_sklearn'] = model_dict['sklearn'].predict(dataset_dict['X_valid'])     \n",
    "    \n",
    "    for metric in metrics:\n",
    "        \n",
    "        if metric in ['accuracy', 'f1']:\n",
    "            y_test_dhdt = np.round(dataset_dict['y_test_dhdt'])\n",
    "            y_valid_dhdt = np.round(dataset_dict['y_valid_dhdt'])\n",
    "            y_test_sklearn = np.round(dataset_dict['y_test_sklearn'])\n",
    "            y_valid_sklearn = np.round(dataset_dict['y_valid_sklearn'])         \n",
    "        else:\n",
    "            y_test_dhdt = dataset_dict['y_test_dhdt']\n",
    "            y_valid_dhdt = dataset_dict['y_valid_dhdt']\n",
    "            y_test_sklearn = dataset_dict['y_test_sklearn']\n",
    "            y_valid_sklearn =    dataset_dict['y_valid_sklearn']                \n",
    "        \n",
    "        scores_dict['sklearn'][metric + '_test'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_test'], y_test_sklearn)\n",
    "        scores_dict['DHDT'][metric + '_test'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_test'], y_test_dhdt)\n",
    "\n",
    "        scores_dict['sklearn'][metric + '_valid'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_valid'], y_valid_sklearn)   \n",
    "        scores_dict['DHDT'][metric + '_valid'] = sklearn.metrics.get_scorer(metric)._score_func(dataset_dict['y_valid'], y_valid_dhdt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a13b2a-ca9d-44de-9a52-b8ca61808093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:39:49.291489Z",
     "iopub.status.busy": "2022-06-09T09:39:49.291362Z",
     "iopub.status.idle": "2022-06-09T09:39:49.342586Z",
     "shell.execute_reply": "2022-06-09T09:39:49.342237Z",
     "shell.execute_reply.started": "2022-06-09T09:39:49.291473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    parallel_eval_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_synthetic = parallel_eval_synthetic(delayed(evaluate_synthetic_parallel)(index = index,\n",
    "                                                                                                random_seed_data = config['computation']['random_seed']+index,\n",
    "                                                                                                random_seed_model = config['computation']['random_seed'],#+random_seed_model,\n",
    "                                                                                                config = config,\n",
    "                                                                                                verbosity = -1) for index in range(config['make_classification']['num_eval']))\n",
    "\n",
    "    for i, synthetic_result in enumerate(evaluation_results_synthetic):\n",
    "        if i == 0:\n",
    "            model_dict_synthetic = synthetic_result[0]\n",
    "            scores_dict_synthetic = synthetic_result[1]\n",
    "            dataset_dict_synthetic = synthetic_result[2]\n",
    "        else: \n",
    "            model_dict_synthetic = mergeDict(model_dict_synthetic, synthetic_result[0])\n",
    "            scores_dict_synthetic = mergeDict(scores_dict_synthetic, synthetic_result[1])\n",
    "            dataset_dict_synthetic = mergeDict(dataset_dict_synthetic, synthetic_result[2])    \n",
    "    \n",
    "    del synthetic_result, evaluation_results_synthetic\n",
    "    \n",
    "    \n",
    "    metric_identifer = '_test'\n",
    "    metrics = ['accuracy', 'f1']\n",
    "    index = [i for i in range(config['make_classification']['num_eval'])]\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "\n",
    "    results_DHDT = None\n",
    "    results_sklearn = None\n",
    "    for metric in metrics:\n",
    "        scores_DHDT = [scores_dict_synthetic[i]['DHDT'][metric + metric_identifer] for i in range(config['make_classification']['num_eval'])]\n",
    "\n",
    "        scores_sklearn = [scores_dict_synthetic[i]['sklearn'][metric + metric_identifer] for i in range(config['make_classification']['num_eval'])]\n",
    "\n",
    "        scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "        scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "        scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "        scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "        scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "        scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "\n",
    "        results_DHDT_by_metric = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "        results_sklearn_by_metric = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "        if results_DHDT is None and results_sklearn is None:\n",
    "            results_DHDT = results_DHDT_by_metric\n",
    "            results_sklearn = results_sklearn_by_metric\n",
    "        else:\n",
    "            results_DHDT = np.vstack([results_DHDT, results_DHDT_by_metric])\n",
    "            results_sklearn = np.vstack([results_sklearn, results_sklearn_by_metric])\n",
    "\n",
    "    scores_dataframe_synthetic = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)    \n",
    "    \n",
    "    del model_dict_synthetic, scores_dict_synthetic, dataset_dict_synthetic\n",
    "    \n",
    "    display(scores_dataframe_synthetic)\n",
    "    display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[1::3]])\n",
    "    display(scores_dataframe_synthetic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856c6c9-368b-4b75-b0d8-6e7a28e4267c",
   "metadata": {},
   "source": [
    "## Real-World Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb9eca0-b6be-4389-960f-857e68e6b197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:39:49.343374Z",
     "iopub.status.busy": "2022-06-09T09:39:49.343211Z",
     "iopub.status.idle": "2022-06-09T09:39:49.366569Z",
     "shell.execute_reply": "2022-06-09T09:39:49.365946Z",
     "shell.execute_reply.started": "2022-06-09T09:39:49.343357Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    identifier_list = [\n",
    "                        'Adult',#: 32,\n",
    "                        'Bank Marketing',#: 32,\n",
    "                        'Loan Credit',#: 32,\n",
    "\n",
    "                        'Credit Card',#: 23, \n",
    "                        'Car',#: 21,\n",
    "\n",
    "\n",
    "                        'Absenteeism',#: 15,\n",
    "                        'Loan House',#: 15,\n",
    "                        'Cervical Cancer',#: 15,\n",
    "\n",
    "                        'Heart Disease',#: 13,           \n",
    "\n",
    "                        'Titanic',#: 10,\n",
    "                        'Medical Insurance',#: 10,\n",
    "                        'Wisconsin Breast Cancer Original',#: 10,\n",
    "                        'Wisconsin Diagnostic Breast Cancer',#: 10,\n",
    "                        'Wisconsin Prognostic Breast Cancer',#: 10,\n",
    "                        'Abalone',#: 10,\n",
    "\n",
    "                        'Habermans Survival',#: 3, \n",
    "                      ]\n",
    "\n",
    "    parallel_eval_real_world = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_real_world = parallel_eval_real_world(delayed(evaluate_real_world_parallel)(identifier_list=identifier_list, \n",
    "                                                                                                   random_seed_model=config['computation']['random_seed']+i,\n",
    "                                                                                                   config = config,\n",
    "                                                                                                   verbosity = -1) for i in range(config['computation']['trials']))\n",
    "\n",
    "\n",
    "    for i, real_world_result in enumerate(evaluation_results_real_world):\n",
    "        if i == 0:\n",
    "            model_dict_real_world = real_world_result[0]\n",
    "            scores_dict_real_world = real_world_result[1]\n",
    "            dataset_dict_real_world = real_world_result[2]\n",
    "        else: \n",
    "            model_dict_real_world = mergeDict(model_dict_real_world, real_world_result[0])\n",
    "            scores_dict_real_world = mergeDict(scores_dict_real_world, real_world_result[1])\n",
    "            dataset_dict_real_world = mergeDict(dataset_dict_real_world, real_world_result[2])    \n",
    "\n",
    "    del real_world_result, evaluation_results_real_world\n",
    "\n",
    "    metric_identifer = '_test'\n",
    "    metrics = ['accuracy', 'f1']\n",
    "    index = identifier_list\n",
    "    columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "\n",
    "    results_DHDT = None\n",
    "    results_sklearn = None\n",
    "    for metric in metrics:\n",
    "        scores_DHDT = [scores_dict_real_world[identifier]['DHDT'][metric + metric_identifer] for identifier in identifier_list]\n",
    "\n",
    "        scores_sklearn = [scores_dict_real_world[identifier]['sklearn'][metric + metric_identifer] for identifier in identifier_list]    \n",
    "\n",
    "        scores_DHDT_mean = np.mean(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "        scores_sklearn_mean = np.mean(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "        scores_DHDT_max = np.max(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else scores_DHDT\n",
    "        scores_sklearn_max = np.max(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else scores_sklearn\n",
    "\n",
    "        scores_DHDT_std = np.std(scores_DHDT, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "        scores_sklearn_std = np.std(scores_sklearn, axis=1) if config['computation']['trials'] > 1 else np.array([0.0] * config['computation']['trials'])\n",
    "\n",
    "        results_DHDT_by_metric = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "        results_sklearn_by_metric = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "        if results_DHDT is None and results_sklearn is None:\n",
    "            results_DHDT = results_DHDT_by_metric\n",
    "            results_sklearn = results_sklearn_by_metric\n",
    "        else:\n",
    "            results_DHDT = np.vstack([results_DHDT, results_DHDT_by_metric])\n",
    "            results_sklearn = np.vstack([results_sklearn, results_sklearn_by_metric])\n",
    "\n",
    "    del model_dict_real_world, scores_dict_real_world, dataset_dict_real_world\n",
    "            \n",
    "    scores_dataframe_real_world = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "    display(scores_dataframe_real_world)\n",
    "    display(scores_dataframe_real_world[scores_dataframe_real_world.columns[1::3]])    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c55370-5fa9-4f3c-a1a8-be597467f808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:39:49.368254Z",
     "iopub.status.busy": "2022-06-09T09:39:49.367762Z",
     "iopub.status.idle": "2022-06-09T09:39:49.386319Z",
     "shell.execute_reply": "2022-06-09T09:39:49.385641Z",
     "shell.execute_reply.started": "2022-06-09T09:39:49.368204Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    identifier = identifier_list[0]#\"Absenteeism\"\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict_real_world[identifier]['DHDT'].plot(normalizer_list=dataset_dict_real_world[identifier]['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict_real_world[identifier]['sklearn'], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fbd88-44c9-4d7f-b58d-def1eeb6d434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84e73582-0f9e-4522-9a94-dc59f4e566e9",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09315b63-50a1-4b2c-bfa9-d7b6d961de34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:39:49.387597Z",
     "iopub.status.busy": "2022-06-09T09:39:49.387316Z",
     "iopub.status.idle": "2022-06-09T09:39:49.439255Z",
     "shell.execute_reply": "2022-06-09T09:39:49.438525Z",
     "shell.execute_reply.started": "2022-06-09T09:39:49.387566Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "        'depth': [3],\n",
    "        'learning_rate': [0.05, 0.01, 0.005, 0.001, 0.0005],#[0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "        \n",
    "        'loss': ['binary_crossentropy'],#['binary_crossentropy', 'rmse'],#'mae',\n",
    "        'optimizer': ['adam', 'sgd'],#['adam', 'sgd'],        \n",
    "        \n",
    "        'initializer': ['GlototUniform', 'GlorotNormal', 'he_uniform', 'he_normal', ' lecun_uniform', ' lecun_normal', 'RandomNormal', 'RandomUniform'], #RandomNormal, RandomUniform\n",
    "    \n",
    "        'beta_1': [10, 50],#[10, 50, 100],\n",
    "        'beta_2': [10, 50],#[10, 50, 100],\n",
    "        \n",
    "        'squeeze_factor': [0.2, 0.5, 1, 2, 5],#[0.2, 0.5, 1, 2, 5],    \n",
    "}\n",
    "\n",
    "parameter_dict = {\n",
    "        #'depth': [3],\n",
    "        #'learning_rate': [0.05, 0.01, 0.005, 0.001, 0.0005],#[0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "        \n",
    "        'loss': ['binary_crossentropy'],#['binary_crossentropy', 'rmse'],#'mae',\n",
    "        'optimizer': ['adam', 'sgd'],#['adam', 'sgd'],   \n",
    "    \n",
    "        #'initializer': ['GlototUniform', 'GlorotNormal', 'he_uniform', 'he_normal', ' lecun_uniform', ' lecun_normal', 'RandomNormal', 'RandomUniform'], #RandomNormal, RandomUniform\n",
    "        \n",
    "        #'beta_1': [10, 50],#[10, 50, 100],\n",
    "        #'beta_2': [10, 50],#[10, 50, 100],\n",
    "        \n",
    "        #'squeeze_factor': [0.2, 0.5, 1, 2, 5],#[0.2, 0.5, 1, 2, 5], \n",
    "    \n",
    "}\n",
    "\n",
    "parameter_grid = ParameterGrid(parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a0db87-7718-4ca7-a823-1409a835eacc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:39:49.440676Z",
     "iopub.status.busy": "2022-06-09T09:39:49.440304Z",
     "iopub.status.idle": "2022-06-09T09:57:50.387305Z",
     "shell.execute_reply": "2022-06-09T09:57:50.386689Z",
     "shell.execute_reply.started": "2022-06-09T09:39:49.440641Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=50)]: Using backend LokyBackend with 50 concurrent workers.\n",
      "[Parallel(n_jobs=50)]: Done   2 out of   2 | elapsed: 18.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=50)]: Done   2 out of   2 | elapsed: 18.0min finished\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a359bc97-ac1d-4a3a-af29-dc59cb574568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T10:06:30.667139Z",
     "iopub.status.busy": "2022-06-09T10:06:30.666063Z",
     "iopub.status.idle": "2022-06-09T10:06:30.694672Z",
     "shell.execute_reply": "2022-06-09T10:06:30.694222Z",
     "shell.execute_reply.started": "2022-06-09T10:06:30.666839Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHDT accuracy_mean</th>\n",
       "      <th>DHDT accuracy_max</th>\n",
       "      <th>DHDT accuracy_std</th>\n",
       "      <th>DHDT f1_mean</th>\n",
       "      <th>DHDT f1_max</th>\n",
       "      <th>DHDT f1_std</th>\n",
       "      <th>sklearn accuracy_mean</th>\n",
       "      <th>sklearn accuracy_max</th>\n",
       "      <th>sklearn accuracy_std</th>\n",
       "      <th>sklearn f1_mean</th>\n",
       "      <th>sklearn f1_max</th>\n",
       "      <th>sklearn f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4976</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.286038</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.322896</td>\n",
       "      <td>0.7548</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>0.727919</td>\n",
       "      <td>0.728889</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.138978</td>\n",
       "      <td>0.654105</td>\n",
       "      <td>0.257634</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.06640</td>\n",
       "      <td>0.914250</td>\n",
       "      <td>0.944915</td>\n",
       "      <td>0.061331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.529057</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.252811</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.00320</td>\n",
       "      <td>0.889521</td>\n",
       "      <td>0.893788</td>\n",
       "      <td>0.002133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5184</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.022464</td>\n",
       "      <td>0.151016</td>\n",
       "      <td>0.640219</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.04720</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.063636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.027868</td>\n",
       "      <td>0.146548</td>\n",
       "      <td>0.693717</td>\n",
       "      <td>0.273699</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.00320</td>\n",
       "      <td>0.748629</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.010301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5064</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>0.415259</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.295250</td>\n",
       "      <td>0.8352</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.00960</td>\n",
       "      <td>0.827607</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.005803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.028380</td>\n",
       "      <td>0.378397</td>\n",
       "      <td>0.633745</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>0.878619</td>\n",
       "      <td>0.903491</td>\n",
       "      <td>0.049744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4972</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.146624</td>\n",
       "      <td>0.661312</td>\n",
       "      <td>0.257657</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.06960</td>\n",
       "      <td>0.818141</td>\n",
       "      <td>0.925144</td>\n",
       "      <td>0.053501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.271410</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.329231</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.04160</td>\n",
       "      <td>0.847388</td>\n",
       "      <td>0.860082</td>\n",
       "      <td>0.025389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.038512</td>\n",
       "      <td>0.274309</td>\n",
       "      <td>0.632011</td>\n",
       "      <td>0.292651</td>\n",
       "      <td>0.7472</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.08640</td>\n",
       "      <td>0.772635</td>\n",
       "      <td>0.920319</td>\n",
       "      <td>0.073842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DHDT accuracy_mean  DHDT accuracy_max  DHDT accuracy_std  DHDT f1_mean  \\\n",
       "0              0.4976              0.520           0.017036      0.286038   \n",
       "1              0.5004              0.518           0.020915      0.138978   \n",
       "2              0.4900              0.500           0.005060      0.529057   \n",
       "3              0.5184              0.534           0.022464      0.151016   \n",
       "4              0.4896              0.532           0.027868      0.146548   \n",
       "5              0.5064              0.534           0.017772      0.415259   \n",
       "6              0.4824              0.534           0.028380      0.378397   \n",
       "7              0.4972              0.514           0.021858      0.146624   \n",
       "8              0.4944              0.510           0.013822      0.271410   \n",
       "9              0.4980              0.548           0.038512      0.274309   \n",
       "\n",
       "   DHDT f1_max  DHDT f1_std  sklearn accuracy_mean  sklearn accuracy_max  \\\n",
       "0     0.684211     0.322896                 0.7548                 0.756   \n",
       "1     0.654105     0.257634                 0.9148                 0.948   \n",
       "2     0.655914     0.252811                 0.8876                 0.894   \n",
       "3     0.640219     0.245067                 0.8236                 0.918   \n",
       "4     0.693717     0.273699                 0.7656                 0.772   \n",
       "5     0.657609     0.295250                 0.8352                 0.840   \n",
       "6     0.633745     0.308965                 0.8740                 0.906   \n",
       "7     0.661312     0.257657                 0.7828                 0.922   \n",
       "8     0.675497     0.329231                 0.8432                 0.864   \n",
       "9     0.632011     0.292651                 0.7472                 0.920   \n",
       "\n",
       "   sklearn accuracy_std  sklearn f1_mean  sklearn f1_max  sklearn f1_std  \n",
       "0               0.00098         0.727919        0.728889        0.000792  \n",
       "1               0.06640         0.914250        0.944915        0.061331  \n",
       "2               0.00320         0.889521        0.893788        0.002133  \n",
       "3               0.04720         0.781818        0.909091        0.063636  \n",
       "4               0.00320         0.748629        0.769231        0.010301  \n",
       "5               0.00960         0.827607        0.830508        0.005803  \n",
       "6               0.06400         0.878619        0.903491        0.049744  \n",
       "7               0.06960         0.818141        0.925144        0.053501  \n",
       "8               0.04160         0.847388        0.860082        0.025389  \n",
       "9               0.08640         0.772635        0.920319        0.073842  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results_hpo_synthetic[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "952be342-9751-474b-8780-f185b3f9c29d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:57:50.388375Z",
     "iopub.status.busy": "2022-06-09T09:57:50.388184Z",
     "iopub.status.idle": "2022-06-09T09:57:50.391984Z",
     "shell.execute_reply": "2022-06-09T09:57:50.391674Z",
     "shell.execute_reply.started": "2022-06-09T09:57:50.388355Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    parallel_hpo_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_hpo_synthetic = parallel_hpo_synthetic(delayed(evaluate_parameter_setting_synthetic)(parameter_setting, config, metrics= ['accuracy', 'f1']) for parameter_setting in parameter_grid)\n",
    "\n",
    "    comparator_metric = 'f1'\n",
    "\n",
    "    dhdt_mean_list = [np.mean(evaluation_results_hpo_synthetic[i][0]['DHDT ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "    dhdt_mean_list = sorted(dhdt_mean_list)\n",
    "\n",
    "    dhdt_max_mean_list = [np.mean(evaluation_results_hpo_synthetic[i][0]['DHDT ' + comparator_metric + '_max']) for i in range(len(parameter_grid))]\n",
    "    dhdt_max_mean_list = [x for _, x in sorted(zip(dhdt_mean_list, dhdt_max_mean_list))]\n",
    "\n",
    "    sklearn_mean_list = [np.mean(evaluation_results_hpo_synthetic[i][0]['sklearn ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "    sklearn_mean_list = [x for _, x in sorted(zip(dhdt_mean_list, sklearn_mean_list))]\n",
    "\n",
    "    parameter_setting_list = [evaluation_results_hpo_synthetic[i][1] for i in range(len(parameter_grid))]\n",
    "    parameter_setting_list = [x for _, x in sorted(zip(dhdt_mean_list, parameter_setting_list))]\n",
    "\n",
    "    hpo_results_synthetic = []\n",
    "    for i, (dhdt_mean, dhdt_max_mean, sklearn_mean, parameter_setting) in enumerate(zip(dhdt_mean_list, dhdt_max_mean_list, sklearn_mean_list, parameter_setting_list)):\n",
    "        result_dict = {\n",
    "                             'DHDT mean (mean)': dhdt_mean,\n",
    "                             'DHDT max (mean)': dhdt_max_mean,\n",
    "                             'sklearn mean': sklearn_mean,\n",
    "                             'parameters': parameter_setting\n",
    "                            }\n",
    "\n",
    "        hpo_results_synthetic.append(result_dict)\n",
    "\n",
    "    display(hpo_results_synthetic[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c54afb22-ae99-4f94-a17d-2f330717dd52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T10:06:35.666247Z",
     "iopub.status.busy": "2022-06-09T10:06:35.665907Z",
     "iopub.status.idle": "2022-06-09T10:07:36.937433Z",
     "shell.execute_reply": "2022-06-09T10:07:36.936943Z",
     "shell.execute_reply.started": "2022-06-09T10:06:35.666220Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=50)]: Using backend LokyBackend with 50 concurrent workers.\n",
      "[Parallel(n_jobs=50)]: Done   2 out of   2 | elapsed:  1.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=50)]: Done   2 out of   2 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "identifier_list = [\n",
    "                    'Adult',#: 32,\n",
    "                    'Bank Marketing',#: 32,\n",
    "                    'Loan Credit',#: 32,\n",
    "\n",
    "                    'Credit Card',#: 23, \n",
    "                    'Car',#: 21,\n",
    "\n",
    "\n",
    "                    'Absenteeism',#: 15,\n",
    "                    'Loan House',#: 15,\n",
    "                    'Cervical Cancer',#: 15,\n",
    "\n",
    "                    'Heart Disease',#: 13,           \n",
    "\n",
    "                    'Titanic',#: 10,\n",
    "                    'Medical Insurance',#: 10,\n",
    "                    'Wisconsin Breast Cancer Original',#: 10,\n",
    "                    'Wisconsin Diagnostic Breast Cancer',#: 10,\n",
    "                    'Wisconsin Prognostic Breast Cancer',#: 10,\n",
    "                    'Abalone',#: 10,\n",
    "\n",
    "                    'Habermans Survival',#: 3, \n",
    "                  ]\n",
    "\n",
    "identifier_list = ['Habermans Survival']\n",
    "\n",
    "sorted_evaluation_results_hpo_real_dict = {}\n",
    "\n",
    "for identifier in identifier_list:\n",
    "    parallel_hpo_real = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "    evaluation_results_hpo_real = parallel_hpo_real(delayed(evaluate_parameter_setting_real_world)(parameter_setting, identifier, config, metrics= ['accuracy', 'f1']) for parameter_setting in parameter_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af8512c-cb73-43ac-811a-d7d334db97ee",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-09T10:06:05.661309Z",
     "iopub.status.idle": "2022-06-09T10:06:05.661989Z",
     "shell.execute_reply": "2022-06-09T10:06:05.661873Z",
     "shell.execute_reply.started": "2022-06-09T10:06:05.661857Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    identifier_list = [\n",
    "                        'Adult',#: 32,\n",
    "                        'Bank Marketing',#: 32,\n",
    "                        'Loan Credit',#: 32,\n",
    "\n",
    "                        'Credit Card',#: 23, \n",
    "                        'Car',#: 21,\n",
    "\n",
    "\n",
    "                        'Absenteeism',#: 15,\n",
    "                        'Loan House',#: 15,\n",
    "                        'Cervical Cancer',#: 15,\n",
    "\n",
    "                        'Heart Disease',#: 13,           \n",
    "\n",
    "                        'Titanic',#: 10,\n",
    "                        'Medical Insurance',#: 10,\n",
    "                        'Wisconsin Breast Cancer Original',#: 10,\n",
    "                        'Wisconsin Diagnostic Breast Cancer',#: 10,\n",
    "                        'Wisconsin Prognostic Breast Cancer',#: 10,\n",
    "                        'Abalone',#: 10,\n",
    "\n",
    "                        'Habermans Survival',#: 3, \n",
    "                      ]\n",
    "    \n",
    "    identifier_list = ['Habermans Survival', 'Titanic']\n",
    "\n",
    "    hpo_results_real_world = {}\n",
    "\n",
    "    for identifier in identifier_list:\n",
    "        parallel_hpo_real = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "        evaluation_results_hpo_real = parallel_hpo_real(delayed(evaluate_parameter_setting_real_world)(parameter_setting, identifier, config, metrics= ['accuracy', 'f1']) for parameter_setting in parameter_grid)\n",
    "\n",
    "        comparator_metric = 'f1'\n",
    "\n",
    "        dhdt_mean_list = [np.mean(evaluation_results_hpo_real[i][0]['DHDT ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        dhdt_mean_list = sorted(dhdt_mean_list)\n",
    "\n",
    "        dhdt_max_mean_list = [np.mean(evaluation_results_hpo_real[i][0]['DHDT ' + comparator_metric + '_max']) for i in range(len(parameter_grid))]\n",
    "        dhdt_max_mean_list = [x for _, x in sorted(zip(dhdt_mean_list, dhdt_max_mean_list))]\n",
    "\n",
    "        sklearn_mean_list = [np.mean(evaluation_results_hpo_real[i][0]['sklearn ' + comparator_metric + '_mean']) for i in range(len(parameter_grid))]\n",
    "        sklearn_mean_list = [x for _, x in sorted(zip(dhdt_mean_list, sklearn_mean_list))]\n",
    "\n",
    "        parameter_setting_list = [evaluation_results_hpo_real[i][1] for i in range(len(parameter_grid))]\n",
    "        parameter_setting_list = [x for _, x in sorted(zip(dhdt_mean_list, parameter_setting_list))]\n",
    "\n",
    "        hpo_results_real_world_by_identifer = []\n",
    "        for i, (dhdt_mean, dhdt_max_mean, sklearn_mean, parameter_setting) in enumerate(zip(dhdt_mean_list, dhdt_max_mean_list, sklearn_mean_list, parameter_setting_list)):\n",
    "            result_dict = {\n",
    "                                 'DHDT mean (mean)': dhdt_mean,\n",
    "                                 'DHDT max (mean)': dhdt_max_mean,\n",
    "                                 'sklearn mean': sklearn_mean,\n",
    "                                 'parameters': parameter_setting\n",
    "                                }\n",
    "\n",
    "            hpo_results_real_world_by_identifer.append(result_dict)\n",
    "\n",
    "        hpo_results_real_world[identifier] = hpo_results_real_world_by_identifer\n",
    "\n",
    "        display(hpo_results_real_world_by_identifer[:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40147db1-760f-432d-ac2c-0267a8256f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358c9e7-58be-4006-b120-6b14f8364122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
