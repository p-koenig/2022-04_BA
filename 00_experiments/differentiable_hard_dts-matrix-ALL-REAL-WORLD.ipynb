{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c3b444-064b-4639-983d-238b3da68ad9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6531aaa-2c26-40f5-8078-d754aceda153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dhdt': {\n",
    "        'depth': 3,\n",
    "        'learning_rate': 1e-3,\n",
    "        \n",
    "        'loss': 'binary_crossentropy',#'mae',\n",
    "        'optimizer': 'adam',        \n",
    "        \n",
    "        'beta_1': 100,\n",
    "        'beta_2': 100,\n",
    "        \n",
    "        'squeeze_factor': 1,\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'make_classification': {\n",
    "        'number_of_variables': 5,\n",
    "        'n_samples': 10_000,\n",
    "    },\n",
    "\n",
    "    'computation': {\n",
    "        'random_seed': 42,\n",
    "        'num_eval': 10,\n",
    "        'trials': 5,\n",
    "        'n_jobs': 60,\n",
    "        'verbosity': 0,\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab8be2-1b4c-4370-a837-9176d15bea41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = '' #'true'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from utilities.utilities import *\n",
    "from utilities.DHDT import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2397843-32d2-4579-b197-0686f4a99b54",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e7da9-12bb-467f-919f-4fd510ce6463",
   "metadata": {},
   "source": [
    "## make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a13b2a-ca9d-44de-9a52-b8ca61808093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_seed_list = [i for i in range(config['computation']['trials'])]\n",
    "#data_seed_list = [i for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "#combined_seed_list = list(product(model_seed_list, data_seed_list))\n",
    "\n",
    "parallel_eval_synthetic = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_synthetic = parallel_eval_synthetic(delayed(evaluate_synthetic_parallel)(index = index,\n",
    "                                                                                            random_seed_data = config['computation']['random_seed']+index,\n",
    "                                                                                            random_seed_model = config['computation']['random_seed'],#+random_seed_model,\n",
    "                                                                                            trials = config['computation']['trials'],\n",
    "                                                                                            config = config['make_classification'],\n",
    "                                                                                            verbosity = -1) for index in range(config['computation']['num_eval']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe87d5f-06be-4f12-b65c-de1828a6f3b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, synthetic_result in enumerate(evaluation_results_synthetic):\n",
    "    if i == 0:\n",
    "        model_dict_synthetic = synthetic_result[0]\n",
    "        scores_dict_synthetic = synthetic_result[1]\n",
    "        dataset_dict_synthetic = synthetic_result[2]\n",
    "    else: \n",
    "        model_dict_synthetic = mergeDict(model_dict_synthetic, synthetic_result[0])\n",
    "        scores_dict_synthetic = mergeDict(scores_dict_synthetic, synthetic_result[1])\n",
    "        dataset_dict_synthetic = mergeDict(dataset_dict_synthetic, synthetic_result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2b804-f2e3-4ec9-9c06-1334d7449519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = ['accuracy']\n",
    "index = [i for i in range(config['computation']['num_eval'])]\n",
    "columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_max', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "scores_DHDT = [scores_dict_synthetic[i]['DHDT']['accuracy'] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "scores_sklearn = [scores_dict_synthetic[i]['sklearn']['accuracy'] for i in range(config['computation']['num_eval'])]\n",
    "\n",
    "\n",
    "scores_DHDT_mean = np.mean(scores_DHDT, axis=1)\n",
    "scores_sklearn_mean = np.mean(scores_sklearn, axis=1)\n",
    "                        \n",
    "scores_DHDT_max = np.max(scores_DHDT, axis=1)\n",
    "scores_sklearn_max = np.max(scores_sklearn, axis=1)\n",
    "                        \n",
    "scores_DHDT_std = np.std(scores_DHDT, axis=1)\n",
    "scores_sklearn_std = np.std(scores_sklearn, axis=1)\n",
    "\n",
    "results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "\n",
    "scores_dataframe_synthetic = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "display(scores_dataframe_synthetic)\n",
    "display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[1::3]])\n",
    "display(scores_dataframe_synthetic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856c6c9-368b-4b75-b0d8-6e7a28e4267c",
   "metadata": {},
   "source": [
    "## Real-World Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9eca0-b6be-4389-960f-857e68e6b197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = [\n",
    "                    'Adult',#: 32,\n",
    "                    'Bank Marketing',#: 32,\n",
    "                    'Loan Credit',#: 32,\n",
    "\n",
    "                    'Credit Card',#: 23, \n",
    "                    'Car',#: 21,\n",
    "\n",
    "\n",
    "                    'Absenteeism',#: 15,\n",
    "                    'Loan House',#: 15,\n",
    "                    'Cervical Cancer',#: 15,\n",
    "\n",
    "                    'Heart Disease',#: 13,           \n",
    "\n",
    "                    'Titanic',#: 10,\n",
    "                    'Medical Insurance',#: 10,\n",
    "                    'Brest Cancer Wisconsin',#: 10,\n",
    "                    'Wisconsin Diagnostic Breast Cancer',#: 10,\n",
    "                    'Wisconsin Prognostic Breast Cancer',#: 10,\n",
    "                    'Abalone',#: 10,\n",
    "\n",
    "                    'Haberman',#: 3, \n",
    "                  ]\n",
    "\n",
    "parallel_eval_real_world = Parallel(n_jobs=config['computation']['n_jobs'], verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_real_world = parallel_eval_real_world(delayed(evaluate_real_world_parallel)(identifier_list=identifier_list, \n",
    "                                                                                               random_seed_model=config['computation']['random_seed']+i,\n",
    "                                                                                               verbosity = -1) for i in range(config['computation']['trials']))\n",
    "\n",
    "\n",
    "for i, real_world_result in enumerate(evaluation_results_real_world):\n",
    "    if i == 0:\n",
    "        model_dict_real_world = real_world_result[0]\n",
    "        scores_dict_real_world = real_world_result[1]\n",
    "        dataset_dict_real_world = real_world_result[2]\n",
    "    else: \n",
    "        model_dict_real_world = mergeDict(model_dict_real_world, real_world_result[0])\n",
    "        scores_dict_real_world = mergeDict(scores_dict_real_world, real_world_result[1])\n",
    "        dataset_dict_real_world = mergeDict(dataset_dict_real_world, real_world_result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c55370-5fa9-4f3c-a1a8-be597467f808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = ['accuracy']\n",
    "index = identifier_list\n",
    "columns = flatten_list([[[approach + ' ' + metric + '_mean', approach + ' ' + metric + '_std'] for metric in metrics] for approach in ['DHDT', 'sklearn']])\n",
    "\n",
    "scores_DHDT = [scores_dict_real_world[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict_real_world[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "\n",
    "scores_DHDT_mean = np.mean(scores_DHDT, axis=1)\n",
    "scores_sklearn_mean = np.mean(scores_sklearn, axis=1)\n",
    "\n",
    "scores_DHDT_max = np.max(scores_DHDT, axis=1)\n",
    "scores_sklearn_max = np.max(scores_sklearn, axis=1)\n",
    "\n",
    "scores_DHDT_std = np.std(scores_DHDT, axis=1)\n",
    "scores_sklearn_std = np.std(scores_sklearn, axis=1)\n",
    "\n",
    "results_DHDT = np.vstack([scores_DHDT_mean, scores_DHDT_max, scores_DHDT_std])\n",
    "results_sklearn = np.vstack([scores_sklearn_mean, scores_sklearn_max, scores_sklearn_std])\n",
    "\n",
    "\n",
    "scores_dataframe_real_world = pd.DataFrame(data=np.vstack([results_DHDT, results_sklearn]).T, index = index, columns = columns)\n",
    "display(scores_dataframe_synthetic)\n",
    "display(scores_dataframe_synthetic[scores_dataframe_synthetic.columns[1::3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fbd88-44c9-4d7f-b58d-def1eeb6d434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad156c9c-8aed-4169-87e9-3e9741f64230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb85a81-881b-47be-96d8-6c6d0578b810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_dict_real_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d69a94-8df3-4133-9e78-239bf0fcec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict_real_world[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict_real_world[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c3f97-e5ab-4b06-9a17-1c23448800fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(scores_DHDT, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec52977-11ff-467a-82e5-89856a10293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict_real_world[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict_real_world[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d00d23-cea4-4946-9495-93a9578c7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73bba7-c127-4e07-939e-72a1417d27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09315b63-50a1-4b2c-bfa9-d7b6d961de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "        'depth': 3,\n",
    "        'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "        \n",
    "        'loss': ['binary_crossentropy', 'rmse'],#'mae',\n",
    "        'optimizer': ['adam', 'sgd'],        \n",
    "        \n",
    "        'beta_1': [10, 50, 100],\n",
    "        'beta_2': [10, 50, 100],\n",
    "        \n",
    "        'squeeze_factor': [0.2, 0.5, 1, 2, 5],    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e9145-2b47-467f-96df-d3bb0f83226a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_DHDT_make_class = [scores_dict_make_class[identifier]['DHDT']['accuracy'] for identifier in range(num_make_class_eval)]\n",
    "\n",
    "scores_sklearn_make_class = [scores_dict_make_class[identifier]['sklearn']['accuracy'] for identifier in range(num_make_class_eval)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db42a3-560d-4f55-b2d3-ee52da3cb7f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## real-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ca2d2-73a1-4675-8d6e-4f75d096fb4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05f2f8-19b1-4800-b9ae-85c0599f0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "--> put eval in function \n",
    "    --> make parallel execution with different seeds / splits, etcs \n",
    "        --> compare (save all values and generate mean+std df, but keep all values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafb753-2e3d-4480-9998-659ff6034a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['n_samples'] = 10_000\n",
    "config['number_of_variables'] = 5\n",
    "random_seed = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab170fa2-c32f-402e-8b60-38b542ae3840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_jobs = 20\n",
    "\n",
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "parallel_real_world_eval = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_by_dataset = parallel_real_world_eval(delayed(evaluate_dhdt)(identifier) for identifier in identifier_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c7b89-7752-49a8-9424-306b2d1d172d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "trials = 20\n",
    "n_jobs = 20\n",
    "random_seed = 42\n",
    "\n",
    "parallel_real_world_eval = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_by_dataset = parallel_real_world_eval(delayed(evaluate_all_parallel)(identifier_list=identifier_list, \n",
    "                                                                               random_seed=random_seed+i) for i in range(trials))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3fdc5-9ae2-47ba-b4db-b2ef5988d1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf508df-fa1a-4c9a-9495-4adfac6c8478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = [\n",
    "                   'Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   #'Absenteeism'\n",
    "                  ]\n",
    "\n",
    "evaluate_all_real_world(identifier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142651c4-44b3-4598-acc2-d71f8980849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_real_world(identifier_list):\n",
    "    \n",
    "    identifier_list = ['Cervical Cancer',\n",
    "                       'Credit Card',\n",
    "                       'Absenteeism']\n",
    "\n",
    "    dataset_dict = {}\n",
    "    model_dict = {}\n",
    "\n",
    "    scores_dict = {}\n",
    "\n",
    "    for identifier in tqdm(identifier_list, desc='dataset loop'):\n",
    "\n",
    "        print('_________________________________________________________________________________________________________________')   \n",
    "\n",
    "        dataset_dict[identifier] = {}\n",
    "        model_dict[identifier] = {}\n",
    "\n",
    "        scores_dict[identifier] = {'sklearn': {},\n",
    "                                   'DHDT': {}}\n",
    "\n",
    "        dataset_dict[identifier] = get_preprocessed_dataset(identifier)    \n",
    "\n",
    "        model_dict[identifier]['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                                                   random_state=42)\n",
    "\n",
    "        model_dict[identifier]['sklearn'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                              dataset_dict[identifier]['y_train'])\n",
    "\n",
    "        scores_dict[identifier]['sklearn']['accuracy'] = model_dict[identifier]['sklearn'].score(dataset_dict[identifier]['X_test'], \n",
    "                                                                                                 dataset_dict[identifier]['y_test'])\n",
    "\n",
    "\n",
    "\n",
    "        model_dict[identifier]['DHDT'] = DHDT(depth=3,\n",
    "                                                 number_of_variables = dataset_dict[identifier]['X_train'].shape[1],\n",
    "                                                 learning_rate=1e-3,\n",
    "                                                 squeeze_factor = 1,\n",
    "                                                 loss='binary_crossentropy',#'binary_crossentropy',\n",
    "                                                 optimizer='rmsprop',\n",
    "                                                 random_seed=40,\n",
    "                                                 verbosity=0)\n",
    "\n",
    "        scores_dict[identifier]['history'] = model_dict[identifier]['DHDT'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                                                              dataset_dict[identifier]['y_train'], \n",
    "                                                                              batch_size=512, \n",
    "                                                                              epochs=1_000, \n",
    "                                                                              early_stopping_epochs=50, \n",
    "                                                                              valid_data=(dataset_dict[identifier]['X_valid'], dataset_dict[identifier]['y_valid']))\n",
    "\n",
    "        dataset_dict[identifier]['y_test_dhdt'] = model_dict[identifier]['DHDT'].predict(dataset_dict[identifier]['X_test'])\n",
    "        scores_dict[identifier]['DHDT']['accuracy'] = accuracy_score(dataset_dict[identifier]['y_test'], np.round(dataset_dict[identifier]['y_test_dhdt']))\n",
    "\n",
    "        print('Test Accuracy Sklearn (' + identifier + ')', scores_dict[identifier]['sklearn']['accuracy'])\n",
    "        print('Test Accuracy DHDT (' + identifier + ')', scores_dict[identifier]['DHDT']['accuracy'])   \n",
    "        print('_________________________________________________________________________________________________________________')   \n",
    "\n",
    "    return   model_dict, scores_dict, dataset_dit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773d8d6-ba4e-42b5-b981-2edd4a323fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list = ['Cervical Cancer',\n",
    "                   'Credit Card',\n",
    "                   'Absenteeism']\n",
    "\n",
    "dataset_dict = {}\n",
    "model_dict = {}\n",
    "\n",
    "scores_dict = {}\n",
    "\n",
    "for identifier in tqdm(identifier_list, desc='dataset loop'):\n",
    "    \n",
    "    print('_________________________________________________________________________________________________________________')   \n",
    "    \n",
    "    dataset_dict[identifier] = {}\n",
    "    model_dict[identifier] = {}\n",
    "\n",
    "    scores_dict[identifier] = {'sklearn': {},\n",
    "                               'DHDT': {}}\n",
    "    \n",
    "    dataset_dict[identifier] = get_preprocessed_dataset(identifier)    \n",
    "\n",
    "    model_dict[identifier]['sklearn'] = DecisionTreeClassifier(max_depth=3, \n",
    "                                                               random_state=42)\n",
    "\n",
    "    model_dict[identifier]['sklearn'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                          dataset_dict[identifier]['y_train'])\n",
    "\n",
    "    scores_dict[identifier]['sklearn']['accuracy'] = model_dict[identifier]['sklearn'].score(dataset_dict[identifier]['X_test'], \n",
    "                                                                                             dataset_dict[identifier]['y_test'])\n",
    "\n",
    "\n",
    "\n",
    "    model_dict[identifier]['DHDT'] = DHDT(depth=3,\n",
    "                                             number_of_variables = dataset_dict[identifier]['X_train'].shape[1],\n",
    "                                             learning_rate=1e-3,\n",
    "                                             squeeze_factor = 1,\n",
    "                                             loss='binary_crossentropy',#'binary_crossentropy',\n",
    "                                             optimizer='rmsprop',\n",
    "                                             random_seed=40,\n",
    "                                             verbosity=0)\n",
    "\n",
    "    scores_dict[identifier]['history'] = model_dict[identifier]['DHDT'].fit(dataset_dict[identifier]['X_train'], \n",
    "                                                                          dataset_dict[identifier]['y_train'], \n",
    "                                                                          batch_size=512, \n",
    "                                                                          epochs=1_000, \n",
    "                                                                          early_stopping_epochs=50, \n",
    "                                                                          valid_data=(dataset_dict[identifier]['X_valid'], dataset_dict[identifier]['y_valid']))\n",
    "\n",
    "    dataset_dict[identifier]['y_test_dhdt'] = model_dict[identifier]['DHDT'].predict(dataset_dict[identifier]['X_test'])\n",
    "    scores_dict[identifier]['DHDT']['accuracy'] = accuracy_score(dataset_dict[identifier]['y_test'], np.round(dataset_dict[identifier]['y_test_dhdt']))\n",
    "    \n",
    "    print('Test Accuracy Sklearn (' + identifier + ')', scores_dict[identifier]['sklearn']['accuracy'])\n",
    "    print('Test Accuracy DHDT (' + identifier + ')', scores_dict[identifier]['DHDT']['accuracy'])   \n",
    "    print('_________________________________________________________________________________________________________________')   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901c3fe-2a4d-4efa-9864-a2e488ce9292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_DHDT = [scores_dict[identifier]['DHDT']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_sklearn = [scores_dict[identifier]['sklearn']['accuracy'] for identifier in identifier_list]\n",
    "\n",
    "scores_dataframe = pd.DataFrame(data=np.vstack([scores_DHDT, scores_sklearn]).T, index = identifier_list, columns = ['DHDT', 'sklearn'])\n",
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d34810-8e9f-418d-a2aa-caf80458179a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = \"Absenteeism\"\n",
    "plt.figure(figsize=(15,8))\n",
    "image = model_dict[identifier]['DHDT'].plot(normalizer_list=dataset_dict['normalizer_list'][identifier])\n",
    "display(image)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plot_tree(model_dict[identifier]['sklearn'], fontsize=10) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a512e12-0fc0-4e43-912a-d01d2b28c7c8",
   "metadata": {},
   "source": [
    "## Absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32042bc9-1008-4311-8d2d-7896db8a3a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc04fcc-841d-4cdb-84ed-8e241db6ba63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
