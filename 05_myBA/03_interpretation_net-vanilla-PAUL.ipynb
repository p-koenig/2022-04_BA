{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Specification of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnpassen: \\n\\nnumber_of_variables --> anzahl variablen\\n\\nlambda_dataset_size --> datensatz größe für training von lambda-nets\\nnumber_of_generated_datasets and  number_of_trained_lambda_nets and interpretation_dataset_size --> anzahl der lambda-nets\\n\\nlambda net --> alles wie in notebook 2\\n\\ni net -->\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Anpassen: \n",
    "\n",
    "number_of_variables --> anzahl variablen\n",
    "\n",
    "lambda_dataset_size --> datensatz größe für training von lambda-nets\n",
    "number_of_generated_datasets and  number_of_trained_lambda_nets and interpretation_dataset_size --> anzahl der lambda-nets\n",
    "\n",
    "lambda net --> alles wie in notebook 2\n",
    "\n",
    "i net -->\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 3,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'vanilla', #'SDT', 'vanilla'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 20, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [],\n",
    "        \n",
    "        'use_distribution_list': True,\n",
    "        'random_parameters_distribution': True, ##MAKEPATH DIFFERENT FILES\n",
    "        'max_distributions_per_class': 1, # None; 0; int >= 1  \n",
    "        'exclude_linearly_seperable': False,\n",
    "        'data_generation_filtering': False,\n",
    "        'fixed_class_probability': False,\n",
    "        'balanced_data': True,\n",
    "        'weighted_data_generation': False,\n",
    "        'shift_distrib': False,\n",
    "        \n",
    "        'dt_type_train': 'vanilla', # (None, 'vanilla', 'SDT')\n",
    "        'maximum_depth_train': 3, #None or int\n",
    "        'decision_sparsity_train': 1, #None or int\n",
    "        \n",
    "        'function_generation_type': 'make_classification',# 'make_classification_distribution', 'make_classification_distribution_trained', 'distribution', 'distribution_trained', 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'distrib_by_feature': True,\n",
    "        'distribution_list': ['uniform', 'normal', 'gamma', 'beta', 'poisson'],#['uniform', 'gamma', 'poisson', 'exponential', 'weibull'],#['uniform', 'normal', 'gamma', 'exponential', 'beta', 'binomial', 'poisson'], \n",
    "        'distribution_list_eval': ['uniform', 'normal', 'gamma', 'beta', 'poisson'],#['uniform', 'gamma', 'poisson', 'exponential', 'weibull'],#['uniform', 'normal', 'gamma', 'beta', 'poisson'],\n",
    "        \n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        'number_of_generated_datasets': 10_000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "        \n",
    "        'data_noise': 0, #None or float\n",
    "        \n",
    "        'distrib_param_max': 5,\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-3,\n",
    "        'restore_best_weights': True,\n",
    "        'patience_lambda': 50,\n",
    "        \n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'use_batchnorm_lambda': False,\n",
    "        \n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 100,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        #'dense_layers': [1024, 1024, 256, 2048, 2048],\n",
    "        'dense_layers': [1792, 512, 512],\n",
    "        #'dense_layers': [1792, 512, 512],\n",
    "        \n",
    "        #'dropout': [0, 0, 0, 0, 0.3],#[0.3, 0.3, 0.3, 0.3, 0.3],\n",
    "        'dropout': [0, 0, 0.5],\n",
    "        #'dropout': [0, 0, 0.5],\n",
    "\n",
    "        #'hidden_activation': 'relu',\n",
    "        'hidden_activation': 'sigmoid',\n",
    "        #'hidden_activation': 'swish',\n",
    "\n",
    "        #'optimizer': 'rmsprop', \n",
    "        'optimizer': 'adam', \n",
    "        #'optimizer': 'adam', \n",
    "        \n",
    "        #'learning_rate': 0.001,\n",
    "        'learning_rate': 0.001,\n",
    "        #'learning_rate': 0.001, \n",
    "        \n",
    "        'separate_weight_bias': False,\n",
    "        \n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,        \n",
    "        'additional_hidden': False,\n",
    "        \n",
    "        'loss': 'binary_crossentropy', #mse; binary_crossentropy; 'binary_accuracy'\n",
    "        'metrics': ['binary_accuracy'], #soft_ or _penalized\n",
    "        \n",
    "        'epochs': 500, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 100,\n",
    "                \n",
    "        'test_size': 5, #Float for fraction, Int for number 0\n",
    "        'evaluate_distribution': True,\n",
    "        'force_evaluate_real_world': False,\n",
    "        \n",
    "        'function_representation_type': 5, # 1=standard representation; 2=sparse representation with classification for variables; 3=softmax to select classes (n top probabilities)\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2,3) #3=autoencoder dimensionality reduction\n",
    "        \n",
    "        'resampling_strategy': None,#'ADASYN', #'SMOTE', None\n",
    "        'resampling_threshold': 0.25,#0.2,\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 60,\n",
    "        'nas_optimizer': 'greedy' #'hyperband',#\"bayesian\",'greedy', 'random'\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "        \n",
    "        'number_of_random_evaluations_per_distribution': 1000,\n",
    "        'random_evaluation_dataset_size_per_distribution': 10_000, \n",
    "        'optimize_sampling': True,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'random_evaluation_dataset_distribution': 'uniform', \n",
    "        \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        #'sklearn_dt_benchmark': False,\n",
    "        #'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': False,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 15,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 42,   \n",
    "        'verbosity': 0\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(config)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth)  if function_representation_type >= 3 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes if function_representation_type >= 3 and dt_type == 'SDT'\n",
    "  else None\n",
    "                                                            )\n",
    "\n",
    "\n",
    "if distrib_by_feature:\n",
    "    config['evaluation']['random_evaluation_dataset_distribution'] = config['data']['distribution_list_eval']\n",
    "    config['data']['distribution_list'] = [config['data']['distribution_list']]\n",
    "    config['data']['distribution_list_eval'] = [config['data']['distribution_list_eval']]\n",
    "  \n",
    "    \n",
    "\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets100_var20_class2_make_classification_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_noBalance_noBalance/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1792-512-512_drop0-0-0.5e500b256_adam_funcRep5_reshapeNone\n",
      "lNetSize5000_numLNets100_var20_class2_make_classification_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_noBalance_noBalance/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['data']['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    \n",
    "    \n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'\n",
    "    \n",
    "    if True:\n",
    "        path_X_data = './data/saved_function_lists/X_data_' + path_dict['path_identifier_function_data'] + '.pkl'\n",
    "        with open(path_X_data, 'rb') as f:\n",
    "            X_data_list = pickle.load(f)\n",
    "\n",
    "        path_y_data = './data/saved_function_lists/y_data_' + path_dict['path_identifier_function_data'] + '.pkl'\n",
    "        with open(path_y_data, 'rb') as f:\n",
    "            y_data_list = pickle.load(f)        \n",
    "            \n",
    "    path_distribution_parameters = directory + '/' + 'distribution_parameters' + '.txt'\n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    \n",
    "    try:\n",
    "        distribution_parameters = pd.read_csv(path_distribution_parameters, sep=\",\", header=None)\n",
    "        distribution_parameters = distribution_parameters.sort_values(by=0)\n",
    "    except:\n",
    "        distribution_parameters = pd.DataFrame([None] * network_parameters.shape[0])\n",
    "    \n",
    "    #if no_noise == False:\n",
    "    #    network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    #    distribution_parameters = distribution_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              distribution_parameters_row,\n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              X_test_network[1].values,\n",
    "                                              y_test_network[1].values,\n",
    "                                              config) for X_test_network, y_test_network, network_parameters_row, distribution_parameters_row in zip(X_data_list[:config['i_net']['interpretation_dataset_size']], \n",
    "                                                                                                                                                     y_data_list[:config['i_net']['interpretation_dataset_size']], \n",
    "                                                                                                                                                     network_parameters.values[:config['i_net']['interpretation_dataset_size']], \n",
    "                                                                                                                                                     distribution_parameters.values[:config['i_net']['interpretation_dataset_size']]))        \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=15)]: Done 100 out of 100 | elapsed:    8.5s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "\n",
    "    lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "    lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "    if test_size > 0 and not evaluate_distribution:\n",
    "        lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "    else:\n",
    "        lambda_net_dataset_test = None\n",
    "        lambda_net_dataset_valid = lambda_net_dataset_eval\n",
    "        \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    if test_size > 0 and not evaluate_distribution:\n",
    "        lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    \n",
    "    else:\n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset, test_split=0.1)    \n",
    "        lambda_net_dataset_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "### Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 2841)\n",
      "(10, 2841)\n"
     ]
    }
   ],
   "source": [
    "print(lambda_net_dataset_train.shape)\n",
    "print(lambda_net_dataset_valid.shape)\n",
    "if test_size > 0 and not evaluate_distribution:\n",
    "    print(lambda_net_dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>split0</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>split6</th>\n",
       "      <th>lp0</th>\n",
       "      <th>lp1</th>\n",
       "      <th>lp2</th>\n",
       "      <th>lp3</th>\n",
       "      <th>lp4</th>\n",
       "      <th>lp5</th>\n",
       "      <th>lp6</th>\n",
       "      <th>lp7</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "      <th>wb_61</th>\n",
       "      <th>wb_62</th>\n",
       "      <th>wb_63</th>\n",
       "      <th>wb_64</th>\n",
       "      <th>wb_65</th>\n",
       "      <th>wb_66</th>\n",
       "      <th>wb_67</th>\n",
       "      <th>wb_68</th>\n",
       "      <th>wb_69</th>\n",
       "      <th>wb_70</th>\n",
       "      <th>wb_71</th>\n",
       "      <th>wb_72</th>\n",
       "      <th>wb_73</th>\n",
       "      <th>wb_74</th>\n",
       "      <th>wb_75</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_2717</th>\n",
       "      <th>wb_2718</th>\n",
       "      <th>wb_2719</th>\n",
       "      <th>wb_2720</th>\n",
       "      <th>wb_2721</th>\n",
       "      <th>wb_2722</th>\n",
       "      <th>wb_2723</th>\n",
       "      <th>wb_2724</th>\n",
       "      <th>wb_2725</th>\n",
       "      <th>wb_2726</th>\n",
       "      <th>wb_2727</th>\n",
       "      <th>wb_2728</th>\n",
       "      <th>wb_2729</th>\n",
       "      <th>wb_2730</th>\n",
       "      <th>wb_2731</th>\n",
       "      <th>wb_2732</th>\n",
       "      <th>wb_2733</th>\n",
       "      <th>wb_2734</th>\n",
       "      <th>wb_2735</th>\n",
       "      <th>wb_2736</th>\n",
       "      <th>wb_2737</th>\n",
       "      <th>wb_2738</th>\n",
       "      <th>wb_2739</th>\n",
       "      <th>wb_2740</th>\n",
       "      <th>wb_2741</th>\n",
       "      <th>wb_2742</th>\n",
       "      <th>wb_2743</th>\n",
       "      <th>wb_2744</th>\n",
       "      <th>wb_2745</th>\n",
       "      <th>wb_2746</th>\n",
       "      <th>wb_2747</th>\n",
       "      <th>wb_2748</th>\n",
       "      <th>wb_2749</th>\n",
       "      <th>wb_2750</th>\n",
       "      <th>wb_2751</th>\n",
       "      <th>wb_2752</th>\n",
       "      <th>wb_2753</th>\n",
       "      <th>wb_2754</th>\n",
       "      <th>wb_2755</th>\n",
       "      <th>wb_2756</th>\n",
       "      <th>wb_2757</th>\n",
       "      <th>wb_2758</th>\n",
       "      <th>wb_2759</th>\n",
       "      <th>wb_2760</th>\n",
       "      <th>wb_2761</th>\n",
       "      <th>wb_2762</th>\n",
       "      <th>wb_2763</th>\n",
       "      <th>wb_2764</th>\n",
       "      <th>wb_2765</th>\n",
       "      <th>wb_2766</th>\n",
       "      <th>wb_2767</th>\n",
       "      <th>wb_2768</th>\n",
       "      <th>wb_2769</th>\n",
       "      <th>wb_2770</th>\n",
       "      <th>wb_2771</th>\n",
       "      <th>wb_2772</th>\n",
       "      <th>wb_2773</th>\n",
       "      <th>wb_2774</th>\n",
       "      <th>wb_2775</th>\n",
       "      <th>wb_2776</th>\n",
       "      <th>wb_2777</th>\n",
       "      <th>wb_2778</th>\n",
       "      <th>wb_2779</th>\n",
       "      <th>wb_2780</th>\n",
       "      <th>wb_2781</th>\n",
       "      <th>wb_2782</th>\n",
       "      <th>wb_2783</th>\n",
       "      <th>wb_2784</th>\n",
       "      <th>wb_2785</th>\n",
       "      <th>wb_2786</th>\n",
       "      <th>wb_2787</th>\n",
       "      <th>wb_2788</th>\n",
       "      <th>wb_2789</th>\n",
       "      <th>wb_2790</th>\n",
       "      <th>wb_2791</th>\n",
       "      <th>wb_2792</th>\n",
       "      <th>wb_2793</th>\n",
       "      <th>wb_2794</th>\n",
       "      <th>wb_2795</th>\n",
       "      <th>wb_2796</th>\n",
       "      <th>wb_2797</th>\n",
       "      <th>wb_2798</th>\n",
       "      <th>wb_2799</th>\n",
       "      <th>wb_2800</th>\n",
       "      <th>wb_2801</th>\n",
       "      <th>wb_2802</th>\n",
       "      <th>wb_2803</th>\n",
       "      <th>wb_2804</th>\n",
       "      <th>wb_2805</th>\n",
       "      <th>wb_2806</th>\n",
       "      <th>wb_2807</th>\n",
       "      <th>wb_2808</th>\n",
       "      <th>wb_2809</th>\n",
       "      <th>wb_2810</th>\n",
       "      <th>wb_2811</th>\n",
       "      <th>wb_2812</th>\n",
       "      <th>wb_2813</th>\n",
       "      <th>wb_2814</th>\n",
       "      <th>wb_2815</th>\n",
       "      <th>wb_2816</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>0.086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>0.657</td>\n",
       "      <td>-1.399</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-1.489</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>1.198</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>2.308</td>\n",
       "      <td>1.892</td>\n",
       "      <td>-1.381</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3.408</td>\n",
       "      <td>-2.477</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>-2.716</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.019</td>\n",
       "      <td>1.314</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.083</td>\n",
       "      <td>3.085</td>\n",
       "      <td>-1.541</td>\n",
       "      <td>-2.100</td>\n",
       "      <td>3.687</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-2.724</td>\n",
       "      <td>2.094</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-2.204</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-3.380</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-2.764</td>\n",
       "      <td>3.189</td>\n",
       "      <td>3.231</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>-1.606</td>\n",
       "      <td>4.036</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-1.191</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-2.734</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-1.438</td>\n",
       "      <td>1.820</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-3.838</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>3.609</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>2.803</td>\n",
       "      <td>-2.062</td>\n",
       "      <td>-4.334</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-2.583</td>\n",
       "      <td>-3.076</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-1.304</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>1.565</td>\n",
       "      <td>-1.451</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-3.752</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>1.970</td>\n",
       "      <td>0.216</td>\n",
       "      <td>3.507</td>\n",
       "      <td>-3.065</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-2.446</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.305</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.585</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>0.708</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.922</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-1.034</td>\n",
       "      <td>1.315</td>\n",
       "      <td>-2.136</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-3.729</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>4.584</td>\n",
       "      <td>5.342</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-2.609</td>\n",
       "      <td>2.785</td>\n",
       "      <td>-2.539</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.019</td>\n",
       "      <td>1.414</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.674</td>\n",
       "      <td>4.157</td>\n",
       "      <td>-2.203</td>\n",
       "      <td>-3.642</td>\n",
       "      <td>1.558</td>\n",
       "      <td>0.133</td>\n",
       "      <td>2.042</td>\n",
       "      <td>0.209</td>\n",
       "      <td>3.008</td>\n",
       "      <td>4.899</td>\n",
       "      <td>-3.406</td>\n",
       "      <td>-3.651</td>\n",
       "      <td>3.230</td>\n",
       "      <td>-2.121</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-3.587</td>\n",
       "      <td>-3.579</td>\n",
       "      <td>1.123</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.617</td>\n",
       "      <td>0.058</td>\n",
       "      <td>2.202</td>\n",
       "      <td>1.194</td>\n",
       "      <td>-4.908</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>3.575</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-3.261</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>5.297</td>\n",
       "      <td>3.501</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-1.849</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-1.461</td>\n",
       "      <td>1.647</td>\n",
       "      <td>-2.120</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>4.044</td>\n",
       "      <td>1.464</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-4.158</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>2.230</td>\n",
       "      <td>-4.801</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-4.106</td>\n",
       "      <td>2.449</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>2.495</td>\n",
       "      <td>-3.471</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-3.539</td>\n",
       "      <td>5.329</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>2.828</td>\n",
       "      <td>-6.285</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-5.206</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1.689</td>\n",
       "      <td>3.927</td>\n",
       "      <td>-3.792</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-4.220</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.553</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.719</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179</td>\n",
       "      <td>3.459</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-4.127</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>3.005</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>2.632</td>\n",
       "      <td>3.357</td>\n",
       "      <td>-4.542</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-3.039</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.052</td>\n",
       "      <td>3.770</td>\n",
       "      <td>-5.491</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>3.773</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.209</td>\n",
       "      <td>1.318</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>3.604</td>\n",
       "      <td>4.763</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-2.725</td>\n",
       "      <td>0.171</td>\n",
       "      <td>3.407</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.058</td>\n",
       "      <td>2.087</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-2.891</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-3.307</td>\n",
       "      <td>3.140</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-2.783</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>4.481</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>3.949</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-4.967</td>\n",
       "      <td>-2.945</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-3.864</td>\n",
       "      <td>1.537</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.981</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-3.972</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-1.839</td>\n",
       "      <td>0.115</td>\n",
       "      <td>1.908</td>\n",
       "      <td>3.653</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.340</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.949</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.583</td>\n",
       "      <td>-2.902</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-2.434</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-2.016</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>4.145</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-4.296</td>\n",
       "      <td>1.591</td>\n",
       "      <td>-4.205</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.157</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.312</td>\n",
       "      <td>3.198</td>\n",
       "      <td>2.219</td>\n",
       "      <td>-3.207</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>3.387</td>\n",
       "      <td>0.133</td>\n",
       "      <td>2.228</td>\n",
       "      <td>0.209</td>\n",
       "      <td>2.154</td>\n",
       "      <td>1.005</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>2.847</td>\n",
       "      <td>2.299</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-2.861</td>\n",
       "      <td>0.967</td>\n",
       "      <td>1.575</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>0.058</td>\n",
       "      <td>2.914</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-1.916</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.546</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-3.138</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-3.300</td>\n",
       "      <td>-2.314</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-5.070</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-2.479</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>4.621</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>2.772</td>\n",
       "      <td>-3.589</td>\n",
       "      <td>-2.535</td>\n",
       "      <td>2.860</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.664</td>\n",
       "      <td>-4.988</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.972</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>3.550</td>\n",
       "      <td>-2.391</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-3.185</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>4.089</td>\n",
       "      <td>2.386</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.654</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.551</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.448</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179</td>\n",
       "      <td>3.399</td>\n",
       "      <td>-2.266</td>\n",
       "      <td>4.192</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.059</td>\n",
       "      <td>1.592</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-3.877</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-4.205</td>\n",
       "      <td>3.002</td>\n",
       "      <td>-2.942</td>\n",
       "      <td>3.140</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-6.815</td>\n",
       "      <td>-2.344</td>\n",
       "      <td>-2.510</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>-3.312</td>\n",
       "      <td>-2.692</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>2.315</td>\n",
       "      <td>0.656</td>\n",
       "      <td>3.924</td>\n",
       "      <td>4.839</td>\n",
       "      <td>-1.030</td>\n",
       "      <td>-3.625</td>\n",
       "      <td>4.735</td>\n",
       "      <td>0.133</td>\n",
       "      <td>3.071</td>\n",
       "      <td>0.209</td>\n",
       "      <td>4.993</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>2.418</td>\n",
       "      <td>0.024</td>\n",
       "      <td>1.452</td>\n",
       "      <td>-2.353</td>\n",
       "      <td>-4.061</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>1.777</td>\n",
       "      <td>3.068</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.058</td>\n",
       "      <td>3.573</td>\n",
       "      <td>-3.608</td>\n",
       "      <td>-3.976</td>\n",
       "      <td>2.601</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-4.077</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-1.841</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-2.764</td>\n",
       "      <td>-2.156</td>\n",
       "      <td>3.360</td>\n",
       "      <td>3.769</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>3.348</td>\n",
       "      <td>4.108</td>\n",
       "      <td>-1.086</td>\n",
       "      <td>-4.568</td>\n",
       "      <td>-4.132</td>\n",
       "      <td>0.832</td>\n",
       "      <td>-3.989</td>\n",
       "      <td>-1.735</td>\n",
       "      <td>-2.350</td>\n",
       "      <td>0.837</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>1.902</td>\n",
       "      <td>4.017</td>\n",
       "      <td>-3.409</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>2.798</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.177</td>\n",
       "      <td>3.771</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-4.942</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.209</td>\n",
       "      <td>0.030</td>\n",
       "      <td>4.329</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2841 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  seed  feat0  feat1  feat2  feat3  feat4  feat5  feat6  split0  \\\n",
       "83 83.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "53 53.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "70 70.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "45 45.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "44 44.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "\n",
       "    split1  split2  split3  split4  split5  split6   lp0   lp1   lp2   lp3  \\\n",
       "83   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "53   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "70   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "45   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "44   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "     lp4   lp5   lp6   lp7   wb_0   wb_1   wb_2   wb_3  wb_4  wb_5   wb_6  \\\n",
       "83 0.000 0.000 0.000 0.000 -0.034  0.188  0.064  0.047 0.261 0.269  0.038   \n",
       "53 0.000 0.000 0.000 0.000 -0.034 -0.151  0.068 -0.074 0.305 0.329 -0.867   \n",
       "70 0.000 0.000 0.000 0.000 -0.034 -0.142 -0.029  0.025 0.263 0.912  0.184   \n",
       "45 0.000 0.000 0.000 0.000 -0.034 -0.112 -0.055  0.028 0.221 0.463  0.576   \n",
       "44 0.000 0.000 0.000 0.000 -0.034 -0.162  0.019 -0.211 0.068 0.926  0.035   \n",
       "\n",
       "     wb_7   wb_8   wb_9  wb_10  wb_11  wb_12  wb_13  wb_14  wb_15  wb_16  \\\n",
       "83 -0.080 -0.095 -0.115 -0.186 -0.115 -0.348 -0.094 -0.407  0.087 -0.017   \n",
       "53 -0.423 -0.116 -0.115 -0.495  0.015 -0.749 -0.094  0.015  0.087 -0.017   \n",
       "70  0.046 -0.068 -0.115 -0.394  0.275 -0.162 -0.094 -0.142  0.087 -0.017   \n",
       "45  0.340 -0.024 -0.115 -0.387 -0.048 -0.135 -0.094 -0.072  0.087 -0.017   \n",
       "44  0.120  0.166 -0.115 -0.713 -0.299  0.085 -0.099  0.132  0.087 -0.017   \n",
       "\n",
       "    wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  wb_24  wb_25  wb_26  \\\n",
       "83 -0.251 -0.116  0.709  0.274 -0.107 -0.182  0.150 -0.253  0.109 -0.098   \n",
       "53 -0.577 -0.116  0.345  0.189 -0.544 -0.182  0.150 -0.119  0.344  0.014   \n",
       "70 -0.168 -0.116 -0.196  0.276 -0.143 -0.182  0.150 -0.117 -0.036 -0.041   \n",
       "45  0.082 -0.116  0.197  0.245  0.141 -0.182  0.150 -0.416  0.092  0.129   \n",
       "44 -0.689 -0.116 -0.286  0.033  0.654 -0.182  0.150 -0.121  0.256 -0.024   \n",
       "\n",
       "    wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  wb_34  wb_35  wb_36  \\\n",
       "83  0.042 -0.104 -0.163  0.318 -0.278  0.076 -0.002  0.179 -0.212  0.000   \n",
       "53  0.072 -0.104 -0.163  0.168 -0.281  0.045 -0.291  0.179 -0.420  0.100   \n",
       "70 -0.001 -0.104 -0.163  0.553 -0.238  0.026 -0.167  0.179 -0.114 -0.105   \n",
       "45  0.064 -0.104 -0.163 -0.208 -0.302  0.135 -0.264  0.179 -0.119 -0.103   \n",
       "44 -0.238 -0.104 -0.163  0.126 -0.361 -0.421 -0.020  0.179 -0.551 -0.085   \n",
       "\n",
       "    wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  wb_44  wb_45  wb_46  \\\n",
       "83 -0.017 -0.234  0.072  0.185 -0.115 -0.352  0.181 -0.129 -0.409 -0.036   \n",
       "53  0.110 -0.560  0.173  0.500  0.305 -0.109  0.256 -0.106 -0.154  0.033   \n",
       "70  0.719 -0.099  0.059  0.848  0.058 -0.126  0.006  0.184 -0.191 -0.063   \n",
       "45  0.249 -0.300  0.110  0.949 -0.205 -0.555 -0.285 -0.198 -0.041 -0.029   \n",
       "44  0.200 -0.448  0.205 -0.051  0.559 -0.623 -0.286 -0.230  0.467 -0.012   \n",
       "\n",
       "    wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  wb_54  wb_55  wb_56  \\\n",
       "83 -0.047 -0.135 -0.319  0.440  0.016  0.035  0.059 -0.201 -0.167  0.117   \n",
       "53  0.035 -0.138 -0.162 -0.093  0.016  0.035  0.159 -0.201  0.403  0.139   \n",
       "70 -0.024 -0.263 -0.209 -0.217  0.016  0.035  0.055 -0.201  0.441  0.112   \n",
       "45  0.002 -0.137 -0.168 -0.149  0.016  0.035  0.101 -0.201  0.039  0.072   \n",
       "44  0.091 -0.079 -0.035 -0.002  0.016  0.035  0.221 -0.201  0.040 -0.171   \n",
       "\n",
       "    wb_57  wb_58  wb_59  wb_60  wb_61  wb_62  wb_63  wb_64  wb_65  wb_66  \\\n",
       "83 -0.073 -0.188  0.618  0.036  0.174 -0.375 -0.190  0.049 -0.168 -0.210   \n",
       "53 -0.543 -0.162  0.633  0.585 -0.379 -0.150 -0.190 -0.423 -0.168 -0.565   \n",
       "70 -0.059 -0.167 -0.082  0.296 -0.044 -0.436 -0.190  0.036 -0.168 -0.054   \n",
       "45 -0.060  0.364  0.683  0.001 -0.024  0.253 -0.190 -0.092 -0.168  0.022   \n",
       "44 -0.446 -0.499 -0.115  0.316 -0.273 -0.111 -0.190 -0.244 -0.168 -0.103   \n",
       "\n",
       "    wb_67  wb_68  wb_69  wb_70  wb_71  wb_72  wb_73  wb_74  wb_75  ...  \\\n",
       "83 -0.109 -0.029  0.512 -0.179 -0.025  0.069  0.042 -0.278  0.086  ...   \n",
       "53 -0.651  0.708 -0.168 -0.922  0.067 -0.130 -0.022  0.243 -0.030  ...   \n",
       "70 -0.092 -0.007  0.188  0.042 -0.042 -0.137  0.048  0.199  0.079  ...   \n",
       "45  0.113  0.048  0.315 -0.091 -0.011 -0.121  0.047  0.349  0.215  ...   \n",
       "44 -0.161  0.044 -0.411 -0.274  0.497  0.145 -0.147  0.320 -0.156  ...   \n",
       "\n",
       "    wb_2717  wb_2718  wb_2719  wb_2720  wb_2721  wb_2722  wb_2723  wb_2724  \\\n",
       "83    0.179    0.194   -0.497    0.657   -1.399    0.059    0.060   -1.489   \n",
       "53    0.179    0.030   -1.034    1.315   -2.136    0.059    0.615   -3.729   \n",
       "70    0.179    3.459   -0.173   -0.005   -0.019    0.059   -0.035   -0.135   \n",
       "45    0.179    1.583   -2.902    0.326   -2.434    0.059   -0.082   -2.016   \n",
       "44    0.179    3.399   -2.266    4.192   -0.045    0.059    1.592   -0.986   \n",
       "\n",
       "    wb_2725  wb_2726  wb_2727  wb_2728  wb_2729  wb_2730  wb_2731  wb_2732  \\\n",
       "83   -0.033    1.198   -0.025    2.308    1.892   -1.381    0.077    3.408   \n",
       "53   -0.051    0.411   -0.191    4.584    5.342   -0.218   -2.609    2.785   \n",
       "70   -4.127    0.027   -0.129    3.005    0.071   -0.157    2.632    3.357   \n",
       "45   -0.904    4.145   -0.147   -4.296    1.591   -4.205    3.000    2.157   \n",
       "44   -3.877   -0.622    0.003   -4.205    3.002   -2.942    3.140    0.086   \n",
       "\n",
       "    wb_2733  wb_2734  wb_2735  wb_2736  wb_2737  wb_2738  wb_2739  wb_2740  \\\n",
       "83   -2.477   -0.035   -0.015   -0.136   -0.347   -2.716   -0.153    0.099   \n",
       "53   -2.539   -0.044   -0.002   -0.081   -0.159   -0.028   -0.153    0.099   \n",
       "70   -4.542   -0.170    0.029   -0.211   -0.324   -0.112   -0.153    0.099   \n",
       "45   -0.011   -0.185   -0.117   -0.085   -0.161   -0.070   -0.153    0.099   \n",
       "44   -6.815   -2.344   -2.510   -0.687   -3.312   -2.692   -0.153    0.099   \n",
       "\n",
       "    wb_2741  wb_2742  wb_2743  wb_2744  wb_2745  wb_2746  wb_2747  wb_2748  \\\n",
       "83   -0.009    0.019    1.314    0.228    0.143    0.083    3.085   -1.541   \n",
       "53   -0.117    0.019    1.414    0.808    0.625    2.674    4.157   -2.203   \n",
       "70   -0.072    0.019   -3.039    0.078    0.058    0.052    3.770   -5.491   \n",
       "45   -0.087    0.019   -0.043   -0.011    0.312    3.198    2.219   -3.207   \n",
       "44    0.058    0.019   -0.443    2.315    0.656    3.924    4.839   -1.030   \n",
       "\n",
       "    wb_2749  wb_2750  wb_2751  wb_2752  wb_2753  wb_2754  wb_2755  wb_2756  \\\n",
       "83   -2.100    3.687    0.133    0.198    0.209   -0.630    0.093   -2.724   \n",
       "53   -3.642    1.558    0.133    2.042    0.209    3.008    4.899   -3.406   \n",
       "70   -0.179    3.773    0.133    0.007    0.209    1.318    0.152   -0.100   \n",
       "45   -0.247    3.387    0.133    2.228    0.209    2.154    1.005   -0.305   \n",
       "44   -3.625    4.735    0.133    3.071    0.209    4.993    0.023   -0.099   \n",
       "\n",
       "    wb_2757  wb_2758  wb_2759  wb_2760  wb_2761  wb_2762  wb_2763  wb_2764  \\\n",
       "83    2.094    0.193   -0.003   -2.204   -0.045   -3.380    0.060    0.061   \n",
       "53   -3.651    3.230   -2.121   -0.110   -3.587   -3.579    1.123    0.177   \n",
       "70    3.604    4.763   -0.071   -0.105   -0.004   -2.725    0.171    3.407   \n",
       "45    2.847    2.299   -0.054   -0.117   -0.005   -2.861    0.967    1.575   \n",
       "44    2.418    0.024    1.452   -2.353   -4.061   -0.813    1.777    3.068   \n",
       "\n",
       "    wb_2765  wb_2766  wb_2767  wb_2768  wb_2769  wb_2770  wb_2771  wb_2772  \\\n",
       "83   -2.764    3.189    3.231   -0.943   -0.861   -1.606    4.036   -0.006   \n",
       "53   -0.617    0.058    2.202    1.194   -4.908   -0.779    3.575   -0.001   \n",
       "70   -0.112    0.058    2.087   -0.102   -2.891   -0.107    0.083   -0.006   \n",
       "45   -0.510    0.058    2.914    0.046   -1.916   -0.064    0.546   -0.000   \n",
       "44   -0.110    0.058    3.573   -3.608   -3.976    2.601   -0.442   -4.077   \n",
       "\n",
       "    wb_2773  wb_2774  wb_2775  wb_2776  wb_2777  wb_2778  wb_2779  wb_2780  \\\n",
       "83   -0.068   -0.044   -0.142    0.126   -1.191   -0.004   -2.734   -0.357   \n",
       "53   -3.261   -0.044    5.297    3.501   -0.072   -0.002   -1.849    0.215   \n",
       "70   -0.061   -0.044   -3.307    3.140   -0.072   -0.004   -0.170   -0.178   \n",
       "45   -3.138   -0.044   -0.229    0.066   -3.300   -2.314   -0.167   -5.070   \n",
       "44   -0.069   -0.044   -1.841    0.063   -0.076   -0.004   -2.764   -2.156   \n",
       "\n",
       "    wb_2781  wb_2782  wb_2783  wb_2784  wb_2785  wb_2786  wb_2787  wb_2788  \\\n",
       "83   -1.438    1.820    0.099   -3.838   -0.156    3.609    0.237   -0.000   \n",
       "53   -1.461    1.647   -2.120   -0.140   -0.156    4.044    1.464   -0.052   \n",
       "70   -2.783    0.022    0.115   -0.164   -0.156    0.111    0.102   -0.084   \n",
       "45    0.077    0.009    0.006   -2.479   -0.156    4.621    0.156   -0.053   \n",
       "44    3.360    3.769    0.173   -0.528   -0.156    3.348    4.108   -1.086   \n",
       "\n",
       "    wb_2789  wb_2790  wb_2791  wb_2792  wb_2793  wb_2794  wb_2795  wb_2796  \\\n",
       "83   -0.018   -0.328    2.803   -2.062   -4.334   -0.046    0.062   -0.178   \n",
       "53   -4.158   -0.197    2.230   -4.801   -0.094   -4.106    2.449   -0.178   \n",
       "70    4.481   -0.213    3.949   -0.141   -4.967   -2.945    0.015   -0.178   \n",
       "45   -0.087   -0.218    2.772   -3.589   -2.535    2.860    0.469   -0.178   \n",
       "44   -4.568   -4.132    0.832   -3.989   -1.735   -2.350    0.837   -0.178   \n",
       "\n",
       "    wb_2797  wb_2798  wb_2799  wb_2800  wb_2801  wb_2802  wb_2803  wb_2804  \\\n",
       "83    0.013    0.771   -2.583   -3.076    0.026   -1.304   -0.025    1.565   \n",
       "53    2.495   -3.471   -0.017   -3.539    5.329   -0.492   -0.176    2.828   \n",
       "70   -0.006   -0.063   -0.011   -3.864    1.537   -0.012   -0.001    0.036   \n",
       "45    0.009    0.664   -4.988   -0.189    1.972   -0.184   -0.125    3.550   \n",
       "44    1.902    4.017   -3.409   -0.428    2.798    0.086    0.177    3.771   \n",
       "\n",
       "    wb_2805  wb_2806  wb_2807  wb_2808  wb_2809  wb_2810  wb_2811  wb_2812  \\\n",
       "83   -1.451    0.061   -3.752    0.134   -0.116    1.970    0.216    3.507   \n",
       "53   -6.285    0.061   -5.206    0.139   -0.182    0.665    1.689    3.927   \n",
       "70   -4.981    0.061   -3.972    0.139   -1.839    0.115    1.908    3.653   \n",
       "45   -2.391    0.061   -3.185    0.139   -0.278    4.089    2.386    0.064   \n",
       "44    0.393    0.061   -4.942    0.139    0.512    1.209    0.030    4.329   \n",
       "\n",
       "    wb_2813  wb_2814  wb_2815  wb_2816  \n",
       "83   -3.065    0.053   -2.446   -0.066  \n",
       "53   -3.792    0.131   -4.220    0.004  \n",
       "70   -0.031    0.003   -0.184    0.060  \n",
       "45   -1.656    0.039   -0.203   -0.025  \n",
       "44   -0.782    1.034    0.058    0.003  \n",
       "\n",
       "[5 rows x 2841 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_net_dataset_train.samples_class_0_list_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_net_dataset_train.distribution_dict_row_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset_train.distribution_dict_list_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "network_parameters_structure [(20, 128), (128,), (128, 1), (1,)]\n",
      "Epoch 1/500\n",
      "1/1 - 7s - loss: 0.8153 - binary_accuracy_inet_decision_function_fv_metric: 0.4969 - val_loss: 0.7379 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4950 - lr: 0.0010 - 7s/epoch - 7s/step\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 0.8018 - binary_accuracy_inet_decision_function_fv_metric: 0.5051 - val_loss: 0.7334 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4988 - lr: 0.0010 - 90ms/epoch - 90ms/step\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 0.8046 - binary_accuracy_inet_decision_function_fv_metric: 0.4924 - val_loss: 0.6987 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5006 - lr: 0.0010 - 85ms/epoch - 85ms/step\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 0.7521 - binary_accuracy_inet_decision_function_fv_metric: 0.5053 - val_loss: 0.7075 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4950 - lr: 0.0010 - 88ms/epoch - 88ms/step\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 0.7738 - binary_accuracy_inet_decision_function_fv_metric: 0.4937 - val_loss: 0.7128 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4942 - lr: 0.0010 - 90ms/epoch - 90ms/step\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 0.7791 - binary_accuracy_inet_decision_function_fv_metric: 0.4903 - val_loss: 0.7101 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4948 - lr: 0.0010 - 98ms/epoch - 98ms/step\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 0.7667 - binary_accuracy_inet_decision_function_fv_metric: 0.5087 - val_loss: 0.7022 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5010 - lr: 0.0010 - 92ms/epoch - 92ms/step\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 0.7540 - binary_accuracy_inet_decision_function_fv_metric: 0.5076 - val_loss: 0.6991 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5222 - lr: 0.0010 - 95ms/epoch - 95ms/step\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 0.7487 - binary_accuracy_inet_decision_function_fv_metric: 0.5040 - val_loss: 0.6949 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5212 - lr: 0.0010 - 94ms/epoch - 94ms/step\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 0.7324 - binary_accuracy_inet_decision_function_fv_metric: 0.5146 - val_loss: 0.6919 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5218 - lr: 0.0010 - 92ms/epoch - 92ms/step\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 0.7428 - binary_accuracy_inet_decision_function_fv_metric: 0.5124 - val_loss: 0.6915 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5270 - lr: 0.0010 - 96ms/epoch - 96ms/step\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 0.7251 - binary_accuracy_inet_decision_function_fv_metric: 0.5017 - val_loss: 0.6953 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4988 - lr: 0.0010 - 105ms/epoch - 105ms/step\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 0.7511 - binary_accuracy_inet_decision_function_fv_metric: 0.4746 - val_loss: 0.7002 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4794 - lr: 0.0010 - 88ms/epoch - 88ms/step\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 0.7356 - binary_accuracy_inet_decision_function_fv_metric: 0.5087 - val_loss: 0.7039 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4794 - lr: 0.0010 - 93ms/epoch - 93ms/step\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 0.7243 - binary_accuracy_inet_decision_function_fv_metric: 0.5116 - val_loss: 0.7040 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4768 - lr: 0.0010 - 86ms/epoch - 86ms/step\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 0.7186 - binary_accuracy_inet_decision_function_fv_metric: 0.5178 - val_loss: 0.7018 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4774 - lr: 0.0010 - 101ms/epoch - 101ms/step\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 0.7298 - binary_accuracy_inet_decision_function_fv_metric: 0.5049 - val_loss: 0.6964 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4796 - lr: 0.0010 - 92ms/epoch - 92ms/step\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 0.7289 - binary_accuracy_inet_decision_function_fv_metric: 0.4881 - val_loss: 0.6943 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4970 - lr: 0.0010 - 92ms/epoch - 92ms/step\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 0.7172 - binary_accuracy_inet_decision_function_fv_metric: 0.5026 - val_loss: 0.6971 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5148 - lr: 0.0010 - 87ms/epoch - 87ms/step\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 0.7230 - binary_accuracy_inet_decision_function_fv_metric: 0.5005 - val_loss: 0.6992 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5222 - lr: 0.0010 - 93ms/epoch - 93ms/step\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 0.7216 - binary_accuracy_inet_decision_function_fv_metric: 0.5025 - val_loss: 0.6991 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5206 - lr: 0.0010 - 87ms/epoch - 87ms/step\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 0.7211 - binary_accuracy_inet_decision_function_fv_metric: 0.5114 - val_loss: 0.6965 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5210 - lr: 0.0010 - 92ms/epoch - 92ms/step\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 0.7238 - binary_accuracy_inet_decision_function_fv_metric: 0.4918 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5208 - lr: 0.0010 - 98ms/epoch - 98ms/step\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 0.7243 - binary_accuracy_inet_decision_function_fv_metric: 0.4961 - val_loss: 0.6953 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4758 - lr: 0.0010 - 90ms/epoch - 90ms/step\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 0.7226 - binary_accuracy_inet_decision_function_fv_metric: 0.4971 - val_loss: 0.6930 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5216 - lr: 0.0010 - 95ms/epoch - 95ms/step\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 0.7157 - binary_accuracy_inet_decision_function_fv_metric: 0.5153 - val_loss: 0.6928 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5188 - lr: 0.0010 - 157ms/epoch - 157ms/step\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 0.7152 - binary_accuracy_inet_decision_function_fv_metric: 0.5037 - val_loss: 0.6942 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4958 - lr: 0.0010 - 88ms/epoch - 88ms/step\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 0.7102 - binary_accuracy_inet_decision_function_fv_metric: 0.5152 - val_loss: 0.6982 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 0.0010 - 89ms/epoch - 89ms/step\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 0.7167 - binary_accuracy_inet_decision_function_fv_metric: 0.4973 - val_loss: 0.7010 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4920 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 0.7158 - binary_accuracy_inet_decision_function_fv_metric: 0.5103 - val_loss: 0.7008 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 0.0010 - 91ms/epoch - 91ms/step\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 0.7062 - binary_accuracy_inet_decision_function_fv_metric: 0.5188 - val_loss: 0.6982 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4930 - lr: 0.0010 - 86ms/epoch - 86ms/step\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 0.7110 - binary_accuracy_inet_decision_function_fv_metric: 0.4996 - val_loss: 0.6949 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4910 - lr: 0.0010 - 86ms/epoch - 86ms/step\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 0.7137 - binary_accuracy_inet_decision_function_fv_metric: 0.4937 - val_loss: 0.6926 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5198 - lr: 0.0010 - 82ms/epoch - 82ms/step\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 0.7054 - binary_accuracy_inet_decision_function_fv_metric: 0.5046 - val_loss: 0.6922 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5106 - lr: 0.0010 - 82ms/epoch - 82ms/step\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 0.7089 - binary_accuracy_inet_decision_function_fv_metric: 0.5007 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5054 - lr: 0.0010 - 97ms/epoch - 97ms/step\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 0.7022 - binary_accuracy_inet_decision_function_fv_metric: 0.4995 - val_loss: 0.6948 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5036 - lr: 0.0010 - 92ms/epoch - 92ms/step\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 0.7016 - binary_accuracy_inet_decision_function_fv_metric: 0.5133 - val_loss: 0.6973 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5002 - lr: 0.0010 - 88ms/epoch - 88ms/step\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 0.7028 - binary_accuracy_inet_decision_function_fv_metric: 0.5056 - val_loss: 0.6964 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5054 - lr: 0.0010 - 91ms/epoch - 91ms/step\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 0.7053 - binary_accuracy_inet_decision_function_fv_metric: 0.5046 - val_loss: 0.6950 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5068 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 0.7045 - binary_accuracy_inet_decision_function_fv_metric: 0.5086 - val_loss: 0.6944 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5088 - lr: 0.0010 - 86ms/epoch - 86ms/step\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 0.7059 - binary_accuracy_inet_decision_function_fv_metric: 0.5107 - val_loss: 0.6951 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4808 - lr: 0.0010 - 82ms/epoch - 82ms/step\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 0.7049 - binary_accuracy_inet_decision_function_fv_metric: 0.5035 - val_loss: 0.6953 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4700 - lr: 0.0010 - 89ms/epoch - 89ms/step\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 0.7036 - binary_accuracy_inet_decision_function_fv_metric: 0.4932 - val_loss: 0.6956 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4932 - lr: 0.0010 - 95ms/epoch - 95ms/step\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 0.7001 - binary_accuracy_inet_decision_function_fv_metric: 0.5052 - val_loss: 0.6953 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4970 - lr: 0.0010 - 96ms/epoch - 96ms/step\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 0.6950 - binary_accuracy_inet_decision_function_fv_metric: 0.5244 - val_loss: 0.6943 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 0.0010 - 95ms/epoch - 95ms/step\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 0.7033 - binary_accuracy_inet_decision_function_fv_metric: 0.5000 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5084 - lr: 0.0010 - 91ms/epoch - 91ms/step\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 0.6972 - binary_accuracy_inet_decision_function_fv_metric: 0.5179 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5084 - lr: 0.0010 - 91ms/epoch - 91ms/step\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 0.6984 - binary_accuracy_inet_decision_function_fv_metric: 0.5097 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5084 - lr: 0.0010 - 93ms/epoch - 93ms/step\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 0.6998 - binary_accuracy_inet_decision_function_fv_metric: 0.5101 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5024 - lr: 0.0010 - 89ms/epoch - 89ms/step\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 0.7013 - binary_accuracy_inet_decision_function_fv_metric: 0.5130 - val_loss: 0.6944 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5058 - lr: 0.0010 - 92ms/epoch - 92ms/step\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 0.6988 - binary_accuracy_inet_decision_function_fv_metric: 0.5080 - val_loss: 0.6942 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5200 - lr: 0.0010 - 97ms/epoch - 97ms/step\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 0.6967 - binary_accuracy_inet_decision_function_fv_metric: 0.5176 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5038 - lr: 0.0010 - 93ms/epoch - 93ms/step\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 0.6924 - binary_accuracy_inet_decision_function_fv_metric: 0.5206 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5202 - lr: 0.0010 - 94ms/epoch - 94ms/step\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 0.6921 - binary_accuracy_inet_decision_function_fv_metric: 0.5237 - val_loss: 0.6930 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5210 - lr: 0.0010 - 104ms/epoch - 104ms/step\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 0.6943 - binary_accuracy_inet_decision_function_fv_metric: 0.5102 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5238 - lr: 0.0010 - 112ms/epoch - 112ms/step\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 0.6927 - binary_accuracy_inet_decision_function_fv_metric: 0.5184 - val_loss: 0.6951 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4856 - lr: 0.0010 - 102ms/epoch - 102ms/step\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 0.6962 - binary_accuracy_inet_decision_function_fv_metric: 0.5015 - val_loss: 0.6956 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4914 - lr: 0.0010 - 105ms/epoch - 105ms/step\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 0.6939 - binary_accuracy_inet_decision_function_fv_metric: 0.5180 - val_loss: 0.6953 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4906 - lr: 0.0010 - 100ms/epoch - 100ms/step\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 0.6970 - binary_accuracy_inet_decision_function_fv_metric: 0.5099 - val_loss: 0.6948 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4968 - lr: 0.0010 - 116ms/epoch - 116ms/step\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 0.6925 - binary_accuracy_inet_decision_function_fv_metric: 0.5277 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4868 - lr: 0.0010 - 93ms/epoch - 93ms/step\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 0.6903 - binary_accuracy_inet_decision_function_fv_metric: 0.5385 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5034 - lr: 1.0000e-04 - 105ms/epoch - 105ms/step\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 0.6882 - binary_accuracy_inet_decision_function_fv_metric: 0.5483 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5042 - lr: 1.0000e-04 - 105ms/epoch - 105ms/step\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 0.6892 - binary_accuracy_inet_decision_function_fv_metric: 0.5350 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5042 - lr: 1.0000e-04 - 96ms/epoch - 96ms/step\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 0.6893 - binary_accuracy_inet_decision_function_fv_metric: 0.5406 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4938 - lr: 1.0000e-04 - 111ms/epoch - 111ms/step\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 0.6904 - binary_accuracy_inet_decision_function_fv_metric: 0.5340 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4930 - lr: 1.0000e-04 - 102ms/epoch - 102ms/step\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 0.6929 - binary_accuracy_inet_decision_function_fv_metric: 0.5249 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4930 - lr: 1.0000e-04 - 107ms/epoch - 107ms/step\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 0.6916 - binary_accuracy_inet_decision_function_fv_metric: 0.5238 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5004 - lr: 1.0000e-04 - 92ms/epoch - 92ms/step\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 0.6925 - binary_accuracy_inet_decision_function_fv_metric: 0.5156 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4990 - lr: 1.0000e-04 - 89ms/epoch - 89ms/step\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 0.6903 - binary_accuracy_inet_decision_function_fv_metric: 0.5277 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4984 - lr: 1.0000e-04 - 89ms/epoch - 89ms/step\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 0.6928 - binary_accuracy_inet_decision_function_fv_metric: 0.5212 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4990 - lr: 1.0000e-04 - 94ms/epoch - 94ms/step\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 0.6905 - binary_accuracy_inet_decision_function_fv_metric: 0.5344 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4996 - lr: 1.0000e-04 - 88ms/epoch - 88ms/step\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 0.6893 - binary_accuracy_inet_decision_function_fv_metric: 0.5369 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4998 - lr: 1.0000e-04 - 88ms/epoch - 88ms/step\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 0.6887 - binary_accuracy_inet_decision_function_fv_metric: 0.5385 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4934 - lr: 1.0000e-04 - 104ms/epoch - 104ms/step\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 0.6907 - binary_accuracy_inet_decision_function_fv_metric: 0.5306 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-04 - 95ms/epoch - 95ms/step\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 0.6905 - binary_accuracy_inet_decision_function_fv_metric: 0.5367 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4924 - lr: 1.0000e-04 - 84ms/epoch - 84ms/step\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 0.6886 - binary_accuracy_inet_decision_function_fv_metric: 0.5379 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4984 - lr: 1.0000e-04 - 101ms/epoch - 101ms/step\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 0.6905 - binary_accuracy_inet_decision_function_fv_metric: 0.5386 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4986 - lr: 1.0000e-04 - 94ms/epoch - 94ms/step\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 0.6886 - binary_accuracy_inet_decision_function_fv_metric: 0.5396 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4986 - lr: 1.0000e-04 - 89ms/epoch - 89ms/step\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 0.6891 - binary_accuracy_inet_decision_function_fv_metric: 0.5365 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4960 - lr: 1.0000e-04 - 86ms/epoch - 86ms/step\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 0.6868 - binary_accuracy_inet_decision_function_fv_metric: 0.5491 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4962 - lr: 1.0000e-04 - 93ms/epoch - 93ms/step\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 0.6862 - binary_accuracy_inet_decision_function_fv_metric: 0.5444 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4960 - lr: 1.0000e-04 - 100ms/epoch - 100ms/step\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 0.6891 - binary_accuracy_inet_decision_function_fv_metric: 0.5367 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4860 - lr: 1.0000e-04 - 88ms/epoch - 88ms/step\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 0.6889 - binary_accuracy_inet_decision_function_fv_metric: 0.5348 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4862 - lr: 1.0000e-04 - 82ms/epoch - 82ms/step\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 0.6866 - binary_accuracy_inet_decision_function_fv_metric: 0.5571 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4858 - lr: 1.0000e-04 - 92ms/epoch - 92ms/step\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 0.6884 - binary_accuracy_inet_decision_function_fv_metric: 0.5390 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4846 - lr: 1.0000e-04 - 111ms/epoch - 111ms/step\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 0.6868 - binary_accuracy_inet_decision_function_fv_metric: 0.5449 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4846 - lr: 1.0000e-04 - 90ms/epoch - 90ms/step\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 0.6880 - binary_accuracy_inet_decision_function_fv_metric: 0.5433 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4838 - lr: 1.0000e-04 - 90ms/epoch - 90ms/step\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 0.6897 - binary_accuracy_inet_decision_function_fv_metric: 0.5325 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4838 - lr: 1.0000e-04 - 86ms/epoch - 86ms/step\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 0.6881 - binary_accuracy_inet_decision_function_fv_metric: 0.5358 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4916 - lr: 1.0000e-04 - 100ms/epoch - 100ms/step\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 0.6890 - binary_accuracy_inet_decision_function_fv_metric: 0.5418 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4914 - lr: 1.0000e-04 - 92ms/epoch - 92ms/step\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 0.6870 - binary_accuracy_inet_decision_function_fv_metric: 0.5501 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4916 - lr: 1.0000e-04 - 92ms/epoch - 92ms/step\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 0.6883 - binary_accuracy_inet_decision_function_fv_metric: 0.5388 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4918 - lr: 1.0000e-04 - 86ms/epoch - 86ms/step\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 0.6882 - binary_accuracy_inet_decision_function_fv_metric: 0.5457 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4918 - lr: 1.0000e-04 - 95ms/epoch - 95ms/step\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 0.6884 - binary_accuracy_inet_decision_function_fv_metric: 0.5357 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4916 - lr: 1.0000e-04 - 97ms/epoch - 97ms/step\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 0.6892 - binary_accuracy_inet_decision_function_fv_metric: 0.5350 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4920 - lr: 1.0000e-04 - 96ms/epoch - 96ms/step\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 0.6870 - binary_accuracy_inet_decision_function_fv_metric: 0.5419 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4940 - lr: 1.0000e-04 - 104ms/epoch - 104ms/step\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 0.6840 - binary_accuracy_inet_decision_function_fv_metric: 0.5584 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 1.0000e-04 - 101ms/epoch - 101ms/step\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 0.6885 - binary_accuracy_inet_decision_function_fv_metric: 0.5429 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 1.0000e-04 - 90ms/epoch - 90ms/step\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 0.6860 - binary_accuracy_inet_decision_function_fv_metric: 0.5467 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4924 - lr: 1.0000e-04 - 86ms/epoch - 86ms/step\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 0.6866 - binary_accuracy_inet_decision_function_fv_metric: 0.5452 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4924 - lr: 1.0000e-04 - 88ms/epoch - 88ms/step\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 0.6853 - binary_accuracy_inet_decision_function_fv_metric: 0.5563 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 1.0000e-04 - 96ms/epoch - 96ms/step\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 0.6874 - binary_accuracy_inet_decision_function_fv_metric: 0.5485 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4924 - lr: 1.0000e-04 - 103ms/epoch - 103ms/step\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 0.6863 - binary_accuracy_inet_decision_function_fv_metric: 0.5511 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 1.0000e-04 - 98ms/epoch - 98ms/step\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 0.6868 - binary_accuracy_inet_decision_function_fv_metric: 0.5472 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4924 - lr: 1.0000e-04 - 104ms/epoch - 104ms/step\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 0.6855 - binary_accuracy_inet_decision_function_fv_metric: 0.5518 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 1.0000e-04 - 90ms/epoch - 90ms/step\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 0.6875 - binary_accuracy_inet_decision_function_fv_metric: 0.5418 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 1.0000e-04 - 101ms/epoch - 101ms/step\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 0.6858 - binary_accuracy_inet_decision_function_fv_metric: 0.5465 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4926 - lr: 1.0000e-04 - 91ms/epoch - 91ms/step\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 0.6878 - binary_accuracy_inet_decision_function_fv_metric: 0.5435 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-04 - 101ms/epoch - 101ms/step\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 0.6840 - binary_accuracy_inet_decision_function_fv_metric: 0.5569 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-04 - 99ms/epoch - 99ms/step\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 0.6870 - binary_accuracy_inet_decision_function_fv_metric: 0.5474 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-04 - 94ms/epoch - 94ms/step\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 0.6824 - binary_accuracy_inet_decision_function_fv_metric: 0.5622 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 98ms/epoch - 98ms/step\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 0.6857 - binary_accuracy_inet_decision_function_fv_metric: 0.5587 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 86ms/epoch - 86ms/step\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 0.6852 - binary_accuracy_inet_decision_function_fv_metric: 0.5463 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 88ms/epoch - 88ms/step\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 0.6840 - binary_accuracy_inet_decision_function_fv_metric: 0.5588 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 99ms/epoch - 99ms/step\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 0.6843 - binary_accuracy_inet_decision_function_fv_metric: 0.5553 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 100ms/epoch - 100ms/step\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 0.6871 - binary_accuracy_inet_decision_function_fv_metric: 0.5399 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 93ms/epoch - 93ms/step\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 0.6853 - binary_accuracy_inet_decision_function_fv_metric: 0.5537 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 92ms/epoch - 92ms/step\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 0.6865 - binary_accuracy_inet_decision_function_fv_metric: 0.5505 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 107ms/epoch - 107ms/step\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 0.6870 - binary_accuracy_inet_decision_function_fv_metric: 0.5404 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 87ms/epoch - 87ms/step\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 0.6838 - binary_accuracy_inet_decision_function_fv_metric: 0.5511 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 92ms/epoch - 92ms/step\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 0.6857 - binary_accuracy_inet_decision_function_fv_metric: 0.5474 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 106ms/epoch - 106ms/step\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 0.6846 - binary_accuracy_inet_decision_function_fv_metric: 0.5530 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 102ms/epoch - 102ms/step\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 0.6856 - binary_accuracy_inet_decision_function_fv_metric: 0.5546 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 91ms/epoch - 91ms/step\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 0.6846 - binary_accuracy_inet_decision_function_fv_metric: 0.5563 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 88ms/epoch - 88ms/step\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 0.6831 - binary_accuracy_inet_decision_function_fv_metric: 0.5610 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 1.0000e-05 - 117ms/epoch - 117ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as activation_2_layer_call_fn, activation_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0:00:22\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model,\n",
    " encoder_model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=plot_losses\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate I-Net Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "        \n",
    "    writepath_nas = './results_nas.csv'\n",
    "\n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "\n",
    "    if not os.path.exists(writepath_nas):\n",
    "        with open(writepath_nas, 'w+') as text_file:       \n",
    "            for key in flat_config.keys():\n",
    "                text_file.write(key)\n",
    "                text_file.write(';')         \n",
    "\n",
    "            for hp in history[0].hyperparameters.values.keys():\n",
    "                text_file.write(hp + ';')    \n",
    "               \n",
    "            text_file.write('score')\n",
    "            \n",
    "            text_file.write('\\n')\n",
    "\n",
    "    with open(writepath_nas, 'a+') as text_file:  \n",
    "        for value in flat_config.values():\n",
    "            text_file.write(str(value))\n",
    "            text_file.write(';')\n",
    "\n",
    "        for hp, value in history[0].hyperparameters.values.items():\n",
    "            text_file.write(str(value) + ';')        \n",
    "\n",
    "        \n",
    "        text_file.write(str(history[0].score))\n",
    "            \n",
    "        text_file.write('\\n')            \n",
    "\n",
    "        text_file.close()      \n",
    "        \n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make_classification evaluation Paul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_LR = {\n",
    "    'data': {\n",
    "        'n_datasets': 10_000,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, mean_squared_error\n",
    "\n",
    "def precision(tp, fp, tn, fn):\n",
    "    return tp / (tp + fp)\n",
    "def recall(tp, fp, tn, fn):\n",
    "    return tp / (tp + fn)\n",
    "def f1(tp, fp, tn, fn):\n",
    "    pre = precision(tp, fp, tn, fn)\n",
    "    rec = recall(tp, fp, tn, fn)\n",
    "    return 2 * (pre * rec) / (pre + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluateSingleSample(i, loss_function, metrics, config):\n",
    "    \n",
    "    informative = np.random.randint(config['data']['number_of_variables']//2, high=config['data']['number_of_variables']+1) #config['data']['number_of_variables']\n",
    "    redundant = np.random.randint(0, high=config['data']['number_of_variables']-informative+1) #0\n",
    "    repeated = config['data']['number_of_variables']-informative-redundant # 0\n",
    "\n",
    "    n_clusters_per_class =  max(2, np.random.randint(0, high=informative//2+1)) #2\n",
    "\n",
    "    X_data, y_data = make_classification(n_samples=config['data']['lambda_dataset_size'], \n",
    "                                                       n_features=config['data']['number_of_variables'], #The total number of features. These comprise n_informative informative features, n_redundant redundant features, n_repeated duplicated features and n_features-n_informative-n_redundant-n_repeated useless features drawn at random.\n",
    "                                                       n_informative=informative,#config['data']['number_of_variables'], #The number of informative features. Each class is composed of a number of gaussian clusters each located around the vertices of a hypercube in a subspace of dimension n_informative.\n",
    "                                                       n_redundant=redundant, #The number of redundant features. These features are generated as random linear combinations of the informative features.\n",
    "                                                       n_repeated=repeated, #The number of duplicated features, drawn randomly from the informative and the redundant features.\n",
    "                                                       n_classes=config['data']['num_classes'], \n",
    "                                                       n_clusters_per_class=n_clusters_per_class, \n",
    "                                                       #flip_y=0.0, #The fraction of samples whose class is assigned randomly. \n",
    "                                                       #class_sep=1.0, #The factor multiplying the hypercube size. Larger values spread out the clusters/classes and make the classification task easier.\n",
    "                                                       #hypercube=False, #If True, the clusters are put on the vertices of a hypercube. If False, the clusters are put on the vertices of a random polytope.\n",
    "                                                       #shift=0.0, #Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep].\n",
    "                                                       #scale=1.0, #Multiply features by the specified value. \n",
    "                                                       shuffle=True, \n",
    "                                                       random_state=100_000+i) \n",
    "    \n",
    "    ## normalisierung\n",
    "    for i, column in enumerate(X_data.T):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(column.reshape(-1, 1))\n",
    "        X_data[:,i] = scaler.transform(column.reshape(-1, 1)).ravel()    \n",
    "    \n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = split_train_test_valid(X_data, y_data, valid_frac=0.25, test_frac=0.1, seed=42)\n",
    "    \n",
    "    \n",
    "    lambda_net = generate_base_model(config)\n",
    "    \n",
    "    x_lambda_weights = shaped_network_parameters_to_array(lambda_net.get_weights(), config)\n",
    "    \n",
    "    \n",
    "    #### so meinte ich das quasi wie du ein logistic regression model basierend auf den lambda-net predictions bekommst ###\n",
    "    #model_valid = LogisticRegression()\n",
    "    #model_valid.fit(X_data, network_parameters_to_network(x_lambda_weights, config).predict(X_train))      \n",
    "    #y_coef_truth = model_valid.coef_\n",
    "\n",
    "        \n",
    "    inet_model = load_inet(loss_function, metrics, config)\n",
    "    \n",
    "    y_dt_pred = inet_model.predict(x_lambda_weights.reshape(1, -1))\n",
    "    y_dt_pred = y_dt_pred[0]\n",
    "    \n",
    "    ## hier für den vergleich dann das model auch auf den network parameters trainieren ###\n",
    "    #model_groundTruth = get_LR(X_train, network_parameters_to_network(x_lambda_weights, config).predict(X_train)\n",
    "    \n",
    "    #model_pred = LogisticRegression()\n",
    "    #model_pred.coef_ = y_coef_pred\n",
    "    #model_pred.intercept_ = 0\n",
    "    #model_pred.classes_ = model_groundTruth.classes_\n",
    "    \n",
    "    \n",
    "    model_pred_inet = parameterDT(y_dt_pred, config)\n",
    "    \n",
    "    y_train_lambda_net = network_parameters_to_network(x_lambda_weights, config).predict(X_train)\n",
    "    model_standard = DecisionTreeClassifier(max_depth=config['function_family']['maximum_depth']) \n",
    "    model_standard.fit(X_train, np.round(y_train_lambda_net))\n",
    "    \n",
    "    y_lambda_net = np.round(network_parameters_to_network(x_lambda_weights, config).predict(X_test)).flatten()\n",
    "    \n",
    "    score_standard_model = model_standard.score(X_test, y_lambda_net)\n",
    "\n",
    "    y_pred_standard_model = np.round(model_standard.predict(X_test))\n",
    "    y_pred_inet_model  = np.round(model_pred_inet.predict(X_test))\n",
    "    \n",
    "    score_inet_model = accuracy_score(y_lambda_net, y_pred_inet_model)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_lambda_net, y_pred_inet_model, labels=[1,0]).ravel()\n",
    "    \n",
    "    pre = precision(tp, fp, tn, fn)\n",
    "    rec = recall(tp, fp, tn, fn)\n",
    "    fone = f1(tp, fp, tn, fn)\n",
    "    \n",
    "    #results.append([i, score_groundTruthModel, score_predModel, mse, tp, fn, fp, tn, pre, rec, fone])\n",
    "    \n",
    "    return i+1, score_standard_model, score_inet_model, tp, fn, fp, tn, pre, rec, fone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=15)]: Done  31 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=15)]: Done  42 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=15)]: Done  55 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=15)]: Done  68 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=15)]: Done  83 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=15)]: Done  98 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=15)]: Done 115 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=15)]: Done 132 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=15)]: Done 151 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=15)]: Done 170 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=15)]: Done 191 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=15)]: Done 212 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=15)]: Done 235 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=15)]: Done 258 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=15)]: Done 283 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=15)]: Done 308 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=15)]: Done 335 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=15)]: Done 362 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=15)]: Done 391 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=15)]: Done 420 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=15)]: Done 451 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=15)]: Done 482 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=15)]: Done 515 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=15)]: Done 548 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=15)]: Done 583 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=15)]: Done 618 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=15)]: Done 655 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=15)]: Done 692 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=15)]: Done 731 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=15)]: Done 770 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=15)]: Done 811 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=15)]: Done 852 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=15)]: Done 895 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=15)]: Done 938 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=15)]: Done 983 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=15)]: Done 1028 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=15)]: Done 1075 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=15)]: Done 1122 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=15)]: Done 1171 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=15)]: Done 1220 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=15)]: Done 1271 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=15)]: Done 1322 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=15)]: Done 1375 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=15)]: Done 1428 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=15)]: Done 1483 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=15)]: Done 1538 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=15)]: Done 1595 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=15)]: Done 1652 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=15)]: Done 1711 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=15)]: Done 1770 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=15)]: Done 1831 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=15)]: Done 1892 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=15)]: Done 1955 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=15)]: Done 2018 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=15)]: Done 2083 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=15)]: Done 2148 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=15)]: Done 2215 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=15)]: Done 2282 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=15)]: Done 2351 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=15)]: Done 2420 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=15)]: Done 2491 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=15)]: Done 2562 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=15)]: Done 2635 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=15)]: Done 2708 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=15)]: Done 2783 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=15)]: Done 2858 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=15)]: Done 2935 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=15)]: Done 3012 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=15)]: Done 3091 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=15)]: Done 3170 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=15)]: Done 3251 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=15)]: Done 3332 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=15)]: Done 3415 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=15)]: Done 3498 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=15)]: Done 3583 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=15)]: Done 3668 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=15)]: Done 3755 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=15)]: Done 3842 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=15)]: Done 3931 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=15)]: Done 4020 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=15)]: Done 4111 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=15)]: Done 4202 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=15)]: Done 4295 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=15)]: Done 4388 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=15)]: Done 4483 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=15)]: Done 4578 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=15)]: Done 4675 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=15)]: Done 4772 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=15)]: Done 4871 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=15)]: Done 4970 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=15)]: Done 5071 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=15)]: Done 5172 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=15)]: Done 5275 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=15)]: Done 5378 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=15)]: Done 5483 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=15)]: Done 5588 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=15)]: Done 5695 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=15)]: Done 5802 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=15)]: Done 5911 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=15)]: Done 6020 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=15)]: Done 6131 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=15)]: Done 6242 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=15)]: Done 6355 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=15)]: Done 6468 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=15)]: Done 6583 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=15)]: Done 6698 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=15)]: Done 6815 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=15)]: Done 6932 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=15)]: Done 7051 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=15)]: Done 7170 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=15)]: Done 7291 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=15)]: Done 7412 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=15)]: Done 7535 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=15)]: Done 7658 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=15)]: Done 7783 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=15)]: Done 7908 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=15)]: Done 8035 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=15)]: Done 8162 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=15)]: Done 8291 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=15)]: Done 8420 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=15)]: Done 8551 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=15)]: Done 8682 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=15)]: Done 8815 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=15)]: Done 8948 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=15)]: Done 9083 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=15)]: Done 9218 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=15)]: Done 9355 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=15)]: Done 9492 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=15)]: Done 9631 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=15)]: Done 9770 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=15)]: Done 9911 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=15)]: Done 10000 out of 10000 | elapsed: 18.2min finished\n"
     ]
    }
   ],
   "source": [
    "parallel = Parallel(n_jobs=config['computation']['n_jobs'], verbose=10, backend='loky') #loky\n",
    "\n",
    "result_list = parallel(delayed(evaluateSingleSample)(i, loss_function, metrics, config) for i in range(config_LR['data']['n_datasets']))\n",
    "\n",
    "results = pd.DataFrame(data=result_list,\n",
    "                       columns=[\"index_0=aggregated\", \n",
    "                                \"scoreOnClassfication_BaseModel\", \n",
    "                                \"scoreOnClassfication_PredictedModel\" , \n",
    "                                #\"mse\",  \n",
    "                                \"tp\", \n",
    "                                \"fn\", \n",
    "                                \"fp\", \n",
    "                                \"tn\", \n",
    "                                \"precision\", \n",
    "                                \"recall\", \n",
    "                                \"f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_0=aggregated</th>\n",
       "      <th>scoreOnClassfication_BaseModel</th>\n",
       "      <th>scoreOnClassfication_PredictedModel</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.984</td>\n",
       "      <td>492</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.972</td>\n",
       "      <td>486</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.980</td>\n",
       "      <td>490</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.976</td>\n",
       "      <td>488</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.984</td>\n",
       "      <td>492</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>498</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.994</td>\n",
       "      <td>497</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.954</td>\n",
       "      <td>477</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.956</td>\n",
       "      <td>478</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_0=aggregated  scoreOnClassfication_BaseModel  \\\n",
       "0                  20                           0.988   \n",
       "1                  20                           1.000   \n",
       "2                  20                           0.996   \n",
       "3                  20                           1.000   \n",
       "4                  20                           0.996   \n",
       "5                  20                           0.998   \n",
       "6                  20                           1.000   \n",
       "7                  20                           0.992   \n",
       "8                  20                           0.996   \n",
       "9                  20                           1.000   \n",
       "\n",
       "   scoreOnClassfication_PredictedModel   tp  fn  fp  tn  precision  recall  \\\n",
       "0                                0.984  492   5   3   0      0.994   0.990   \n",
       "1                                0.972  486  14   0   0      1.000   0.972   \n",
       "2                                0.980  490   8   2   0      0.996   0.984   \n",
       "3                                0.976  488  12   0   0      1.000   0.976   \n",
       "4                                0.984  492   6   2   0      0.996   0.988   \n",
       "5                                0.998  499   1   0   0      1.000   0.998   \n",
       "6                                0.996  498   2   0   0      1.000   0.996   \n",
       "7                                0.994  497   0   3   0      0.994   1.000   \n",
       "8                                0.954  477  21   2   0      0.996   0.958   \n",
       "9                                0.956  478  22   0   0      1.000   0.956   \n",
       "\n",
       "     f1  \n",
       "0 0.992  \n",
       "1 0.986  \n",
       "2 0.990  \n",
       "3 0.988  \n",
       "4 0.992  \n",
       "5 0.999  \n",
       "6 0.998  \n",
       "7 0.997  \n",
       "8 0.976  \n",
       "9 0.978  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_0=aggregated</th>\n",
       "      <th>scoreOnClassfication_BaseModel</th>\n",
       "      <th>scoreOnClassfication_PredictedModel</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.979</td>\n",
       "      <td>489.524</td>\n",
       "      <td>8.669</td>\n",
       "      <td>1.755</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>7.369</td>\n",
       "      <td>6.850</td>\n",
       "      <td>2.757</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.858</td>\n",
       "      <td>429.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.972</td>\n",
       "      <td>486.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.982</td>\n",
       "      <td>491.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>495.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index_0=aggregated  scoreOnClassfication_BaseModel  \\\n",
       "count           10000.000                       10000.000   \n",
       "mean               20.000                           0.996   \n",
       "std                 0.000                           0.005   \n",
       "min                20.000                           0.934   \n",
       "25%                20.000                           0.994   \n",
       "50%                20.000                           0.998   \n",
       "75%                20.000                           1.000   \n",
       "max                20.000                           1.000   \n",
       "\n",
       "       scoreOnClassfication_PredictedModel        tp        fn        fp  \\\n",
       "count                            10000.000 10000.000 10000.000 10000.000   \n",
       "mean                                 0.979   489.524     8.669     1.755   \n",
       "std                                  0.015     7.369     6.850     2.757   \n",
       "min                                  0.858   429.000     0.000     0.000   \n",
       "25%                                  0.972   486.000     4.000     0.000   \n",
       "50%                                  0.982   491.000     7.000     1.000   \n",
       "75%                                  0.990   495.000    12.000     2.000   \n",
       "max                                  1.000   500.000    64.000    46.000   \n",
       "\n",
       "             tn  precision    recall        f1  \n",
       "count 10000.000  10000.000 10000.000 10000.000  \n",
       "mean      0.052      0.996     0.983     0.989  \n",
       "std       0.271      0.006     0.014     0.008  \n",
       "min       0.000      0.908     0.870     0.924  \n",
       "25%       0.000      0.996     0.976     0.986  \n",
       "50%       0.000      0.998     0.986     0.991  \n",
       "75%       0.000      1.000     0.992     0.995  \n",
       "max       6.000      1.000     1.000     1.000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_eval_res_DT(df):\n",
    "    \n",
    "    df.to_csv('./20220627_evalRes_DT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_eval_res_DT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36msave_eval_res_DT\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_eval_res_DT\u001b[39m(df):\n\u001b[1;32m      3\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./20220627_evalRes_DT.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mpath\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "save_eval_res_DT(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ab hier ignorieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    index = 0\n",
    "    lambda_net = lambda_net_dataset_train.lambda_net_list[index]\n",
    "    \n",
    "    lambda_net_model = network_parameters_to_network(lambda_net.network_parameters, config)\n",
    "    lambda_net_model_preds = lambda_net_model.predict(lambda_net.X_train_lambda)\n",
    "    dt_train_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_train_data.fit(lambda_net.X_train_lambda, np.round(lambda_net_model_preds))\n",
    "    \n",
    "    random_data = np.random.uniform(0, 1, lambda_net.X_train_lambda.shape)\n",
    "    lambda_net_model_preds_random = lambda_net_model.predict(random_data)\n",
    "    dt_random_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_random_data.fit(random_data, np.round(lambda_net_model_preds_random))\n",
    "    \n",
    "    plot_decision_area_evaluation(lambda_net.X_train_lambda, \n",
    "                                lambda_net.y_train_lambda.flatten(), \n",
    "                                lambda_net.X_test_lambda, \n",
    "                                lambda_net.y_test_lambda.flatten(),\n",
    "                                random_data,\n",
    "                                lambda_net_model_preds_random.flatten(),                                   \n",
    "                                lambda_net_model,\n",
    "                                dt_train_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                model.predict(np.array([lambda_net.network_parameters]))[0],\n",
    "                                np.array([str(i) for i in range(lambda_net.X_train_lambda.shape[1])]),\n",
    "                                config\n",
    "                               )\n",
    "\n",
    "    index = 0\n",
    "    lambda_net = lambda_net_dataset_valid.lambda_net_list[index]\n",
    "    \n",
    "    lambda_net_model = network_parameters_to_network(lambda_net.network_parameters, config)\n",
    "    lambda_net_model_preds = lambda_net_model.predict(lambda_net.X_train_lambda)\n",
    "    dt_train_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_train_data.fit(lambda_net.X_train_lambda, np.round(lambda_net_model_preds))\n",
    "    \n",
    "    random_data = np.random.uniform(0, 1, lambda_net.X_train_lambda.shape)\n",
    "    lambda_net_model_preds_random = lambda_net_model.predict(random_data)\n",
    "    dt_random_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_random_data.fit(random_data, np.round(lambda_net_model_preds_random))\n",
    "    \n",
    "    plot_decision_area_evaluation(lambda_net.X_train_lambda, \n",
    "                                lambda_net.y_train_lambda.flatten(), \n",
    "                                lambda_net.X_test_lambda, \n",
    "                                lambda_net.y_test_lambda.flatten(),\n",
    "                                random_data,\n",
    "                                lambda_net_model_preds_random.flatten(), \n",
    "                                lambda_net_model,\n",
    "                                dt_train_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                model.predict(np.array([lambda_net.network_parameters]))[0],\n",
    "                                np.array([str(i) for i in range(lambda_net.X_train_lambda.shape[1])]),\n",
    "                                config\n",
    "                               )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "if test_size > 0 and not evaluate_distribution:\n",
    "    network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "else:\n",
    "    network_parameters = np.array([lambda_net_dataset_valid.network_parameters_array[index]])\n",
    "    \n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    encoder_model = load_encoder_model(config)\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data(network_parameters, config, encoder_model)    \n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = None\n",
    "if not function_value_loss:\n",
    "    if test_size > 0 and not evaluate_distribution:\n",
    "        dt_parameters = y_test[index][:-2 ** config['function_family']['maximum_depth'] ]\n",
    "    else:\n",
    "        dt_parameters = y_valid[index][:-2 ** config['function_family']['maximum_depth'] ]\n",
    "\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 2817)]       0           []                               \n",
      "                                                                                                  \n",
      " hidden1_1792 (Dense)           (None, 1792)         5049856     ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation1_sigmoid (Activatio  (None, 1792)        0           ['hidden1_1792[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " hidden2_512 (Dense)            (None, 512)          918016      ['activation1_sigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " activation2_sigmoid (Activatio  (None, 512)         0           ['hidden2_512[0][0]']            \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " hidden3_512 (Dense)            (None, 512)          262656      ['activation2_sigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " activation3_sigmoid (Activatio  (None, 512)         0           ['hidden3_512[0][0]']            \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " dropout3_0.5 (Dropout)         (None, 512)          0           ['activation3_sigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " output_coeff_140 (Dense)       (None, 140)          71820       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_1 (Dense)    (None, 20)           10260       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_2 (Dense)    (None, 20)           10260       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_3 (Dense)    (None, 20)           10260       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_4 (Dense)    (None, 20)           10260       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_5 (Dense)    (None, 20)           10260       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_6 (Dense)    (None, 20)           10260       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_7 (Dense)    (None, 20)           10260       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_leaf_node_8 (Dense)     (None, 8)            4104        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_combined (Concatenate)  (None, 288)          0           ['output_coeff_140[0][0]',       \n",
      "                                                                  'output_identifier_1[0][0]',    \n",
      "                                                                  'output_identifier_2[0][0]',    \n",
      "                                                                  'output_identifier_3[0][0]',    \n",
      "                                                                  'output_identifier_4[0][0]',    \n",
      "                                                                  'output_identifier_5[0][0]',    \n",
      "                                                                  'output_identifier_6[0][0]',    \n",
      "                                                                  'output_identifier_7[0][0]',    \n",
      "                                                                  'output_leaf_node_8[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,378,272\n",
      "Trainable params: 6,378,272\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Normal: This is useful for looking at means and other linear combinations (e.g. regression coefficients) because of the CLT. Related to that is if something is known to arise due to additive effects of many different small causes then the normal may be a reasonable distribution: for example, many biological measures are the result of multiple genes and multiple environmental factors and therefor are often approximately normal.\n",
    "\n",
    "    Gamma: Right skewed and useful for things with a natural minimum at 0. Commonly used for elapsed times and some financial variables.\n",
    "\n",
    "    Exponential: special case of the Gamma. It is memoryless and scales easily.\n",
    "\n",
    "    Chi-squared (𝜒2): special case of the Gamma. Arises as sum of squared normal variables (so used for variances).\n",
    "\n",
    "    Beta: Defined between 0 and 1 (but could be transformed to be between other values), useful for proportions or other quantities that must be between 0 and 1.\n",
    "\n",
    "    Binomial: How many \"successes\" out of a given number of independent trials with same probability of \"success\".\n",
    "\n",
    "    Poisson: Common for counts. Nice properties that if the number of events in a period of time or area follows a Poisson, then the number in twice the time or area still follows the Poisson (with twice the mean): this works for adding Poissons or scaling with values other than 2.\n",
    "\n",
    "    Note that if events occur over time and the time between occurrences follows an exponential then the number that occur in a time period follows a Poisson.\n",
    "\n",
    "    Negative Binomial: Counts with minimum 0 (or other value depending on which version) and no upper bound. Conceptually it is the number of \"failures\" before k \"successes\". The negative binomial is also a mixture of Poisson variables whose means come from a gamma distribution.\n",
    "\n",
    "    Geometric: special case for negative binomial where it is the number of \"failures\" before the 1st \"success\". If you truncate (round down) an exponential variable to make it discrete, the result is geometric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train & Valid Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22958b76e94d42958c707127a78b2e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa838eac8584a2fa8033df4d6e184a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mean_train_parameters = np.round(np.mean(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "std_train_parameters = np.round(np.std(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "\n",
    "(inet_evaluation_result_dict_train, \n",
    " inet_evaluation_result_dict_mean_train, \n",
    " dt_distilled_list_train,\n",
    " distances_dict) = evaluate_interpretation_net_synthetic_data(lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               lambda_net_dataset_train.X_test_lambda_array,\n",
    "                                                               model,\n",
    "                                                               config,\n",
    "                                                               identifier='train',\n",
    "                                                               mean_train_parameters=mean_train_parameters,\n",
    "                                                               std_train_parameters=std_train_parameters,\n",
    "                                                               network_parameters_train_array=lambda_net_dataset_train.network_parameters_array)\n",
    "\n",
    "\n",
    "(inet_evaluation_result_dict_valid, \n",
    " inet_evaluation_result_dict_mean_valid, \n",
    " dt_distilled_list_valid,\n",
    " distances_dict) = evaluate_interpretation_net_synthetic_data(lambda_net_dataset_valid.network_parameters_array, \n",
    "                                                               lambda_net_dataset_valid.X_test_lambda_array,\n",
    "                                                               model,\n",
    "                                                               config,\n",
    "                                                               identifier='valid',\n",
    "                                                               mean_train_parameters=mean_train_parameters,\n",
    "                                                               std_train_parameters=std_train_parameters,\n",
    "                                                               network_parameters_train_array=lambda_net_dataset_train.network_parameters_array,\n",
    "                                                               distances_dict=distances_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T10:48:37.785965Z",
     "iopub.status.busy": "2022-02-26T10:48:37.785727Z",
     "iopub.status.idle": "2022-02-26T10:48:38.372347Z",
     "shell.execute_reply": "2022-02-26T10:48:38.371431Z",
     "shell.execute_reply.started": "2022-02-26T10:48:37.785945Z"
    },
    "tags": []
   },
   "source": [
    "## Test Data Evaluation (+ Distribution Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#set_loky_pickler('pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#config['computation']['n_jobs'] = 60\n",
    "#config['i_net']['test_size'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 out of   5 | elapsed:    8.7s remaining:   13.1s\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed:   11.2s finished\n"
     ]
    }
   ],
   "source": [
    "if evaluate_distribution and test_size > 0:\n",
    "    \n",
    "    (distances_dict, \n",
    "     inet_evaluation_result_dict_test, \n",
    "     inet_evaluation_result_dict_complete_by_distribution_test,\n",
    "     inet_evaluation_result_dict_mean_test,\n",
    "     inet_evaluation_result_dict_mean_by_distribution_test,\n",
    "     inet_evaluation_results_test, \n",
    "     dt_inet_list_test, \n",
    "     dt_distilled_list_test, \n",
    "     data_dict_list_test, \n",
    "     normalizer_list_list_test,\n",
    "     test_network_list_distrib,\n",
    "     model_history_list,\n",
    "     distribution_parameter_list_list) = distribution_evaluation_interpretation_net_synthetic_data(loss_function, \n",
    "                                                                                            metrics,\n",
    "                                                                                            #model,\n",
    "                                                                                           config,\n",
    "                                                                                           distribution_list_evaluation = config['data']['distribution_list_eval'],#['uniform', 'normal', 'gamma', 'exponential', 'beta', 'binomial', 'poisson'],\n",
    "                                                                                           identifier='test',\n",
    "                                                                                           lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                                           mean_train_parameters=mean_train_parameters,\n",
    "                                                                                           std_train_parameters=std_train_parameters,\n",
    "                                                                                           distances_dict=distances_dict,\n",
    "                                                                                           max_distributions_per_class=max_distributions_per_class,#max_distributions_per_class,\n",
    "                                                                                           flip_percentage=noise_injected_level, #0.1,#\n",
    "                                                                                           data_noise=data_noise, #0.1,#\n",
    "                                                                                           random_parameters = random_parameters_distribution, #random_parameters_distribution\n",
    "                                                                                           verbose=0,\n",
    "                                                                                           backend='loky',#sequential\n",
    "                                                                                    )\n",
    "else:\n",
    "    (inet_evaluation_result_dict_test, \n",
    "     inet_evaluation_result_dict_mean_test, \n",
    "     dt_distilled_list_test,\n",
    "     distances_dict) = evaluate_interpretation_net_synthetic_data(lambda_net_dataset_test.network_parameters_array, \n",
    "                                                                   lambda_net_dataset_test.X_test_lambda_array,\n",
    "                                                                   model,\n",
    "                                                                   config,\n",
    "                                                                   identifier='test',\n",
    "                                                                   mean_train_parameters=mean_train_parameters,\n",
    "                                                                   std_train_parameters=std_train_parameters,\n",
    "                                                                   network_parameters_train_array=lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                   distances_dict=distances_dict)\n",
    "    \n",
    "    print_results_synthetic_evaluation(inet_evaluation_result_dict_mean_train, \n",
    "                                       inet_evaluation_result_dict_mean_valid, \n",
    "                                       inet_evaluation_result_dict_mean_test, \n",
    "                                       distances_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-Net Performance by Network:  [0.496 0.484 0.49  0.51  0.484]\n",
      "Distilled Mean Performance by Network:  [0.56  0.938 0.712 1.    0.988]\n",
      "Distilled Max Performance by Network:  [0.56  0.938 0.712 1.    0.988]\n",
      "Median I-Net: 0.49\n",
      "Median DT Distilled: 0.938\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc Distilled Train Data</th>\n",
       "      <th>Acc Distilled Data Random</th>\n",
       "      <th>Acc Distilled</th>\n",
       "      <th>Acc I-Net</th>\n",
       "      <th>Soft BC Distilled Train Data</th>\n",
       "      <th>Soft BC Distilled Data Random</th>\n",
       "      <th>Soft BC Distilled</th>\n",
       "      <th>Soft BC I-Net</th>\n",
       "      <th>BC Distilled Train Data</th>\n",
       "      <th>BC Distilled Data Random</th>\n",
       "      <th>BC Distilled</th>\n",
       "      <th>BC I-Net</th>\n",
       "      <th>F1 Score Distilled Train Data</th>\n",
       "      <th>F1 Score Distilled Data Random</th>\n",
       "      <th>F1 Score Distilled</th>\n",
       "      <th>F1 Score I-Net</th>\n",
       "      <th>ROC AUC Score Distilled Train Data</th>\n",
       "      <th>ROC AUC Score Distilled Data Random</th>\n",
       "      <th>ROC AUC Score Distilled</th>\n",
       "      <th>ROC AUC Score I-Net</th>\n",
       "      <th>Runtime Distilled Train Data</th>\n",
       "      <th>Runtime Distilled Data Random</th>\n",
       "      <th>Runtime Distilled</th>\n",
       "      <th>Runtime I-Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['uniform', 'normal', 'gamma', 'beta', 'poisson']</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.699</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.329</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Acc Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                     1.000   \n",
       "\n",
       "                                                   Acc Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                      0.914   \n",
       "\n",
       "                                                   Acc Distilled  Acc I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']          0.840      0.493   \n",
       "\n",
       "                                                   Soft BC Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                         0.320   \n",
       "\n",
       "                                                   Soft BC Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                          0.497   \n",
       "\n",
       "                                                   Soft BC Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']              0.554   \n",
       "\n",
       "                                                   Soft BC I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']          0.696   \n",
       "\n",
       "                                                   BC Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                    0.000   \n",
       "\n",
       "                                                   BC Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                     0.214   \n",
       "\n",
       "                                                   BC Distilled  BC I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']         0.693     0.699   \n",
       "\n",
       "                                                   F1 Score Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                          1.000   \n",
       "\n",
       "                                                   F1 Score Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                           0.900   \n",
       "\n",
       "                                                   F1 Score Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']               0.816   \n",
       "\n",
       "                                                   F1 Score I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']           0.329   \n",
       "\n",
       "                                                   ROC AUC Score Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                               1.000   \n",
       "\n",
       "                                                   ROC AUC Score Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                                0.857   \n",
       "\n",
       "                                                   ROC AUC Score Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                    0.859   \n",
       "\n",
       "                                                   ROC AUC Score I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                0.404   \n",
       "\n",
       "                                                   Runtime Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                         0.050   \n",
       "\n",
       "                                                   Runtime Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                          0.050   \n",
       "\n",
       "                                                   Runtime Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']              0.050   \n",
       "\n",
       "                                                   Runtime I-Net  \n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']          0.105  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Z-Score (Sample to Train Data)</th>\n",
       "      <th>Average Distance to Initialization</th>\n",
       "      <th>Average Mean Distance to Train Data</th>\n",
       "      <th>Average Distance to closest Train Data Sample</th>\n",
       "      <th>Average Biggest Distance for Single Neuron</th>\n",
       "      <th>Minimum Biggest Distance for Single Neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1505.098</td>\n",
       "      <td>415.884</td>\n",
       "      <td>631.605</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.607</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>1780.448</td>\n",
       "      <td>506.158</td>\n",
       "      <td>690.202</td>\n",
       "      <td>582.107</td>\n",
       "      <td>7.326</td>\n",
       "      <td>4.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1243.232</td>\n",
       "      <td>167.027</td>\n",
       "      <td>550.874</td>\n",
       "      <td>402.190</td>\n",
       "      <td>5.436</td>\n",
       "      <td>3.234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average Z-Score (Sample to Train Data)  \\\n",
       "train                                1505.098   \n",
       "valid                                1780.448   \n",
       "test                                 1243.232   \n",
       "\n",
       "       Average Distance to Initialization  \\\n",
       "train                             415.884   \n",
       "valid                             506.158   \n",
       "test                              167.027   \n",
       "\n",
       "       Average Mean Distance to Train Data  \\\n",
       "train                              631.605   \n",
       "valid                              690.202   \n",
       "test                               550.874   \n",
       "\n",
       "       Average Distance to closest Train Data Sample  \\\n",
       "train                                          0.000   \n",
       "valid                                        582.107   \n",
       "test                                         402.190   \n",
       "\n",
       "       Average Biggest Distance for Single Neuron  \\\n",
       "train                                       6.607   \n",
       "valid                                       7.326   \n",
       "test                                        5.436   \n",
       "\n",
       "       Minimum Biggest Distance for Single Neuron  \n",
       "train                                       0.000  \n",
       "valid                                       4.871  \n",
       "test                                        3.234  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if evaluate_distribution and test_size > 0:\n",
    "    #print(distribution_parameter_list_list[0])\n",
    "    #print(lambda_net_dataset_valid.distribution_dict_list_list[0])\n",
    "\n",
    "    inet_performance_distrib_evaluation = np.array(inet_evaluation_result_dict_complete_by_distribution_test[list(inet_evaluation_result_dict_complete_by_distribution_test.keys())[0]]['inet_scores']['accuracy'])\n",
    "    print('I-Net Performance by Network: ', inet_performance_distrib_evaluation)\n",
    "\n",
    "    mean_random_performance_distrib_evaluation = np.mean(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)\n",
    "    print('Distilled Mean Performance by Network: ', mean_random_performance_distrib_evaluation)\n",
    "\n",
    "    max_random_performance_distrib_evaluation = np.max(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)\n",
    "    print('Distilled Max Performance by Network: ', max_random_performance_distrib_evaluation)\n",
    "\n",
    "    print('Median I-Net:', np.median(inet_evaluation_result_dict_complete_by_distribution_test[list(inet_evaluation_result_dict_complete_by_distribution_test.keys())[0]]['inet_scores']['accuracy']))\n",
    "    print('Median DT Distilled:', np.median(np.median(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)))#np.median(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['dt_scores']['accuracy']))\n",
    "\n",
    "    complete_distribution_evaluation_results = get_complete_distribution_evaluation_results_dataframe(inet_evaluation_result_dict_mean_by_distribution_test)\n",
    "    display(complete_distribution_evaluation_results.head(20))\n",
    "    \n",
    "    network_distances = get_print_network_distances_dataframe(distances_dict)\n",
    "    display(network_distances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distribution_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdistribution_dict\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mlist\u001b[39m(distribution_dict[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distribution_dict' is not defined"
     ]
    }
   ],
   "source": [
    "distribution_dict[0][list(distribution_dict[0].keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if evaluate_distribution:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    identifier_folder = config['function_family']['dt_type'] + '_' + str(config['function_family']['decision_sparsity']) + '_' + timestr\n",
    "    os.makedirs('./data/distrib_plots/' + identifier_folder + '/', exist_ok=True)\n",
    "    \n",
    "    for i in range(min(3, test_size)):\n",
    "        #index = 14\n",
    "        #index = np.argmax(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['dt_scores']['accuracy']))\n",
    "        top_number = i\n",
    "        #index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['dt_scores']['accuracy']))[::-1][top_number]\n",
    "\n",
    "        scores_distilled_median_random = np.median(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)\n",
    "        scores_distilled_uniform = inet_evaluation_result_dict_complete_by_distribution_test[str(config['data']['distribution_list_eval'][0])]['dt_scores']['accuracy_uniform_data']\n",
    "        scores_distilled_normal = inet_evaluation_result_dict_complete_by_distribution_test[str(config['data']['distribution_list_eval'][0])]['dt_scores']['accuracy_normal_data']\n",
    "        \n",
    "        scores_distilled_array = np.mean([scores_distilled_median_random, scores_distilled_uniform, scores_distilled_normal], axis=0)\n",
    "        \n",
    "        index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test[list(inet_evaluation_result_dict_complete_by_distribution_test.keys())[0]]['inet_scores']['accuracy']) - scores_distilled_array)[::-1][top_number]\n",
    "        #index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.max(np.array([inet_evaluation_result_dict_complete_by_distribution_test[distrib]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0))[::-1][top_number]\n",
    "        #index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.mean(np.array([inet_evaluation_result_dict_complete_by_distribution_test[distrib]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0))[::-1][top_number]\n",
    "\n",
    "        distrib_for_index = np.argmax(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']])[:,index])\n",
    "\n",
    "        print('Index: ', index)\n",
    "        distribution_dict = distribution_parameter_list_list[index]\n",
    "\n",
    "        print('Feature 1: ', 'Samples', distribution_dict[0][list(distribution_dict[0].keys())[0]]['samples_class_0'], '/', config['data']['lambda_dataset_size']-distribution_dict[0][list(distribution_dict[0].keys())[0]]['samples_class_0'])\n",
    "        print('\\t Distribution 1: ' + list(distribution_dict[0].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[0][list(distribution_dict[0].keys())[0]]['class_0'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "        print('\\t Distribution 2: ' + list(distribution_dict[0].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[0][list(distribution_dict[0].keys())[0]]['class_1'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "\n",
    "        print('Feature 2: ', 'Samples', distribution_dict[1][list(distribution_dict[1].keys())[0]]['samples_class_0'], '/', config['data']['lambda_dataset_size']-distribution_dict[1][list(distribution_dict[1].keys())[0]]['samples_class_0'])\n",
    "        print('\\t Distribution 1: ' + list(distribution_dict[1].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[1][list(distribution_dict[1].keys())[0]]['class_0'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "        print('\\t Distribution 2: ' + list(distribution_dict[1].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[1][list(distribution_dict[1].keys())[0]]['class_1'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "\n",
    "        identifier_file = 'index' + str(index) + '_' + '_'.join([list(dist.keys())[0] + '_' +  '_'.join([key + '-' + str(np.round(value, 4)) for key, value in dist[list(dist.keys())[0]]['class_0'].items()]) + '_' + '_'.join([key + '-' + str(np.round(value, 4)) for key, value in dist[list(dist.keys())[0]]['class_1'].items()]) for dist in distribution_parameter_list_list[index]])\n",
    "        \n",
    "        plot_decision_area_evaluation_all_distrib(data_dict_list_test[index]['X_train'], \n",
    "                                            data_dict_list_test[index]['y_train'], \n",
    "                                            data_dict_list_test[index]['X_test'], \n",
    "                                            data_dict_list_test[index]['y_test'],\n",
    "                                            None,\n",
    "                                            None,\n",
    "                                            network_parameters_to_network(shaped_network_parameters_to_array(test_network_list_distrib[index], config), config),\n",
    "                                            dt_distilled_list_test[0][index][-3],\n",
    "                                            dt_distilled_list_test[0][index][-2],\n",
    "                                            dt_distilled_list_test[0][index][-1],\n",
    "                                            [dt_distilled_list_test[i][index][0] for i in range(len(config['data']['distribution_list_eval']))],     \n",
    "                                            dt_inet_list_test[0][index],\n",
    "                                            np.array([str(i) for i in range(data_dict_list_test[index]['X_train'].shape[1])]),\n",
    "                                            config['data']['distribution_list_eval'],\n",
    "                                            config,\n",
    "                                            identifier_folder = identifier_folder,\n",
    "                                            identifier_file = identifier_file\n",
    "                                           )    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    print('I-Net Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    dt_inet = parameterDT(dt_inet_list_test[distrib_for_index][index], config)\n",
    "    image = dt_inet.plot()\n",
    "    display(image)\n",
    "    \n",
    "    print('Random Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(dt_distilled_list_test[distrib_for_index][index][0], fontsize=10)  #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(dt_distilled_list_test[distrib_for_index][index][1], fontsize=10)  #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    plt.show()    \n",
    "    \n",
    "    print('Uniform Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(dt_distilled_list_test[distrib_for_index][index][2], fontsize=10)  #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    plt.show()    \n",
    "else:\n",
    "    print('I-Net Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    dt_parameters = dt_inet_list_test[distrib_for_index][index]\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "    display(image)\n",
    "    \n",
    "    print('Random Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = dt_distilled_list_test[distrib_for_index][index][0].plot_tree() #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    display(image)\n",
    "    \n",
    "    print('Train Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8)) \n",
    "    image = dt_distilled_list_test[distrib_for_index][index][1].plot_tree() #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL'] \n",
    "    display(image)\n",
    "    \n",
    "    print('Uniform Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = dt_distilled_list_test[distrib_for_index][index][2].plot_tree() #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_class_distrib_by_feature(model = model,\n",
    "                                  index = index,\n",
    "                                  test_network = network_parameters_to_network(lambda_net_dataset_valid.network_parameters_array[index], config, base_model=None),\n",
    "                                  distribution_training = config['data']['distribution_list_eval'][distrib_for_index],\n",
    "                                  distribution_dict = lambda_net_dataset_valid.distribution_dict_list_list[index],\n",
    "                                  X_test = lambda_net_dataset_valid.X_test_lambda_array[index],\n",
    "                                  config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_class_distrib_by_feature(model = model,\n",
    "                                  index = index,\n",
    "                                  test_network = network_parameters_to_network(shaped_network_parameters_to_array(test_network_list_distrib[index], config), config, base_model=None),\n",
    "                                  distribution_training = config['data']['distribution_list_eval'][distrib_for_index],\n",
    "                                  distribution_dict = lambda_net_dataset_valid.distribution_dict_list_list[index],\n",
    "                                  X_test =  data_dict_list_test[0]['X_test'],\n",
    "                                  config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Evaluation (Selected Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "if False:\n",
    "    evaluate_network_on_distribution_custom_parameters(distribution_name_feature_0 = 'normal',\n",
    "                                                       distribution_name_feature_1 = 'normal',\n",
    "                                                       distribution_parameters_0_param_1_feature_0 = 1.188840288782265,\n",
    "                                                       distribution_parameters_0_param_2_feature_0 = 0.8566173698593895,\n",
    "                                                       distribution_parameters_1_param_1_feature_0 = 0.8713650102755661,\n",
    "                                                       distribution_parameters_1_param_2_feature_0 = 1.8484540179178748,\n",
    "                                                       distribution_parameters_0_param_1_feature_1 = 1.7185974826882278,\n",
    "                                                       distribution_parameters_0_param_2_feature_1 = 0.5807878500034862,\n",
    "                                                       distribution_parameters_1_param_1_feature_1 = 0.44369536008631294,\n",
    "                                                       distribution_parameters_1_param_2_feature_1 = 1.17864258666672,\n",
    "                                                       inet = model,\n",
    "                                                       config = config,\n",
    "                                                       distribution_list_evaluation = config['data']['distribution_list_eval'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Real-World Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset_size_list = flatten_list([[config['evaluation']['random_evaluation_dataset_size_per_distribution']]*config['evaluation']['number_of_random_evaluations_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL'])\n",
    "dataset_size_list = flatten_list([[config['evaluation']['random_evaluation_dataset_size_per_distribution']]*config['evaluation']['number_of_random_evaluations_per_distribution'], \n",
    "                                  'TRAINDATA', \n",
    "                                  ['STANDARDUNIFORM']*config['evaluation']['number_of_random_evaluations_per_distribution'], \n",
    "                                  ['STANDARDNORMAL']*config['evaluation']['number_of_random_evaluations_per_distribution']])\n",
    "\n",
    "\n",
    "dataset_size_list_print = []\n",
    "for size in dataset_size_list:\n",
    "    if type(size) is int:\n",
    "        size = size//1000\n",
    "        size = str(size) + 'k'\n",
    "        dataset_size_list_print.append(size)\n",
    "    else:\n",
    "        dataset_size_list_print.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#distances_dict = {}\n",
    "evaluation_result_dict = {}\n",
    "results_dict = {}\n",
    "dt_inet_dict = {}\n",
    "dt_distilled_list_dict = {}\n",
    "data_dict = {}\n",
    "normalizer_list_dict = {}\n",
    "test_network_list = {}\n",
    "\n",
    "identifier_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "\n",
    "#adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "#adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "#adult_data.head()\n",
    "\n",
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 #\"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 #\"Occupation\",  #6\n",
    "                 #\"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 \"capital_gain\"\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "nominal_features_adult = [\n",
    "                          'Race', \n",
    "                          'Workclass', \n",
    "                          #'Education',\n",
    "                          \"Marital Status\",\n",
    "                          #\"Occupation\", \n",
    "                          #\"Relationship\"\n",
    "                        ]\n",
    "ordinal_features_adult = ['Sex']\n",
    "\n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "#y_data_adult = pd.Series(OrdinalEncoder().fit_transform(adult_data['capital_gain'].values.reshape(-1, 1)).flatten(), name='capital_gain')\n",
    "y_data_adult = ((adult_data['capital_gain'] != ' <=50K') * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_train_network_adult = deepcopy(config)\n",
    "#config_train_network_adult['lambda_net']['batch_lambda'] = 32\n",
    "#config_train_network_adult['lambda_net']['learning_rate_lambda'] = 0.0003\n",
    "#config_train_network_adult['lambda_net']['dropout_lambda'] = 0.25\n",
    "#config_train_network_adult['lambda_net']['epochs_lambda'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Adult'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_adult, \n",
    "                                                                y_data_adult, \n",
    "                                                                nominal_features = nominal_features_adult, \n",
    "                                                                ordinal_features = ordinal_features_adult,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = config_train_network_adult)\n",
    "\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict['Adult'], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "\n",
    "features_select = [\n",
    "                    #'Cabin', \n",
    "                    #'Ticket', \n",
    "                    #'Name', \n",
    "                    #'PassengerId'    \n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "nominal_features_titanic = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features_titanic = ['Sex']\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Titanic'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_titanic, \n",
    "                                                                y_data_titanic, \n",
    "                                                                nominal_features = nominal_features_titanic, \n",
    "                                                                ordinal_features = ordinal_features_titanic,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     \n",
    "    \n",
    "    y_train = data_dict[identifier]['y_train']\n",
    "    y_train_pred = pd.Series(np.round(test_network_list[identifier].predict(data_dict[identifier]['X_train'])).ravel(), \n",
    "                             name=\"Survived\")\n",
    "    X_data = pd.concat([data_dict[identifier]['X_train'], y_train_pred], axis=1)\n",
    "    display(X_data.head())\n",
    "    \n",
    "    X_data.groupby(\"Survived\").SibSp.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    #X_data[X_data.Parch > 0.8].groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    #plt.show()\n",
    "    X_data.groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    X_data.groupby(\"Survived\").Sex.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    uniform_data = generate_random_data_points_custom(config['data']['x_min'], \n",
    "                                   config['data']['x_max'],\n",
    "                                   config['evaluation']['random_evaluation_dataset_size_per_distribution'], \n",
    "                                   config['data']['number_of_variables'], \n",
    "                                   config['data']['categorical_indices'],\n",
    "                                   distrib='standarduniform',\n",
    "                                   random_parameters=config['data']['random_parameters_distribution'],\n",
    "                                   distrib_param_max=config['data']['distrib_param_max'],\n",
    "                                   seed=config['computation']['RANDOM_SEED'],\n",
    "                                   config=config)    \n",
    "    \n",
    "    y_uniform_data = np.round(test_network_list[identifier].predict(uniform_data))\n",
    "\n",
    "    uniform_data_with_labels_df = pd.DataFrame(data=np.hstack([uniform_data, y_uniform_data]), columns=X_data.columns)    \n",
    "    \n",
    "    uniform_data_with_labels_df.groupby(\"Survived\").SibSp.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    uniform_data_with_labels_df[uniform_data_with_labels_df.SibSp > 0.56].groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    uniform_data_with_labels_df[uniform_data_with_labels_df.SibSp < 0.56].groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()    \n",
    "    \n",
    "    uniform_data_with_labels_df.groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    uniform_data_with_labels_df.groupby(\"Survived\").Sex.hist(alpha=0.6)\n",
    "    plt.show()        \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           'Weight', \n",
    "                           'Height', \n",
    "                           'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "nominal_features_absenteeism = []\n",
    "ordinal_features_absenteeism = []\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 4) * 1) #absenteeism_data['Absenteeism time in hours']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Absenteeism'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_absenteeism, \n",
    "                                                                y_data_absenteeism, \n",
    "                                                                nominal_features = nominal_features_absenteeism, \n",
    "                                                                ordinal_features = ordinal_features_absenteeism,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('real_world_datasets/Loan/loan-train.csv', delimiter=',')\n",
    "\n",
    "loan_data['Gender'].fillna(loan_data['Gender'].mode()[0], inplace=True)\n",
    "loan_data['Dependents'].fillna(loan_data['Dependents'].mode()[0], inplace=True)\n",
    "loan_data['Married'].fillna(loan_data['Married'].mode()[0], inplace=True)\n",
    "loan_data['Self_Employed'].fillna(loan_data['Self_Employed'].mode()[0], inplace=True)\n",
    "loan_data['LoanAmount'].fillna(loan_data['LoanAmount'].mean(), inplace=True)\n",
    "loan_data['Loan_Amount_Term'].fillna(loan_data['Loan_Amount_Term'].mean(), inplace=True)\n",
    "loan_data['Credit_History'].fillna(loan_data['Credit_History'].mean(), inplace=True)\n",
    "\n",
    "features_select = [\n",
    "                    #'Loan_ID', \n",
    "                    'Gender', #\n",
    "                    'Married', \n",
    "                    'Dependents', \n",
    "                    'Education',\n",
    "                    'Self_Employed', \n",
    "                    'ApplicantIncome', \n",
    "                    'CoapplicantIncome', \n",
    "                    'LoanAmount',\n",
    "                    'Loan_Amount_Term', \n",
    "                    'Credit_History', \n",
    "                    'Property_Area', \n",
    "                    'Loan_Status'\n",
    "                    ]\n",
    "\n",
    "loan_data = loan_data[features_select]\n",
    "\n",
    "#loan_data['Dependents'][loan_data['Dependents'] == '3+'] = 4\n",
    "#loan_data['Dependents'] = loan_data['Dependents'].astype(int)\n",
    "\n",
    "#loan_data['Property_Area'][loan_data['Property_Area'] == 'Rural'] = 0\n",
    "#loan_data['Property_Area'][loan_data['Property_Area'] == 'Semiurban'] = 1\n",
    "#loan_data['Property_Area'][loan_data['Property_Area'] == 'Urban'] = 2\n",
    "#loan_data['Property_Area'] = loan_data['Property_Area'].astype(int)\n",
    "\n",
    "nominal_features_loan = [\n",
    "                        'Dependents',\n",
    "                        'Property_Area',    \n",
    "                        ]\n",
    "\n",
    "\n",
    "ordinal_features_loan = [\n",
    "                    'Education',\n",
    "                    'Gender', \n",
    "                    'Married', \n",
    "                    'Self_Employed',\n",
    "                   ]\n",
    "    \n",
    "X_data_loan = loan_data.drop(['Loan_Status'], axis = 1)\n",
    "y_data_loan = ((loan_data['Loan_Status'] == 'Y') * 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_train_network_loan_house = deepcopy(config)\n",
    "#config_train_network_loan_house['lambda_net']['batch_lambda'] = 64#16\n",
    "#config_train_network_loan_house['lambda_net']['learning_rate_lambda'] = 0.001\n",
    "#config_train_network_loan_house['lambda_net']['dropout_lambda'] = 0#.1\n",
    "#config_train_network_loan_house['lambda_net']['epochs_lambda'] = 500\n",
    "#config_train_network_loan_house['lambda_net']['optimizer_lambda'] = 'adam'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Loan House'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_loan, \n",
    "                                                                y_data_loan, \n",
    "                                                                nominal_features = nominal_features_loan, \n",
    "                                                                ordinal_features = ordinal_features_loan,\n",
    "                                                                #config = config_train_network_loan_house,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loan_credit_data = pd.read_csv('real_world_datasets/Credit Loan/train_split.csv', delimiter=',')\n",
    "\n",
    "loan_credit_data['emp_title'].fillna(loan_credit_data['emp_title'].mode()[0], inplace=True)\n",
    "loan_credit_data['emp_length'].fillna(loan_credit_data['emp_length'].mode()[0], inplace=True)\n",
    "#loan_credit_data['desc'].fillna(loan_credit_data['desc'].mode()[0], inplace=True)\n",
    "loan_credit_data['title'].fillna(loan_credit_data['title'].mode()[0], inplace=True)\n",
    "#loan_credit_data['mths_since_last_delinq'].fillna(loan_credit_data['mths_since_last_delinq'].mode()[0], inplace=True)\n",
    "#loan_credit_data['mths_since_last_record'].fillna(loan_credit_data['mths_since_last_record'].mode()[0], inplace=True)\n",
    "loan_credit_data['revol_util'].fillna(loan_credit_data['revol_util'].mode()[0], inplace=True)\n",
    "loan_credit_data['collections_12_mths_ex_med'].fillna(loan_credit_data['collections_12_mths_ex_med'].mode()[0], inplace=True)\n",
    "#loan_credit_data['mths_since_last_major_derog'].fillna(loan_credit_data['mths_since_last_major_derog'].mode()[0], inplace=True)\n",
    "#loan_credit_data['verification_status_joint'].fillna(loan_credit_data['verification_status_joint'].mode()[0], inplace=True)\n",
    "loan_credit_data['tot_coll_amt'].fillna(loan_credit_data['tot_coll_amt'].mode()[0], inplace=True)\n",
    "loan_credit_data['tot_cur_bal'].fillna(loan_credit_data['tot_cur_bal'].mode()[0], inplace=True)\n",
    "loan_credit_data['total_rev_hi_lim'].fillna(loan_credit_data['total_rev_hi_lim'].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "##remove too many null\n",
    "#'mths_since_last_delinq','mths_since_last_record', 'mths_since_last_major_derog','pymnt_plan','desc', 'verification_status_joint'\n",
    "\n",
    "\n",
    "features_select = [\n",
    "                    #'member_id', \n",
    "                    'loan_amnt', \n",
    "                    'funded_amnt', \n",
    "                    'funded_amnt_inv', \n",
    "                    'term',\n",
    "                    #'batch_enrolled',\n",
    "                    'int_rate', \n",
    "                    'grade', \n",
    "                    #'sub_grade', \n",
    "                    #'emp_title',\n",
    "                    'emp_length',\n",
    "                    'home_ownership', \n",
    "                    'annual_inc', \n",
    "                    'verification_status',\n",
    "                    #'pymnt_plan', \n",
    "                    #'desc', \n",
    "                    'purpose', \n",
    "                    'title', \n",
    "                    #'zip_code', \n",
    "                    #'addr_state',\n",
    "                    'dti', \n",
    "                    'delinq_2yrs', \n",
    "                    'inq_last_6mths', \n",
    "                    #'mths_since_last_delinq',\n",
    "                    #'mths_since_last_record',\n",
    "                    'open_acc', \n",
    "                    'pub_rec', \n",
    "                    'revol_bal',\n",
    "                    'revol_util', \n",
    "                    'total_acc', \n",
    "                    'initial_list_status', \n",
    "                    'total_rec_int',\n",
    "                    'total_rec_late_fee', \n",
    "                    'recoveries', \n",
    "                    'collection_recovery_fee',\n",
    "                    'collections_12_mths_ex_med', \n",
    "                    #'mths_since_last_major_derog',\n",
    "                    'application_type', \n",
    "                    #'verification_status_joint', \n",
    "                    'last_week_pay',\n",
    "                    'acc_now_delinq', \n",
    "                    'tot_coll_amt', \n",
    "                    'tot_cur_bal', \n",
    "                    'total_rev_hi_lim',\n",
    "                    'loan_status'\n",
    "                    ]\n",
    "\n",
    "loan_credit_data = loan_credit_data[features_select]\n",
    "\n",
    "nominal_features_loan_credit = [\n",
    "\n",
    "                        ]\n",
    "ordinal_features_loan_credit = [\n",
    "                    #'member_id', \n",
    "                    'loan_amnt', \n",
    "                    'funded_amnt', \n",
    "                    'funded_amnt_inv', \n",
    "                    'term',\n",
    "                    #'batch_enrolled',\n",
    "                    'int_rate', \n",
    "                    'grade', \n",
    "                    #'sub_grade', \n",
    "                    #'emp_title',\n",
    "                    'emp_length',\n",
    "                    'home_ownership', \n",
    "                    'annual_inc', \n",
    "                    'verification_status',\n",
    "                    #'pymnt_plan', \n",
    "                    #'desc', \n",
    "                    'purpose', \n",
    "                    'title', \n",
    "                    #'zip_code', \n",
    "                    #'addr_state',\n",
    "                    'dti', \n",
    "                    'delinq_2yrs', \n",
    "                    'inq_last_6mths', \n",
    "                    #'mths_since_last_delinq',\n",
    "                    #'mths_since_last_record',\n",
    "                    'open_acc', \n",
    "                    'pub_rec', \n",
    "                    'revol_bal',\n",
    "                    'revol_util', \n",
    "                    'total_acc', \n",
    "                    'initial_list_status', \n",
    "                    'total_rec_int',\n",
    "                    'total_rec_late_fee', \n",
    "                    'recoveries', \n",
    "                    'collection_recovery_fee',\n",
    "                    'collections_12_mths_ex_med', \n",
    "                    #'mths_since_last_major_derog',\n",
    "                    'application_type', \n",
    "                    #'verification_status_joint', \n",
    "                    'last_week_pay',\n",
    "                    'acc_now_delinq', \n",
    "                    'tot_coll_amt', \n",
    "                    'tot_cur_bal', \n",
    "                    'total_rev_hi_lim',\n",
    "                   ]\n",
    "    \n",
    "X_data_loan_credit = loan_credit_data.drop(['loan_status'], axis = 1)\n",
    "y_data_loan_credit = pd.Series(OrdinalEncoder().fit_transform(loan_credit_data['loan_status'].values.reshape(-1, 1)).flatten(), name='loan_status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Loan Credit'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_loan_credit, \n",
    "                                                                y_data_loan_credit, \n",
    "                                                                nominal_features = nominal_features_loan_credit, \n",
    "                                                                ordinal_features = ordinal_features_loan_credit,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medical_insurance_data = pd.read_csv('real_world_datasets/Medical Insurance/insurance.csv', delimiter=',')\n",
    "\n",
    "features_select = [\n",
    "                    'age', \n",
    "                    'sex', \n",
    "                    'bmi', \n",
    "                    'children', \n",
    "                    'smoker',\n",
    "                    'region',\n",
    "                    'charges'\n",
    "                    ]\n",
    "\n",
    "medical_insurance_data = medical_insurance_data[features_select]\n",
    "\n",
    "nominal_features_medical_insurance = [\n",
    "                    'region',\n",
    "                        ]\n",
    "ordinal_features_medical_insurance = [\n",
    "                    'sex',\n",
    "                    'smoker'\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_medical_insurance = medical_insurance_data.drop(['charges'], axis = 1)\n",
    "y_data_medical_insurance = ((medical_insurance_data['charges'] > 10_000) * 1)\n",
    "\n",
    "X_data_medical_insurance.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Medical Insurance'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_medical_insurance, \n",
    "                                                                y_data_medical_insurance, \n",
    "                                                                nominal_features = nominal_features_medical_insurance, \n",
    "                                                                ordinal_features = ordinal_features_medical_insurance,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bank_data = pd.read_csv('real_world_datasets/Bank Marketing/bank-full.csv', delimiter=';') #bank\n",
    "\n",
    "features_select = [\n",
    "                    'age',\n",
    "                    'job', \n",
    "                    'marital', \n",
    "                    'education', \n",
    "                    'default',\n",
    "                    'housing',\n",
    "                    'loan',\n",
    "                    #'contact',\n",
    "                    #'day',\n",
    "                    #'month',\n",
    "                    'duration',\n",
    "                    'campaign',\n",
    "                    'pdays',\n",
    "                    'previous',\n",
    "                    'poutcome',\n",
    "                    'y',\n",
    "                    ]\n",
    "\n",
    "bank_data = bank_data[features_select]\n",
    "\n",
    "nominal_features_bank = [\n",
    "                        'job',\n",
    "                        'education',\n",
    "                        #'contact',\n",
    "                        #'day',\n",
    "                        #'month',\n",
    "                        'poutcome',\n",
    "                        ]\n",
    "ordinal_features_bank = [\n",
    "                    'marital',\n",
    "                    'default',\n",
    "                    'housing',\n",
    "                    'loan',\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_bank = bank_data.drop(['y'], axis = 1)\n",
    "y_data_bank = pd.Series(OrdinalEncoder().fit_transform(bank_data['y'].values.reshape(-1, 1)).flatten(), name='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Bank Marketing'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_bank, \n",
    "                                                                y_data_bank, \n",
    "                                                                nominal_features = nominal_features_bank, \n",
    "                                                                ordinal_features = ordinal_features_bank,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cervical cancer (Risk Factors) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00383/risk_factors_cervical_cancer.csv', index_col=False)#, names=feature_names\n",
    "\n",
    "features_select = [\n",
    "                    'Age',\n",
    "                    'Number of sexual partners',\n",
    "                    'First sexual intercourse',\n",
    "                    'Num of pregnancies',\n",
    "                    'Smokes',\n",
    "                    'Smokes (years)',\n",
    "                    'Hormonal Contraceptives',\n",
    "                    'Hormonal Contraceptives (years)',\n",
    "                    'IUD',\n",
    "                    'IUD (years)',\n",
    "                    'STDs',\n",
    "                    'STDs (number)',\n",
    "                    'STDs: Number of diagnosis',\n",
    "                    'STDs: Time since first diagnosis',\n",
    "                    'STDs: Time since last diagnosis',\n",
    "                    'Biopsy'\n",
    "                    ]\n",
    "\n",
    "cc_data = cc_data[features_select]\n",
    "\n",
    "cc_data['Number of sexual partners'][cc_data['Number of sexual partners'] == '?'] = cc_data['Number of sexual partners'].mode()[0]\n",
    "cc_data['First sexual intercourse'][cc_data['First sexual intercourse'] == '?'] = cc_data['First sexual intercourse'].mode()[0]\n",
    "cc_data['Num of pregnancies'][cc_data['Num of pregnancies'] == '?'] = cc_data['Num of pregnancies'].mode()[0]\n",
    "cc_data['Smokes'][cc_data['Smokes'] == '?'] = cc_data['Smokes'].mode()[0]\n",
    "cc_data['Smokes (years)'][cc_data['Smokes (years)'] == '?'] = cc_data['Smokes (years)'].mode()[0]\n",
    "cc_data['Hormonal Contraceptives'][cc_data['Hormonal Contraceptives'] == '?'] = cc_data['Hormonal Contraceptives'].mode()[0]\n",
    "cc_data['Hormonal Contraceptives (years)'][cc_data['Hormonal Contraceptives (years)'] == '?'] = cc_data['Hormonal Contraceptives (years)'].mode()[0]\n",
    "cc_data['IUD'][cc_data['IUD'] == '?'] = cc_data['IUD'].mode()[0]\n",
    "cc_data['IUD (years)'][cc_data['IUD (years)'] == '?'] = cc_data['IUD (years)'].mode()[0]\n",
    "cc_data['STDs'][cc_data['STDs'] == '?'] = cc_data['STDs'].mode()[0]\n",
    "cc_data['STDs (number)'][cc_data['STDs (number)'] == '?'] = cc_data['STDs (number)'].mode()[0]\n",
    "cc_data['STDs: Time since first diagnosis'][cc_data['STDs: Time since first diagnosis'] == '?'] = cc_data['STDs: Time since first diagnosis'][cc_data['STDs: Time since first diagnosis'] != '?'].mode()[0]\n",
    "cc_data['STDs: Time since last diagnosis'][cc_data['STDs: Time since last diagnosis'] == '?'] = cc_data['STDs: Time since last diagnosis'][cc_data['STDs: Time since last diagnosis'] != '?'].mode()[0]\n",
    "\n",
    "nominal_features_cc = [\n",
    "                        ]\n",
    "ordinal_features_cc = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_cc = cc_data.drop(['Biopsy'], axis = 1)\n",
    "y_data_cc = pd.Series(OrdinalEncoder().fit_transform(cc_data['Biopsy'].values.reshape(-1, 1)).flatten(), name='Biopsy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Cervical Cancer'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_cc, \n",
    "                                                                y_data_cc, \n",
    "                                                                nominal_features = nominal_features_cc, \n",
    "                                                                ordinal_features = ordinal_features_cc,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brest Cancer Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'Sample code number',\n",
    "                'Clump Thickness',\n",
    "                'Uniformity of Cell Size',\n",
    "                'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion',\n",
    "                'Single Epithelial Cell Size',\n",
    "                'Bare Nuclei',\n",
    "                'Bland Chromatin',\n",
    "                'Normal Nucleoli',\n",
    "                'Mitoses',\n",
    "                'Class',\n",
    "                ]\n",
    "\n",
    "bcw_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', names=feature_names, index_col=False)\n",
    "\n",
    "bcw_data['Clump Thickness'][bcw_data['Clump Thickness'] == '?'] = bcw_data['Clump Thickness'].mode()[0]\n",
    "bcw_data['Uniformity of Cell Size'][bcw_data['Uniformity of Cell Size'] == '?'] = bcw_data['Uniformity of Cell Size'].mode()[0]\n",
    "bcw_data['Uniformity of Cell Shape'][bcw_data['Uniformity of Cell Shape'] == '?'] = bcw_data['Uniformity of Cell Shape'].mode()[0]\n",
    "bcw_data['Marginal Adhesion'][bcw_data['Marginal Adhesion'] == '?'] = bcw_data['Marginal Adhesion'].mode()[0]\n",
    "bcw_data['Single Epithelial Cell Size'][bcw_data['Single Epithelial Cell Size'] == '?'] = bcw_data['Single Epithelial Cell Size'].mode()[0]\n",
    "bcw_data['Bare Nuclei'][bcw_data['Bare Nuclei'] == '?'] = bcw_data['Bare Nuclei'].mode()[0]\n",
    "bcw_data['Bland Chromatin'][bcw_data['Bland Chromatin'] == '?'] = bcw_data['Bland Chromatin'].mode()[0]\n",
    "bcw_data['Normal Nucleoli'][bcw_data['Normal Nucleoli'] == '?'] = bcw_data['Normal Nucleoli'].mode()[0]\n",
    "bcw_data['Mitoses'][bcw_data['Mitoses'] == '?'] = bcw_data['Mitoses'].mode()[0]\n",
    "\n",
    "features_select = [\n",
    "                #'Sample code number',\n",
    "                'Clump Thickness',\n",
    "                'Uniformity of Cell Size',\n",
    "                'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion',\n",
    "                'Single Epithelial Cell Size',\n",
    "                'Bare Nuclei',\n",
    "                'Bland Chromatin',\n",
    "                'Normal Nucleoli',\n",
    "                'Mitoses',\n",
    "                'Class',\n",
    "                    ]\n",
    "\n",
    "bcw_data = bcw_data[features_select]\n",
    "\n",
    "nominal_features_bcw = [\n",
    "                        ]\n",
    "ordinal_features_bcw = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_bcw = bcw_data.drop(['Class'], axis = 1)\n",
    "y_data_bcw = pd.Series(OrdinalEncoder().fit_transform(bcw_data['Class'].values.reshape(-1, 1)).flatten(), name='Class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Brest Cancer Wisconsin'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_bcw, \n",
    "                                                                y_data_bcw, \n",
    "                                                                nominal_features = nominal_features_bcw, \n",
    "                                                                ordinal_features = ordinal_features_bcw,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin Diagnostic Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'ID number',\n",
    "                'Diagnosis',\n",
    "                'radius',# (mean of distances from center to points on the perimeter)\n",
    "                'texture',# (standard deviation of gray-scale values)\n",
    "                'perimeter',\n",
    "                'area',\n",
    "                'smoothness',# (local variation in radius lengths)\n",
    "                'compactness',# (perimeter^2 / area - 1.0)\n",
    "                'concavity',# (severity of concave portions of the contour)\n",
    "                'concave points',# (number of concave portions of the contour)\n",
    "                'symmetry',\n",
    "                'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                ]\n",
    "#Wisconsin Diagnostic Breast Cancer\n",
    "wdbc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', names=feature_names, index_col=False)\n",
    "\n",
    "features_select = [\n",
    "                    #'ID number',\n",
    "                    'Diagnosis',\n",
    "                    'radius',# (mean of distances from center to points on the perimeter)\n",
    "                    'texture',# (standard deviation of gray-scale values)\n",
    "                    'perimeter',\n",
    "                    'area',\n",
    "                    'smoothness',# (local variation in radius lengths)\n",
    "                    'compactness',# (perimeter^2 / area - 1.0)\n",
    "                    'concavity',# (severity of concave portions of the contour)\n",
    "                    'concave points',# (number of concave portions of the contour)\n",
    "                    'symmetry',\n",
    "                    'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                    ]\n",
    "\n",
    "wdbc_data = wdbc_data[features_select]\n",
    "\n",
    "nominal_features_wdbc = [\n",
    "                        ]\n",
    "ordinal_features_wdbc = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_wdbc = wdbc_data.drop(['Diagnosis'], axis = 1)\n",
    "y_data_wdbc= pd.Series(OrdinalEncoder().fit_transform(wdbc_data['Diagnosis'].values.reshape(-1, 1)).flatten(), name='Diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Wisconsin Diagnostic Breast Cancer'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_wdbc, \n",
    "                                                                y_data_wdbc, \n",
    "                                                                nominal_features = nominal_features_wdbc, \n",
    "                                                                ordinal_features = ordinal_features_wdbc,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin Prognostic Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'ID number',\n",
    "                'Diagnosis',\n",
    "                'radius',# (mean of distances from center to points on the perimeter)\n",
    "                'texture',# (standard deviation of gray-scale values)\n",
    "                'perimeter',\n",
    "                'area',\n",
    "                'smoothness',# (local variation in radius lengths)\n",
    "                'compactness',# (perimeter^2 / area - 1.0)\n",
    "                'concavity',# (severity of concave portions of the contour)\n",
    "                'concave points',# (number of concave portions of the contour)\n",
    "                'symmetry',\n",
    "                'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                ]\n",
    "#Wisconsin Prognostic Breast Cancer\n",
    "wpbc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wpbc.data', names=feature_names, index_col=False)\n",
    "\n",
    "features_select = [\n",
    "                    #'ID number',\n",
    "                    'Diagnosis',\n",
    "                    'radius',# (mean of distances from center to points on the perimeter)\n",
    "                    'texture',# (standard deviation of gray-scale values)\n",
    "                    'perimeter',\n",
    "                    'area',\n",
    "                    'smoothness',# (local variation in radius lengths)\n",
    "                    'compactness',# (perimeter^2 / area - 1.0)\n",
    "                    'concavity',# (severity of concave portions of the contour)\n",
    "                    'concave points',# (number of concave portions of the contour)\n",
    "                    'symmetry',\n",
    "                    'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                    ]\n",
    "\n",
    "wpbc_data = wpbc_data[features_select]\n",
    "\n",
    "nominal_features_wpbc = [\n",
    "                        ]\n",
    "ordinal_features_wpbc = [\n",
    "                   ]\n",
    " \n",
    "X_data_wpbc = wpbc_data.drop(['Diagnosis'], axis = 1)\n",
    "y_data_wpbc= pd.Series(OrdinalEncoder().fit_transform(wpbc_data['Diagnosis'].values.reshape(-1, 1)).flatten(), name='Diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Wisconsin Prognostic Breast Cancer'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_wpbc, \n",
    "                                                                y_data_wpbc, \n",
    "                                                                nominal_features = nominal_features_wpbc, \n",
    "                                                                ordinal_features = ordinal_features_wpbc,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'Sex',#\t\tnominal\t\t\tM, F, and I (infant)\n",
    "                'Length',#\tcontinuous\tmm\tLongest shell measurement\n",
    "                'Diameter',#\tcontinuous\tmm\tperpendicular to length\n",
    "                'Height',#\t\tcontinuous\tmm\twith meat in shell\n",
    "                'Whole weight',#\tcontinuous\tgrams\twhole abalone\n",
    "                'Shucked weight',#\tcontinuous\tgrams\tweight of meat\n",
    "                'Viscera weight',#\tcontinuous\tgrams\tgut weight (after bleeding)\n",
    "                'Shell weight',#\tcontinuous\tgrams\tafter being dried\n",
    "                'Rings',#\t\tinteger\t\t\t+1.5 gives the age in years\n",
    "                ]\n",
    "\n",
    "abalone_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data', names=feature_names, index_col=False)\n",
    "\n",
    "\n",
    "features_select = [\n",
    "                'Sex',#\t\tnominal\t\t\tM, F, and I (infant)\n",
    "                'Length',#\tcontinuous\tmm\tLongest shell measurement\n",
    "                'Diameter',#\tcontinuous\tmm\tperpendicular to length\n",
    "                'Height',#\t\tcontinuous\tmm\twith meat in shell\n",
    "                'Whole weight',#\tcontinuous\tgrams\twhole abalone\n",
    "                'Shucked weight',#\tcontinuous\tgrams\tweight of meat\n",
    "                'Viscera weight',#\tcontinuous\tgrams\tgut weight (after bleeding)\n",
    "                'Shell weight',#\tcontinuous\tgrams\tafter being dried\n",
    "                'Rings',#\t\tinteger\t\t\t+1.5 gives the age in years\n",
    "                    ]\n",
    "\n",
    "abalone_data = abalone_data[features_select]\n",
    "\n",
    "nominal_features_abalone = [\n",
    "                        'Sex',\n",
    "                        ]\n",
    "ordinal_features_abalone = [\n",
    "                   ]\n",
    "   \n",
    "X_data_abalone = abalone_data.drop(['Rings'], axis = 1)\n",
    "y_data_abalone = ((abalone_data['Rings'] > 10) * 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Abalone'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_abalone, \n",
    "                                                                y_data_abalone, \n",
    "                                                                nominal_features = nominal_features_abalone, \n",
    "                                                                ordinal_features = ordinal_features_abalone,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "   'buying',#       v-high, high, med, low\n",
    "   'maint',#        v-high, high, med, low\n",
    "   'doors',#        2, 3, 4, 5-more\n",
    "   'persons',#      2, 4, more\n",
    "   'lug_boot',#     small, med, big\n",
    "   'safety',#       low, med, high\n",
    "   'class',#        unacc, acc, good, v-good\n",
    "                ]\n",
    "\n",
    "car_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=feature_names, index_col=False)\n",
    "\n",
    "features_select = [\n",
    "                   'buying',#       v-high, high, med, low\n",
    "                   'maint',#        v-high, high, med, low\n",
    "                   'doors',#        2, 3, 4, 5-more\n",
    "                   'persons',#      2, 4, more\n",
    "                   'lug_boot',#     small, med, big\n",
    "                   'safety',#       low, med, high\n",
    "                   'class',#        unacc, acc, good, v-good\n",
    "                    ]\n",
    "\n",
    "car_data = car_data[features_select]\n",
    "\n",
    "nominal_features_car = [\n",
    "                       'buying',#       v-high, high, med, low\n",
    "                       'maint',#        v-high, high, med, low\n",
    "                       'doors',#        2, 3, 4, 5-more\n",
    "                       'persons',#      2, 4, more\n",
    "                       'lug_boot',#     small, med, big\n",
    "                       'safety',#       low, med, high\n",
    "                        ]\n",
    "\n",
    "ordinal_features_car = [\n",
    "                   ]\n",
    "\n",
    "\n",
    "    \n",
    "X_data_car = car_data.drop(['class'], axis = 1)\n",
    "y_data_car = ((car_data['class'] != 'unacc') * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Car'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_car, \n",
    "                                                                y_data_car, \n",
    "                                                                nominal_features = nominal_features_car, \n",
    "                                                                ordinal_features = ordinal_features_car,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "   'age',#      \n",
    "   'sex',#   \n",
    "   'cp',#      \n",
    "   'trestbps',#\n",
    "   'chol',#    \n",
    "   'fbs',#      \n",
    "   'restecg',# \n",
    "   'thalach',#      \n",
    "   'exang',#   \n",
    "   'oldpeak',#      \n",
    "   'slope',#\n",
    "   'ca',#    \n",
    "   'thal',#      \n",
    "   'num',#     \n",
    "                ]\n",
    "\n",
    "heart_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data', names=feature_names, index_col=False) #, delimiter=' '\n",
    "print(heart_data.shape)\n",
    "\n",
    "\n",
    "nominal_features_heart = [\n",
    "                        ]\n",
    "\n",
    "ordinal_features_heart = [\n",
    "                   ]\n",
    "\n",
    "\n",
    "heart_data['age'][heart_data['age'] == '?'] = heart_data['age'].mode()[0]\n",
    "heart_data['sex'][heart_data['sex'] == '?'] = heart_data['sex'].mode()[0]\n",
    "heart_data['cp'][heart_data['cp'] == '?'] = heart_data['cp'].mode()[0]\n",
    "heart_data['trestbps'][heart_data['trestbps'] == '?'] = heart_data['trestbps'].mode()[0]\n",
    "heart_data['chol'][heart_data['chol'] == '?'] = heart_data['chol'].mode()[0]\n",
    "heart_data['fbs'][heart_data['fbs'] == '?'] = heart_data['fbs'].mode()[0]\n",
    "heart_data['restecg'][heart_data['restecg'] == '?'] = heart_data['restecg'].mode()[0]\n",
    "heart_data['thalach'][heart_data['thalach'] == '?'] = heart_data['thalach'].mode()[0]\n",
    "heart_data['exang'][heart_data['exang'] == '?'] = heart_data['exang'].mode()[0]\n",
    "heart_data['oldpeak'][heart_data['oldpeak'] == '?'] = heart_data['oldpeak'].mode()[0]\n",
    "heart_data['slope'][heart_data['slope'] == '?'] = heart_data['slope'].mode()[0]\n",
    "heart_data['ca'][heart_data['ca'] == '?'] = heart_data['ca'].mode()[0]\n",
    "heart_data['thal'][heart_data['thal'] == '?'] = heart_data['thal'].mode()[0]\n",
    "    \n",
    "X_data_heart = heart_data.drop(['num'], axis = 1)\n",
    "y_data_heart = ((heart_data['num'] < 1) * 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Heart Disease'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_heart, \n",
    "                                                                y_data_heart, \n",
    "                                                                nominal_features = nominal_features_heart, \n",
    "                                                                ordinal_features = ordinal_features_heart,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "credit_card_data = pd.read_csv('./real_world_datasets/UCI_Credit_Card/UCI_Credit_Card.csv', index_col=False) #, delimiter=' '\n",
    "credit_card_data = credit_card_data.drop(['ID'], axis = 1)\n",
    "print(credit_card_data.shape)\n",
    "\n",
    "nominal_features_credit_card = [\n",
    "                        ]\n",
    "\n",
    "ordinal_features_credit_card = [\n",
    "                   ]\n",
    "    \n",
    "X_data_credit_card = credit_card_data.drop(['default.payment.next.month'], axis = 1)\n",
    "y_data_credit_card = ((credit_card_data['default.payment.next.month'] < 1) * 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Credit Card'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_credit_card, \n",
    "                                                                y_data_credit_card, \n",
    "                                                                nominal_features = nominal_features_credit_card, \n",
    "                                                                ordinal_features = ordinal_features_credit_card,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haberman's Survival Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "   'age',#      \n",
    "   'year',#   \n",
    "   'nodes_detected',#      \n",
    "   'survival',#     \n",
    "                ]\n",
    "\n",
    "haberman_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data', names=feature_names, index_col=False) #, delimiter=' '\n",
    "print(haberman_data.shape)\n",
    "\n",
    "\n",
    "nominal_features_haberman = [\n",
    "                        ]\n",
    "\n",
    "ordinal_features_haberman = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_haberman = haberman_data.drop(['survival'], axis = 1)\n",
    "y_data_haberman = ((haberman_data['survival'] < 2) * 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Haberman'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_haberman, \n",
    "                                                                y_data_haberman, \n",
    "                                                                nominal_features = nominal_features_haberman, \n",
    "                                                                ordinal_features = ordinal_features_haberman,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure_data = pd.read_csv('real_world_datasets/Heart Failure/heart_failure_clinical_records_dataset.csv', delimiter=',')\n",
    "\n",
    "\n",
    "nominal_features_heart_failure = [\n",
    "                        ]\n",
    "ordinal_features_heart_failure = [\n",
    "\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_heart_failure = heart_failure_data.drop(['DEATH_EVENT'], axis = 1)\n",
    "y_data_heart_failure = ((heart_failure_data['DEATH_EVENT'] > 0) * 1)\n",
    "\n",
    "X_data_heart_failure.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 'Heart Failure'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_heart_failure, \n",
    "                                                                y_data_heart_failure, \n",
    "                                                                nominal_features = nominal_features_heart_failure, \n",
    "                                                                ordinal_features = ordinal_features_heart_failure,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list_reduced = deepcopy(identifier_list)\n",
    "for identifier in identifier_list:\n",
    "    if test_network_list[identifier] is None:\n",
    "        identifier_list_reduced.remove(identifier)\n",
    "\n",
    "try:\n",
    "    #print_complete_performance_evaluation_results(results_dict, identifier_list, dataset_size_list, dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    complete_performance_evaluation_results = get_complete_performance_evaluation_results_dataframe(results_dict, \n",
    "                                                                                                    identifier_list_reduced, \n",
    "                                                                                                    dataset_size_list,\n",
    "                                                                                                    dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    display(complete_performance_evaluation_results.head(20))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    #print_complete_performance_evaluation_results(results_dict, identifier_list, dataset_size_list, dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    complete_performance_evaluation_results = get_complete_performance_evaluation_results_dataframe_all_distrib(results_dict, \n",
    "                                                                                                                identifier_list_reduced, \n",
    "                                                                                                                dataset_size_list,\n",
    "                                                                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                                                                dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    display(complete_performance_evaluation_results.head(20))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#print_network_distances(distances_dict)\n",
    "network_distances = get_print_network_distances_dataframe(distances_dict)\n",
    "display(network_distances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if different_eval_data:\n",
    "    flat_config = flatten_dict(config_train)\n",
    "else:\n",
    "    flat_config = flatten_dict(config)    \n",
    "\n",
    "flat_dict_train = flatten_dict(inet_evaluation_result_dict_train)\n",
    "flat_dict_valid = flatten_dict(inet_evaluation_result_dict_valid)\n",
    "if not evaluate_distribution:\n",
    "    flat_dict_test = flatten_dict(inet_evaluation_result_dict_test)\n",
    "else:\n",
    "    flat_dict_test = flatten_dict(inet_evaluation_result_dict_complete_by_distribution_test)\n",
    "\n",
    "header_column = ''  \n",
    "\n",
    "for key in flat_config.keys():\n",
    "    header_column += key\n",
    "    header_column += ';'     \n",
    "\n",
    "number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "for key in flat_dict_train.keys():\n",
    "    #if 'function_values' not in key:\n",
    "    for i in range(number_of_evaluated_networks):\n",
    "        header_column += key + '_train_' + str(i) + ';'  \n",
    "\n",
    "number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "for key in flat_dict_valid.keys():\n",
    "    #if 'function_values' not in key:\n",
    "    for i in range(number_of_evaluated_networks):\n",
    "        header_column += key + '_valid_' + str(i) + ';'       \n",
    "\n",
    "number_of_evaluated_networks = np.array(flat_dict_test[list(flat_dict_test.keys())[0]]).shape[0]\n",
    "for key in flat_dict_test.keys():\n",
    "    #if 'function_values' not in key:\n",
    "    for i in range(number_of_evaluated_networks):\n",
    "        header_column += key + '_test_' + str(i) + ';'          \n",
    "\n",
    "header_column += '\\n'\n",
    "\n",
    "\n",
    "if os.path.exists(writepath_complete):        \n",
    "    with open(writepath_complete, 'r') as text_file: \n",
    "        lines = text_file.readlines()\n",
    "    \n",
    "    counter = 1\n",
    "    while lines[0] != header_column:  \n",
    "        writepath_complete = './results_complete-' + str(counter) + '.csv' \n",
    "        if os.path.exists(writepath_complete):\n",
    "            with open(writepath_complete, 'r') as text_file: \n",
    "                lines = text_file.readlines()\n",
    "        else:\n",
    "            break\n",
    "        counter += 1\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file: \n",
    "        text_file.write(header_column)\n",
    "\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file:  \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "            \n",
    "        \n",
    "    number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_train.items():\n",
    "        #if 'function_values' not in key:\n",
    "        for score in values:\n",
    "            text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_valid.items():\n",
    "        #if 'function_values' not in key:\n",
    "        for score in values:\n",
    "            text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_test[list(flat_dict_test.keys())[0]]).shape[0]\n",
    "    for key, values in flat_dict_test.items():\n",
    "        #if 'function_values' not in key:\n",
    "        for score in values:\n",
    "            text_file.write(str(score) + ';')   \n",
    "                    \n",
    "    text_file.write('\\n')            \n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inet_evaluation_result_dict_mean_train_flat = flatten_dict(inet_evaluation_result_dict_mean_train)\n",
    "inet_evaluation_result_dict_mean_valid_flat = flatten_dict(inet_evaluation_result_dict_mean_valid)\n",
    "if not evaluate_distribution:\n",
    "    inet_evaluation_result_dict_mean_test_flat = flatten_dict(inet_evaluation_result_dict_mean_test)\n",
    "else:\n",
    "    inet_evaluation_result_dict_mean_test_flat = flatten_dict(inet_evaluation_result_dict_mean_by_distribution_test)\n",
    "\n",
    "#identifier_list_synthetic = ['train', 'valid', 'test']\n",
    "identifier_list_combined = list(flatten_list([identifier_list, ['train', 'valid', 'test']]))\n",
    "\n",
    "header_column = ''\n",
    "\n",
    "for key in flat_config.keys():\n",
    "    header_column += key + ';'\n",
    "\n",
    "for key in inet_evaluation_result_dict_mean_train_flat.keys():\n",
    "    header_column += 'train_' + key + ';'\n",
    "for key in inet_evaluation_result_dict_mean_valid_flat.keys():\n",
    "    header_column += 'valid_' + key + ';'          \n",
    "for key in inet_evaluation_result_dict_mean_test_flat.keys():\n",
    "    header_column += 'test_' + key + ';'                \n",
    "\n",
    "for dataset_size in dataset_size_list:\n",
    "    for identifier in identifier_list:\n",
    "        results_dict_flat = flatten_dict(results_dict[identifier][-2])\n",
    "        #del results_dict_flat['function_values_y_test_inet_dt']\n",
    "        #del results_dict_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "        for key in results_dict_flat.keys():\n",
    "            header_column += key + '_' + identifier + '_' + str(dataset_size) + ';'                                   \n",
    "\n",
    "for key in distances_dict['train'].keys():\n",
    "    for identifier in identifier_list_combined:\n",
    "        header_column += key + '_' + identifier + ';' \n",
    "\n",
    "header_column += '\\n'\n",
    " \n",
    "if os.path.exists(writepath_summary):        \n",
    "    with open(writepath_summary, 'r') as text_file: \n",
    "        lines = text_file.readlines()\n",
    "\n",
    "    counter = 1\n",
    "    while lines[0] != header_column:  \n",
    "        writepath_summary = './results_summary-' + str(counter) + '.csv' \n",
    "        if os.path.exists(writepath_summary):\n",
    "            with open(writepath_summary, 'r') as text_file: \n",
    "                lines = text_file.readlines()\n",
    "        else:\n",
    "            break\n",
    "        counter += 1\n",
    "\n",
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "        text_file.write(header_column)\n",
    "\n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "        \n",
    "    for value in inet_evaluation_result_dict_mean_train_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "    for value in inet_evaluation_result_dict_mean_valid_flat.values():\n",
    "        text_file.write(str(value) + ';')            \n",
    "    for value in inet_evaluation_result_dict_mean_test_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "\n",
    "    for i in range(len(dataset_size_list)):\n",
    "        for identifier in identifier_list:\n",
    "            evaluation_result_dict_flat = flatten_dict(evaluation_result_dict[identifier])\n",
    "            #del evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "            #del evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "            \n",
    "            for key, values in evaluation_result_dict_flat.items():\n",
    "                text_file.write(str(values[i]) + ';')    #values[i]        \n",
    "     \n",
    "    for key in distances_dict['train'].keys():\n",
    "        for identifier in identifier_list_combined:\n",
    "            text_file.write(str(distances_dict[identifier][key]) + ';')      \n",
    "    \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myBA",
   "language": "python",
   "name": "myba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
