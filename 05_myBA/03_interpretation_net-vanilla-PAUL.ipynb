{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Specification of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnpassen: \\n\\nnumber_of_variables --> anzahl variablen\\n\\nlambda_dataset_size --> datensatz größe für training von lambda-nets\\nnumber_of_generated_datasets and  number_of_trained_lambda_nets and interpretation_dataset_size --> anzahl der lambda-nets\\n\\nlambda net --> alles wie in notebook 2\\n\\ni net -->\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Anpassen: \n",
    "\n",
    "number_of_variables --> anzahl variablen\n",
    "\n",
    "lambda_dataset_size --> datensatz größe für training von lambda-nets\n",
    "number_of_generated_datasets and  number_of_trained_lambda_nets and interpretation_dataset_size --> anzahl der lambda-nets\n",
    "\n",
    "lambda net --> alles wie in notebook 2\n",
    "\n",
    "i net -->\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 3,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'vanilla', #'SDT', 'vanilla'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 10, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [],\n",
    "        \n",
    "        'use_distribution_list': True,\n",
    "        'random_parameters_distribution': True, ##MAKEPATH DIFFERENT FILES\n",
    "        'max_distributions_per_class': 1, # None; 0; int >= 1  \n",
    "        'exclude_linearly_seperable': False,\n",
    "        'data_generation_filtering': False,\n",
    "        'fixed_class_probability': False,\n",
    "        'balanced_data': False,\n",
    "        'weighted_data_generation': False,\n",
    "        'shift_distrib': False,\n",
    "        \n",
    "        'dt_type_train': 'vanilla', # (None, 'vanilla', 'SDT')\n",
    "        'maximum_depth_train': 3, #None or int\n",
    "        'decision_sparsity_train': 1, #None or int\n",
    "        \n",
    "        'function_generation_type': 'make_classification',# 'make_classification_distribution', 'make_classification_distribution_trained', 'distribution', 'distribution_trained', 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'distrib_by_feature': True,\n",
    "        'distribution_list': ['uniform', 'normal', 'gamma', 'beta', 'poisson'],#['uniform', 'gamma', 'poisson', 'exponential', 'weibull'],#['uniform', 'normal', 'gamma', 'exponential', 'beta', 'binomial', 'poisson'], \n",
    "        'distribution_list_eval': ['uniform', 'normal', 'gamma', 'beta', 'poisson'],#['uniform', 'gamma', 'poisson', 'exponential', 'weibull'],#['uniform', 'normal', 'gamma', 'beta', 'poisson'],\n",
    "        \n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        'number_of_generated_datasets': 100,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "        \n",
    "        'data_noise': 0, #None or float\n",
    "        \n",
    "        'distrib_param_max': 5,\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-3,\n",
    "        'restore_best_weights': True,\n",
    "        'patience_lambda': 50,\n",
    "        \n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'use_batchnorm_lambda': False,\n",
    "        \n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 100,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        #'dense_layers': [1024, 1024, 256, 2048, 2048],\n",
    "        'dense_layers': [1792, 512, 512],\n",
    "        #'dense_layers': [1792, 512, 512],\n",
    "        \n",
    "        #'dropout': [0, 0, 0, 0, 0.3],#[0.3, 0.3, 0.3, 0.3, 0.3],\n",
    "        'dropout': [0, 0, 0.5],\n",
    "        #'dropout': [0, 0, 0.5],\n",
    "\n",
    "        #'hidden_activation': 'relu',\n",
    "        'hidden_activation': 'sigmoid',\n",
    "        #'hidden_activation': 'swish',\n",
    "\n",
    "        #'optimizer': 'rmsprop', \n",
    "        'optimizer': 'adam', \n",
    "        #'optimizer': 'adam', \n",
    "        \n",
    "        #'learning_rate': 0.001,\n",
    "        'learning_rate': 0.001,\n",
    "        #'learning_rate': 0.001, \n",
    "        \n",
    "        'separate_weight_bias': False,\n",
    "        \n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,        \n",
    "        'additional_hidden': False,\n",
    "        \n",
    "        'loss': 'binary_crossentropy', #mse; binary_crossentropy; 'binary_accuracy'\n",
    "        'metrics': ['binary_accuracy'], #soft_ or _penalized\n",
    "        \n",
    "        'epochs': 500, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 100,\n",
    "                \n",
    "        'test_size': 5, #Float for fraction, Int for number 0\n",
    "        'evaluate_distribution': True,\n",
    "        'force_evaluate_real_world': False,\n",
    "        \n",
    "        'function_representation_type': 5, # 1=standard representation; 2=sparse representation with classification for variables; 3=softmax to select classes (n top probabilities)\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2,3) #3=autoencoder dimensionality reduction\n",
    "        \n",
    "        'resampling_strategy': None,#'ADASYN', #'SMOTE', None\n",
    "        'resampling_threshold': 0.25,#0.2,\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 60,\n",
    "        'nas_optimizer': 'greedy' #'hyperband',#\"bayesian\",'greedy', 'random'\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "        \n",
    "        'number_of_random_evaluations_per_distribution': 10,\n",
    "        'random_evaluation_dataset_size_per_distribution': 10_000, \n",
    "        'optimize_sampling': True,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'random_evaluation_dataset_distribution': 'uniform', \n",
    "        \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        #'sklearn_dt_benchmark': False,\n",
    "        #'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': False,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 15,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 42,   \n",
    "        'verbosity': 0\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(config)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth)  if function_representation_type >= 3 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes if function_representation_type >= 3 and dt_type == 'SDT'\n",
    "  else None\n",
    "                                                            )\n",
    "\n",
    "\n",
    "if distrib_by_feature:\n",
    "    config['evaluation']['random_evaluation_dataset_distribution'] = config['data']['distribution_list_eval']\n",
    "    config['data']['distribution_list'] = [config['data']['distribution_list']]\n",
    "    config['data']['distribution_list_eval'] = [config['data']['distribution_list_eval']]\n",
    "  \n",
    "    \n",
    "\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets100_var10_class2_make_classification_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_noBalance_noBalance/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1792-512-512_drop0-0-0.5e500b256_adam_funcRep5_reshapeNone\n",
      "lNetSize5000_numLNets100_var10_class2_make_classification_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_noBalance_noBalance/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['data']['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    \n",
    "    \n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'\n",
    "    \n",
    "    if True:\n",
    "        path_X_data = './data/saved_function_lists/X_data_' + path_dict['path_identifier_function_data'] + '.pkl'\n",
    "        with open(path_X_data, 'rb') as f:\n",
    "            X_data_list = pickle.load(f)\n",
    "\n",
    "        path_y_data = './data/saved_function_lists/y_data_' + path_dict['path_identifier_function_data'] + '.pkl'\n",
    "        with open(path_y_data, 'rb') as f:\n",
    "            y_data_list = pickle.load(f)        \n",
    "            \n",
    "    path_distribution_parameters = directory + '/' + 'distribution_parameters' + '.txt'\n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    \n",
    "    try:\n",
    "        distribution_parameters = pd.read_csv(path_distribution_parameters, sep=\",\", header=None)\n",
    "        distribution_parameters = distribution_parameters.sort_values(by=0)\n",
    "    except:\n",
    "        distribution_parameters = pd.DataFrame([None] * network_parameters.shape[0])\n",
    "    \n",
    "    #if no_noise == False:\n",
    "    #    network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    #    distribution_parameters = distribution_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              distribution_parameters_row,\n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              X_test_network[1].values,\n",
    "                                              y_test_network[1].values,\n",
    "                                              config) for X_test_network, y_test_network, network_parameters_row, distribution_parameters_row in zip(X_data_list[:config['i_net']['interpretation_dataset_size']], \n",
    "                                                                                                                                                     y_data_list[:config['i_net']['interpretation_dataset_size']], \n",
    "                                                                                                                                                     network_parameters.values[:config['i_net']['interpretation_dataset_size']], \n",
    "                                                                                                                                                     distribution_parameters.values[:config['i_net']['interpretation_dataset_size']]))        \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=15)]: Done 100 out of 100 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "\n",
    "    lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "    lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "    if test_size > 0 and not evaluate_distribution:\n",
    "        lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "    else:\n",
    "        lambda_net_dataset_test = None\n",
    "        lambda_net_dataset_valid = lambda_net_dataset_eval\n",
    "        \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    if test_size > 0 and not evaluate_distribution:\n",
    "        lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    \n",
    "    else:\n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset, test_split=0.1)    \n",
    "        lambda_net_dataset_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "### Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 1561)\n",
      "(10, 1561)\n"
     ]
    }
   ],
   "source": [
    "print(lambda_net_dataset_train.shape)\n",
    "print(lambda_net_dataset_valid.shape)\n",
    "if test_size > 0 and not evaluate_distribution:\n",
    "    print(lambda_net_dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>split0</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>split6</th>\n",
       "      <th>lp0</th>\n",
       "      <th>lp1</th>\n",
       "      <th>lp2</th>\n",
       "      <th>lp3</th>\n",
       "      <th>lp4</th>\n",
       "      <th>lp5</th>\n",
       "      <th>lp6</th>\n",
       "      <th>lp7</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "      <th>wb_61</th>\n",
       "      <th>wb_62</th>\n",
       "      <th>wb_63</th>\n",
       "      <th>wb_64</th>\n",
       "      <th>wb_65</th>\n",
       "      <th>wb_66</th>\n",
       "      <th>wb_67</th>\n",
       "      <th>wb_68</th>\n",
       "      <th>wb_69</th>\n",
       "      <th>wb_70</th>\n",
       "      <th>wb_71</th>\n",
       "      <th>wb_72</th>\n",
       "      <th>wb_73</th>\n",
       "      <th>wb_74</th>\n",
       "      <th>wb_75</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1437</th>\n",
       "      <th>wb_1438</th>\n",
       "      <th>wb_1439</th>\n",
       "      <th>wb_1440</th>\n",
       "      <th>wb_1441</th>\n",
       "      <th>wb_1442</th>\n",
       "      <th>wb_1443</th>\n",
       "      <th>wb_1444</th>\n",
       "      <th>wb_1445</th>\n",
       "      <th>wb_1446</th>\n",
       "      <th>wb_1447</th>\n",
       "      <th>wb_1448</th>\n",
       "      <th>wb_1449</th>\n",
       "      <th>wb_1450</th>\n",
       "      <th>wb_1451</th>\n",
       "      <th>wb_1452</th>\n",
       "      <th>wb_1453</th>\n",
       "      <th>wb_1454</th>\n",
       "      <th>wb_1455</th>\n",
       "      <th>wb_1456</th>\n",
       "      <th>wb_1457</th>\n",
       "      <th>wb_1458</th>\n",
       "      <th>wb_1459</th>\n",
       "      <th>wb_1460</th>\n",
       "      <th>wb_1461</th>\n",
       "      <th>wb_1462</th>\n",
       "      <th>wb_1463</th>\n",
       "      <th>wb_1464</th>\n",
       "      <th>wb_1465</th>\n",
       "      <th>wb_1466</th>\n",
       "      <th>wb_1467</th>\n",
       "      <th>wb_1468</th>\n",
       "      <th>wb_1469</th>\n",
       "      <th>wb_1470</th>\n",
       "      <th>wb_1471</th>\n",
       "      <th>wb_1472</th>\n",
       "      <th>wb_1473</th>\n",
       "      <th>wb_1474</th>\n",
       "      <th>wb_1475</th>\n",
       "      <th>wb_1476</th>\n",
       "      <th>wb_1477</th>\n",
       "      <th>wb_1478</th>\n",
       "      <th>wb_1479</th>\n",
       "      <th>wb_1480</th>\n",
       "      <th>wb_1481</th>\n",
       "      <th>wb_1482</th>\n",
       "      <th>wb_1483</th>\n",
       "      <th>wb_1484</th>\n",
       "      <th>wb_1485</th>\n",
       "      <th>wb_1486</th>\n",
       "      <th>wb_1487</th>\n",
       "      <th>wb_1488</th>\n",
       "      <th>wb_1489</th>\n",
       "      <th>wb_1490</th>\n",
       "      <th>wb_1491</th>\n",
       "      <th>wb_1492</th>\n",
       "      <th>wb_1493</th>\n",
       "      <th>wb_1494</th>\n",
       "      <th>wb_1495</th>\n",
       "      <th>wb_1496</th>\n",
       "      <th>wb_1497</th>\n",
       "      <th>wb_1498</th>\n",
       "      <th>wb_1499</th>\n",
       "      <th>wb_1500</th>\n",
       "      <th>wb_1501</th>\n",
       "      <th>wb_1502</th>\n",
       "      <th>wb_1503</th>\n",
       "      <th>wb_1504</th>\n",
       "      <th>wb_1505</th>\n",
       "      <th>wb_1506</th>\n",
       "      <th>wb_1507</th>\n",
       "      <th>wb_1508</th>\n",
       "      <th>wb_1509</th>\n",
       "      <th>wb_1510</th>\n",
       "      <th>wb_1511</th>\n",
       "      <th>wb_1512</th>\n",
       "      <th>wb_1513</th>\n",
       "      <th>wb_1514</th>\n",
       "      <th>wb_1515</th>\n",
       "      <th>wb_1516</th>\n",
       "      <th>wb_1517</th>\n",
       "      <th>wb_1518</th>\n",
       "      <th>wb_1519</th>\n",
       "      <th>wb_1520</th>\n",
       "      <th>wb_1521</th>\n",
       "      <th>wb_1522</th>\n",
       "      <th>wb_1523</th>\n",
       "      <th>wb_1524</th>\n",
       "      <th>wb_1525</th>\n",
       "      <th>wb_1526</th>\n",
       "      <th>wb_1527</th>\n",
       "      <th>wb_1528</th>\n",
       "      <th>wb_1529</th>\n",
       "      <th>wb_1530</th>\n",
       "      <th>wb_1531</th>\n",
       "      <th>wb_1532</th>\n",
       "      <th>wb_1533</th>\n",
       "      <th>wb_1534</th>\n",
       "      <th>wb_1535</th>\n",
       "      <th>wb_1536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.528</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.729</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.893</td>\n",
       "      <td>-1.760</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-1.921</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.729</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.947</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.075</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.725</td>\n",
       "      <td>5.630</td>\n",
       "      <td>-6.076</td>\n",
       "      <td>4.953</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>7.220</td>\n",
       "      <td>1.927</td>\n",
       "      <td>-3.182</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-4.596</td>\n",
       "      <td>1.360</td>\n",
       "      <td>-2.168</td>\n",
       "      <td>1.388</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.830</td>\n",
       "      <td>1.888</td>\n",
       "      <td>5.951</td>\n",
       "      <td>-4.067</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-1.008</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>-3.569</td>\n",
       "      <td>1.674</td>\n",
       "      <td>-2.855</td>\n",
       "      <td>5.301</td>\n",
       "      <td>0.626</td>\n",
       "      <td>-3.545</td>\n",
       "      <td>-10.063</td>\n",
       "      <td>-5.600</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-11.072</td>\n",
       "      <td>0.977</td>\n",
       "      <td>-1.256</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>5.518</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-2.092</td>\n",
       "      <td>-1.803</td>\n",
       "      <td>2.098</td>\n",
       "      <td>-5.108</td>\n",
       "      <td>-2.135</td>\n",
       "      <td>5.704</td>\n",
       "      <td>1.324</td>\n",
       "      <td>6.711</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-2.206</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-7.629</td>\n",
       "      <td>-1.147</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.685</td>\n",
       "      <td>5.215</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-1.485</td>\n",
       "      <td>4.089</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>1.706</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>1.276</td>\n",
       "      <td>2.835</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-1.329</td>\n",
       "      <td>4.157</td>\n",
       "      <td>2.636</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-3.702</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-2.785</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>3.270</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-3.025</td>\n",
       "      <td>-2.604</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.951</td>\n",
       "      <td>-3.261</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-5.743</td>\n",
       "      <td>-3.393</td>\n",
       "      <td>-2.951</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.573</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.767</td>\n",
       "      <td>1.368</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.727</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>1.627</td>\n",
       "      <td>-5.102</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>1.183</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-3.638</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-2.678</td>\n",
       "      <td>0.552</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>1.215</td>\n",
       "      <td>-2.516</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-2.775</td>\n",
       "      <td>2.915</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-1.283</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-2.325</td>\n",
       "      <td>-4.131</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>5.576</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-2.344</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-1.888</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1.789</td>\n",
       "      <td>3.516</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-2.574</td>\n",
       "      <td>5.133</td>\n",
       "      <td>-2.119</td>\n",
       "      <td>-4.241</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-4.740</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>4.229</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-3.275</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>4.095</td>\n",
       "      <td>1.432</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>-2.533</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>3.194</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>6.026</td>\n",
       "      <td>3.244</td>\n",
       "      <td>4.304</td>\n",
       "      <td>0.175</td>\n",
       "      <td>2.786</td>\n",
       "      <td>3.910</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-3.452</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-1.258</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.613</td>\n",
       "      <td>3.455</td>\n",
       "      <td>3.631</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.494</td>\n",
       "      <td>7.303</td>\n",
       "      <td>1.316</td>\n",
       "      <td>-2.111</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3.864</td>\n",
       "      <td>-3.219</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-1.183</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-3.976</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.947</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>0.213</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.261</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.384</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>-1.114</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>2.620</td>\n",
       "      <td>-2.408</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.059</td>\n",
       "      <td>2.168</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-4.326</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-2.958</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-3.039</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-1.034</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1.064</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-2.332</td>\n",
       "      <td>2.765</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>2.936</td>\n",
       "      <td>-5.857</td>\n",
       "      <td>1.603</td>\n",
       "      <td>0.173</td>\n",
       "      <td>5.314</td>\n",
       "      <td>-3.740</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-2.438</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>3.686</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.024</td>\n",
       "      <td>2.228</td>\n",
       "      <td>-4.975</td>\n",
       "      <td>-1.923</td>\n",
       "      <td>0.158</td>\n",
       "      <td>2.913</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>-3.701</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>2.802</td>\n",
       "      <td>2.169</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-2.338</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.095</td>\n",
       "      <td>-3.513</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>2.184</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>5.748</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.179</td>\n",
       "      <td>3.316</td>\n",
       "      <td>2.024</td>\n",
       "      <td>-2.822</td>\n",
       "      <td>3.199</td>\n",
       "      <td>5.816</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-3.460</td>\n",
       "      <td>0.230</td>\n",
       "      <td>3.001</td>\n",
       "      <td>-2.694</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.565</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-3.037</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-4.565</td>\n",
       "      <td>-1.704</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-4.680</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.602</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.812</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.613</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-1.379</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.178</td>\n",
       "      <td>3.887</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-1.242</td>\n",
       "      <td>-1.724</td>\n",
       "      <td>5.409</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>-4.635</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-2.169</td>\n",
       "      <td>2.696</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-5.598</td>\n",
       "      <td>1.671</td>\n",
       "      <td>1.892</td>\n",
       "      <td>2.077</td>\n",
       "      <td>-4.809</td>\n",
       "      <td>-3.952</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-2.655</td>\n",
       "      <td>2.165</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>3.237</td>\n",
       "      <td>-1.730</td>\n",
       "      <td>5.305</td>\n",
       "      <td>-2.247</td>\n",
       "      <td>-3.504</td>\n",
       "      <td>-6.087</td>\n",
       "      <td>-1.774</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-4.384</td>\n",
       "      <td>2.232</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-1.809</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-3.043</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>1.647</td>\n",
       "      <td>6.733</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-1.717</td>\n",
       "      <td>4.428</td>\n",
       "      <td>4.507</td>\n",
       "      <td>-1.927</td>\n",
       "      <td>-3.150</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>2.471</td>\n",
       "      <td>1.558</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>3.581</td>\n",
       "      <td>2.819</td>\n",
       "      <td>-3.606</td>\n",
       "      <td>-2.417</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>1.346</td>\n",
       "      <td>-2.130</td>\n",
       "      <td>-2.810</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-1.919</td>\n",
       "      <td>0.129</td>\n",
       "      <td>1.462</td>\n",
       "      <td>4.700</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-2.025</td>\n",
       "      <td>3.235</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-1.925</td>\n",
       "      <td>6.356</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-3.701</td>\n",
       "      <td>2.599</td>\n",
       "      <td>0.087</td>\n",
       "      <td>1.416</td>\n",
       "      <td>-2.588</td>\n",
       "      <td>0.045</td>\n",
       "      <td>1.878</td>\n",
       "      <td>-2.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-3.392</td>\n",
       "      <td>-1.129</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-2.008</td>\n",
       "      <td>5.385</td>\n",
       "      <td>-4.888</td>\n",
       "      <td>-6.423</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.325</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.627</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.627</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.390</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.145</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.219</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-1.655</td>\n",
       "      <td>1.767</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.334</td>\n",
       "      <td>2.886</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-2.532</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-2.748</td>\n",
       "      <td>-2.385</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-1.576</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-2.362</td>\n",
       "      <td>1.414</td>\n",
       "      <td>-2.772</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-2.441</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>3.923</td>\n",
       "      <td>-2.271</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.059</td>\n",
       "      <td>2.101</td>\n",
       "      <td>0.982</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.075</td>\n",
       "      <td>2.283</td>\n",
       "      <td>-1.534</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.888</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-3.251</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.258</td>\n",
       "      <td>1.168</td>\n",
       "      <td>-2.337</td>\n",
       "      <td>0.319</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>2.803</td>\n",
       "      <td>4.091</td>\n",
       "      <td>-2.787</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>2.786</td>\n",
       "      <td>1.816</td>\n",
       "      <td>-1.824</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>1.111</td>\n",
       "      <td>4.733</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.871</td>\n",
       "      <td>2.728</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.061</td>\n",
       "      <td>1.286</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>1.970</td>\n",
       "      <td>1.324</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-3.232</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3.472</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-3.181</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-1.521</td>\n",
       "      <td>-2.284</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  seed  feat0  feat1  feat2  feat3  feat4  feat5  feat6  split0  \\\n",
       "83 83.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "53 53.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "70 70.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "45 45.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "44 44.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "\n",
       "    split1  split2  split3  split4  split5  split6   lp0   lp1   lp2   lp3  \\\n",
       "83   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "53   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "70   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "45   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "44   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "     lp4   lp5   lp6   lp7   wb_0   wb_1   wb_2   wb_3   wb_4   wb_5  wb_6  \\\n",
       "83 0.000 0.000 0.000 0.000 -0.035 -0.097  0.106  0.254  0.600 -0.325 0.048   \n",
       "53 0.000 0.000 0.000 0.000 -0.035 -0.097  0.522  0.049  0.767  1.368 0.048   \n",
       "70 0.000 0.000 0.000 0.000 -0.035 -0.097  0.240 -0.301 -0.145  0.400 0.048   \n",
       "45 0.000 0.000 0.000 0.000 -0.035 -0.097  0.196 -0.223 -0.117  0.559 0.048   \n",
       "44 0.000 0.000 0.000 0.000 -0.035 -0.097 -0.055 -0.117  0.093  0.160 0.048   \n",
       "\n",
       "     wb_7   wb_8   wb_9  wb_10  wb_11  wb_12  wb_13  wb_14  wb_15  wb_16  \\\n",
       "83 -0.059 -0.259 -0.610  0.066 -0.053  0.005 -0.919  0.178  0.528 -0.028   \n",
       "53 -0.059  0.258 -0.408 -0.725 -0.050 -0.114  0.174  0.601  0.075 -0.076   \n",
       "70 -0.059  0.008 -0.140 -0.953  0.213 -0.113 -0.369  0.099  0.076  0.366   \n",
       "45 -0.059 -0.138 -0.196 -0.187  0.168  0.318 -0.089  0.071  0.580 -0.046   \n",
       "44 -0.059  0.174 -0.357 -0.188  0.087 -0.426  0.219 -0.063  0.325 -0.027   \n",
       "\n",
       "    wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  wb_24  wb_25  wb_26  \\\n",
       "83 -0.585  0.298  0.133 -0.072 -0.019 -0.189  0.155 -0.118  0.441  0.072   \n",
       "53 -0.267  0.056 -0.020  0.269 -0.160 -0.189  0.155 -0.142  0.165  0.210   \n",
       "70 -0.355 -0.130 -0.466  0.381 -0.716 -0.189  0.191 -0.113  0.400 -0.160   \n",
       "45  0.428 -0.136  0.082 -0.237  0.005 -0.189  0.155 -0.602 -0.048  0.455   \n",
       "44 -0.327 -0.137  0.291  0.286 -0.029 -0.189  0.155 -0.861  0.228  0.293   \n",
       "\n",
       "    wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  wb_34  wb_35  wb_36  \\\n",
       "83  0.061 -0.108  0.179 -0.646 -0.061 -0.387  0.004  0.729 -0.779  0.362   \n",
       "53  0.036 -0.108 -0.177 -0.066 -0.700  0.009  0.076  0.109 -0.646 -0.018   \n",
       "70  0.128 -0.108 -0.181  0.220 -0.751 -0.324 -0.310  0.511 -0.207 -0.388   \n",
       "45 -0.180 -0.108  0.004  0.641 -0.170 -0.295 -0.232  0.812 -0.442  0.237   \n",
       "44  0.034 -0.108 -0.672  0.297 -0.575 -0.552 -0.116  0.330 -0.627  0.007   \n",
       "\n",
       "    wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  wb_44  wb_45  wb_46  \\\n",
       "83  0.262 -0.938  0.493  0.469 -0.519 -0.117  0.183 -0.112 -0.503 -0.409   \n",
       "53  0.124 -0.051  0.290  0.727 -0.072 -0.117  0.267  0.456 -0.072  0.286   \n",
       "70  0.126 -0.976 -0.045 -0.031  0.192 -0.117 -0.065 -0.221  0.209  0.261   \n",
       "45  0.123 -0.229  0.033  0.613 -0.460 -0.117 -0.090 -0.234 -0.426 -0.234   \n",
       "44  0.130 -0.555  0.126  0.109 -0.099 -0.117 -0.062 -0.514 -0.097  0.214   \n",
       "\n",
       "    wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  wb_54  wb_55  wb_56  \\\n",
       "83  0.893 -1.760 -0.345 -0.020  0.017  0.020  0.128 -0.208  0.431 -0.492   \n",
       "53  0.093 -0.292  0.030  0.057 -0.197  0.927  0.098 -0.208  0.385 -0.050   \n",
       "70 -0.071 -0.152 -0.301 -0.292  0.010  0.188  0.384 -0.208 -0.632  0.028   \n",
       "45 -0.284  0.217  0.218 -0.149  0.017  0.022  0.287 -0.208  0.309 -0.016   \n",
       "44  0.294 -0.151 -0.175 -0.131  0.012  0.022  0.239 -0.208  0.449  0.483   \n",
       "\n",
       "    wb_57  wb_58  wb_59  wb_60  wb_61  wb_62  wb_63  wb_64  wb_65  wb_66  \\\n",
       "83 -1.921 -0.605  0.460  0.067 -0.230 -0.018 -0.951 -0.410 -0.174 -0.254   \n",
       "53  0.018 -0.409  0.375  0.165  0.990  0.004 -0.303 -0.057 -0.174 -0.196   \n",
       "70 -0.309 -0.391 -0.222  0.718  0.140 -0.373 -1.114 -0.237 -0.174 -0.471   \n",
       "45 -0.157 -0.970  0.119  0.106  0.371 -0.151 -1.379 -0.260 -0.174 -0.063   \n",
       "44 -0.640 -0.187  0.697  0.259 -0.089  0.627 -0.311 -0.087 -0.174 -0.064   \n",
       "\n",
       "    wb_67  wb_68  wb_69  wb_70  wb_71  wb_72  wb_73  wb_74  wb_75  ...  \\\n",
       "83 -0.729  0.266  0.084 -0.174  0.947 -0.298  0.189  0.481  0.075  ...   \n",
       "53 -0.383 -0.047  1.199 -0.174  0.419  0.881  0.049  0.566  0.154  ...   \n",
       "70 -0.223 -0.153 -0.056 -0.174  0.281 -0.528  0.065  0.459  0.305  ...   \n",
       "45 -0.290  0.175  0.099 -0.174 -0.409  0.063  0.494  0.051 -0.243  ...   \n",
       "44 -0.101  0.744  0.390 -0.174  0.248 -0.487  0.391  0.071  0.145  ...   \n",
       "\n",
       "    wb_1437  wb_1438  wb_1439  wb_1440  wb_1441  wb_1442  wb_1443  wb_1444  \\\n",
       "83   -3.725    5.630   -6.076    4.953   -0.008    7.220    1.927   -3.182   \n",
       "53   -0.177    1.627   -5.102   -0.129   -0.322   -0.038    1.183   -0.102   \n",
       "70   -0.181    2.620   -2.408   -0.072    0.059    2.168    0.439   -4.326   \n",
       "45   -4.178    3.887    0.019   -1.242   -1.724    5.409   -0.598   -4.635   \n",
       "44   -2.219    0.197   -1.655    1.767   -0.294    0.334    2.886   -0.272   \n",
       "\n",
       "    wb_1445  wb_1446  wb_1447  wb_1448  wb_1449  wb_1450  wb_1451  wb_1452  \\\n",
       "83   -0.183   -4.596    1.360   -2.168    1.388   -0.200    0.150   -0.168   \n",
       "53   -0.079   -0.257   -0.069   -3.638    0.034   -0.200   -0.189   -2.678   \n",
       "70   -0.084   -2.958   -0.028   -3.039   -0.005   -0.200   -1.034   -0.111   \n",
       "45   -0.080   -0.068   -0.096   -2.169    2.696   -0.200   -0.011   -5.598   \n",
       "44   -0.084   -2.532   -0.175   -0.395   -0.170   -0.200   -2.748   -2.385   \n",
       "\n",
       "    wb_1453  wb_1454  wb_1455  wb_1456  wb_1457  wb_1458  wb_1459  wb_1460  \\\n",
       "83    0.830    1.888    5.951   -4.067   -4.269   -0.003   -0.171    0.180   \n",
       "53    0.552   -0.330    1.215   -2.516   -0.367   -0.220   -2.775    2.915   \n",
       "70    0.037    0.149    1.064   -0.027   -0.340   -0.168   -0.167    0.996   \n",
       "45    1.671    1.892    2.077   -4.809   -3.952   -0.039   -0.171    0.189   \n",
       "44   -0.130   -1.576    0.739   -0.363   -0.113   -0.258   -0.166    0.219   \n",
       "\n",
       "    wb_1461  wb_1462  wb_1463  wb_1464  wb_1465  wb_1466  wb_1467  wb_1468  \\\n",
       "83    0.025    0.044   -1.008   -0.615   -3.569    1.674   -2.855    5.301   \n",
       "53    0.065    0.044   -1.283    0.018   -0.279   -2.325   -4.131   -0.079   \n",
       "70    0.209    0.044   -2.332    2.765   -0.276    2.936   -5.857    1.603   \n",
       "45    0.091    0.044   -2.655    2.165   -0.111    3.237   -1.730    5.305   \n",
       "44    0.152    0.044   -2.362    1.414   -2.772   -0.355   -2.441   -0.009   \n",
       "\n",
       "    wb_1469  wb_1470  wb_1471  wb_1472  wb_1473  wb_1474  wb_1475  wb_1476  \\\n",
       "83    0.626   -3.545  -10.063   -5.600   -0.111  -11.072    0.977   -1.256   \n",
       "53    5.576   -0.186   -2.344   -0.980   -0.111   -1.888    0.472    1.789   \n",
       "70    0.173    5.314   -3.740   -0.447   -0.111   -2.438    0.042   -0.237   \n",
       "45   -2.247   -3.504   -6.087   -1.774   -0.111   -4.384    2.232   -1.200   \n",
       "44   -0.292    3.923   -2.271   -0.160   -0.111   -0.192    0.059    2.101   \n",
       "\n",
       "    wb_1477  wb_1478  wb_1479  wb_1480  wb_1481  wb_1482  wb_1483  wb_1484  \\\n",
       "83    0.048   -0.195    5.518    0.083   -0.046   -2.092   -1.803    2.098   \n",
       "53    3.516   -0.195   -2.574    5.133   -2.119   -4.241   -0.190    0.326   \n",
       "70    3.686   -0.195    0.024    2.228   -4.975   -1.923    0.158    2.913   \n",
       "45    0.054   -0.195   -1.809    0.109   -3.043   -0.180    1.647    6.733   \n",
       "44    0.982   -0.195    0.075    2.283   -1.534   -0.189    0.987    1.888   \n",
       "\n",
       "    wb_1485  wb_1486  wb_1487  wb_1488  wb_1489  wb_1490  wb_1491  wb_1492  \\\n",
       "83   -5.108   -2.135    5.704    1.324    6.711   -0.129   -2.206    0.465   \n",
       "53   -4.740   -0.256    4.229    0.544   -0.088   -3.275   -0.199    0.166   \n",
       "70   -0.371   -3.701   -0.085    0.103   -0.194   -0.009   -0.011    2.802   \n",
       "45   -0.134   -1.717    4.428    4.507   -1.927   -3.150   -0.104    2.471   \n",
       "44   -0.123   -3.251    0.134   -0.909    0.031   -0.970   -0.364    0.258   \n",
       "\n",
       "    wb_1493  wb_1494  wb_1495  wb_1496  wb_1497  wb_1498  wb_1499  wb_1500  \\\n",
       "83    0.046   -7.629   -1.147   -0.027    0.685    5.215   -0.128   -0.105   \n",
       "53    0.050   -0.113   -0.442   -0.027    4.095    1.432   -0.392   -2.533   \n",
       "70    2.169   -0.107   -2.338   -0.027    0.001    1.095   -3.513   -0.022   \n",
       "45    1.558   -0.096    1.240   -0.027    3.581    2.819   -3.606   -2.417   \n",
       "44    1.168   -2.337    0.319   -0.027    2.803    4.091   -2.787   -0.312   \n",
       "\n",
       "    wb_1501  wb_1502  wb_1503  wb_1504  wb_1505  wb_1506  wb_1507  wb_1508  \\\n",
       "83   -1.485    4.089   -0.945    1.706   -0.092    1.276    2.835    0.137   \n",
       "53   -0.150    3.194   -0.913   -0.262   -0.092    6.026    3.244    4.304   \n",
       "70   -0.141    2.184   -0.046   -0.355   -0.092    5.748    0.411    0.398   \n",
       "45   -0.040    1.346   -2.130   -2.810   -0.092    0.081   -1.919    0.129   \n",
       "44   -0.201    2.786    1.816   -1.824   -0.092    1.111    4.733    0.128   \n",
       "\n",
       "    wb_1509  wb_1510  wb_1511  wb_1512  wb_1513  wb_1514  wb_1515  wb_1516  \\\n",
       "83    0.182    0.188   -0.065    0.124   -1.329    4.157    2.636    0.125   \n",
       "53    0.175    2.786    3.910    0.052   -3.452    0.132   -1.258    0.125   \n",
       "70    0.175    0.179    3.316    2.024   -2.822    3.199    5.816    0.125   \n",
       "45    1.462    4.700    0.327    0.122   -2.025    3.235    0.089    0.125   \n",
       "44    0.871    2.728    0.915    0.130   -0.155    0.061    1.286    0.125   \n",
       "\n",
       "    wb_1517  wb_1518  wb_1519  wb_1520  wb_1521  wb_1522  wb_1523  wb_1524  \\\n",
       "83   -3.702    0.097   -2.785   -0.122    3.270    0.085   -3.025   -2.604   \n",
       "53    0.613    3.455    3.631   -0.188    0.494    7.303    1.316   -2.111   \n",
       "70   -3.460    0.230    3.001   -2.694    0.269    1.565    0.019   -0.063   \n",
       "45   -1.925    6.356   -0.207   -3.701    2.599    0.087    1.416   -2.588   \n",
       "44   -0.215    0.101   -0.195   -0.115    1.970    1.324   -0.970   -3.232   \n",
       "\n",
       "    wb_1525  wb_1526  wb_1527  wb_1528  wb_1529  wb_1530  wb_1531  wb_1532  \\\n",
       "83    0.045    0.951   -3.261    0.035   -0.713   -5.743   -3.393   -2.951   \n",
       "53    0.045    3.864   -3.219    0.035   -1.183   -0.135   -3.976   -0.114   \n",
       "70    0.045    0.051   -3.037    0.035   -4.565   -1.704   -0.157   -4.680   \n",
       "45    0.045    1.878   -2.050    0.035   -3.392   -1.129   -0.162   -2.008   \n",
       "44    0.045    3.472   -1.055    0.035   -3.181   -0.123   -1.521   -2.284   \n",
       "\n",
       "    wb_1533  wb_1534  wb_1535  wb_1536  \n",
       "83    0.041    0.573   -0.033   -0.040  \n",
       "53    0.364    0.947   -0.033    0.017  \n",
       "70    0.039   -0.006   -0.033   -0.182  \n",
       "45    5.385   -4.888   -6.423    0.063  \n",
       "44    0.317   -0.027   -0.033   -0.057  \n",
       "\n",
       "[5 rows x 1561 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_net_dataset_train.samples_class_0_list_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_net_dataset_train.distribution_dict_row_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset_train.distribution_dict_list_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "network_parameters_structure [(10, 128), (128,), (128, 1), (1,)]\n",
      "Epoch 1/500\n",
      "1/1 - 49s - loss: 0.8472 - binary_accuracy_inet_decision_function_fv_metric: 0.4932 - val_loss: 0.7786 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4986 - lr: 0.0010 - 49s/epoch - 49s/step\n",
      "Epoch 2/500\n",
      "1/1 - 1s - loss: 0.8040 - binary_accuracy_inet_decision_function_fv_metric: 0.4943 - val_loss: 0.8636 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4836 - lr: 0.0010 - 551ms/epoch - 551ms/step\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 0.7785 - binary_accuracy_inet_decision_function_fv_metric: 0.5065 - val_loss: 0.7384 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5008 - lr: 0.0010 - 448ms/epoch - 448ms/step\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 0.7810 - binary_accuracy_inet_decision_function_fv_metric: 0.5019 - val_loss: 0.7217 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4986 - lr: 0.0010 - 494ms/epoch - 494ms/step\n",
      "Epoch 5/500\n",
      "1/1 - 1s - loss: 0.7502 - binary_accuracy_inet_decision_function_fv_metric: 0.5135 - val_loss: 0.6979 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5006 - lr: 0.0010 - 1s/epoch - 1s/step\n",
      "Epoch 6/500\n",
      "1/1 - 1s - loss: 0.7615 - binary_accuracy_inet_decision_function_fv_metric: 0.4954 - val_loss: 0.6957 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5002 - lr: 0.0010 - 673ms/epoch - 673ms/step\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 0.7535 - binary_accuracy_inet_decision_function_fv_metric: 0.5035 - val_loss: 0.7023 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5000 - lr: 0.0010 - 434ms/epoch - 434ms/step\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 0.7616 - binary_accuracy_inet_decision_function_fv_metric: 0.4924 - val_loss: 0.7069 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4914 - lr: 0.0010 - 278ms/epoch - 278ms/step\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 0.7581 - binary_accuracy_inet_decision_function_fv_metric: 0.4983 - val_loss: 0.7058 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4880 - lr: 0.0010 - 348ms/epoch - 348ms/step\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 0.7441 - binary_accuracy_inet_decision_function_fv_metric: 0.5009 - val_loss: 0.7022 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4962 - lr: 0.0010 - 458ms/epoch - 458ms/step\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 0.7424 - binary_accuracy_inet_decision_function_fv_metric: 0.4943 - val_loss: 0.6976 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5014 - lr: 0.0010 - 346ms/epoch - 346ms/step\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 0.7336 - binary_accuracy_inet_decision_function_fv_metric: 0.4982 - val_loss: 0.6943 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5068 - lr: 0.0010 - 431ms/epoch - 431ms/step\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 0.7371 - binary_accuracy_inet_decision_function_fv_metric: 0.5016 - val_loss: 0.6929 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5186 - lr: 0.0010 - 415ms/epoch - 415ms/step\n",
      "Epoch 14/500\n",
      "1/1 - 1s - loss: 0.7369 - binary_accuracy_inet_decision_function_fv_metric: 0.4909 - val_loss: 0.6947 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5172 - lr: 0.0010 - 560ms/epoch - 560ms/step\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 0.7305 - binary_accuracy_inet_decision_function_fv_metric: 0.5084 - val_loss: 0.6980 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5084 - lr: 0.0010 - 441ms/epoch - 441ms/step\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 0.7328 - binary_accuracy_inet_decision_function_fv_metric: 0.4990 - val_loss: 0.7018 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5138 - lr: 0.0010 - 326ms/epoch - 326ms/step\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 0.7283 - binary_accuracy_inet_decision_function_fv_metric: 0.5102 - val_loss: 0.7031 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5022 - lr: 0.0010 - 443ms/epoch - 443ms/step\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 0.7314 - binary_accuracy_inet_decision_function_fv_metric: 0.5029 - val_loss: 0.7011 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5072 - lr: 0.0010 - 455ms/epoch - 455ms/step\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 0.7221 - binary_accuracy_inet_decision_function_fv_metric: 0.5044 - val_loss: 0.6982 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5080 - lr: 0.0010 - 450ms/epoch - 450ms/step\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 0.7249 - binary_accuracy_inet_decision_function_fv_metric: 0.5022 - val_loss: 0.6954 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5100 - lr: 0.0010 - 418ms/epoch - 418ms/step\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 0.7291 - binary_accuracy_inet_decision_function_fv_metric: 0.5016 - val_loss: 0.6942 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5050 - lr: 0.0010 - 343ms/epoch - 343ms/step\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 0.7231 - binary_accuracy_inet_decision_function_fv_metric: 0.5124 - val_loss: 0.6945 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4790 - lr: 0.0010 - 353ms/epoch - 353ms/step\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 0.7237 - binary_accuracy_inet_decision_function_fv_metric: 0.4961 - val_loss: 0.6981 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4952 - lr: 0.0010 - 448ms/epoch - 448ms/step\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 0.7158 - binary_accuracy_inet_decision_function_fv_metric: 0.5029 - val_loss: 0.7031 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4854 - lr: 0.0010 - 360ms/epoch - 360ms/step\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 0.7127 - binary_accuracy_inet_decision_function_fv_metric: 0.5139 - val_loss: 0.7071 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4846 - lr: 0.0010 - 395ms/epoch - 395ms/step\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 0.7197 - binary_accuracy_inet_decision_function_fv_metric: 0.5009 - val_loss: 0.7084 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4854 - lr: 0.0010 - 447ms/epoch - 447ms/step\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 0.7171 - binary_accuracy_inet_decision_function_fv_metric: 0.5036 - val_loss: 0.7072 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4844 - lr: 0.0010 - 336ms/epoch - 336ms/step\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 0.7166 - binary_accuracy_inet_decision_function_fv_metric: 0.5025 - val_loss: 0.7033 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4846 - lr: 0.0010 - 290ms/epoch - 290ms/step\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 0.7088 - binary_accuracy_inet_decision_function_fv_metric: 0.5136 - val_loss: 0.6991 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4808 - lr: 0.0010 - 343ms/epoch - 343ms/step\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 0.7116 - binary_accuracy_inet_decision_function_fv_metric: 0.5021 - val_loss: 0.6957 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4792 - lr: 0.0010 - 416ms/epoch - 416ms/step\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 0.7097 - binary_accuracy_inet_decision_function_fv_metric: 0.5052 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5138 - lr: 0.0010 - 367ms/epoch - 367ms/step\n",
      "Epoch 32/500\n",
      "1/1 - 1s - loss: 0.7053 - binary_accuracy_inet_decision_function_fv_metric: 0.5082 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5104 - lr: 0.0010 - 549ms/epoch - 549ms/step\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 0.7079 - binary_accuracy_inet_decision_function_fv_metric: 0.5078 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5078 - lr: 0.0010 - 366ms/epoch - 366ms/step\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 0.7075 - binary_accuracy_inet_decision_function_fv_metric: 0.4946 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5054 - lr: 0.0010 - 353ms/epoch - 353ms/step\n",
      "Epoch 35/500\n",
      "1/1 - 1s - loss: 0.7108 - binary_accuracy_inet_decision_function_fv_metric: 0.4970 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5114 - lr: 0.0010 - 590ms/epoch - 590ms/step\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 0.7078 - binary_accuracy_inet_decision_function_fv_metric: 0.5034 - val_loss: 0.7006 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4868 - lr: 0.0010 - 493ms/epoch - 493ms/step\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 0.7054 - binary_accuracy_inet_decision_function_fv_metric: 0.4986 - val_loss: 0.7032 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4668 - lr: 0.0010 - 404ms/epoch - 404ms/step\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 0.7116 - binary_accuracy_inet_decision_function_fv_metric: 0.4902 - val_loss: 0.6995 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4968 - lr: 0.0010 - 482ms/epoch - 482ms/step\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 0.7003 - binary_accuracy_inet_decision_function_fv_metric: 0.5143 - val_loss: 0.6971 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4942 - lr: 0.0010 - 483ms/epoch - 483ms/step\n",
      "Epoch 40/500\n",
      "1/1 - 1s - loss: 0.7011 - binary_accuracy_inet_decision_function_fv_metric: 0.5013 - val_loss: 0.6947 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4952 - lr: 0.0010 - 621ms/epoch - 621ms/step\n",
      "Epoch 41/500\n",
      "1/1 - 1s - loss: 0.7049 - binary_accuracy_inet_decision_function_fv_metric: 0.4944 - val_loss: 0.6929 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4894 - lr: 0.0010 - 622ms/epoch - 622ms/step\n",
      "Epoch 42/500\n",
      "1/1 - 1s - loss: 0.7052 - binary_accuracy_inet_decision_function_fv_metric: 0.5015 - val_loss: 0.6923 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5174 - lr: 0.0010 - 547ms/epoch - 547ms/step\n",
      "Epoch 43/500\n",
      "1/1 - 1s - loss: 0.7019 - binary_accuracy_inet_decision_function_fv_metric: 0.5039 - val_loss: 0.6927 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5166 - lr: 0.0010 - 676ms/epoch - 676ms/step\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 0.7058 - binary_accuracy_inet_decision_function_fv_metric: 0.4972 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5156 - lr: 0.0010 - 353ms/epoch - 353ms/step\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 0.7024 - binary_accuracy_inet_decision_function_fv_metric: 0.4962 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4954 - lr: 0.0010 - 430ms/epoch - 430ms/step\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 0.7014 - binary_accuracy_inet_decision_function_fv_metric: 0.4970 - val_loss: 0.6945 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5006 - lr: 0.0010 - 490ms/epoch - 490ms/step\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 0.6997 - binary_accuracy_inet_decision_function_fv_metric: 0.5043 - val_loss: 0.6948 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5122 - lr: 0.0010 - 474ms/epoch - 474ms/step\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 0.6994 - binary_accuracy_inet_decision_function_fv_metric: 0.5138 - val_loss: 0.6950 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5016 - lr: 0.0010 - 350ms/epoch - 350ms/step\n",
      "Epoch 49/500\n",
      "1/1 - 1s - loss: 0.6996 - binary_accuracy_inet_decision_function_fv_metric: 0.5102 - val_loss: 0.6949 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4870 - lr: 0.0010 - 511ms/epoch - 511ms/step\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 0.6999 - binary_accuracy_inet_decision_function_fv_metric: 0.4958 - val_loss: 0.6949 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4922 - lr: 0.0010 - 347ms/epoch - 347ms/step\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 0.7036 - binary_accuracy_inet_decision_function_fv_metric: 0.4848 - val_loss: 0.6943 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4982 - lr: 0.0010 - 453ms/epoch - 453ms/step\n",
      "Epoch 52/500\n",
      "1/1 - 1s - loss: 0.7012 - binary_accuracy_inet_decision_function_fv_metric: 0.4937 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5020 - lr: 0.0010 - 619ms/epoch - 619ms/step\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 0.6996 - binary_accuracy_inet_decision_function_fv_metric: 0.4915 - val_loss: 0.6923 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5276 - lr: 0.0010 - 396ms/epoch - 396ms/step\n",
      "Epoch 54/500\n",
      "1/1 - 1s - loss: 0.7004 - binary_accuracy_inet_decision_function_fv_metric: 0.4924 - val_loss: 0.6918 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5096 - lr: 0.0010 - 652ms/epoch - 652ms/step\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 0.6987 - binary_accuracy_inet_decision_function_fv_metric: 0.4966 - val_loss: 0.6918 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5244 - lr: 0.0010 - 445ms/epoch - 445ms/step\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 0.6994 - binary_accuracy_inet_decision_function_fv_metric: 0.4827 - val_loss: 0.6920 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5250 - lr: 0.0010 - 397ms/epoch - 397ms/step\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 0.7017 - binary_accuracy_inet_decision_function_fv_metric: 0.4852 - val_loss: 0.6924 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5258 - lr: 0.0010 - 316ms/epoch - 316ms/step\n",
      "Epoch 58/500\n",
      "1/1 - 1s - loss: 0.6988 - binary_accuracy_inet_decision_function_fv_metric: 0.4983 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5106 - lr: 0.0010 - 527ms/epoch - 527ms/step\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 0.6971 - binary_accuracy_inet_decision_function_fv_metric: 0.5081 - val_loss: 0.6940 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4870 - lr: 0.0010 - 406ms/epoch - 406ms/step\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 0.6974 - binary_accuracy_inet_decision_function_fv_metric: 0.4993 - val_loss: 0.6947 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4890 - lr: 0.0010 - 400ms/epoch - 400ms/step\n",
      "Epoch 61/500\n",
      "1/1 - 1s - loss: 0.6977 - binary_accuracy_inet_decision_function_fv_metric: 0.4996 - val_loss: 0.6953 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4916 - lr: 0.0010 - 509ms/epoch - 509ms/step\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 0.6976 - binary_accuracy_inet_decision_function_fv_metric: 0.4992 - val_loss: 0.6958 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4802 - lr: 0.0010 - 402ms/epoch - 402ms/step\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 0.6956 - binary_accuracy_inet_decision_function_fv_metric: 0.5140 - val_loss: 0.6962 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4804 - lr: 0.0010 - 398ms/epoch - 398ms/step\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 0.6973 - binary_accuracy_inet_decision_function_fv_metric: 0.5010 - val_loss: 0.6959 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4584 - lr: 0.0010 - 402ms/epoch - 402ms/step\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 0.6969 - binary_accuracy_inet_decision_function_fv_metric: 0.5014 - val_loss: 0.6956 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4584 - lr: 0.0010 - 339ms/epoch - 339ms/step\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 0.6969 - binary_accuracy_inet_decision_function_fv_metric: 0.5021 - val_loss: 0.6950 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4596 - lr: 0.0010 - 380ms/epoch - 380ms/step\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 0.6973 - binary_accuracy_inet_decision_function_fv_metric: 0.4838 - val_loss: 0.6946 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4798 - lr: 0.0010 - 450ms/epoch - 450ms/step\n",
      "Epoch 68/500\n",
      "1/1 - 1s - loss: 0.6978 - binary_accuracy_inet_decision_function_fv_metric: 0.4919 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4806 - lr: 0.0010 - 555ms/epoch - 555ms/step\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 0.6946 - binary_accuracy_inet_decision_function_fv_metric: 0.5105 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4954 - lr: 0.0010 - 395ms/epoch - 395ms/step\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 0.6952 - binary_accuracy_inet_decision_function_fv_metric: 0.5013 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5002 - lr: 0.0010 - 391ms/epoch - 391ms/step\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 0.6949 - binary_accuracy_inet_decision_function_fv_metric: 0.5045 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4902 - lr: 0.0010 - 434ms/epoch - 434ms/step\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 0.6945 - binary_accuracy_inet_decision_function_fv_metric: 0.5106 - val_loss: 0.6926 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5062 - lr: 0.0010 - 302ms/epoch - 302ms/step\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 0.6964 - binary_accuracy_inet_decision_function_fv_metric: 0.4933 - val_loss: 0.6926 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5174 - lr: 0.0010 - 457ms/epoch - 457ms/step\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 0.6957 - binary_accuracy_inet_decision_function_fv_metric: 0.5004 - val_loss: 0.6923 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5204 - lr: 0.0010 - 383ms/epoch - 383ms/step\n",
      "Epoch 75/500\n",
      "1/1 - 1s - loss: 0.6952 - binary_accuracy_inet_decision_function_fv_metric: 0.5004 - val_loss: 0.6924 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5192 - lr: 0.0010 - 549ms/epoch - 549ms/step\n",
      "Epoch 76/500\n",
      "1/1 - 1s - loss: 0.6960 - binary_accuracy_inet_decision_function_fv_metric: 0.4969 - val_loss: 0.6925 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5168 - lr: 0.0010 - 508ms/epoch - 508ms/step\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 0.6929 - binary_accuracy_inet_decision_function_fv_metric: 0.5142 - val_loss: 0.6925 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5194 - lr: 0.0010 - 350ms/epoch - 350ms/step\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 0.6942 - binary_accuracy_inet_decision_function_fv_metric: 0.5007 - val_loss: 0.6927 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5088 - lr: 0.0010 - 492ms/epoch - 492ms/step\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 0.6947 - binary_accuracy_inet_decision_function_fv_metric: 0.4969 - val_loss: 0.6930 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5060 - lr: 0.0010 - 382ms/epoch - 382ms/step\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 0.6939 - binary_accuracy_inet_decision_function_fv_metric: 0.5059 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5026 - lr: 0.0010 - 265ms/epoch - 265ms/step\n",
      "Epoch 81/500\n",
      "1/1 - 1s - loss: 0.6956 - binary_accuracy_inet_decision_function_fv_metric: 0.4948 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4900 - lr: 0.0010 - 708ms/epoch - 708ms/step\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 0.6958 - binary_accuracy_inet_decision_function_fv_metric: 0.4953 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4914 - lr: 0.0010 - 383ms/epoch - 383ms/step\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 0.6947 - binary_accuracy_inet_decision_function_fv_metric: 0.4914 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4906 - lr: 0.0010 - 385ms/epoch - 385ms/step\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 0.6956 - binary_accuracy_inet_decision_function_fv_metric: 0.4923 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4910 - lr: 0.0010 - 365ms/epoch - 365ms/step\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 0.6945 - binary_accuracy_inet_decision_function_fv_metric: 0.5050 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4912 - lr: 0.0010 - 454ms/epoch - 454ms/step\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 0.6954 - binary_accuracy_inet_decision_function_fv_metric: 0.4896 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4928 - lr: 0.0010 - 435ms/epoch - 435ms/step\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 0.6948 - binary_accuracy_inet_decision_function_fv_metric: 0.5000 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4924 - lr: 0.0010 - 405ms/epoch - 405ms/step\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 0.6957 - binary_accuracy_inet_decision_function_fv_metric: 0.4921 - val_loss: 0.6929 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4936 - lr: 0.0010 - 371ms/epoch - 371ms/step\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 0.6958 - binary_accuracy_inet_decision_function_fv_metric: 0.4918 - val_loss: 0.6926 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5064 - lr: 0.0010 - 463ms/epoch - 463ms/step\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 0.6949 - binary_accuracy_inet_decision_function_fv_metric: 0.5049 - val_loss: 0.6924 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5168 - lr: 0.0010 - 453ms/epoch - 453ms/step\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 0.6951 - binary_accuracy_inet_decision_function_fv_metric: 0.4971 - val_loss: 0.6922 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5264 - lr: 0.0010 - 344ms/epoch - 344ms/step\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 0.6933 - binary_accuracy_inet_decision_function_fv_metric: 0.5026 - val_loss: 0.6921 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5388 - lr: 0.0010 - 387ms/epoch - 387ms/step\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.5007 - val_loss: 0.6920 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5292 - lr: 0.0010 - 492ms/epoch - 492ms/step\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 0.6938 - binary_accuracy_inet_decision_function_fv_metric: 0.5059 - val_loss: 0.6920 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5278 - lr: 0.0010 - 419ms/epoch - 419ms/step\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 0.6959 - binary_accuracy_inet_decision_function_fv_metric: 0.4934 - val_loss: 0.6921 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5288 - lr: 0.0010 - 382ms/epoch - 382ms/step\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 0.6932 - binary_accuracy_inet_decision_function_fv_metric: 0.5031 - val_loss: 0.6922 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5264 - lr: 0.0010 - 402ms/epoch - 402ms/step\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 0.6950 - binary_accuracy_inet_decision_function_fv_metric: 0.4922 - val_loss: 0.6923 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5272 - lr: 0.0010 - 422ms/epoch - 422ms/step\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 0.6940 - binary_accuracy_inet_decision_function_fv_metric: 0.5029 - val_loss: 0.6923 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5322 - lr: 0.0010 - 397ms/epoch - 397ms/step\n",
      "Epoch 99/500\n",
      "1/1 - 1s - loss: 0.6937 - binary_accuracy_inet_decision_function_fv_metric: 0.5031 - val_loss: 0.6926 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5234 - lr: 0.0010 - 534ms/epoch - 534ms/step\n",
      "Epoch 100/500\n",
      "1/1 - 1s - loss: 0.6943 - binary_accuracy_inet_decision_function_fv_metric: 0.4969 - val_loss: 0.6928 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5038 - lr: 0.0010 - 712ms/epoch - 712ms/step\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 0.6942 - binary_accuracy_inet_decision_function_fv_metric: 0.4977 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4988 - lr: 0.0010 - 336ms/epoch - 336ms/step\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 0.6933 - binary_accuracy_inet_decision_function_fv_metric: 0.5146 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4886 - lr: 0.0010 - 325ms/epoch - 325ms/step\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 0.6940 - binary_accuracy_inet_decision_function_fv_metric: 0.4975 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4876 - lr: 0.0010 - 361ms/epoch - 361ms/step\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 0.6945 - binary_accuracy_inet_decision_function_fv_metric: 0.4979 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4882 - lr: 0.0010 - 262ms/epoch - 262ms/step\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 0.6940 - binary_accuracy_inet_decision_function_fv_metric: 0.4975 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4882 - lr: 1.0000e-04 - 444ms/epoch - 444ms/step\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 0.6947 - binary_accuracy_inet_decision_function_fv_metric: 0.5030 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4884 - lr: 1.0000e-04 - 362ms/epoch - 362ms/step\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 0.6942 - binary_accuracy_inet_decision_function_fv_metric: 0.4905 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4884 - lr: 1.0000e-04 - 439ms/epoch - 439ms/step\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 0.6940 - binary_accuracy_inet_decision_function_fv_metric: 0.5012 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4884 - lr: 1.0000e-04 - 339ms/epoch - 339ms/step\n",
      "Epoch 109/500\n",
      "1/1 - 1s - loss: 0.6945 - binary_accuracy_inet_decision_function_fv_metric: 0.4995 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4884 - lr: 1.0000e-04 - 513ms/epoch - 513ms/step\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.5062 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4884 - lr: 1.0000e-04 - 323ms/epoch - 323ms/step\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 0.6938 - binary_accuracy_inet_decision_function_fv_metric: 0.5052 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4882 - lr: 1.0000e-04 - 319ms/epoch - 319ms/step\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.5025 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4886 - lr: 1.0000e-04 - 377ms/epoch - 377ms/step\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 0.6935 - binary_accuracy_inet_decision_function_fv_metric: 0.4997 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4886 - lr: 1.0000e-04 - 293ms/epoch - 293ms/step\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 0.6926 - binary_accuracy_inet_decision_function_fv_metric: 0.5159 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4880 - lr: 1.0000e-04 - 478ms/epoch - 478ms/step\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 0.6935 - binary_accuracy_inet_decision_function_fv_metric: 0.5126 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4880 - lr: 1.0000e-04 - 361ms/epoch - 361ms/step\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 0.6922 - binary_accuracy_inet_decision_function_fv_metric: 0.5173 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4882 - lr: 1.0000e-04 - 370ms/epoch - 370ms/step\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 0.6948 - binary_accuracy_inet_decision_function_fv_metric: 0.5009 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4882 - lr: 1.0000e-04 - 379ms/epoch - 379ms/step\n",
      "Epoch 118/500\n",
      "1/1 - 1s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.4978 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4886 - lr: 1.0000e-04 - 551ms/epoch - 551ms/step\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 0.6942 - binary_accuracy_inet_decision_function_fv_metric: 0.5033 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4892 - lr: 1.0000e-04 - 370ms/epoch - 370ms/step\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 0.6945 - binary_accuracy_inet_decision_function_fv_metric: 0.5088 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4892 - lr: 1.0000e-04 - 410ms/epoch - 410ms/step\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.4936 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4892 - lr: 1.0000e-04 - 321ms/epoch - 321ms/step\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 0.6931 - binary_accuracy_inet_decision_function_fv_metric: 0.5060 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4892 - lr: 1.0000e-04 - 341ms/epoch - 341ms/step\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 0.6939 - binary_accuracy_inet_decision_function_fv_metric: 0.5054 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4890 - lr: 1.0000e-04 - 484ms/epoch - 484ms/step\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 0.6939 - binary_accuracy_inet_decision_function_fv_metric: 0.5077 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4892 - lr: 1.0000e-04 - 429ms/epoch - 429ms/step\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.4958 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4892 - lr: 1.0000e-04 - 318ms/epoch - 318ms/step\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.5006 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4892 - lr: 1.0000e-04 - 257ms/epoch - 257ms/step\n",
      "Epoch 127/500\n",
      "1/1 - 1s - loss: 0.6944 - binary_accuracy_inet_decision_function_fv_metric: 0.4956 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4890 - lr: 1.0000e-04 - 612ms/epoch - 612ms/step\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 0.6938 - binary_accuracy_inet_decision_function_fv_metric: 0.4976 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4888 - lr: 1.0000e-04 - 281ms/epoch - 281ms/step\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 0.6937 - binary_accuracy_inet_decision_function_fv_metric: 0.5120 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4888 - lr: 1.0000e-04 - 296ms/epoch - 296ms/step\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 0.6940 - binary_accuracy_inet_decision_function_fv_metric: 0.4949 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4812 - lr: 1.0000e-04 - 332ms/epoch - 332ms/step\n",
      "Epoch 131/500\n",
      "1/1 - 1s - loss: 0.6942 - binary_accuracy_inet_decision_function_fv_metric: 0.5069 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4888 - lr: 1.0000e-04 - 643ms/epoch - 643ms/step\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 0.6945 - binary_accuracy_inet_decision_function_fv_metric: 0.4930 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5098 - lr: 1.0000e-04 - 280ms/epoch - 280ms/step\n",
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 0.6929 - binary_accuracy_inet_decision_function_fv_metric: 0.5119 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5082 - lr: 1.0000e-04 - 332ms/epoch - 332ms/step\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 0.6940 - binary_accuracy_inet_decision_function_fv_metric: 0.5012 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5052 - lr: 1.0000e-04 - 231ms/epoch - 231ms/step\n",
      "Epoch 135/500\n",
      "1/1 - 1s - loss: 0.6931 - binary_accuracy_inet_decision_function_fv_metric: 0.5051 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5052 - lr: 1.0000e-04 - 821ms/epoch - 821ms/step\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 0.6938 - binary_accuracy_inet_decision_function_fv_metric: 0.4979 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5084 - lr: 1.0000e-04 - 424ms/epoch - 424ms/step\n",
      "Epoch 137/500\n",
      "1/1 - 1s - loss: 0.6935 - binary_accuracy_inet_decision_function_fv_metric: 0.5104 - val_loss: 0.6930 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5100 - lr: 1.0000e-04 - 730ms/epoch - 730ms/step\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 0.6947 - binary_accuracy_inet_decision_function_fv_metric: 0.4956 - val_loss: 0.6930 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5194 - lr: 1.0000e-04 - 490ms/epoch - 490ms/step\n",
      "Epoch 139/500\n",
      "1/1 - 0s - loss: 0.6934 - binary_accuracy_inet_decision_function_fv_metric: 0.5049 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5092 - lr: 1.0000e-04 - 336ms/epoch - 336ms/step\n",
      "Epoch 140/500\n",
      "1/1 - 0s - loss: 0.6928 - binary_accuracy_inet_decision_function_fv_metric: 0.5091 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4870 - lr: 1.0000e-04 - 407ms/epoch - 407ms/step\n",
      "Epoch 141/500\n",
      "1/1 - 0s - loss: 0.6939 - binary_accuracy_inet_decision_function_fv_metric: 0.4975 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4932 - lr: 1.0000e-04 - 457ms/epoch - 457ms/step\n",
      "Epoch 142/500\n",
      "1/1 - 0s - loss: 0.6937 - binary_accuracy_inet_decision_function_fv_metric: 0.5089 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4976 - lr: 1.0000e-04 - 370ms/epoch - 370ms/step\n",
      "Epoch 143/500\n",
      "1/1 - 0s - loss: 0.6934 - binary_accuracy_inet_decision_function_fv_metric: 0.5129 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4906 - lr: 1.0000e-04 - 425ms/epoch - 425ms/step\n",
      "Epoch 144/500\n",
      "1/1 - 1s - loss: 0.6947 - binary_accuracy_inet_decision_function_fv_metric: 0.4936 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4904 - lr: 1.0000e-04 - 532ms/epoch - 532ms/step\n",
      "Epoch 145/500\n",
      "1/1 - 0s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.4954 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4908 - lr: 1.0000e-04 - 394ms/epoch - 394ms/step\n",
      "Epoch 146/500\n",
      "1/1 - 0s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.5005 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4910 - lr: 1.0000e-04 - 370ms/epoch - 370ms/step\n",
      "Epoch 147/500\n",
      "1/1 - 0s - loss: 0.6937 - binary_accuracy_inet_decision_function_fv_metric: 0.5016 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4908 - lr: 1.0000e-04 - 313ms/epoch - 313ms/step\n",
      "Epoch 148/500\n",
      "1/1 - 0s - loss: 0.6937 - binary_accuracy_inet_decision_function_fv_metric: 0.5009 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4910 - lr: 1.0000e-04 - 247ms/epoch - 247ms/step\n",
      "Epoch 149/500\n",
      "1/1 - 0s - loss: 0.6938 - binary_accuracy_inet_decision_function_fv_metric: 0.5017 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4918 - lr: 1.0000e-04 - 448ms/epoch - 448ms/step\n",
      "Epoch 150/500\n",
      "1/1 - 0s - loss: 0.6939 - binary_accuracy_inet_decision_function_fv_metric: 0.4969 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4914 - lr: 1.0000e-04 - 330ms/epoch - 330ms/step\n",
      "Epoch 151/500\n",
      "1/1 - 0s - loss: 0.6941 - binary_accuracy_inet_decision_function_fv_metric: 0.4977 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4912 - lr: 1.0000e-04 - 354ms/epoch - 354ms/step\n",
      "Epoch 152/500\n",
      "1/1 - 0s - loss: 0.6934 - binary_accuracy_inet_decision_function_fv_metric: 0.5071 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4912 - lr: 1.0000e-04 - 426ms/epoch - 426ms/step\n",
      "Epoch 153/500\n",
      "1/1 - 0s - loss: 0.6947 - binary_accuracy_inet_decision_function_fv_metric: 0.5002 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4912 - lr: 1.0000e-04 - 324ms/epoch - 324ms/step\n",
      "Epoch 154/500\n",
      "1/1 - 0s - loss: 0.6939 - binary_accuracy_inet_decision_function_fv_metric: 0.4966 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4980 - lr: 1.0000e-04 - 209ms/epoch - 209ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as activation_2_layer_call_fn, activation_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0:02:10\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model,\n",
    " encoder_model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=plot_losses\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate I-Net Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "        \n",
    "    writepath_nas = './results_nas.csv'\n",
    "\n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "\n",
    "    if not os.path.exists(writepath_nas):\n",
    "        with open(writepath_nas, 'w+') as text_file:       \n",
    "            for key in flat_config.keys():\n",
    "                text_file.write(key)\n",
    "                text_file.write(';')         \n",
    "\n",
    "            for hp in history[0].hyperparameters.values.keys():\n",
    "                text_file.write(hp + ';')    \n",
    "               \n",
    "            text_file.write('score')\n",
    "            \n",
    "            text_file.write('\\n')\n",
    "\n",
    "    with open(writepath_nas, 'a+') as text_file:  \n",
    "        for value in flat_config.values():\n",
    "            text_file.write(str(value))\n",
    "            text_file.write(';')\n",
    "\n",
    "        for hp, value in history[0].hyperparameters.values.items():\n",
    "            text_file.write(str(value) + ';')        \n",
    "\n",
    "        \n",
    "        text_file.write(str(history[0].score))\n",
    "            \n",
    "        text_file.write('\\n')            \n",
    "\n",
    "        text_file.close()      \n",
    "        \n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make_classification evaluation Paul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_LR = {\n",
    "    'data': {\n",
    "        'n_datasets': 10,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, mean_squared_error\n",
    "\n",
    "def precision(tp, fp, tn, fn):\n",
    "    return tp / (tp + fp)\n",
    "def recall(tp, fp, tn, fn):\n",
    "    return tp / (tp + fn)\n",
    "def f1(tp, fp, tn, fn):\n",
    "    pre = precision(tp, fp, tn, fn)\n",
    "    rec = recall(tp, fp, tn, fn)\n",
    "    return 2 * (pre * rec) / (pre + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluateSingleSample(i, loss_function, metrics, config):\n",
    "    \n",
    "    informative = np.random.randint(config['data']['number_of_variables']//2, high=config['data']['number_of_variables']+1) #config['data']['number_of_variables']\n",
    "    redundant = np.random.randint(0, high=config['data']['number_of_variables']-informative+1) #0\n",
    "    repeated = config['data']['number_of_variables']-informative-redundant # 0\n",
    "\n",
    "    n_clusters_per_class =  max(2, np.random.randint(0, high=informative//2+1)) #2\n",
    "\n",
    "    X_data, y_data = make_classification(n_samples=config['data']['lambda_dataset_size'], \n",
    "                                                       n_features=config['data']['number_of_variables'], #The total number of features. These comprise n_informative informative features, n_redundant redundant features, n_repeated duplicated features and n_features-n_informative-n_redundant-n_repeated useless features drawn at random.\n",
    "                                                       n_informative=informative,#config['data']['number_of_variables'], #The number of informative features. Each class is composed of a number of gaussian clusters each located around the vertices of a hypercube in a subspace of dimension n_informative.\n",
    "                                                       n_redundant=redundant, #The number of redundant features. These features are generated as random linear combinations of the informative features.\n",
    "                                                       n_repeated=repeated, #The number of duplicated features, drawn randomly from the informative and the redundant features.\n",
    "                                                       n_classes=config['data']['num_classes'], \n",
    "                                                       n_clusters_per_class=n_clusters_per_class, \n",
    "                                                       #flip_y=0.0, #The fraction of samples whose class is assigned randomly. \n",
    "                                                       #class_sep=1.0, #The factor multiplying the hypercube size. Larger values spread out the clusters/classes and make the classification task easier.\n",
    "                                                       #hypercube=False, #If True, the clusters are put on the vertices of a hypercube. If False, the clusters are put on the vertices of a random polytope.\n",
    "                                                       #shift=0.0, #Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep].\n",
    "                                                       #scale=1.0, #Multiply features by the specified value. \n",
    "                                                       shuffle=True, \n",
    "                                                       random_state=100_000+i) \n",
    "    \n",
    "    ## normalisierung\n",
    "    for i, column in enumerate(X_data.T):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(column.reshape(-1, 1))\n",
    "        X_data[:,i] = scaler.transform(column.reshape(-1, 1)).ravel()    \n",
    "    \n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = split_train_test_valid(X_data, y_data, valid_frac=0.25, test_frac=0.1, seed=42)\n",
    "    \n",
    "    \n",
    "    lambda_net = generate_base_model(config)\n",
    "    \n",
    "    x_lambda_weights = shaped_network_parameters_to_array(lambda_net.get_weights(), config)\n",
    "    \n",
    "    \n",
    "    #### so meinte ich das quasi wie du ein logistic regression model basierend auf den lambda-net predictions bekommst ###\n",
    "    #model_valid = LogisticRegression()\n",
    "    #model_valid.fit(X_data, network_parameters_to_network(x_lambda_weights, config).predict(X_train))      \n",
    "    #y_coef_truth = model_valid.coef_\n",
    "\n",
    "        \n",
    "    inet_model = load_inet(loss_function, metrics, config)\n",
    "    \n",
    "    y_dt_pred = inet_model.predict(x_lambda_weights.reshape(1, -1))\n",
    "    y_dt_pred = y_dt_pred[0]\n",
    "    \n",
    "    ## hier für den vergleich dann das model auch auf den network parameters trainieren ###\n",
    "    #model_groundTruth = get_LR(X_train, network_parameters_to_network(x_lambda_weights, config).predict(X_train)\n",
    "    \n",
    "    #model_pred = LogisticRegression()\n",
    "    #model_pred.coef_ = y_coef_pred\n",
    "    #model_pred.intercept_ = 0\n",
    "    #model_pred.classes_ = model_groundTruth.classes_\n",
    "    \n",
    "    \n",
    "    model_pred_inet = parameterDT(y_dt_pred, config)\n",
    "    \n",
    "    y_train_lambda_net = network_parameters_to_network(x_lambda_weights, config).predict(X_train)\n",
    "    model_standard = DecisionTreeClassifier(max_depth=config['function_family']['maximum_depth']) \n",
    "    model_standard.fit(X_train, np.round(y_train_lambda_net))\n",
    "    \n",
    "    y_lambda_net = np.round(network_parameters_to_network(x_lambda_weights, config).predict(X_test)).flatten()\n",
    "    \n",
    "    score_standard_model = model_standard.score(X_test, y_lambda_net)\n",
    "\n",
    "    y_pred_standard_model = np.round(model_standard.predict(X_test))\n",
    "    y_pred_inet_model  = np.round(model_pred_inet.predict(X_test))\n",
    "    \n",
    "    score_inet_model = accuracy_score(y_lambda_net, y_pred_inet_model)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_lambda_net, y_pred_inet_model, labels=[1,0]).ravel()\n",
    "    \n",
    "    pre = precision(tp, fp, tn, fn)\n",
    "    rec = recall(tp, fp, tn, fn)\n",
    "    fone = f1(tp, fp, tn, fn)\n",
    "    \n",
    "    #results.append([i, score_groundTruthModel, score_predModel, mse, tp, fn, fp, tn, pre, rec, fone])\n",
    "    \n",
    "    return i+1, score_standard_model, score_inet_model, tp, fn, fp, tn, pre, rec, fone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   3 out of  10 | elapsed:   10.7s remaining:   25.0s\n",
      "[Parallel(n_jobs=15)]: Done   5 out of  10 | elapsed:   12.4s remaining:   12.4s\n",
      "[Parallel(n_jobs=15)]: Done   7 out of  10 | elapsed:   13.6s remaining:    5.8s\n",
      "[Parallel(n_jobs=15)]: Done  10 out of  10 | elapsed:   14.7s finished\n"
     ]
    }
   ],
   "source": [
    "parallel = Parallel(n_jobs=config['computation']['n_jobs'], verbose=10, backend='loky') #loky\n",
    "\n",
    "result_list = parallel(delayed(evaluateSingleSample)(i, loss_function, metrics, config) for i in range(config_LR['data']['n_datasets']))\n",
    "\n",
    "results = pd.DataFrame(data=result_list,\n",
    "                       columns=[\"index_0=aggregated\", \n",
    "                                \"scoreOnClassfication_BaseModel\", \n",
    "                                \"scoreOnClassfication_PredictedModel\" , \n",
    "                                #\"mse\",  \n",
    "                                \"tp\", \n",
    "                                \"fn\", \n",
    "                                \"fp\", \n",
    "                                \"tn\", \n",
    "                                \"precision\", \n",
    "                                \"recall\", \n",
    "                                \"f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_0=aggregated</th>\n",
       "      <th>scoreOnClassfication_BaseModel</th>\n",
       "      <th>scoreOnClassfication_PredictedModel</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.380</td>\n",
       "      <td>178</td>\n",
       "      <td>304</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.382</td>\n",
       "      <td>189</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>336</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.414</td>\n",
       "      <td>205</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.310</td>\n",
       "      <td>151</td>\n",
       "      <td>340</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.272</td>\n",
       "      <td>130</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.586</td>\n",
       "      <td>292</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.544</td>\n",
       "      <td>268</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.474</td>\n",
       "      <td>223</td>\n",
       "      <td>261</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.496</td>\n",
       "      <td>248</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_0=aggregated  scoreOnClassfication_BaseModel  \\\n",
       "0                  10                           0.978   \n",
       "1                  10                           0.994   \n",
       "2                  10                           1.000   \n",
       "3                  10                           0.994   \n",
       "4                  10                           0.992   \n",
       "5                  10                           0.984   \n",
       "6                  10                           0.998   \n",
       "7                  10                           0.992   \n",
       "8                  10                           0.980   \n",
       "9                  10                           1.000   \n",
       "\n",
       "   scoreOnClassfication_PredictedModel   tp   fn  fp  tn  precision  recall  \\\n",
       "0                                0.380  178  304   6  12      0.967   0.369   \n",
       "1                                0.382  189  309   0   2      1.000   0.380   \n",
       "2                                0.672  336  164   0   0      1.000   0.672   \n",
       "3                                0.414  205  293   0   2      1.000   0.412   \n",
       "4                                0.310  151  340   5   4      0.968   0.308   \n",
       "5                                0.272  130  364   0   6      1.000   0.263   \n",
       "6                                0.586  292  207   0   1      1.000   0.585   \n",
       "7                                0.544  268  228   0   4      1.000   0.540   \n",
       "8                                0.474  223  261   2  14      0.991   0.461   \n",
       "9                                0.496  248  252   0   0      1.000   0.496   \n",
       "\n",
       "     f1  \n",
       "0 0.535  \n",
       "1 0.550  \n",
       "2 0.804  \n",
       "3 0.583  \n",
       "4 0.467  \n",
       "5 0.417  \n",
       "6 0.738  \n",
       "7 0.702  \n",
       "8 0.629  \n",
       "9 0.663  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ab hier ignorieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    index = 0\n",
    "    lambda_net = lambda_net_dataset_train.lambda_net_list[index]\n",
    "    \n",
    "    lambda_net_model = network_parameters_to_network(lambda_net.network_parameters, config)\n",
    "    lambda_net_model_preds = lambda_net_model.predict(lambda_net.X_train_lambda)\n",
    "    dt_train_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_train_data.fit(lambda_net.X_train_lambda, np.round(lambda_net_model_preds))\n",
    "    \n",
    "    random_data = np.random.uniform(0, 1, lambda_net.X_train_lambda.shape)\n",
    "    lambda_net_model_preds_random = lambda_net_model.predict(random_data)\n",
    "    dt_random_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_random_data.fit(random_data, np.round(lambda_net_model_preds_random))\n",
    "    \n",
    "    plot_decision_area_evaluation(lambda_net.X_train_lambda, \n",
    "                                lambda_net.y_train_lambda.flatten(), \n",
    "                                lambda_net.X_test_lambda, \n",
    "                                lambda_net.y_test_lambda.flatten(),\n",
    "                                random_data,\n",
    "                                lambda_net_model_preds_random.flatten(),                                   \n",
    "                                lambda_net_model,\n",
    "                                dt_train_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                model.predict(np.array([lambda_net.network_parameters]))[0],\n",
    "                                np.array([str(i) for i in range(lambda_net.X_train_lambda.shape[1])]),\n",
    "                                config\n",
    "                               )\n",
    "\n",
    "    index = 0\n",
    "    lambda_net = lambda_net_dataset_valid.lambda_net_list[index]\n",
    "    \n",
    "    lambda_net_model = network_parameters_to_network(lambda_net.network_parameters, config)\n",
    "    lambda_net_model_preds = lambda_net_model.predict(lambda_net.X_train_lambda)\n",
    "    dt_train_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_train_data.fit(lambda_net.X_train_lambda, np.round(lambda_net_model_preds))\n",
    "    \n",
    "    random_data = np.random.uniform(0, 1, lambda_net.X_train_lambda.shape)\n",
    "    lambda_net_model_preds_random = lambda_net_model.predict(random_data)\n",
    "    dt_random_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_random_data.fit(random_data, np.round(lambda_net_model_preds_random))\n",
    "    \n",
    "    plot_decision_area_evaluation(lambda_net.X_train_lambda, \n",
    "                                lambda_net.y_train_lambda.flatten(), \n",
    "                                lambda_net.X_test_lambda, \n",
    "                                lambda_net.y_test_lambda.flatten(),\n",
    "                                random_data,\n",
    "                                lambda_net_model_preds_random.flatten(), \n",
    "                                lambda_net_model,\n",
    "                                dt_train_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                model.predict(np.array([lambda_net.network_parameters]))[0],\n",
    "                                np.array([str(i) for i in range(lambda_net.X_train_lambda.shape[1])]),\n",
    "                                config\n",
    "                               )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "if test_size > 0 and not evaluate_distribution:\n",
    "    network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "else:\n",
    "    network_parameters = np.array([lambda_net_dataset_valid.network_parameters_array[index]])\n",
    "    \n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    encoder_model = load_encoder_model(config)\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data(network_parameters, config, encoder_model)    \n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = None\n",
    "if not function_value_loss:\n",
    "    if test_size > 0 and not evaluate_distribution:\n",
    "        dt_parameters = y_test[index][:-2 ** config['function_family']['maximum_depth'] ]\n",
    "    else:\n",
    "        dt_parameters = y_valid[index][:-2 ** config['function_family']['maximum_depth'] ]\n",
    "\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 1537)]       0           []                               \n",
      "                                                                                                  \n",
      " hidden1_1792 (Dense)           (None, 1792)         2756096     ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation1_sigmoid (Activatio  (None, 1792)        0           ['hidden1_1792[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " hidden2_512 (Dense)            (None, 512)          918016      ['activation1_sigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " activation2_sigmoid (Activatio  (None, 512)         0           ['hidden2_512[0][0]']            \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " hidden3_512 (Dense)            (None, 512)          262656      ['activation2_sigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " activation3_sigmoid (Activatio  (None, 512)         0           ['hidden3_512[0][0]']            \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " dropout3_0.5 (Dropout)         (None, 512)          0           ['activation3_sigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " output_coeff_70 (Dense)        (None, 70)           35910       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_1 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_2 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_3 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_4 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_5 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_6 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_7 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_leaf_node_8 (Dense)     (None, 8)            4104        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_combined (Concatenate)  (None, 148)          0           ['output_coeff_70[0][0]',        \n",
      "                                                                  'output_identifier_1[0][0]',    \n",
      "                                                                  'output_identifier_2[0][0]',    \n",
      "                                                                  'output_identifier_3[0][0]',    \n",
      "                                                                  'output_identifier_4[0][0]',    \n",
      "                                                                  'output_identifier_5[0][0]',    \n",
      "                                                                  'output_identifier_6[0][0]',    \n",
      "                                                                  'output_identifier_7[0][0]',    \n",
      "                                                                  'output_leaf_node_8[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,012,692\n",
      "Trainable params: 4,012,692\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Normal: This is useful for looking at means and other linear combinations (e.g. regression coefficients) because of the CLT. Related to that is if something is known to arise due to additive effects of many different small causes then the normal may be a reasonable distribution: for example, many biological measures are the result of multiple genes and multiple environmental factors and therefor are often approximately normal.\n",
    "\n",
    "    Gamma: Right skewed and useful for things with a natural minimum at 0. Commonly used for elapsed times and some financial variables.\n",
    "\n",
    "    Exponential: special case of the Gamma. It is memoryless and scales easily.\n",
    "\n",
    "    Chi-squared (𝜒2): special case of the Gamma. Arises as sum of squared normal variables (so used for variances).\n",
    "\n",
    "    Beta: Defined between 0 and 1 (but could be transformed to be between other values), useful for proportions or other quantities that must be between 0 and 1.\n",
    "\n",
    "    Binomial: How many \"successes\" out of a given number of independent trials with same probability of \"success\".\n",
    "\n",
    "    Poisson: Common for counts. Nice properties that if the number of events in a period of time or area follows a Poisson, then the number in twice the time or area still follows the Poisson (with twice the mean): this works for adding Poissons or scaling with values other than 2.\n",
    "\n",
    "    Note that if events occur over time and the time between occurrences follows an exponential then the number that occur in a time period follows a Poisson.\n",
    "\n",
    "    Negative Binomial: Counts with minimum 0 (or other value depending on which version) and no upper bound. Conceptually it is the number of \"failures\" before k \"successes\". The negative binomial is also a mixture of Poisson variables whose means come from a gamma distribution.\n",
    "\n",
    "    Geometric: special case for negative binomial where it is the number of \"failures\" before the 1st \"success\". If you truncate (round down) an exponential variable to make it discrete, the result is geometric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train & Valid Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55b2ca22e824c9fbc71e2c65e69bdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26c412f439641769bab873df4993d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mean_train_parameters = np.round(np.mean(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "std_train_parameters = np.round(np.std(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "\n",
    "(inet_evaluation_result_dict_train, \n",
    " inet_evaluation_result_dict_mean_train, \n",
    " dt_distilled_list_train,\n",
    " distances_dict) = evaluate_interpretation_net_synthetic_data(lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               lambda_net_dataset_train.X_test_lambda_array,\n",
    "                                                               model,\n",
    "                                                               config,\n",
    "                                                               identifier='train',\n",
    "                                                               mean_train_parameters=mean_train_parameters,\n",
    "                                                               std_train_parameters=std_train_parameters,\n",
    "                                                               network_parameters_train_array=lambda_net_dataset_train.network_parameters_array)\n",
    "\n",
    "\n",
    "(inet_evaluation_result_dict_valid, \n",
    " inet_evaluation_result_dict_mean_valid, \n",
    " dt_distilled_list_valid,\n",
    " distances_dict) = evaluate_interpretation_net_synthetic_data(lambda_net_dataset_valid.network_parameters_array, \n",
    "                                                               lambda_net_dataset_valid.X_test_lambda_array,\n",
    "                                                               model,\n",
    "                                                               config,\n",
    "                                                               identifier='valid',\n",
    "                                                               mean_train_parameters=mean_train_parameters,\n",
    "                                                               std_train_parameters=std_train_parameters,\n",
    "                                                               network_parameters_train_array=lambda_net_dataset_train.network_parameters_array,\n",
    "                                                               distances_dict=distances_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T10:48:37.785965Z",
     "iopub.status.busy": "2022-02-26T10:48:37.785727Z",
     "iopub.status.idle": "2022-02-26T10:48:38.372347Z",
     "shell.execute_reply": "2022-02-26T10:48:38.371431Z",
     "shell.execute_reply.started": "2022-02-26T10:48:37.785945Z"
    },
    "tags": []
   },
   "source": [
    "## Test Data Evaluation (+ Distribution Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#set_loky_pickler('pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#config['computation']['n_jobs'] = 60\n",
    "#config['i_net']['test_size'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 out of   5 | elapsed:  1.2min remaining:  1.8min\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "if evaluate_distribution and test_size > 0:\n",
    "    \n",
    "    (distances_dict, \n",
    "     inet_evaluation_result_dict_test, \n",
    "     inet_evaluation_result_dict_complete_by_distribution_test,\n",
    "     inet_evaluation_result_dict_mean_test,\n",
    "     inet_evaluation_result_dict_mean_by_distribution_test,\n",
    "     inet_evaluation_results_test, \n",
    "     dt_inet_list_test, \n",
    "     dt_distilled_list_test, \n",
    "     data_dict_list_test, \n",
    "     normalizer_list_list_test,\n",
    "     test_network_list_distrib,\n",
    "     model_history_list,\n",
    "     distribution_parameter_list_list) = distribution_evaluation_interpretation_net_synthetic_data(loss_function, \n",
    "                                                                                            metrics,\n",
    "                                                                                            #model,\n",
    "                                                                                           config,\n",
    "                                                                                           distribution_list_evaluation = config['data']['distribution_list_eval'],#['uniform', 'normal', 'gamma', 'exponential', 'beta', 'binomial', 'poisson'],\n",
    "                                                                                           identifier='test',\n",
    "                                                                                           lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                                           mean_train_parameters=mean_train_parameters,\n",
    "                                                                                           std_train_parameters=std_train_parameters,\n",
    "                                                                                           distances_dict=distances_dict,\n",
    "                                                                                           max_distributions_per_class=max_distributions_per_class,#max_distributions_per_class,\n",
    "                                                                                           flip_percentage=noise_injected_level, #0.1,#\n",
    "                                                                                           data_noise=data_noise, #0.1,#\n",
    "                                                                                           random_parameters = random_parameters_distribution, #random_parameters_distribution\n",
    "                                                                                           verbose=0,\n",
    "                                                                                           backend='loky',#sequential\n",
    "                                                                                    )\n",
    "else:\n",
    "    (inet_evaluation_result_dict_test, \n",
    "     inet_evaluation_result_dict_mean_test, \n",
    "     dt_distilled_list_test,\n",
    "     distances_dict) = evaluate_interpretation_net_synthetic_data(lambda_net_dataset_test.network_parameters_array, \n",
    "                                                                   lambda_net_dataset_test.X_test_lambda_array,\n",
    "                                                                   model,\n",
    "                                                                   config,\n",
    "                                                                   identifier='test',\n",
    "                                                                   mean_train_parameters=mean_train_parameters,\n",
    "                                                                   std_train_parameters=std_train_parameters,\n",
    "                                                                   network_parameters_train_array=lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                   distances_dict=distances_dict)\n",
    "    \n",
    "    print_results_synthetic_evaluation(inet_evaluation_result_dict_mean_train, \n",
    "                                       inet_evaluation_result_dict_mean_valid, \n",
    "                                       inet_evaluation_result_dict_mean_test, \n",
    "                                       distances_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-Net Performance by Network:  [0.86  0.968 0.708 0.494 1.   ]\n",
      "Distilled Mean Performance by Network:  [0.624 0.542 0.99  0.512 0.984]\n",
      "Distilled Max Performance by Network:  [0.624 0.542 0.99  0.512 0.984]\n",
      "Median I-Net: 0.86\n",
      "Median DT Distilled: 0.624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc Distilled Train Data</th>\n",
       "      <th>Acc Distilled Data Random</th>\n",
       "      <th>Acc Distilled</th>\n",
       "      <th>Acc I-Net</th>\n",
       "      <th>Soft BC Distilled Train Data</th>\n",
       "      <th>Soft BC Distilled Data Random</th>\n",
       "      <th>Soft BC Distilled</th>\n",
       "      <th>Soft BC I-Net</th>\n",
       "      <th>BC Distilled Train Data</th>\n",
       "      <th>BC Distilled Data Random</th>\n",
       "      <th>BC Distilled</th>\n",
       "      <th>BC I-Net</th>\n",
       "      <th>F1 Score Distilled Train Data</th>\n",
       "      <th>F1 Score Distilled Data Random</th>\n",
       "      <th>F1 Score Distilled</th>\n",
       "      <th>F1 Score I-Net</th>\n",
       "      <th>ROC AUC Score Distilled Train Data</th>\n",
       "      <th>ROC AUC Score Distilled Data Random</th>\n",
       "      <th>ROC AUC Score Distilled</th>\n",
       "      <th>ROC AUC Score I-Net</th>\n",
       "      <th>Runtime Distilled Train Data</th>\n",
       "      <th>Runtime Distilled Data Random</th>\n",
       "      <th>Runtime Distilled</th>\n",
       "      <th>Runtime I-Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['uniform', 'normal', 'gamma', 'beta', 'poisson']</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>5.786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Acc Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                     0.999   \n",
       "\n",
       "                                                   Acc Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                      0.915   \n",
       "\n",
       "                                                   Acc Distilled  Acc I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']          0.730      0.806   \n",
       "\n",
       "                                                   Soft BC Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                         0.322   \n",
       "\n",
       "                                                   Soft BC Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                          0.490   \n",
       "\n",
       "                                                   Soft BC Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']              0.593   \n",
       "\n",
       "                                                   Soft BC I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']          0.682   \n",
       "\n",
       "                                                   BC Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                    0.041   \n",
       "\n",
       "                                                   BC Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                     0.212   \n",
       "\n",
       "                                                   BC Distilled  BC I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']         0.961     0.672   \n",
       "\n",
       "                                                   F1 Score Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                          0.999   \n",
       "\n",
       "                                                   F1 Score Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                           0.906   \n",
       "\n",
       "                                                   F1 Score Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']               0.679   \n",
       "\n",
       "                                                   F1 Score I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']           0.794   \n",
       "\n",
       "                                                   ROC AUC Score Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                               0.999   \n",
       "\n",
       "                                                   ROC AUC Score Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                                0.824   \n",
       "\n",
       "                                                   ROC AUC Score Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                    0.813   \n",
       "\n",
       "                                                   ROC AUC Score I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                0.929   \n",
       "\n",
       "                                                   Runtime Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                         0.135   \n",
       "\n",
       "                                                   Runtime Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                          0.135   \n",
       "\n",
       "                                                   Runtime Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']              0.135   \n",
       "\n",
       "                                                   Runtime I-Net  \n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']          5.786  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Z-Score (Sample to Train Data)</th>\n",
       "      <th>Average Distance to Initialization</th>\n",
       "      <th>Average Mean Distance to Train Data</th>\n",
       "      <th>Average Distance to closest Train Data Sample</th>\n",
       "      <th>Average Biggest Distance for Single Neuron</th>\n",
       "      <th>Minimum Biggest Distance for Single Neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>985.923</td>\n",
       "      <td>459.561</td>\n",
       "      <td>636.776</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.513</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>1001.409</td>\n",
       "      <td>448.078</td>\n",
       "      <td>639.114</td>\n",
       "      <td>513.148</td>\n",
       "      <td>9.734</td>\n",
       "      <td>6.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1193.600</td>\n",
       "      <td>134.623</td>\n",
       "      <td>518.841</td>\n",
       "      <td>333.237</td>\n",
       "      <td>8.524</td>\n",
       "      <td>3.716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average Z-Score (Sample to Train Data)  \\\n",
       "train                                 985.923   \n",
       "valid                                1001.409   \n",
       "test                                 1193.600   \n",
       "\n",
       "       Average Distance to Initialization  \\\n",
       "train                             459.561   \n",
       "valid                             448.078   \n",
       "test                              134.623   \n",
       "\n",
       "       Average Mean Distance to Train Data  \\\n",
       "train                              636.776   \n",
       "valid                              639.114   \n",
       "test                               518.841   \n",
       "\n",
       "       Average Distance to closest Train Data Sample  \\\n",
       "train                                          0.000   \n",
       "valid                                        513.148   \n",
       "test                                         333.237   \n",
       "\n",
       "       Average Biggest Distance for Single Neuron  \\\n",
       "train                                      10.513   \n",
       "valid                                       9.734   \n",
       "test                                        8.524   \n",
       "\n",
       "       Minimum Biggest Distance for Single Neuron  \n",
       "train                                       0.000  \n",
       "valid                                       6.230  \n",
       "test                                        3.716  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if evaluate_distribution and test_size > 0:\n",
    "    #print(distribution_parameter_list_list[0])\n",
    "    #print(lambda_net_dataset_valid.distribution_dict_list_list[0])\n",
    "\n",
    "    inet_performance_distrib_evaluation = np.array(inet_evaluation_result_dict_complete_by_distribution_test[list(inet_evaluation_result_dict_complete_by_distribution_test.keys())[0]]['inet_scores']['accuracy'])\n",
    "    print('I-Net Performance by Network: ', inet_performance_distrib_evaluation)\n",
    "\n",
    "    mean_random_performance_distrib_evaluation = np.mean(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)\n",
    "    print('Distilled Mean Performance by Network: ', mean_random_performance_distrib_evaluation)\n",
    "\n",
    "    max_random_performance_distrib_evaluation = np.max(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)\n",
    "    print('Distilled Max Performance by Network: ', max_random_performance_distrib_evaluation)\n",
    "\n",
    "    print('Median I-Net:', np.median(inet_evaluation_result_dict_complete_by_distribution_test[list(inet_evaluation_result_dict_complete_by_distribution_test.keys())[0]]['inet_scores']['accuracy']))\n",
    "    print('Median DT Distilled:', np.median(np.median(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)))#np.median(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['dt_scores']['accuracy']))\n",
    "\n",
    "    complete_distribution_evaluation_results = get_complete_distribution_evaluation_results_dataframe(inet_evaluation_result_dict_mean_by_distribution_test)\n",
    "    display(complete_distribution_evaluation_results.head(20))\n",
    "    \n",
    "    network_distances = get_print_network_distances_dataframe(distances_dict)\n",
    "    display(network_distances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'samples_class_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex: \u001b[39m\u001b[38;5;124m'\u001b[39m, index)\n\u001b[1;32m     25\u001b[0m distribution_dict \u001b[38;5;241m=\u001b[39m distribution_parameter_list_list[index]\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature 1: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSamples\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mdistribution_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdistribution_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msamples_class_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_dataset_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39mdistribution_dict[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mlist\u001b[39m(distribution_dict[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples_class_0\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Distribution 1: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(distribution_dict[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, (distrib_parameter_name, distrib_parameter_value) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(distribution_dict[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mlist\u001b[39m(distribution_dict[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'samples_class_0'"
     ]
    }
   ],
   "source": [
    "if evaluate_distribution:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    identifier_folder = config['function_family']['dt_type'] + '_' + str(config['function_family']['decision_sparsity']) + '_' + timestr\n",
    "    os.makedirs('./data/distrib_plots/' + identifier_folder + '/', exist_ok=True)\n",
    "    \n",
    "    for i in range(min(3, test_size)):\n",
    "        #index = 14\n",
    "        #index = np.argmax(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['dt_scores']['accuracy']))\n",
    "        top_number = i\n",
    "        #index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['dt_scores']['accuracy']))[::-1][top_number]\n",
    "\n",
    "        scores_distilled_median_random = np.median(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)\n",
    "        scores_distilled_uniform = inet_evaluation_result_dict_complete_by_distribution_test[str(config['data']['distribution_list_eval'][0])]['dt_scores']['accuracy_uniform_data']\n",
    "        scores_distilled_normal = inet_evaluation_result_dict_complete_by_distribution_test[str(config['data']['distribution_list_eval'][0])]['dt_scores']['accuracy_normal_data']\n",
    "        \n",
    "        scores_distilled_array = np.mean([scores_distilled_median_random, scores_distilled_uniform, scores_distilled_normal], axis=0)\n",
    "        \n",
    "        index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test[list(inet_evaluation_result_dict_complete_by_distribution_test.keys())[0]]['inet_scores']['accuracy']) - scores_distilled_array)[::-1][top_number]\n",
    "        #index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.max(np.array([inet_evaluation_result_dict_complete_by_distribution_test[distrib]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0))[::-1][top_number]\n",
    "        #index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.mean(np.array([inet_evaluation_result_dict_complete_by_distribution_test[distrib]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0))[::-1][top_number]\n",
    "\n",
    "        distrib_for_index = np.argmax(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']])[:,index])\n",
    "\n",
    "        print('Index: ', index)\n",
    "        distribution_dict = distribution_parameter_list_list[index]\n",
    "\n",
    "        print('Feature 1: ', 'Samples', distribution_dict[0][list(distribution_dict[0].keys())[0]]['samples_class_0'], '/', config['data']['lambda_dataset_size']-distribution_dict[0][list(distribution_dict[0].keys())[0]]['samples_class_0'])\n",
    "        print('\\t Distribution 1: ' + list(distribution_dict[0].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[0][list(distribution_dict[0].keys())[0]]['class_0'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "        print('\\t Distribution 2: ' + list(distribution_dict[0].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[0][list(distribution_dict[0].keys())[0]]['class_1'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "\n",
    "        print('Feature 2: ', 'Samples', distribution_dict[1][list(distribution_dict[1].keys())[0]]['samples_class_0'], '/', config['data']['lambda_dataset_size']-distribution_dict[1][list(distribution_dict[1].keys())[0]]['samples_class_0'])\n",
    "        print('\\t Distribution 1: ' + list(distribution_dict[1].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[1][list(distribution_dict[1].keys())[0]]['class_0'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "        print('\\t Distribution 2: ' + list(distribution_dict[1].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[1][list(distribution_dict[1].keys())[0]]['class_1'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "\n",
    "        identifier_file = 'index' + str(index) + '_' + '_'.join([list(dist.keys())[0] + '_' +  '_'.join([key + '-' + str(np.round(value, 4)) for key, value in dist[list(dist.keys())[0]]['class_0'].items()]) + '_' + '_'.join([key + '-' + str(np.round(value, 4)) for key, value in dist[list(dist.keys())[0]]['class_1'].items()]) for dist in distribution_parameter_list_list[index]])\n",
    "        \n",
    "        plot_decision_area_evaluation_all_distrib(data_dict_list_test[index]['X_train'], \n",
    "                                            data_dict_list_test[index]['y_train'], \n",
    "                                            data_dict_list_test[index]['X_test'], \n",
    "                                            data_dict_list_test[index]['y_test'],\n",
    "                                            None,\n",
    "                                            None,\n",
    "                                            network_parameters_to_network(shaped_network_parameters_to_array(test_network_list_distrib[index], config), config),\n",
    "                                            dt_distilled_list_test[0][index][-3],\n",
    "                                            dt_distilled_list_test[0][index][-2],\n",
    "                                            dt_distilled_list_test[0][index][-1],\n",
    "                                            [dt_distilled_list_test[i][index][0] for i in range(len(config['data']['distribution_list_eval']))],     \n",
    "                                            dt_inet_list_test[0][index],\n",
    "                                            np.array([str(i) for i in range(data_dict_list_test[index]['X_train'].shape[1])]),\n",
    "                                            config['data']['distribution_list_eval'],\n",
    "                                            config,\n",
    "                                            identifier_folder = identifier_folder,\n",
    "                                            identifier_file = identifier_file\n",
    "                                           )    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    print('I-Net Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    dt_inet = parameterDT(dt_inet_list_test[distrib_for_index][index], config)\n",
    "    image = dt_inet.plot()\n",
    "    display(image)\n",
    "    \n",
    "    print('Random Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(dt_distilled_list_test[distrib_for_index][index][0], fontsize=10)  #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(dt_distilled_list_test[distrib_for_index][index][1], fontsize=10)  #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    plt.show()    \n",
    "    \n",
    "    print('Uniform Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(dt_distilled_list_test[distrib_for_index][index][2], fontsize=10)  #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    plt.show()    \n",
    "else:\n",
    "    print('I-Net Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    dt_parameters = dt_inet_list_test[distrib_for_index][index]\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "    display(image)\n",
    "    \n",
    "    print('Random Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = dt_distilled_list_test[distrib_for_index][index][0].plot_tree() #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    display(image)\n",
    "    \n",
    "    print('Train Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8)) \n",
    "    image = dt_distilled_list_test[distrib_for_index][index][1].plot_tree() #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL'] \n",
    "    display(image)\n",
    "    \n",
    "    print('Uniform Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = dt_distilled_list_test[distrib_for_index][index][2].plot_tree() #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_class_distrib_by_feature(model = model,\n",
    "                                  index = index,\n",
    "                                  test_network = network_parameters_to_network(lambda_net_dataset_valid.network_parameters_array[index], config, base_model=None),\n",
    "                                  distribution_training = config['data']['distribution_list_eval'][distrib_for_index],\n",
    "                                  distribution_dict = lambda_net_dataset_valid.distribution_dict_list_list[index],\n",
    "                                  X_test = lambda_net_dataset_valid.X_test_lambda_array[index],\n",
    "                                  config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_class_distrib_by_feature(model = model,\n",
    "                                  index = index,\n",
    "                                  test_network = network_parameters_to_network(shaped_network_parameters_to_array(test_network_list_distrib[index], config), config, base_model=None),\n",
    "                                  distribution_training = config['data']['distribution_list_eval'][distrib_for_index],\n",
    "                                  distribution_dict = lambda_net_dataset_valid.distribution_dict_list_list[index],\n",
    "                                  X_test =  data_dict_list_test[0]['X_test'],\n",
    "                                  config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Evaluation (Selected Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "if False:\n",
    "    evaluate_network_on_distribution_custom_parameters(distribution_name_feature_0 = 'normal',\n",
    "                                                       distribution_name_feature_1 = 'normal',\n",
    "                                                       distribution_parameters_0_param_1_feature_0 = 1.188840288782265,\n",
    "                                                       distribution_parameters_0_param_2_feature_0 = 0.8566173698593895,\n",
    "                                                       distribution_parameters_1_param_1_feature_0 = 0.8713650102755661,\n",
    "                                                       distribution_parameters_1_param_2_feature_0 = 1.8484540179178748,\n",
    "                                                       distribution_parameters_0_param_1_feature_1 = 1.7185974826882278,\n",
    "                                                       distribution_parameters_0_param_2_feature_1 = 0.5807878500034862,\n",
    "                                                       distribution_parameters_1_param_1_feature_1 = 0.44369536008631294,\n",
    "                                                       distribution_parameters_1_param_2_feature_1 = 1.17864258666672,\n",
    "                                                       inet = model,\n",
    "                                                       config = config,\n",
    "                                                       distribution_list_evaluation = config['data']['distribution_list_eval'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Real-World Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset_size_list = flatten_list([[config['evaluation']['random_evaluation_dataset_size_per_distribution']]*config['evaluation']['number_of_random_evaluations_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL'])\n",
    "dataset_size_list = flatten_list([[config['evaluation']['random_evaluation_dataset_size_per_distribution']]*config['evaluation']['number_of_random_evaluations_per_distribution'], \n",
    "                                  'TRAINDATA', \n",
    "                                  ['STANDARDUNIFORM']*config['evaluation']['number_of_random_evaluations_per_distribution'], \n",
    "                                  ['STANDARDNORMAL']*config['evaluation']['number_of_random_evaluations_per_distribution']])\n",
    "\n",
    "\n",
    "dataset_size_list_print = []\n",
    "for size in dataset_size_list:\n",
    "    if type(size) is int:\n",
    "        size = size//1000\n",
    "        size = str(size) + 'k'\n",
    "        dataset_size_list_print.append(size)\n",
    "    else:\n",
    "        dataset_size_list_print.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#distances_dict = {}\n",
    "evaluation_result_dict = {}\n",
    "results_dict = {}\n",
    "dt_inet_dict = {}\n",
    "dt_distilled_list_dict = {}\n",
    "data_dict = {}\n",
    "normalizer_list_dict = {}\n",
    "test_network_list = {}\n",
    "\n",
    "identifier_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "\n",
    "#adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "#adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "#adult_data.head()\n",
    "\n",
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 #\"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 #\"Occupation\",  #6\n",
    "                 #\"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 \"capital_gain\"\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "nominal_features_adult = [\n",
    "                          'Race', \n",
    "                          'Workclass', \n",
    "                          #'Education',\n",
    "                          \"Marital Status\",\n",
    "                          #\"Occupation\", \n",
    "                          #\"Relationship\"\n",
    "                        ]\n",
    "ordinal_features_adult = ['Sex']\n",
    "\n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "#y_data_adult = pd.Series(OrdinalEncoder().fit_transform(adult_data['capital_gain'].values.reshape(-1, 1)).flatten(), name='capital_gain')\n",
    "y_data_adult = ((adult_data['capital_gain'] != ' <=50K') * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_train_network_adult = deepcopy(config)\n",
    "#config_train_network_adult['lambda_net']['batch_lambda'] = 32\n",
    "#config_train_network_adult['lambda_net']['learning_rate_lambda'] = 0.0003\n",
    "#config_train_network_adult['lambda_net']['dropout_lambda'] = 0.25\n",
    "#config_train_network_adult['lambda_net']['epochs_lambda'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Adult'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_adult, \n",
    "                                                                y_data_adult, \n",
    "                                                                nominal_features = nominal_features_adult, \n",
    "                                                                ordinal_features = ordinal_features_adult,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = config_train_network_adult)\n",
    "\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict['Adult'], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "\n",
    "features_select = [\n",
    "                    #'Cabin', \n",
    "                    #'Ticket', \n",
    "                    #'Name', \n",
    "                    #'PassengerId'    \n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "nominal_features_titanic = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features_titanic = ['Sex']\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Titanic'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_titanic, \n",
    "                                                                y_data_titanic, \n",
    "                                                                nominal_features = nominal_features_titanic, \n",
    "                                                                ordinal_features = ordinal_features_titanic,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     \n",
    "    \n",
    "    y_train = data_dict[identifier]['y_train']\n",
    "    y_train_pred = pd.Series(np.round(test_network_list[identifier].predict(data_dict[identifier]['X_train'])).ravel(), \n",
    "                             name=\"Survived\")\n",
    "    X_data = pd.concat([data_dict[identifier]['X_train'], y_train_pred], axis=1)\n",
    "    display(X_data.head())\n",
    "    \n",
    "    X_data.groupby(\"Survived\").SibSp.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    #X_data[X_data.Parch > 0.8].groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    #plt.show()\n",
    "    X_data.groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    X_data.groupby(\"Survived\").Sex.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    uniform_data = generate_random_data_points_custom(config['data']['x_min'], \n",
    "                                   config['data']['x_max'],\n",
    "                                   config['evaluation']['random_evaluation_dataset_size_per_distribution'], \n",
    "                                   config['data']['number_of_variables'], \n",
    "                                   config['data']['categorical_indices'],\n",
    "                                   distrib='standarduniform',\n",
    "                                   random_parameters=config['data']['random_parameters_distribution'],\n",
    "                                   distrib_param_max=config['data']['distrib_param_max'],\n",
    "                                   seed=config['computation']['RANDOM_SEED'],\n",
    "                                   config=config)    \n",
    "    \n",
    "    y_uniform_data = np.round(test_network_list[identifier].predict(uniform_data))\n",
    "\n",
    "    uniform_data_with_labels_df = pd.DataFrame(data=np.hstack([uniform_data, y_uniform_data]), columns=X_data.columns)    \n",
    "    \n",
    "    uniform_data_with_labels_df.groupby(\"Survived\").SibSp.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    uniform_data_with_labels_df[uniform_data_with_labels_df.SibSp > 0.56].groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    uniform_data_with_labels_df[uniform_data_with_labels_df.SibSp < 0.56].groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()    \n",
    "    \n",
    "    uniform_data_with_labels_df.groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    uniform_data_with_labels_df.groupby(\"Survived\").Sex.hist(alpha=0.6)\n",
    "    plt.show()        \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           'Weight', \n",
    "                           'Height', \n",
    "                           'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "nominal_features_absenteeism = []\n",
    "ordinal_features_absenteeism = []\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 4) * 1) #absenteeism_data['Absenteeism time in hours']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Absenteeism'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_absenteeism, \n",
    "                                                                y_data_absenteeism, \n",
    "                                                                nominal_features = nominal_features_absenteeism, \n",
    "                                                                ordinal_features = ordinal_features_absenteeism,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('real_world_datasets/Loan/loan-train.csv', delimiter=',')\n",
    "\n",
    "loan_data['Gender'].fillna(loan_data['Gender'].mode()[0], inplace=True)\n",
    "loan_data['Dependents'].fillna(loan_data['Dependents'].mode()[0], inplace=True)\n",
    "loan_data['Married'].fillna(loan_data['Married'].mode()[0], inplace=True)\n",
    "loan_data['Self_Employed'].fillna(loan_data['Self_Employed'].mode()[0], inplace=True)\n",
    "loan_data['LoanAmount'].fillna(loan_data['LoanAmount'].mean(), inplace=True)\n",
    "loan_data['Loan_Amount_Term'].fillna(loan_data['Loan_Amount_Term'].mean(), inplace=True)\n",
    "loan_data['Credit_History'].fillna(loan_data['Credit_History'].mean(), inplace=True)\n",
    "\n",
    "features_select = [\n",
    "                    #'Loan_ID', \n",
    "                    'Gender', #\n",
    "                    'Married', \n",
    "                    'Dependents', \n",
    "                    'Education',\n",
    "                    'Self_Employed', \n",
    "                    'ApplicantIncome', \n",
    "                    'CoapplicantIncome', \n",
    "                    'LoanAmount',\n",
    "                    'Loan_Amount_Term', \n",
    "                    'Credit_History', \n",
    "                    'Property_Area', \n",
    "                    'Loan_Status'\n",
    "                    ]\n",
    "\n",
    "loan_data = loan_data[features_select]\n",
    "\n",
    "#loan_data['Dependents'][loan_data['Dependents'] == '3+'] = 4\n",
    "#loan_data['Dependents'] = loan_data['Dependents'].astype(int)\n",
    "\n",
    "#loan_data['Property_Area'][loan_data['Property_Area'] == 'Rural'] = 0\n",
    "#loan_data['Property_Area'][loan_data['Property_Area'] == 'Semiurban'] = 1\n",
    "#loan_data['Property_Area'][loan_data['Property_Area'] == 'Urban'] = 2\n",
    "#loan_data['Property_Area'] = loan_data['Property_Area'].astype(int)\n",
    "\n",
    "nominal_features_loan = [\n",
    "                        'Dependents',\n",
    "                        'Property_Area',    \n",
    "                        ]\n",
    "\n",
    "\n",
    "ordinal_features_loan = [\n",
    "                    'Education',\n",
    "                    'Gender', \n",
    "                    'Married', \n",
    "                    'Self_Employed',\n",
    "                   ]\n",
    "    \n",
    "X_data_loan = loan_data.drop(['Loan_Status'], axis = 1)\n",
    "y_data_loan = ((loan_data['Loan_Status'] == 'Y') * 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_train_network_loan_house = deepcopy(config)\n",
    "#config_train_network_loan_house['lambda_net']['batch_lambda'] = 64#16\n",
    "#config_train_network_loan_house['lambda_net']['learning_rate_lambda'] = 0.001\n",
    "#config_train_network_loan_house['lambda_net']['dropout_lambda'] = 0#.1\n",
    "#config_train_network_loan_house['lambda_net']['epochs_lambda'] = 500\n",
    "#config_train_network_loan_house['lambda_net']['optimizer_lambda'] = 'adam'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Loan House'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_loan, \n",
    "                                                                y_data_loan, \n",
    "                                                                nominal_features = nominal_features_loan, \n",
    "                                                                ordinal_features = ordinal_features_loan,\n",
    "                                                                #config = config_train_network_loan_house,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loan_credit_data = pd.read_csv('real_world_datasets/Credit Loan/train_split.csv', delimiter=',')\n",
    "\n",
    "loan_credit_data['emp_title'].fillna(loan_credit_data['emp_title'].mode()[0], inplace=True)\n",
    "loan_credit_data['emp_length'].fillna(loan_credit_data['emp_length'].mode()[0], inplace=True)\n",
    "#loan_credit_data['desc'].fillna(loan_credit_data['desc'].mode()[0], inplace=True)\n",
    "loan_credit_data['title'].fillna(loan_credit_data['title'].mode()[0], inplace=True)\n",
    "#loan_credit_data['mths_since_last_delinq'].fillna(loan_credit_data['mths_since_last_delinq'].mode()[0], inplace=True)\n",
    "#loan_credit_data['mths_since_last_record'].fillna(loan_credit_data['mths_since_last_record'].mode()[0], inplace=True)\n",
    "loan_credit_data['revol_util'].fillna(loan_credit_data['revol_util'].mode()[0], inplace=True)\n",
    "loan_credit_data['collections_12_mths_ex_med'].fillna(loan_credit_data['collections_12_mths_ex_med'].mode()[0], inplace=True)\n",
    "#loan_credit_data['mths_since_last_major_derog'].fillna(loan_credit_data['mths_since_last_major_derog'].mode()[0], inplace=True)\n",
    "#loan_credit_data['verification_status_joint'].fillna(loan_credit_data['verification_status_joint'].mode()[0], inplace=True)\n",
    "loan_credit_data['tot_coll_amt'].fillna(loan_credit_data['tot_coll_amt'].mode()[0], inplace=True)\n",
    "loan_credit_data['tot_cur_bal'].fillna(loan_credit_data['tot_cur_bal'].mode()[0], inplace=True)\n",
    "loan_credit_data['total_rev_hi_lim'].fillna(loan_credit_data['total_rev_hi_lim'].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "##remove too many null\n",
    "#'mths_since_last_delinq','mths_since_last_record', 'mths_since_last_major_derog','pymnt_plan','desc', 'verification_status_joint'\n",
    "\n",
    "\n",
    "features_select = [\n",
    "                    #'member_id', \n",
    "                    'loan_amnt', \n",
    "                    'funded_amnt', \n",
    "                    'funded_amnt_inv', \n",
    "                    'term',\n",
    "                    #'batch_enrolled',\n",
    "                    'int_rate', \n",
    "                    'grade', \n",
    "                    #'sub_grade', \n",
    "                    #'emp_title',\n",
    "                    'emp_length',\n",
    "                    'home_ownership', \n",
    "                    'annual_inc', \n",
    "                    'verification_status',\n",
    "                    #'pymnt_plan', \n",
    "                    #'desc', \n",
    "                    'purpose', \n",
    "                    'title', \n",
    "                    #'zip_code', \n",
    "                    #'addr_state',\n",
    "                    'dti', \n",
    "                    'delinq_2yrs', \n",
    "                    'inq_last_6mths', \n",
    "                    #'mths_since_last_delinq',\n",
    "                    #'mths_since_last_record',\n",
    "                    'open_acc', \n",
    "                    'pub_rec', \n",
    "                    'revol_bal',\n",
    "                    'revol_util', \n",
    "                    'total_acc', \n",
    "                    'initial_list_status', \n",
    "                    'total_rec_int',\n",
    "                    'total_rec_late_fee', \n",
    "                    'recoveries', \n",
    "                    'collection_recovery_fee',\n",
    "                    'collections_12_mths_ex_med', \n",
    "                    #'mths_since_last_major_derog',\n",
    "                    'application_type', \n",
    "                    #'verification_status_joint', \n",
    "                    'last_week_pay',\n",
    "                    'acc_now_delinq', \n",
    "                    'tot_coll_amt', \n",
    "                    'tot_cur_bal', \n",
    "                    'total_rev_hi_lim',\n",
    "                    'loan_status'\n",
    "                    ]\n",
    "\n",
    "loan_credit_data = loan_credit_data[features_select]\n",
    "\n",
    "nominal_features_loan_credit = [\n",
    "\n",
    "                        ]\n",
    "ordinal_features_loan_credit = [\n",
    "                    #'member_id', \n",
    "                    'loan_amnt', \n",
    "                    'funded_amnt', \n",
    "                    'funded_amnt_inv', \n",
    "                    'term',\n",
    "                    #'batch_enrolled',\n",
    "                    'int_rate', \n",
    "                    'grade', \n",
    "                    #'sub_grade', \n",
    "                    #'emp_title',\n",
    "                    'emp_length',\n",
    "                    'home_ownership', \n",
    "                    'annual_inc', \n",
    "                    'verification_status',\n",
    "                    #'pymnt_plan', \n",
    "                    #'desc', \n",
    "                    'purpose', \n",
    "                    'title', \n",
    "                    #'zip_code', \n",
    "                    #'addr_state',\n",
    "                    'dti', \n",
    "                    'delinq_2yrs', \n",
    "                    'inq_last_6mths', \n",
    "                    #'mths_since_last_delinq',\n",
    "                    #'mths_since_last_record',\n",
    "                    'open_acc', \n",
    "                    'pub_rec', \n",
    "                    'revol_bal',\n",
    "                    'revol_util', \n",
    "                    'total_acc', \n",
    "                    'initial_list_status', \n",
    "                    'total_rec_int',\n",
    "                    'total_rec_late_fee', \n",
    "                    'recoveries', \n",
    "                    'collection_recovery_fee',\n",
    "                    'collections_12_mths_ex_med', \n",
    "                    #'mths_since_last_major_derog',\n",
    "                    'application_type', \n",
    "                    #'verification_status_joint', \n",
    "                    'last_week_pay',\n",
    "                    'acc_now_delinq', \n",
    "                    'tot_coll_amt', \n",
    "                    'tot_cur_bal', \n",
    "                    'total_rev_hi_lim',\n",
    "                   ]\n",
    "    \n",
    "X_data_loan_credit = loan_credit_data.drop(['loan_status'], axis = 1)\n",
    "y_data_loan_credit = pd.Series(OrdinalEncoder().fit_transform(loan_credit_data['loan_status'].values.reshape(-1, 1)).flatten(), name='loan_status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Loan Credit'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_loan_credit, \n",
    "                                                                y_data_loan_credit, \n",
    "                                                                nominal_features = nominal_features_loan_credit, \n",
    "                                                                ordinal_features = ordinal_features_loan_credit,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medical_insurance_data = pd.read_csv('real_world_datasets/Medical Insurance/insurance.csv', delimiter=',')\n",
    "\n",
    "features_select = [\n",
    "                    'age', \n",
    "                    'sex', \n",
    "                    'bmi', \n",
    "                    'children', \n",
    "                    'smoker',\n",
    "                    'region',\n",
    "                    'charges'\n",
    "                    ]\n",
    "\n",
    "medical_insurance_data = medical_insurance_data[features_select]\n",
    "\n",
    "nominal_features_medical_insurance = [\n",
    "                    'region',\n",
    "                        ]\n",
    "ordinal_features_medical_insurance = [\n",
    "                    'sex',\n",
    "                    'smoker'\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_medical_insurance = medical_insurance_data.drop(['charges'], axis = 1)\n",
    "y_data_medical_insurance = ((medical_insurance_data['charges'] > 10_000) * 1)\n",
    "\n",
    "X_data_medical_insurance.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Medical Insurance'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_medical_insurance, \n",
    "                                                                y_data_medical_insurance, \n",
    "                                                                nominal_features = nominal_features_medical_insurance, \n",
    "                                                                ordinal_features = ordinal_features_medical_insurance,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bank_data = pd.read_csv('real_world_datasets/Bank Marketing/bank-full.csv', delimiter=';') #bank\n",
    "\n",
    "features_select = [\n",
    "                    'age',\n",
    "                    'job', \n",
    "                    'marital', \n",
    "                    'education', \n",
    "                    'default',\n",
    "                    'housing',\n",
    "                    'loan',\n",
    "                    #'contact',\n",
    "                    #'day',\n",
    "                    #'month',\n",
    "                    'duration',\n",
    "                    'campaign',\n",
    "                    'pdays',\n",
    "                    'previous',\n",
    "                    'poutcome',\n",
    "                    'y',\n",
    "                    ]\n",
    "\n",
    "bank_data = bank_data[features_select]\n",
    "\n",
    "nominal_features_bank = [\n",
    "                        'job',\n",
    "                        'education',\n",
    "                        #'contact',\n",
    "                        #'day',\n",
    "                        #'month',\n",
    "                        'poutcome',\n",
    "                        ]\n",
    "ordinal_features_bank = [\n",
    "                    'marital',\n",
    "                    'default',\n",
    "                    'housing',\n",
    "                    'loan',\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_bank = bank_data.drop(['y'], axis = 1)\n",
    "y_data_bank = pd.Series(OrdinalEncoder().fit_transform(bank_data['y'].values.reshape(-1, 1)).flatten(), name='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Bank Marketing'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_bank, \n",
    "                                                                y_data_bank, \n",
    "                                                                nominal_features = nominal_features_bank, \n",
    "                                                                ordinal_features = ordinal_features_bank,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cervical cancer (Risk Factors) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00383/risk_factors_cervical_cancer.csv', index_col=False)#, names=feature_names\n",
    "\n",
    "features_select = [\n",
    "                    'Age',\n",
    "                    'Number of sexual partners',\n",
    "                    'First sexual intercourse',\n",
    "                    'Num of pregnancies',\n",
    "                    'Smokes',\n",
    "                    'Smokes (years)',\n",
    "                    'Hormonal Contraceptives',\n",
    "                    'Hormonal Contraceptives (years)',\n",
    "                    'IUD',\n",
    "                    'IUD (years)',\n",
    "                    'STDs',\n",
    "                    'STDs (number)',\n",
    "                    'STDs: Number of diagnosis',\n",
    "                    'STDs: Time since first diagnosis',\n",
    "                    'STDs: Time since last diagnosis',\n",
    "                    'Biopsy'\n",
    "                    ]\n",
    "\n",
    "cc_data = cc_data[features_select]\n",
    "\n",
    "cc_data['Number of sexual partners'][cc_data['Number of sexual partners'] == '?'] = cc_data['Number of sexual partners'].mode()[0]\n",
    "cc_data['First sexual intercourse'][cc_data['First sexual intercourse'] == '?'] = cc_data['First sexual intercourse'].mode()[0]\n",
    "cc_data['Num of pregnancies'][cc_data['Num of pregnancies'] == '?'] = cc_data['Num of pregnancies'].mode()[0]\n",
    "cc_data['Smokes'][cc_data['Smokes'] == '?'] = cc_data['Smokes'].mode()[0]\n",
    "cc_data['Smokes (years)'][cc_data['Smokes (years)'] == '?'] = cc_data['Smokes (years)'].mode()[0]\n",
    "cc_data['Hormonal Contraceptives'][cc_data['Hormonal Contraceptives'] == '?'] = cc_data['Hormonal Contraceptives'].mode()[0]\n",
    "cc_data['Hormonal Contraceptives (years)'][cc_data['Hormonal Contraceptives (years)'] == '?'] = cc_data['Hormonal Contraceptives (years)'].mode()[0]\n",
    "cc_data['IUD'][cc_data['IUD'] == '?'] = cc_data['IUD'].mode()[0]\n",
    "cc_data['IUD (years)'][cc_data['IUD (years)'] == '?'] = cc_data['IUD (years)'].mode()[0]\n",
    "cc_data['STDs'][cc_data['STDs'] == '?'] = cc_data['STDs'].mode()[0]\n",
    "cc_data['STDs (number)'][cc_data['STDs (number)'] == '?'] = cc_data['STDs (number)'].mode()[0]\n",
    "cc_data['STDs: Time since first diagnosis'][cc_data['STDs: Time since first diagnosis'] == '?'] = cc_data['STDs: Time since first diagnosis'][cc_data['STDs: Time since first diagnosis'] != '?'].mode()[0]\n",
    "cc_data['STDs: Time since last diagnosis'][cc_data['STDs: Time since last diagnosis'] == '?'] = cc_data['STDs: Time since last diagnosis'][cc_data['STDs: Time since last diagnosis'] != '?'].mode()[0]\n",
    "\n",
    "nominal_features_cc = [\n",
    "                        ]\n",
    "ordinal_features_cc = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_cc = cc_data.drop(['Biopsy'], axis = 1)\n",
    "y_data_cc = pd.Series(OrdinalEncoder().fit_transform(cc_data['Biopsy'].values.reshape(-1, 1)).flatten(), name='Biopsy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Cervical Cancer'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_cc, \n",
    "                                                                y_data_cc, \n",
    "                                                                nominal_features = nominal_features_cc, \n",
    "                                                                ordinal_features = ordinal_features_cc,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brest Cancer Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'Sample code number',\n",
    "                'Clump Thickness',\n",
    "                'Uniformity of Cell Size',\n",
    "                'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion',\n",
    "                'Single Epithelial Cell Size',\n",
    "                'Bare Nuclei',\n",
    "                'Bland Chromatin',\n",
    "                'Normal Nucleoli',\n",
    "                'Mitoses',\n",
    "                'Class',\n",
    "                ]\n",
    "\n",
    "bcw_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', names=feature_names, index_col=False)\n",
    "\n",
    "bcw_data['Clump Thickness'][bcw_data['Clump Thickness'] == '?'] = bcw_data['Clump Thickness'].mode()[0]\n",
    "bcw_data['Uniformity of Cell Size'][bcw_data['Uniformity of Cell Size'] == '?'] = bcw_data['Uniformity of Cell Size'].mode()[0]\n",
    "bcw_data['Uniformity of Cell Shape'][bcw_data['Uniformity of Cell Shape'] == '?'] = bcw_data['Uniformity of Cell Shape'].mode()[0]\n",
    "bcw_data['Marginal Adhesion'][bcw_data['Marginal Adhesion'] == '?'] = bcw_data['Marginal Adhesion'].mode()[0]\n",
    "bcw_data['Single Epithelial Cell Size'][bcw_data['Single Epithelial Cell Size'] == '?'] = bcw_data['Single Epithelial Cell Size'].mode()[0]\n",
    "bcw_data['Bare Nuclei'][bcw_data['Bare Nuclei'] == '?'] = bcw_data['Bare Nuclei'].mode()[0]\n",
    "bcw_data['Bland Chromatin'][bcw_data['Bland Chromatin'] == '?'] = bcw_data['Bland Chromatin'].mode()[0]\n",
    "bcw_data['Normal Nucleoli'][bcw_data['Normal Nucleoli'] == '?'] = bcw_data['Normal Nucleoli'].mode()[0]\n",
    "bcw_data['Mitoses'][bcw_data['Mitoses'] == '?'] = bcw_data['Mitoses'].mode()[0]\n",
    "\n",
    "features_select = [\n",
    "                #'Sample code number',\n",
    "                'Clump Thickness',\n",
    "                'Uniformity of Cell Size',\n",
    "                'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion',\n",
    "                'Single Epithelial Cell Size',\n",
    "                'Bare Nuclei',\n",
    "                'Bland Chromatin',\n",
    "                'Normal Nucleoli',\n",
    "                'Mitoses',\n",
    "                'Class',\n",
    "                    ]\n",
    "\n",
    "bcw_data = bcw_data[features_select]\n",
    "\n",
    "nominal_features_bcw = [\n",
    "                        ]\n",
    "ordinal_features_bcw = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_bcw = bcw_data.drop(['Class'], axis = 1)\n",
    "y_data_bcw = pd.Series(OrdinalEncoder().fit_transform(bcw_data['Class'].values.reshape(-1, 1)).flatten(), name='Class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Brest Cancer Wisconsin'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_bcw, \n",
    "                                                                y_data_bcw, \n",
    "                                                                nominal_features = nominal_features_bcw, \n",
    "                                                                ordinal_features = ordinal_features_bcw,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin Diagnostic Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'ID number',\n",
    "                'Diagnosis',\n",
    "                'radius',# (mean of distances from center to points on the perimeter)\n",
    "                'texture',# (standard deviation of gray-scale values)\n",
    "                'perimeter',\n",
    "                'area',\n",
    "                'smoothness',# (local variation in radius lengths)\n",
    "                'compactness',# (perimeter^2 / area - 1.0)\n",
    "                'concavity',# (severity of concave portions of the contour)\n",
    "                'concave points',# (number of concave portions of the contour)\n",
    "                'symmetry',\n",
    "                'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                ]\n",
    "#Wisconsin Diagnostic Breast Cancer\n",
    "wdbc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', names=feature_names, index_col=False)\n",
    "\n",
    "features_select = [\n",
    "                    #'ID number',\n",
    "                    'Diagnosis',\n",
    "                    'radius',# (mean of distances from center to points on the perimeter)\n",
    "                    'texture',# (standard deviation of gray-scale values)\n",
    "                    'perimeter',\n",
    "                    'area',\n",
    "                    'smoothness',# (local variation in radius lengths)\n",
    "                    'compactness',# (perimeter^2 / area - 1.0)\n",
    "                    'concavity',# (severity of concave portions of the contour)\n",
    "                    'concave points',# (number of concave portions of the contour)\n",
    "                    'symmetry',\n",
    "                    'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                    ]\n",
    "\n",
    "wdbc_data = wdbc_data[features_select]\n",
    "\n",
    "nominal_features_wdbc = [\n",
    "                        ]\n",
    "ordinal_features_wdbc = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_wdbc = wdbc_data.drop(['Diagnosis'], axis = 1)\n",
    "y_data_wdbc= pd.Series(OrdinalEncoder().fit_transform(wdbc_data['Diagnosis'].values.reshape(-1, 1)).flatten(), name='Diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Wisconsin Diagnostic Breast Cancer'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_wdbc, \n",
    "                                                                y_data_wdbc, \n",
    "                                                                nominal_features = nominal_features_wdbc, \n",
    "                                                                ordinal_features = ordinal_features_wdbc,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin Prognostic Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'ID number',\n",
    "                'Diagnosis',\n",
    "                'radius',# (mean of distances from center to points on the perimeter)\n",
    "                'texture',# (standard deviation of gray-scale values)\n",
    "                'perimeter',\n",
    "                'area',\n",
    "                'smoothness',# (local variation in radius lengths)\n",
    "                'compactness',# (perimeter^2 / area - 1.0)\n",
    "                'concavity',# (severity of concave portions of the contour)\n",
    "                'concave points',# (number of concave portions of the contour)\n",
    "                'symmetry',\n",
    "                'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                ]\n",
    "#Wisconsin Prognostic Breast Cancer\n",
    "wpbc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wpbc.data', names=feature_names, index_col=False)\n",
    "\n",
    "features_select = [\n",
    "                    #'ID number',\n",
    "                    'Diagnosis',\n",
    "                    'radius',# (mean of distances from center to points on the perimeter)\n",
    "                    'texture',# (standard deviation of gray-scale values)\n",
    "                    'perimeter',\n",
    "                    'area',\n",
    "                    'smoothness',# (local variation in radius lengths)\n",
    "                    'compactness',# (perimeter^2 / area - 1.0)\n",
    "                    'concavity',# (severity of concave portions of the contour)\n",
    "                    'concave points',# (number of concave portions of the contour)\n",
    "                    'symmetry',\n",
    "                    'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                    ]\n",
    "\n",
    "wpbc_data = wpbc_data[features_select]\n",
    "\n",
    "nominal_features_wpbc = [\n",
    "                        ]\n",
    "ordinal_features_wpbc = [\n",
    "                   ]\n",
    " \n",
    "X_data_wpbc = wpbc_data.drop(['Diagnosis'], axis = 1)\n",
    "y_data_wpbc= pd.Series(OrdinalEncoder().fit_transform(wpbc_data['Diagnosis'].values.reshape(-1, 1)).flatten(), name='Diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Wisconsin Prognostic Breast Cancer'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_wpbc, \n",
    "                                                                y_data_wpbc, \n",
    "                                                                nominal_features = nominal_features_wpbc, \n",
    "                                                                ordinal_features = ordinal_features_wpbc,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'Sex',#\t\tnominal\t\t\tM, F, and I (infant)\n",
    "                'Length',#\tcontinuous\tmm\tLongest shell measurement\n",
    "                'Diameter',#\tcontinuous\tmm\tperpendicular to length\n",
    "                'Height',#\t\tcontinuous\tmm\twith meat in shell\n",
    "                'Whole weight',#\tcontinuous\tgrams\twhole abalone\n",
    "                'Shucked weight',#\tcontinuous\tgrams\tweight of meat\n",
    "                'Viscera weight',#\tcontinuous\tgrams\tgut weight (after bleeding)\n",
    "                'Shell weight',#\tcontinuous\tgrams\tafter being dried\n",
    "                'Rings',#\t\tinteger\t\t\t+1.5 gives the age in years\n",
    "                ]\n",
    "\n",
    "abalone_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data', names=feature_names, index_col=False)\n",
    "\n",
    "\n",
    "features_select = [\n",
    "                'Sex',#\t\tnominal\t\t\tM, F, and I (infant)\n",
    "                'Length',#\tcontinuous\tmm\tLongest shell measurement\n",
    "                'Diameter',#\tcontinuous\tmm\tperpendicular to length\n",
    "                'Height',#\t\tcontinuous\tmm\twith meat in shell\n",
    "                'Whole weight',#\tcontinuous\tgrams\twhole abalone\n",
    "                'Shucked weight',#\tcontinuous\tgrams\tweight of meat\n",
    "                'Viscera weight',#\tcontinuous\tgrams\tgut weight (after bleeding)\n",
    "                'Shell weight',#\tcontinuous\tgrams\tafter being dried\n",
    "                'Rings',#\t\tinteger\t\t\t+1.5 gives the age in years\n",
    "                    ]\n",
    "\n",
    "abalone_data = abalone_data[features_select]\n",
    "\n",
    "nominal_features_abalone = [\n",
    "                        'Sex',\n",
    "                        ]\n",
    "ordinal_features_abalone = [\n",
    "                   ]\n",
    "   \n",
    "X_data_abalone = abalone_data.drop(['Rings'], axis = 1)\n",
    "y_data_abalone = ((abalone_data['Rings'] > 10) * 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Abalone'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_abalone, \n",
    "                                                                y_data_abalone, \n",
    "                                                                nominal_features = nominal_features_abalone, \n",
    "                                                                ordinal_features = ordinal_features_abalone,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "   'buying',#       v-high, high, med, low\n",
    "   'maint',#        v-high, high, med, low\n",
    "   'doors',#        2, 3, 4, 5-more\n",
    "   'persons',#      2, 4, more\n",
    "   'lug_boot',#     small, med, big\n",
    "   'safety',#       low, med, high\n",
    "   'class',#        unacc, acc, good, v-good\n",
    "                ]\n",
    "\n",
    "car_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=feature_names, index_col=False)\n",
    "\n",
    "features_select = [\n",
    "                   'buying',#       v-high, high, med, low\n",
    "                   'maint',#        v-high, high, med, low\n",
    "                   'doors',#        2, 3, 4, 5-more\n",
    "                   'persons',#      2, 4, more\n",
    "                   'lug_boot',#     small, med, big\n",
    "                   'safety',#       low, med, high\n",
    "                   'class',#        unacc, acc, good, v-good\n",
    "                    ]\n",
    "\n",
    "car_data = car_data[features_select]\n",
    "\n",
    "nominal_features_car = [\n",
    "                       'buying',#       v-high, high, med, low\n",
    "                       'maint',#        v-high, high, med, low\n",
    "                       'doors',#        2, 3, 4, 5-more\n",
    "                       'persons',#      2, 4, more\n",
    "                       'lug_boot',#     small, med, big\n",
    "                       'safety',#       low, med, high\n",
    "                        ]\n",
    "\n",
    "ordinal_features_car = [\n",
    "                   ]\n",
    "\n",
    "\n",
    "    \n",
    "X_data_car = car_data.drop(['class'], axis = 1)\n",
    "y_data_car = ((car_data['class'] != 'unacc') * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Car'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_car, \n",
    "                                                                y_data_car, \n",
    "                                                                nominal_features = nominal_features_car, \n",
    "                                                                ordinal_features = ordinal_features_car,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "   'age',#      \n",
    "   'sex',#   \n",
    "   'cp',#      \n",
    "   'trestbps',#\n",
    "   'chol',#    \n",
    "   'fbs',#      \n",
    "   'restecg',# \n",
    "   'thalach',#      \n",
    "   'exang',#   \n",
    "   'oldpeak',#      \n",
    "   'slope',#\n",
    "   'ca',#    \n",
    "   'thal',#      \n",
    "   'num',#     \n",
    "                ]\n",
    "\n",
    "heart_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data', names=feature_names, index_col=False) #, delimiter=' '\n",
    "print(heart_data.shape)\n",
    "\n",
    "\n",
    "nominal_features_heart = [\n",
    "                        ]\n",
    "\n",
    "ordinal_features_heart = [\n",
    "                   ]\n",
    "\n",
    "\n",
    "heart_data['age'][heart_data['age'] == '?'] = heart_data['age'].mode()[0]\n",
    "heart_data['sex'][heart_data['sex'] == '?'] = heart_data['sex'].mode()[0]\n",
    "heart_data['cp'][heart_data['cp'] == '?'] = heart_data['cp'].mode()[0]\n",
    "heart_data['trestbps'][heart_data['trestbps'] == '?'] = heart_data['trestbps'].mode()[0]\n",
    "heart_data['chol'][heart_data['chol'] == '?'] = heart_data['chol'].mode()[0]\n",
    "heart_data['fbs'][heart_data['fbs'] == '?'] = heart_data['fbs'].mode()[0]\n",
    "heart_data['restecg'][heart_data['restecg'] == '?'] = heart_data['restecg'].mode()[0]\n",
    "heart_data['thalach'][heart_data['thalach'] == '?'] = heart_data['thalach'].mode()[0]\n",
    "heart_data['exang'][heart_data['exang'] == '?'] = heart_data['exang'].mode()[0]\n",
    "heart_data['oldpeak'][heart_data['oldpeak'] == '?'] = heart_data['oldpeak'].mode()[0]\n",
    "heart_data['slope'][heart_data['slope'] == '?'] = heart_data['slope'].mode()[0]\n",
    "heart_data['ca'][heart_data['ca'] == '?'] = heart_data['ca'].mode()[0]\n",
    "heart_data['thal'][heart_data['thal'] == '?'] = heart_data['thal'].mode()[0]\n",
    "    \n",
    "X_data_heart = heart_data.drop(['num'], axis = 1)\n",
    "y_data_heart = ((heart_data['num'] < 1) * 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Heart Disease'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_heart, \n",
    "                                                                y_data_heart, \n",
    "                                                                nominal_features = nominal_features_heart, \n",
    "                                                                ordinal_features = ordinal_features_heart,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "credit_card_data = pd.read_csv('./real_world_datasets/UCI_Credit_Card/UCI_Credit_Card.csv', index_col=False) #, delimiter=' '\n",
    "credit_card_data = credit_card_data.drop(['ID'], axis = 1)\n",
    "print(credit_card_data.shape)\n",
    "\n",
    "nominal_features_credit_card = [\n",
    "                        ]\n",
    "\n",
    "ordinal_features_credit_card = [\n",
    "                   ]\n",
    "    \n",
    "X_data_credit_card = credit_card_data.drop(['default.payment.next.month'], axis = 1)\n",
    "y_data_credit_card = ((credit_card_data['default.payment.next.month'] < 1) * 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Credit Card'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_credit_card, \n",
    "                                                                y_data_credit_card, \n",
    "                                                                nominal_features = nominal_features_credit_card, \n",
    "                                                                ordinal_features = ordinal_features_credit_card,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haberman's Survival Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "   'age',#      \n",
    "   'year',#   \n",
    "   'nodes_detected',#      \n",
    "   'survival',#     \n",
    "                ]\n",
    "\n",
    "haberman_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data', names=feature_names, index_col=False) #, delimiter=' '\n",
    "print(haberman_data.shape)\n",
    "\n",
    "\n",
    "nominal_features_haberman = [\n",
    "                        ]\n",
    "\n",
    "ordinal_features_haberman = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_haberman = haberman_data.drop(['survival'], axis = 1)\n",
    "y_data_haberman = ((haberman_data['survival'] < 2) * 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Haberman'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_haberman, \n",
    "                                                                y_data_haberman, \n",
    "                                                                nominal_features = nominal_features_haberman, \n",
    "                                                                ordinal_features = ordinal_features_haberman,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure_data = pd.read_csv('real_world_datasets/Heart Failure/heart_failure_clinical_records_dataset.csv', delimiter=',')\n",
    "\n",
    "\n",
    "nominal_features_heart_failure = [\n",
    "                        ]\n",
    "ordinal_features_heart_failure = [\n",
    "\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_heart_failure = heart_failure_data.drop(['DEATH_EVENT'], axis = 1)\n",
    "y_data_heart_failure = ((heart_failure_data['DEATH_EVENT'] > 0) * 1)\n",
    "\n",
    "X_data_heart_failure.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 'Heart Failure'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_heart_failure, \n",
    "                                                                y_data_heart_failure, \n",
    "                                                                nominal_features = nominal_features_heart_failure, \n",
    "                                                                ordinal_features = ordinal_features_heart_failure,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list_reduced = deepcopy(identifier_list)\n",
    "for identifier in identifier_list:\n",
    "    if test_network_list[identifier] is None:\n",
    "        identifier_list_reduced.remove(identifier)\n",
    "\n",
    "try:\n",
    "    #print_complete_performance_evaluation_results(results_dict, identifier_list, dataset_size_list, dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    complete_performance_evaluation_results = get_complete_performance_evaluation_results_dataframe(results_dict, \n",
    "                                                                                                    identifier_list_reduced, \n",
    "                                                                                                    dataset_size_list,\n",
    "                                                                                                    dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    display(complete_performance_evaluation_results.head(20))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    #print_complete_performance_evaluation_results(results_dict, identifier_list, dataset_size_list, dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    complete_performance_evaluation_results = get_complete_performance_evaluation_results_dataframe_all_distrib(results_dict, \n",
    "                                                                                                                identifier_list_reduced, \n",
    "                                                                                                                dataset_size_list,\n",
    "                                                                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                                                                dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    display(complete_performance_evaluation_results.head(20))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#print_network_distances(distances_dict)\n",
    "network_distances = get_print_network_distances_dataframe(distances_dict)\n",
    "display(network_distances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if different_eval_data:\n",
    "    flat_config = flatten_dict(config_train)\n",
    "else:\n",
    "    flat_config = flatten_dict(config)    \n",
    "\n",
    "flat_dict_train = flatten_dict(inet_evaluation_result_dict_train)\n",
    "flat_dict_valid = flatten_dict(inet_evaluation_result_dict_valid)\n",
    "if not evaluate_distribution:\n",
    "    flat_dict_test = flatten_dict(inet_evaluation_result_dict_test)\n",
    "else:\n",
    "    flat_dict_test = flatten_dict(inet_evaluation_result_dict_complete_by_distribution_test)\n",
    "\n",
    "header_column = ''  \n",
    "\n",
    "for key in flat_config.keys():\n",
    "    header_column += key\n",
    "    header_column += ';'     \n",
    "\n",
    "number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "for key in flat_dict_train.keys():\n",
    "    #if 'function_values' not in key:\n",
    "    for i in range(number_of_evaluated_networks):\n",
    "        header_column += key + '_train_' + str(i) + ';'  \n",
    "\n",
    "number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "for key in flat_dict_valid.keys():\n",
    "    #if 'function_values' not in key:\n",
    "    for i in range(number_of_evaluated_networks):\n",
    "        header_column += key + '_valid_' + str(i) + ';'       \n",
    "\n",
    "number_of_evaluated_networks = np.array(flat_dict_test[list(flat_dict_test.keys())[0]]).shape[0]\n",
    "for key in flat_dict_test.keys():\n",
    "    #if 'function_values' not in key:\n",
    "    for i in range(number_of_evaluated_networks):\n",
    "        header_column += key + '_test_' + str(i) + ';'          \n",
    "\n",
    "header_column += '\\n'\n",
    "\n",
    "\n",
    "if os.path.exists(writepath_complete):        \n",
    "    with open(writepath_complete, 'r') as text_file: \n",
    "        lines = text_file.readlines()\n",
    "    \n",
    "    counter = 1\n",
    "    while lines[0] != header_column:  \n",
    "        writepath_complete = './results_complete-' + str(counter) + '.csv' \n",
    "        if os.path.exists(writepath_complete):\n",
    "            with open(writepath_complete, 'r') as text_file: \n",
    "                lines = text_file.readlines()\n",
    "        else:\n",
    "            break\n",
    "        counter += 1\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file: \n",
    "        text_file.write(header_column)\n",
    "\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file:  \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "            \n",
    "        \n",
    "    number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_train.items():\n",
    "        #if 'function_values' not in key:\n",
    "        for score in values:\n",
    "            text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_valid.items():\n",
    "        #if 'function_values' not in key:\n",
    "        for score in values:\n",
    "            text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_test[list(flat_dict_test.keys())[0]]).shape[0]\n",
    "    for key, values in flat_dict_test.items():\n",
    "        #if 'function_values' not in key:\n",
    "        for score in values:\n",
    "            text_file.write(str(score) + ';')   \n",
    "                    \n",
    "    text_file.write('\\n')            \n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inet_evaluation_result_dict_mean_train_flat = flatten_dict(inet_evaluation_result_dict_mean_train)\n",
    "inet_evaluation_result_dict_mean_valid_flat = flatten_dict(inet_evaluation_result_dict_mean_valid)\n",
    "if not evaluate_distribution:\n",
    "    inet_evaluation_result_dict_mean_test_flat = flatten_dict(inet_evaluation_result_dict_mean_test)\n",
    "else:\n",
    "    inet_evaluation_result_dict_mean_test_flat = flatten_dict(inet_evaluation_result_dict_mean_by_distribution_test)\n",
    "\n",
    "#identifier_list_synthetic = ['train', 'valid', 'test']\n",
    "identifier_list_combined = list(flatten_list([identifier_list, ['train', 'valid', 'test']]))\n",
    "\n",
    "header_column = ''\n",
    "\n",
    "for key in flat_config.keys():\n",
    "    header_column += key + ';'\n",
    "\n",
    "for key in inet_evaluation_result_dict_mean_train_flat.keys():\n",
    "    header_column += 'train_' + key + ';'\n",
    "for key in inet_evaluation_result_dict_mean_valid_flat.keys():\n",
    "    header_column += 'valid_' + key + ';'          \n",
    "for key in inet_evaluation_result_dict_mean_test_flat.keys():\n",
    "    header_column += 'test_' + key + ';'                \n",
    "\n",
    "for dataset_size in dataset_size_list:\n",
    "    for identifier in identifier_list:\n",
    "        results_dict_flat = flatten_dict(results_dict[identifier][-2])\n",
    "        #del results_dict_flat['function_values_y_test_inet_dt']\n",
    "        #del results_dict_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "        for key in results_dict_flat.keys():\n",
    "            header_column += key + '_' + identifier + '_' + str(dataset_size) + ';'                                   \n",
    "\n",
    "for key in distances_dict['train'].keys():\n",
    "    for identifier in identifier_list_combined:\n",
    "        header_column += key + '_' + identifier + ';' \n",
    "\n",
    "header_column += '\\n'\n",
    " \n",
    "if os.path.exists(writepath_summary):        \n",
    "    with open(writepath_summary, 'r') as text_file: \n",
    "        lines = text_file.readlines()\n",
    "\n",
    "    counter = 1\n",
    "    while lines[0] != header_column:  \n",
    "        writepath_summary = './results_summary-' + str(counter) + '.csv' \n",
    "        if os.path.exists(writepath_summary):\n",
    "            with open(writepath_summary, 'r') as text_file: \n",
    "                lines = text_file.readlines()\n",
    "        else:\n",
    "            break\n",
    "        counter += 1\n",
    "\n",
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "        text_file.write(header_column)\n",
    "\n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "        \n",
    "    for value in inet_evaluation_result_dict_mean_train_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "    for value in inet_evaluation_result_dict_mean_valid_flat.values():\n",
    "        text_file.write(str(value) + ';')            \n",
    "    for value in inet_evaluation_result_dict_mean_test_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "\n",
    "    for i in range(len(dataset_size_list)):\n",
    "        for identifier in identifier_list:\n",
    "            evaluation_result_dict_flat = flatten_dict(evaluation_result_dict[identifier])\n",
    "            #del evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "            #del evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "            \n",
    "            for key, values in evaluation_result_dict_flat.items():\n",
    "                text_file.write(str(values[i]) + ';')    #values[i]        \n",
    "     \n",
    "    for key in distances_dict['train'].keys():\n",
    "        for identifier in identifier_list_combined:\n",
    "            text_file.write(str(distances_dict[identifier][key]) + ';')      \n",
    "    \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myBA",
   "language": "python",
   "name": "myba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
