{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:14.422879Z",
     "iopub.status.busy": "2021-10-19T11:47:14.422510Z",
     "iopub.status.idle": "2021-10-19T11:47:14.452927Z",
     "shell.execute_reply": "2021-10-19T11:47:14.451887Z",
     "shell.execute_reply.started": "2021-10-19T11:47:14.422768Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "config = {\n",
    "    'data': {\n",
    "        'd': 3, #degree\n",
    "        'n': 1, #number of variables\n",
    "        'monomial_vars': None, #int or None\n",
    "        'laurent': False, #use Laurent polynomials (negative degree with up to -d)  \n",
    "        'neg_d': 0,#int or None\n",
    "        'neg_d_prob': 0,\n",
    "        'sparsity': None,\n",
    "        'sample_sparsity': 4,\n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        'a_max': 1,\n",
    "        'a_min': -1,\n",
    "        'lambda_nets_total': 50000,\n",
    "        'noise': 0,\n",
    "        'noise_distrib': 'normal', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        \n",
    "        'shift_polynomial': False,\n",
    "        \n",
    "        'border_min': 0.2, # defines an intervall. Value is randomly chosen and defines the minimum gap between x_min / x_max and the outermost stationary points => two values (left and right gap will be generated per variable)\n",
    "        'border_max': 0.4,\n",
    "        'lower_degree_prob': 0.5, # probability that the degree of the whole polynomial will be reduced\n",
    "        'a_random_prob': 0.5, # probability that a random generated function is used without adjustement\n",
    "                \n",
    "        'global_stationary_prob': 1, # probability that all variables are used for adjustement (0 recommended for higher number of variables)\n",
    "        'bulge_min': 1, # bulge_min and bulge_max define an intervall of how much the function is bulged\n",
    "        'bulge_max': 4,\n",
    "        'min_variables_used': 2, # defines an Intervall of how many variables are used to get stationary points and therefore adjust the function\n",
    "        'max_variables_used': 6,\n",
    "        'max_monomials': 7, # maximum number of monomials, before adjusting the function (monomial of degree 0 is always defined, but is included in this number)\n",
    "        'max_monomials_random': 10, #maximum number of monomials for random generated functions\n",
    "        \n",
    "        'same_training_all_lambda_nets': False,\n",
    "\n",
    "        'fixed_seed_lambda_training': True,\n",
    "        'fixed_initialization_lambda_training': False,\n",
    "        'number_different_lambda_trainings': 1,\n",
    "    },\n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True,  #if early stopping is used, multi_epoch_analysis is deactivated\n",
    "        'early_stopping_min_delta_lambda': 1e-4,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout': 0,\n",
    "        'lambda_network_layers': [5*'sample_sparsity'],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'mae',\n",
    "        'number_of_lambda_weights': None,\n",
    "        'lambda_dataset_size': 5000,\n",
    "    },\n",
    "    'i_net': {\n",
    "        'optimizer': 'custom',#adam\n",
    "        'inet_loss': 'mae',\n",
    "        'inet_metrics': ['r2'],\n",
    "        'dropout': 0,\n",
    "        'dropout_output': 0,\n",
    "        'epochs': 2000, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "        'dense_layers': [2048],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'interpretation_dataset_size': 50000,\n",
    "                \n",
    "        'interpretation_net_output_monomials': 2, #(None, int) #CONSTANT IS NOT INCLUDED\n",
    "        'interpretation_net_output_shape': None, #calculated automatically later\n",
    "        'test_size': 100, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'normalize_inet_data': False,\n",
    "        'inet_training_without_noise': False, #dataset size without noise hardcoded to 50k in generate_paths\n",
    "        'sparse_poly_representation_version': 1, #(1, 2); 1=old, 2=new\n",
    "\n",
    "        'evaluate_with_real_function': False, #False\n",
    "        'consider_labels_training': False, #False\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 100,\n",
    "    },\n",
    "    'evaluation': {   \n",
    "        'inet_holdout_seed_evaluation': False,\n",
    "        \n",
    "        #set if multi_epoch_analysis should be performed\n",
    "        'multi_epoch_analysis': True,\n",
    "        'each_epochs_save_lambda': 100,\n",
    "        'epoch_start': 0, #use to skip first epochs in multi_epoch_analysis\n",
    "        \n",
    "        #set if samples analysis should be performed\n",
    "        'samples_list': None,#[100, 500, 750, 1000, 2500, 5000, 7500, 10000, 15000, 20000, 25000, 28125] \n",
    "       \n",
    "        'random_evaluation_dataset_size': 500,\n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "        \n",
    "        'adjusted_symbolic_metamodeling_code': False,\n",
    "        'symbolic_metamodeling_evaluation': False,\n",
    "        'symbolic_metamodeling_poly_evaluation': False,\n",
    "        'symbolic_metamodeling_function_evaluation': False,\n",
    "        'symbolic_metamodeling_poly_function_evaluation': False,\n",
    "        \n",
    "        \n",
    "        'symbolic_regression_evaluation': False,\n",
    "        'per_network_evaluation': False,\n",
    "    },\n",
    "    'computation':{\n",
    "        'train_model': True,\n",
    "        'n_jobs': 5,\n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '0',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:14.454881Z",
     "iopub.status.busy": "2021-10-19T11:47:14.454548Z",
     "iopub.status.idle": "2021-10-19T11:47:14.464032Z",
     "shell.execute_reply": "2021-10-19T11:47:14.462892Z",
     "shell.execute_reply.started": "2021-10-19T11:47:14.454836Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:14.465996Z",
     "iopub.status.busy": "2021-10-19T11:47:14.465605Z",
     "iopub.status.idle": "2021-10-19T11:47:20.059392Z",
     "shell.execute_reply": "2021-10-19T11:47:20.058430Z",
     "shell.execute_reply.started": "2021-10-19T11:47:14.465954Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "tf.autograph.set_verbosity(2)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import colored\n",
    "import math\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random \n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:20.062160Z",
     "iopub.status.busy": "2021-10-19T11:47:20.061423Z",
     "iopub.status.idle": "2021-10-19T11:47:20.070849Z",
     "shell.execute_reply": "2021-10-19T11:47:20.069851Z",
     "shell.execute_reply.started": "2021-10-19T11:47:20.062129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:20.073115Z",
     "iopub.status.busy": "2021-10-19T11:47:20.072803Z",
     "iopub.status.idle": "2021-10-19T11:47:20.088414Z",
     "shell.execute_reply": "2021-10-19T11:47:20.087504Z",
     "shell.execute_reply.started": "2021-10-19T11:47:20.073076Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "\n",
    "n_jobs = min((epochs_lambda//each_epochs_save_lambda+1, n_jobs)) if multi_epoch_analysis else min(len(samples_list), n_jobs) if samples_list!=None else 1\n",
    "\n",
    "multi_epoch_analysis = False if early_stopping_lambda else multi_epoch_analysis #deactivate multi_epoch_analysis if early stopping is used\n",
    "\n",
    "each_epochs_save_lambda = each_epochs_save_lambda if multi_epoch_analysis else epochs_lambda\n",
    "epochs_save_range_lambda = range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda) if each_epochs_save_lambda == 1 else range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda+1) if multi_epoch_analysis else range(1,2)\n",
    "\n",
    "data_reshape_version = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/lib/cuda-10.1'\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:20.089908Z",
     "iopub.status.busy": "2021-10-19T11:47:20.089585Z",
     "iopub.status.idle": "2021-10-19T11:47:21.397668Z",
     "shell.execute_reply": "2021-10-19T11:47:21.396741Z",
     "shell.execute_reply.started": "2021-10-19T11:47:20.089858Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 4\n",
      "[[3], [2], [1], [0]]\n"
     ]
    }
   ],
   "source": [
    "from utilities.utility_functions import flatten, rec_gen, gen_monomial_identifier_list\n",
    "\n",
    "list_of_monomial_identifiers_extended = []\n",
    "\n",
    "if laurent:\n",
    "    variable_sets = [list(flatten([[_d for _d in range(d+1)], [-_d for _d in range(1, neg_d+1)]])) for _ in range(n)]\n",
    "    list_of_monomial_identifiers_extended = rec_gen(variable_sets)    \n",
    "        \n",
    "    print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "    #print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "    #print('Sparsity:' + str(sparsity))\n",
    "    if len(list_of_monomial_identifiers_extended) < 500:\n",
    "        print(list_of_monomial_identifiers_extended)     \n",
    "        \n",
    "    list_of_monomial_identifiers = []\n",
    "    for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "        if np.sum(monomial_identifier) <= d:\n",
    "            if monomial_vars == None or len(list(filter(lambda x: x != 0, monomial_identifier))) <= monomial_vars:\n",
    "                list_of_monomial_identifiers.append(monomial_identifier)        \n",
    "else:\n",
    "    variable_list = ['x'+ str(i) for i in range(n)]\n",
    "    list_of_monomial_identifiers = gen_monomial_identifier_list(variable_list, d, n)\n",
    "            \n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "#print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "#print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:21.400231Z",
     "iopub.status.busy": "2021-10-19T11:47:21.399390Z",
     "iopub.status.idle": "2021-10-19T11:47:21.560485Z",
     "shell.execute_reply": "2021-10-19T11:47:21.559669Z",
     "shell.execute_reply.started": "2021-10-19T11:47:21.400189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape:  10\n"
     ]
    }
   ],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "config['evaluation']['multi_epoch_analysis'] = multi_epoch_analysis\n",
    "config['evaluation']['each_epochs_save_lambda'] = each_epochs_save_lambda\n",
    "config['i_net']['data_reshape_version'] = data_reshape_version\n",
    "\n",
    "config['data']['sparsity'] = nCr(config['data']['n']+config['data']['d'], config['data']['d']) if not laurent else len(list_of_monomial_identifiers)\n",
    "config['data']['sample_sparsity'] = config['data']['sparsity'] if config['data']['sample_sparsity'] == None else config['data']['sample_sparsity']\n",
    "\n",
    "config['i_net']['interpretation_net_output_shape'] = config['data']['sparsity'] if config['i_net']['interpretation_net_output_monomials'] is None else config['data']['sparsity']*config['i_net']['interpretation_net_output_monomials']+config['i_net']['interpretation_net_output_monomials'] if config['i_net']['sparse_poly_representation_version'] == 1 else config['data']['n']*(config['data']['d']+1)*config['i_net']['interpretation_net_output_monomials']+config['i_net']['interpretation_net_output_monomials']  \n",
    "print('Output Shape: ', config['i_net']['interpretation_net_output_shape'])\n",
    "\n",
    "transformed_layers = []\n",
    "for layer in config['lambda_net']['lambda_network_layers']:\n",
    "    if type(layer) == str:\n",
    "        transformed_layers.append(layer.count('sample_sparsity')*config['data']['sample_sparsity'])\n",
    "    else:\n",
    "        transformed_layers.append(layer)\n",
    "config['lambda_net']['lambda_network_layers'] = transformed_layers\n",
    "\n",
    "layers_with_input_output = list(flatten([[config['data']['n']], config['lambda_net']['lambda_network_layers'], [1]]))\n",
    "number_of_lambda_weights = 0\n",
    "for i in range(len(layers_with_input_output)-1):\n",
    "    number_of_lambda_weights += (layers_with_input_output[i]+1)*layers_with_input_output[i+1]  \n",
    "config['lambda_net']['number_of_lambda_weights'] = number_of_lambda_weights\n",
    "    \n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "\n",
    "\n",
    "initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "initialize_metrics_config_from_curent_notebook(config)\n",
    "initialize_utility_functions_config_from_curent_notebook(config)\n",
    "initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(path_type='interpretation_net'))\n",
    "create_folders_inet()\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:21.562210Z",
     "iopub.status.busy": "2021-10-19T11:47:21.561770Z",
     "iopub.status.idle": "2021-10-19T11:47:21.567851Z",
     "shell.execute_reply": "2021-10-19T11:47:21.566688Z",
     "shell.execute_reply.started": "2021-10-19T11:47:21.562167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inet_dense2048-output_10_drop0e2000b256_custom/lnets_50000_20-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_1_d_3_negd_0_prob_0_spars_4_amin_-1_amax_1_xdist_uniform_noise_normal_0\n",
      "lnets_50000_20-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_1_d_3_negd_0_prob_0_spars_4_amin_-1_amax_1_xdist_uniform_noise_normal_0\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net_data)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:21.569605Z",
     "iopub.status.busy": "2021-10-19T11:47:21.569241Z",
     "iopub.status.idle": "2021-10-19T11:47:21.577250Z",
     "shell.execute_reply": "2021-10-19T11:47:21.576325Z",
     "shell.execute_reply.started": "2021-10-19T11:47:21.569561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:21.581729Z",
     "iopub.status.busy": "2021-10-19T11:47:21.581118Z",
     "iopub.status.idle": "2021-10-19T11:47:21.597110Z",
     "shell.execute_reply": "2021-10-19T11:47:21.596202Z",
     "shell.execute_reply.started": "2021-10-19T11:47:21.581684Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(index, no_noise=False):\n",
    "    \n",
    "    if psutil.virtual_memory().percent > 80:\n",
    "        raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    path_identifier_lambda_net_data_loading = None \n",
    "                \n",
    "    if no_noise==True:\n",
    "        path_identifier_lambda_net_data_loading = generate_paths(path_type='interpretation_net_no_noise')['path_identifier_lambda_net_data']\n",
    "    else:\n",
    "        path_identifier_lambda_net_data_loading = path_identifier_lambda_net_data \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_identifier_lambda_net_data_loading + '/'\n",
    "    path_weights = directory + 'weights_epoch_' + str(index).zfill(3) + '.txt'\n",
    "    path_X_data = directory + 'lambda_X_test_data.txt'\n",
    "    path_y_data = directory + 'lambda_y_test_data.txt'        \n",
    "    \n",
    "    weight_data = pd.read_csv(path_weights, sep=\",\", header=None)\n",
    "    weight_data = weight_data.sort_values(by=0).sample(frac=1, random_state=RANDOM_SEED)\n",
    "    if no_noise == False:\n",
    "        weight_data = weight_data.sort_values(by=0).sample(n=interpretation_dataset_size, random_state=RANDOM_SEED)\n",
    "    \n",
    "    lambda_X_test_data = pd.read_csv(path_X_data, sep=\",\", header=None)\n",
    "    lambda_X_test_data = lambda_X_test_data.sort_values(by=0).sample(frac=1, random_state=RANDOM_SEED)\n",
    "    if no_noise == False:\n",
    "        lambda_X_test_data = lambda_X_test_data.sort_values(by=0).sample(n=interpretation_dataset_size, random_state=RANDOM_SEED)\n",
    "    \n",
    "    lambda_y_test_data = pd.read_csv(path_y_data, sep=\",\", header=None)\n",
    "    lambda_y_test_data = lambda_y_test_data.sort_values(by=0).sample(frac=1, random_state=RANDOM_SEED)\n",
    "    if no_noise == False:\n",
    "        lambda_y_test_data = lambda_y_test_data.sort_values(by=0).sample(n=interpretation_dataset_size, random_state=RANDOM_SEED)\n",
    "        \n",
    "    lambda_nets = [None] * weight_data.shape[0]\n",
    "    for i, (row_weights, row_lambda_X_test_data, row_lambda_y_test_data) in enumerate(zip(weight_data.values, lambda_X_test_data.values, lambda_y_test_data.values)):        \n",
    "        lambda_net = LambdaNet(row_weights, row_lambda_X_test_data, row_lambda_y_test_data)\n",
    "        lambda_nets[i] = lambda_net\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:47:21.598763Z",
     "iopub.status.busy": "2021-10-19T11:47:21.598398Z",
     "iopub.status.idle": "2021-10-19T11:50:32.804599Z",
     "shell.execute_reply": "2021-10-19T11:50:32.803528Z",
     "shell.execute_reply.started": "2021-10-19T11:47:21.598715Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend MultiprocessingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   1 out of   1 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if inet_training_without_noise:\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "    lambda_net_dataset_list_without_noise = parallel(delayed(load_lambda_nets)((i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1, no_noise=True) for i in epochs_save_range_lambda)  \n",
    "    del parallel\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "    lambda_net_dataset_list = parallel(delayed(load_lambda_nets)((i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1) for i in epochs_save_range_lambda)  \n",
    "    del parallel\n",
    "else:\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "    lambda_net_dataset_list = parallel(delayed(load_lambda_nets)((i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1) for i in epochs_save_range_lambda)  \n",
    "    del parallel\n",
    "\n",
    "lambda_net_dataset = lambda_net_dataset_list[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:30:49.711839Z",
     "start_time": "2021-01-05T09:29:48.873305Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:32.809800Z",
     "iopub.status.busy": "2021-10-19T11:50:32.809361Z",
     "iopub.status.idle": "2021-10-19T11:50:36.465139Z",
     "shell.execute_reply": "2021-10-19T11:50:36.464325Z",
     "shell.execute_reply.started": "2021-10-19T11:50:32.809753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>3-target</th>\n",
       "      <th>2-target</th>\n",
       "      <th>1-target</th>\n",
       "      <th>0-target</th>\n",
       "      <th>3-lstsq_lambda</th>\n",
       "      <th>2-lstsq_lambda</th>\n",
       "      <th>1-lstsq_lambda</th>\n",
       "      <th>0-lstsq_lambda</th>\n",
       "      <th>3-lstsq_target</th>\n",
       "      <th>2-lstsq_target</th>\n",
       "      <th>1-lstsq_target</th>\n",
       "      <th>0-lstsq_target</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.736</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.525</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.736</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.589</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.479</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.346</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.389</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.696</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.957</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.957</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.530</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.409</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seed  3-target  2-target  1-target  0-target  3-lstsq_lambda  \\\n",
       "33553  1373158606     0.047     0.040     0.339     0.505           0.005   \n",
       "9427   1373158606    -0.383     0.736    -0.337     0.589           0.002   \n",
       "199    1373158606    -0.216    -0.516    -0.499    -0.033          -0.206   \n",
       "12447  1373158606     0.957    -0.893    -0.418     0.426           0.006   \n",
       "39489  1373158606    -0.500     0.755     0.504     0.403          -0.176   \n",
       "\n",
       "       2-lstsq_lambda  1-lstsq_lambda  0-lstsq_lambda  3-lstsq_target  \\\n",
       "33553          -0.009           0.422           0.489           0.047   \n",
       "9427           -0.003           0.083           0.525          -0.383   \n",
       "199            -0.532          -0.493          -0.033          -0.216   \n",
       "12447          -0.009          -0.529           0.419           0.957   \n",
       "39489           0.196           0.784           0.367          -0.500   \n",
       "\n",
       "       2-lstsq_target  1-lstsq_target  0-lstsq_target   wb_0   wb_1  wb_2  \\\n",
       "33553           0.040           0.339           0.505 -0.011 -0.275 0.296   \n",
       "9427            0.736          -0.337           0.589 -0.011 -0.275 0.334   \n",
       "199            -0.516          -0.499          -0.033 -0.011 -0.275 0.515   \n",
       "12447          -0.893          -0.418           0.426 -0.011 -0.275 0.399   \n",
       "39489           0.755           0.504           0.403 -0.011 -0.275 0.194   \n",
       "\n",
       "       wb_3  wb_4  wb_5  wb_6   wb_7  wb_8  wb_9  wb_10  wb_11  wb_12  wb_13  \\\n",
       "33553 0.176 0.358 0.282 0.245 -0.361 0.139 0.367  0.441 -0.107 -0.023  0.299   \n",
       "9427  0.214 0.315 0.240 0.283 -0.361 0.178 0.318  0.479 -0.107 -0.023  0.337   \n",
       "199   0.387 0.153 0.085 0.455 -0.361 0.334 0.619  0.696 -0.107 -0.023  0.530   \n",
       "12447 0.272 0.248 0.172 0.350 -0.361 0.232 0.459  0.550 -0.107 -0.023  0.405   \n",
       "39489 0.147 0.393 0.317 0.172 -0.361 0.128 0.419  0.409 -0.107 -0.023  0.250   \n",
       "\n",
       "       wb_14  wb_15  wb_16  wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  \\\n",
       "33553  0.278  0.423  0.110  0.419  0.463  0.438  0.000  0.000 -0.002 -0.001   \n",
       "9427   0.235  0.461  0.068  0.374  0.421  0.394  0.000  0.000 -0.002 -0.001   \n",
       "199    0.084  0.670  0.012  0.277  0.251  0.257  0.000  0.000 -0.082 -0.186   \n",
       "12447  0.167  0.530 -0.004  0.309  0.353  0.328  0.000  0.000 -0.004 -0.002   \n",
       "39489  0.314  0.388  0.144  0.457  0.497  0.474  0.000  0.000 -0.149 -0.118   \n",
       "\n",
       "       wb_24  wb_25  wb_26  wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  \\\n",
       "33553  0.134  0.134 -0.002  0.000 -0.001  0.091 -0.010  0.000  0.000 -0.003   \n",
       "9427   0.150  0.150 -0.001  0.000 -0.000  0.077 -0.005  0.000  0.000 -0.002   \n",
       "199   -0.023 -0.088 -0.275  0.000 -0.281 -0.451 -0.007  0.000  0.000 -0.175   \n",
       "12447  0.128  0.130 -0.003  0.000 -0.002 -0.004 -0.007  0.000  0.000 -0.004   \n",
       "39489  0.099  0.099 -0.133  0.000 -0.107  0.038  0.000  0.000  0.000 -0.001   \n",
       "\n",
       "       wb_34  wb_35  wb_36  wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  \\\n",
       "33553  0.136 -0.008  0.132  0.141  0.133  0.138 -0.309 -0.436 -0.299 -0.294   \n",
       "9427   0.153 -0.005  0.150  0.157  0.148  0.153 -0.309 -0.436 -0.346 -0.347   \n",
       "199   -0.086 -0.000 -0.026 -0.071 -0.038 -0.036 -0.309 -0.436 -0.535 -0.616   \n",
       "12447  0.130 -0.007  0.139  0.124  0.127  0.125 -0.309 -0.436 -0.412 -0.408   \n",
       "39489  0.100  0.000  0.098  0.103  0.099  0.101 -0.309 -0.436 -0.276 -0.357   \n",
       "\n",
       "       wb_44  wb_45  wb_46  wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  \\\n",
       "33553  0.365  0.405 -0.104 -0.495 -0.319  0.052 -0.135 -0.428 -0.442 -0.126   \n",
       "9427   0.343  0.389 -0.154 -0.495 -0.380  0.016 -0.180 -0.428 -0.442 -0.173   \n",
       "199    0.113  0.211 -0.455 -0.495 -0.749 -0.404 -0.377 -0.428 -0.442 -0.407   \n",
       "12447  0.278  0.330 -0.218 -0.495 -0.438 -0.083 -0.248 -0.428 -0.442 -0.239   \n",
       "39489  0.375  0.412 -0.108 -0.495 -0.409  0.074 -0.086 -0.428 -0.442 -0.024   \n",
       "\n",
       "       wb_54  wb_55  wb_56  wb_57  wb_58  wb_59  wb_60  \n",
       "33553  0.326 -0.228  0.637  0.219  0.408  0.266  0.126  \n",
       "9427   0.310 -0.273  0.651  0.196  0.382  0.242  0.141  \n",
       "199    0.130 -0.470  0.480 -0.056  0.160  0.012 -0.034  \n",
       "12447  0.251 -0.341  0.668  0.127  0.314  0.173  0.129  \n",
       "39489  0.332 -0.180  0.623  0.232  0.423  0.280  0.095  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset.as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:31:56.898548Z",
     "start_time": "2021-01-05T09:30:49.715497Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:36.466755Z",
     "iopub.status.busy": "2021-10-19T11:50:36.466477Z",
     "iopub.status.idle": "2021-10-19T11:50:40.266237Z",
     "shell.execute_reply": "2021-10-19T11:50:40.265199Z",
     "shell.execute_reply.started": "2021-10-19T11:50:36.466727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>3-target</th>\n",
       "      <th>2-target</th>\n",
       "      <th>1-target</th>\n",
       "      <th>0-target</th>\n",
       "      <th>3-lstsq_lambda</th>\n",
       "      <th>2-lstsq_lambda</th>\n",
       "      <th>1-lstsq_lambda</th>\n",
       "      <th>0-lstsq_lambda</th>\n",
       "      <th>3-lstsq_target</th>\n",
       "      <th>2-lstsq_target</th>\n",
       "      <th>1-lstsq_target</th>\n",
       "      <th>0-lstsq_target</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1373158606.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.518</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.436</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1373158606.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.405</td>\n",
       "      <td>-1.078</td>\n",
       "      <td>-1.394</td>\n",
       "      <td>-1.005</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>-0.479</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.522</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-1.044</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>-0.541</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.881</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-1.110</td>\n",
       "      <td>-1.315</td>\n",
       "      <td>-1.311</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-1.147</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-1.723</td>\n",
       "      <td>-1.504</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-1.720</td>\n",
       "      <td>-1.005</td>\n",
       "      <td>-1.738</td>\n",
       "      <td>-0.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1373158606.000</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1373158606.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.292</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.495</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.325</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1373158606.000</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.503</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.579</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.474</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1373158606.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.506</td>\n",
       "      <td>1.064</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.658</td>\n",
       "      <td>1.335</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1.631</td>\n",
       "      <td>1.483</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.766</td>\n",
       "      <td>1.052</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1.436</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.109</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>1.006</td>\n",
       "      <td>1.193</td>\n",
       "      <td>1.835</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>1.494</td>\n",
       "      <td>1.616</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>1.802</td>\n",
       "      <td>1.245</td>\n",
       "      <td>1.838</td>\n",
       "      <td>1.951</td>\n",
       "      <td>1.160</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                seed  3-target  2-target  1-target  0-target  3-lstsq_lambda  \\\n",
       "count      50000.000 50000.000 50000.000 50000.000 50000.000       50000.000   \n",
       "mean  1373158606.000     0.000     0.005     0.002    -0.000           0.018   \n",
       "std            0.000     0.577     0.579     0.576     0.578           0.494   \n",
       "min   1373158606.000    -1.000    -1.000    -1.000    -1.000          -1.405   \n",
       "25%   1373158606.000    -0.502    -0.500    -0.495    -0.503          -0.259   \n",
       "50%   1373158606.000     0.005     0.007     0.007    -0.003          -0.000   \n",
       "75%   1373158606.000     0.499     0.509     0.502     0.503           0.325   \n",
       "max   1373158606.000     1.000     1.000     1.000     1.000           1.506   \n",
       "\n",
       "       2-lstsq_lambda  1-lstsq_lambda  0-lstsq_lambda  3-lstsq_target  \\\n",
       "count       50000.000       50000.000       50000.000       50000.000   \n",
       "mean            0.016          -0.024           0.005           0.000   \n",
       "std             0.461           0.582           0.552           0.577   \n",
       "min            -1.078          -1.394          -1.005          -1.000   \n",
       "25%            -0.265          -0.519          -0.462          -0.502   \n",
       "50%             0.001          -0.030          -0.003           0.005   \n",
       "75%             0.323           0.475           0.475           0.499   \n",
       "max             1.064           1.250           1.007           1.000   \n",
       "\n",
       "       2-lstsq_target  1-lstsq_target  0-lstsq_target      wb_0      wb_1  \\\n",
       "count       50000.000       50000.000       50000.000 50000.000 50000.000   \n",
       "mean            0.005           0.002          -0.000    -0.011    -0.275   \n",
       "std             0.579           0.576           0.578     0.000     0.000   \n",
       "min            -1.000          -1.000          -1.000    -0.011    -0.275   \n",
       "25%            -0.500          -0.495          -0.503    -0.011    -0.275   \n",
       "50%             0.007           0.007          -0.003    -0.011    -0.275   \n",
       "75%             0.509           0.502           0.503    -0.011    -0.275   \n",
       "max             1.000           1.000           1.000    -0.011    -0.275   \n",
       "\n",
       "           wb_2      wb_3      wb_4      wb_5      wb_6      wb_7      wb_8  \\\n",
       "count 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000   \n",
       "mean      0.332     0.215     0.321     0.250     0.306    -0.361     0.180   \n",
       "std       0.126     0.128     0.130     0.132     0.153     0.000     0.130   \n",
       "min      -0.049    -0.225    -0.086    -0.169    -0.141    -0.361    -0.277   \n",
       "25%       0.253     0.101     0.239     0.157     0.210    -0.361     0.082   \n",
       "50%       0.335     0.214     0.321     0.250     0.292    -0.361     0.175   \n",
       "75%       0.411     0.294     0.399     0.331     0.380    -0.361     0.259   \n",
       "max       0.759     0.731     0.848     0.658     1.335    -0.361     0.813   \n",
       "\n",
       "           wb_9     wb_10     wb_11     wb_12     wb_13     wb_14     wb_15  \\\n",
       "count 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000   \n",
       "mean      0.489     0.518    -0.107    -0.023     0.364     0.249     0.474   \n",
       "std       0.236     0.147     0.000     0.000     0.148     0.137     0.124   \n",
       "min      -0.099     0.130    -0.107    -0.023    -0.064    -0.185     0.106   \n",
       "25%       0.344     0.425    -0.107    -0.023     0.275     0.151     0.399   \n",
       "50%       0.427     0.495    -0.107    -0.023     0.349     0.246     0.468   \n",
       "75%       0.592     0.579    -0.107    -0.023     0.430     0.333     0.543   \n",
       "max       1.631     1.483    -0.107    -0.023     1.347     0.766     1.052   \n",
       "\n",
       "          wb_16     wb_17     wb_18     wb_19     wb_20     wb_21     wb_22  \\\n",
       "count 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000   \n",
       "mean      0.079     0.434     0.429     0.430     0.000     0.000     0.014   \n",
       "std       0.132     0.179     0.133     0.149     0.000     0.000     0.151   \n",
       "min      -0.312    -0.040     0.040    -0.004     0.000     0.000    -0.452   \n",
       "25%       0.012     0.320     0.347     0.331     0.000     0.000    -0.134   \n",
       "50%       0.026     0.402     0.424     0.411     0.000     0.000    -0.000   \n",
       "75%       0.140     0.502     0.501     0.501     0.000     0.000     0.147   \n",
       "max       0.647     1.436     0.892     1.109     0.000     0.000     0.397   \n",
       "\n",
       "          wb_23     wb_24     wb_25     wb_26     wb_27     wb_28     wb_29  \\\n",
       "count 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000   \n",
       "mean     -0.013     0.010    -0.001    -0.021     0.000    -0.018    -0.066   \n",
       "std       0.177     0.155     0.167     0.195     0.000     0.185     0.306   \n",
       "min      -0.479    -0.457    -0.522    -0.741     0.000    -0.518    -1.044   \n",
       "25%      -0.106    -0.113    -0.098    -0.150     0.000    -0.089    -0.321   \n",
       "50%      -0.001    -0.000    -0.000    -0.001     0.000    -0.001     0.015   \n",
       "75%       0.144     0.141     0.141     0.144     0.000     0.142     0.171   \n",
       "max       0.369     0.358     0.311     0.368     0.000     0.351     0.353   \n",
       "\n",
       "          wb_30     wb_31     wb_32     wb_33     wb_34     wb_35     wb_36  \\\n",
       "count 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000   \n",
       "mean      0.029     0.000     0.000    -0.006    -0.014     0.038     0.015   \n",
       "std       0.150     0.000     0.000     0.181     0.187     0.128     0.152   \n",
       "min      -0.892     0.000     0.000    -0.804    -0.541    -0.534    -0.442   \n",
       "25%      -0.010     0.000     0.000    -0.152    -0.096    -0.008    -0.026   \n",
       "50%      -0.000     0.000     0.000    -0.000    -0.000     0.000    -0.001   \n",
       "75%       0.142     0.000     0.000     0.144     0.142     0.147     0.141   \n",
       "max       0.301     0.000     0.000     0.365     0.314     0.443     0.311   \n",
       "\n",
       "          wb_37     wb_38     wb_39     wb_40     wb_41     wb_42     wb_43  \\\n",
       "count 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000   \n",
       "mean     -0.023     0.043     0.020    -0.309    -0.436    -0.412    -0.469   \n",
       "std       0.215     0.113     0.147     0.000     0.000     0.134     0.192   \n",
       "min      -0.881    -0.451    -0.758    -0.309    -0.436    -1.110    -1.315   \n",
       "25%      -0.120    -0.007    -0.013    -0.309    -0.436    -0.466    -0.513   \n",
       "50%      -0.001     0.000    -0.000    -0.309    -0.436    -0.403    -0.427   \n",
       "75%       0.136     0.140     0.139    -0.309    -0.436    -0.320    -0.328   \n",
       "max       0.273     0.391     0.262    -0.309    -0.436    -0.086    -0.178   \n",
       "\n",
       "          wb_44     wb_45     wb_46     wb_47     wb_48     wb_49     wb_50  \\\n",
       "count 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000   \n",
       "mean      0.368     0.436    -0.226    -0.495    -0.524    -0.003    -0.185   \n",
       "std       0.152     0.181     0.265     0.000     0.221     0.334     0.244   \n",
       "min      -1.311     0.132    -1.147    -0.495    -1.723    -1.504    -0.653   \n",
       "25%       0.272     0.320    -0.294    -0.495    -0.570    -0.131    -0.283   \n",
       "50%       0.351     0.403    -0.222    -0.495    -0.466    -0.041    -0.215   \n",
       "75%       0.418     0.474    -0.128    -0.495    -0.353     0.088    -0.140   \n",
       "max       1.006     1.193     1.835    -0.495    -0.236     1.494     1.616   \n",
       "\n",
       "          wb_51     wb_52     wb_53     wb_54     wb_55     wb_56     wb_57  \\\n",
       "count 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000 50000.000   \n",
       "mean     -0.428    -0.442    -0.212     0.371    -0.305     0.695     0.159   \n",
       "std       0.000     0.000     0.265     0.202     0.162     0.258     0.327   \n",
       "min      -0.428    -0.442    -0.875     0.033    -0.720     0.405    -1.720   \n",
       "25%      -0.428    -0.442    -0.295     0.241    -0.378     0.480     0.118   \n",
       "50%      -0.428    -0.442    -0.230     0.325    -0.310     0.628     0.199   \n",
       "75%      -0.428    -0.442    -0.142     0.403    -0.238     0.762     0.268   \n",
       "max      -0.428    -0.442     1.802     1.245     1.838     1.951     1.160   \n",
       "\n",
       "          wb_58     wb_59     wb_60  \n",
       "count 50000.000 50000.000 50000.000  \n",
       "mean      0.384     0.220    -0.006  \n",
       "std       0.125     0.243     0.154  \n",
       "min      -1.005    -1.738    -0.504  \n",
       "25%       0.307     0.166    -0.152  \n",
       "50%       0.379     0.242    -0.002  \n",
       "75%       0.445     0.311     0.139  \n",
       "max       0.960     0.825     0.421  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset.as_pandas().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:40.268308Z",
     "iopub.status.busy": "2021-10-19T11:50:40.267933Z",
     "iopub.status.idle": "2021-10-19T11:50:40.276554Z",
     "shell.execute_reply": "2021-10-19T11:50:40.275704Z",
     "shell.execute_reply.started": "2021-10-19T11:50:40.268269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24457676],\n",
       "       [0.19267431],\n",
       "       [0.71539711],\n",
       "       [0.13782812],\n",
       "       [0.94373167],\n",
       "       [0.85158305],\n",
       "       [0.19021396],\n",
       "       [0.00893767],\n",
       "       [0.91506872],\n",
       "       [0.50437039]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset.X_test_data_list[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:40.278357Z",
     "iopub.status.busy": "2021-10-19T11:50:40.277940Z",
     "iopub.status.idle": "2021-10-19T11:50:40.285521Z",
     "shell.execute_reply": "2021-10-19T11:50:40.284721Z",
     "shell.execute_reply.started": "2021-10-19T11:50:40.278317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59131193],\n",
       "       [0.57244897],\n",
       "       [0.78575999],\n",
       "       [0.55291176],\n",
       "       [0.90085733],\n",
       "       [0.85241354],\n",
       "       [0.5715642 ],\n",
       "       [0.50833553],\n",
       "       [0.88548255],\n",
       "       [0.69260138]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset.y_test_data_list[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets for Interpretation-Net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:32:09.782470Z",
     "start_time": "2021-01-05T09:31:56.901018Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:40.287606Z",
     "iopub.status.busy": "2021-10-19T11:50:40.287319Z",
     "iopub.status.idle": "2021-10-19T11:50:41.170888Z",
     "shell.execute_reply": "2021-10-19T11:50:41.169728Z",
     "shell.execute_reply.started": "2021-10-19T11:50:40.287568Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate train, test and validation data for training\n",
    "\n",
    "lambda_net_train_dataset_list = []\n",
    "lambda_net_valid_dataset_list = []\n",
    "lambda_net_test_dataset_list = []\n",
    "\n",
    "\n",
    "if inet_training_without_noise:\n",
    "   \n",
    "    for lambda_net_dataset, lambda_net_dataset_without_noise in zip(lambda_net_dataset_list, lambda_net_dataset_list_without_noise):\n",
    "        if inet_holdout_seed_evaluation:\n",
    "            raise SystemExit('Holdout Evaluation not implemented with inet training without noise')\n",
    "            \n",
    "        else:\n",
    "            lambda_net_train_dataset, lambda_net_valid_dataset = split_LambdaNetDataset(lambda_net_dataset_without_noise, test_split=0.1)\n",
    "\n",
    "            _, lambda_net_test_dataset = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "\n",
    "            lambda_net_train_dataset_list.append(lambda_net_train_dataset)\n",
    "            lambda_net_valid_dataset_list.append(lambda_net_valid_dataset)\n",
    "            lambda_net_test_dataset_list.append(lambda_net_test_dataset)\n",
    "\n",
    "            del lambda_net_dataset, lambda_net_dataset_list_without_noise\n",
    "        \n",
    "else:\n",
    "\n",
    "    for lambda_net_dataset in lambda_net_dataset_list:\n",
    "\n",
    "        if inet_holdout_seed_evaluation:\n",
    "\n",
    "            complete_seed_list = list(set(lambda_net_dataset.train_settings_list['seed']))#list(weight_data.iloc[:,1].unique())\n",
    "\n",
    "            random.seed(RANDOM_SEED)\n",
    "\n",
    "            if isinstance(test_size, float):\n",
    "                test_size = int(len(complete_seed_list)-len(complete_seed_list)/(1/(1-test_size)))\n",
    "\n",
    "            test_seeds = random.sample(complete_seed_list, test_size)\n",
    "            lambda_net_test_dataset = lambda_net_dataset.get_lambda_nets_by_seed(test_seeds)\n",
    "            complete_seed_list = list(set(complete_seed_list) - set(test_seeds))#complete_seed_list.remove(test_seeds)\n",
    "\n",
    "            random.seed(RANDOM_SEED)\n",
    "            valid_seeds = random.sample(complete_seed_list, int(len(complete_seed_list)-len(complete_seed_list)/(1/(1-0.1))))\n",
    "            lambda_net_valid_dataset = lambda_net_dataset.get_lambda_nets_by_seed(valid_seeds)\n",
    "            complete_seed_list = list(set(complete_seed_list) - set(valid_seeds))\n",
    "\n",
    "            train_seeds = complete_seed_list\n",
    "            lambda_net_train_dataset = lambda_net_dataset.get_lambda_nets_by_seed(train_seeds)       \n",
    "\n",
    "            lambda_net_train_dataset_list.append(lambda_net_train_dataset)\n",
    "            lambda_net_valid_dataset_list.append(lambda_net_valid_dataset)\n",
    "            lambda_net_test_dataset_list.append(lambda_net_test_dataset)\n",
    "\n",
    "            del lambda_net_dataset\n",
    "        else:\n",
    "\n",
    "            lambda_net_train_with_valid_dataset, lambda_net_test_dataset = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "            lambda_net_train_dataset, lambda_net_valid_dataset = split_LambdaNetDataset(lambda_net_train_with_valid_dataset, test_split=0.1)\n",
    "\n",
    "            lambda_net_train_dataset_list.append(lambda_net_train_dataset)\n",
    "            lambda_net_valid_dataset_list.append(lambda_net_valid_dataset)\n",
    "            lambda_net_test_dataset_list.append(lambda_net_test_dataset)\n",
    "\n",
    "            del lambda_net_dataset, lambda_net_train_with_valid_dataset\n",
    "\n",
    "\n",
    "del lambda_net_dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:06.495716Z",
     "start_time": "2021-01-05T09:32:09.784760Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:41.174838Z",
     "iopub.status.busy": "2021-10-19T11:50:41.173320Z",
     "iopub.status.idle": "2021-10-19T11:50:49.340915Z",
     "shell.execute_reply": "2021-10-19T11:50:49.339117Z",
     "shell.execute_reply.started": "2021-10-19T11:50:41.174790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44910, 74)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_train_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:08.945802Z",
     "start_time": "2021-01-05T09:33:06.499150Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:49.351769Z",
     "iopub.status.busy": "2021-10-19T11:50:49.347314Z",
     "iopub.status.idle": "2021-10-19T11:50:50.545030Z",
     "shell.execute_reply": "2021-10-19T11:50:50.544158Z",
     "shell.execute_reply.started": "2021-10-19T11:50:49.351718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4990, 74)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_valid_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:11.543306Z",
     "start_time": "2021-01-05T09:33:08.947468Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:50.550197Z",
     "iopub.status.busy": "2021-10-19T11:50:50.547321Z",
     "iopub.status.idle": "2021-10-19T11:50:50.594705Z",
     "shell.execute_reply": "2021-10-19T11:50:50.593831Z",
     "shell.execute_reply.started": "2021-10-19T11:50:50.550141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 74)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_test_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:50.598309Z",
     "iopub.status.busy": "2021-10-19T11:50:50.597416Z",
     "iopub.status.idle": "2021-10-19T11:50:56.725646Z",
     "shell.execute_reply": "2021-10-19T11:50:56.724686Z",
     "shell.execute_reply.started": "2021-10-19T11:50:50.598264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>3-target</th>\n",
       "      <th>2-target</th>\n",
       "      <th>1-target</th>\n",
       "      <th>0-target</th>\n",
       "      <th>3-lstsq_lambda</th>\n",
       "      <th>2-lstsq_lambda</th>\n",
       "      <th>1-lstsq_lambda</th>\n",
       "      <th>0-lstsq_lambda</th>\n",
       "      <th>3-lstsq_target</th>\n",
       "      <th>2-lstsq_target</th>\n",
       "      <th>1-lstsq_target</th>\n",
       "      <th>0-lstsq_target</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9901</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.930</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.501</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>0.186</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.791</td>\n",
       "      <td>-0.791</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>-0.852</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.791</td>\n",
       "      <td>-0.791</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.574</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18619</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33312</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.619</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.619</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47430</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.871</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.833</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.871</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.474</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.909</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>0.369</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>1.429</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.601</td>\n",
       "      <td>-0.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seed  3-target  2-target  1-target  0-target  3-lstsq_lambda  \\\n",
       "9901   1373158606    -0.327     0.619     0.918    -0.537          -0.292   \n",
       "5910   1373158606     0.437    -0.791    -0.791    -0.593           0.364   \n",
       "18619  1373158606     0.270    -0.369     0.066     0.068           0.078   \n",
       "33312  1373158606     0.440    -0.619     0.605     0.145           0.148   \n",
       "47430  1373158606     0.672     0.871    -0.668    -0.189           0.693   \n",
       "\n",
       "       2-lstsq_lambda  1-lstsq_lambda  0-lstsq_lambda  3-lstsq_target  \\\n",
       "9901            0.577           0.930          -0.538          -0.327   \n",
       "5910           -0.665          -0.852          -0.586           0.437   \n",
       "18619          -0.139           0.002           0.071           0.270   \n",
       "33312          -0.266           0.500           0.150           0.440   \n",
       "47430           0.833          -0.649          -0.192           0.672   \n",
       "\n",
       "       2-lstsq_target  1-lstsq_target  0-lstsq_target   wb_0   wb_1  wb_2  \\\n",
       "9901            0.619           0.918          -0.537 -0.011 -0.275 0.203   \n",
       "5910           -0.791          -0.791          -0.593 -0.011 -0.275 0.421   \n",
       "18619          -0.369           0.066           0.068 -0.011 -0.275 0.332   \n",
       "33312          -0.619           0.605           0.145 -0.011 -0.275 0.284   \n",
       "47430           0.871          -0.668          -0.189 -0.011 -0.275 0.306   \n",
       "\n",
       "       wb_3  wb_4  wb_5  wb_6   wb_7  wb_8  wb_9  wb_10  wb_11  wb_12  wb_13  \\\n",
       "9901  0.073 0.487 0.411 0.174 -0.361 0.081 0.555  0.371 -0.107 -0.023  0.225   \n",
       "5910  0.292 0.159 0.135 0.371 -0.361 0.252 0.461  0.574 -0.107 -0.023  0.427   \n",
       "18619 0.202 0.300 0.224 0.278 -0.361 0.160 0.349  0.482 -0.107 -0.023  0.335   \n",
       "33312 0.157 0.347 0.271 0.231 -0.361 0.072 0.362  0.440 -0.107 -0.023  0.288   \n",
       "47430 0.173 0.533 0.475 0.267 -0.361 0.129 0.702  0.474 -0.107 -0.023  0.323   \n",
       "\n",
       "       wb_14  wb_15  wb_16  wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  \\\n",
       "9901   0.413  0.340  0.236  0.547  0.589  0.572  0.000  0.000  0.239  0.174   \n",
       "5910   0.134  0.554  0.011  0.542  0.339  0.313  0.000  0.000  0.151  0.151   \n",
       "18619  0.220  0.464  0.053  0.359  0.405  0.379  0.000  0.000 -0.004 -0.014   \n",
       "33312  0.267  0.421  0.100  0.408  0.452  0.427  0.000  0.000 -0.033 -0.032   \n",
       "47430  0.479  0.444  0.349  0.615  0.652  0.636  0.000  0.000  0.075  0.077   \n",
       "\n",
       "       wb_24  wb_25  wb_26  wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  \\\n",
       "9901  -0.006 -0.004  0.206  0.000 -0.092 -0.203  0.210  0.000  0.000  0.214   \n",
       "5910  -0.139 -0.111  0.158  0.000  0.151  0.179  0.155  0.000  0.000  0.156   \n",
       "18619  0.021  0.021 -0.004  0.000 -0.026 -0.010 -0.006  0.000  0.000 -0.004   \n",
       "33312  0.043  0.043 -0.044  0.000 -0.075 -0.043 -0.013  0.000  0.000 -0.039   \n",
       "47430 -0.332 -0.342  0.065  0.000  0.078 -0.120  0.066  0.000  0.000  0.067   \n",
       "\n",
       "       wb_34  wb_35  wb_36  wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  \\\n",
       "9901  -0.004  0.232 -0.002 -0.094 -0.008 -0.020 -0.309 -0.436 -0.328 -0.306   \n",
       "5910  -0.107  0.152 -0.026 -0.165 -0.001 -0.001 -0.309 -0.436 -0.465 -0.466   \n",
       "18619  0.021 -0.006  0.021  0.020  0.021  0.021 -0.309 -0.436 -0.343 -0.332   \n",
       "33312  0.043 -0.009  0.043  0.044  0.043  0.043 -0.309 -0.436 -0.291 -0.280   \n",
       "47430 -0.388  0.072 -0.315 -0.325 -0.194 -0.271 -0.309 -0.436 -0.310 -0.313   \n",
       "\n",
       "       wb_44  wb_45  wb_46  wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  \\\n",
       "9901   0.458  0.501 -0.125 -0.495 -0.305  0.186 -0.119 -0.428 -0.442 -0.137   \n",
       "5910   0.219  0.306 -0.274 -0.495 -0.499 -0.138 -0.297 -0.428 -0.442 -0.293   \n",
       "18619  0.279  0.314 -0.147 -0.495 -0.360 -0.013 -0.183 -0.428 -0.442 -0.171   \n",
       "33312  0.324  0.358 -0.096 -0.495 -0.301  0.037 -0.134 -0.428 -0.442 -0.119   \n",
       "47430  0.790  0.909 -0.119 -0.495 -0.349  0.369 -0.146 -0.428 -0.442 -0.138   \n",
       "\n",
       "       wb_54  wb_55  wb_56  wb_57  wb_58  wb_59  wb_60  \n",
       "9901   0.422 -0.224  0.751  0.307  0.502  0.357 -0.259  \n",
       "5910   0.225 -0.391  0.480 -0.416  0.244  0.094 -0.143  \n",
       "18619  0.234 -0.276  0.515  0.137  0.328  0.185  0.021  \n",
       "33312  0.278 -0.227  0.557  0.181  0.373  0.230  0.043  \n",
       "47430  0.900 -0.239  1.429  0.602  0.665  0.601 -0.082  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_train_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:56.727178Z",
     "iopub.status.busy": "2021-10-19T11:50:56.726888Z",
     "iopub.status.idle": "2021-10-19T11:50:57.734414Z",
     "shell.execute_reply": "2021-10-19T11:50:57.729996Z",
     "shell.execute_reply.started": "2021-10-19T11:50:56.727139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>3-target</th>\n",
       "      <th>2-target</th>\n",
       "      <th>1-target</th>\n",
       "      <th>0-target</th>\n",
       "      <th>3-lstsq_lambda</th>\n",
       "      <th>2-lstsq_lambda</th>\n",
       "      <th>1-lstsq_lambda</th>\n",
       "      <th>0-lstsq_lambda</th>\n",
       "      <th>3-lstsq_target</th>\n",
       "      <th>2-lstsq_target</th>\n",
       "      <th>1-lstsq_target</th>\n",
       "      <th>0-lstsq_target</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>0.646</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.645</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>0.646</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.583</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.612</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.783</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-1.029</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>0.257</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>0.846</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30770</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.629</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.507</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.629</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.354</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.558</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.268</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41342</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.725</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.715</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.725</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.626</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.610</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.430</td>\n",
       "      <td>-0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21084</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.777</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.739</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.777</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.561</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.424</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47211</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.704</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.664</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>1.162</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-0.123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seed  3-target  2-target  1-target  0-target  3-lstsq_lambda  \\\n",
       "7038   1373158606    -0.989    -0.035    -0.980     0.646          -0.959   \n",
       "30770  1373158606     0.629    -0.845    -0.341     0.188           0.155   \n",
       "41342  1373158606     0.525     0.040     0.725    -0.409           0.511   \n",
       "21084  1373158606    -0.777    -0.243     0.164    -0.426          -0.014   \n",
       "47211  1373158606     0.505     0.230    -0.332    -0.317           0.494   \n",
       "\n",
       "       2-lstsq_lambda  1-lstsq_lambda  0-lstsq_lambda  3-lstsq_target  \\\n",
       "7038           -0.075          -0.966           0.645          -0.989   \n",
       "30770          -0.275          -0.507           0.196           0.629   \n",
       "41342           0.062           0.715          -0.408           0.525   \n",
       "21084           0.024          -0.739          -0.223          -0.777   \n",
       "47211           0.242          -0.334          -0.318           0.505   \n",
       "\n",
       "       2-lstsq_target  1-lstsq_target  0-lstsq_target   wb_0   wb_1  wb_2  \\\n",
       "7038           -0.035          -0.980           0.646 -0.011 -0.275 0.581   \n",
       "30770          -0.845          -0.341           0.188 -0.011 -0.275 0.407   \n",
       "41342           0.040           0.725          -0.409 -0.011 -0.275 0.145   \n",
       "21084          -0.243           0.164          -0.426 -0.011 -0.275 0.410   \n",
       "47211           0.230          -0.332          -0.317 -0.011 -0.275 0.208   \n",
       "\n",
       "       wb_3  wb_4   wb_5  wb_6   wb_7  wb_8  wb_9  wb_10  wb_11  wb_12  wb_13  \\\n",
       "7038  0.507 0.035 -0.060 0.583 -0.361 0.474 0.685  0.811 -0.107 -0.023  0.612   \n",
       "30770 0.275 0.232  0.156 0.354 -0.361 0.235 0.440  0.558 -0.107 -0.023  0.411   \n",
       "41342 0.011 0.475  0.432 0.129 -0.361 0.076 0.595  0.333 -0.107 -0.023  0.180   \n",
       "21084 0.281 0.233  0.157 0.358 -0.361 0.241 0.440  0.561 -0.107 -0.023  0.414   \n",
       "47211 0.073 0.405  0.351 0.155 -0.361 0.031 0.350  0.368 -0.107 -0.023  0.215   \n",
       "\n",
       "       wb_14  wb_15  wb_16  wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  \\\n",
       "7038  -0.067  0.783 -0.243  0.216  0.151  0.161  0.000  0.000 -0.160 -0.387   \n",
       "30770  0.152  0.539  0.009  0.294  0.337  0.312  0.000  0.000 -0.001 -0.029   \n",
       "41342  0.432  0.289  0.315  0.637  0.655  0.647  0.000  0.000  0.202  0.190   \n",
       "21084  0.153  0.542  0.012  0.293  0.335  0.311  0.000  0.000  0.063  0.063   \n",
       "47211  0.355  0.344  0.243  0.480  0.516  0.499  0.000  0.000  0.121  0.123   \n",
       "\n",
       "       wb_24  wb_25  wb_26  wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  \\\n",
       "7038   0.206  0.217 -0.382  0.000 -0.405 -0.382 -0.011  0.000  0.000 -0.272   \n",
       "30770  0.084  0.084 -0.009  0.000 -0.037 -0.001 -0.005  0.000  0.000 -0.001   \n",
       "41342 -0.131 -0.206  0.157  0.000 -0.088 -0.437  0.162  0.000  0.000  0.167   \n",
       "21084 -0.005 -0.001  0.064  0.000  0.063  0.070  0.064  0.000  0.000  0.064   \n",
       "47211 -0.248 -0.251  0.119  0.000  0.125  0.078  0.115  0.000  0.000  0.118   \n",
       "\n",
       "       wb_34  wb_35  wb_36  wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  \\\n",
       "7038   0.217 -0.003  0.244  0.126  0.201  0.175 -0.309 -0.436 -0.628 -0.945   \n",
       "30770  0.083 -0.004 -0.028  0.079  0.085  0.082 -0.309 -0.436 -0.417 -0.407   \n",
       "41342 -0.269  0.192 -0.268 -0.004 -0.004 -0.002 -0.309 -0.436 -0.272 -0.317   \n",
       "21084 -0.002  0.063 -0.026 -0.014 -0.011 -0.012 -0.309 -0.436 -0.424 -0.416   \n",
       "47211 -0.283  0.118 -0.215 -0.244 -0.123 -0.200 -0.309 -0.436 -0.307 -0.351   \n",
       "\n",
       "       wb_44  wb_45  wb_46  wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  \\\n",
       "7038   0.213  0.334 -0.692 -0.495 -1.029 -0.502 -0.489 -0.428 -0.442 -0.572   \n",
       "30770  0.227  0.268 -0.221 -0.495 -0.436 -0.087 -0.255 -0.428 -0.442 -0.244   \n",
       "41342  0.468  0.626 -0.067 -0.495 -0.300  0.404 -0.056 -0.428 -0.442 -0.077   \n",
       "21084  0.199  0.230 -0.229 -0.495 -0.444 -0.094 -0.262 -0.428 -0.442 -0.251   \n",
       "47211  0.597  0.704 -0.128 -0.495 -0.407  0.038 -0.116 -0.428 -0.442 -0.133   \n",
       "\n",
       "       wb_54  wb_55  wb_56  wb_57  wb_58  wb_59  wb_60  \n",
       "7038   0.257 -0.582  0.846 -0.013  0.197  0.049  0.218  \n",
       "30770  0.188 -0.349  0.477  0.081  0.271  0.129  0.088  \n",
       "41342  0.610 -0.163  1.150  0.383  0.571  0.430 -0.228  \n",
       "21084  0.148 -0.356  0.480  0.057  0.250  0.106 -0.061  \n",
       "47211  0.664 -0.213  1.162  0.414  0.473  0.414 -0.123  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_valid_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:57.736053Z",
     "iopub.status.busy": "2021-10-19T11:50:57.735758Z",
     "iopub.status.idle": "2021-10-19T11:50:57.966974Z",
     "shell.execute_reply": "2021-10-19T11:50:57.962751Z",
     "shell.execute_reply.started": "2021-10-19T11:50:57.736012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>3-target</th>\n",
       "      <th>2-target</th>\n",
       "      <th>1-target</th>\n",
       "      <th>0-target</th>\n",
       "      <th>3-lstsq_lambda</th>\n",
       "      <th>2-lstsq_lambda</th>\n",
       "      <th>1-lstsq_lambda</th>\n",
       "      <th>0-lstsq_lambda</th>\n",
       "      <th>3-lstsq_target</th>\n",
       "      <th>2-lstsq_target</th>\n",
       "      <th>1-lstsq_target</th>\n",
       "      <th>0-lstsq_target</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35587</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.605</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>0.574</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.605</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.360</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.557</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.537</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32681</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.696</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.686</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.696</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.596</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.675</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>1.190</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.477</td>\n",
       "      <td>-0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40971</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.738</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.738</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.530</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.690</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.728</td>\n",
       "      <td>-0.927</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-1.010</td>\n",
       "      <td>-0.541</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>0.479</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21022</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.733</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.727</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.602</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.465</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-1.232</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-1.012</td>\n",
       "      <td>-0.228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seed  3-target  2-target  1-target  0-target  3-lstsq_lambda  \\\n",
       "35587  1373158606    -0.423     0.605    -0.763     0.593           0.000   \n",
       "32681  1373158606     0.573     0.425     0.696    -0.089           0.559   \n",
       "40971  1373158606    -0.738    -0.737     0.350    -0.071          -0.781   \n",
       "21022  1373158606    -0.385    -0.915    -0.257     0.785          -0.370   \n",
       "6403   1373158606    -0.526    -0.885    -0.241    -0.955          -0.682   \n",
       "\n",
       "       2-lstsq_lambda  1-lstsq_lambda  0-lstsq_lambda  3-lstsq_target  \\\n",
       "35587          -0.001          -0.530           0.574          -0.423   \n",
       "32681           0.448           0.686          -0.089           0.573   \n",
       "40971          -0.661           0.310          -0.065          -0.738   \n",
       "21022          -0.938          -0.250           0.785          -0.385   \n",
       "6403           -0.635          -0.355          -0.939          -0.526   \n",
       "\n",
       "       2-lstsq_target  1-lstsq_target  0-lstsq_target   wb_0   wb_1  wb_2  \\\n",
       "35587           0.605          -0.763           0.593 -0.011 -0.275 0.407   \n",
       "32681           0.425           0.696          -0.089 -0.011 -0.275 0.152   \n",
       "40971          -0.737           0.350          -0.071 -0.011 -0.275 0.556   \n",
       "21022          -0.915          -0.257           0.785 -0.011 -0.275 0.569   \n",
       "6403           -0.885          -0.241          -0.955 -0.011 -0.275 0.309   \n",
       "\n",
       "       wb_3  wb_4   wb_5  wb_6   wb_7  wb_8  wb_9  wb_10  wb_11  wb_12  wb_13  \\\n",
       "35587 0.282 0.247  0.170 0.360 -0.361 0.244 0.469  0.557 -0.107 -0.023  0.414   \n",
       "32681 0.103 0.561  0.487 0.130 -0.361 0.084 0.801  0.380 -0.107 -0.023  0.240   \n",
       "40971 0.453 0.170  0.089 0.530 -0.361 0.423 0.686  0.690 -0.107 -0.023  0.572   \n",
       "21022 0.436 0.060 -0.023 0.531 -0.361 0.394 0.641  0.733 -0.107 -0.023  0.575   \n",
       "6403  0.176 0.132  0.098 0.255 -0.361 0.135 0.349  0.465 -0.107 -0.023  0.314   \n",
       "\n",
       "       wb_14  wb_15  wb_16  wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  \\\n",
       "35587  0.165  0.537 -0.005  0.305  0.353  0.326  0.000  0.000 -0.001 -0.001   \n",
       "32681  0.498  0.304  0.347  0.661  0.707  0.708  0.000  0.000 -0.152 -0.103   \n",
       "40971  0.095  0.687  0.011  0.298  0.271  0.267  0.000  0.000 -0.259 -0.369   \n",
       "21022 -0.035  0.727 -0.199  0.117  0.177  0.145  0.000  0.000 -0.188 -0.292   \n",
       "6403   0.096  0.445  0.012  1.022  0.430  0.941  0.000  0.000  0.241  0.244   \n",
       "\n",
       "       wb_24  wb_25  wb_26  wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  \\\n",
       "35587  0.165  0.168 -0.001  0.000 -0.000 -0.001 -0.001  0.000  0.000 -0.001   \n",
       "32681 -0.108 -0.243 -0.130  0.000 -0.086 -0.596 -0.028  0.000  0.000 -0.136   \n",
       "40971 -0.000 -0.000 -0.389  0.000 -0.377 -0.447 -0.243  0.000  0.000 -0.323   \n",
       "21022  0.208  0.214 -0.299  0.000 -0.339 -0.493 -0.130  0.000  0.000 -0.263   \n",
       "6403  -0.132 -0.098  0.254  0.000  0.244  0.283  0.247  0.000  0.000  0.250   \n",
       "\n",
       "       wb_34  wb_35  wb_36  wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  \\\n",
       "35587  0.171 -0.001  0.178  0.166  0.162  0.164 -0.309 -0.436 -0.420 -0.420   \n",
       "32681 -0.314 -0.057 -0.298 -0.238 -0.004 -0.004 -0.309 -0.436 -0.218 -0.274   \n",
       "40971 -0.000 -0.156 -0.027 -0.045 -0.000 -0.000 -0.309 -0.436 -0.728 -0.927   \n",
       "21022  0.220 -0.024  0.221  0.208  0.199  0.203 -0.309 -0.436 -0.679 -0.834   \n",
       "6403  -0.096  0.242 -0.026 -0.703  0.000 -0.348 -0.309 -0.436 -0.458 -0.484   \n",
       "\n",
       "       wb_44  wb_45  wb_46  wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  \\\n",
       "35587  0.315  0.374 -0.228 -0.495 -0.453 -0.088 -0.253 -0.428 -0.442 -0.247   \n",
       "32681  0.546  0.694 -0.012 -0.495 -0.316  0.521  0.040 -0.428 -0.442  0.119   \n",
       "40971  0.142  0.185 -0.686 -0.495 -1.010 -0.541 -0.483 -0.428 -0.442 -0.613   \n",
       "21022  0.350  0.457 -0.602 -0.495 -0.933 -0.535 -0.447 -0.428 -0.442 -0.561   \n",
       "6403   0.169  0.229 -0.279 -0.495 -0.526 -0.136 -0.272 -0.428 -0.442 -0.287   \n",
       "\n",
       "       wb_54  wb_55  wb_56  wb_57  wb_58  wb_59  wb_60  \n",
       "35587  0.297 -0.347  0.727  0.160  0.342  0.204  0.161  \n",
       "32681  0.675 -0.073  1.190  0.463  0.616  0.477 -0.087  \n",
       "40971  0.104 -0.542  0.479 -0.067  0.185  0.040 -0.056  \n",
       "21022  0.386 -0.542  0.857  0.166  0.324  0.199  0.198  \n",
       "6403   0.149 -0.366  0.480 -1.232  0.336 -1.012 -0.228  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_test_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:57.968484Z",
     "iopub.status.busy": "2021-10-19T11:50:57.968189Z",
     "iopub.status.idle": "2021-10-19T11:50:57.973372Z",
     "shell.execute_reply": "2021-10-19T11:50:57.972548Z",
     "shell.execute_reply.started": "2021-10-19T11:50:57.968444Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:57.975264Z",
     "iopub.status.busy": "2021-10-19T11:50:57.974851Z",
     "iopub.status.idle": "2021-10-19T11:50:57.985968Z",
     "shell.execute_reply": "2021-10-19T11:50:57.981500Z",
     "shell.execute_reply.started": "2021-10-19T11:50:57.975224Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_train_dataset_list[0].weight_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:50:57.989777Z",
     "iopub.status.busy": "2021-10-19T11:50:57.988305Z",
     "iopub.status.idle": "2021-10-19T13:00:15.763622Z",
     "shell.execute_reply": "2021-10-19T13:00:15.740079Z",
     "shell.execute_reply.started": "2021-10-19T11:50:57.989734Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "Epoch 1/2000\n",
      "176/176 [==============================] - 71s 311ms/step - loss: 0.4124 - r2_inet_lambda_fv_loss: 6944.6868 - val_loss: 0.2050 - val_r2_inet_lambda_fv_loss: 105.4875\n",
      "Epoch 2/2000\n",
      "176/176 [==============================] - 44s 248ms/step - loss: 0.2114 - r2_inet_lambda_fv_loss: 1806.0803 - val_loss: 0.1943 - val_r2_inet_lambda_fv_loss: 58.7493\n",
      "Epoch 3/2000\n",
      "176/176 [==============================] - 54s 306ms/step - loss: 0.1771 - r2_inet_lambda_fv_loss: 38.9518 - val_loss: 0.1275 - val_r2_inet_lambda_fv_loss: 3.3631\n",
      "Epoch 4/2000\n",
      "176/176 [==============================] - 40s 227ms/step - loss: 0.1334 - r2_inet_lambda_fv_loss: 7.3986 - val_loss: 0.1249 - val_r2_inet_lambda_fv_loss: 3.3056\n",
      "Epoch 5/2000\n",
      "176/176 [==============================] - 20s 115ms/step - loss: 0.1297 - r2_inet_lambda_fv_loss: 4.5248 - val_loss: 0.1233 - val_r2_inet_lambda_fv_loss: 3.3007\n",
      "Epoch 6/2000\n",
      "176/176 [==============================] - 34s 193ms/step - loss: 0.1239 - r2_inet_lambda_fv_loss: 9.0292 - val_loss: 0.1179 - val_r2_inet_lambda_fv_loss: 2.8293\n",
      "Epoch 7/2000\n",
      "176/176 [==============================] - 52s 297ms/step - loss: 0.1213 - r2_inet_lambda_fv_loss: 5.6287 - val_loss: 0.1143 - val_r2_inet_lambda_fv_loss: 2.3346\n",
      "Epoch 8/2000\n",
      "176/176 [==============================] - 49s 280ms/step - loss: 0.1165 - r2_inet_lambda_fv_loss: 5.0657 - val_loss: 0.1111 - val_r2_inet_lambda_fv_loss: 2.0010\n",
      "Epoch 9/2000\n",
      "176/176 [==============================] - 39s 218ms/step - loss: 0.1134 - r2_inet_lambda_fv_loss: 5.7059 - val_loss: 0.1103 - val_r2_inet_lambda_fv_loss: 1.9305\n",
      "Epoch 10/2000\n",
      "176/176 [==============================] - 43s 243ms/step - loss: 0.1130 - r2_inet_lambda_fv_loss: 10.5687 - val_loss: 0.1110 - val_r2_inet_lambda_fv_loss: 2.0606\n",
      "Epoch 11/2000\n",
      "176/176 [==============================] - 24s 139ms/step - loss: 0.1119 - r2_inet_lambda_fv_loss: 3.8871 - val_loss: 0.1095 - val_r2_inet_lambda_fv_loss: 1.9001\n",
      "Epoch 12/2000\n",
      "176/176 [==============================] - 54s 307ms/step - loss: 0.1130 - r2_inet_lambda_fv_loss: 4.3913 - val_loss: 0.1103 - val_r2_inet_lambda_fv_loss: 1.7637\n",
      "Epoch 13/2000\n",
      "176/176 [==============================] - 54s 307ms/step - loss: 0.1126 - r2_inet_lambda_fv_loss: 3.5409 - val_loss: 0.1097 - val_r2_inet_lambda_fv_loss: 1.6824\n",
      "Epoch 14/2000\n",
      "176/176 [==============================] - 51s 291ms/step - loss: 0.1120 - r2_inet_lambda_fv_loss: 3.3791 - val_loss: 0.1097 - val_r2_inet_lambda_fv_loss: 1.5054\n",
      "Epoch 15/2000\n",
      "176/176 [==============================] - 34s 189ms/step - loss: 0.1104 - r2_inet_lambda_fv_loss: 1.8874 - val_loss: 0.1085 - val_r2_inet_lambda_fv_loss: 1.3561\n",
      "Epoch 16/2000\n",
      "176/176 [==============================] - 33s 190ms/step - loss: 0.1095 - r2_inet_lambda_fv_loss: 3.7708 - val_loss: 0.1079 - val_r2_inet_lambda_fv_loss: 1.3102\n",
      "Epoch 17/2000\n",
      "176/176 [==============================] - 56s 318ms/step - loss: 0.1100 - r2_inet_lambda_fv_loss: 2.5244 - val_loss: 0.1070 - val_r2_inet_lambda_fv_loss: 1.2591\n",
      "Epoch 18/2000\n",
      "176/176 [==============================] - 47s 268ms/step - loss: 0.1080 - r2_inet_lambda_fv_loss: 1.6584 - val_loss: 0.1064 - val_r2_inet_lambda_fv_loss: 1.2148\n",
      "Epoch 19/2000\n",
      "176/176 [==============================] - 40s 225ms/step - loss: 0.1093 - r2_inet_lambda_fv_loss: 1.5742 - val_loss: 0.1060 - val_r2_inet_lambda_fv_loss: 1.2160\n",
      "Epoch 20/2000\n",
      "176/176 [==============================] - 36s 206ms/step - loss: 0.1076 - r2_inet_lambda_fv_loss: 3.9158 - val_loss: 0.1048 - val_r2_inet_lambda_fv_loss: 1.1507\n",
      "Epoch 21/2000\n",
      "176/176 [==============================] - 25s 145ms/step - loss: 0.1068 - r2_inet_lambda_fv_loss: 1.5991 - val_loss: 0.1055 - val_r2_inet_lambda_fv_loss: 1.4170\n",
      "Epoch 22/2000\n",
      "176/176 [==============================] - 39s 221ms/step - loss: 0.1066 - r2_inet_lambda_fv_loss: 1.6200 - val_loss: 0.1048 - val_r2_inet_lambda_fv_loss: 1.1359\n",
      "Epoch 23/2000\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 0.1081 - r2_inet_lambda_fv_loss: 1.4634 - val_loss: 0.1043 - val_r2_inet_lambda_fv_loss: 1.1342\n",
      "Epoch 24/2000\n",
      "176/176 [==============================] - 66s 374ms/step - loss: 0.1075 - r2_inet_lambda_fv_loss: 4.2641 - val_loss: 0.1049 - val_r2_inet_lambda_fv_loss: 1.1441\n",
      "Epoch 25/2000\n",
      "176/176 [==============================] - 35s 196ms/step - loss: 0.1074 - r2_inet_lambda_fv_loss: 9.7862 - val_loss: 0.1043 - val_r2_inet_lambda_fv_loss: 1.0450\n",
      "Epoch 26/2000\n",
      "176/176 [==============================] - 26s 149ms/step - loss: 0.1068 - r2_inet_lambda_fv_loss: 1.8676 - val_loss: 0.1045 - val_r2_inet_lambda_fv_loss: 1.1348\n",
      "Epoch 27/2000\n",
      "176/176 [==============================] - 51s 290ms/step - loss: 0.1098 - r2_inet_lambda_fv_loss: 3.0510 - val_loss: 0.1055 - val_r2_inet_lambda_fv_loss: 0.8970\n",
      "Epoch 28/2000\n",
      "176/176 [==============================] - 52s 298ms/step - loss: 0.1099 - r2_inet_lambda_fv_loss: 1.6670 - val_loss: 0.1033 - val_r2_inet_lambda_fv_loss: 0.8954\n",
      "Epoch 29/2000\n",
      "176/176 [==============================] - 49s 279ms/step - loss: 0.1087 - r2_inet_lambda_fv_loss: 3.0957 - val_loss: 0.1029 - val_r2_inet_lambda_fv_loss: 0.8821\n",
      "Epoch 30/2000\n",
      "176/176 [==============================] - 33s 189ms/step - loss: 0.1073 - r2_inet_lambda_fv_loss: 1.6693 - val_loss: 0.1031 - val_r2_inet_lambda_fv_loss: 1.0002\n",
      "Epoch 31/2000\n",
      "176/176 [==============================] - 34s 192ms/step - loss: 0.1066 - r2_inet_lambda_fv_loss: 1.8403 - val_loss: 0.1031 - val_r2_inet_lambda_fv_loss: 1.3626\n",
      "Epoch 32/2000\n",
      "176/176 [==============================] - 49s 281ms/step - loss: 0.1071 - r2_inet_lambda_fv_loss: 2.6352 - val_loss: 0.1005 - val_r2_inet_lambda_fv_loss: 0.9103\n",
      "Epoch 33/2000\n",
      "176/176 [==============================] - 57s 326ms/step - loss: 0.1056 - r2_inet_lambda_fv_loss: 2.4661 - val_loss: 0.1014 - val_r2_inet_lambda_fv_loss: 1.0622\n",
      "Epoch 34/2000\n",
      "176/176 [==============================] - 59s 338ms/step - loss: 0.1053 - r2_inet_lambda_fv_loss: 2.0310 - val_loss: 0.1017 - val_r2_inet_lambda_fv_loss: 0.9760\n",
      "Epoch 35/2000\n",
      "176/176 [==============================] - 23s 128ms/step - loss: 0.1066 - r2_inet_lambda_fv_loss: 2.7487 - val_loss: 0.1031 - val_r2_inet_lambda_fv_loss: 1.0997\n",
      "Epoch 36/2000\n",
      "176/176 [==============================] - 24s 137ms/step - loss: 0.1073 - r2_inet_lambda_fv_loss: 4.8888 - val_loss: 0.1047 - val_r2_inet_lambda_fv_loss: 1.3131\n",
      "Epoch 37/2000\n",
      "176/176 [==============================] - 46s 263ms/step - loss: 0.1068 - r2_inet_lambda_fv_loss: 1.6969 - val_loss: 0.1030 - val_r2_inet_lambda_fv_loss: 1.0656\n",
      "Epoch 38/2000\n",
      "176/176 [==============================] - 53s 303ms/step - loss: 0.1064 - r2_inet_lambda_fv_loss: 5.0317 - val_loss: 0.1027 - val_r2_inet_lambda_fv_loss: 1.1389\n",
      "Epoch 39/2000\n",
      "176/176 [==============================] - 54s 310ms/step - loss: 0.1060 - r2_inet_lambda_fv_loss: 1.6450 - val_loss: 0.1023 - val_r2_inet_lambda_fv_loss: 1.0335\n",
      "Epoch 40/2000\n",
      "176/176 [==============================] - 24s 137ms/step - loss: 0.1060 - r2_inet_lambda_fv_loss: 1.4710 - val_loss: 0.1010 - val_r2_inet_lambda_fv_loss: 0.7991\n",
      "Epoch 41/2000\n",
      "176/176 [==============================] - 23s 129ms/step - loss: 0.1040 - r2_inet_lambda_fv_loss: 1.9544 - val_loss: 0.1005 - val_r2_inet_lambda_fv_loss: 0.8551\n",
      "Epoch 42/2000\n",
      "176/176 [==============================] - 26s 148ms/step - loss: 0.1022 - r2_inet_lambda_fv_loss: 1.6867 - val_loss: 0.0958 - val_r2_inet_lambda_fv_loss: 0.4654\n",
      "Epoch 43/2000\n",
      "176/176 [==============================] - 58s 328ms/step - loss: 0.0975 - r2_inet_lambda_fv_loss: 1.5034 - val_loss: 0.0944 - val_r2_inet_lambda_fv_loss: 0.5191\n",
      "Epoch 44/2000\n",
      "176/176 [==============================] - 53s 299ms/step - loss: 0.0980 - r2_inet_lambda_fv_loss: 1.6125 - val_loss: 0.0962 - val_r2_inet_lambda_fv_loss: 0.4982\n",
      "Epoch 45/2000\n",
      "176/176 [==============================] - 53s 303ms/step - loss: 0.1001 - r2_inet_lambda_fv_loss: 1.6032 - val_loss: 0.0928 - val_r2_inet_lambda_fv_loss: 0.4158\n",
      "Epoch 46/2000\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 0.0961 - r2_inet_lambda_fv_loss: 2.4947 - val_loss: 0.0969 - val_r2_inet_lambda_fv_loss: 0.6446\n",
      "Epoch 47/2000\n",
      "176/176 [==============================] - 27s 154ms/step - loss: 0.1013 - r2_inet_lambda_fv_loss: 1.5218 - val_loss: 0.0989 - val_r2_inet_lambda_fv_loss: 0.8757\n",
      "Epoch 48/2000\n",
      "176/176 [==============================] - 57s 323ms/step - loss: 0.1023 - r2_inet_lambda_fv_loss: 1.5437 - val_loss: 0.0984 - val_r2_inet_lambda_fv_loss: 0.8111\n",
      "Epoch 49/2000\n",
      "176/176 [==============================] - 52s 296ms/step - loss: 0.1009 - r2_inet_lambda_fv_loss: 2.2167 - val_loss: 0.0969 - val_r2_inet_lambda_fv_loss: 0.6321\n",
      "Epoch 50/2000\n",
      "176/176 [==============================] - 47s 265ms/step - loss: 0.1009 - r2_inet_lambda_fv_loss: 1.8302 - val_loss: 0.0991 - val_r2_inet_lambda_fv_loss: 0.8090\n",
      "Epoch 51/2000\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 0.1028 - r2_inet_lambda_fv_loss: 1.8034 - val_loss: 0.0998 - val_r2_inet_lambda_fv_loss: 0.9140\n",
      "Epoch 52/2000\n",
      "176/176 [==============================] - 21s 117ms/step - loss: 0.1038 - r2_inet_lambda_fv_loss: 3.5329 - val_loss: 0.1039 - val_r2_inet_lambda_fv_loss: 1.0647\n",
      "Epoch 53/2000\n",
      "176/176 [==============================] - 30s 172ms/step - loss: 0.1072 - r2_inet_lambda_fv_loss: 2.3063 - val_loss: 0.1071 - val_r2_inet_lambda_fv_loss: 1.2315\n",
      "Epoch 54/2000\n",
      "176/176 [==============================] - 58s 331ms/step - loss: 0.1111 - r2_inet_lambda_fv_loss: 4.9714 - val_loss: 0.1076 - val_r2_inet_lambda_fv_loss: 1.3848\n",
      "Epoch 55/2000\n",
      "176/176 [==============================] - 57s 326ms/step - loss: 0.1143 - r2_inet_lambda_fv_loss: 2.2177 - val_loss: 0.1128 - val_r2_inet_lambda_fv_loss: 1.4976\n",
      "Epoch 56/2000\n",
      "176/176 [==============================] - 34s 196ms/step - loss: 0.1163 - r2_inet_lambda_fv_loss: 2.5338 - val_loss: 0.1146 - val_r2_inet_lambda_fv_loss: 1.6535\n",
      "Epoch 57/2000\n",
      "176/176 [==============================] - 42s 239ms/step - loss: 0.1187 - r2_inet_lambda_fv_loss: 2.6727 - val_loss: 0.1169 - val_r2_inet_lambda_fv_loss: 1.7766\n",
      "Epoch 58/2000\n",
      "176/176 [==============================] - 24s 134ms/step - loss: 0.1216 - r2_inet_lambda_fv_loss: 8.3631 - val_loss: 0.1207 - val_r2_inet_lambda_fv_loss: 1.8879\n",
      "Epoch 59/2000\n",
      "176/176 [==============================] - 56s 316ms/step - loss: 0.1264 - r2_inet_lambda_fv_loss: 3.0322 - val_loss: 0.1213 - val_r2_inet_lambda_fv_loss: 1.9870\n",
      "Epoch 60/2000\n",
      "176/176 [==============================] - 55s 316ms/step - loss: 0.1257 - r2_inet_lambda_fv_loss: 5.6321 - val_loss: 0.1201 - val_r2_inet_lambda_fv_loss: 1.8798\n",
      "Epoch 61/2000\n",
      "176/176 [==============================] - 56s 318ms/step - loss: 0.1265 - r2_inet_lambda_fv_loss: 3.3900 - val_loss: 0.1264 - val_r2_inet_lambda_fv_loss: 2.3275\n",
      "Epoch 62/2000\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 0.1321 - r2_inet_lambda_fv_loss: 4.3423 - val_loss: 0.1262 - val_r2_inet_lambda_fv_loss: 2.2281\n",
      "Epoch 63/2000\n",
      "176/176 [==============================] - 27s 155ms/step - loss: 0.1320 - r2_inet_lambda_fv_loss: 4.0293 - val_loss: 0.1275 - val_r2_inet_lambda_fv_loss: 2.4250\n",
      "Epoch 64/2000\n",
      "176/176 [==============================] - 51s 290ms/step - loss: 0.1339 - r2_inet_lambda_fv_loss: 3.9013 - val_loss: 0.1302 - val_r2_inet_lambda_fv_loss: 2.5001\n",
      "Epoch 65/2000\n",
      "176/176 [==============================] - 59s 338ms/step - loss: 0.1390 - r2_inet_lambda_fv_loss: 4.0717 - val_loss: 0.1315 - val_r2_inet_lambda_fv_loss: 2.5726\n",
      "Epoch 66/2000\n",
      "176/176 [==============================] - 53s 300ms/step - loss: 0.1406 - r2_inet_lambda_fv_loss: 4.3902 - val_loss: 0.1438 - val_r2_inet_lambda_fv_loss: 3.9675\n",
      "Epoch 67/2000\n",
      "176/176 [==============================] - 40s 225ms/step - loss: 0.1497 - r2_inet_lambda_fv_loss: 5.7329 - val_loss: 0.1515 - val_r2_inet_lambda_fv_loss: 4.8255\n",
      "Epoch 68/2000\n",
      "176/176 [==============================] - 20s 114ms/step - loss: 0.1617 - r2_inet_lambda_fv_loss: 34.5403 - val_loss: 0.1695 - val_r2_inet_lambda_fv_loss: 24.5709\n",
      "Epoch 69/2000\n",
      "176/176 [==============================] - 43s 244ms/step - loss: 0.1767 - r2_inet_lambda_fv_loss: 428.0795 - val_loss: 0.1780 - val_r2_inet_lambda_fv_loss: 50.9575\n",
      "Epoch 70/2000\n",
      "176/176 [==============================] - 58s 330ms/step - loss: 0.1965 - r2_inet_lambda_fv_loss: 659.2824 - val_loss: 0.2017 - val_r2_inet_lambda_fv_loss: 103.9991\n",
      "Epoch 71/2000\n",
      "176/176 [==============================] - 55s 312ms/step - loss: 0.2073 - r2_inet_lambda_fv_loss: 3307.5985 - val_loss: 0.1966 - val_r2_inet_lambda_fv_loss: 103.6806\n",
      "Epoch 72/2000\n",
      "176/176 [==============================] - 54s 307ms/step - loss: 0.2004 - r2_inet_lambda_fv_loss: 4150.8702 - val_loss: 0.1995 - val_r2_inet_lambda_fv_loss: 103.1867\n",
      "Epoch 73/2000\n",
      "176/176 [==============================] - 37s 206ms/step - loss: 0.2072 - r2_inet_lambda_fv_loss: 5076.2050 - val_loss: 0.2040 - val_r2_inet_lambda_fv_loss: 110.0282\n",
      "Epoch 74/2000\n",
      "176/176 [==============================] - 34s 191ms/step - loss: 0.2118 - r2_inet_lambda_fv_loss: 6849.4901 - val_loss: 0.2085 - val_r2_inet_lambda_fv_loss: 112.5994\n",
      "Epoch 75/2000\n",
      "176/176 [==============================] - 55s 315ms/step - loss: 0.2141 - r2_inet_lambda_fv_loss: 4566.7771 - val_loss: 0.2131 - val_r2_inet_lambda_fv_loss: 106.9633\n",
      "Epoch 76/2000\n",
      "176/176 [==============================] - 57s 326ms/step - loss: 0.2193 - r2_inet_lambda_fv_loss: 3359.9141 - val_loss: 0.2220 - val_r2_inet_lambda_fv_loss: 107.3066\n",
      "Epoch 77/2000\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.2259 - r2_inet_lambda_fv_loss: 5599.2929 - val_loss: 0.2196 - val_r2_inet_lambda_fv_loss: 105.8185\n",
      "Epoch 78/2000\n",
      "176/176 [==============================] - 43s 246ms/step - loss: 0.2242 - r2_inet_lambda_fv_loss: 2926.5624 - val_loss: 0.2214 - val_r2_inet_lambda_fv_loss: 105.5623\n",
      "Epoch 79/2000\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.2241 - r2_inet_lambda_fv_loss: 8575.5106 - val_loss: 0.2213 - val_r2_inet_lambda_fv_loss: 106.0593\n",
      "Epoch 80/2000\n",
      "176/176 [==============================] - 44s 249ms/step - loss: 0.2279 - r2_inet_lambda_fv_loss: 2979.6513 - val_loss: 0.2273 - val_r2_inet_lambda_fv_loss: 109.7431\n",
      "Epoch 81/2000\n",
      "176/176 [==============================] - 57s 326ms/step - loss: 0.2340 - r2_inet_lambda_fv_loss: 6002.3939 - val_loss: 0.2325 - val_r2_inet_lambda_fv_loss: 109.7600\n",
      "Epoch 82/2000\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 0.2360 - r2_inet_lambda_fv_loss: 6613.4694 - val_loss: 0.2282 - val_r2_inet_lambda_fv_loss: 105.8769\n",
      "Epoch 83/2000\n",
      "176/176 [==============================] - 25s 145ms/step - loss: 0.2332 - r2_inet_lambda_fv_loss: 4112.0489 - val_loss: 0.2254 - val_r2_inet_lambda_fv_loss: 107.7131\n",
      "Epoch 84/2000\n",
      "176/176 [==============================] - 51s 292ms/step - loss: 0.2287 - r2_inet_lambda_fv_loss: 2086.5413 - val_loss: 0.2219 - val_r2_inet_lambda_fv_loss: 105.3704\n",
      "Epoch 85/2000\n",
      "176/176 [==============================] - 38s 216ms/step - loss: 0.2259 - r2_inet_lambda_fv_loss: 3166.8349 - val_loss: 0.2234 - val_r2_inet_lambda_fv_loss: 107.5192\n",
      "Epoch 86/2000\n",
      "176/176 [==============================] - 55s 315ms/step - loss: 0.2272 - r2_inet_lambda_fv_loss: 4959.5810 - val_loss: 0.2203 - val_r2_inet_lambda_fv_loss: 105.9525\n",
      "Epoch 87/2000\n",
      "176/176 [==============================] - 55s 316ms/step - loss: 0.2265 - r2_inet_lambda_fv_loss: 9659.2566 - val_loss: 0.2231 - val_r2_inet_lambda_fv_loss: 109.2882\n",
      "Epoch 88/2000\n",
      "176/176 [==============================] - 29s 166ms/step - loss: 0.2276 - r2_inet_lambda_fv_loss: 2085.6962 - val_loss: 0.2210 - val_r2_inet_lambda_fv_loss: 108.6321\n",
      "Epoch 89/2000\n",
      "176/176 [==============================] - 37s 211ms/step - loss: 0.2267 - r2_inet_lambda_fv_loss: 1838.9370 - val_loss: 0.2208 - val_r2_inet_lambda_fv_loss: 108.6851\n",
      "Epoch 90/2000\n",
      "176/176 [==============================] - 53s 298ms/step - loss: 0.2258 - r2_inet_lambda_fv_loss: 8633.0570 - val_loss: 0.2205 - val_r2_inet_lambda_fv_loss: 108.3754\n",
      "Epoch 91/2000\n",
      "176/176 [==============================] - 60s 343ms/step - loss: 0.2239 - r2_inet_lambda_fv_loss: 2443.6442 - val_loss: 0.2229 - val_r2_inet_lambda_fv_loss: 108.0913\n",
      "Epoch 92/2000\n",
      "176/176 [==============================] - 46s 260ms/step - loss: 0.2281 - r2_inet_lambda_fv_loss: 11528.7068 - val_loss: 0.2188 - val_r2_inet_lambda_fv_loss: 107.9830\n",
      "Epoch 93/2000\n",
      "176/176 [==============================] - 46s 262ms/step - loss: 0.2239 - r2_inet_lambda_fv_loss: 2593.2532 - val_loss: 0.2230 - val_r2_inet_lambda_fv_loss: 108.2185\n",
      "Epoch 94/2000\n",
      "176/176 [==============================] - 39s 221ms/step - loss: 0.2273 - r2_inet_lambda_fv_loss: 11120.8862 - val_loss: 0.2192 - val_r2_inet_lambda_fv_loss: 107.8019\n",
      "Epoch 95/2000\n",
      "176/176 [==============================] - 53s 303ms/step - loss: 0.2258 - r2_inet_lambda_fv_loss: 708.1455 - val_loss: 0.2236 - val_r2_inet_lambda_fv_loss: 108.3640\n",
      "Training Time: 1:09:13\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3146842/181021107.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%autoreload 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m ((X_valid_list, y_valid_list), \n\u001b[0m\u001b[1;32m      3\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mX_test_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0mhistory_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "((X_valid_list, y_valid_list), \n",
    " (X_test_list, y_test_list),\n",
    " history_list, \n",
    "\n",
    " #scores_valid_list,\n",
    " #scores_test_list, \n",
    "\n",
    " #function_values_valid_list, \n",
    " #function_values_test_list, \n",
    "\n",
    " #polynomial_dict_valid_list,\n",
    " #polynomial_dict_test_list,\n",
    "\n",
    " #distrib_dict_valid_list,\n",
    " #distrib_dict_test_list,\n",
    "\n",
    " model_list) = interpretation_net_training(lambda_net_train_dataset_list, \n",
    "                                           lambda_net_valid_dataset_list, \n",
    "                                           lambda_net_test_dataset_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.768547Z",
     "iopub.status.idle": "2021-10-19T13:00:15.772629Z",
     "shell.execute_reply": "2021-10-19T13:00:15.772303Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.772266Z"
    }
   },
   "outputs": [],
   "source": [
    "inet_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.778378Z",
     "iopub.status.idle": "2021-10-19T13:00:15.781905Z",
     "shell.execute_reply": "2021-10-19T13:00:15.781616Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.781582Z"
    }
   },
   "outputs": [],
   "source": [
    "inet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.787301Z",
     "iopub.status.idle": "2021-10-19T13:00:15.790800Z",
     "shell.execute_reply": "2021-10-19T13:00:15.790511Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.790476Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.794236Z",
     "iopub.status.idle": "2021-10-19T13:00:15.797770Z",
     "shell.execute_reply": "2021-10-19T13:00:15.797481Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.797447Z"
    }
   },
   "outputs": [],
   "source": [
    "#polynomial_dict_valid_list = []\n",
    "polynomial_dict_test_list = []  \n",
    "\n",
    "\n",
    "for lambda_net_valid_dataset, lambda_net_test_dataset in zip(lambda_net_valid_dataset_list, lambda_net_test_dataset_list):\n",
    "\n",
    "    #polynomial_dict_valid = {'lstsq_lambda_pred_polynomials': lambda_net_valid_dataset.lstsq_lambda_pred_polynomial_list,\n",
    "    #                        'lstsq_target_polynomials': lambda_net_valid_dataset.lstsq_target_polynomial_list,\n",
    "    #                        'target_polynomials': lambda_net_valid_dataset.target_polynomial_list}    \n",
    "\n",
    "    polynomial_dict_test = {'lstsq_lambda_pred_polynomials': lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list,\n",
    "                            'lstsq_target_polynomials': lambda_net_test_dataset.lstsq_target_polynomial_list,\n",
    "                            'target_polynomials': lambda_net_test_dataset.target_polynomial_list}    \n",
    "\n",
    "    #polynomial_dict_valid_list.append(polynomial_dict_valid)  \n",
    "    polynomial_dict_test_list.append(polynomial_dict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.800735Z",
     "iopub.status.idle": "2021-10-19T13:00:15.803868Z",
     "shell.execute_reply": "2021-10-19T13:00:15.803575Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.803541Z"
    }
   },
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------- PREDICT INET ------------------------------------------------------')\n",
    "\n",
    "start = time.time() \n",
    "\n",
    "for i, (X_test, model) in enumerate(zip(X_test_list, model_list)):\n",
    "    #y_test_pred = model.predict(X_test)    \n",
    "    #print(model.summary())\n",
    "    #print(X_test.shape)\n",
    "    y_test_pred = make_inet_prediction(model, X_test, network_data=None, lambda_trained_normalized=False, inet_training_normalized=normalize_inet_data, normalization_parameter_dict=None)\n",
    "    #print(y_test_pred.shape)   \n",
    "    polynomial_dict_test_list[i]['inet_polynomials'] = y_test_pred\n",
    "\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('Predict Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.806303Z",
     "iopub.status.idle": "2021-10-19T13:00:15.807995Z",
     "shell.execute_reply": "2021-10-19T13:00:15.807711Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.807678Z"
    }
   },
   "outputs": [],
   "source": [
    "if symbolic_metamodeling_poly_evaluation:\n",
    "    print('-------------------------------------------------- CALCULATE METAMODEL POLY -----------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        \n",
    "        metamodel_functions_test = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=False, force_polynomial=True)\n",
    "        polynomial_dict_test_list[i]['metamodel_poly'] = metamodel_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Metamodel Poly Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.811519Z",
     "iopub.status.idle": "2021-10-19T13:00:15.815005Z",
     "shell.execute_reply": "2021-10-19T13:00:15.814717Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.814683Z"
    }
   },
   "outputs": [],
   "source": [
    "if symbolic_metamodeling_evaluation:\n",
    "    print('---------------------------------------------------- CALCULATE METAMODEL --------------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        metamodel_functions_test = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=False, force_polynomial=False)\n",
    "        polynomial_dict_test_list[i]['metamodel_functions'] = metamodel_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Metamodel Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.817421Z",
     "iopub.status.idle": "2021-10-19T13:00:15.820163Z",
     "shell.execute_reply": "2021-10-19T13:00:15.819874Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.819841Z"
    }
   },
   "outputs": [],
   "source": [
    "if symbolic_metamodeling_function_evaluation:\n",
    "    print('----------------------------------------------- CALCULATE METAMODEL FUNCTION ----------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        metamodel_functions_test = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=True)\n",
    "        polynomial_dict_test_list[i]['metamodel_functions_no_GD'] = metamodel_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Metamodel Function Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.824691Z",
     "iopub.status.idle": "2021-10-19T13:00:15.826392Z",
     "shell.execute_reply": "2021-10-19T13:00:15.826081Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.826049Z"
    }
   },
   "outputs": [],
   "source": [
    "if symbolic_regression_evaluation:\n",
    "    print('----------------------------------------- CALCULATE SYMBOLIC REGRESSION FUNCTION ------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        symbolic_regression_functions_test = symbolic_regression_function_generation(lambda_net_test_dataset)\n",
    "        polynomial_dict_test_list[i]['symbolic_regression_functions'] = symbolic_regression_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Symbolic Regression Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.829604Z",
     "iopub.status.idle": "2021-10-19T13:00:15.834888Z",
     "shell.execute_reply": "2021-10-19T13:00:15.834602Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.834568Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if per_network_evaluation:\n",
    "    print('------------------------------------------------ CALCULATE PER NETWORK POLY -----------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        per_network_poly_test = per_network_poly_generation(lambda_net_test_dataset, optimization_type='scipy')\n",
    "        polynomial_dict_test_list[i]['per_network_polynomials'] = per_network_poly_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Per Network Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.837355Z",
     "iopub.status.idle": "2021-10-19T13:00:15.838973Z",
     "shell.execute_reply": "2021-10-19T13:00:15.838691Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.838657Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.841411Z",
     "iopub.status.idle": "2021-10-19T13:00:15.846791Z",
     "shell.execute_reply": "2021-10-19T13:00:15.846523Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.846494Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "print('------------------------------------------------ CALCULATE FUNCTION VALUES ------------------------------------------------')                \n",
    "\n",
    "start = time.time() \n",
    "\n",
    "function_values_test_list = []\n",
    "for lambda_net_test_dataset, polynomial_dict_test in zip(lambda_net_test_dataset_list, polynomial_dict_test_list):\n",
    "    function_values_test = calculate_all_function_values(lambda_net_test_dataset, polynomial_dict_test)\n",
    "    function_values_test_list.append(function_values_test)\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('FV Calculation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.849041Z",
     "iopub.status.idle": "2021-10-19T13:00:15.851031Z",
     "shell.execute_reply": "2021-10-19T13:00:15.850394Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.850361Z"
    }
   },
   "outputs": [],
   "source": [
    "print('----------------------------------------------------- CALCULATE SCORES ----------------------------------------------------')                \n",
    "\n",
    "start = time.time() \n",
    "\n",
    "scores_test_list = []\n",
    "distrib_dict_test_list = []\n",
    "\n",
    "for function_values_test, polynomial_dict_test in zip(function_values_test_list, polynomial_dict_test_list):\n",
    "    scores_test, distrib_test = evaluate_all_predictions(function_values_test, polynomial_dict_test)\n",
    "    scores_test_list.append(scores_test)\n",
    "    distrib_dict_test_list.append(distrib_test)\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('Score Calculation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.853092Z",
     "iopub.status.idle": "2021-10-19T13:00:15.854733Z",
     "shell.execute_reply": "2021-10-19T13:00:15.854457Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.854424Z"
    }
   },
   "outputs": [],
   "source": [
    "identifier_type = 'epochs' if samples_list == None else 'samples'\n",
    "save_results(scores_list=scores_test_list, by=identifier_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Interpretation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.862408Z",
     "iopub.status.idle": "2021-10-19T13:00:15.864065Z",
     "shell.execute_reply": "2021-10-19T13:00:15.863786Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.863744Z"
    }
   },
   "outputs": [],
   "source": [
    "if nas:\n",
    "    for trial in history_list[-1]: \n",
    "        print(trial.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.866508Z",
     "iopub.status.idle": "2021-10-19T13:00:15.868551Z",
     "shell.execute_reply": "2021-10-19T13:00:15.867883Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.867850Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(model_list) >= 1:\n",
    "    print(model_list[-1].summary())\n",
    "    print(model_list[-1].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.871330Z",
     "iopub.status.idle": "2021-10-19T13:00:15.872647Z",
     "shell.execute_reply": "2021-10-19T13:00:15.872370Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.872337Z"
    }
   },
   "outputs": [],
   "source": [
    "if evaluate_with_real_function:\n",
    "    keys = ['inetPoly_VS_targetPoly_test', 'perNetworkPoly_VS_targetPoly_test', 'predLambda_VS_targetPoly_test', 'lstsqLambda_VS_targetPoly_test', 'lstsqTarget_VS_targetPoly_test']\n",
    "else:\n",
    "    keys = ['inetPoly_VS_predLambda_test', 'inetPoly_VS_lstsqLambda_test', 'perNetworkPoly_VS_predLambda_test', 'perNetworkPoly_VS_lstsqLambda_test', 'lstsqLambda_VS_predLambda_test', 'predLambda_VS_targetPoly_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.878767Z",
     "iopub.status.idle": "2021-10-19T13:00:15.880391Z",
     "shell.execute_reply": "2021-10-19T13:00:15.880118Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.880084Z"
    }
   },
   "outputs": [],
   "source": [
    "#0.183\t0.234\t3.604\t0.143\t0.687\t2.559\t0.215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.882728Z",
     "iopub.status.idle": "2021-10-19T13:00:15.884306Z",
     "shell.execute_reply": "2021-10-19T13:00:15.884030Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.883998Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_test_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.890746Z",
     "iopub.status.idle": "2021-10-19T13:00:15.892429Z",
     "shell.execute_reply": "2021-10-19T13:00:15.892150Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.892118Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.894742Z",
     "iopub.status.idle": "2021-10-19T13:00:15.896367Z",
     "shell.execute_reply": "2021-10-19T13:00:15.896090Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.896058Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_inet_polynomials'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:55.162513Z",
     "start_time": "2021-01-08T11:56:54.472198Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.898744Z",
     "iopub.status.idle": "2021-10-19T13:00:15.901685Z",
     "shell.execute_reply": "2021-10-19T13:00:15.901398Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.901362Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:56.434915Z",
     "start_time": "2021-01-08T11:56:55.669304Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.904138Z",
     "iopub.status.idle": "2021-10-19T13:00:15.911277Z",
     "shell.execute_reply": "2021-10-19T13:00:15.910983Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.910947Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T20:33:18.514683Z",
     "start_time": "2021-01-07T20:33:18.506614Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.913656Z",
     "iopub.status.idle": "2021-10-19T13:00:15.915436Z",
     "shell.execute_reply": "2021-10-19T13:00:15.915152Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.915120Z"
    }
   },
   "outputs": [],
   "source": [
    "index_min = int(np.argmin(distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials']))\n",
    "\n",
    "print(distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'][index_min])\n",
    "\n",
    "polynomial_lambda = lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list[index_min]\n",
    "print_polynomial_from_coefficients(polynomial_lambda, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:42.304392Z",
     "start_time": "2021-01-07T15:49:42.291475Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.917745Z",
     "iopub.status.idle": "2021-10-19T13:00:15.919393Z",
     "shell.execute_reply": "2021-10-19T13:00:15.919092Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.919060Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_values_inet = distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_inet_polynomials']\n",
    "print('Mean: ' + str(np.mean(r2_values_inet)) + ' (' + str(r2_values_inet.shape[0]) + ' Samples)')\n",
    "\n",
    "r2_values_positive_inet = r2_values_inet[r2_values_inet>0]\n",
    "print('Mean (only positive): ' + str(np.mean(r2_values_positive_inet)) + ' (' + str(r2_values_positive_inet.shape[0]) + ' Samples)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:42.833577Z",
     "start_time": "2021-01-07T15:49:42.821286Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.921959Z",
     "iopub.status.idle": "2021-10-19T13:00:15.929480Z",
     "shell.execute_reply": "2021-10-19T13:00:15.929188Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.929153Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_values_lstsq_lambda = distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials']\n",
    "print('Mean: ' + str(np.mean(r2_values_lstsq_lambda)) + ' (' + str(r2_values_inet.shape[0]) + ' Samples)')\n",
    "\n",
    "r2_values_positive_lstsq_lambda = r2_values_lstsq_lambda[r2_values_lstsq_lambda>0]\n",
    "print('Mean (only positive): ' + str(np.mean(r2_values_positive_lstsq_lambda)) + ' (' + str(r2_values_positive_lstsq_lambda.shape[0]) + ' Samples)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.931833Z",
     "iopub.status.idle": "2021-10-19T13:00:15.933445Z",
     "shell.execute_reply": "2021-10-19T13:00:15.933171Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.933139Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'] < 50], binwidth=0.1)\n",
    "#p.set(xlim=(0, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.935772Z",
     "iopub.status.idle": "2021-10-19T13:00:15.937369Z",
     "shell.execute_reply": "2021-10-19T13:00:15.937097Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.937065Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'] < 50], binwidth=0.1)\n",
    "p.set(xlim=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.939667Z",
     "iopub.status.idle": "2021-10-19T13:00:15.941261Z",
     "shell.execute_reply": "2021-10-19T13:00:15.940987Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.940955Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'] < 50], binwidth=0.1)\n",
    "#p.set(xlim=(0, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:44.179590Z",
     "start_time": "2021-01-07T15:49:43.001746Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.951724Z",
     "iopub.status.idle": "2021-10-19T13:00:15.959752Z",
     "shell.execute_reply": "2021-10-19T13:00:15.959469Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.959434Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'] < 50], binwidth=0.1)\n",
    "p.set(xlim=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.410283Z",
     "start_time": "2021-01-07T15:49:48.254228Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.962858Z",
     "iopub.status.idle": "2021-10-19T13:00:15.965209Z",
     "shell.execute_reply": "2021-10-19T13:00:15.964935Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.964903Z"
    }
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history[list(history.keys())[1]])\n",
    "    try:\n",
    "        plt.plot(history[list(history.keys())[len(history.keys())//2+1]]) \n",
    "    except:\n",
    "        pass\n",
    "    plt.title('model ' + list(history.keys())[1])\n",
    "    plt.ylabel('metric')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/metric_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.567983Z",
     "start_time": "2021-01-07T15:49:48.413234Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.968314Z",
     "iopub.status.idle": "2021-10-19T13:00:15.970719Z",
     "shell.execute_reply": "2021-10-19T13:00:15.970452Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.970420Z"
    }
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    try:\n",
    "        plt.plot(history['val_loss'])\n",
    "    except:\n",
    "        pass\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/loss_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Epoch/Sampes Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Comparison Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.973772Z",
     "iopub.status.idle": "2021-10-19T13:00:15.976063Z",
     "shell.execute_reply": "2021-10-19T13:00:15.975788Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.975755Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.980430Z",
     "iopub.status.idle": "2021-10-19T13:00:15.982715Z",
     "shell.execute_reply": "2021-10-19T13:00:15.982439Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.982407Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['MAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.987533Z",
     "iopub.status.idle": "2021-10-19T13:00:15.989803Z",
     "shell.execute_reply": "2021-10-19T13:00:15.989533Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.989500Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['R2 FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list, ylim=(-5, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate and Analyze Predictions for Random Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:15.993780Z",
     "iopub.status.idle": "2021-10-19T13:00:15.997930Z",
     "shell.execute_reply": "2021-10-19T13:00:15.997648Z",
     "shell.execute_reply.started": "2021-10-19T13:00:15.997614Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 6\n",
    "\n",
    "custom_representation_keys_fixed = ['target_polynomials', 'lstsq_target_polynomials', 'lstsq_lambda_pred_polynomials', 'lstsq_lambda_pred_polynomials']\n",
    "custom_representation_keys_dynamic = ['inet_polynomials', 'per_network_polynomials']\n",
    "sympy_representation_keys = ['metamodel_functions']\n",
    "\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "for key in polynomial_dict_test_list[-1].keys():\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print(key)\n",
    "    if key in custom_representation_keys_fixed:\n",
    "        print_polynomial_from_coefficients(polynomial_dict_test_list[-1][key][index], force_complete_poly_representation=True, round_digits=4)\n",
    "        print(polynomial_dict_test_list[-1][key][index])\n",
    "    elif key in custom_representation_keys_dynamic:\n",
    "        print_polynomial_from_coefficients(polynomial_dict_test_list[-1][key][index], round_digits=4)\n",
    "        print(polynomial_dict_test_list[-1][key][index])\n",
    "    else:\n",
    "        display(polynomial_dict_test_list[-1][key][index])\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:52.425282Z",
     "start_time": "2021-01-07T15:49:51.529992Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.000853Z",
     "iopub.status.idle": "2021-10-19T13:00:16.004209Z",
     "shell.execute_reply": "2021-10-19T13:00:16.003923Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.003889Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      polynomial_dict_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:57.631017Z",
     "start_time": "2021-01-07T15:49:52.427326Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.007133Z",
     "iopub.status.idle": "2021-10-19T13:00:16.011275Z",
     "shell.execute_reply": "2021-10-19T13:00:16.010991Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.010957Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      polynomial_dict_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.014277Z",
     "iopub.status.idle": "2021-10-19T13:00:16.017702Z",
     "shell.execute_reply": "2021-10-19T13:00:16.017412Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.017378Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      polynomial_dict_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.022570Z",
     "iopub.status.idle": "2021-10-19T13:00:16.024885Z",
     "shell.execute_reply": "2021-10-19T13:00:16.024612Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.024581Z"
    }
   },
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (RANDOM GUESS) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:50:04.140254Z",
     "start_time": "2021-01-07T15:50:03.647192Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.028876Z",
     "iopub.status.idle": "2021-10-19T13:00:16.031396Z",
     "shell.execute_reply": "2021-10-19T13:00:16.031109Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.031076Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_random_polynomials = np.random.uniform(low=-10, high=10, size=(len(lambda_net_test_dataset_list[-1]), sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.030192Z",
     "start_time": "2021-01-07T15:50:04.141837Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.034508Z",
     "iopub.status.idle": "2021-10-19T13:00:16.036933Z",
     "shell.execute_reply": "2021-10-19T13:00:16.036651Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.036620Z"
    }
   },
   "outputs": [],
   "source": [
    "true_fv_test = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)\n",
    "random_fv_test = parallel_fv_calculation_from_polynomial(list_of_random_polynomials, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.064612Z",
     "start_time": "2021-01-07T16:08:23.032372Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.040008Z",
     "iopub.status.idle": "2021-10-19T13:00:16.042404Z",
     "shell.execute_reply": "2021-10-19T13:00:16.042062Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.042028Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error Coefficients: ' + str(np.round(mean_absolute_error(lambda_net_test_dataset_list[-1].target_polynomial_list, list_of_random_polynomials), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.204426Z",
     "start_time": "2021-01-07T16:08:23.066205Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.045559Z",
     "iopub.status.idle": "2021-10-19T13:00:16.047817Z",
     "shell.execute_reply": "2021-10-19T13:00:16.047528Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.047494Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, random_fv_test), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (EDUCATED GUESS/MEAN PREDICTION) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:31.911007Z",
     "start_time": "2021-01-07T16:08:23.205879Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.050911Z",
     "iopub.status.idle": "2021-10-19T13:00:16.053310Z",
     "shell.execute_reply": "2021-10-19T13:00:16.053045Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.053011Z"
    }
   },
   "outputs": [],
   "source": [
    "true_fv_train = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)\n",
    "\n",
    "mean_fv = np.mean(true_fv_train)\n",
    "mean_fv_pred_test = [mean_fv for _ in range(true_fv_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.029945Z",
     "start_time": "2021-01-07T16:17:31.912980Z"
    },
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.056284Z",
     "iopub.status.idle": "2021-10-19T13:00:16.058640Z",
     "shell.execute_reply": "2021-10-19T13:00:16.058368Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.058336Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Educated Guess/Mean Prediction Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, mean_fv_pred_test), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.508984Z",
     "start_time": "2021-01-07T16:17:32.031355Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.061740Z",
     "iopub.status.idle": "2021-10-19T13:00:16.064221Z",
     "shell.execute_reply": "2021-10-19T13:00:16.063945Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.063912Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "base_model = generate_base_model()\n",
    "random_evaluation_dataset = np.random.uniform(low=x_min, high=x_max, size=(random_evaluation_dataset_size, n))\n",
    "#random_evaluation_dataset = lambda_train_input_train_split[0]#lambda_train_input[0] #JUST [0] HERE BECAUSE EVALUATION ALWAYS ON THE SAME DATASET FOR ALL!!\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)\n",
    "\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "#X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "\n",
    "seed_in_inet_training = False\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "seed_in_inet_training = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.067381Z",
     "iopub.status.idle": "2021-10-19T13:00:16.069827Z",
     "shell.execute_reply": "2021-10-19T13:00:16.069553Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.069521Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "current_jobs = 1\n",
    "\n",
    "lr=0.5\n",
    "max_steps = 100\n",
    "early_stopping=10\n",
    "restarts=2\n",
    "per_network_dataset_size = 500\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "if n_jobs != -1:\n",
    "    n_jobs_per_network = min(n_jobs, os.cpu_count() // current_jobs)\n",
    "else: \n",
    "    n_jobs_per_network = os.cpu_count() // current_jobs - 1\n",
    "\n",
    "printing = True if n_jobs_per_network == 1 else False\n",
    "\n",
    "\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "if evaluate_with_real_function: #target polynomial as inet target\n",
    "    poly_representation_list = np.array(lambda_net_test_dataset.target_polynomial_list)\n",
    "else: #lstsq lambda pred polynomial as inet target\n",
    "    poly_representation_list = np.array(lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list)\n",
    "\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         #'list_of_monomial_identifiers': list_of_monomial_identifiers,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "lambda_network_weights = lambda_network_weights_list[0]\n",
    "poly_representation = poly_representation_list[0]\n",
    "\n",
    "\n",
    "\n",
    "per_network_poly_optimization_tf(per_network_dataset_size, \n",
    "                                lambda_network_weights, \n",
    "                                  list_of_monomial_identifiers_numbers, \n",
    "                                  config, \n",
    "                                  lr=lr, \n",
    "                                  max_steps = max_steps, \n",
    "                                  early_stopping=early_stopping, \n",
    "                                  restarts=restarts, \n",
    "                                  printing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Real Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Auto MPG-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.073209Z",
     "iopub.status.idle": "2021-10-19T13:00:16.075718Z",
     "shell.execute_reply": "2021-10-19T13:00:16.075427Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.075391Z"
    }
   },
   "outputs": [],
   "source": [
    "interpretation_possible_autoMPG = False\n",
    "print_head_autoMPG = None\n",
    "\n",
    "url_autoMPG = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names_autoMPG = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset_autoMPG = pd.read_csv(url_autoMPG, names=column_names_autoMPG,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)\n",
    "\n",
    "dataset_autoMPG = raw_dataset_autoMPG.dropna()\n",
    "\n",
    "dataset_autoMPG['Origin'] = dataset_autoMPG['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset_autoMPG = pd.get_dummies(dataset_autoMPG, columns=['Origin'], prefix='', prefix_sep='')\n",
    "\n",
    "\n",
    "features_autoMPG = dataset_autoMPG.copy()\n",
    "\n",
    "labels_autoMPG = features_autoMPG.pop('MPG')\n",
    "\n",
    "features_autoMPG_normalized = (features_autoMPG-features_autoMPG.min())/(features_autoMPG.max()-features_autoMPG.min())\n",
    "\n",
    "#labels_autoMPG = (labels_autoMPG-labels_autoMPG.min())/(labels_autoMPG.max()-labels_autoMPG.min())\n",
    "\n",
    "\n",
    "if features_autoMPG_normalized.shape[1] >= n:\n",
    "    if n == 1:\n",
    "        features_autoMPG_model = features_autoMPG_normalized[['Horsepower']]\n",
    "    elif n == features_autoMPG_normalized.shape[1]:\n",
    "        features_autoMPG_model = features_autoMPG_normalized\n",
    "    else:\n",
    "        features_autoMPG_model = features_autoMPG_normalized.sample(n=n, axis='columns')\n",
    "        \n",
    "    print_head_autoMPG = features_autoMPG_model.head()\n",
    "    interpretation_possible_autoMPG = True\n",
    "\n",
    "print_head_autoMPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.078892Z",
     "iopub.status.idle": "2021-10-19T13:00:16.081317Z",
     "shell.execute_reply": "2021-10-19T13:00:16.081043Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.081011Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.084416Z",
     "iopub.status.idle": "2021-10-19T13:00:16.086861Z",
     "shell.execute_reply": "2021-10-19T13:00:16.086593Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.086564Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    ((lambda_index_autoMPG, \n",
    "     current_seed_autoMPG, \n",
    "     polynomial_autoMPG, \n",
    "     polynomial_lstsq_pred_list_autoMPG, \n",
    "     polynomial_lstsq_true_list_autoMPG), \n",
    "    scores_list_autoMPG, \n",
    "    pred_list_autoMPG, \n",
    "    history_autoMPG, \n",
    "    model_autoMPG) = train_nn(lambda_index=0, \n",
    "                              X_data_lambda=features_autoMPG_model.values, \n",
    "                              y_data_real_lambda=labels_autoMPG.values, \n",
    "                              polynomial=None, \n",
    "                              seed_list=[RANDOM_SEED], \n",
    "                              callbacks=[PlotLossesKerasTF()], \n",
    "                              return_history=True, \n",
    "                              each_epochs_save=None, \n",
    "                              printing=False, \n",
    "                              return_model=True)\n",
    "    \n",
    "    polynomial_lstsq_pred_autoMPG = polynomial_lstsq_pred_list_autoMPG[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.090002Z",
     "iopub.status.idle": "2021-10-19T13:00:16.092378Z",
     "shell.execute_reply": "2021-10-19T13:00:16.092106Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.092074Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and n==1:\n",
    "    x = tf.linspace(0.0, 250, 251)\n",
    "    y = model_autoMPG.predict(x)\n",
    "\n",
    "    plt.scatter(features_autoMPG_model['Horsepower'], labels_autoMPG, label='Data')\n",
    "    plt.plot(x, y, color='k', label='Predictions')\n",
    "    plt.xlabel('Horsepower')\n",
    "    plt.ylabel('MPG')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.095538Z",
     "iopub.status.idle": "2021-10-19T13:00:16.097967Z",
     "shell.execute_reply": "2021-10-19T13:00:16.097702Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.097672Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "        'n': n,\n",
    "        'd': d,\n",
    "        'inet_loss': inet_loss,\n",
    "        'sparsity': sparsity,\n",
    "        'lambda_network_layers': lambda_network_layers,\n",
    "        'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "        'RANDOM_SEED': RANDOM_SEED,\n",
    "        'nas': nas,\n",
    "        'number_of_lambda_weights': number_of_lambda_weights,\n",
    "        'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "        'fixed_initialization_lambda_training': fixed_initialization_lambda_training,\n",
    "        'dropout': dropout,\n",
    "        'lambda_network_layers': lambda_network_layers,\n",
    "        'optimizer_lambda': optimizer_lambda,\n",
    "        'loss_lambda': loss_lambda,        \n",
    "         #'list_of_monomial_identifiers': list_of_monomial_identifiers,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "weights_autoMPG = model_autoMPG.get_weights()\n",
    "\n",
    "weights_flat_autoMPG = []\n",
    "for layer_weights, biases in pairwise(weights_autoMPG):    #clf.get_weights()\n",
    "    for neuron in layer_weights:\n",
    "        for weight in neuron:\n",
    "            weights_flat_autoMPG.append(weight)\n",
    "    for bias in biases:\n",
    "        weights_flat_autoMPG.append(bias)\n",
    "        \n",
    "weights_flat_autoMPG = np.array(weights_flat_autoMPG)\n",
    "\n",
    "\n",
    "x = pred_list_autoMPG['X_test_lambda']\n",
    "y = pred_list_autoMPG['y_test_real_lambda']\n",
    "\n",
    "y_model_autoMPG = model_autoMPG.predict(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.101071Z",
     "iopub.status.idle": "2021-10-19T13:00:16.103444Z",
     "shell.execute_reply": "2021-10-19T13:00:16.103158Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.103123Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "    y_polynomial_lstsq_pred_autoMPG = calculate_function_values_from_polynomial(polynomial_lstsq_pred_autoMPG, x, force_complete_poly_representation=True)\n",
    "\n",
    "    mae_model_polynomial_lstsq_pred_autoMPGy = mean_absolute_error(y_model_autoMPG, y_polynomial_lstsq_pred_autoMPG)\n",
    "    mae_data_polynomial_lstsq_pred_autoMPG = mean_absolute_error(y, y_polynomial_lstsq_pred_autoMPG)\n",
    "\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('LSTSQt Poly:')\n",
    "    print_polynomial_from_coefficients(y_polynomial_lstsq_pred_autoMPG, force_complete_poly_representation=True)\n",
    "    print('MAE Model: ', mae_model_polynomial_lstsq_pred_autoMPGy)\n",
    "    print('MAE Data: ', mae_data_polynomial_lstsq_pred_autoMPG)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.106530Z",
     "iopub.status.idle": "2021-10-19T13:00:16.109006Z",
     "shell.execute_reply": "2021-10-19T13:00:16.108727Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.108696Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    interpretation_net = model_list[-1]\n",
    "    \n",
    "    start = time.time() \n",
    "    \n",
    "    #interpretation_net_poly = interpretation_net.predict(np.array([weights_flat_autoMPG]))[0]\n",
    "    interpretation_net_poly = make_inet_prediction(interpretation_net, weights_flat_autoMPG, network_data=None, lambda_trained_normalized=False, inet_training_normalized=normalize_inet_data, normalization_parameter_dict=None)\n",
    "    \n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_interpretation_net_poly = calculate_function_values_from_polynomial(interpretation_net_poly, x, force_complete_poly_representation=False)\n",
    "    \n",
    "    mae_model_interpretation_net_poly = mean_absolute_error(y_model_autoMPG, y_interpretation_net_poly)\n",
    "    mae_data_interpretation_net_poly = mean_absolute_error(y, y_interpretation_net_poly)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Interpretation Net Poly:')\n",
    "    print_polynomial_from_coefficients(interpretation_net_poly, force_complete_poly_representation=False)\n",
    "    print('MAE Model: ', mae_model_interpretation_net_poly)\n",
    "    print('MAE Data: ', mae_data_interpretation_net_poly)    \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.112211Z",
     "iopub.status.idle": "2021-10-19T13:00:16.114675Z",
     "shell.execute_reply": "2021-10-19T13:00:16.114375Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.114342Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "\n",
    "    start = time.time() \n",
    "    \n",
    "    if False:\n",
    "        per_network_hyperparams = {\n",
    "            'optimizer':  'Powell',\n",
    "            'jac': 'fprime',\n",
    "            'max_steps': 5000,#100,\n",
    "            'restarts': 3,\n",
    "            'per_network_dataset_size': 500,\n",
    "        }      \n",
    "        \n",
    "        per_network_function =  per_network_poly_optimization_scipy(per_network_dataset_size, \n",
    "                                                                  weights_flat_autoMPG, \n",
    "                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                  config, \n",
    "                                                                  optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                  jac = per_network_hyperparams['jac'],\n",
    "                                                                  max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                  restarts=per_network_hyperparams['restarts'], \n",
    "                                                                  printing=True,\n",
    "                                                                  return_error=False)\n",
    "    else:\n",
    "        per_network_hyperparams = {\n",
    "            'optimizer': tf.keras.optimizers.RMSprop,\n",
    "            'lr': 0.02,\n",
    "            'max_steps': 500,\n",
    "            'early_stopping': 10,\n",
    "            'restarts': 3,\n",
    "            'per_network_dataset_size': 5000,\n",
    "        }   \n",
    "        \n",
    "        per_network_function =  per_network_poly_optimization_tf(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                              weights_flat_autoMPG, \n",
    "                                                              list_of_monomial_identifiers_numbers, \n",
    "                                                              config, \n",
    "                                                              optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                              lr=per_network_hyperparams['lr'], \n",
    "                                                              max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                              early_stopping=per_network_hyperparams['early_stopping'], \n",
    "                                                              restarts=per_network_hyperparams['restarts'], \n",
    "                                                              printing=True,\n",
    "                                                              return_error=False)\n",
    "            \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)  \n",
    "    \n",
    "    y_per_network_function = calculate_function_values_from_polynomial(per_network_function, x, force_complete_poly_representation=False)\n",
    "    \n",
    "    mae_model_interpretation_net_poly = mean_absolute_error(y_model_autoMPG, y_per_network_function)\n",
    "    mae_data_interpretation_net_poly = mean_absolute_error(y, y_per_network_function)    \n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Per Network Poly:')\n",
    "    print_polynomial_from_coefficients(per_network_function)\n",
    "    print('MAE Model: ', mae_model_interpretation_net_poly)\n",
    "    print('MAE Data: ', mae_data_interpretation_net_poly)       \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.117753Z",
     "iopub.status.idle": "2021-10-19T13:00:16.120037Z",
     "shell.execute_reply": "2021-10-19T13:00:16.119759Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.119726Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.123188Z",
     "iopub.status.idle": "2021-10-19T13:00:16.125698Z",
     "shell.execute_reply": "2021-10-19T13:00:16.125402Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.125369Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    \n",
    "    symbolic_regression_hyperparams = {\n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "\n",
    "    start = time.time() \n",
    "    \n",
    "    symbolic_regression_function =  symbolic_regression(model_autoMPG, \n",
    "                                                      config,\n",
    "                                                      symbolic_regression_hyperparams,\n",
    "                                                      #printing = True,\n",
    "                                                      return_error = False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    variable_names = ['X' + str(i) for i in range(n)]\n",
    "    \n",
    "    y_symbolic_regression_function = calculate_function_values_from_sympy(symbolic_regression_function, x, variable_names=variable_names)\n",
    "    \n",
    "    mae_model_symbolic_regression_function = mean_absolute_error(y_model_autoMPG, y_symbolic_regression_function)\n",
    "    mae_data_symbolic_regression_function = mean_absolute_error(y, y_symbolic_regression_function)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Symbolic Regression Poly:')    \n",
    "    display(symbolic_regression_function)\n",
    "    print('MAE Model: ', mae_model_symbolic_regression_function)\n",
    "    print('MAE Data: ', mae_data_symbolic_regression_function)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.128864Z",
     "iopub.status.idle": "2021-10-19T13:00:16.131336Z",
     "shell.execute_reply": "2021-10-19T13:00:16.131053Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.131020Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG and True:\n",
    "    metamodeling_hyperparams = {\n",
    "        'num_iter': 500,\n",
    "        'batch_size': None,\n",
    "        'learning_rate': 0.01,        \n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "    \n",
    "    start = time.time() \n",
    "\n",
    "    metamodel_function =  symbolic_metamodeling(model_autoMPG, \n",
    "                                              config,\n",
    "                                              metamodeling_hyperparams,\n",
    "                                              #printing = True,\n",
    "                                              return_error = False,\n",
    "                                              return_expression = 'approx', #'approx', #'exact',\n",
    "                                              function_metamodeling = False,\n",
    "                                              force_polynomial=False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_metamodel_function = calculate_function_values_from_sympy(metamodel_function, x)\n",
    "    \n",
    "    mae_model_metamodel_function = mean_absolute_error(y_model_autoMPG, y_metamodel_function)\n",
    "    mae_data_metamodel_function = mean_absolute_error(y, y_metamodel_function)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function:')    \n",
    "    display(metamodel_function)\n",
    "    print('MAE Model: ', mae_model_metamodel_function)\n",
    "    print('MAE Data: ', mae_data_metamodel_function)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.134590Z",
     "iopub.status.idle": "2021-10-19T13:00:16.137093Z",
     "shell.execute_reply": "2021-10-19T13:00:16.136806Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.136772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and False:\n",
    "    metamodeling_hyperparams = {\n",
    "        'num_iter': 500,\n",
    "        'batch_size': None,\n",
    "        'learning_rate': 0.01,        \n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "    \n",
    "    start = time.time() \n",
    "\n",
    "    metamodel_function_basic =  symbolic_metamodeling(model_autoMPG, \n",
    "                                              config,\n",
    "                                              metamodeling_hyperparams,\n",
    "                                              #printing = True,\n",
    "                                              return_error = False,\n",
    "                                              return_expression = 'approx', #'approx', #'exact',\n",
    "                                              function_metamodeling = True,\n",
    "                                              force_polynomial=False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_metamodel_function_basic = calculate_function_values_from_sympy(metamodel_function_basic, x)\n",
    "    \n",
    "    mae_metamodel_function_basic = mean_absolute_error(y_model_autoMPG, y_metamodel_function_basic)\n",
    "    mae_metamodel_function_basic = mean_absolute_error(y, y_metamodel_function_basic)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function Basic:')    \n",
    "    display(metamodel_function_basic)\n",
    "    print('MAE Model: ', mae_metamodel_function_basic)\n",
    "    print('MAE Data: ', mae_metamodel_function_basic)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.140229Z",
     "iopub.status.idle": "2021-10-19T13:00:16.142597Z",
     "shell.execute_reply": "2021-10-19T13:00:16.142318Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.142283Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Interpretation Net Poly:')\n",
    "    print_polynomial_from_coefficients(interpretation_net_poly, force_complete_poly_representation=False)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Per Network Poly:')\n",
    "    print_polynomial_from_coefficients(per_network_function, force_complete_poly_representation=False)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('LSTSQ Poly:')\n",
    "    print_polynomial_from_coefficients(polynomial_lstsq_pred_autoMPG, force_complete_poly_representation=True)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Symbolic Regression Function:')\n",
    "    display(symbolic_regression_function)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function:')\n",
    "    display(metamodel_function)\n",
    "    #print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    #print('Metamodel Function Basic:')\n",
    "    #display(metamodel_function_basic)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.145779Z",
     "iopub.status.idle": "2021-10-19T13:00:16.150980Z",
     "shell.execute_reply": "2021-10-19T13:00:16.150698Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.150664Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and n==1:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
    "    \n",
    "    ax.set_ylim([0,50])\n",
    "    \n",
    "    plt.scatter(features_autoMPG_model['Horsepower'], labels_autoMPG, label='Data')\n",
    "    plt.scatter(x, y, label='Test Data')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_model_autoMPG))]) , label='Model Predictions')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_interpretation_net_poly))]) , label='Interpretation Net Poly')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_per_network_function))]) , label='Per Network Poly')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_polynomial_lstsq_pred_autoMPG))]) , label='LSTSQ Poly')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_symbolic_regression_function))]) , label='Symbolic Regression Function')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_metamodel_function))]) , label='Metamodel Function')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y))]) y_metamodel_function_basic, label='Metamodel Function Basic')\n",
    "    plt.xlabel('Horsepower')\n",
    "    plt.ylabel('MPG')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.154843Z",
     "iopub.status.idle": "2021-10-19T13:00:16.157830Z",
     "shell.execute_reply": "2021-10-19T13:00:16.157573Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.157543Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_data_X = np.array([i for i in range(1000)])\n",
    "sample_data_y = np.array([3*i for i in range(1000)])\n",
    "\n",
    "current_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.161676Z",
     "iopub.status.idle": "2021-10-19T13:00:16.164894Z",
     "shell.execute_reply": "2021-10-19T13:00:16.164622Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.164590Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.168786Z",
     "iopub.status.idle": "2021-10-19T13:00:16.171868Z",
     "shell.execute_reply": "2021-10-19T13:00:16.171579Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.171545Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y*1000,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.175749Z",
     "iopub.status.idle": "2021-10-19T13:00:16.178910Z",
     "shell.execute_reply": "2021-10-19T13:00:16.178629Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.178593Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y+1000,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.182767Z",
     "iopub.status.idle": "2021-10-19T13:00:16.185852Z",
     "shell.execute_reply": "2021-10-19T13:00:16.185584Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.185553Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_2_weights = model.get_weights()\n",
    "model_2_normalized_weights = model_2_weights #[weights/10 for weights in model_2_weights]\n",
    "\n",
    "\n",
    "model_2_normalized_weights[-6] = model_2_normalized_weights[-6]/10\n",
    "model_2_normalized_weights[-5] = model_2_normalized_weights[-5]/10\n",
    "\n",
    "model_2_normalized_weights[-4] = model_2_normalized_weights[-4]/10\n",
    "model_2_normalized_weights[-3] = model_2_normalized_weights[-3]/100\n",
    "\n",
    "model_2_normalized_weights[-2] = model_2_normalized_weights[-2]/10\n",
    "model_2_normalized_weights[-1] = model_2_normalized_weights[-1]/1000\n",
    "\n",
    "model_2.set_weights(model_2_normalized_weights)\n",
    "\n",
    "print(model_2.get_weights())\n",
    "print(model_2.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Per-Network Poly Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Optimization (Common Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.189787Z",
     "iopub.status.idle": "2021-10-19T13:00:16.193058Z",
     "shell.execute_reply": "2021-10-19T13:00:16.192765Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.192731Z"
    }
   },
   "outputs": [],
   "source": [
    "random_index = RANDOM_SEED\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer':  'Powell',\n",
    "    'jac': 'fprime',\n",
    "    'max_steps': 5000,#100,\n",
    "    'restarts': 3,\n",
    "    'per_network_dataset_size': 500,\n",
    "}\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "lambda_network_weights = lambda_network_weights_list[random_index]\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "printing = True\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "per_network_optimization_error, per_network_optimization_polynomial = per_network_poly_optimization_scipy(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                                                                      lambda_network_weights, \n",
    "                                                                                                      list_of_monomial_identifiers_numbers, \n",
    "                                                                                                      config,\n",
    "                                                                                                      optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                                                      jac = per_network_hyperparams['jac'],\n",
    "                                                                                                      max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                                                      restarts = per_network_hyperparams['restarts'],\n",
    "                                                                                                      printing = True,\n",
    "                                                                                                      return_error = True)\n",
    "\n",
    "print('\\n\\nError: ' + str(per_network_optimization_error))\n",
    "print_polynomial_from_coefficients(per_network_optimization_polynomial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Optimization (Neural Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.197350Z",
     "iopub.status.idle": "2021-10-19T13:00:16.200717Z",
     "shell.execute_reply": "2021-10-19T13:00:16.200435Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.200401Z"
    }
   },
   "outputs": [],
   "source": [
    "random_index = RANDOM_SEED\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer': tf.keras.optimizers.RMSprop,\n",
    "    'lr': 0.02,\n",
    "    'max_steps': 500,\n",
    "    'early_stopping': 10,\n",
    "    'restarts': 3,\n",
    "    'per_network_dataset_size': 5000,\n",
    "}\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "lambda_network_weights = lambda_network_weights_list[random_index]\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "printing = True\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "per_network_optimization_error, per_network_optimization_polynomial = per_network_poly_optimization_tf(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                                                                      lambda_network_weights, \n",
    "                                                                                                      list_of_monomial_identifiers_numbers, \n",
    "                                                                                                      config,\n",
    "                                                                                                      optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                                                      lr = per_network_hyperparams['lr'], \n",
    "                                                                                                      max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                                                      early_stopping = per_network_hyperparams['early_stopping'], \n",
    "                                                                                                      restarts = per_network_hyperparams['restarts'],\n",
    "                                                                                                      printing = True,\n",
    "                                                                                                      return_error = True)\n",
    "\n",
    "print('\\n\\nError: ' + str(per_network_optimization_error.numpy()))\n",
    "print_polynomial_from_coefficients(per_network_optimization_polynomial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Common Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.204669Z",
     "iopub.status.idle": "2021-10-19T13:00:16.206510Z",
     "shell.execute_reply": "2021-10-19T13:00:16.206226Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.206193Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "evaluation_size = 10\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer':  [\n",
    "                   'Nelder-Mead', \n",
    "                   'Powell', \n",
    "        \n",
    "                   'CG',\n",
    "                   'BFGS',\n",
    "                   'Newton-CG', \n",
    "                   #'L-BFGS-B', #'>' not supported between instances of 'int' and 'NoneType'\n",
    "                   'TNC', \n",
    "                   \n",
    "                   'COBYLA', \n",
    "                   'SLSQP', \n",
    "                   \n",
    "                   #'trust-constr', # TypeError: _minimize_trustregion_constr() got an unexpected keyword argument 'maxfun'\n",
    "                   #'dogleg', # ValueError: Hessian is required for dogleg minimization\n",
    "                   #'trust-ncg', #ValueError: Either the Hessian or the Hessian-vector product is required for Newton-CG trust-region minimization\n",
    "                   #'trust-exact', # ValueError: Hessian matrix is required for trust region exact minimization.\n",
    "                   #'trust-krylov' #ValueError: Either the Hessian or the Hessian-vector product is required for Krylov trust-region minimization\n",
    "                   ], \n",
    "    'jac': ['fprime'],\n",
    "    'max_steps': [5000],#100,\n",
    "    'restarts': [3],\n",
    "    'per_network_dataset_size': [500],\n",
    "}\n",
    "\n",
    "#param_iterator = ParameterSampler(per_network_hyperparams, n_iter=60, random_state=RANDOM_SEED)\n",
    "param_iterator = ParameterGrid(per_network_hyperparams)\n",
    "\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "printing = True if n_jobs == 1 else False\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.208599Z",
     "iopub.status.idle": "2021-10-19T13:00:16.209116Z",
     "shell.execute_reply": "2021-10-19T13:00:16.208860Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.208832Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "params_error_list = []\n",
    "for params in tqdm(param_iterator):\n",
    "    parallel_per_network = Parallel(n_jobs=n_jobs, verbose=0, backend='loky')\n",
    "\n",
    "    result_list = parallel_per_network(delayed(per_network_poly_optimization_scipy)(params['per_network_dataset_size'], \n",
    "                                                                                  lambda_network_weights, \n",
    "                                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                                  config,\n",
    "                                                                                  optimizer = params['optimizer'],\n",
    "                                                                                  jac = params['jac'],\n",
    "                                                                                  max_steps = params['max_steps'], \n",
    "                                                                                  restarts = params['restarts'],\n",
    "                                                                                  printing = printing,\n",
    "                                                                                  return_error = True) for lambda_network_weights in lambda_network_weights_list[:evaluation_size])  \n",
    "    \n",
    "    \n",
    "    per_network_optimization_errors = [result[0] for result in result_list]\n",
    "    per_network_optimization_polynomials = [result[1] for result in result_list]\n",
    "        \n",
    "    params_score = np.mean(per_network_optimization_errors)\n",
    "    \n",
    "    evaluation_result = list(params.values())\n",
    "    evaluation_result.append(params_score)\n",
    "    \n",
    "    params_error_list.append(evaluation_result)\n",
    "        \n",
    "    del parallel_per_network\n",
    "\n",
    "columns = list(params.keys())\n",
    "columns.append('score')\n",
    "params_error_df = pd.DataFrame(data=params_error_list, columns=columns).sort_values(by='score')\n",
    "params_error_df.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Neural Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.214261Z",
     "iopub.status.idle": "2021-10-19T13:00:16.218368Z",
     "shell.execute_reply": "2021-10-19T13:00:16.218056Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.218022Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "evaluation_size = 100\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer': [tf.keras.optimizers.RMSprop], #[tf.keras.optimizers.SGD, tf.optimizers.Adam, tf.keras.optimizers.RMSprop, tf.keras.optimizers.Adadelta]\n",
    "    'lr': [0.02], #[0.5, 0.25, 0.1, 0.05, 0.025]\n",
    "    'max_steps': [5000],#100,\n",
    "    'early_stopping': [10],\n",
    "    'restarts': [3],\n",
    "    'per_network_dataset_size': [5000],\n",
    "}\n",
    "\n",
    "#param_iterator = ParameterSampler(per_network_hyperparams, n_iter=60, random_state=RANDOM_SEED)\n",
    "param_iterator = ParameterGrid(per_network_hyperparams)\n",
    "\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "printing = True if n_jobs == 1 else False\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.222404Z",
     "iopub.status.idle": "2021-10-19T13:00:16.222944Z",
     "shell.execute_reply": "2021-10-19T13:00:16.222673Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.222643Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "params_error_list = []\n",
    "for params in tqdm(param_iterator):\n",
    "    parallel_per_network = Parallel(n_jobs=n_jobs, verbose=0, backend='loky')\n",
    "\n",
    "    result_list = parallel_per_network(delayed(per_network_poly_optimization_tf)(params['per_network_dataset_size'], \n",
    "                                                                                  lambda_network_weights, \n",
    "                                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                                  config,\n",
    "                                                                                  optimizer = params['optimizer'],\n",
    "                                                                                  lr = params['lr'], \n",
    "                                                                                  max_steps = params['max_steps'], \n",
    "                                                                                  early_stopping = params['early_stopping'], \n",
    "                                                                                  restarts = params['restarts'],\n",
    "                                                                                  printing = printing,\n",
    "                                                                                  return_error = True) for lambda_network_weights in lambda_network_weights_list[:evaluation_size])  \n",
    "    \n",
    "    \n",
    "    per_network_optimization_errors = [result[0] for result in result_list]\n",
    "    per_network_optimization_polynomials = [result[1] for result in result_list]\n",
    "        \n",
    "    params_score = np.mean(per_network_optimization_errors)\n",
    "    \n",
    "    evaluation_result = list(params.values())\n",
    "    evaluation_result.append(params_score)\n",
    "    \n",
    "    params_error_list.append(evaluation_result)\n",
    "        \n",
    "    del parallel_per_network\n",
    "\n",
    "columns = list(params.keys())\n",
    "columns.append('score')\n",
    "params_error_df = pd.DataFrame(data=params_error_list, columns=columns).sort_values(by='score')\n",
    "params_error_df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-19T13:00:16.228425Z",
     "iopub.status.idle": "2021-10-19T13:00:16.232108Z",
     "shell.execute_reply": "2021-10-19T13:00:16.231818Z",
     "shell.execute_reply.started": "2021-10-19T13:00:16.231784Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
