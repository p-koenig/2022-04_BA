{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:15.338004Z",
     "iopub.status.busy": "2022-01-17T12:42:15.337581Z",
     "iopub.status.idle": "2022-01-17T12:42:15.372205Z",
     "shell.execute_reply": "2022-01-17T12:42:15.371046Z",
     "shell.execute_reply.started": "2022-01-17T12:42:15.337873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "config = {\n",
    "    'data': {\n",
    "        'd': 3, #degree\n",
    "        'n': 5, #number of variables\n",
    "        'monomial_vars': None, #int or None\n",
    "        'laurent': False, #use Laurent polynomials (negative degree with up to -d)  \n",
    "        'neg_d': 0,#int or None\n",
    "        'neg_d_prob': 0,\n",
    "        'sparsity': None,\n",
    "        'sample_sparsity': 5,\n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        'a_max': 1,\n",
    "        'a_min': -1,\n",
    "        'lambda_nets_total': 50000,\n",
    "        'noise': 0,\n",
    "        'noise_distrib': 'normal', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        \n",
    "        'function_generation_type': 'polynomial',# 'friedman', 'polynomial'\n",
    "        \n",
    "        'shift_polynomial': False,\n",
    "        \n",
    "        'border_min': 0.2, # defines an intervall. Value is randomly chosen and defines the minimum gap between x_min / x_max and the outermost stationary points => two values (left and right gap will be generated per variable)\n",
    "        'border_max': 0.4,\n",
    "        'lower_degree_prob': 0.5, # probability that the degree of the whole polynomial will be reduced\n",
    "        'a_random_prob': 0.5, # probability that a random generated function is used without adjustement\n",
    "                \n",
    "        'global_stationary_prob': 1, # probability that all variables are used for adjustement (0 recommended for higher number of variables)\n",
    "        'bulge_min': 1, # bulge_min and bulge_max define an intervall of how much the function is bulged\n",
    "        'bulge_max': 4,\n",
    "        'min_variables_used': 2, # defines an Intervall of how many variables are used to get stationary points and therefore adjust the function\n",
    "        'max_variables_used': 6,\n",
    "        'max_monomials': 7, # maximum number of monomials, before adjusting the function (monomial of degree 0 is always defined, but is included in this number)\n",
    "        'max_monomials_random': 10, #maximum number of monomials for random generated functions\n",
    "        \n",
    "        'same_training_all_lambda_nets': False,\n",
    "\n",
    "        'fixed_seed_lambda_training': True,\n",
    "        'fixed_initialization_lambda_training': False,\n",
    "        'number_different_lambda_trainings': 1,\n",
    "    },\n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True,  #if early stopping is used, multi_epoch_analysis is deactivated\n",
    "        'early_stopping_min_delta_lambda': 1e-4,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout': 0,\n",
    "        'lambda_network_layers': [5*'sample_sparsity'],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'mae',\n",
    "        'number_of_lambda_weights': None,\n",
    "        'lambda_dataset_size': 50000,\n",
    "    },\n",
    "    'i_net': {\n",
    "        'optimizer': 'adam',#adam\n",
    "        'inet_loss': 'mae',\n",
    "        'inet_metrics': ['r2'],\n",
    "        'dropout': 0,\n",
    "        'dropout_output': 0,\n",
    "        'epochs': 2000, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "        'dense_layers': [4096, 2048, 1024, 512],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'interpretation_dataset_size': 50000,\n",
    "                \n",
    "        'interpretation_net_output_monomials': 5, #(None, int) #CONSTANT IS NOT INCLUDED\n",
    "        'interpretation_net_output_shape': None, #calculated automatically later\n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'normalize_inet_data': False,\n",
    "        'inet_training_without_noise': True, #dataset size without noise hardcoded to 50k in generate_paths\n",
    "        'sparse_poly_representation_version': 1, #(1, 2); 1=old, 2=new\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'evaluate_with_real_function': False, #False\n",
    "        'consider_labels_training': False, #False\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 100,\n",
    "    },\n",
    "    'evaluation': {   \n",
    "        'inet_holdout_seed_evaluation': False,\n",
    "        \n",
    "        #set if multi_epoch_analysis should be performed\n",
    "        'multi_epoch_analysis': False,\n",
    "        'each_epochs_save_lambda': 100,\n",
    "        'epoch_start': 0, #use to skip first epochs in multi_epoch_analysis\n",
    "        \n",
    "        'max_optimization_minutes': 60,\n",
    "        \n",
    "        #set if samples analysis should be performed\n",
    "        'samples_list': None,#[100, 500, 750, 1000, 2500, 5000, 7500, 10000, 15000, 20000, 25000, 28125] \n",
    "       \n",
    "        'random_evaluation_dataset_size': 500,\n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "        \n",
    "        'adjusted_symbolic_metamodeling_code': False,\n",
    "        'symbolic_metamodeling_evaluation': False,\n",
    "        'symbolic_metamodeling_poly_evaluation': False,\n",
    "        'symbolic_metamodeling_function_evaluation': False,\n",
    "        'symbolic_metamodeling_poly_function_evaluation': False,\n",
    "        \n",
    "        'polynomial_regression_evaluation': False,\n",
    "        'symbolic_regression_evaluation': True,\n",
    "        'per_network_evaluation': False,\n",
    "        \n",
    "        'different_eval_data': False,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'polynomial',# 'friedman1', 'polynomial'\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise': 0, \n",
    "            'eval_data_noise_distrib': 'normal', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            'eval_data_shift_polynomial': False,\n",
    "            'eval_data_lambda_nets_total': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "        }        \n",
    "        \n",
    "    },\n",
    "    'computation':{\n",
    "        'train_model': True,\n",
    "        'n_jobs': 10,\n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '4',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:15.374478Z",
     "iopub.status.busy": "2022-01-17T12:42:15.373836Z",
     "iopub.status.idle": "2022-01-17T12:42:15.428885Z",
     "shell.execute_reply": "2022-01-17T12:42:15.426961Z",
     "shell.execute_reply.started": "2022-01-17T12:42:15.374438Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:15.431834Z",
     "iopub.status.busy": "2022-01-17T12:42:15.431516Z",
     "iopub.status.idle": "2022-01-17T12:42:22.773669Z",
     "shell.execute_reply": "2022-01-17T12:42:22.772196Z",
     "shell.execute_reply.started": "2022-01-17T12:42:15.431791Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "tf.autograph.set_verbosity(2)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import colored\n",
    "import math\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random \n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:22.779987Z",
     "iopub.status.busy": "2022-01-17T12:42:22.778292Z",
     "iopub.status.idle": "2022-01-17T12:42:22.794324Z",
     "shell.execute_reply": "2022-01-17T12:42:22.793298Z",
     "shell.execute_reply.started": "2022-01-17T12:42:22.779945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:22.796097Z",
     "iopub.status.busy": "2022-01-17T12:42:22.795588Z",
     "iopub.status.idle": "2022-01-17T12:42:22.821881Z",
     "shell.execute_reply": "2022-01-17T12:42:22.820851Z",
     "shell.execute_reply.started": "2022-01-17T12:42:22.796054Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "\n",
    "n_jobs = min((epochs_lambda//each_epochs_save_lambda+1, n_jobs)) if multi_epoch_analysis else min(len(samples_list), n_jobs) if samples_list!=None else 1\n",
    "\n",
    "multi_epoch_analysis = False if early_stopping_lambda else multi_epoch_analysis #deactivate multi_epoch_analysis if early stopping is used\n",
    "\n",
    "each_epochs_save_lambda = each_epochs_save_lambda if multi_epoch_analysis else epochs_lambda\n",
    "epochs_save_range_lambda = range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda) if each_epochs_save_lambda == 1 else range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda+1) if multi_epoch_analysis else range(1,2)\n",
    "\n",
    "data_reshape_version = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2, --tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:22.823626Z",
     "iopub.status.busy": "2022-01-17T12:42:22.823287Z",
     "iopub.status.idle": "2022-01-17T12:42:24.409719Z",
     "shell.execute_reply": "2022-01-17T12:42:24.408346Z",
     "shell.execute_reply.started": "2022-01-17T12:42:22.823582Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 56\n",
      "[[3, 0, 0, 0, 0], [2, 1, 0, 0, 0], [2, 0, 1, 0, 0], [2, 0, 0, 1, 0], [2, 0, 0, 0, 1], [2, 0, 0, 0, 0], [1, 2, 0, 0, 0], [1, 1, 1, 0, 0], [1, 1, 0, 1, 0], [1, 1, 0, 0, 1], [1, 1, 0, 0, 0], [1, 0, 2, 0, 0], [1, 0, 1, 1, 0], [1, 0, 1, 0, 1], [1, 0, 1, 0, 0], [1, 0, 0, 2, 0], [1, 0, 0, 1, 1], [1, 0, 0, 1, 0], [1, 0, 0, 0, 2], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0], [0, 3, 0, 0, 0], [0, 2, 1, 0, 0], [0, 2, 0, 1, 0], [0, 2, 0, 0, 1], [0, 2, 0, 0, 0], [0, 1, 2, 0, 0], [0, 1, 1, 1, 0], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0], [0, 1, 0, 2, 0], [0, 1, 0, 1, 1], [0, 1, 0, 1, 0], [0, 1, 0, 0, 2], [0, 1, 0, 0, 1], [0, 1, 0, 0, 0], [0, 0, 3, 0, 0], [0, 0, 2, 1, 0], [0, 0, 2, 0, 1], [0, 0, 2, 0, 0], [0, 0, 1, 2, 0], [0, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 0, 1, 0, 2], [0, 0, 1, 0, 1], [0, 0, 1, 0, 0], [0, 0, 0, 3, 0], [0, 0, 0, 2, 1], [0, 0, 0, 2, 0], [0, 0, 0, 1, 2], [0, 0, 0, 1, 1], [0, 0, 0, 1, 0], [0, 0, 0, 0, 3], [0, 0, 0, 0, 2], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "from utilities.utility_functions import flatten, rec_gen, gen_monomial_identifier_list\n",
    "\n",
    "list_of_monomial_identifiers_extended = []\n",
    "\n",
    "if laurent:\n",
    "    variable_sets = [list(flatten([[_d for _d in range(d+1)], [-_d for _d in range(1, neg_d+1)]])) for _ in range(n)]\n",
    "    list_of_monomial_identifiers_extended = rec_gen(variable_sets)    \n",
    "        \n",
    "    print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "    #print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "    #print('Sparsity:' + str(sparsity))\n",
    "    if len(list_of_monomial_identifiers_extended) < 500:\n",
    "        print(list_of_monomial_identifiers_extended)     \n",
    "        \n",
    "    list_of_monomial_identifiers = []\n",
    "    for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "        if np.sum(monomial_identifier) <= d:\n",
    "            if monomial_vars == None or len(list(filter(lambda x: x != 0, monomial_identifier))) <= monomial_vars:\n",
    "                list_of_monomial_identifiers.append(monomial_identifier)        \n",
    "else:\n",
    "    variable_list = ['x'+ str(i) for i in range(n)]\n",
    "    list_of_monomial_identifiers = gen_monomial_identifier_list(variable_list, d, n)\n",
    "            \n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "#print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "#print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:24.412814Z",
     "iopub.status.busy": "2022-01-17T12:42:24.412552Z",
     "iopub.status.idle": "2022-01-17T12:42:24.734049Z",
     "shell.execute_reply": "2022-01-17T12:42:24.732320Z",
     "shell.execute_reply.started": "2022-01-17T12:42:24.412773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape:  285\n"
     ]
    }
   ],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "config['evaluation']['multi_epoch_analysis'] = multi_epoch_analysis\n",
    "config['evaluation']['each_epochs_save_lambda'] = each_epochs_save_lambda\n",
    "config['i_net']['data_reshape_version'] = data_reshape_version\n",
    "\n",
    "config['data']['sparsity'] = nCr(config['data']['n']+config['data']['d'], config['data']['d']) if not laurent else len(list_of_monomial_identifiers)\n",
    "config['data']['sample_sparsity'] = config['data']['sparsity'] if config['data']['sample_sparsity'] == None else config['data']['sample_sparsity']\n",
    "\n",
    "config['i_net']['interpretation_net_output_shape'] = config['data']['sparsity'] if config['i_net']['interpretation_net_output_monomials'] is None else config['data']['sparsity']*config['i_net']['interpretation_net_output_monomials']+config['i_net']['interpretation_net_output_monomials'] if config['i_net']['sparse_poly_representation_version'] == 1 else config['data']['n']*(config['data']['d']+1)*config['i_net']['interpretation_net_output_monomials']+config['i_net']['interpretation_net_output_monomials']  \n",
    "print('Output Shape: ', config['i_net']['interpretation_net_output_shape'])\n",
    "\n",
    "transformed_layers = []\n",
    "for layer in config['lambda_net']['lambda_network_layers']:\n",
    "    if type(layer) == str:\n",
    "        transformed_layers.append(layer.count('sample_sparsity')*config['data']['sample_sparsity'])\n",
    "    else:\n",
    "        transformed_layers.append(layer)\n",
    "config['lambda_net']['lambda_network_layers'] = transformed_layers\n",
    "\n",
    "layers_with_input_output = list(flatten([[config['data']['n']], config['lambda_net']['lambda_network_layers'], [1]]))\n",
    "number_of_lambda_weights = 0\n",
    "for i in range(len(layers_with_input_output)-1):\n",
    "    number_of_lambda_weights += (layers_with_input_output[i]+1)*layers_with_input_output[i+1]  \n",
    "config['lambda_net']['number_of_lambda_weights'] = number_of_lambda_weights\n",
    "    \n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "\n",
    "\n",
    "initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "initialize_metrics_config_from_curent_notebook(config)\n",
    "initialize_utility_functions_config_from_curent_notebook(config)\n",
    "initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(path_type='interpretation_net'))\n",
    "create_folders_inet()\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:24.747247Z",
     "iopub.status.busy": "2022-01-17T12:42:24.738409Z",
     "iopub.status.idle": "2022-01-17T12:42:24.756073Z",
     "shell.execute_reply": "2022-01-17T12:42:24.754383Z",
     "shell.execute_reply.started": "2022-01-17T12:42:24.747181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inet_dense4096-2048-1024-512-output_285_drop0e2000b256_adam/lnets_100_25-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_5_d_3_negd_0_prob_0_spars_5_amin_-1_amax_1_xdist_uniform_noise_normal_0_polynomial\n",
      "lnets_100_25-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_5_d_3_negd_0_prob_0_spars_5_amin_-1_amax_1_xdist_uniform_noise_normal_0_polynomial\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net_data)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:24.757802Z",
     "iopub.status.busy": "2022-01-17T12:42:24.757493Z",
     "iopub.status.idle": "2022-01-17T12:42:24.907150Z",
     "shell.execute_reply": "2022-01-17T12:42:24.905790Z",
     "shell.execute_reply.started": "2022-01-17T12:42:24.757772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num XLA-GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:24.909407Z",
     "iopub.status.busy": "2022-01-17T12:42:24.909084Z",
     "iopub.status.idle": "2022-01-17T12:42:24.937024Z",
     "shell.execute_reply": "2022-01-17T12:42:24.935129Z",
     "shell.execute_reply.started": "2022-01-17T12:42:24.909364Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, index, no_noise=False):\n",
    "        \n",
    "    if psutil.virtual_memory().percent > 80:\n",
    "        raise SystemExit(\"Out of RAM!\")\n",
    "                    \n",
    "    path_identifier_lambda_net_data_loading = generate_paths(config, path_type='interpretation_net')['path_identifier_lambda_net_data']\n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_identifier_lambda_net_data_loading + '/'\n",
    "    path_weights = directory + 'weights_epoch_' + str(index).zfill(3) + '.txt'\n",
    "    path_X_data = directory + 'lambda_X_test_data.txt'\n",
    "    path_y_data = directory + 'lambda_y_test_data.txt'        \n",
    "    \n",
    "    weight_data = pd.read_csv(path_weights, sep=\",\", header=None)\n",
    "    weight_data = weight_data.sort_values(by=0).sample(n=config['i_net']['interpretation_dataset_size'], random_state=RANDOM_SEED)\n",
    "\n",
    "    lambda_X_test_data = pd.read_csv(path_X_data, sep=\",\", header=None)\n",
    "    lambda_X_test_data = lambda_X_test_data.sort_values(by=0).sample(n=config['i_net']['interpretation_dataset_size'], random_state=RANDOM_SEED)\n",
    "\n",
    "    lambda_y_test_data = pd.read_csv(path_y_data, sep=\",\", header=None)\n",
    "    lambda_y_test_data = lambda_y_test_data.sort_values(by=0).sample(n=config['i_net']['interpretation_dataset_size'], random_state=RANDOM_SEED)\n",
    "    \n",
    "    lambda_nets = [None] * weight_data.shape[0]\n",
    "    for i, (row_weights, row_lambda_X_test_data, row_lambda_y_test_data) in enumerate(zip(weight_data.values, lambda_X_test_data.values, lambda_y_test_data.values)):        \n",
    "        lambda_net = LambdaNet(row_weights, row_lambda_X_test_data, row_lambda_y_test_data)\n",
    "        lambda_nets[i] = lambda_net\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:24.939229Z",
     "iopub.status.busy": "2022-01-17T12:42:24.938879Z",
     "iopub.status.idle": "2022-01-17T12:42:26.495354Z",
     "shell.execute_reply": "2022-01-17T12:42:26.494331Z",
     "shell.execute_reply.started": "2022-01-17T12:42:24.939185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise'] = config['evaluation']['eval_data_description']['eval_data_noise']\n",
    "    config_eval['data']['noise_distrib'] = config['evaluation']['eval_data_description']['eval_data_noise_distrib'] \n",
    "    config_eval['data']['lambda_nets_total'] = config['evaluation']['eval_data_description']['eval_data_lambda_nets_total']   \n",
    "    config_eval['data']['shift_polynomial'] = config['evaluation']['eval_data_description']['eval_data_shift_polynomial']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "    index = each_epochs_save_lambda\n",
    "\n",
    "    lambda_net_dataset_train = load_lambda_nets(config_train, each_epochs_save_lambda)\n",
    "    lambda_net_dataset_eval = load_lambda_nets(config_eval, each_epochs_save_lambda)\n",
    "\n",
    "    lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)    \n",
    "\n",
    "    lambda_net_train_dataset_list = [lambda_net_dataset_train]\n",
    "    lambda_net_valid_dataset_list = [lambda_net_dataset_valid]\n",
    "    lambda_net_test_dataset_list = [lambda_net_dataset_test]\n",
    "    \n",
    "else:\n",
    "    index = each_epochs_save_lambda\n",
    "    \n",
    "    lambda_net_dataset = load_lambda_nets(config, each_epochs_save_lambda)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    \n",
    "    \n",
    "    lambda_net_train_dataset_list = [lambda_net_dataset_train]\n",
    "    lambda_net_valid_dataset_list = [lambda_net_dataset_valid]\n",
    "    lambda_net_test_dataset_list = [lambda_net_dataset_test]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets for Interpretation-Net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:06.495716Z",
     "start_time": "2021-01-05T09:32:09.784760Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:26.501669Z",
     "iopub.status.busy": "2022-01-17T12:42:26.501309Z",
     "iopub.status.idle": "2022-01-17T12:42:26.542874Z",
     "shell.execute_reply": "2022-01-17T12:42:26.540825Z",
     "shell.execute_reply.started": "2022-01-17T12:42:26.501639Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 345)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_train_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:08.945802Z",
     "start_time": "2021-01-05T09:33:06.499150Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:26.544399Z",
     "iopub.status.busy": "2022-01-17T12:42:26.544153Z",
     "iopub.status.idle": "2022-01-17T12:42:26.577807Z",
     "shell.execute_reply": "2022-01-17T12:42:26.576955Z",
     "shell.execute_reply.started": "2022-01-17T12:42:26.544364Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 345)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_valid_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:11.543306Z",
     "start_time": "2021-01-05T09:33:08.947468Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:26.579643Z",
     "iopub.status.busy": "2022-01-17T12:42:26.579286Z",
     "iopub.status.idle": "2022-01-17T12:42:26.621798Z",
     "shell.execute_reply": "2022-01-17T12:42:26.620737Z",
     "shell.execute_reply.started": "2022-01-17T12:42:26.579598Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 345)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_test_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:26.623238Z",
     "iopub.status.busy": "2022-01-17T12:42:26.622834Z",
     "iopub.status.idle": "2022-01-17T12:42:26.913166Z",
     "shell.execute_reply": "2022-01-17T12:42:26.911540Z",
     "shell.execute_reply.started": "2022-01-17T12:42:26.623194Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>30000-target</th>\n",
       "      <th>21000-target</th>\n",
       "      <th>20100-target</th>\n",
       "      <th>20010-target</th>\n",
       "      <th>20001-target</th>\n",
       "      <th>20000-target</th>\n",
       "      <th>12000-target</th>\n",
       "      <th>11100-target</th>\n",
       "      <th>11010-target</th>\n",
       "      <th>11001-target</th>\n",
       "      <th>11000-target</th>\n",
       "      <th>10200-target</th>\n",
       "      <th>10110-target</th>\n",
       "      <th>10101-target</th>\n",
       "      <th>10100-target</th>\n",
       "      <th>10020-target</th>\n",
       "      <th>10011-target</th>\n",
       "      <th>10010-target</th>\n",
       "      <th>10002-target</th>\n",
       "      <th>10001-target</th>\n",
       "      <th>10000-target</th>\n",
       "      <th>03000-target</th>\n",
       "      <th>02100-target</th>\n",
       "      <th>02010-target</th>\n",
       "      <th>02001-target</th>\n",
       "      <th>02000-target</th>\n",
       "      <th>01200-target</th>\n",
       "      <th>01110-target</th>\n",
       "      <th>01101-target</th>\n",
       "      <th>01100-target</th>\n",
       "      <th>01020-target</th>\n",
       "      <th>01011-target</th>\n",
       "      <th>01010-target</th>\n",
       "      <th>01002-target</th>\n",
       "      <th>01001-target</th>\n",
       "      <th>01000-target</th>\n",
       "      <th>00300-target</th>\n",
       "      <th>00210-target</th>\n",
       "      <th>00201-target</th>\n",
       "      <th>00200-target</th>\n",
       "      <th>00120-target</th>\n",
       "      <th>00111-target</th>\n",
       "      <th>00110-target</th>\n",
       "      <th>00102-target</th>\n",
       "      <th>00101-target</th>\n",
       "      <th>00100-target</th>\n",
       "      <th>00030-target</th>\n",
       "      <th>00021-target</th>\n",
       "      <th>00020-target</th>\n",
       "      <th>00012-target</th>\n",
       "      <th>00011-target</th>\n",
       "      <th>00010-target</th>\n",
       "      <th>00003-target</th>\n",
       "      <th>00002-target</th>\n",
       "      <th>00001-target</th>\n",
       "      <th>00000-target</th>\n",
       "      <th>30000-lstsq_lambda</th>\n",
       "      <th>21000-lstsq_lambda</th>\n",
       "      <th>20100-lstsq_lambda</th>\n",
       "      <th>20010-lstsq_lambda</th>\n",
       "      <th>20001-lstsq_lambda</th>\n",
       "      <th>20000-lstsq_lambda</th>\n",
       "      <th>12000-lstsq_lambda</th>\n",
       "      <th>11100-lstsq_lambda</th>\n",
       "      <th>11010-lstsq_lambda</th>\n",
       "      <th>11001-lstsq_lambda</th>\n",
       "      <th>11000-lstsq_lambda</th>\n",
       "      <th>10200-lstsq_lambda</th>\n",
       "      <th>10110-lstsq_lambda</th>\n",
       "      <th>10101-lstsq_lambda</th>\n",
       "      <th>10100-lstsq_lambda</th>\n",
       "      <th>10020-lstsq_lambda</th>\n",
       "      <th>10011-lstsq_lambda</th>\n",
       "      <th>10010-lstsq_lambda</th>\n",
       "      <th>10002-lstsq_lambda</th>\n",
       "      <th>10001-lstsq_lambda</th>\n",
       "      <th>10000-lstsq_lambda</th>\n",
       "      <th>03000-lstsq_lambda</th>\n",
       "      <th>02100-lstsq_lambda</th>\n",
       "      <th>02010-lstsq_lambda</th>\n",
       "      <th>02001-lstsq_lambda</th>\n",
       "      <th>02000-lstsq_lambda</th>\n",
       "      <th>01200-lstsq_lambda</th>\n",
       "      <th>01110-lstsq_lambda</th>\n",
       "      <th>01101-lstsq_lambda</th>\n",
       "      <th>01100-lstsq_lambda</th>\n",
       "      <th>01020-lstsq_lambda</th>\n",
       "      <th>01011-lstsq_lambda</th>\n",
       "      <th>01010-lstsq_lambda</th>\n",
       "      <th>01002-lstsq_lambda</th>\n",
       "      <th>01001-lstsq_lambda</th>\n",
       "      <th>01000-lstsq_lambda</th>\n",
       "      <th>00300-lstsq_lambda</th>\n",
       "      <th>00210-lstsq_lambda</th>\n",
       "      <th>00201-lstsq_lambda</th>\n",
       "      <th>00200-lstsq_lambda</th>\n",
       "      <th>00120-lstsq_lambda</th>\n",
       "      <th>00111-lstsq_lambda</th>\n",
       "      <th>00110-lstsq_lambda</th>\n",
       "      <th>00102-lstsq_lambda</th>\n",
       "      <th>00101-lstsq_lambda</th>\n",
       "      <th>00100-lstsq_lambda</th>\n",
       "      <th>00030-lstsq_lambda</th>\n",
       "      <th>00021-lstsq_lambda</th>\n",
       "      <th>00020-lstsq_lambda</th>\n",
       "      <th>00012-lstsq_lambda</th>\n",
       "      <th>00011-lstsq_lambda</th>\n",
       "      <th>00010-lstsq_lambda</th>\n",
       "      <th>00003-lstsq_lambda</th>\n",
       "      <th>00002-lstsq_lambda</th>\n",
       "      <th>00001-lstsq_lambda</th>\n",
       "      <th>00000-lstsq_lambda</th>\n",
       "      <th>30000-lstsq_target</th>\n",
       "      <th>21000-lstsq_target</th>\n",
       "      <th>20100-lstsq_target</th>\n",
       "      <th>20010-lstsq_target</th>\n",
       "      <th>20001-lstsq_target</th>\n",
       "      <th>20000-lstsq_target</th>\n",
       "      <th>12000-lstsq_target</th>\n",
       "      <th>11100-lstsq_target</th>\n",
       "      <th>11010-lstsq_target</th>\n",
       "      <th>11001-lstsq_target</th>\n",
       "      <th>11000-lstsq_target</th>\n",
       "      <th>10200-lstsq_target</th>\n",
       "      <th>10110-lstsq_target</th>\n",
       "      <th>10101-lstsq_target</th>\n",
       "      <th>10100-lstsq_target</th>\n",
       "      <th>10020-lstsq_target</th>\n",
       "      <th>10011-lstsq_target</th>\n",
       "      <th>10010-lstsq_target</th>\n",
       "      <th>10002-lstsq_target</th>\n",
       "      <th>10001-lstsq_target</th>\n",
       "      <th>10000-lstsq_target</th>\n",
       "      <th>03000-lstsq_target</th>\n",
       "      <th>02100-lstsq_target</th>\n",
       "      <th>02010-lstsq_target</th>\n",
       "      <th>02001-lstsq_target</th>\n",
       "      <th>02000-lstsq_target</th>\n",
       "      <th>01200-lstsq_target</th>\n",
       "      <th>01110-lstsq_target</th>\n",
       "      <th>01101-lstsq_target</th>\n",
       "      <th>01100-lstsq_target</th>\n",
       "      <th>01020-lstsq_target</th>\n",
       "      <th>01011-lstsq_target</th>\n",
       "      <th>01010-lstsq_target</th>\n",
       "      <th>01002-lstsq_target</th>\n",
       "      <th>01001-lstsq_target</th>\n",
       "      <th>01000-lstsq_target</th>\n",
       "      <th>00300-lstsq_target</th>\n",
       "      <th>00210-lstsq_target</th>\n",
       "      <th>00201-lstsq_target</th>\n",
       "      <th>00200-lstsq_target</th>\n",
       "      <th>00120-lstsq_target</th>\n",
       "      <th>00111-lstsq_target</th>\n",
       "      <th>00110-lstsq_target</th>\n",
       "      <th>00102-lstsq_target</th>\n",
       "      <th>00101-lstsq_target</th>\n",
       "      <th>00100-lstsq_target</th>\n",
       "      <th>00030-lstsq_target</th>\n",
       "      <th>00021-lstsq_target</th>\n",
       "      <th>00020-lstsq_target</th>\n",
       "      <th>00012-lstsq_target</th>\n",
       "      <th>00011-lstsq_target</th>\n",
       "      <th>00010-lstsq_target</th>\n",
       "      <th>00003-lstsq_target</th>\n",
       "      <th>00002-lstsq_target</th>\n",
       "      <th>00001-lstsq_target</th>\n",
       "      <th>00000-lstsq_target</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "      <th>wb_61</th>\n",
       "      <th>wb_62</th>\n",
       "      <th>wb_63</th>\n",
       "      <th>wb_64</th>\n",
       "      <th>wb_65</th>\n",
       "      <th>wb_66</th>\n",
       "      <th>wb_67</th>\n",
       "      <th>wb_68</th>\n",
       "      <th>wb_69</th>\n",
       "      <th>wb_70</th>\n",
       "      <th>wb_71</th>\n",
       "      <th>wb_72</th>\n",
       "      <th>wb_73</th>\n",
       "      <th>wb_74</th>\n",
       "      <th>wb_75</th>\n",
       "      <th>wb_76</th>\n",
       "      <th>wb_77</th>\n",
       "      <th>wb_78</th>\n",
       "      <th>wb_79</th>\n",
       "      <th>wb_80</th>\n",
       "      <th>wb_81</th>\n",
       "      <th>wb_82</th>\n",
       "      <th>wb_83</th>\n",
       "      <th>wb_84</th>\n",
       "      <th>wb_85</th>\n",
       "      <th>wb_86</th>\n",
       "      <th>wb_87</th>\n",
       "      <th>wb_88</th>\n",
       "      <th>wb_89</th>\n",
       "      <th>wb_90</th>\n",
       "      <th>wb_91</th>\n",
       "      <th>wb_92</th>\n",
       "      <th>wb_93</th>\n",
       "      <th>wb_94</th>\n",
       "      <th>wb_95</th>\n",
       "      <th>wb_96</th>\n",
       "      <th>wb_97</th>\n",
       "      <th>wb_98</th>\n",
       "      <th>wb_99</th>\n",
       "      <th>wb_100</th>\n",
       "      <th>wb_101</th>\n",
       "      <th>wb_102</th>\n",
       "      <th>wb_103</th>\n",
       "      <th>wb_104</th>\n",
       "      <th>wb_105</th>\n",
       "      <th>wb_106</th>\n",
       "      <th>wb_107</th>\n",
       "      <th>wb_108</th>\n",
       "      <th>wb_109</th>\n",
       "      <th>wb_110</th>\n",
       "      <th>wb_111</th>\n",
       "      <th>wb_112</th>\n",
       "      <th>wb_113</th>\n",
       "      <th>wb_114</th>\n",
       "      <th>wb_115</th>\n",
       "      <th>wb_116</th>\n",
       "      <th>wb_117</th>\n",
       "      <th>wb_118</th>\n",
       "      <th>wb_119</th>\n",
       "      <th>wb_120</th>\n",
       "      <th>wb_121</th>\n",
       "      <th>wb_122</th>\n",
       "      <th>wb_123</th>\n",
       "      <th>wb_124</th>\n",
       "      <th>wb_125</th>\n",
       "      <th>wb_126</th>\n",
       "      <th>wb_127</th>\n",
       "      <th>wb_128</th>\n",
       "      <th>wb_129</th>\n",
       "      <th>wb_130</th>\n",
       "      <th>wb_131</th>\n",
       "      <th>wb_132</th>\n",
       "      <th>wb_133</th>\n",
       "      <th>wb_134</th>\n",
       "      <th>wb_135</th>\n",
       "      <th>wb_136</th>\n",
       "      <th>wb_137</th>\n",
       "      <th>wb_138</th>\n",
       "      <th>wb_139</th>\n",
       "      <th>wb_140</th>\n",
       "      <th>wb_141</th>\n",
       "      <th>wb_142</th>\n",
       "      <th>wb_143</th>\n",
       "      <th>wb_144</th>\n",
       "      <th>wb_145</th>\n",
       "      <th>wb_146</th>\n",
       "      <th>wb_147</th>\n",
       "      <th>wb_148</th>\n",
       "      <th>wb_149</th>\n",
       "      <th>wb_150</th>\n",
       "      <th>wb_151</th>\n",
       "      <th>wb_152</th>\n",
       "      <th>wb_153</th>\n",
       "      <th>wb_154</th>\n",
       "      <th>wb_155</th>\n",
       "      <th>wb_156</th>\n",
       "      <th>wb_157</th>\n",
       "      <th>wb_158</th>\n",
       "      <th>wb_159</th>\n",
       "      <th>wb_160</th>\n",
       "      <th>wb_161</th>\n",
       "      <th>wb_162</th>\n",
       "      <th>wb_163</th>\n",
       "      <th>wb_164</th>\n",
       "      <th>wb_165</th>\n",
       "      <th>wb_166</th>\n",
       "      <th>wb_167</th>\n",
       "      <th>wb_168</th>\n",
       "      <th>wb_169</th>\n",
       "      <th>wb_170</th>\n",
       "      <th>wb_171</th>\n",
       "      <th>wb_172</th>\n",
       "      <th>wb_173</th>\n",
       "      <th>wb_174</th>\n",
       "      <th>wb_175</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.279</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.319</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.446</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.268</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-1.305</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.563</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.312</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.491</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.525</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.353</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.464</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.312</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.464</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.529</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.257</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.408</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.446</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.522</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.299</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>0.268</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.261</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.545</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.303</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.319</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.228</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.739</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.833</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>0.416</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.495</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.517</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.363</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.466</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.396</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.361</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.598</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.805</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.627</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.517</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>0.360</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          seed  30000-target  21000-target  20100-target  20010-target  \\\n",
       "86  1373158606         0.000         0.026         0.000         0.000   \n",
       "57  1373158606         0.000         0.000         0.000         0.000   \n",
       "64  1373158606         0.000         0.748         0.000         0.000   \n",
       "65  1373158606         0.000         0.000         0.000         0.000   \n",
       "14  1373158606         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    20001-target  20000-target  12000-target  11100-target  11010-target  \\\n",
       "86         0.000         0.000         0.000         0.000         0.000   \n",
       "57         0.000         0.000         0.000         0.000         0.000   \n",
       "64         0.000         0.000         0.000         0.000         0.000   \n",
       "65         0.586         0.000         0.000         0.000         0.000   \n",
       "14         0.000         0.000        -0.134         0.000         0.000   \n",
       "\n",
       "    11001-target  11000-target  10200-target  10110-target  10101-target  \\\n",
       "86         0.000         0.000         0.000         0.000         0.000   \n",
       "57         0.000         0.000         0.000         0.000         0.000   \n",
       "64         0.000         0.000         0.000         0.000         0.000   \n",
       "65         0.000         0.000         0.000         0.000         0.000   \n",
       "14         0.000        -0.463         0.000         0.000         0.000   \n",
       "\n",
       "    10100-target  10020-target  10011-target  10010-target  10002-target  \\\n",
       "86         0.000         0.000         0.000         0.000         0.000   \n",
       "57         0.000         0.000         0.000         0.000         0.000   \n",
       "64         0.000         0.000         0.000         0.000         0.000   \n",
       "65         0.000         0.000         0.000         0.000         0.000   \n",
       "14         0.000         0.711         0.000         0.000         0.000   \n",
       "\n",
       "    10001-target  10000-target  03000-target  02100-target  02010-target  \\\n",
       "86         0.000         0.000         0.000        -0.369         0.000   \n",
       "57         0.000        -0.624         0.000         0.000         0.000   \n",
       "64         0.081         0.000         0.000         0.000         0.000   \n",
       "65         0.000         0.000         0.000         0.000         0.000   \n",
       "14         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    02001-target  02000-target  01200-target  01110-target  01101-target  \\\n",
       "86         0.000         0.000         0.000         0.000         0.000   \n",
       "57         0.000         0.000         0.000         0.000         0.000   \n",
       "64         0.000         0.000         0.000         0.000         0.000   \n",
       "65         0.000         0.000         0.000         0.000         0.000   \n",
       "14         0.000         0.000         0.000         0.000         0.877   \n",
       "\n",
       "    01100-target  01020-target  01011-target  01010-target  01002-target  \\\n",
       "86         0.000         0.000         0.707         0.000         0.000   \n",
       "57         0.000         0.033         0.000         0.000         0.765   \n",
       "64         0.000         0.000         0.000         0.000         0.000   \n",
       "65         0.000         0.000         0.000         0.000         0.000   \n",
       "14         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    01001-target  01000-target  00300-target  00210-target  00201-target  \\\n",
       "86         0.000         0.000         0.000         0.000         0.000   \n",
       "57         0.000         0.000         0.000         0.000         0.000   \n",
       "64         0.000        -0.559         0.000         0.000        -0.270   \n",
       "65         0.000         0.000         0.405         0.000         0.489   \n",
       "14         0.000         0.000         0.000        -0.493         0.000   \n",
       "\n",
       "    00200-target  00120-target  00111-target  00110-target  00102-target  \\\n",
       "86         0.000         0.000         0.000         0.000         0.000   \n",
       "57         0.000         0.000         0.000         0.151         0.000   \n",
       "64         0.000         0.000         0.000         0.000         0.000   \n",
       "65         0.003         0.000         0.000         0.000         0.000   \n",
       "14         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    00101-target  00100-target  00030-target  00021-target  00020-target  \\\n",
       "86         0.000         0.000        -0.642         0.000         0.000   \n",
       "57         0.000         0.000         0.000         0.000         0.000   \n",
       "64         0.000         0.000         0.000         0.000         0.000   \n",
       "65         0.000         0.000         0.000         0.000         0.000   \n",
       "14         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    00012-target  00011-target  00010-target  00003-target  00002-target  \\\n",
       "86         0.000         0.000         0.000         0.000         0.136   \n",
       "57         0.000         0.000         0.000         0.000         0.000   \n",
       "64         0.000         0.000         0.000         0.000         0.000   \n",
       "65         0.000         0.000         0.483         0.000         0.000   \n",
       "14         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    00001-target  00000-target  30000-lstsq_lambda  21000-lstsq_lambda  \\\n",
       "86         0.000         0.000              -0.003               0.076   \n",
       "57         0.000        -0.114               0.015               0.025   \n",
       "64         0.635         0.000               0.130               0.623   \n",
       "65         0.000         0.000               0.031              -0.014   \n",
       "14         0.000         0.000              -0.046              -0.079   \n",
       "\n",
       "    20100-lstsq_lambda  20010-lstsq_lambda  20001-lstsq_lambda  \\\n",
       "86               0.016               0.026              -0.053   \n",
       "57               0.002               0.021               0.012   \n",
       "64               0.002               0.122              -0.033   \n",
       "65              -0.043              -0.027               0.545   \n",
       "14              -0.072              -0.106               0.036   \n",
       "\n",
       "    20000-lstsq_lambda  12000-lstsq_lambda  11100-lstsq_lambda  \\\n",
       "86              -0.011               0.039               0.013   \n",
       "57              -0.067               0.009               0.019   \n",
       "64              -0.230              -0.081              -0.003   \n",
       "65              -0.001              -0.014               0.004   \n",
       "14               0.147              -0.105               0.020   \n",
       "\n",
       "    11010-lstsq_lambda  11001-lstsq_lambda  11000-lstsq_lambda  \\\n",
       "86              -0.030               0.006              -0.096   \n",
       "57               0.025               0.026              -0.066   \n",
       "64              -0.071              -0.046               0.230   \n",
       "65               0.026              -0.030               0.028   \n",
       "14              -0.024               0.012              -0.379   \n",
       "\n",
       "    10200-lstsq_lambda  10110-lstsq_lambda  10101-lstsq_lambda  \\\n",
       "86              -0.007              -0.027               0.004   \n",
       "57              -0.010              -0.036              -0.014   \n",
       "64               0.003               0.004               0.013   \n",
       "65              -0.020              -0.015              -0.028   \n",
       "14               0.089              -0.001               0.033   \n",
       "\n",
       "    10100-lstsq_lambda  10020-lstsq_lambda  10011-lstsq_lambda  \\\n",
       "86              -0.005              -0.005              -0.047   \n",
       "57               0.024               0.019              -0.021   \n",
       "64              -0.024              -0.037              -0.005   \n",
       "65               0.083               0.030              -0.038   \n",
       "14              -0.034               0.514              -0.068   \n",
       "\n",
       "    10010-lstsq_lambda  10002-lstsq_lambda  10001-lstsq_lambda  \\\n",
       "86               0.023               0.021               0.036   \n",
       "57              -0.031               0.028              -0.029   \n",
       "64              -0.067              -0.004               0.136   \n",
       "65               0.011              -0.060               0.140   \n",
       "14               0.294              -0.055               0.067   \n",
       "\n",
       "    10000-lstsq_lambda  03000-lstsq_lambda  02100-lstsq_lambda  \\\n",
       "86               0.021               0.064              -0.230   \n",
       "57              -0.563               0.013              -0.014   \n",
       "64               0.096               0.036              -0.005   \n",
       "65              -0.056               0.005              -0.001   \n",
       "14              -0.150              -0.096              -0.001   \n",
       "\n",
       "    02010-lstsq_lambda  02001-lstsq_lambda  02000-lstsq_lambda  \\\n",
       "86              -0.037              -0.010              -0.144   \n",
       "57              -0.014              -0.005              -0.018   \n",
       "64               0.075               0.040              -0.070   \n",
       "65              -0.031               0.015               0.006   \n",
       "14               0.038              -0.039               0.112   \n",
       "\n",
       "    01200-lstsq_lambda  01110-lstsq_lambda  01101-lstsq_lambda  \\\n",
       "86               0.044              -0.050               0.005   \n",
       "57              -0.016              -0.001               0.018   \n",
       "64               0.077              -0.073               0.026   \n",
       "65               0.005               0.015               0.012   \n",
       "14              -0.060               0.058               0.520   \n",
       "\n",
       "    01100-lstsq_lambda  01020-lstsq_lambda  01011-lstsq_lambda  \\\n",
       "86              -0.158              -0.007               0.517   \n",
       "57               0.019               0.004               0.011   \n",
       "64              -0.053              -0.061               0.082   \n",
       "65              -0.015               0.003              -0.060   \n",
       "14               0.140               0.033              -0.104   \n",
       "\n",
       "    01010-lstsq_lambda  01002-lstsq_lambda  01001-lstsq_lambda  \\\n",
       "86               0.167               0.019               0.063   \n",
       "57               0.011               0.644               0.075   \n",
       "64               0.009               0.066              -0.124   \n",
       "65               0.039               0.007               0.014   \n",
       "14              -0.026              -0.107               0.328   \n",
       "\n",
       "    01000-lstsq_lambda  00300-lstsq_lambda  00210-lstsq_lambda  \\\n",
       "86               0.066              -0.030               0.100   \n",
       "57               0.022              -0.038              -0.002   \n",
       "64              -0.537              -0.062              -0.086   \n",
       "65              -0.014               0.303              -0.001   \n",
       "14              -0.133               0.041              -0.353   \n",
       "\n",
       "    00201-lstsq_lambda  00200-lstsq_lambda  00120-lstsq_lambda  \\\n",
       "86              -0.025              -0.003               0.015   \n",
       "57              -0.034               0.073               0.008   \n",
       "64              -0.134               0.008               0.040   \n",
       "65               0.383               0.202              -0.019   \n",
       "14              -0.144              -0.080               0.073   \n",
       "\n",
       "    00111-lstsq_lambda  00110-lstsq_lambda  00102-lstsq_lambda  \\\n",
       "86              -0.088              -0.020               0.096   \n",
       "57               0.019               0.142              -0.027   \n",
       "64               0.041               0.054              -0.107   \n",
       "65              -0.036               0.058              -0.008   \n",
       "14               0.103              -0.281              -0.136   \n",
       "\n",
       "    00101-lstsq_lambda  00100-lstsq_lambda  00030-lstsq_lambda  \\\n",
       "86              -0.042               0.040              -0.600   \n",
       "57               0.060              -0.042              -0.014   \n",
       "64              -0.031               0.028              -0.000   \n",
       "65               0.122              -0.137              -0.014   \n",
       "14               0.347               0.014               0.067   \n",
       "\n",
       "    00021-lstsq_lambda  00020-lstsq_lambda  00012-lstsq_lambda  \\\n",
       "86               0.037              -0.068              -0.023   \n",
       "57              -0.004              -0.007              -0.037   \n",
       "64               0.029               0.000              -0.097   \n",
       "65              -0.032               0.028              -0.009   \n",
       "14               0.017              -0.100               0.039   \n",
       "\n",
       "    00011-lstsq_lambda  00010-lstsq_lambda  00003-lstsq_lambda  \\\n",
       "86               0.147              -0.056              -0.039   \n",
       "57               0.041               0.027               0.021   \n",
       "64               0.024               0.003              -0.014   \n",
       "65               0.101               0.421               0.022   \n",
       "14               0.002               0.055               0.002   \n",
       "\n",
       "    00002-lstsq_lambda  00001-lstsq_lambda  00000-lstsq_lambda  \\\n",
       "86               0.138              -0.030              -0.006   \n",
       "57               0.033              -0.042              -0.130   \n",
       "64               0.076               0.593              -0.013   \n",
       "65              -0.002              -0.074               0.041   \n",
       "14               0.097              -0.200               0.049   \n",
       "\n",
       "    30000-lstsq_target  21000-lstsq_target  20100-lstsq_target  \\\n",
       "86              -0.000               0.026              -0.000   \n",
       "57              -0.000              -0.000              -0.000   \n",
       "64               0.000               0.748              -0.000   \n",
       "65              -0.000               0.000               0.000   \n",
       "14              -0.000              -0.000               0.000   \n",
       "\n",
       "    20010-lstsq_target  20001-lstsq_target  20000-lstsq_target  \\\n",
       "86               0.000              -0.000               0.000   \n",
       "57               0.000               0.000               0.000   \n",
       "64              -0.000               0.000              -0.000   \n",
       "65               0.000               0.586               0.000   \n",
       "14               0.000               0.000              -0.000   \n",
       "\n",
       "    12000-lstsq_target  11100-lstsq_target  11010-lstsq_target  \\\n",
       "86               0.000              -0.000              -0.000   \n",
       "57              -0.000              -0.000               0.000   \n",
       "64              -0.000              -0.000              -0.000   \n",
       "65               0.000              -0.000              -0.000   \n",
       "14              -0.134              -0.000               0.000   \n",
       "\n",
       "    11001-lstsq_target  11000-lstsq_target  10200-lstsq_target  \\\n",
       "86              -0.000              -0.000              -0.000   \n",
       "57              -0.000               0.000               0.000   \n",
       "64               0.000               0.000               0.000   \n",
       "65               0.000              -0.000              -0.000   \n",
       "14               0.000              -0.463               0.000   \n",
       "\n",
       "    10110-lstsq_target  10101-lstsq_target  10100-lstsq_target  \\\n",
       "86               0.000               0.000               0.000   \n",
       "57              -0.000              -0.000               0.000   \n",
       "64              -0.000              -0.000               0.000   \n",
       "65              -0.000               0.000               0.000   \n",
       "14               0.000               0.000              -0.000   \n",
       "\n",
       "    10020-lstsq_target  10011-lstsq_target  10010-lstsq_target  \\\n",
       "86              -0.000               0.000              -0.000   \n",
       "57               0.000              -0.000              -0.000   \n",
       "64               0.000              -0.000               0.000   \n",
       "65              -0.000              -0.000               0.000   \n",
       "14               0.711               0.000              -0.000   \n",
       "\n",
       "    10002-lstsq_target  10001-lstsq_target  10000-lstsq_target  \\\n",
       "86              -0.000               0.000              -0.000   \n",
       "57               0.000               0.000              -0.624   \n",
       "64               0.000               0.081              -0.000   \n",
       "65              -0.000               0.000              -0.000   \n",
       "14               0.000              -0.000               0.000   \n",
       "\n",
       "    03000-lstsq_target  02100-lstsq_target  02010-lstsq_target  \\\n",
       "86              -0.000              -0.369               0.000   \n",
       "57              -0.000               0.000              -0.000   \n",
       "64              -0.000              -0.000              -0.000   \n",
       "65              -0.000               0.000              -0.000   \n",
       "14              -0.000              -0.000               0.000   \n",
       "\n",
       "    02001-lstsq_target  02000-lstsq_target  01200-lstsq_target  \\\n",
       "86               0.000               0.000              -0.000   \n",
       "57              -0.000               0.000              -0.000   \n",
       "64              -0.000               0.000              -0.000   \n",
       "65               0.000               0.000               0.000   \n",
       "14              -0.000               0.000               0.000   \n",
       "\n",
       "    01110-lstsq_target  01101-lstsq_target  01100-lstsq_target  \\\n",
       "86               0.000               0.000              -0.000   \n",
       "57               0.000               0.000               0.000   \n",
       "64              -0.000              -0.000               0.000   \n",
       "65               0.000               0.000              -0.000   \n",
       "14              -0.000               0.877               0.000   \n",
       "\n",
       "    01020-lstsq_target  01011-lstsq_target  01010-lstsq_target  \\\n",
       "86              -0.000               0.707              -0.000   \n",
       "57               0.033              -0.000               0.000   \n",
       "64              -0.000               0.000               0.000   \n",
       "65              -0.000               0.000               0.000   \n",
       "14               0.000               0.000              -0.000   \n",
       "\n",
       "    01002-lstsq_target  01001-lstsq_target  01000-lstsq_target  \\\n",
       "86              -0.000              -0.000               0.000   \n",
       "57               0.765               0.000              -0.000   \n",
       "64              -0.000               0.000              -0.559   \n",
       "65               0.000              -0.000               0.000   \n",
       "14              -0.000               0.000              -0.000   \n",
       "\n",
       "    00300-lstsq_target  00210-lstsq_target  00201-lstsq_target  \\\n",
       "86              -0.000              -0.000               0.000   \n",
       "57               0.000              -0.000              -0.000   \n",
       "64               0.000               0.000              -0.270   \n",
       "65               0.405               0.000               0.489   \n",
       "14               0.000              -0.493               0.000   \n",
       "\n",
       "    00200-lstsq_target  00120-lstsq_target  00111-lstsq_target  \\\n",
       "86               0.000               0.000              -0.000   \n",
       "57              -0.000              -0.000               0.000   \n",
       "64              -0.000              -0.000              -0.000   \n",
       "65               0.003              -0.000               0.000   \n",
       "14              -0.000               0.000              -0.000   \n",
       "\n",
       "    00110-lstsq_target  00102-lstsq_target  00101-lstsq_target  \\\n",
       "86              -0.000               0.000              -0.000   \n",
       "57               0.151              -0.000               0.000   \n",
       "64               0.000               0.000               0.000   \n",
       "65              -0.000              -0.000              -0.000   \n",
       "14              -0.000              -0.000               0.000   \n",
       "\n",
       "    00100-lstsq_target  00030-lstsq_target  00021-lstsq_target  \\\n",
       "86               0.000              -0.642               0.000   \n",
       "57              -0.000              -0.000              -0.000   \n",
       "64              -0.000              -0.000               0.000   \n",
       "65               0.000              -0.000               0.000   \n",
       "14               0.000               0.000               0.000   \n",
       "\n",
       "    00020-lstsq_target  00012-lstsq_target  00011-lstsq_target  \\\n",
       "86              -0.000              -0.000              -0.000   \n",
       "57               0.000              -0.000               0.000   \n",
       "64               0.000               0.000              -0.000   \n",
       "65               0.000               0.000              -0.000   \n",
       "14              -0.000               0.000              -0.000   \n",
       "\n",
       "    00010-lstsq_target  00003-lstsq_target  00002-lstsq_target  \\\n",
       "86               0.000              -0.000               0.136   \n",
       "57              -0.000              -0.000               0.000   \n",
       "64              -0.000              -0.000               0.000   \n",
       "65               0.483              -0.000               0.000   \n",
       "14               0.000               0.000              -0.000   \n",
       "\n",
       "    00001-lstsq_target  00000-lstsq_target   wb_0   wb_1  wb_2   wb_3  wb_4  \\\n",
       "86               0.000              -0.000  0.004 -0.053 0.036  0.045 0.304   \n",
       "57              -0.000              -0.114 -0.033 -0.062 0.422  0.309 0.199   \n",
       "64               0.635               0.000 -0.067 -0.178 0.378  0.169 0.290   \n",
       "65               0.000               0.000 -0.077 -0.259 0.394  0.096 0.304   \n",
       "14               0.000              -0.000 -0.342 -0.247 0.250 -0.006 0.242   \n",
       "\n",
       "    wb_5  wb_6   wb_7  wb_8   wb_9  wb_10  wb_11  wb_12  wb_13  wb_14  wb_15  \\\n",
       "86 0.162 0.279 -0.404 0.084  0.033  0.200  0.020  0.011  0.337  0.100  0.422   \n",
       "57 0.091 0.312 -0.418 0.205  0.420  0.536 -0.117 -0.000  0.380  0.089  0.491   \n",
       "64 0.190 0.257 -0.362 0.151  0.116  0.431 -0.201  0.002  0.300  0.192  0.409   \n",
       "65 0.209 0.197 -0.155 0.067 -0.002  0.398 -0.205 -0.143  0.340  0.230  0.432   \n",
       "14 0.131 0.306 -0.041 0.214  0.381  0.517 -0.196  0.158  0.369  0.113  0.260   \n",
       "\n",
       "    wb_16  wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  wb_24  wb_25  \\\n",
       "86  0.086  0.267  0.158  0.171  0.110  0.033 -0.016  0.049 -0.492 -0.072   \n",
       "57 -0.000  0.200  0.006  0.021 -0.026  0.070  0.021  0.048  0.002 -0.149   \n",
       "64  0.291  0.301  0.348  0.600  0.103 -0.044 -0.213  0.014 -0.493 -0.133   \n",
       "65  0.115  0.316  0.460  0.536  0.148 -0.042  0.013 -0.008 -0.296 -0.153   \n",
       "14 -0.078  0.240  0.297  0.151 -0.097 -0.016  0.338  0.069 -0.236 -0.252   \n",
       "\n",
       "    wb_26  wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  wb_34  wb_35  \\\n",
       "86  0.205 -0.384 -0.352 -0.071  0.261  0.360  0.032  0.317 -0.189 -0.262   \n",
       "57 -0.013 -0.134 -0.096  0.023  0.375  0.258  0.061  0.210  0.011 -0.145   \n",
       "64  0.163 -0.388 -0.162 -0.113  0.202  0.444  0.142  0.378 -0.007 -0.380   \n",
       "65 -0.074 -0.025 -0.320 -0.078  0.290  0.304  0.111  0.319 -0.002  0.041   \n",
       "14 -0.051  0.097 -0.313 -0.032  0.315  0.331  0.151  0.363 -0.290 -0.085   \n",
       "\n",
       "    wb_36  wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  wb_44  wb_45  \\\n",
       "86 -0.212  0.152 -0.080 -0.380  0.215  0.321  0.406 -0.243  0.263  0.263   \n",
       "57 -0.445 -0.074 -0.156 -0.126  0.092  0.237  0.525 -0.187  0.269  0.093   \n",
       "64 -0.217  0.035 -0.395 -0.274  0.250  0.206  0.345 -0.252  0.356  0.165   \n",
       "65 -0.410  0.090 -0.004 -0.185  0.006  0.006  0.438 -0.001  0.007  0.004   \n",
       "14 -0.242  0.071 -0.055 -0.240  0.365  0.161  0.466 -0.407  0.438  0.080   \n",
       "\n",
       "    wb_46  wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  wb_54  wb_55  \\\n",
       "86 -0.322  0.407  0.319 -0.493  0.022  0.132 -0.142 -0.073 -0.272  0.418   \n",
       "57 -0.269  0.486  0.240 -0.437 -0.111  0.112 -0.115 -0.016 -0.175  0.498   \n",
       "64 -0.038  0.497  0.408 -0.494 -0.113  0.217 -0.169 -0.219 -0.294  0.422   \n",
       "65 -0.011  0.344  0.327 -0.530 -0.099 -0.028 -0.332 -0.147 -0.001  0.693   \n",
       "14 -0.075  0.368  0.300 -0.568 -0.065  0.012 -0.355 -0.189 -0.120  0.464   \n",
       "\n",
       "    wb_56  wb_57  wb_58  wb_59  wb_60  wb_61  wb_62  wb_63  wb_64  wb_65  \\\n",
       "86  0.462 -0.525  0.019  0.058  0.167  0.290  0.043  0.191  0.207  0.030   \n",
       "57  0.353 -0.523  0.006 -0.097  0.258  0.197  0.320  0.160  0.367 -0.044   \n",
       "64  0.446 -0.530  0.041 -0.522 -0.081  0.413  0.353  0.147  0.304  0.043   \n",
       "65  0.203 -0.359 -0.066 -0.775  0.086  0.171  0.046  0.004  0.577  0.003   \n",
       "14  0.396 -0.559 -0.024 -0.280  0.303  0.509  0.348  0.191  0.332 -0.175   \n",
       "\n",
       "    wb_66  wb_67  wb_68  wb_69  wb_70  wb_71  wb_72  wb_73  wb_74  wb_75  \\\n",
       "86 -0.289  0.379  0.156 -0.351  0.338 -0.309  0.212  0.446 -0.080  0.544   \n",
       "57  0.035  0.464 -0.048 -0.298  0.366 -0.292 -0.004  0.342  0.004  0.161   \n",
       "64 -0.205  0.388  0.090  0.018  0.357 -0.539 -0.231  0.435 -0.092  0.170   \n",
       "65 -0.562  0.673  0.001 -0.000  0.681 -0.387 -0.130  0.203 -0.034  0.144   \n",
       "14 -0.284  0.431 -0.191 -0.298  0.414 -0.495 -0.025  0.389  0.318  0.205   \n",
       "\n",
       "    wb_76  wb_77  wb_78  wb_79  wb_80  wb_81  wb_82  wb_83  wb_84  wb_85  \\\n",
       "86  0.297 -0.249  0.609  0.376 -0.111  0.156  0.034 -0.104  0.002  0.077   \n",
       "57  0.270 -0.119  0.355  0.566  0.027  0.059  0.063 -0.082  0.195 -0.029   \n",
       "64  0.299 -0.069  0.245  0.514 -0.033  0.129  0.042 -0.027  0.121 -0.059   \n",
       "65  0.208 -0.238  0.206  0.531  0.061  0.038  0.056 -0.024  0.009  0.010   \n",
       "14  0.361 -0.348  0.255  0.598 -0.056  0.153  0.174 -0.102  0.336 -0.063   \n",
       "\n",
       "    wb_86  wb_87  wb_88  wb_89  wb_90  wb_91  wb_92  wb_93  wb_94  wb_95  \\\n",
       "86  0.480 -0.632  0.024  0.253  0.179 -0.061 -0.233 -0.024 -0.157 -0.386   \n",
       "57  0.098 -0.312 -0.082  0.372  0.076  0.039 -0.075 -0.073 -0.255 -0.415   \n",
       "64  0.280 -0.242 -0.004  0.321  0.167 -0.108 -0.133  0.078  0.031 -0.491   \n",
       "65  0.101 -0.490  0.017  0.407  0.008 -0.021 -0.062  0.006  0.003 -0.023   \n",
       "14  0.277 -0.253 -0.054  0.277  0.075 -0.179 -0.163  0.091  0.006 -0.805   \n",
       "\n",
       "    wb_96  wb_97  wb_98  wb_99  wb_100  wb_101  wb_102  wb_103  wb_104  \\\n",
       "86  0.199 -0.504  0.393 -0.335  -0.088  -0.082   0.268  -0.165   0.263   \n",
       "57  0.251 -0.134  0.252  0.013  -0.373   0.022   0.176  -0.136   0.206   \n",
       "64  0.005 -0.265  0.324 -0.344  -0.381   0.055  -0.112  -0.546   0.268   \n",
       "65  0.110 -0.412  0.252 -0.343  -0.376  -0.047   0.108  -0.519   0.268   \n",
       "14 -0.037 -0.315  0.345  0.082  -0.285  -0.000   0.127  -0.528   0.072   \n",
       "\n",
       "    wb_105  wb_106  wb_107  wb_108  wb_109  wb_110  wb_111  wb_112  wb_113  \\\n",
       "86  -0.041  -0.215   0.161  -0.195  -0.614  -0.874  -0.249   0.138  -0.035   \n",
       "57  -0.058  -0.305   0.161  -0.114  -0.212  -0.182  -0.441   0.098  -0.001   \n",
       "64  -0.014  -0.270   0.147  -0.046  -0.384  -0.274  -0.168   0.167   0.049   \n",
       "65   0.002  -0.334   0.385  -0.093  -0.209  -0.609  -0.527  -0.042  -0.189   \n",
       "14  -0.001  -0.230   0.297  -0.228  -0.627  -0.242  -0.250   0.040  -0.085   \n",
       "\n",
       "    wb_114  wb_115  wb_116  wb_117  wb_118  wb_119  wb_120  wb_121  wb_122  \\\n",
       "86   0.274  -0.119   0.153   0.457  -0.109   0.334   0.245   0.193  -0.219   \n",
       "57   0.312  -0.191   0.407   0.464  -0.460   0.449   0.303   0.152  -0.379   \n",
       "64   0.368  -0.209   0.229   0.507   0.122  -0.090   0.134   0.261  -0.092   \n",
       "65   0.375  -0.306  -0.083   0.517   0.221   0.234   0.223   0.326   0.199   \n",
       "14   0.365  -0.310  -0.230   0.517  -0.059   0.317  -0.105   0.330  -0.248   \n",
       "\n",
       "    wb_123  wb_124  wb_125  wb_126  wb_127  wb_128  wb_129  wb_130  wb_131  \\\n",
       "86  -0.149   0.277  -0.345  -0.183   0.333   0.149   0.126   0.116  -0.019   \n",
       "57  -0.223   0.529  -0.090   0.036   0.253   0.161   0.040  -0.023   0.061   \n",
       "64  -0.195   0.269  -0.075  -0.020   0.108   0.035   0.116   0.063   0.023   \n",
       "65  -0.191   0.281  -0.100  -0.147   0.483  -0.170  -0.129  -0.104   0.009   \n",
       "14  -0.175   0.374  -0.036  -0.136   0.238  -0.145  -0.489   0.072   0.037   \n",
       "\n",
       "    wb_132  wb_133  wb_134  wb_135  wb_136  wb_137  wb_138  wb_139  wb_140  \\\n",
       "86  -0.166   0.014   0.443   0.127  -0.038   0.143  -0.007  -0.015   0.013   \n",
       "57  -0.181   0.108   0.191   0.217  -0.174  -0.014   0.145  -0.008   0.140   \n",
       "64  -0.186   0.023   0.427  -0.153  -0.026  -0.016  -0.148   0.089   0.088   \n",
       "65   0.047   0.125   0.682   0.093  -0.187   0.028  -0.241  -0.094  -0.175   \n",
       "14  -0.150  -0.242   0.238   0.173   0.032   0.052   0.087   0.037   0.100   \n",
       "\n",
       "    wb_141  wb_142  wb_143  wb_144  wb_145  wb_146  wb_147  wb_148  wb_149  \\\n",
       "86  -0.211   0.107   0.110  -0.006   0.049   0.125   0.223  -0.020  -0.143   \n",
       "57  -0.463  -0.011   0.316  -0.126  -0.157   0.037  -0.044   0.038  -0.213   \n",
       "64  -0.233   0.065   0.042  -0.534  -0.001  -0.136   0.025   0.006  -0.149   \n",
       "65   0.228  -0.128  -0.468  -0.337  -0.473   0.220   0.131   0.109  -0.102   \n",
       "14   0.185   0.074   0.127  -0.097   0.062   0.259   0.023   0.007  -0.086   \n",
       "\n",
       "    wb_150  wb_151  wb_152  wb_153  wb_154  wb_155  wb_156  wb_157  wb_158  \\\n",
       "86  -1.305  -0.323  -0.427  -0.521   0.208   0.267  -0.146  -0.284  -0.307   \n",
       "57  -0.220  -0.227  -0.399  -0.210   0.236   0.310  -0.096  -0.315  -0.334   \n",
       "64  -0.223  -0.302  -0.252  -0.057   0.365   0.238  -0.178  -0.283  -0.372   \n",
       "65  -0.209  -0.228  -0.739  -0.145   0.331   0.444  -0.009  -0.060  -0.320   \n",
       "14  -0.485  -0.373  -0.394  -0.201   0.809   0.291  -0.113  -0.335  -0.740   \n",
       "\n",
       "    wb_159  wb_160  wb_161  wb_162  wb_163  wb_164  wb_165  wb_166  wb_167  \\\n",
       "86   0.286   0.157  -0.280  -0.489  -0.168   0.223  -0.205   0.437   0.144   \n",
       "57  -0.073  -0.256  -0.218  -0.277  -0.265   0.240  -0.321   1.167   0.159   \n",
       "64  -0.333  -0.106  -0.166  -0.295  -0.341   0.294  -0.247   0.589   0.139   \n",
       "65   0.833  -0.134  -0.246  -0.137  -0.476   0.416  -0.316   0.521   0.252   \n",
       "14   0.360  -0.185  -0.383  -0.316  -0.215   0.262  -0.262   0.444   0.176   \n",
       "\n",
       "    wb_168  wb_169  wb_170  wb_171  wb_172  wb_173  wb_174  wb_175  \n",
       "86   0.217   0.197   0.126  -0.188  -0.254  -0.274  -0.306   0.114  \n",
       "57   0.611   0.253   0.101  -0.091  -0.145  -0.149  -0.438  -0.003  \n",
       "64   0.352   0.847   0.132  -0.252  -0.129  -0.287  -0.317   0.069  \n",
       "65   0.853   0.475   0.495  -0.268  -0.021  -0.123   0.021  -0.082  \n",
       "14   0.488   0.254   0.378  -0.407  -0.158  -0.225  -0.378   0.078  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_train_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:26.918185Z",
     "iopub.status.busy": "2022-01-17T12:42:26.917661Z",
     "iopub.status.idle": "2022-01-17T12:42:27.195049Z",
     "shell.execute_reply": "2022-01-17T12:42:27.193630Z",
     "shell.execute_reply.started": "2022-01-17T12:42:26.918141Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>30000-target</th>\n",
       "      <th>21000-target</th>\n",
       "      <th>20100-target</th>\n",
       "      <th>20010-target</th>\n",
       "      <th>20001-target</th>\n",
       "      <th>20000-target</th>\n",
       "      <th>12000-target</th>\n",
       "      <th>11100-target</th>\n",
       "      <th>11010-target</th>\n",
       "      <th>11001-target</th>\n",
       "      <th>11000-target</th>\n",
       "      <th>10200-target</th>\n",
       "      <th>10110-target</th>\n",
       "      <th>10101-target</th>\n",
       "      <th>10100-target</th>\n",
       "      <th>10020-target</th>\n",
       "      <th>10011-target</th>\n",
       "      <th>10010-target</th>\n",
       "      <th>10002-target</th>\n",
       "      <th>10001-target</th>\n",
       "      <th>10000-target</th>\n",
       "      <th>03000-target</th>\n",
       "      <th>02100-target</th>\n",
       "      <th>02010-target</th>\n",
       "      <th>02001-target</th>\n",
       "      <th>02000-target</th>\n",
       "      <th>01200-target</th>\n",
       "      <th>01110-target</th>\n",
       "      <th>01101-target</th>\n",
       "      <th>01100-target</th>\n",
       "      <th>01020-target</th>\n",
       "      <th>01011-target</th>\n",
       "      <th>01010-target</th>\n",
       "      <th>01002-target</th>\n",
       "      <th>01001-target</th>\n",
       "      <th>01000-target</th>\n",
       "      <th>00300-target</th>\n",
       "      <th>00210-target</th>\n",
       "      <th>00201-target</th>\n",
       "      <th>00200-target</th>\n",
       "      <th>00120-target</th>\n",
       "      <th>00111-target</th>\n",
       "      <th>00110-target</th>\n",
       "      <th>00102-target</th>\n",
       "      <th>00101-target</th>\n",
       "      <th>00100-target</th>\n",
       "      <th>00030-target</th>\n",
       "      <th>00021-target</th>\n",
       "      <th>00020-target</th>\n",
       "      <th>00012-target</th>\n",
       "      <th>00011-target</th>\n",
       "      <th>00010-target</th>\n",
       "      <th>00003-target</th>\n",
       "      <th>00002-target</th>\n",
       "      <th>00001-target</th>\n",
       "      <th>00000-target</th>\n",
       "      <th>30000-lstsq_lambda</th>\n",
       "      <th>21000-lstsq_lambda</th>\n",
       "      <th>20100-lstsq_lambda</th>\n",
       "      <th>20010-lstsq_lambda</th>\n",
       "      <th>20001-lstsq_lambda</th>\n",
       "      <th>20000-lstsq_lambda</th>\n",
       "      <th>12000-lstsq_lambda</th>\n",
       "      <th>11100-lstsq_lambda</th>\n",
       "      <th>11010-lstsq_lambda</th>\n",
       "      <th>11001-lstsq_lambda</th>\n",
       "      <th>11000-lstsq_lambda</th>\n",
       "      <th>10200-lstsq_lambda</th>\n",
       "      <th>10110-lstsq_lambda</th>\n",
       "      <th>10101-lstsq_lambda</th>\n",
       "      <th>10100-lstsq_lambda</th>\n",
       "      <th>10020-lstsq_lambda</th>\n",
       "      <th>10011-lstsq_lambda</th>\n",
       "      <th>10010-lstsq_lambda</th>\n",
       "      <th>10002-lstsq_lambda</th>\n",
       "      <th>10001-lstsq_lambda</th>\n",
       "      <th>10000-lstsq_lambda</th>\n",
       "      <th>03000-lstsq_lambda</th>\n",
       "      <th>02100-lstsq_lambda</th>\n",
       "      <th>02010-lstsq_lambda</th>\n",
       "      <th>02001-lstsq_lambda</th>\n",
       "      <th>02000-lstsq_lambda</th>\n",
       "      <th>01200-lstsq_lambda</th>\n",
       "      <th>01110-lstsq_lambda</th>\n",
       "      <th>01101-lstsq_lambda</th>\n",
       "      <th>01100-lstsq_lambda</th>\n",
       "      <th>01020-lstsq_lambda</th>\n",
       "      <th>01011-lstsq_lambda</th>\n",
       "      <th>01010-lstsq_lambda</th>\n",
       "      <th>01002-lstsq_lambda</th>\n",
       "      <th>01001-lstsq_lambda</th>\n",
       "      <th>01000-lstsq_lambda</th>\n",
       "      <th>00300-lstsq_lambda</th>\n",
       "      <th>00210-lstsq_lambda</th>\n",
       "      <th>00201-lstsq_lambda</th>\n",
       "      <th>00200-lstsq_lambda</th>\n",
       "      <th>00120-lstsq_lambda</th>\n",
       "      <th>00111-lstsq_lambda</th>\n",
       "      <th>00110-lstsq_lambda</th>\n",
       "      <th>00102-lstsq_lambda</th>\n",
       "      <th>00101-lstsq_lambda</th>\n",
       "      <th>00100-lstsq_lambda</th>\n",
       "      <th>00030-lstsq_lambda</th>\n",
       "      <th>00021-lstsq_lambda</th>\n",
       "      <th>00020-lstsq_lambda</th>\n",
       "      <th>00012-lstsq_lambda</th>\n",
       "      <th>00011-lstsq_lambda</th>\n",
       "      <th>00010-lstsq_lambda</th>\n",
       "      <th>00003-lstsq_lambda</th>\n",
       "      <th>00002-lstsq_lambda</th>\n",
       "      <th>00001-lstsq_lambda</th>\n",
       "      <th>00000-lstsq_lambda</th>\n",
       "      <th>30000-lstsq_target</th>\n",
       "      <th>21000-lstsq_target</th>\n",
       "      <th>20100-lstsq_target</th>\n",
       "      <th>20010-lstsq_target</th>\n",
       "      <th>20001-lstsq_target</th>\n",
       "      <th>20000-lstsq_target</th>\n",
       "      <th>12000-lstsq_target</th>\n",
       "      <th>11100-lstsq_target</th>\n",
       "      <th>11010-lstsq_target</th>\n",
       "      <th>11001-lstsq_target</th>\n",
       "      <th>11000-lstsq_target</th>\n",
       "      <th>10200-lstsq_target</th>\n",
       "      <th>10110-lstsq_target</th>\n",
       "      <th>10101-lstsq_target</th>\n",
       "      <th>10100-lstsq_target</th>\n",
       "      <th>10020-lstsq_target</th>\n",
       "      <th>10011-lstsq_target</th>\n",
       "      <th>10010-lstsq_target</th>\n",
       "      <th>10002-lstsq_target</th>\n",
       "      <th>10001-lstsq_target</th>\n",
       "      <th>10000-lstsq_target</th>\n",
       "      <th>03000-lstsq_target</th>\n",
       "      <th>02100-lstsq_target</th>\n",
       "      <th>02010-lstsq_target</th>\n",
       "      <th>02001-lstsq_target</th>\n",
       "      <th>02000-lstsq_target</th>\n",
       "      <th>01200-lstsq_target</th>\n",
       "      <th>01110-lstsq_target</th>\n",
       "      <th>01101-lstsq_target</th>\n",
       "      <th>01100-lstsq_target</th>\n",
       "      <th>01020-lstsq_target</th>\n",
       "      <th>01011-lstsq_target</th>\n",
       "      <th>01010-lstsq_target</th>\n",
       "      <th>01002-lstsq_target</th>\n",
       "      <th>01001-lstsq_target</th>\n",
       "      <th>01000-lstsq_target</th>\n",
       "      <th>00300-lstsq_target</th>\n",
       "      <th>00210-lstsq_target</th>\n",
       "      <th>00201-lstsq_target</th>\n",
       "      <th>00200-lstsq_target</th>\n",
       "      <th>00120-lstsq_target</th>\n",
       "      <th>00111-lstsq_target</th>\n",
       "      <th>00110-lstsq_target</th>\n",
       "      <th>00102-lstsq_target</th>\n",
       "      <th>00101-lstsq_target</th>\n",
       "      <th>00100-lstsq_target</th>\n",
       "      <th>00030-lstsq_target</th>\n",
       "      <th>00021-lstsq_target</th>\n",
       "      <th>00020-lstsq_target</th>\n",
       "      <th>00012-lstsq_target</th>\n",
       "      <th>00011-lstsq_target</th>\n",
       "      <th>00010-lstsq_target</th>\n",
       "      <th>00003-lstsq_target</th>\n",
       "      <th>00002-lstsq_target</th>\n",
       "      <th>00001-lstsq_target</th>\n",
       "      <th>00000-lstsq_target</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "      <th>wb_61</th>\n",
       "      <th>wb_62</th>\n",
       "      <th>wb_63</th>\n",
       "      <th>wb_64</th>\n",
       "      <th>wb_65</th>\n",
       "      <th>wb_66</th>\n",
       "      <th>wb_67</th>\n",
       "      <th>wb_68</th>\n",
       "      <th>wb_69</th>\n",
       "      <th>wb_70</th>\n",
       "      <th>wb_71</th>\n",
       "      <th>wb_72</th>\n",
       "      <th>wb_73</th>\n",
       "      <th>wb_74</th>\n",
       "      <th>wb_75</th>\n",
       "      <th>wb_76</th>\n",
       "      <th>wb_77</th>\n",
       "      <th>wb_78</th>\n",
       "      <th>wb_79</th>\n",
       "      <th>wb_80</th>\n",
       "      <th>wb_81</th>\n",
       "      <th>wb_82</th>\n",
       "      <th>wb_83</th>\n",
       "      <th>wb_84</th>\n",
       "      <th>wb_85</th>\n",
       "      <th>wb_86</th>\n",
       "      <th>wb_87</th>\n",
       "      <th>wb_88</th>\n",
       "      <th>wb_89</th>\n",
       "      <th>wb_90</th>\n",
       "      <th>wb_91</th>\n",
       "      <th>wb_92</th>\n",
       "      <th>wb_93</th>\n",
       "      <th>wb_94</th>\n",
       "      <th>wb_95</th>\n",
       "      <th>wb_96</th>\n",
       "      <th>wb_97</th>\n",
       "      <th>wb_98</th>\n",
       "      <th>wb_99</th>\n",
       "      <th>wb_100</th>\n",
       "      <th>wb_101</th>\n",
       "      <th>wb_102</th>\n",
       "      <th>wb_103</th>\n",
       "      <th>wb_104</th>\n",
       "      <th>wb_105</th>\n",
       "      <th>wb_106</th>\n",
       "      <th>wb_107</th>\n",
       "      <th>wb_108</th>\n",
       "      <th>wb_109</th>\n",
       "      <th>wb_110</th>\n",
       "      <th>wb_111</th>\n",
       "      <th>wb_112</th>\n",
       "      <th>wb_113</th>\n",
       "      <th>wb_114</th>\n",
       "      <th>wb_115</th>\n",
       "      <th>wb_116</th>\n",
       "      <th>wb_117</th>\n",
       "      <th>wb_118</th>\n",
       "      <th>wb_119</th>\n",
       "      <th>wb_120</th>\n",
       "      <th>wb_121</th>\n",
       "      <th>wb_122</th>\n",
       "      <th>wb_123</th>\n",
       "      <th>wb_124</th>\n",
       "      <th>wb_125</th>\n",
       "      <th>wb_126</th>\n",
       "      <th>wb_127</th>\n",
       "      <th>wb_128</th>\n",
       "      <th>wb_129</th>\n",
       "      <th>wb_130</th>\n",
       "      <th>wb_131</th>\n",
       "      <th>wb_132</th>\n",
       "      <th>wb_133</th>\n",
       "      <th>wb_134</th>\n",
       "      <th>wb_135</th>\n",
       "      <th>wb_136</th>\n",
       "      <th>wb_137</th>\n",
       "      <th>wb_138</th>\n",
       "      <th>wb_139</th>\n",
       "      <th>wb_140</th>\n",
       "      <th>wb_141</th>\n",
       "      <th>wb_142</th>\n",
       "      <th>wb_143</th>\n",
       "      <th>wb_144</th>\n",
       "      <th>wb_145</th>\n",
       "      <th>wb_146</th>\n",
       "      <th>wb_147</th>\n",
       "      <th>wb_148</th>\n",
       "      <th>wb_149</th>\n",
       "      <th>wb_150</th>\n",
       "      <th>wb_151</th>\n",
       "      <th>wb_152</th>\n",
       "      <th>wb_153</th>\n",
       "      <th>wb_154</th>\n",
       "      <th>wb_155</th>\n",
       "      <th>wb_156</th>\n",
       "      <th>wb_157</th>\n",
       "      <th>wb_158</th>\n",
       "      <th>wb_159</th>\n",
       "      <th>wb_160</th>\n",
       "      <th>wb_161</th>\n",
       "      <th>wb_162</th>\n",
       "      <th>wb_163</th>\n",
       "      <th>wb_164</th>\n",
       "      <th>wb_165</th>\n",
       "      <th>wb_166</th>\n",
       "      <th>wb_167</th>\n",
       "      <th>wb_168</th>\n",
       "      <th>wb_169</th>\n",
       "      <th>wb_170</th>\n",
       "      <th>wb_171</th>\n",
       "      <th>wb_172</th>\n",
       "      <th>wb_173</th>\n",
       "      <th>wb_174</th>\n",
       "      <th>wb_175</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.698</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.819</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.698</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.264</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.409</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-0.547</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.382</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.618</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.557</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.222</td>\n",
       "      <td>-0.496</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.384</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.563</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.619</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.447</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.268</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.349</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.265</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.746</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.712</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.645</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.451</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.292</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.382</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.284</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>0.530</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>0.186</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.312</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.564</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.265</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-0.522</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          seed  30000-target  21000-target  20100-target  20010-target  \\\n",
       "95  1373158606         0.000         0.272         0.000         0.000   \n",
       "2   1373158606         0.000         0.000         0.000         0.000   \n",
       "43  1373158606         0.000         0.000         0.178         0.000   \n",
       "56  1373158606         0.000         0.000         0.000         0.432   \n",
       "61  1373158606         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    20001-target  20000-target  12000-target  11100-target  11010-target  \\\n",
       "95         0.000         0.000         0.000         0.000         0.000   \n",
       "2          0.000         0.000         0.000         0.000         0.000   \n",
       "43         0.000         0.000         0.000         0.000         0.000   \n",
       "56         0.000         0.000        -0.778         0.000         0.000   \n",
       "61         0.000         0.265         0.000         0.000         0.000   \n",
       "\n",
       "    11001-target  11000-target  10200-target  10110-target  10101-target  \\\n",
       "95         0.000         0.000         0.000         0.000         0.000   \n",
       "2          0.000         0.000         0.000         0.000         0.000   \n",
       "43         0.000         0.000         0.000         0.000         0.000   \n",
       "56         0.000         0.000         0.000         0.000         0.000   \n",
       "61         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    10100-target  10020-target  10011-target  10010-target  10002-target  \\\n",
       "95         0.000         0.000         0.000         0.000         0.000   \n",
       "2          0.000         0.000         0.000         0.000         0.000   \n",
       "43         0.000         0.000         0.000         0.000         0.000   \n",
       "56         0.000         0.000         0.000         0.000         0.000   \n",
       "61        -0.461         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    10001-target  10000-target  03000-target  02100-target  02010-target  \\\n",
       "95         0.000         0.000         0.000         0.000         0.000   \n",
       "2          0.000         0.000         0.000         0.601         0.000   \n",
       "43         0.000         0.277         0.000         0.000         0.000   \n",
       "56         0.000         0.000         0.561         0.000        -0.939   \n",
       "61         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    02001-target  02000-target  01200-target  01110-target  01101-target  \\\n",
       "95         0.000         0.000         0.000         0.000         0.000   \n",
       "2          0.000         0.000         0.000         0.000         0.000   \n",
       "43         0.000         0.000         0.491         0.000        -0.031   \n",
       "56         0.000         0.000         0.000         0.000         0.000   \n",
       "61         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    01100-target  01020-target  01011-target  01010-target  01002-target  \\\n",
       "95         0.000         0.000         0.000         0.000         0.000   \n",
       "2          0.000         0.000         0.000         0.000         0.000   \n",
       "43         0.000         0.000         0.000         0.000         0.000   \n",
       "56         0.000         0.000         0.000         0.000         0.000   \n",
       "61         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    01001-target  01000-target  00300-target  00210-target  00201-target  \\\n",
       "95        -0.699        -0.210         0.000         0.000         0.000   \n",
       "2          0.000         0.000         0.000         0.000         0.000   \n",
       "43         0.000         0.000         0.000         0.000         0.000   \n",
       "56         0.000         0.196         0.000         0.000         0.000   \n",
       "61         0.000         0.000         0.000         0.000         0.362   \n",
       "\n",
       "    00200-target  00120-target  00111-target  00110-target  00102-target  \\\n",
       "95         0.000         0.000         0.000         0.000        -0.698   \n",
       "2          0.000         0.000         0.000         0.000         0.000   \n",
       "43         0.000         0.000         0.000         0.000         0.739   \n",
       "56         0.000         0.000         0.000         0.000         0.000   \n",
       "61         0.000         0.000         0.000         0.424         0.000   \n",
       "\n",
       "    00101-target  00100-target  00030-target  00021-target  00020-target  \\\n",
       "95         0.000         0.000         0.000         0.000         0.000   \n",
       "2          0.000         0.163         0.000         0.694        -0.520   \n",
       "43         0.000         0.000         0.000         0.000         0.000   \n",
       "56         0.000         0.000         0.000         0.000         0.000   \n",
       "61         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    00012-target  00011-target  00010-target  00003-target  00002-target  \\\n",
       "95         0.000         0.000         0.000        -0.013         0.000   \n",
       "2         -0.012         0.000         0.000         0.000         0.000   \n",
       "43         0.000         0.000         0.000         0.000         0.000   \n",
       "56         0.000         0.000         0.000         0.000         0.000   \n",
       "61         0.000        -0.222         0.000         0.000         0.000   \n",
       "\n",
       "    00001-target  00000-target  30000-lstsq_lambda  21000-lstsq_lambda  \\\n",
       "95         0.000         0.000               0.054               0.156   \n",
       "2          0.000         0.000               0.045              -0.008   \n",
       "43         0.000         0.000              -0.044              -0.080   \n",
       "56         0.000         0.000               0.083               0.015   \n",
       "61         0.000         0.000               0.009              -0.030   \n",
       "\n",
       "    20100-lstsq_lambda  20010-lstsq_lambda  20001-lstsq_lambda  \\\n",
       "95              -0.107              -0.003               0.044   \n",
       "2               -0.002               0.021               0.024   \n",
       "43              -0.001               0.017              -0.117   \n",
       "56              -0.044               0.260               0.006   \n",
       "61               0.022              -0.009              -0.015   \n",
       "\n",
       "    20000-lstsq_lambda  12000-lstsq_lambda  11100-lstsq_lambda  \\\n",
       "95               0.005               0.051              -0.026   \n",
       "2               -0.105              -0.070               0.002   \n",
       "43               0.183              -0.054              -0.056   \n",
       "56              -0.040              -0.712               0.000   \n",
       "61               0.249               0.020               0.073   \n",
       "\n",
       "    11010-lstsq_lambda  11001-lstsq_lambda  11000-lstsq_lambda  \\\n",
       "95               0.011              -0.030               0.086   \n",
       "2               -0.042               0.000               0.096   \n",
       "43               0.017              -0.088               0.218   \n",
       "56               0.032              -0.025              -0.062   \n",
       "61               0.057              -0.009              -0.059   \n",
       "\n",
       "    10200-lstsq_lambda  10110-lstsq_lambda  10101-lstsq_lambda  \\\n",
       "95              -0.045               0.033              -0.023   \n",
       "2                0.089               0.033              -0.001   \n",
       "43               0.052              -0.009              -0.043   \n",
       "56               0.061              -0.082               0.006   \n",
       "61               0.000              -0.000              -0.031   \n",
       "\n",
       "    10100-lstsq_lambda  10020-lstsq_lambda  10011-lstsq_lambda  \\\n",
       "95               0.172              -0.034               0.013   \n",
       "2               -0.086               0.021              -0.024   \n",
       "43               0.182               0.021              -0.006   \n",
       "56               0.030              -0.004               0.019   \n",
       "61              -0.450               0.002               0.011   \n",
       "\n",
       "    10010-lstsq_lambda  10002-lstsq_lambda  10001-lstsq_lambda  \\\n",
       "95               0.020              -0.022              -0.022   \n",
       "2               -0.016               0.028              -0.042   \n",
       "43              -0.049               0.005               0.167   \n",
       "56               0.193              -0.019               0.020   \n",
       "61              -0.021               0.027               0.026   \n",
       "\n",
       "    10000-lstsq_lambda  03000-lstsq_lambda  02100-lstsq_lambda  \\\n",
       "95              -0.067               0.063              -0.014   \n",
       "2                0.058              -0.054               0.432   \n",
       "43               0.093               0.041              -0.044   \n",
       "56              -0.051               0.570              -0.017   \n",
       "61               0.006              -0.018               0.039   \n",
       "\n",
       "    02010-lstsq_lambda  02001-lstsq_lambda  02000-lstsq_lambda  \\\n",
       "95               0.008               0.115              -0.189   \n",
       "2               -0.021               0.024               0.168   \n",
       "43              -0.069               0.036              -0.006   \n",
       "56              -0.831               0.035              -0.094   \n",
       "61              -0.017              -0.023               0.008   \n",
       "\n",
       "    01200-lstsq_lambda  01110-lstsq_lambda  01101-lstsq_lambda  \\\n",
       "95               0.003              -0.049               0.062   \n",
       "2               -0.093               0.051               0.020   \n",
       "43               0.447              -0.014               0.002   \n",
       "56               0.028               0.021              -0.014   \n",
       "61              -0.034              -0.072              -0.016   \n",
       "\n",
       "    01100-lstsq_lambda  01020-lstsq_lambda  01011-lstsq_lambda  \\\n",
       "95               0.024               0.026               0.028   \n",
       "2                0.179               0.024              -0.025   \n",
       "43               0.091              -0.028               0.027   \n",
       "56              -0.026               0.027              -0.045   \n",
       "61              -0.006               0.017               0.050   \n",
       "\n",
       "    01010-lstsq_lambda  01002-lstsq_lambda  01001-lstsq_lambda  \\\n",
       "95              -0.023              -0.001              -0.819   \n",
       "2                0.002               0.039              -0.062   \n",
       "43               0.078              -0.043               0.021   \n",
       "56              -0.115               0.022              -0.021   \n",
       "61              -0.021               0.060              -0.051   \n",
       "\n",
       "    01000-lstsq_lambda  00300-lstsq_lambda  00210-lstsq_lambda  \\\n",
       "95              -0.114               0.006              -0.060   \n",
       "2               -0.101              -0.008              -0.031   \n",
       "43              -0.082               0.007              -0.007   \n",
       "56               0.276               0.029               0.049   \n",
       "61               0.046              -0.117               0.006   \n",
       "\n",
       "    00201-lstsq_lambda  00200-lstsq_lambda  00120-lstsq_lambda  \\\n",
       "95               0.012               0.031               0.010   \n",
       "2                0.029              -0.010               0.001   \n",
       "43              -0.025              -0.011               0.033   \n",
       "56              -0.036              -0.087               0.003   \n",
       "61               0.136               0.267               0.007   \n",
       "\n",
       "    00111-lstsq_lambda  00110-lstsq_lambda  00102-lstsq_lambda  \\\n",
       "95               0.083               0.029              -0.591   \n",
       "2               -0.082               0.024               0.027   \n",
       "43              -0.027              -0.014               0.624   \n",
       "56              -0.007              -0.008              -0.046   \n",
       "61              -0.078               0.457              -0.124   \n",
       "\n",
       "    00101-lstsq_lambda  00100-lstsq_lambda  00030-lstsq_lambda  \\\n",
       "95              -0.145              -0.050              -0.013   \n",
       "2               -0.046               0.190              -0.180   \n",
       "43               0.136              -0.046               0.007   \n",
       "56               0.096               0.017               0.006   \n",
       "61               0.395              -0.200              -0.025   \n",
       "\n",
       "    00021-lstsq_lambda  00020-lstsq_lambda  00012-lstsq_lambda  \\\n",
       "95               0.024               0.018               0.059   \n",
       "2                0.618              -0.240              -0.015   \n",
       "43              -0.034               0.001              -0.028   \n",
       "56              -0.045               0.006               0.008   \n",
       "61              -0.016               0.005               0.038   \n",
       "\n",
       "    00011-lstsq_lambda  00010-lstsq_lambda  00003-lstsq_lambda  \\\n",
       "95              -0.143               0.008              -0.000   \n",
       "2                0.107              -0.129               0.051   \n",
       "43               0.055              -0.008              -0.037   \n",
       "56               0.062              -0.050               0.027   \n",
       "61              -0.237               0.027               0.014   \n",
       "\n",
       "    00002-lstsq_lambda  00001-lstsq_lambda  00000-lstsq_lambda  \\\n",
       "95              -0.071               0.106              -0.001   \n",
       "2               -0.137               0.088              -0.008   \n",
       "43               0.132              -0.128               0.047   \n",
       "56              -0.024              -0.031               0.021   \n",
       "61              -0.052              -0.028               0.008   \n",
       "\n",
       "    30000-lstsq_target  21000-lstsq_target  20100-lstsq_target  \\\n",
       "95               0.000               0.272               0.000   \n",
       "2               -0.000               0.000               0.000   \n",
       "43              -0.000               0.000               0.178   \n",
       "56              -0.000               0.000              -0.000   \n",
       "61               0.000               0.000              -0.000   \n",
       "\n",
       "    20010-lstsq_target  20001-lstsq_target  20000-lstsq_target  \\\n",
       "95              -0.000               0.000              -0.000   \n",
       "2               -0.000               0.000               0.000   \n",
       "43              -0.000               0.000              -0.000   \n",
       "56               0.432              -0.000               0.000   \n",
       "61              -0.000               0.000               0.265   \n",
       "\n",
       "    12000-lstsq_target  11100-lstsq_target  11010-lstsq_target  \\\n",
       "95               0.000               0.000              -0.000   \n",
       "2                0.000               0.000              -0.000   \n",
       "43               0.000               0.000              -0.000   \n",
       "56              -0.778              -0.000               0.000   \n",
       "61               0.000               0.000               0.000   \n",
       "\n",
       "    11001-lstsq_target  11000-lstsq_target  10200-lstsq_target  \\\n",
       "95               0.000              -0.000               0.000   \n",
       "2               -0.000              -0.000               0.000   \n",
       "43              -0.000              -0.000              -0.000   \n",
       "56               0.000              -0.000               0.000   \n",
       "61               0.000              -0.000              -0.000   \n",
       "\n",
       "    10110-lstsq_target  10101-lstsq_target  10100-lstsq_target  \\\n",
       "95               0.000               0.000              -0.000   \n",
       "2               -0.000               0.000              -0.000   \n",
       "43              -0.000              -0.000              -0.000   \n",
       "56              -0.000              -0.000               0.000   \n",
       "61               0.000               0.000              -0.461   \n",
       "\n",
       "    10020-lstsq_target  10011-lstsq_target  10010-lstsq_target  \\\n",
       "95               0.000              -0.000               0.000   \n",
       "2                0.000               0.000              -0.000   \n",
       "43               0.000              -0.000              -0.000   \n",
       "56               0.000               0.000              -0.000   \n",
       "61              -0.000              -0.000               0.000   \n",
       "\n",
       "    10002-lstsq_target  10001-lstsq_target  10000-lstsq_target  \\\n",
       "95              -0.000              -0.000               0.000   \n",
       "2                0.000              -0.000               0.000   \n",
       "43              -0.000               0.000               0.277   \n",
       "56               0.000              -0.000              -0.000   \n",
       "61               0.000              -0.000               0.000   \n",
       "\n",
       "    03000-lstsq_target  02100-lstsq_target  02010-lstsq_target  \\\n",
       "95              -0.000               0.000              -0.000   \n",
       "2                0.000               0.601               0.000   \n",
       "43               0.000               0.000               0.000   \n",
       "56               0.561               0.000              -0.939   \n",
       "61               0.000               0.000              -0.000   \n",
       "\n",
       "    02001-lstsq_target  02000-lstsq_target  01200-lstsq_target  \\\n",
       "95               0.000              -0.000              -0.000   \n",
       "2                0.000              -0.000              -0.000   \n",
       "43              -0.000              -0.000               0.491   \n",
       "56               0.000               0.000               0.000   \n",
       "61               0.000              -0.000               0.000   \n",
       "\n",
       "    01110-lstsq_target  01101-lstsq_target  01100-lstsq_target  \\\n",
       "95              -0.000               0.000              -0.000   \n",
       "2               -0.000               0.000              -0.000   \n",
       "43               0.000              -0.031              -0.000   \n",
       "56              -0.000               0.000              -0.000   \n",
       "61               0.000               0.000              -0.000   \n",
       "\n",
       "    01020-lstsq_target  01011-lstsq_target  01010-lstsq_target  \\\n",
       "95               0.000               0.000               0.000   \n",
       "2               -0.000              -0.000               0.000   \n",
       "43              -0.000               0.000              -0.000   \n",
       "56              -0.000               0.000               0.000   \n",
       "61              -0.000               0.000              -0.000   \n",
       "\n",
       "    01002-lstsq_target  01001-lstsq_target  01000-lstsq_target  \\\n",
       "95               0.000              -0.699              -0.210   \n",
       "2                0.000              -0.000               0.000   \n",
       "43              -0.000               0.000               0.000   \n",
       "56               0.000              -0.000               0.196   \n",
       "61               0.000              -0.000               0.000   \n",
       "\n",
       "    00300-lstsq_target  00210-lstsq_target  00201-lstsq_target  \\\n",
       "95               0.000              -0.000               0.000   \n",
       "2                0.000               0.000               0.000   \n",
       "43               0.000               0.000              -0.000   \n",
       "56               0.000               0.000               0.000   \n",
       "61               0.000               0.000               0.362   \n",
       "\n",
       "    00200-lstsq_target  00120-lstsq_target  00111-lstsq_target  \\\n",
       "95              -0.000              -0.000              -0.000   \n",
       "2               -0.000               0.000              -0.000   \n",
       "43              -0.000               0.000               0.000   \n",
       "56              -0.000               0.000              -0.000   \n",
       "61              -0.000               0.000              -0.000   \n",
       "\n",
       "    00110-lstsq_target  00102-lstsq_target  00101-lstsq_target  \\\n",
       "95               0.000              -0.698              -0.000   \n",
       "2                0.000              -0.000              -0.000   \n",
       "43              -0.000               0.739               0.000   \n",
       "56               0.000               0.000               0.000   \n",
       "61               0.424              -0.000               0.000   \n",
       "\n",
       "    00100-lstsq_target  00030-lstsq_target  00021-lstsq_target  \\\n",
       "95               0.000               0.000              -0.000   \n",
       "2                0.163               0.000               0.694   \n",
       "43               0.000               0.000               0.000   \n",
       "56               0.000              -0.000              -0.000   \n",
       "61               0.000              -0.000              -0.000   \n",
       "\n",
       "    00020-lstsq_target  00012-lstsq_target  00011-lstsq_target  \\\n",
       "95              -0.000               0.000              -0.000   \n",
       "2               -0.520              -0.012               0.000   \n",
       "43              -0.000               0.000              -0.000   \n",
       "56               0.000               0.000              -0.000   \n",
       "61               0.000              -0.000              -0.222   \n",
       "\n",
       "    00010-lstsq_target  00003-lstsq_target  00002-lstsq_target  \\\n",
       "95               0.000              -0.013              -0.000   \n",
       "2                0.000              -0.000               0.000   \n",
       "43               0.000              -0.000               0.000   \n",
       "56               0.000               0.000              -0.000   \n",
       "61              -0.000              -0.000               0.000   \n",
       "\n",
       "    00001-lstsq_target  00000-lstsq_target   wb_0   wb_1  wb_2   wb_3  wb_4  \\\n",
       "95               0.000              -0.000  0.151 -0.025 0.236  0.007 0.091   \n",
       "2               -0.000              -0.000 -0.021 -0.102 0.359 -0.001 0.042   \n",
       "43              -0.000              -0.000 -0.067 -0.148 0.333  0.105 0.298   \n",
       "56               0.000              -0.000  0.050 -0.120 0.083 -0.026 0.337   \n",
       "61              -0.000              -0.000 -0.080 -0.085 0.156 -0.011 0.254   \n",
       "\n",
       "    wb_5  wb_6   wb_7  wb_8  wb_9  wb_10  wb_11  wb_12  wb_13  wb_14  wb_15  \\\n",
       "95 0.094 0.240 -0.055 0.158 0.475  0.357 -0.212 -0.038  0.305  0.177  0.376   \n",
       "2  0.182 0.227 -0.119 0.049 0.046  0.428 -0.083 -0.040  0.297  0.177  0.241   \n",
       "43 0.238 0.206 -0.027 0.074 0.032  0.114 -0.099 -0.086 -0.010  0.233  0.365   \n",
       "56 0.112 0.314 -0.203 0.145 0.514  0.440 -0.067 -0.009  0.399  0.094  0.341   \n",
       "61 0.051 0.312 -0.141 0.227 0.526  0.234 -0.187  0.014  0.447  0.061  0.498   \n",
       "\n",
       "    wb_16  wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  wb_24  wb_25  \\\n",
       "95  0.184  0.180  0.336  0.425 -0.050  0.038 -0.122 -0.010 -0.419 -0.262   \n",
       "2  -0.060  0.290  0.331  0.050  0.001  0.175 -0.000 -0.009 -0.451 -0.069   \n",
       "43 -0.084  0.351  0.381  0.386  0.067  0.012  0.194 -0.039 -0.493 -0.147   \n",
       "56 -0.255  0.214  0.384  0.282 -0.179  0.222  0.127  0.040 -0.645 -0.730   \n",
       "61  0.211  0.186  0.355  0.372 -0.064 -0.009  0.051  0.060 -0.465 -0.140   \n",
       "\n",
       "    wb_26  wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  wb_34  wb_35  \\\n",
       "95  0.127 -0.070  0.017 -0.105  0.283  0.405  0.262  0.345  0.338 -0.398   \n",
       "2  -0.016 -0.040 -0.081 -0.514  0.404  0.256  0.436  0.330  0.059 -0.295   \n",
       "43  0.029 -0.065 -0.152 -0.076  0.329  0.294 -0.015  0.225  0.036  0.030   \n",
       "56  0.055 -0.345 -0.340 -0.534  0.302  0.327  0.050  0.351 -0.348 -0.423   \n",
       "61  0.048 -0.377 -0.309 -0.080  0.333  0.307  0.029  0.259  0.006 -0.089   \n",
       "\n",
       "    wb_36  wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  wb_44  wb_45  \\\n",
       "95 -0.405  0.095 -0.047 -0.268  0.094 -0.108  0.264 -0.220  0.293  0.186   \n",
       "2  -0.220 -0.100 -0.235 -0.095  0.076  0.152  0.557 -0.037  0.583  0.481   \n",
       "43 -0.313 -0.280 -0.051 -0.124  0.181 -0.092  0.482 -0.061  0.290  0.244   \n",
       "56 -0.439 -0.189 -0.097 -0.223  0.197  0.591  0.451 -0.374  0.372  0.365   \n",
       "61 -0.417  0.019 -0.114 -0.182  0.146  0.005  0.483 -0.036  0.296  0.070   \n",
       "\n",
       "    wb_46  wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  wb_54  wb_55  \\\n",
       "95  0.141  0.254  0.378 -0.370 -0.035  0.155 -0.539 -0.270 -0.455  0.344   \n",
       "2   0.033  0.139  0.222 -0.496  0.041  0.118 -0.110 -0.048 -0.389  0.519   \n",
       "43  0.024  0.332  0.268 -0.503 -0.098  0.064 -0.275  0.003 -0.154  0.594   \n",
       "56  0.114  0.579  0.292 -0.219 -0.000  0.151 -0.038 -0.122 -0.209  0.449   \n",
       "61  0.012  0.412  0.277 -0.504 -0.104  0.064 -0.353 -0.203 -0.163  0.542   \n",
       "\n",
       "    wb_56  wb_57  wb_58  wb_59  wb_60  wb_61  wb_62  wb_63  wb_64  wb_65  \\\n",
       "95  0.531 -0.011  0.150 -0.061 -0.273  0.166  0.275  0.292  0.199 -0.038   \n",
       "2   0.348 -0.348 -0.253 -0.235  0.256  0.351  0.230  0.158  0.384 -0.241   \n",
       "43  0.296 -0.290 -0.269 -0.239 -0.038  0.492  0.358  0.358  0.471 -0.114   \n",
       "56  0.403 -0.490  0.009  0.001  0.000  0.164  0.199  0.183  0.314 -0.094   \n",
       "61  0.338 -0.364  0.027 -0.564  0.433  0.197  0.305  0.102  0.410 -0.059   \n",
       "\n",
       "    wb_66  wb_67  wb_68  wb_69  wb_70  wb_71  wb_72  wb_73  wb_74  wb_75  \\\n",
       "95 -0.348  0.219  0.076 -0.030  0.409 -0.170  0.172  0.521  0.129  0.189   \n",
       "2  -0.251  0.489  0.146 -0.006  0.431 -0.256  0.106  0.341 -0.050  0.372   \n",
       "43 -0.473  0.570  0.256 -0.098  0.582 -0.391 -0.440  0.280 -0.074  0.154   \n",
       "56 -0.072  0.410  0.036 -0.233  0.145 -0.242  0.056  0.387  0.152  0.140   \n",
       "61 -0.435  0.512 -0.003 -0.285  0.411 -0.506  0.133  0.316 -0.077  0.166   \n",
       "\n",
       "    wb_76  wb_77  wb_78  wb_79  wb_80  wb_81  wb_82  wb_83  wb_84  wb_85  \\\n",
       "95  0.121 -0.215  0.064  0.334 -0.010  0.059  0.022 -0.078  0.108 -0.060   \n",
       "2   0.366 -0.231  0.553  0.121 -0.054  0.127 -0.000 -0.028  0.504  0.109   \n",
       "43  0.365 -0.119  0.370  0.455 -0.043  0.132 -0.014  0.000  0.018  0.030   \n",
       "56  0.382 -0.344  0.211  0.357 -0.087  0.151  0.119  0.129  0.308 -0.535   \n",
       "61  0.266 -0.365  0.239  0.561  0.063 -0.017  0.290 -0.123  0.088 -0.286   \n",
       "\n",
       "    wb_86  wb_87  wb_88  wb_89  wb_90  wb_91  wb_92  wb_93  wb_94  wb_95  \\\n",
       "95  0.113 -0.133 -0.062  0.332  0.136 -0.095 -0.230  0.060  0.015 -0.463   \n",
       "2   0.343 -0.335 -0.001  0.275  0.296 -0.406 -0.164  0.093  0.001 -0.357   \n",
       "43  0.018  0.019  0.027  0.286  0.224 -0.015 -0.155  0.101 -0.088  0.007   \n",
       "56  0.233 -0.288 -0.004  0.236  0.275 -0.231 -0.221  0.210 -0.131 -0.510   \n",
       "61  0.110 -0.351 -0.135  0.387  0.069 -0.300 -0.058  0.030 -0.092 -0.324   \n",
       "\n",
       "    wb_96  wb_97  wb_98  wb_99  wb_100  wb_101  wb_102  wb_103  wb_104  \\\n",
       "95  0.116 -0.038  0.276 -0.395  -0.254   0.328  -0.198  -0.466   0.219   \n",
       "2   0.141  0.345  0.351 -0.374  -0.272   0.038   0.195  -0.402   0.057   \n",
       "43 -0.014 -0.055  0.349 -0.344  -0.385  -0.044   0.032  -0.343   0.322   \n",
       "56  0.245  0.044  0.373 -0.571  -0.018   0.085  -0.004  -0.508  -0.018   \n",
       "61  0.265 -0.380  0.252 -0.340  -0.379   0.110  -0.028  -0.500   0.023   \n",
       "\n",
       "    wb_105  wb_106  wb_107  wb_108  wb_109  wb_110  wb_111  wb_112  wb_113  \\\n",
       "95  -0.481   0.007   0.534   0.210  -0.499  -0.441  -0.547   0.346   0.182   \n",
       "2   -0.051  -0.260   0.046  -0.016  -0.325  -0.156  -0.283   0.236   0.037   \n",
       "43   0.077  -0.367   0.444   0.008  -0.717  -0.976  -0.243  -0.136  -0.409   \n",
       "56  -0.110  -0.205   0.116   0.002  -0.004   0.035  -0.400   0.039   0.028   \n",
       "61  -0.162  -0.226   0.345  -0.028  -0.311  -0.353  -0.522  -0.016   0.029   \n",
       "\n",
       "    wb_114  wb_115  wb_116  wb_117  wb_118  wb_119  wb_120  wb_121  wb_122  \\\n",
       "95   0.017  -0.003   0.289   0.160  -0.025  -0.210  -0.045   0.626   0.409   \n",
       "2    0.306  -0.164  -0.008   0.458   0.076   0.003  -0.126   0.373   0.394   \n",
       "43   0.427  -0.205  -0.117   0.584   0.160   0.214   0.196   0.422   0.008   \n",
       "56   0.243  -0.012  -0.010   0.391   0.020   0.059   0.075   0.374   0.000   \n",
       "61   0.232  -0.119   0.032   0.380   0.080   0.017   0.367   0.317  -0.156   \n",
       "\n",
       "    wb_123  wb_124  wb_125  wb_126  wb_127  wb_128  wb_129  wb_130  wb_131  \\\n",
       "95   0.086   0.232   0.030  -0.394   0.060   0.467   0.191  -0.039  -0.076   \n",
       "2   -0.165   0.269  -0.221   0.078   0.255  -0.066   0.441  -0.009   0.038   \n",
       "43  -0.266   0.259  -0.091   0.153   0.407  -0.027  -0.052  -0.093   0.121   \n",
       "56  -0.143   0.239   0.031  -0.026   0.398  -0.165   0.184   0.091  -0.042   \n",
       "61  -0.128   0.266  -0.079   0.020  -0.102  -0.155   0.024  -0.015   0.019   \n",
       "\n",
       "    wb_132  wb_133  wb_134  wb_135  wb_136  wb_137  wb_138  wb_139  wb_140  \\\n",
       "95  -0.275  -0.082  -0.014   0.152  -0.169  -0.227  -0.000   0.126  -0.022   \n",
       "2   -0.103  -0.118  -0.263   0.206  -0.072   0.020   0.153  -0.005   0.117   \n",
       "43  -0.302   0.020   0.573   0.278  -0.026  -0.144   0.092  -0.092   0.192   \n",
       "56  -0.219  -0.406  -0.425   0.002  -0.155   0.165   0.049   0.067  -0.214   \n",
       "61  -0.155   0.053   0.123  -0.072  -0.171   0.077   0.162  -0.002   0.108   \n",
       "\n",
       "    wb_141  wb_142  wb_143  wb_144  wb_145  wb_146  wb_147  wb_148  wb_149  \\\n",
       "95  -0.033  -0.019   0.103  -0.352   0.066  -0.070  -0.474  -0.080  -0.214   \n",
       "2   -0.114  -0.014  -0.014  -0.308  -0.059   0.160  -0.563   0.059  -0.138   \n",
       "43   0.314  -0.115  -0.105  -0.202  -0.686  -0.182  -0.121   0.150  -0.150   \n",
       "56  -0.216   0.070  -0.161   0.052   0.186   0.017  -0.355  -0.056  -0.126   \n",
       "61   0.220   0.004  -0.217   0.042  -0.184   0.147  -0.042   0.017  -0.155   \n",
       "\n",
       "    wb_150  wb_151  wb_152  wb_153  wb_154  wb_155  wb_156  wb_157  wb_158  \\\n",
       "95  -0.177  -0.538  -0.110  -0.533   0.227   0.382  -0.133  -0.408  -0.427   \n",
       "2   -0.655  -0.276  -0.366  -0.421   0.538   0.374  -0.041  -0.202  -0.459   \n",
       "43  -0.222  -0.298  -0.481   0.000   0.274   0.405  -0.085  -0.488  -0.246   \n",
       "56  -0.435  -0.306  -0.463  -0.034   0.413   0.284  -0.116  -0.174  -0.818   \n",
       "61  -0.223  -0.199  -0.177  -0.174   0.259   0.351  -0.062  -0.255  -0.322   \n",
       "\n",
       "    wb_159  wb_160  wb_161  wb_162  wb_163  wb_164  wb_165  wb_166  wb_167  \\\n",
       "95   0.215  -0.155  -0.256  -0.453  -0.196   0.171  -0.094   0.330  -0.003   \n",
       "2   -0.306  -0.099  -0.175  -0.255  -0.217   0.235  -0.154   0.301   0.212   \n",
       "43   0.527   0.265  -0.242  -0.476  -0.242   0.343  -0.245   0.645   0.264   \n",
       "56   0.530  -0.283  -0.128  -0.190  -0.226   0.186  -0.237   1.040   0.130   \n",
       "61   0.315  -0.109  -0.247  -0.263  -0.328   0.269  -0.244   0.595   0.146   \n",
       "\n",
       "    wb_168  wb_169  wb_170  wb_171  wb_172  wb_173  wb_174  wb_175  \n",
       "95   0.314   0.462   0.098  -0.440  -0.521  -0.266  -0.308   0.121  \n",
       "2    0.260   0.403   0.244  -0.248   0.619  -0.176  -0.283  -0.006  \n",
       "43   0.389   0.216   0.746  -0.345  -0.082  -0.216  -0.285  -0.097  \n",
       "56   0.545   0.143   0.197  -0.275  -0.272  -0.229  -0.308   0.086  \n",
       "61   0.407   0.173   0.184  -0.400  -0.064  -0.136  -0.307   0.012  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_valid_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:27.196526Z",
     "iopub.status.busy": "2022-01-17T12:42:27.196266Z",
     "iopub.status.idle": "2022-01-17T12:42:27.553574Z",
     "shell.execute_reply": "2022-01-17T12:42:27.552559Z",
     "shell.execute_reply.started": "2022-01-17T12:42:27.196499Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>30000-target</th>\n",
       "      <th>21000-target</th>\n",
       "      <th>20100-target</th>\n",
       "      <th>20010-target</th>\n",
       "      <th>20001-target</th>\n",
       "      <th>20000-target</th>\n",
       "      <th>12000-target</th>\n",
       "      <th>11100-target</th>\n",
       "      <th>11010-target</th>\n",
       "      <th>11001-target</th>\n",
       "      <th>11000-target</th>\n",
       "      <th>10200-target</th>\n",
       "      <th>10110-target</th>\n",
       "      <th>10101-target</th>\n",
       "      <th>10100-target</th>\n",
       "      <th>10020-target</th>\n",
       "      <th>10011-target</th>\n",
       "      <th>10010-target</th>\n",
       "      <th>10002-target</th>\n",
       "      <th>10001-target</th>\n",
       "      <th>10000-target</th>\n",
       "      <th>03000-target</th>\n",
       "      <th>02100-target</th>\n",
       "      <th>02010-target</th>\n",
       "      <th>02001-target</th>\n",
       "      <th>02000-target</th>\n",
       "      <th>01200-target</th>\n",
       "      <th>01110-target</th>\n",
       "      <th>01101-target</th>\n",
       "      <th>01100-target</th>\n",
       "      <th>01020-target</th>\n",
       "      <th>01011-target</th>\n",
       "      <th>01010-target</th>\n",
       "      <th>01002-target</th>\n",
       "      <th>01001-target</th>\n",
       "      <th>01000-target</th>\n",
       "      <th>00300-target</th>\n",
       "      <th>00210-target</th>\n",
       "      <th>00201-target</th>\n",
       "      <th>00200-target</th>\n",
       "      <th>00120-target</th>\n",
       "      <th>00111-target</th>\n",
       "      <th>00110-target</th>\n",
       "      <th>00102-target</th>\n",
       "      <th>00101-target</th>\n",
       "      <th>00100-target</th>\n",
       "      <th>00030-target</th>\n",
       "      <th>00021-target</th>\n",
       "      <th>00020-target</th>\n",
       "      <th>00012-target</th>\n",
       "      <th>00011-target</th>\n",
       "      <th>00010-target</th>\n",
       "      <th>00003-target</th>\n",
       "      <th>00002-target</th>\n",
       "      <th>00001-target</th>\n",
       "      <th>00000-target</th>\n",
       "      <th>30000-lstsq_lambda</th>\n",
       "      <th>21000-lstsq_lambda</th>\n",
       "      <th>20100-lstsq_lambda</th>\n",
       "      <th>20010-lstsq_lambda</th>\n",
       "      <th>20001-lstsq_lambda</th>\n",
       "      <th>20000-lstsq_lambda</th>\n",
       "      <th>12000-lstsq_lambda</th>\n",
       "      <th>11100-lstsq_lambda</th>\n",
       "      <th>11010-lstsq_lambda</th>\n",
       "      <th>11001-lstsq_lambda</th>\n",
       "      <th>11000-lstsq_lambda</th>\n",
       "      <th>10200-lstsq_lambda</th>\n",
       "      <th>10110-lstsq_lambda</th>\n",
       "      <th>10101-lstsq_lambda</th>\n",
       "      <th>10100-lstsq_lambda</th>\n",
       "      <th>10020-lstsq_lambda</th>\n",
       "      <th>10011-lstsq_lambda</th>\n",
       "      <th>10010-lstsq_lambda</th>\n",
       "      <th>10002-lstsq_lambda</th>\n",
       "      <th>10001-lstsq_lambda</th>\n",
       "      <th>10000-lstsq_lambda</th>\n",
       "      <th>03000-lstsq_lambda</th>\n",
       "      <th>02100-lstsq_lambda</th>\n",
       "      <th>02010-lstsq_lambda</th>\n",
       "      <th>02001-lstsq_lambda</th>\n",
       "      <th>02000-lstsq_lambda</th>\n",
       "      <th>01200-lstsq_lambda</th>\n",
       "      <th>01110-lstsq_lambda</th>\n",
       "      <th>01101-lstsq_lambda</th>\n",
       "      <th>01100-lstsq_lambda</th>\n",
       "      <th>01020-lstsq_lambda</th>\n",
       "      <th>01011-lstsq_lambda</th>\n",
       "      <th>01010-lstsq_lambda</th>\n",
       "      <th>01002-lstsq_lambda</th>\n",
       "      <th>01001-lstsq_lambda</th>\n",
       "      <th>01000-lstsq_lambda</th>\n",
       "      <th>00300-lstsq_lambda</th>\n",
       "      <th>00210-lstsq_lambda</th>\n",
       "      <th>00201-lstsq_lambda</th>\n",
       "      <th>00200-lstsq_lambda</th>\n",
       "      <th>00120-lstsq_lambda</th>\n",
       "      <th>00111-lstsq_lambda</th>\n",
       "      <th>00110-lstsq_lambda</th>\n",
       "      <th>00102-lstsq_lambda</th>\n",
       "      <th>00101-lstsq_lambda</th>\n",
       "      <th>00100-lstsq_lambda</th>\n",
       "      <th>00030-lstsq_lambda</th>\n",
       "      <th>00021-lstsq_lambda</th>\n",
       "      <th>00020-lstsq_lambda</th>\n",
       "      <th>00012-lstsq_lambda</th>\n",
       "      <th>00011-lstsq_lambda</th>\n",
       "      <th>00010-lstsq_lambda</th>\n",
       "      <th>00003-lstsq_lambda</th>\n",
       "      <th>00002-lstsq_lambda</th>\n",
       "      <th>00001-lstsq_lambda</th>\n",
       "      <th>00000-lstsq_lambda</th>\n",
       "      <th>30000-lstsq_target</th>\n",
       "      <th>21000-lstsq_target</th>\n",
       "      <th>20100-lstsq_target</th>\n",
       "      <th>20010-lstsq_target</th>\n",
       "      <th>20001-lstsq_target</th>\n",
       "      <th>20000-lstsq_target</th>\n",
       "      <th>12000-lstsq_target</th>\n",
       "      <th>11100-lstsq_target</th>\n",
       "      <th>11010-lstsq_target</th>\n",
       "      <th>11001-lstsq_target</th>\n",
       "      <th>11000-lstsq_target</th>\n",
       "      <th>10200-lstsq_target</th>\n",
       "      <th>10110-lstsq_target</th>\n",
       "      <th>10101-lstsq_target</th>\n",
       "      <th>10100-lstsq_target</th>\n",
       "      <th>10020-lstsq_target</th>\n",
       "      <th>10011-lstsq_target</th>\n",
       "      <th>10010-lstsq_target</th>\n",
       "      <th>10002-lstsq_target</th>\n",
       "      <th>10001-lstsq_target</th>\n",
       "      <th>10000-lstsq_target</th>\n",
       "      <th>03000-lstsq_target</th>\n",
       "      <th>02100-lstsq_target</th>\n",
       "      <th>02010-lstsq_target</th>\n",
       "      <th>02001-lstsq_target</th>\n",
       "      <th>02000-lstsq_target</th>\n",
       "      <th>01200-lstsq_target</th>\n",
       "      <th>01110-lstsq_target</th>\n",
       "      <th>01101-lstsq_target</th>\n",
       "      <th>01100-lstsq_target</th>\n",
       "      <th>01020-lstsq_target</th>\n",
       "      <th>01011-lstsq_target</th>\n",
       "      <th>01010-lstsq_target</th>\n",
       "      <th>01002-lstsq_target</th>\n",
       "      <th>01001-lstsq_target</th>\n",
       "      <th>01000-lstsq_target</th>\n",
       "      <th>00300-lstsq_target</th>\n",
       "      <th>00210-lstsq_target</th>\n",
       "      <th>00201-lstsq_target</th>\n",
       "      <th>00200-lstsq_target</th>\n",
       "      <th>00120-lstsq_target</th>\n",
       "      <th>00111-lstsq_target</th>\n",
       "      <th>00110-lstsq_target</th>\n",
       "      <th>00102-lstsq_target</th>\n",
       "      <th>00101-lstsq_target</th>\n",
       "      <th>00100-lstsq_target</th>\n",
       "      <th>00030-lstsq_target</th>\n",
       "      <th>00021-lstsq_target</th>\n",
       "      <th>00020-lstsq_target</th>\n",
       "      <th>00012-lstsq_target</th>\n",
       "      <th>00011-lstsq_target</th>\n",
       "      <th>00010-lstsq_target</th>\n",
       "      <th>00003-lstsq_target</th>\n",
       "      <th>00002-lstsq_target</th>\n",
       "      <th>00001-lstsq_target</th>\n",
       "      <th>00000-lstsq_target</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "      <th>wb_61</th>\n",
       "      <th>wb_62</th>\n",
       "      <th>wb_63</th>\n",
       "      <th>wb_64</th>\n",
       "      <th>wb_65</th>\n",
       "      <th>wb_66</th>\n",
       "      <th>wb_67</th>\n",
       "      <th>wb_68</th>\n",
       "      <th>wb_69</th>\n",
       "      <th>wb_70</th>\n",
       "      <th>wb_71</th>\n",
       "      <th>wb_72</th>\n",
       "      <th>wb_73</th>\n",
       "      <th>wb_74</th>\n",
       "      <th>wb_75</th>\n",
       "      <th>wb_76</th>\n",
       "      <th>wb_77</th>\n",
       "      <th>wb_78</th>\n",
       "      <th>wb_79</th>\n",
       "      <th>wb_80</th>\n",
       "      <th>wb_81</th>\n",
       "      <th>wb_82</th>\n",
       "      <th>wb_83</th>\n",
       "      <th>wb_84</th>\n",
       "      <th>wb_85</th>\n",
       "      <th>wb_86</th>\n",
       "      <th>wb_87</th>\n",
       "      <th>wb_88</th>\n",
       "      <th>wb_89</th>\n",
       "      <th>wb_90</th>\n",
       "      <th>wb_91</th>\n",
       "      <th>wb_92</th>\n",
       "      <th>wb_93</th>\n",
       "      <th>wb_94</th>\n",
       "      <th>wb_95</th>\n",
       "      <th>wb_96</th>\n",
       "      <th>wb_97</th>\n",
       "      <th>wb_98</th>\n",
       "      <th>wb_99</th>\n",
       "      <th>wb_100</th>\n",
       "      <th>wb_101</th>\n",
       "      <th>wb_102</th>\n",
       "      <th>wb_103</th>\n",
       "      <th>wb_104</th>\n",
       "      <th>wb_105</th>\n",
       "      <th>wb_106</th>\n",
       "      <th>wb_107</th>\n",
       "      <th>wb_108</th>\n",
       "      <th>wb_109</th>\n",
       "      <th>wb_110</th>\n",
       "      <th>wb_111</th>\n",
       "      <th>wb_112</th>\n",
       "      <th>wb_113</th>\n",
       "      <th>wb_114</th>\n",
       "      <th>wb_115</th>\n",
       "      <th>wb_116</th>\n",
       "      <th>wb_117</th>\n",
       "      <th>wb_118</th>\n",
       "      <th>wb_119</th>\n",
       "      <th>wb_120</th>\n",
       "      <th>wb_121</th>\n",
       "      <th>wb_122</th>\n",
       "      <th>wb_123</th>\n",
       "      <th>wb_124</th>\n",
       "      <th>wb_125</th>\n",
       "      <th>wb_126</th>\n",
       "      <th>wb_127</th>\n",
       "      <th>wb_128</th>\n",
       "      <th>wb_129</th>\n",
       "      <th>wb_130</th>\n",
       "      <th>wb_131</th>\n",
       "      <th>wb_132</th>\n",
       "      <th>wb_133</th>\n",
       "      <th>wb_134</th>\n",
       "      <th>wb_135</th>\n",
       "      <th>wb_136</th>\n",
       "      <th>wb_137</th>\n",
       "      <th>wb_138</th>\n",
       "      <th>wb_139</th>\n",
       "      <th>wb_140</th>\n",
       "      <th>wb_141</th>\n",
       "      <th>wb_142</th>\n",
       "      <th>wb_143</th>\n",
       "      <th>wb_144</th>\n",
       "      <th>wb_145</th>\n",
       "      <th>wb_146</th>\n",
       "      <th>wb_147</th>\n",
       "      <th>wb_148</th>\n",
       "      <th>wb_149</th>\n",
       "      <th>wb_150</th>\n",
       "      <th>wb_151</th>\n",
       "      <th>wb_152</th>\n",
       "      <th>wb_153</th>\n",
       "      <th>wb_154</th>\n",
       "      <th>wb_155</th>\n",
       "      <th>wb_156</th>\n",
       "      <th>wb_157</th>\n",
       "      <th>wb_158</th>\n",
       "      <th>wb_159</th>\n",
       "      <th>wb_160</th>\n",
       "      <th>wb_161</th>\n",
       "      <th>wb_162</th>\n",
       "      <th>wb_163</th>\n",
       "      <th>wb_164</th>\n",
       "      <th>wb_165</th>\n",
       "      <th>wb_166</th>\n",
       "      <th>wb_167</th>\n",
       "      <th>wb_168</th>\n",
       "      <th>wb_169</th>\n",
       "      <th>wb_170</th>\n",
       "      <th>wb_171</th>\n",
       "      <th>wb_172</th>\n",
       "      <th>wb_173</th>\n",
       "      <th>wb_174</th>\n",
       "      <th>wb_175</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.339</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.517</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.419</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.298</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.355</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.602</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>-0.581</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.825</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.594</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.825</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.423</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.388</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>-0.512</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.355</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.339</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.204</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-1.127</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.445</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.507</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.486</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.499</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.388</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.419</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.303</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.851</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.905</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.698</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.363</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.927</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.379</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.655</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.474</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.516</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.213</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.399</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.494</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.342</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.553</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.762</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1373158606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.424</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.453</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.279</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.349</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.292</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          seed  30000-target  21000-target  20100-target  20010-target  \\\n",
       "29  1373158606         0.000         0.000         0.000         0.000   \n",
       "38  1373158606         0.000         0.000         0.000         0.000   \n",
       "79  1373158606         0.000         0.000         0.000         0.362   \n",
       "19  1373158606         0.000         0.000         0.000         0.000   \n",
       "27  1373158606         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    20001-target  20000-target  12000-target  11100-target  11010-target  \\\n",
       "29        -0.378         0.000         0.000         0.000         0.000   \n",
       "38         0.000         0.000         0.000         0.000        -0.825   \n",
       "79         0.000         0.000         0.000         0.000         0.000   \n",
       "19         0.000         0.000         0.000         0.000         0.000   \n",
       "27         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    11001-target  11000-target  10200-target  10110-target  10101-target  \\\n",
       "29         0.000         0.000         0.000         0.000         0.000   \n",
       "38         0.000         0.000        -0.153         0.000         0.000   \n",
       "79         0.000         0.000         0.000         0.000         0.000   \n",
       "19         0.000         0.000         0.000         0.000         0.000   \n",
       "27         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    10100-target  10020-target  10011-target  10010-target  10002-target  \\\n",
       "29         0.000         0.893         0.107         0.000         0.000   \n",
       "38         0.000         0.000         0.000         0.000         0.000   \n",
       "79         0.000         0.000         0.000        -0.775         0.000   \n",
       "19         0.000         0.000         0.000         0.000         0.000   \n",
       "27         0.000         0.000         0.000         0.000         0.349   \n",
       "\n",
       "    10001-target  10000-target  03000-target  02100-target  02010-target  \\\n",
       "29         0.000         0.000         0.000         0.000         0.000   \n",
       "38         0.000         0.000         0.000         0.000         0.000   \n",
       "79         0.000         0.000         0.000         0.000         0.000   \n",
       "19        -0.770        -0.546         0.000         0.000         0.000   \n",
       "27         0.000        -0.357         0.000         0.000         0.000   \n",
       "\n",
       "    02001-target  02000-target  01200-target  01110-target  01101-target  \\\n",
       "29         0.000         0.189         0.000        -0.146         0.000   \n",
       "38         0.000         0.000         0.307         0.000        -0.988   \n",
       "79         0.000         0.000         0.000         0.000         0.000   \n",
       "19         0.000         0.690         0.000         0.927         0.000   \n",
       "27         0.000         0.000         0.000         0.000        -0.824   \n",
       "\n",
       "    01100-target  01020-target  01011-target  01010-target  01002-target  \\\n",
       "29         0.000         0.000         0.000         0.000         0.000   \n",
       "38         0.000         0.000         0.000         0.000         0.000   \n",
       "79         0.000         0.000         0.000         0.000         0.000   \n",
       "19         0.000         0.000         0.000         0.000         0.000   \n",
       "27         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    01001-target  01000-target  00300-target  00210-target  00201-target  \\\n",
       "29         0.000         0.000         0.000         0.000         0.000   \n",
       "38         0.000         0.000         0.000         0.000         0.000   \n",
       "79         0.000         0.000         0.000         0.000        -0.085   \n",
       "19         0.000         0.069         0.000         0.000         0.000   \n",
       "27         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    00200-target  00120-target  00111-target  00110-target  00102-target  \\\n",
       "29         0.000         0.000         0.000         0.000         0.000   \n",
       "38         0.000         0.000         0.000         0.000        -0.225   \n",
       "79         0.000         0.000         0.000        -0.717         0.000   \n",
       "19         0.000         0.000         0.000         0.000         0.000   \n",
       "27         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    00101-target  00100-target  00030-target  00021-target  00020-target  \\\n",
       "29         0.000         0.000         0.000         0.000         0.000   \n",
       "38         0.000         0.000         0.000         0.000         0.000   \n",
       "79         0.000         0.000         0.000         0.000         0.000   \n",
       "19         0.000         0.000         0.000         0.000         0.000   \n",
       "27         0.000         0.000         0.000         0.000         0.000   \n",
       "\n",
       "    00012-target  00011-target  00010-target  00003-target  00002-target  \\\n",
       "29         0.000         0.000         0.000         0.000         0.000   \n",
       "38         0.000         0.000         0.000         0.000         0.000   \n",
       "79         0.000         0.000         0.214         0.000         0.000   \n",
       "19         0.000         0.000         0.000         0.000         0.000   \n",
       "27         0.000         0.012         0.000        -0.436         0.000   \n",
       "\n",
       "    00001-target  00000-target  30000-lstsq_lambda  21000-lstsq_lambda  \\\n",
       "29         0.000         0.000               0.001               0.004   \n",
       "38         0.000         0.000              -0.035               0.078   \n",
       "79         0.000         0.000              -0.036              -0.071   \n",
       "19         0.000         0.000               0.036              -0.021   \n",
       "27         0.000         0.000               0.047               0.019   \n",
       "\n",
       "    20100-lstsq_lambda  20010-lstsq_lambda  20001-lstsq_lambda  \\\n",
       "29               0.004              -0.024              -0.323   \n",
       "38               0.026              -0.020              -0.058   \n",
       "79              -0.010               0.287              -0.028   \n",
       "19              -0.013              -0.016               0.036   \n",
       "27               0.035              -0.010              -0.049   \n",
       "\n",
       "    20000-lstsq_lambda  12000-lstsq_lambda  11100-lstsq_lambda  \\\n",
       "29              -0.027              -0.003               0.038   \n",
       "38               0.031              -0.005               0.014   \n",
       "79               0.139              -0.004              -0.031   \n",
       "19              -0.078               0.002              -0.021   \n",
       "27              -0.059               0.006               0.003   \n",
       "\n",
       "    11010-lstsq_lambda  11001-lstsq_lambda  11000-lstsq_lambda  \\\n",
       "29               0.006              -0.001              -0.019   \n",
       "38              -0.594              -0.002              -0.169   \n",
       "79               0.007              -0.022               0.099   \n",
       "19              -0.048               0.027               0.043   \n",
       "27               0.001              -0.047              -0.001   \n",
       "\n",
       "    10200-lstsq_lambda  10110-lstsq_lambda  10101-lstsq_lambda  \\\n",
       "29               0.061              -0.013               0.051   \n",
       "38               0.033              -0.005              -0.035   \n",
       "79               0.000               0.008               0.028   \n",
       "19               0.079              -0.138               0.046   \n",
       "27               0.051               0.001               0.005   \n",
       "\n",
       "    10100-lstsq_lambda  10020-lstsq_lambda  10011-lstsq_lambda  \\\n",
       "29              -0.101               0.740               0.045   \n",
       "38              -0.188              -0.012               0.018   \n",
       "79               0.009               0.007              -0.015   \n",
       "19              -0.020               0.035               0.010   \n",
       "27              -0.080              -0.023              -0.047   \n",
       "\n",
       "    10010-lstsq_lambda  10002-lstsq_lambda  10001-lstsq_lambda  \\\n",
       "29               0.197              -0.083               0.042   \n",
       "38              -0.045              -0.039               0.081   \n",
       "79              -0.700              -0.012               0.047   \n",
       "19               0.058               0.012              -0.851   \n",
       "27               0.067               0.334               0.099   \n",
       "\n",
       "    10000-lstsq_lambda  03000-lstsq_lambda  02100-lstsq_lambda  \\\n",
       "29              -0.001              -0.004               0.023   \n",
       "38               0.051              -0.094              -0.005   \n",
       "79              -0.115              -0.016               0.012   \n",
       "19              -0.505              -0.083              -0.133   \n",
       "27              -0.369               0.023              -0.003   \n",
       "\n",
       "    02010-lstsq_lambda  02001-lstsq_lambda  02000-lstsq_lambda  \\\n",
       "29               0.007               0.029               0.149   \n",
       "38              -0.008               0.026               0.120   \n",
       "79              -0.016              -0.034               0.045   \n",
       "19              -0.058              -0.064               0.905   \n",
       "27               0.002               0.036              -0.063   \n",
       "\n",
       "    01200-lstsq_lambda  01110-lstsq_lambda  01101-lstsq_lambda  \\\n",
       "29              -0.027               0.012              -0.036   \n",
       "38               0.244               0.022              -0.837   \n",
       "79               0.019               0.051               0.006   \n",
       "19              -0.077               0.698              -0.068   \n",
       "27              -0.002               0.031              -0.671   \n",
       "\n",
       "    01100-lstsq_lambda  01020-lstsq_lambda  01011-lstsq_lambda  \\\n",
       "29              -0.071              -0.002              -0.025   \n",
       "38              -0.006               0.067              -0.001   \n",
       "79              -0.031               0.009              -0.001   \n",
       "19               0.363              -0.028              -0.085   \n",
       "27              -0.087               0.044               0.040   \n",
       "\n",
       "    01010-lstsq_lambda  01002-lstsq_lambda  01001-lstsq_lambda  \\\n",
       "29              -0.061               0.015              -0.004   \n",
       "38              -0.167               0.020              -0.114   \n",
       "79              -0.030              -0.012               0.056   \n",
       "19               0.264               0.071               0.037   \n",
       "27              -0.085               0.014              -0.113   \n",
       "\n",
       "    01000-lstsq_lambda  00300-lstsq_lambda  00210-lstsq_lambda  \\\n",
       "29               0.066               0.002              -0.018   \n",
       "38               0.053               0.067              -0.095   \n",
       "79              -0.044               0.005               0.051   \n",
       "19              -0.180               0.034               0.107   \n",
       "27               0.097              -0.042               0.017   \n",
       "\n",
       "    00201-lstsq_lambda  00200-lstsq_lambda  00120-lstsq_lambda  \\\n",
       "29              -0.005              -0.015              -0.018   \n",
       "38              -0.015              -0.127              -0.011   \n",
       "79              -0.032              -0.061               0.030   \n",
       "19               0.076              -0.178               0.043   \n",
       "27               0.003               0.017               0.032   \n",
       "\n",
       "    00111-lstsq_lambda  00110-lstsq_lambda  00102-lstsq_lambda  \\\n",
       "29              -0.018              -0.023              -0.016   \n",
       "38               0.004               0.096              -0.084   \n",
       "79              -0.017              -0.789               0.020   \n",
       "19              -0.065               0.017               0.011   \n",
       "27              -0.022              -0.054              -0.046   \n",
       "\n",
       "    00101-lstsq_lambda  00100-lstsq_lambda  00030-lstsq_lambda  \\\n",
       "29               0.030               0.045               0.011   \n",
       "38              -0.160               0.103              -0.018   \n",
       "79              -0.070               0.057               0.021   \n",
       "19              -0.068               0.057               0.118   \n",
       "27              -0.015               0.055              -0.036   \n",
       "\n",
       "    00021-lstsq_lambda  00020-lstsq_lambda  00012-lstsq_lambda  \\\n",
       "29               0.025               0.042               0.055   \n",
       "38              -0.009              -0.004              -0.036   \n",
       "79              -0.009              -0.052               0.024   \n",
       "19               0.020              -0.261              -0.049   \n",
       "27               0.029               0.014              -0.088   \n",
       "\n",
       "    00011-lstsq_lambda  00010-lstsq_lambda  00003-lstsq_lambda  \\\n",
       "29              -0.031              -0.042               0.001   \n",
       "38               0.031               0.029               0.021   \n",
       "79               0.021               0.231               0.012   \n",
       "19               0.106               0.039              -0.042   \n",
       "27               0.101              -0.008              -0.314   \n",
       "\n",
       "    00002-lstsq_lambda  00001-lstsq_lambda  00000-lstsq_lambda  \\\n",
       "29               0.011              -0.033              -0.001   \n",
       "38              -0.081               0.088              -0.044   \n",
       "79              -0.017              -0.023               0.021   \n",
       "19               0.032              -0.005               0.015   \n",
       "27              -0.105               0.009              -0.012   \n",
       "\n",
       "    30000-lstsq_target  21000-lstsq_target  20100-lstsq_target  \\\n",
       "29              -0.000              -0.000               0.000   \n",
       "38              -0.000              -0.000              -0.000   \n",
       "79              -0.000              -0.000              -0.000   \n",
       "19              -0.000               0.000               0.000   \n",
       "27              -0.000               0.000              -0.000   \n",
       "\n",
       "    20010-lstsq_target  20001-lstsq_target  20000-lstsq_target  \\\n",
       "29              -0.000              -0.378               0.000   \n",
       "38              -0.000              -0.000               0.000   \n",
       "79               0.362               0.000               0.000   \n",
       "19              -0.000              -0.000               0.000   \n",
       "27              -0.000               0.000               0.000   \n",
       "\n",
       "    12000-lstsq_target  11100-lstsq_target  11010-lstsq_target  \\\n",
       "29              -0.000               0.000              -0.000   \n",
       "38              -0.000               0.000              -0.825   \n",
       "79              -0.000              -0.000               0.000   \n",
       "19              -0.000              -0.000              -0.000   \n",
       "27              -0.000              -0.000               0.000   \n",
       "\n",
       "    11001-lstsq_target  11000-lstsq_target  10200-lstsq_target  \\\n",
       "29              -0.000               0.000               0.000   \n",
       "38              -0.000               0.000              -0.153   \n",
       "79               0.000               0.000               0.000   \n",
       "19               0.000              -0.000               0.000   \n",
       "27               0.000               0.000               0.000   \n",
       "\n",
       "    10110-lstsq_target  10101-lstsq_target  10100-lstsq_target  \\\n",
       "29               0.000               0.000              -0.000   \n",
       "38               0.000               0.000               0.000   \n",
       "79               0.000               0.000              -0.000   \n",
       "19               0.000               0.000              -0.000   \n",
       "27               0.000              -0.000              -0.000   \n",
       "\n",
       "    10020-lstsq_target  10011-lstsq_target  10010-lstsq_target  \\\n",
       "29               0.893               0.107               0.000   \n",
       "38               0.000              -0.000               0.000   \n",
       "79               0.000               0.000              -0.775   \n",
       "19               0.000              -0.000               0.000   \n",
       "27               0.000               0.000               0.000   \n",
       "\n",
       "    10002-lstsq_target  10001-lstsq_target  10000-lstsq_target  \\\n",
       "29              -0.000               0.000              -0.000   \n",
       "38               0.000               0.000              -0.000   \n",
       "79               0.000              -0.000               0.000   \n",
       "19              -0.000              -0.770              -0.546   \n",
       "27               0.349              -0.000              -0.357   \n",
       "\n",
       "    03000-lstsq_target  02100-lstsq_target  02010-lstsq_target  \\\n",
       "29              -0.000              -0.000              -0.000   \n",
       "38               0.000               0.000               0.000   \n",
       "79               0.000              -0.000              -0.000   \n",
       "19               0.000              -0.000               0.000   \n",
       "27              -0.000               0.000              -0.000   \n",
       "\n",
       "    02001-lstsq_target  02000-lstsq_target  01200-lstsq_target  \\\n",
       "29              -0.000               0.189               0.000   \n",
       "38               0.000              -0.000               0.307   \n",
       "79              -0.000               0.000               0.000   \n",
       "19              -0.000               0.690              -0.000   \n",
       "27               0.000               0.000               0.000   \n",
       "\n",
       "    01110-lstsq_target  01101-lstsq_target  01100-lstsq_target  \\\n",
       "29              -0.146              -0.000               0.000   \n",
       "38              -0.000              -0.988               0.000   \n",
       "79               0.000               0.000              -0.000   \n",
       "19               0.927              -0.000               0.000   \n",
       "27               0.000              -0.824              -0.000   \n",
       "\n",
       "    01020-lstsq_target  01011-lstsq_target  01010-lstsq_target  \\\n",
       "29              -0.000               0.000               0.000   \n",
       "38              -0.000              -0.000               0.000   \n",
       "79               0.000               0.000              -0.000   \n",
       "19              -0.000              -0.000              -0.000   \n",
       "27               0.000              -0.000               0.000   \n",
       "\n",
       "    01002-lstsq_target  01001-lstsq_target  01000-lstsq_target  \\\n",
       "29              -0.000               0.000              -0.000   \n",
       "38              -0.000               0.000               0.000   \n",
       "79              -0.000              -0.000               0.000   \n",
       "19              -0.000               0.000               0.069   \n",
       "27              -0.000              -0.000              -0.000   \n",
       "\n",
       "    00300-lstsq_target  00210-lstsq_target  00201-lstsq_target  \\\n",
       "29              -0.000               0.000               0.000   \n",
       "38               0.000              -0.000              -0.000   \n",
       "79               0.000              -0.000              -0.085   \n",
       "19               0.000               0.000              -0.000   \n",
       "27              -0.000               0.000              -0.000   \n",
       "\n",
       "    00200-lstsq_target  00120-lstsq_target  00111-lstsq_target  \\\n",
       "29              -0.000               0.000               0.000   \n",
       "38              -0.000              -0.000              -0.000   \n",
       "79              -0.000              -0.000               0.000   \n",
       "19              -0.000              -0.000              -0.000   \n",
       "27               0.000              -0.000              -0.000   \n",
       "\n",
       "    00110-lstsq_target  00102-lstsq_target  00101-lstsq_target  \\\n",
       "29              -0.000               0.000              -0.000   \n",
       "38               0.000              -0.225               0.000   \n",
       "79              -0.717               0.000              -0.000   \n",
       "19              -0.000              -0.000               0.000   \n",
       "27               0.000              -0.000               0.000   \n",
       "\n",
       "    00100-lstsq_target  00030-lstsq_target  00021-lstsq_target  \\\n",
       "29               0.000              -0.000               0.000   \n",
       "38              -0.000              -0.000              -0.000   \n",
       "79               0.000               0.000               0.000   \n",
       "19               0.000               0.000              -0.000   \n",
       "27              -0.000               0.000              -0.000   \n",
       "\n",
       "    00020-lstsq_target  00012-lstsq_target  00011-lstsq_target  \\\n",
       "29               0.000              -0.000               0.000   \n",
       "38               0.000              -0.000               0.000   \n",
       "79              -0.000               0.000              -0.000   \n",
       "19               0.000               0.000               0.000   \n",
       "27              -0.000              -0.000               0.012   \n",
       "\n",
       "    00010-lstsq_target  00003-lstsq_target  00002-lstsq_target  \\\n",
       "29              -0.000               0.000              -0.000   \n",
       "38              -0.000              -0.000               0.000   \n",
       "79               0.214               0.000              -0.000   \n",
       "19              -0.000              -0.000               0.000   \n",
       "27              -0.000              -0.436               0.000   \n",
       "\n",
       "    00001-lstsq_target  00000-lstsq_target   wb_0   wb_1   wb_2  wb_3   wb_4  \\\n",
       "29               0.000               0.000 -0.331 -0.362  0.472 0.065  0.204   \n",
       "38              -0.000               0.000 -0.269  0.133 -0.146 0.144  0.084   \n",
       "79               0.000              -0.000  0.064  0.001 -0.026 0.352 -0.112   \n",
       "19              -0.000               0.000 -0.088  0.093  0.558 0.040  0.107   \n",
       "27              -0.000               0.000 -0.073 -0.073  0.237 0.122  0.168   \n",
       "\n",
       "     wb_5  wb_6   wb_7  wb_8  wb_9  wb_10  wb_11  wb_12  wb_13  wb_14  wb_15  \\\n",
       "29  0.191 0.235 -0.404 0.249 0.494  0.559 -0.275  0.186  0.334  0.186  0.392   \n",
       "38 -0.023 0.297 -0.262 0.112 0.128  0.025 -0.218 -0.065  0.423 -0.003  0.253   \n",
       "79  0.071 0.330 -0.388 0.242 0.280  0.577  0.017  0.135  0.402  0.082  0.507   \n",
       "19  0.002 0.379 -0.288 0.279 0.508  0.655 -0.003  0.056  0.434  0.002  0.580   \n",
       "27  0.120 0.178 -0.163 0.223 0.146  0.344 -0.119 -0.034  0.375  0.114  0.435   \n",
       "\n",
       "    wb_16  wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  wb_24  wb_25  \\\n",
       "29 -0.134  0.298  0.339 -0.010  0.030  0.116  0.348 -0.028 -0.396  0.016   \n",
       "38  0.020  0.152  0.378 -0.095  0.375  0.181  0.388  0.047 -0.468 -0.205   \n",
       "79  0.097  0.193  0.450  0.261  0.165  0.252 -0.170 -0.022 -0.458 -0.152   \n",
       "19 -0.031  0.103  0.474 -0.033 -0.026  0.366  0.038  0.140 -0.321 -0.137   \n",
       "27  0.056  0.210  0.281  0.099 -0.093  0.216  0.037  0.040 -0.424 -0.145   \n",
       "\n",
       "    wb_26  wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  wb_34  wb_35  \\\n",
       "29  0.046 -0.040 -0.339 -0.015  0.367  0.270  0.030  0.014 -0.016  0.015   \n",
       "38  0.178 -0.232  0.183 -0.328  0.235  0.435  0.091  0.196 -0.198 -0.464   \n",
       "79  0.015 -0.135 -0.121 -0.040  0.193  0.302  0.094  0.273  0.028 -0.146   \n",
       "19 -0.018 -0.077 -0.186 -0.000  0.271  0.233  0.074 -0.006 -0.179 -0.187   \n",
       "27  0.137 -0.044 -0.212 -0.234  0.281  0.422  0.070  0.306 -0.212 -0.513   \n",
       "\n",
       "    wb_36  wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  wb_44  wb_45  \\\n",
       "29 -0.378  0.058 -0.008 -0.122 -0.039  0.026  0.517 -0.045  0.591  0.166   \n",
       "38 -0.422  0.031 -0.062 -0.281  0.252  0.286  0.388 -0.242  0.527  0.196   \n",
       "79 -0.143  0.067 -0.116 -0.198  0.054  0.232  0.445 -0.057  0.362  0.034   \n",
       "19 -0.328 -0.104 -0.161 -0.109  0.042  0.536  0.568  0.062  0.628  0.516   \n",
       "27 -0.516  0.089 -0.067 -0.219  0.086  0.274  0.407 -0.277  0.443  0.027   \n",
       "\n",
       "    wb_46  wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  wb_54  wb_55  \\\n",
       "29 -0.041  0.136  0.234 -0.534  0.030  0.098 -0.059 -0.235 -0.028  0.428   \n",
       "38  0.217  0.415  0.316 -0.460 -0.137  0.157 -0.300 -0.516 -0.512  0.439   \n",
       "79  0.061  0.210  0.195 -0.481  0.073  0.260 -0.250  0.051 -0.453  0.380   \n",
       "19 -0.026  0.287  0.213 -0.543 -0.093  0.002 -0.108 -0.377 -0.158  0.321   \n",
       "27  0.143  0.287  0.323 -0.328 -0.099  0.105 -0.398 -0.298 -0.368  0.385   \n",
       "\n",
       "    wb_56  wb_57  wb_58  wb_59  wb_60  wb_61  wb_62  wb_63  wb_64  wb_65  \\\n",
       "29  0.419 -0.505  0.039 -0.009  0.131  0.174  0.359  0.040  0.298 -0.058   \n",
       "38  0.252 -0.307  0.177 -0.309  0.391  0.196  0.269  0.221  0.355 -0.035   \n",
       "79  0.507 -0.504  0.012 -0.064 -0.007  0.391  0.409  0.241  0.243 -0.033   \n",
       "19  0.315 -0.534  0.084 -0.192  0.264  0.313  0.448  0.239  0.399 -0.046   \n",
       "27  0.428  0.042  0.054 -0.284 -0.052  0.318  0.314  0.239  0.250  0.050   \n",
       "\n",
       "    wb_66  wb_67  wb_68  wb_69  wb_70  wb_71  wb_72  wb_73  wb_74  wb_75  \\\n",
       "29  0.023  0.392  0.078 -0.124  0.410 -0.130  0.173  0.411 -0.047  0.129   \n",
       "38 -0.403  0.339 -0.063 -0.159  0.023 -0.262  0.102  0.426 -0.062  0.171   \n",
       "79 -0.240  0.338  0.002 -0.244  0.471 -0.211 -0.427  0.486 -0.071  0.249   \n",
       "19  0.040  0.512  0.018  0.161  0.494 -0.200  0.328  0.315 -0.027  0.165   \n",
       "27 -0.341  0.339  0.025 -0.414  0.457 -0.209  0.265  0.453 -0.098  0.155   \n",
       "\n",
       "    wb_76  wb_77  wb_78  wb_79  wb_80  wb_81  wb_82  wb_83  wb_84  wb_85  \\\n",
       "29  0.371 -0.341  0.233  0.567  0.049  0.026  0.076 -0.101  0.355 -0.336   \n",
       "38  0.131 -0.298  0.152  0.174 -0.149 -0.098  0.009  0.119  0.171 -0.339   \n",
       "79  0.294 -0.240  0.405  0.499 -0.181  0.104 -0.059 -0.009  0.397 -0.202   \n",
       "19  0.286 -0.122  0.479  0.542  0.298  0.077  0.050 -0.037  0.264  0.047   \n",
       "27  0.101 -0.292  0.183  0.288  0.032 -0.006  0.021 -0.055 -0.014 -0.096   \n",
       "\n",
       "    wb_86  wb_87  wb_88  wb_89  wb_90  wb_91  wb_92  wb_93  wb_94  wb_95  \\\n",
       "29  0.150 -0.327 -0.416  0.380  0.266 -0.602 -0.069  0.205 -0.005 -0.259   \n",
       "38  0.058 -0.110 -0.087  0.265  0.263 -0.190 -0.121 -0.263 -0.188 -0.565   \n",
       "79  0.388 -0.211 -0.001  0.254  0.214 -0.282 -0.192 -0.216 -0.153 -0.590   \n",
       "19  0.214 -0.269 -0.123  0.350  0.109  0.148 -0.070  0.007  0.107 -0.074   \n",
       "27  0.079 -0.188 -0.067  0.331  0.049 -0.066 -0.133 -0.070 -0.020 -0.379   \n",
       "\n",
       "    wb_96  wb_97  wb_98  wb_99  wb_100  wb_101  wb_102  wb_103  wb_104  \\\n",
       "29 -0.102 -0.505  0.252 -0.312  -0.169   0.032   0.112  -0.545   0.034   \n",
       "38  0.107 -0.253  0.241 -0.362  -0.268   0.169  -0.109  -0.566   0.411   \n",
       "79  0.154 -0.414  0.270 -0.342  -0.080   0.108  -0.075  -0.111   0.082   \n",
       "19  0.075 -0.345  0.278 -0.351  -0.389   0.142   0.253   0.040   0.095   \n",
       "27  0.129 -0.053  0.279 -0.271  -0.390   0.349  -0.167  -0.440   0.282   \n",
       "\n",
       "    wb_105  wb_106  wb_107  wb_108  wb_109  wb_110  wb_111  wb_112  wb_113  \\\n",
       "29  -0.148  -0.189   0.162   0.130  -0.292  -0.112  -0.499   0.228   0.085   \n",
       "38  -0.405  -0.130   0.154   0.204  -0.398  -0.506  -0.559   0.345   0.188   \n",
       "79  -0.181  -0.212   0.172   0.009  -0.420  -0.043  -0.033   0.228   0.007   \n",
       "19   0.003  -0.086   0.131   0.290   0.055  -0.101   0.004   0.048   0.230   \n",
       "27  -0.255  -0.411   0.536   0.179  -0.379  -0.455  -0.254   0.344   0.146   \n",
       "\n",
       "    wb_114  wb_115  wb_116  wb_117  wb_118  wb_119  wb_120  wb_121  wb_122  \\\n",
       "29   0.227  -0.338  -0.016   0.371  -0.008  -0.009   0.190   0.420   0.126   \n",
       "38  -0.141  -0.013   0.199   0.159   0.092  -0.173  -0.177   0.671   0.211   \n",
       "79   0.235  -0.108   0.137   0.380  -0.019   0.126   0.004   0.446   0.042   \n",
       "19   0.202  -0.054   0.003   0.342  -0.491   0.008   0.024   0.363   0.006   \n",
       "27   0.048  -0.161   0.205   0.204   0.157  -0.174  -0.115   0.616   0.239   \n",
       "\n",
       "    wb_123  wb_124  wb_125  wb_126  wb_127  wb_128  wb_129  wb_130  wb_131  \\\n",
       "29  -0.121   0.245   0.290  -0.271  -0.077  -0.109  -0.520   0.027   0.002   \n",
       "38  -0.024   0.286  -0.008  -0.391   0.375  -0.042   0.274   0.009  -0.228   \n",
       "79  -0.188   0.295  -0.160  -0.236   0.419  -0.142   0.144   0.042  -0.075   \n",
       "19  -0.032   0.274  -0.084  -0.062   0.178   0.059   0.160  -0.553  -0.042   \n",
       "27   0.001   0.326  -0.089  -0.289   0.099   0.291   0.144   0.154  -0.080   \n",
       "\n",
       "    wb_132  wb_133  wb_134  wb_135  wb_136  wb_137  wb_138  wb_139  wb_140  \\\n",
       "29  -0.185  -0.216  -0.452   0.121  -0.157   0.124   0.092   0.045  -0.049   \n",
       "38  -0.208  -0.528   0.450   0.168  -0.152  -0.216   0.071   0.107  -0.468   \n",
       "79  -0.175  -0.051   0.101  -0.169  -0.389   0.080   0.044   0.086  -0.038   \n",
       "19  -0.195  -0.307   0.109   0.207  -0.282   0.021   0.046   0.127   0.037   \n",
       "27  -0.398  -0.060   0.527   0.117  -0.068  -0.052   0.016   0.124   0.013   \n",
       "\n",
       "    wb_141  wb_142  wb_143  wb_144  wb_145  wb_146  wb_147  wb_148  wb_149  \\\n",
       "29   0.295   0.031   0.052  -0.217   0.033   0.067   0.076   0.001  -0.160   \n",
       "38  -0.027   0.037   0.139   0.185  -0.054   0.013  -0.174  -0.101  -0.132   \n",
       "79   0.071   0.081   0.032   0.079   0.081   0.033   0.259  -0.147  -0.126   \n",
       "19  -0.219   0.140  -0.033  -0.520  -0.251  -0.282  -0.372  -0.056  -0.147   \n",
       "27  -0.186   0.095  -0.088   0.181   0.152   0.010  -0.502  -0.110  -0.162   \n",
       "\n",
       "    wb_150  wb_151  wb_152  wb_153  wb_154  wb_155  wb_156  wb_157  wb_158  \\\n",
       "29  -0.577  -0.581  -0.334  -0.180   0.819   0.316  -0.051  -0.292  -0.431   \n",
       "38  -0.263  -0.651  -0.444  -0.179   0.489   0.356  -0.123  -0.198  -1.127   \n",
       "79  -0.292  -0.388  -0.369  -0.248   0.387   0.201  -0.163  -0.313  -0.321   \n",
       "19  -0.217  -0.231  -0.523  -0.237   0.180   0.762  -0.031  -0.293  -0.654   \n",
       "27  -0.214  -0.498  -0.061  -0.320   0.239   0.292  -0.194  -0.715  -0.391   \n",
       "\n",
       "    wb_159  wb_160  wb_161  wb_162  wb_163  wb_164  wb_165  wb_166  wb_167  \\\n",
       "29   0.366  -0.124  -0.232  -0.482  -0.308   0.228   0.220   0.677   0.142   \n",
       "38  -0.332  -0.315  -0.254  -0.378  -0.288   0.219  -0.639   0.412   0.010   \n",
       "79   0.077   0.215  -0.490  -0.380  -0.260   0.152  -0.261   0.356   0.099   \n",
       "19  -0.088  -0.332  -0.258  -0.360  -0.320   0.203  -0.286   0.733   0.207   \n",
       "27  -0.408  -0.181  -0.154  -0.400  -0.255   0.170  -0.137   0.460   0.035   \n",
       "\n",
       "    wb_168  wb_169  wb_170  wb_171  wb_172  wb_173  wb_174  wb_175  \n",
       "29   0.292   0.325   0.040  -0.108  -0.119  -0.163  -0.254   0.043  \n",
       "38   0.510   0.308   0.207  -0.488  -0.220  -0.196  -0.316   0.073  \n",
       "79   0.491   0.171   0.303  -0.294  -0.173  -0.226  -0.331   0.090  \n",
       "19   0.640   0.793   0.351  -0.382  -0.394  -0.134  -0.234   0.141  \n",
       "27   0.298   0.314   0.129  -0.451  -0.498  -0.232  -0.207   0.127  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_test_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:27.555975Z",
     "iopub.status.busy": "2022-01-17T12:42:27.555281Z",
     "iopub.status.idle": "2022-01-17T12:42:27.560601Z",
     "shell.execute_reply": "2022-01-17T12:42:27.559274Z",
     "shell.execute_reply.started": "2022-01-17T12:42:27.555925Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:27.563630Z",
     "iopub.status.busy": "2022-01-17T12:42:27.562456Z",
     "iopub.status.idle": "2022-01-17T12:42:27.603799Z",
     "shell.execute_reply": "2022-01-17T12:42:27.602906Z",
     "shell.execute_reply.started": "2022-01-17T12:42:27.563586Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_train_dataset_list[0].weight_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:42:27.606281Z",
     "iopub.status.busy": "2022-01-17T12:42:27.605690Z",
     "iopub.status.idle": "2022-01-17T12:43:03.741044Z",
     "shell.execute_reply": "2022-01-17T12:43:03.739721Z",
     "shell.execute_reply.started": "2022-01-17T12:42:27.606237Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.2752 - r2_inet_lambda_fv_loss: 0.8760 - val_loss: 0.2522 - val_r2_inet_lambda_fv_loss: 3.5599\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3281 - r2_inet_lambda_fv_loss: 2.5649 - val_loss: 0.9729 - val_r2_inet_lambda_fv_loss: 73.7303\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.9886 - r2_inet_lambda_fv_loss: 30.3593 - val_loss: 0.2823 - val_r2_inet_lambda_fv_loss: 3.8817\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3028 - r2_inet_lambda_fv_loss: 1.4793 - val_loss: 0.1891 - val_r2_inet_lambda_fv_loss: 0.6849\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.2830 - r2_inet_lambda_fv_loss: 1.1599 - val_loss: 0.1900 - val_r2_inet_lambda_fv_loss: 0.5839\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2701 - r2_inet_lambda_fv_loss: 0.8805 - val_loss: 0.1945 - val_r2_inet_lambda_fv_loss: 0.7133\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2574 - r2_inet_lambda_fv_loss: 0.6588 - val_loss: 0.1998 - val_r2_inet_lambda_fv_loss: 0.8924\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2506 - r2_inet_lambda_fv_loss: 0.5684 - val_loss: 0.1771 - val_r2_inet_lambda_fv_loss: 0.4888\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.2399 - r2_inet_lambda_fv_loss: 0.4656 - val_loss: 0.1576 - val_r2_inet_lambda_fv_loss: 0.2638\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2256 - r2_inet_lambda_fv_loss: 0.3440 - val_loss: 0.1465 - val_r2_inet_lambda_fv_loss: 0.3173\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2165 - r2_inet_lambda_fv_loss: 0.2350 - val_loss: 0.1125 - val_r2_inet_lambda_fv_loss: 0.0506\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2152 - r2_inet_lambda_fv_loss: 0.2579 - val_loss: 0.1405 - val_r2_inet_lambda_fv_loss: 0.5176\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2120 - r2_inet_lambda_fv_loss: 0.2534 - val_loss: 0.1375 - val_r2_inet_lambda_fv_loss: 0.5050\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2311 - r2_inet_lambda_fv_loss: 0.5253 - val_loss: 0.1450 - val_r2_inet_lambda_fv_loss: 0.1566\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2083 - r2_inet_lambda_fv_loss: 0.1166 - val_loss: 0.1668 - val_r2_inet_lambda_fv_loss: 0.4609\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2155 - r2_inet_lambda_fv_loss: 0.2910 - val_loss: 0.1267 - val_r2_inet_lambda_fv_loss: -0.0907\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2019 - r2_inet_lambda_fv_loss: 0.0975 - val_loss: 0.1470 - val_r2_inet_lambda_fv_loss: 0.2266\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2115 - r2_inet_lambda_fv_loss: 0.2780 - val_loss: 0.1373 - val_r2_inet_lambda_fv_loss: -0.0286\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1972 - r2_inet_lambda_fv_loss: 0.0305 - val_loss: 0.1541 - val_r2_inet_lambda_fv_loss: 0.2470\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2011 - r2_inet_lambda_fv_loss: 0.0666 - val_loss: 0.1447 - val_r2_inet_lambda_fv_loss: 0.0971\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1933 - r2_inet_lambda_fv_loss: -0.0217 - val_loss: 0.1389 - val_r2_inet_lambda_fv_loss: 0.0021\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1926 - r2_inet_lambda_fv_loss: 0.0098 - val_loss: 0.1334 - val_r2_inet_lambda_fv_loss: -0.0582\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1867 - r2_inet_lambda_fv_loss: -0.0501 - val_loss: 0.1324 - val_r2_inet_lambda_fv_loss: -0.0195\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1846 - r2_inet_lambda_fv_loss: -0.0752 - val_loss: 0.1342 - val_r2_inet_lambda_fv_loss: 0.0256\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1834 - r2_inet_lambda_fv_loss: -0.0680 - val_loss: 0.1272 - val_r2_inet_lambda_fv_loss: -0.0949\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1806 - r2_inet_lambda_fv_loss: -0.1067 - val_loss: 0.1243 - val_r2_inet_lambda_fv_loss: -0.1362\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1805 - r2_inet_lambda_fv_loss: -0.1086 - val_loss: 0.1281 - val_r2_inet_lambda_fv_loss: -0.0828\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1768 - r2_inet_lambda_fv_loss: -0.1313 - val_loss: 0.1361 - val_r2_inet_lambda_fv_loss: 0.0712\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1772 - r2_inet_lambda_fv_loss: -0.1210 - val_loss: 0.1306 - val_r2_inet_lambda_fv_loss: -0.0643\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1763 - r2_inet_lambda_fv_loss: -0.1526 - val_loss: 0.1305 - val_r2_inet_lambda_fv_loss: -0.0557\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1814 - r2_inet_lambda_fv_loss: -0.0758 - val_loss: 0.1333 - val_r2_inet_lambda_fv_loss: -0.0345\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.1796 - r2_inet_lambda_fv_loss: -0.0796 - val_loss: 0.1289 - val_r2_inet_lambda_fv_loss: -0.0773\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1788 - r2_inet_lambda_fv_loss: -0.1037 - val_loss: 0.1325 - val_r2_inet_lambda_fv_loss: -0.0346\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.1792 - r2_inet_lambda_fv_loss: -0.1047 - val_loss: 0.1330 - val_r2_inet_lambda_fv_loss: -0.0391\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1766 - r2_inet_lambda_fv_loss: -0.1314 - val_loss: 0.1314 - val_r2_inet_lambda_fv_loss: -0.0610\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1755 - r2_inet_lambda_fv_loss: -0.1390 - val_loss: 0.1399 - val_r2_inet_lambda_fv_loss: -0.0049\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1728 - r2_inet_lambda_fv_loss: -0.1601 - val_loss: 0.1424 - val_r2_inet_lambda_fv_loss: 0.0709\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1771 - r2_inet_lambda_fv_loss: -0.1352 - val_loss: 0.1403 - val_r2_inet_lambda_fv_loss: 0.0424\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1790 - r2_inet_lambda_fv_loss: -0.1187 - val_loss: 0.1362 - val_r2_inet_lambda_fv_loss: -0.0505\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1869 - r2_inet_lambda_fv_loss: -0.0546 - val_loss: 0.1355 - val_r2_inet_lambda_fv_loss: -0.0644\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1913 - r2_inet_lambda_fv_loss: -0.0238 - val_loss: 0.1420 - val_r2_inet_lambda_fv_loss: 0.0688\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1907 - r2_inet_lambda_fv_loss: -0.0394 - val_loss: 0.1447 - val_r2_inet_lambda_fv_loss: 0.1265\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1945 - r2_inet_lambda_fv_loss: -0.0230 - val_loss: 0.1471 - val_r2_inet_lambda_fv_loss: 0.1743\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1934 - r2_inet_lambda_fv_loss: -0.0057 - val_loss: 0.1440 - val_r2_inet_lambda_fv_loss: 0.1115\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1939 - r2_inet_lambda_fv_loss: -0.0096 - val_loss: 0.1471 - val_r2_inet_lambda_fv_loss: 0.1345\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1931 - r2_inet_lambda_fv_loss: -0.0100 - val_loss: 0.1440 - val_r2_inet_lambda_fv_loss: 0.1078\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1884 - r2_inet_lambda_fv_loss: -0.0626 - val_loss: 0.1335 - val_r2_inet_lambda_fv_loss: -0.0026\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1877 - r2_inet_lambda_fv_loss: -0.0585 - val_loss: 0.1339 - val_r2_inet_lambda_fv_loss: 0.0634\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1855 - r2_inet_lambda_fv_loss: -0.0589 - val_loss: 0.1307 - val_r2_inet_lambda_fv_loss: -0.0339\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1844 - r2_inet_lambda_fv_loss: -0.0728 - val_loss: 0.1328 - val_r2_inet_lambda_fv_loss: -0.0298\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1818 - r2_inet_lambda_fv_loss: -0.1048 - val_loss: 0.1405 - val_r2_inet_lambda_fv_loss: 0.0722\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1843 - r2_inet_lambda_fv_loss: -0.0951 - val_loss: 0.1347 - val_r2_inet_lambda_fv_loss: 0.0251\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1827 - r2_inet_lambda_fv_loss: -0.1098 - val_loss: 0.1280 - val_r2_inet_lambda_fv_loss: -0.0151\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1838 - r2_inet_lambda_fv_loss: -0.0909 - val_loss: 0.1263 - val_r2_inet_lambda_fv_loss: -0.0075\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1862 - r2_inet_lambda_fv_loss: -0.0900 - val_loss: 0.1352 - val_r2_inet_lambda_fv_loss: 0.0523\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1826 - r2_inet_lambda_fv_loss: -0.1307 - val_loss: 0.1407 - val_r2_inet_lambda_fv_loss: 0.0817\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1873 - r2_inet_lambda_fv_loss: -0.0827 - val_loss: 0.1386 - val_r2_inet_lambda_fv_loss: 0.0539\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1860 - r2_inet_lambda_fv_loss: -0.0908 - val_loss: 0.1344 - val_r2_inet_lambda_fv_loss: 0.0213\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1808 - r2_inet_lambda_fv_loss: -0.1310 - val_loss: 0.1235 - val_r2_inet_lambda_fv_loss: -0.0890\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1763 - r2_inet_lambda_fv_loss: -0.1700 - val_loss: 0.1143 - val_r2_inet_lambda_fv_loss: -0.1952\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1757 - r2_inet_lambda_fv_loss: -0.1737 - val_loss: 0.1150 - val_r2_inet_lambda_fv_loss: -0.1871\n",
      "Training Time: 0:00:33\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "((X_valid_list, y_valid_list), \n",
    " (X_test_list, y_test_list),\n",
    " history_list, \n",
    "\n",
    " #scores_valid_list,\n",
    " #scores_test_list, \n",
    "\n",
    " #function_values_valid_list, \n",
    " #function_values_test_list, \n",
    "\n",
    " #polynomial_dict_valid_list,\n",
    " #polynomial_dict_test_list,\n",
    "\n",
    " #distrib_dict_valid_list,\n",
    " #distrib_dict_test_list,\n",
    "\n",
    " model_list) = interpretation_net_training(lambda_net_train_dataset_list, \n",
    "                                           lambda_net_valid_dataset_list, \n",
    "                                           lambda_net_test_dataset_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:43:03.742882Z",
     "iopub.status.busy": "2022-01-17T12:43:03.742610Z",
     "iopub.status.idle": "2022-01-17T12:43:03.772794Z",
     "shell.execute_reply": "2022-01-17T12:43:03.771254Z",
     "shell.execute_reply.started": "2022-01-17T12:43:03.742849Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 176)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_4096 (Dense)            (None, 4096)         724992      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation1_relu (Activation)   (None, 4096)         0           hidden1_4096[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_2048 (Dense)            (None, 2048)         8390656     activation1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation2_relu (Activation)   (None, 2048)         0           hidden2_2048[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "hidden3_1024 (Dense)            (None, 1024)         2098176     activation2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation3_relu (Activation)   (None, 1024)         0           hidden3_1024[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "hidden4_512 (Dense)             (None, 512)          524800      activation3_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation4_relu (Activation)   (None, 512)          0           hidden4_512[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_coeff_5 (Dense)          (None, 5)            2565        activation4_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier1_56 (Dense)   (None, 56)           28728       activation4_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier2_56 (Dense)   (None, 56)           28728       activation4_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier3_56 (Dense)   (None, 56)           28728       activation4_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier4_56 (Dense)   (None, 56)           28728       activation4_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier5_56 (Dense)   (None, 56)           28728       activation4_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_combined (Concatenate)   (None, 285)          0           output_coeff_5[0][0]             \n",
      "                                                                 output_identifier1_56[0][0]      \n",
      "                                                                 output_identifier2_56[0][0]      \n",
      "                                                                 output_identifier3_56[0][0]      \n",
      "                                                                 output_identifier4_56[0][0]      \n",
      "                                                                 output_identifier5_56[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 11,884,829\n",
      "Trainable params: 11,884,829\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_list[-1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:43:03.775392Z",
     "iopub.status.busy": "2022-01-17T12:43:03.774773Z",
     "iopub.status.idle": "2022-01-17T12:43:03.874204Z",
     "shell.execute_reply": "2022-01-17T12:43:03.871729Z",
     "shell.execute_reply.started": "2022-01-17T12:43:03.775347Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#polynomial_dict_valid_list = []\n",
    "polynomial_dict_test_list = []  \n",
    "runtimes_list = []\n",
    "\n",
    "for lambda_net_valid_dataset, lambda_net_test_dataset in zip(lambda_net_valid_dataset_list, lambda_net_test_dataset_list):\n",
    "\n",
    "    #polynomial_dict_valid = {'lstsq_lambda_pred_polynomials': lambda_net_valid_dataset.lstsq_lambda_pred_polynomial_list,\n",
    "    #                        'lstsq_target_polynomials': lambda_net_valid_dataset.lstsq_target_polynomial_list,\n",
    "    #                        'target_polynomials': lambda_net_valid_dataset.target_polynomial_list}    \n",
    "\n",
    "    polynomial_dict_test = {'lstsq_lambda_pred_polynomials': lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list,\n",
    "                            'lstsq_target_polynomials': lambda_net_test_dataset.lstsq_target_polynomial_list,\n",
    "                            'target_polynomials': lambda_net_test_dataset.target_polynomial_list}    \n",
    "\n",
    "    #polynomial_dict_valid_list.append(polynomial_dict_valid)  \n",
    "    polynomial_dict_test_list.append(polynomial_dict_test)\n",
    "    runtimes_list.append({})\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:43:03.878130Z",
     "iopub.status.busy": "2022-01-17T12:43:03.875446Z",
     "iopub.status.idle": "2022-01-17T12:43:04.173130Z",
     "shell.execute_reply": "2022-01-17T12:43:04.172089Z",
     "shell.execute_reply.started": "2022-01-17T12:43:03.878081Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------- PREDICT INET ------------------------------------------------------\n",
      "Predict Time: 0:00:00\n",
      "---------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------- PREDICT INET ------------------------------------------------------')\n",
    "\n",
    "start = time.time() \n",
    "\n",
    "for i, (X_test, model) in enumerate(zip(X_test_list, model_list)):\n",
    "    #y_test_pred = model.predict(X_test)    \n",
    "    #print(model.summary())\n",
    "    #print(X_test.shape)\n",
    "    y_test_pred, inet_runtime = make_inet_prediction(model, X_test, network_data=None, lambda_trained_normalized=False, inet_training_normalized=normalize_inet_data, normalization_parameter_dict=None)\n",
    "    #print(y_test_pred.shape)   \n",
    "    polynomial_dict_test_list[i]['inet_polynomials'] = y_test_pred\n",
    "    runtimes_list[i]['inet_runtime'] =  np.array([inet_runtime/len(lambda_net_test_dataset.target_polynomial_list) for _ in range(len(lambda_net_test_dataset.target_polynomial_list))])\n",
    "    \n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('Predict Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:43:04.182300Z",
     "iopub.status.busy": "2022-01-17T12:43:04.177511Z",
     "iopub.status.idle": "2022-01-17T12:43:04.196444Z",
     "shell.execute_reply": "2022-01-17T12:43:04.194845Z",
     "shell.execute_reply.started": "2022-01-17T12:43:04.181696Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    if symbolic_metamodeling_poly_evaluation:\n",
    "        print('-------------------------------------------------- CALCULATE METAMODEL POLY -----------------------------------------------')\n",
    "\n",
    "        start = time.time() \n",
    "\n",
    "        for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "            metamodel_functions_test, metamodel_runtimes = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=False, force_polynomial=True)\n",
    "            polynomial_dict_test_list[i]['metamodel_poly'] = metamodel_functions_test     \n",
    "            runtimes_list[i]['metamodel_poly_runtime'] = metamodel_runtimes\n",
    "\n",
    "        end = time.time()     \n",
    "        inet_train_time = (end - start) \n",
    "        minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "        hours, minutes = divmod(minutes, 60)        \n",
    "        print('Metamodel Poly Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "        print('---------------------------------------------------------------------------------------------------------------------------') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:43:04.198258Z",
     "iopub.status.busy": "2022-01-17T12:43:04.197816Z",
     "iopub.status.idle": "2022-01-17T12:43:04.291381Z",
     "shell.execute_reply": "2022-01-17T12:43:04.289982Z",
     "shell.execute_reply.started": "2022-01-17T12:43:04.198218Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    if symbolic_metamodeling_evaluation:\n",
    "        print('---------------------------------------------------- CALCULATE METAMODEL --------------------------------------------------')\n",
    "\n",
    "        start = time.time() \n",
    "\n",
    "        for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "            metamodel_functions_test, metamodel_runtimes = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=False, force_polynomial=False)\n",
    "            polynomial_dict_test_list[i]['metamodel_functions'] = metamodel_functions_test       \n",
    "            runtimes_list[i]['metamodel_functions_runtime'] = metamodel_runtimes\n",
    "\n",
    "        end = time.time()     \n",
    "        inet_train_time = (end - start) \n",
    "        minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "        hours, minutes = divmod(minutes, 60)        \n",
    "        print('Metamodel Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "        print('---------------------------------------------------------------------------------------------------------------------------') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:43:04.294781Z",
     "iopub.status.busy": "2022-01-17T12:43:04.293595Z",
     "iopub.status.idle": "2022-01-17T12:43:04.442141Z",
     "shell.execute_reply": "2022-01-17T12:43:04.441034Z",
     "shell.execute_reply.started": "2022-01-17T12:43:04.294740Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    if symbolic_metamodeling_function_evaluation:\n",
    "        print('----------------------------------------------- CALCULATE METAMODEL FUNCTION ----------------------------------------------')\n",
    "\n",
    "        start = time.time() \n",
    "\n",
    "        for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "            metamodel_functions_test, metamodel_runtimes = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=True)\n",
    "            polynomial_dict_test_list[i]['metamodel_functions_no_GD'] = metamodel_functions_test   \n",
    "            runtimes_list[i]['metamodel_functions_no_GD_runtime'] = metamodel_runtimes\n",
    "\n",
    "        end = time.time()     \n",
    "        inet_train_time = (end - start) \n",
    "        minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "        hours, minutes = divmod(minutes, 60)        \n",
    "        print('Metamodel Function Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "        print('---------------------------------------------------------------------------------------------------------------------------') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T12:43:04.445318Z",
     "iopub.status.busy": "2022-01-17T12:43:04.443786Z",
     "iopub.status.idle": "2022-01-17T12:48:56.801490Z",
     "shell.execute_reply": "2022-01-17T12:48:56.794625Z",
     "shell.execute_reply.started": "2022-01-17T12:43:04.445268Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- CALCULATE SYMBOLIC REGRESSION FUNCTION ------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "2022-01-17 13:43:13.641414: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 13:43:13.735808: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 13:43:13.985346: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 13:43:14.099126: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 13:43:14.099125: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 13:43:14.117211: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 13:43:14.170400: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 13:43:14.208673: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 13:43:14.246954: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 13:43:14.271520: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "[Parallel(n_jobs=10)]: Done   1 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done   2 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done   3 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done   4 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=10)]: Done   6 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=10)]: Done   7 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=10)]: Done   8 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=10)]: Done   9 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=10)]: Done  10 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=10)]: Done  11 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=10)]: Done  13 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=10)]: Done  14 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=10)]: Done  15 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=10)]: Done  16 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=10)]: Done  17 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=10)]: Done  18 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=10)]: Done  19 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  20 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  22 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  23 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  24 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  25 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  26 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  27 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  28 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  29 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  31 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=10)]: Done  35 out of  38 | elapsed:  5.8min remaining:   29.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3998708/2114250694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_net_test_dataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_net_test_dataset_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0msymbolic_regression_functions_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_regression_runtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbolic_regression_function_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_net_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mpolynomial_dict_test_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symbolic_regression_functions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbolic_regression_functions_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mruntimes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symbolic_regression_runtime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbolic_regression_runtimes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work-ceph/smarton/InES_XAI/02_polynomials/utilities/InterpretationNet.py\u001b[0m in \u001b[0;36msymbolic_regression_function_generation\u001b[0;34m(lambda_net_dataset, backend)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0mreturn_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m     result_list_symbolic_regression = parallel_symbolic_regression(delayed(symbolic_regression)(lambda_net, \n\u001b[0m\u001b[1;32m   1298\u001b[0m                                                                                   \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                                                                                   \u001b[0msymbolic_regression_hyperparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    if symbolic_regression_evaluation:\n",
    "        print('----------------------------------------- CALCULATE SYMBOLIC REGRESSION FUNCTION ------------------------------------------')\n",
    "\n",
    "        start = time.time() \n",
    "\n",
    "        for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "            symbolic_regression_functions_test, symbolic_regression_runtimes = symbolic_regression_function_generation(lambda_net_test_dataset)\n",
    "            polynomial_dict_test_list[i]['symbolic_regression_functions'] = symbolic_regression_functions_test    \n",
    "            runtimes_list[i]['symbolic_regression_runtime'] = symbolic_regression_runtimes\n",
    "\n",
    "        end = time.time()     \n",
    "        inet_train_time = (end - start) \n",
    "        minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "        hours, minutes = divmod(minutes, 60)        \n",
    "        print('Symbolic Regression Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "        print('---------------------------------------------------------------------------------------------------------------------------')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.802730Z",
     "iopub.status.idle": "2022-01-17T12:48:56.803490Z",
     "shell.execute_reply": "2022-01-17T12:48:56.803223Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.803190Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.805176Z",
     "iopub.status.idle": "2022-01-17T12:48:56.805800Z",
     "shell.execute_reply": "2022-01-17T12:48:56.805531Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.805502Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "with tf.device('/CPU:0'):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    if polynomial_regression_evaluation:\n",
    "        print('----------------------------------------- CALCULATE POLYNOMIAL REGRESSION FUNCTION ------------------------------------------')\n",
    "\n",
    "        start = time.time() \n",
    "\n",
    "        for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "            polynomial_regression_functions_test, polynomial_regression_runtimes = polynomial_regression_function_generation(lambda_net_test_dataset)\n",
    "            polynomial_dict_test_list[i]['polynomial_regression_functions'] = polynomial_regression_functions_test    \n",
    "            runtimes_list[i]['polynomial_regression_runtime'] = polynomial_regression_runtimes\n",
    "\n",
    "        end = time.time()     \n",
    "        inet_train_time = (end - start) \n",
    "        minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "        hours, minutes = divmod(minutes, 60)        \n",
    "        print('Polynomial Regression Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "        print('---------------------------------------------------------------------------------------------------------------------------')    \n",
    "    #os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.807250Z",
     "iopub.status.idle": "2022-01-17T12:48:56.807950Z",
     "shell.execute_reply": "2022-01-17T12:48:56.807735Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.807711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "with tf.device('/CPU:0'):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    if per_network_evaluation:\n",
    "        print('------------------------------------------------ CALCULATE PER NETWORK POLY -----------------------------------------------')\n",
    "\n",
    "        start = time.time() \n",
    "\n",
    "        for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "            per_network_poly_test = per_network_poly_generation(lambda_net_test_dataset, optimization_type='scipy')\n",
    "            polynomial_dict_test_list[i]['per_network_polynomials'] = per_network_poly_test       \n",
    "\n",
    "        end = time.time()     \n",
    "        inet_train_time = (end - start) \n",
    "        minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "        hours, minutes = divmod(minutes, 60)        \n",
    "        print('Per Network Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "        print('---------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.808898Z",
     "iopub.status.idle": "2022-01-17T12:48:56.809375Z",
     "shell.execute_reply": "2022-01-17T12:48:56.809121Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.809102Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.812418Z",
     "iopub.status.idle": "2022-01-17T12:48:56.812849Z",
     "shell.execute_reply": "2022-01-17T12:48:56.812612Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.812584Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('------------------------------------------------ CALCULATE FUNCTION VALUES ------------------------------------------------')                \n",
    "\n",
    "start = time.time() \n",
    "\n",
    "function_values_test_list = []\n",
    "for lambda_net_test_dataset, polynomial_dict_test in zip(lambda_net_test_dataset_list, polynomial_dict_test_list):\n",
    "    function_values_test = calculate_all_function_values(lambda_net_test_dataset, polynomial_dict_test)\n",
    "    function_values_test_list.append(function_values_test)\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('FV Calculation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.814936Z",
     "iopub.status.idle": "2022-01-17T12:48:56.815472Z",
     "shell.execute_reply": "2022-01-17T12:48:56.815211Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.815190Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('----------------------------------------------------- CALCULATE SCORES ----------------------------------------------------')                \n",
    "\n",
    "start = time.time() \n",
    "\n",
    "scores_test_list = []\n",
    "distrib_dict_test_list = []\n",
    "runtime_distrib_list = []\n",
    "for function_values_test, polynomial_dict_test, runtimes_dict in zip(function_values_test_list, polynomial_dict_test_list, runtimes_list):\n",
    "    scores_test, distrib_test = evaluate_all_predictions(function_values_test, polynomial_dict_test)\n",
    "    scores_test_list.append(scores_test)\n",
    "    distrib_dict_test_list.append(distrib_test)\n",
    "    runtimes_list.append(pd.DataFrame(runtimes_dict))\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('Score Calculation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.816688Z",
     "iopub.status.idle": "2022-01-17T12:48:56.817902Z",
     "shell.execute_reply": "2022-01-17T12:48:56.817622Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.817588Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_type = 'epochs' if samples_list == None else 'samples'\n",
    "save_results(scores_list=scores_test_list, by=identifier_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Interpretation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.819032Z",
     "iopub.status.idle": "2022-01-17T12:48:56.819709Z",
     "shell.execute_reply": "2022-01-17T12:48:56.819424Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.819388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if nas:\n",
    "    for trial in history_list[-1]: \n",
    "        print(trial.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.821353Z",
     "iopub.status.idle": "2022-01-17T12:48:56.821933Z",
     "shell.execute_reply": "2022-01-17T12:48:56.821691Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.821669Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(model_list) >= 1:\n",
    "    print(model_list[-1].summary())\n",
    "    print(model_list[-1].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.824284Z",
     "iopub.status.idle": "2022-01-17T12:48:56.826831Z",
     "shell.execute_reply": "2022-01-17T12:48:56.826481Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.826449Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if evaluate_with_real_function:\n",
    "    keys = ['inetPoly_VS_targetPoly_test', 'perNetworkPoly_VS_targetPoly_test', 'predLambda_VS_targetPoly_test', 'lstsqLambda_VS_targetPoly_test', 'lstsqTarget_VS_targetPoly_test']\n",
    "else:\n",
    "    keys = ['inetPoly_VS_predLambda_test', 'inetPoly_VS_lstsqLambda_test', 'perNetworkPoly_VS_predLambda_test', 'perNetworkPoly_VS_lstsqLambda_test', 'lstsqLambda_VS_predLambda_test', 'predLambda_VS_targetPoly_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.828171Z",
     "iopub.status.idle": "2022-01-17T12:48:56.829269Z",
     "shell.execute_reply": "2022-01-17T12:48:56.828441Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.828412Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#0.183\t0.234\t3.604\t0.143\t0.687\t2.559\t0.215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: INET NORMALIZATION TESTEN\n",
    "# LARGER TRAINING DATA TESTEN\n",
    "# FUNCTION SHIFTING TESTEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.830811Z",
     "iopub.status.idle": "2022-01-17T12:48:56.831688Z",
     "shell.execute_reply": "2022-01-17T12:48:56.831402Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.831370Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_test_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:55.162513Z",
     "start_time": "2021-01-08T11:56:54.472198Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.835273Z",
     "iopub.status.idle": "2022-01-17T12:48:56.835755Z",
     "shell.execute_reply": "2022-01-17T12:48:56.835504Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.835473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:56.434915Z",
     "start_time": "2021-01-08T11:56:55.669304Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.838462Z",
     "iopub.status.idle": "2022-01-17T12:48:56.838937Z",
     "shell.execute_reply": "2022-01-17T12:48:56.838713Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.838687Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.839958Z",
     "iopub.status.idle": "2022-01-17T12:48:56.840520Z",
     "shell.execute_reply": "2022-01-17T12:48:56.840199Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.840170Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtimes_list[-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.841540Z",
     "iopub.status.idle": "2022-01-17T12:48:56.842248Z",
     "shell.execute_reply": "2022-01-17T12:48:56.841994Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.841966Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths_dict = generate_paths(config, path_type = 'interpretation_net')\n",
    "\n",
    "path_mae = './data/results/' + paths_dict['path_identifier_interpretation_net_data'] + '/mae_distrib_test_data_' + 'noise' + str(noise) + '_size' + str(interpretation_dataset_size) + '_' + str(function_generation_type) + '.csv'\n",
    "path_r2 = './data/results/' + paths_dict['path_identifier_interpretation_net_data'] + '/r2_distrib_test_data_' + 'noise' + str(noise) + '_size' + str(interpretation_dataset_size) + '_' + str(function_generation_type) + '.csv'\n",
    "path_runtimes = './data/results/' + paths_dict['path_identifier_interpretation_net_data'] + '/runtimes_' + 'noise' + str(noise) + '_size' + str(interpretation_dataset_size) + '_' + str(function_generation_type) + '.csv'\n",
    "path_fv = './data/results/' + paths_dict['path_identifier_interpretation_net_data'] + '/fvs_' + 'noise' + str(noise) + '_size' + str(interpretation_dataset_size) + '_' + str(function_generation_type) + '.csv'\n",
    "path_functions = './data/results/' + paths_dict['path_identifier_interpretation_net_data'] + '/functions_' + 'noise' + str(noise) + '_size' + str(interpretation_dataset_size) + '_' + str(function_generation_type) + '.csv'\n",
    "\n",
    "\n",
    "distrib_dict_test_list[-1]['MAE'].to_csv(path_mae)\n",
    "distrib_dict_test_list[-1]['R2'].to_csv(path_r2)\n",
    "runtimes_list[-1].to_csv(path_runtimes)\n",
    "\n",
    "with open(path_fv, 'wb') as f:\n",
    "    pickle.dump(function_values_test_list[-1], f, protocol=2)\n",
    "\n",
    "with open(path_functions, 'wb') as f:\n",
    "    pickle.dump(polynomial_dict_test_list[-1], f, protocol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.410283Z",
     "start_time": "2021-01-07T15:49:48.254228Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.844461Z",
     "iopub.status.idle": "2022-01-17T12:48:56.845604Z",
     "shell.execute_reply": "2022-01-17T12:48:56.845332Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.845300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history[list(history.keys())[1]])\n",
    "    try:\n",
    "        plt.plot(history[list(history.keys())[len(history.keys())//2+1]]) \n",
    "    except:\n",
    "        pass\n",
    "    plt.title('model ' + list(history.keys())[1])\n",
    "    plt.ylabel('metric')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/metric_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.567983Z",
     "start_time": "2021-01-07T15:49:48.413234Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.847014Z",
     "iopub.status.idle": "2022-01-17T12:48:56.847902Z",
     "shell.execute_reply": "2022-01-17T12:48:56.847561Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.847530Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    try:\n",
    "        plt.plot(history['val_loss'])\n",
    "    except:\n",
    "        pass\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/loss_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Epoch/Sampes Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Comparison Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.848810Z",
     "iopub.status.idle": "2022-01-17T12:48:56.849437Z",
     "shell.execute_reply": "2022-01-17T12:48:56.849159Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.849126Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.851130Z",
     "iopub.status.idle": "2022-01-17T12:48:56.851744Z",
     "shell.execute_reply": "2022-01-17T12:48:56.851492Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.851343Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['MAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.853776Z",
     "iopub.status.idle": "2022-01-17T12:48:56.854469Z",
     "shell.execute_reply": "2022-01-17T12:48:56.854195Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.854159Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['R2 FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list, ylim=(-5, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate and Analyze Predictions for Random Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.856535Z",
     "iopub.status.idle": "2022-01-17T12:48:56.856996Z",
     "shell.execute_reply": "2022-01-17T12:48:56.856771Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.856746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 5\n",
    "\n",
    "custom_representation_keys_fixed = ['target_polynomials']#['target_polynomials', 'lstsq_target_polynomials', 'lstsq_lambda_pred_polynomials']\n",
    "custom_representation_keys_dynamic = ['inet_polynomials', 'per_network_polynomials']\n",
    "sympy_representation_keys = ['metamodel_functions', 'symbolic_regression_functions', 'polynomial_regression_functions']\n",
    "\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "for key in polynomial_dict_test_list[-1].keys():\n",
    "    if key in custom_representation_keys_fixed:\n",
    "        print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "        print(key)        \n",
    "        print_polynomial_from_coefficients(polynomial_dict_test_list[-1][key][index], force_complete_poly_representation=True, round_digits=4)\n",
    "        print('MAE: ', distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_' + key][index])\n",
    "        #print(polynomial_dict_test_list[-1][key][index])\n",
    "    elif key in custom_representation_keys_dynamic:\n",
    "        print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "        print(key)              \n",
    "        print_polynomial_from_coefficients(polynomial_dict_test_list[-1][key][index], round_digits=4)\n",
    "        print('MAE: ', distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_' + key][index])\n",
    "        #print(polynomial_dict_test_list[-1][key][index])\n",
    "    elif key in sympy_representation_keys:\n",
    "        print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "        print(key)              \n",
    "        display(polynomial_dict_test_list[-1][key][index])\n",
    "        print('MAE: ', distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_' + key][index])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.859020Z",
     "iopub.status.idle": "2022-01-17T12:48:56.859570Z",
     "shell.execute_reply": "2022-01-17T12:48:56.859295Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.859266Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sym.expand(sympify('x1*x2*(x3+x4)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.861603Z",
     "iopub.status.idle": "2022-01-17T12:48:56.862265Z",
     "shell.execute_reply": "2022-01-17T12:48:56.861851Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.861821Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "for key in polynomial_dict_test_list[-1].keys():\n",
    "    terms = []\n",
    "    \n",
    "    if key not in list(flatten([custom_representation_keys_fixed, custom_representation_keys_dynamic, sympy_representation_keys])):\n",
    "        continue\n",
    "    \n",
    "    for index in range(5): #test_size\n",
    "        if key in custom_representation_keys_fixed:\n",
    "            string = str(round_expr(sym.expand(get_sympy_string_from_coefficients(polynomial_dict_test_list[-1][key][index], force_complete_poly_representation=True, round_digits=4)), 4))\n",
    "        elif key in custom_representation_keys_dynamic:\n",
    "            string = str(round_expr(sym.expand(get_sympy_string_from_coefficients(polynomial_dict_test_list[-1][key][index], round_digits=4)), 4))\n",
    "        elif key in sympy_representation_keys:\n",
    "            string = str(round_expr(sym.expand(polynomial_dict_test_list[-1][key][index]), 4))\n",
    "\n",
    "        #print('string', string)\n",
    "            \n",
    "        try:\n",
    "            str_split = string.split('-')\n",
    "\n",
    "            str_split_2 = []\n",
    "            for split in str_split:\n",
    "                str_split_2.append(split.split('+'))\n",
    "\n",
    "            str_split_2 = list(flatten(str_split_2))\n",
    "            terms.append(len(str_split_2))\n",
    "        except:\n",
    "            pass        \n",
    "\n",
    "    print(terms)\n",
    "    terms_array = np.array(terms)\n",
    "    print(key)          \n",
    "    print('Complexity: ', np.mean(terms_array))\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.863797Z",
     "iopub.status.idle": "2022-01-17T12:48:56.865589Z",
     "shell.execute_reply": "2022-01-17T12:48:56.865315Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.865283Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Target Poly: ', str(get_sympy_string_from_coefficients(polynomial_dict_test_list[-1]['target_polynomials'][index], force_complete_poly_representation=True, round_digits=4)))\n",
    "print('Inet Poly: ', str(round_expr(get_sympy_string_from_coefficients(polynomial_dict_test_list[-1]['inet_polynomials'][index], round_digits=4), 4)))\n",
    "\n",
    "try:\n",
    "    print('SR Function: ', str(round_expr(polynomial_dict_test_list[-1]['symbolic_regression_functions'][index], 4)))\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    print('PR Poly: ', str(round_expr(polynomial_dict_test_list[-1]['polynomial_regression_functions'][index], 4)))\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    print('SM Poly: ', str(round_expr(polynomial_dict_test_list[-1]['metamodel_poly'][index], 10)))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    print('SM Function: ', str(round_expr(polynomial_dict_test_list[-1]['metamodel_functions'][index], 10)))\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.867025Z",
     "iopub.status.idle": "2022-01-17T12:48:56.868400Z",
     "shell.execute_reply": "2022-01-17T12:48:56.867449Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.867420Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambda_net_test_dataset_list[-1].weight_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.870186Z",
     "iopub.status.idle": "2022-01-17T12:48:56.870730Z",
     "shell.execute_reply": "2022-01-17T12:48:56.870522Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.870501Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if n==1:\n",
    "    from IPython.display import clear_output\n",
    "\n",
    "    for i in tqdm(range(test_size)):\n",
    "        clear_output(wait=True)\n",
    "        plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                              function_values_test_list, \n",
    "                                                              polynomial_dict_test_list,\n",
    "                                                              rand_index=i, \n",
    "                                                              plot_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:52.425282Z",
     "start_time": "2021-01-07T15:49:51.529992Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.872246Z",
     "iopub.status.idle": "2022-01-17T12:48:56.873087Z",
     "shell.execute_reply": "2022-01-17T12:48:56.872851Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.872822Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                          function_values_test_list, \n",
    "                                                          polynomial_dict_test_list,\n",
    "                                                          rand_index=index, \n",
    "                                                          plot_type=1)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:57.631017Z",
     "start_time": "2021-01-07T15:49:52.427326Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.874418Z",
     "iopub.status.idle": "2022-01-17T12:48:56.875168Z",
     "shell.execute_reply": "2022-01-17T12:48:56.874881Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.874844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                          function_values_test_list, \n",
    "                                                          polynomial_dict_test_list,\n",
    "                                                          rand_index=index, \n",
    "                                                          plot_type=2)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.877685Z",
     "iopub.status.idle": "2022-01-17T12:48:56.881438Z",
     "shell.execute_reply": "2022-01-17T12:48:56.880911Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.880876Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                          function_values_test_list, \n",
    "                                                          polynomial_dict_test_list,\n",
    "                                                          rand_index=index, \n",
    "                                                          plot_type=3)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.882748Z",
     "iopub.status.idle": "2022-01-17T12:48:56.883301Z",
     "shell.execute_reply": "2022-01-17T12:48:56.883043Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.883013Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtimes_list[-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.885189Z",
     "iopub.status.idle": "2022-01-17T12:48:56.885686Z",
     "shell.execute_reply": "2022-01-17T12:48:56.885445Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.885415Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'].values\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.886718Z",
     "iopub.status.idle": "2022-01-17T12:48:56.887306Z",
     "shell.execute_reply": "2022-01-17T12:48:56.887054Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.887024Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_symbolic_regression_functions'].values\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.888529Z",
     "iopub.status.idle": "2022-01-17T12:48:56.889006Z",
     "shell.execute_reply": "2022-01-17T12:48:56.888765Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.888736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_metamodel_functions'].values\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.889907Z",
     "iopub.status.idle": "2022-01-17T12:48:56.890620Z",
     "shell.execute_reply": "2022-01-17T12:48:56.890404Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.890380Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_inet_polynomials'].values\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.892398Z",
     "iopub.status.idle": "2022-01-17T12:48:56.892877Z",
     "shell.execute_reply": "2022-01-17T12:48:56.892644Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.892618Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_symbolic_regression_functions'].values\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.895899Z",
     "iopub.status.idle": "2022-01-17T12:48:56.896426Z",
     "shell.execute_reply": "2022-01-17T12:48:56.896167Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.896139Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_metamodel_functions'].values\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.897715Z",
     "iopub.status.idle": "2022-01-17T12:48:56.898631Z",
     "shell.execute_reply": "2022-01-17T12:48:56.898368Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.898337Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.900184Z",
     "iopub.status.idle": "2022-01-17T12:48:56.900787Z",
     "shell.execute_reply": "2022-01-17T12:48:56.900521Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.900407Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (RANDOM GUESS) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:50:04.140254Z",
     "start_time": "2021-01-07T15:50:03.647192Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.902576Z",
     "iopub.status.idle": "2022-01-17T12:48:56.906470Z",
     "shell.execute_reply": "2022-01-17T12:48:56.902822Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.902794Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_of_random_polynomials = np.random.uniform(low=-10, high=10, size=(len(lambda_net_test_dataset_list[-1]), sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.030192Z",
     "start_time": "2021-01-07T15:50:04.141837Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.908079Z",
     "iopub.status.idle": "2022-01-17T12:48:56.908669Z",
     "shell.execute_reply": "2022-01-17T12:48:56.908401Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.908371Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_fv_test = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)\n",
    "random_fv_test = parallel_fv_calculation_from_polynomial(list_of_random_polynomials, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.064612Z",
     "start_time": "2021-01-07T16:08:23.032372Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.910087Z",
     "iopub.status.idle": "2022-01-17T12:48:56.910739Z",
     "shell.execute_reply": "2022-01-17T12:48:56.910510Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.910475Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error Coefficients: ' + str(np.round(mean_absolute_error(lambda_net_test_dataset_list[-1].target_polynomial_list, list_of_random_polynomials), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.204426Z",
     "start_time": "2021-01-07T16:08:23.066205Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.912178Z",
     "iopub.status.idle": "2022-01-17T12:48:56.913055Z",
     "shell.execute_reply": "2022-01-17T12:48:56.912769Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.912737Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, random_fv_test), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (EDUCATED GUESS/MEAN PREDICTION) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:31.911007Z",
     "start_time": "2021-01-07T16:08:23.205879Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.914137Z",
     "iopub.status.idle": "2022-01-17T12:48:56.914618Z",
     "shell.execute_reply": "2022-01-17T12:48:56.914389Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.914363Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_fv_train = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)\n",
    "\n",
    "mean_fv = np.mean(true_fv_train)\n",
    "mean_fv_pred_test = [mean_fv for _ in range(true_fv_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.029945Z",
     "start_time": "2021-01-07T16:17:31.912980Z"
    },
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.917672Z",
     "iopub.status.idle": "2022-01-17T12:48:56.918187Z",
     "shell.execute_reply": "2022-01-17T12:48:56.917917Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.917889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Educated Guess/Mean Prediction Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, mean_fv_pred_test), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.508984Z",
     "start_time": "2021-01-07T16:17:32.031355Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.919773Z",
     "iopub.status.idle": "2022-01-17T12:48:56.920178Z",
     "shell.execute_reply": "2022-01-17T12:48:56.919999Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.919979Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "base_model = generate_base_model()\n",
    "random_evaluation_dataset = np.random.uniform(low=x_min, high=x_max, size=(random_evaluation_dataset_size, n))\n",
    "#random_evaluation_dataset = lambda_train_input_train_split[0]#lambda_train_input[0] #JUST [0] HERE BECAUSE EVALUATION ALWAYS ON THE SAME DATASET FOR ALL!!\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)\n",
    "\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "#X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "\n",
    "seed_in_inet_training = False\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "seed_in_inet_training = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.923184Z",
     "iopub.status.idle": "2022-01-17T12:48:56.923983Z",
     "shell.execute_reply": "2022-01-17T12:48:56.923691Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.923658Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "current_jobs = 1\n",
    "\n",
    "lr=0.5\n",
    "max_steps = 100\n",
    "early_stopping=10\n",
    "restarts=2\n",
    "per_network_dataset_size = 500\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "if n_jobs != -1:\n",
    "    n_jobs_per_network = min(n_jobs, os.cpu_count() // current_jobs)\n",
    "else: \n",
    "    n_jobs_per_network = os.cpu_count() // current_jobs - 1\n",
    "\n",
    "printing = True if n_jobs_per_network == 1 else False\n",
    "\n",
    "\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "if evaluate_with_real_function: #target polynomial as inet target\n",
    "    poly_representation_list = np.array(lambda_net_test_dataset.target_polynomial_list)\n",
    "else: #lstsq lambda pred polynomial as inet target\n",
    "    poly_representation_list = np.array(lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list)\n",
    "\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         #'list_of_monomial_identifiers': list_of_monomial_identifiers,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "lambda_network_weights = lambda_network_weights_list[0]\n",
    "poly_representation = poly_representation_list[0]\n",
    "\n",
    "\n",
    "\n",
    "per_network_poly_optimization_tf(per_network_dataset_size, \n",
    "                                lambda_network_weights, \n",
    "                                  list_of_monomial_identifiers_numbers, \n",
    "                                  config, \n",
    "                                  lr=lr, \n",
    "                                  max_steps = max_steps, \n",
    "                                  early_stopping=early_stopping, \n",
    "                                  restarts=restarts, \n",
    "                                  printing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Real Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Auto MPG-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.925113Z",
     "iopub.status.idle": "2022-01-17T12:48:56.926821Z",
     "shell.execute_reply": "2022-01-17T12:48:56.926599Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.926577Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interpretation_possible_autoMPG = False\n",
    "print_head_autoMPG = None\n",
    "\n",
    "url_autoMPG = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names_autoMPG = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset_autoMPG = pd.read_csv(url_autoMPG, names=column_names_autoMPG,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)\n",
    "\n",
    "dataset_autoMPG = raw_dataset_autoMPG.dropna()\n",
    "\n",
    "dataset_autoMPG['Origin'] = dataset_autoMPG['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset_autoMPG = pd.get_dummies(dataset_autoMPG, columns=['Origin'], prefix='', prefix_sep='')\n",
    "\n",
    "\n",
    "features_autoMPG = dataset_autoMPG.copy()\n",
    "\n",
    "labels_autoMPG = features_autoMPG.pop('MPG')\n",
    "\n",
    "features_autoMPG_normalized = (features_autoMPG-features_autoMPG.min())/(features_autoMPG.max()-features_autoMPG.min())\n",
    "\n",
    "#labels_autoMPG = (labels_autoMPG-labels_autoMPG.min())/(labels_autoMPG.max()-labels_autoMPG.min())\n",
    "\n",
    "\n",
    "if features_autoMPG_normalized.shape[1] >= n:\n",
    "    if n == 1:\n",
    "        features_autoMPG_model = features_autoMPG_normalized[['Horsepower']]\n",
    "    elif n == features_autoMPG_normalized.shape[1]:\n",
    "        features_autoMPG_model = features_autoMPG_normalized\n",
    "    else:\n",
    "        features_autoMPG_model = features_autoMPG_normalized.sample(n=n, axis='columns')\n",
    "        \n",
    "    print_head_autoMPG = features_autoMPG_model.head()\n",
    "    interpretation_possible_autoMPG = True\n",
    "\n",
    "print_head_autoMPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.928337Z",
     "iopub.status.idle": "2022-01-17T12:48:56.929324Z",
     "shell.execute_reply": "2022-01-17T12:48:56.928563Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.928534Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.931725Z",
     "iopub.status.idle": "2022-01-17T12:48:56.932355Z",
     "shell.execute_reply": "2022-01-17T12:48:56.931991Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.931961Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    ((lambda_index_autoMPG, \n",
    "     current_seed_autoMPG, \n",
    "     polynomial_autoMPG, \n",
    "     polynomial_lstsq_pred_list_autoMPG, \n",
    "     polynomial_lstsq_true_list_autoMPG), \n",
    "    scores_list_autoMPG, \n",
    "    pred_list_autoMPG, \n",
    "    history_autoMPG, \n",
    "    model_autoMPG) = train_nn(lambda_index=0, \n",
    "                              X_data_lambda=features_autoMPG_model.values, \n",
    "                              y_data_real_lambda=labels_autoMPG.values, \n",
    "                              polynomial=None, \n",
    "                              seed_list=[RANDOM_SEED], \n",
    "                              callbacks=[PlotLossesKerasTF()], \n",
    "                              return_history=True, \n",
    "                              each_epochs_save=None, \n",
    "                              printing=False, \n",
    "                              return_model=True)\n",
    "    \n",
    "    polynomial_lstsq_pred_autoMPG = polynomial_lstsq_pred_list_autoMPG[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.934152Z",
     "iopub.status.idle": "2022-01-17T12:48:56.934509Z",
     "shell.execute_reply": "2022-01-17T12:48:56.934348Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.934330Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and n==1:\n",
    "    x = tf.linspace(0.0, 250, 251)\n",
    "    y = model_autoMPG.predict(x)\n",
    "\n",
    "    plt.scatter(features_autoMPG_model['Horsepower'], labels_autoMPG, label='Data')\n",
    "    plt.plot(x, y, color='k', label='Predictions')\n",
    "    plt.xlabel('Horsepower')\n",
    "    plt.ylabel('MPG')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.937289Z",
     "iopub.status.idle": "2022-01-17T12:48:56.937878Z",
     "shell.execute_reply": "2022-01-17T12:48:56.937565Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.937536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "        'n': n,\n",
    "        'd': d,\n",
    "        'inet_loss': inet_loss,\n",
    "        'sparsity': sparsity,\n",
    "        'lambda_network_layers': lambda_network_layers,\n",
    "        'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "        'RANDOM_SEED': RANDOM_SEED,\n",
    "        'nas': nas,\n",
    "        'number_of_lambda_weights': number_of_lambda_weights,\n",
    "        'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "        'fixed_initialization_lambda_training': fixed_initialization_lambda_training,\n",
    "        'dropout': dropout,\n",
    "        'lambda_network_layers': lambda_network_layers,\n",
    "        'optimizer_lambda': optimizer_lambda,\n",
    "        'loss_lambda': loss_lambda,        \n",
    "         #'list_of_monomial_identifiers': list_of_monomial_identifiers,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "weights_autoMPG = model_autoMPG.get_weights()\n",
    "\n",
    "weights_flat_autoMPG = []\n",
    "for layer_weights, biases in pairwise(weights_autoMPG):    #clf.get_weights()\n",
    "    for neuron in layer_weights:\n",
    "        for weight in neuron:\n",
    "            weights_flat_autoMPG.append(weight)\n",
    "    for bias in biases:\n",
    "        weights_flat_autoMPG.append(bias)\n",
    "        \n",
    "weights_flat_autoMPG = np.array(weights_flat_autoMPG)\n",
    "\n",
    "\n",
    "x = pred_list_autoMPG['X_test_lambda']\n",
    "y = pred_list_autoMPG['y_test_real_lambda']\n",
    "\n",
    "y_model_autoMPG = model_autoMPG.predict(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.939032Z",
     "iopub.status.idle": "2022-01-17T12:48:56.939754Z",
     "shell.execute_reply": "2022-01-17T12:48:56.939493Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.939470Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "    y_polynomial_lstsq_pred_autoMPG = calculate_function_values_from_polynomial(polynomial_lstsq_pred_autoMPG, x, force_complete_poly_representation=True)\n",
    "\n",
    "    mae_model_polynomial_lstsq_pred_autoMPGy = mean_absolute_error(y_model_autoMPG, y_polynomial_lstsq_pred_autoMPG)\n",
    "    mae_data_polynomial_lstsq_pred_autoMPG = mean_absolute_error(y, y_polynomial_lstsq_pred_autoMPG)\n",
    "\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('LSTSQt Poly:')\n",
    "    print_polynomial_from_coefficients(y_polynomial_lstsq_pred_autoMPG, force_complete_poly_representation=True)\n",
    "    print('MAE Model: ', mae_model_polynomial_lstsq_pred_autoMPGy)\n",
    "    print('MAE Data: ', mae_data_polynomial_lstsq_pred_autoMPG)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.940773Z",
     "iopub.status.idle": "2022-01-17T12:48:56.943864Z",
     "shell.execute_reply": "2022-01-17T12:48:56.943562Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.943526Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    interpretation_net = model_list[-1]\n",
    "    \n",
    "    start = time.time() \n",
    "    \n",
    "    #interpretation_net_poly = interpretation_net.predict(np.array([weights_flat_autoMPG]))[0]\n",
    "    interpretation_net_poly = make_inet_prediction(interpretation_net, weights_flat_autoMPG, network_data=None, lambda_trained_normalized=False, inet_training_normalized=normalize_inet_data, normalization_parameter_dict=None)\n",
    "    \n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_interpretation_net_poly = calculate_function_values_from_polynomial(interpretation_net_poly, x, force_complete_poly_representation=False)\n",
    "    \n",
    "    mae_model_interpretation_net_poly = mean_absolute_error(y_model_autoMPG, y_interpretation_net_poly)\n",
    "    mae_data_interpretation_net_poly = mean_absolute_error(y, y_interpretation_net_poly)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Interpretation Net Poly:')\n",
    "    print_polynomial_from_coefficients(interpretation_net_poly, force_complete_poly_representation=False)\n",
    "    print('MAE Model: ', mae_model_interpretation_net_poly)\n",
    "    print('MAE Data: ', mae_data_interpretation_net_poly)    \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.946697Z",
     "iopub.status.idle": "2022-01-17T12:48:56.947684Z",
     "shell.execute_reply": "2022-01-17T12:48:56.947425Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.947394Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "\n",
    "    start = time.time() \n",
    "    \n",
    "    if False:\n",
    "        per_network_hyperparams = {\n",
    "            'optimizer':  'Powell',\n",
    "            'jac': 'fprime',\n",
    "            'max_steps': 5000,#100,\n",
    "            'restarts': 3,\n",
    "            'per_network_dataset_size': 500,\n",
    "        }      \n",
    "        \n",
    "        per_network_function =  per_network_poly_optimization_scipy(per_network_dataset_size, \n",
    "                                                                  weights_flat_autoMPG, \n",
    "                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                  config, \n",
    "                                                                  optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                  jac = per_network_hyperparams['jac'],\n",
    "                                                                  max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                  restarts=per_network_hyperparams['restarts'], \n",
    "                                                                  printing=True,\n",
    "                                                                  return_error=False)\n",
    "    else:\n",
    "        per_network_hyperparams = {\n",
    "            'optimizer': tf.keras.optimizers.RMSprop,\n",
    "            'lr': 0.02,\n",
    "            'max_steps': 500,\n",
    "            'early_stopping': 10,\n",
    "            'restarts': 3,\n",
    "            'per_network_dataset_size': 5000,\n",
    "        }   \n",
    "        \n",
    "        per_network_function =  per_network_poly_optimization_tf(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                              weights_flat_autoMPG, \n",
    "                                                              list_of_monomial_identifiers_numbers, \n",
    "                                                              config, \n",
    "                                                              optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                              lr=per_network_hyperparams['lr'], \n",
    "                                                              max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                              early_stopping=per_network_hyperparams['early_stopping'], \n",
    "                                                              restarts=per_network_hyperparams['restarts'], \n",
    "                                                              printing=True,\n",
    "                                                              return_error=False)\n",
    "            \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)  \n",
    "    \n",
    "    y_per_network_function = calculate_function_values_from_polynomial(per_network_function, x, force_complete_poly_representation=False)\n",
    "    \n",
    "    mae_model_interpretation_net_poly = mean_absolute_error(y_model_autoMPG, y_per_network_function)\n",
    "    mae_data_interpretation_net_poly = mean_absolute_error(y, y_per_network_function)    \n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Per Network Poly:')\n",
    "    print_polynomial_from_coefficients(per_network_function)\n",
    "    print('MAE Model: ', mae_model_interpretation_net_poly)\n",
    "    print('MAE Data: ', mae_data_interpretation_net_poly)       \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.948952Z",
     "iopub.status.idle": "2022-01-17T12:48:56.949705Z",
     "shell.execute_reply": "2022-01-17T12:48:56.949435Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.949405Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.952017Z",
     "iopub.status.idle": "2022-01-17T12:48:56.952521Z",
     "shell.execute_reply": "2022-01-17T12:48:56.952260Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.952232Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    \n",
    "    symbolic_regression_hyperparams = {\n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "\n",
    "    start = time.time() \n",
    "    \n",
    "    symbolic_regression_function =  symbolic_regression(model_autoMPG, \n",
    "                                                      config,\n",
    "                                                      symbolic_regression_hyperparams,\n",
    "                                                      #printing = True,\n",
    "                                                      return_error = False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    variable_names = ['X' + str(i) for i in range(n)]\n",
    "    \n",
    "    y_symbolic_regression_function = calculate_function_values_from_sympy(symbolic_regression_function, x, variable_names=variable_names)\n",
    "    \n",
    "    mae_model_symbolic_regression_function = mean_absolute_error(y_model_autoMPG, y_symbolic_regression_function)\n",
    "    mae_data_symbolic_regression_function = mean_absolute_error(y, y_symbolic_regression_function)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Symbolic Regression Poly:')    \n",
    "    display(symbolic_regression_function)\n",
    "    print('MAE Model: ', mae_model_symbolic_regression_function)\n",
    "    print('MAE Data: ', mae_data_symbolic_regression_function)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.953473Z",
     "iopub.status.idle": "2022-01-17T12:48:56.953942Z",
     "shell.execute_reply": "2022-01-17T12:48:56.953713Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.953685Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG and True:\n",
    "    metamodeling_hyperparams = {\n",
    "        'num_iter': 500,\n",
    "        'batch_size': None,\n",
    "        'learning_rate': 0.01,        \n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "    \n",
    "    start = time.time() \n",
    "\n",
    "    metamodel_function =  symbolic_metamodeling(model_autoMPG, \n",
    "                                              config,\n",
    "                                              metamodeling_hyperparams,\n",
    "                                              #printing = True,\n",
    "                                              return_error = False,\n",
    "                                              return_expression = 'approx', #'approx', #'exact',\n",
    "                                              function_metamodeling = False,\n",
    "                                              force_polynomial=False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_metamodel_function = calculate_function_values_from_sympy(metamodel_function, x)\n",
    "    \n",
    "    mae_model_metamodel_function = mean_absolute_error(y_model_autoMPG, y_metamodel_function)\n",
    "    mae_data_metamodel_function = mean_absolute_error(y, y_metamodel_function)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function:')    \n",
    "    display(metamodel_function)\n",
    "    print('MAE Model: ', mae_model_metamodel_function)\n",
    "    print('MAE Data: ', mae_data_metamodel_function)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.955523Z",
     "iopub.status.idle": "2022-01-17T12:48:56.956341Z",
     "shell.execute_reply": "2022-01-17T12:48:56.956091Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.956061Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and False:\n",
    "    metamodeling_hyperparams = {\n",
    "        'num_iter': 500,\n",
    "        'batch_size': None,\n",
    "        'learning_rate': 0.01,        \n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "    \n",
    "    start = time.time() \n",
    "\n",
    "    metamodel_function_basic =  symbolic_metamodeling(model_autoMPG, \n",
    "                                              config,\n",
    "                                              metamodeling_hyperparams,\n",
    "                                              #printing = True,\n",
    "                                              return_error = False,\n",
    "                                              return_expression = 'approx', #'approx', #'exact',\n",
    "                                              function_metamodeling = True,\n",
    "                                              force_polynomial=False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_metamodel_function_basic = calculate_function_values_from_sympy(metamodel_function_basic, x)\n",
    "    \n",
    "    mae_metamodel_function_basic = mean_absolute_error(y_model_autoMPG, y_metamodel_function_basic)\n",
    "    mae_metamodel_function_basic = mean_absolute_error(y, y_metamodel_function_basic)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function Basic:')    \n",
    "    display(metamodel_function_basic)\n",
    "    print('MAE Model: ', mae_metamodel_function_basic)\n",
    "    print('MAE Data: ', mae_metamodel_function_basic)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.957567Z",
     "iopub.status.idle": "2022-01-17T12:48:56.958102Z",
     "shell.execute_reply": "2022-01-17T12:48:56.957872Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.957841Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Interpretation Net Poly:')\n",
    "    print_polynomial_from_coefficients(interpretation_net_poly, force_complete_poly_representation=False)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Per Network Poly:')\n",
    "    print_polynomial_from_coefficients(per_network_function, force_complete_poly_representation=False)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('LSTSQ Poly:')\n",
    "    print_polynomial_from_coefficients(polynomial_lstsq_pred_autoMPG, force_complete_poly_representation=True)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Symbolic Regression Function:')\n",
    "    display(symbolic_regression_function)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function:')\n",
    "    display(metamodel_function)\n",
    "    #print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    #print('Metamodel Function Basic:')\n",
    "    #display(metamodel_function_basic)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.959811Z",
     "iopub.status.idle": "2022-01-17T12:48:56.960294Z",
     "shell.execute_reply": "2022-01-17T12:48:56.960043Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.960015Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and n==1:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
    "    \n",
    "    ax.set_ylim([0,50])\n",
    "    \n",
    "    plt.scatter(features_autoMPG_model['Horsepower'], labels_autoMPG, label='Data')\n",
    "    plt.scatter(x, y, label='Test Data')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_model_autoMPG))]) , label='Model Predictions')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_interpretation_net_poly))]) , label='Interpretation Net Poly')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_per_network_function))]) , label='Per Network Poly')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_polynomial_lstsq_pred_autoMPG))]) , label='LSTSQ Poly')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_symbolic_regression_function))]) , label='Symbolic Regression Function')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_metamodel_function))]) , label='Metamodel Function')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y))]) y_metamodel_function_basic, label='Metamodel Function Basic')\n",
    "    plt.xlabel('Horsepower')\n",
    "    plt.ylabel('MPG')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.961341Z",
     "iopub.status.idle": "2022-01-17T12:48:56.961895Z",
     "shell.execute_reply": "2022-01-17T12:48:56.961593Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.961566Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_data_X = np.array([i for i in range(1000)])\n",
    "sample_data_y = np.array([3*i for i in range(1000)])\n",
    "\n",
    "current_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.962817Z",
     "iopub.status.idle": "2022-01-17T12:48:56.963782Z",
     "shell.execute_reply": "2022-01-17T12:48:56.963529Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.963504Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.965065Z",
     "iopub.status.idle": "2022-01-17T12:48:56.965532Z",
     "shell.execute_reply": "2022-01-17T12:48:56.965288Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.965264Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y*1000,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.966430Z",
     "iopub.status.idle": "2022-01-17T12:48:56.966892Z",
     "shell.execute_reply": "2022-01-17T12:48:56.966668Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.966641Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y+1000,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.969156Z",
     "iopub.status.idle": "2022-01-17T12:48:56.969642Z",
     "shell.execute_reply": "2022-01-17T12:48:56.969402Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.969371Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_2_weights = model.get_weights()\n",
    "model_2_normalized_weights = model_2_weights #[weights/10 for weights in model_2_weights]\n",
    "\n",
    "\n",
    "model_2_normalized_weights[-6] = model_2_normalized_weights[-6]/10\n",
    "model_2_normalized_weights[-5] = model_2_normalized_weights[-5]/10\n",
    "\n",
    "model_2_normalized_weights[-4] = model_2_normalized_weights[-4]/10\n",
    "model_2_normalized_weights[-3] = model_2_normalized_weights[-3]/100\n",
    "\n",
    "model_2_normalized_weights[-2] = model_2_normalized_weights[-2]/10\n",
    "model_2_normalized_weights[-1] = model_2_normalized_weights[-1]/1000\n",
    "\n",
    "model_2.set_weights(model_2_normalized_weights)\n",
    "\n",
    "print(model_2.get_weights())\n",
    "print(model_2.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Per-Network Poly Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Optimization (Common Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.970598Z",
     "iopub.status.idle": "2022-01-17T12:48:56.971053Z",
     "shell.execute_reply": "2022-01-17T12:48:56.970838Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.970810Z"
    }
   },
   "outputs": [],
   "source": [
    "random_index = RANDOM_SEED\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer':  'Powell',\n",
    "    'jac': 'fprime',\n",
    "    'max_steps': 5000,#100,\n",
    "    'restarts': 3,\n",
    "    'per_network_dataset_size': 500,\n",
    "}\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "lambda_network_weights = lambda_network_weights_list[random_index]\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "printing = True\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "per_network_optimization_error, per_network_optimization_polynomial = per_network_poly_optimization_scipy(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                                                                      lambda_network_weights, \n",
    "                                                                                                      list_of_monomial_identifiers_numbers, \n",
    "                                                                                                      config,\n",
    "                                                                                                      optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                                                      jac = per_network_hyperparams['jac'],\n",
    "                                                                                                      max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                                                      restarts = per_network_hyperparams['restarts'],\n",
    "                                                                                                      printing = True,\n",
    "                                                                                                      return_error = True)\n",
    "\n",
    "print('\\n\\nError: ' + str(per_network_optimization_error))\n",
    "print_polynomial_from_coefficients(per_network_optimization_polynomial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Optimization (Neural Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.971871Z",
     "iopub.status.idle": "2022-01-17T12:48:56.972362Z",
     "shell.execute_reply": "2022-01-17T12:48:56.972100Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.972071Z"
    }
   },
   "outputs": [],
   "source": [
    "random_index = RANDOM_SEED\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer': tf.keras.optimizers.RMSprop,\n",
    "    'lr': 0.02,\n",
    "    'max_steps': 500,\n",
    "    'early_stopping': 10,\n",
    "    'restarts': 3,\n",
    "    'per_network_dataset_size': 5000,\n",
    "}\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "lambda_network_weights = lambda_network_weights_list[random_index]\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "printing = True\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "per_network_optimization_error, per_network_optimization_polynomial = per_network_poly_optimization_tf(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                                                                      lambda_network_weights, \n",
    "                                                                                                      list_of_monomial_identifiers_numbers, \n",
    "                                                                                                      config,\n",
    "                                                                                                      optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                                                      lr = per_network_hyperparams['lr'], \n",
    "                                                                                                      max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                                                      early_stopping = per_network_hyperparams['early_stopping'], \n",
    "                                                                                                      restarts = per_network_hyperparams['restarts'],\n",
    "                                                                                                      printing = True,\n",
    "                                                                                                      return_error = True)\n",
    "\n",
    "print('\\n\\nError: ' + str(per_network_optimization_error.numpy()))\n",
    "print_polynomial_from_coefficients(per_network_optimization_polynomial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Common Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.973233Z",
     "iopub.status.idle": "2022-01-17T12:48:56.973881Z",
     "shell.execute_reply": "2022-01-17T12:48:56.973611Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.973573Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "evaluation_size = 10\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer':  [\n",
    "                   'Nelder-Mead', \n",
    "                   'Powell', \n",
    "        \n",
    "                   'CG',\n",
    "                   'BFGS',\n",
    "                   'Newton-CG', \n",
    "                   #'L-BFGS-B', #'>' not supported between instances of 'int' and 'NoneType'\n",
    "                   'TNC', \n",
    "                   \n",
    "                   'COBYLA', \n",
    "                   'SLSQP', \n",
    "                   \n",
    "                   #'trust-constr', # TypeError: _minimize_trustregion_constr() got an unexpected keyword argument 'maxfun'\n",
    "                   #'dogleg', # ValueError: Hessian is required for dogleg minimization\n",
    "                   #'trust-ncg', #ValueError: Either the Hessian or the Hessian-vector product is required for Newton-CG trust-region minimization\n",
    "                   #'trust-exact', # ValueError: Hessian matrix is required for trust region exact minimization.\n",
    "                   #'trust-krylov' #ValueError: Either the Hessian or the Hessian-vector product is required for Krylov trust-region minimization\n",
    "                   ], \n",
    "    'jac': ['fprime'],\n",
    "    'max_steps': [5000],#100,\n",
    "    'restarts': [3],\n",
    "    'per_network_dataset_size': [500],\n",
    "}\n",
    "\n",
    "#param_iterator = ParameterSampler(per_network_hyperparams, n_iter=60, random_state=RANDOM_SEED)\n",
    "param_iterator = ParameterGrid(per_network_hyperparams)\n",
    "\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "printing = True if n_jobs == 1 else False\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.975382Z",
     "iopub.status.idle": "2022-01-17T12:48:56.975956Z",
     "shell.execute_reply": "2022-01-17T12:48:56.975700Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.975672Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "params_error_list = []\n",
    "for params in tqdm(param_iterator):\n",
    "    parallel_per_network = Parallel(n_jobs=n_jobs, verbose=0, backend='loky')\n",
    "\n",
    "    result_list = parallel_per_network(delayed(per_network_poly_optimization_scipy)(params['per_network_dataset_size'], \n",
    "                                                                                  lambda_network_weights, \n",
    "                                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                                  config,\n",
    "                                                                                  optimizer = params['optimizer'],\n",
    "                                                                                  jac = params['jac'],\n",
    "                                                                                  max_steps = params['max_steps'], \n",
    "                                                                                  restarts = params['restarts'],\n",
    "                                                                                  printing = printing,\n",
    "                                                                                  return_error = True) for lambda_network_weights in lambda_network_weights_list[:evaluation_size])  \n",
    "    \n",
    "    \n",
    "    per_network_optimization_errors = [result[0] for result in result_list]\n",
    "    per_network_optimization_polynomials = [result[1] for result in result_list]\n",
    "        \n",
    "    params_score = np.mean(per_network_optimization_errors)\n",
    "    \n",
    "    evaluation_result = list(params.values())\n",
    "    evaluation_result.append(params_score)\n",
    "    \n",
    "    params_error_list.append(evaluation_result)\n",
    "        \n",
    "    del parallel_per_network\n",
    "\n",
    "columns = list(params.keys())\n",
    "columns.append('score')\n",
    "params_error_df = pd.DataFrame(data=params_error_list, columns=columns).sort_values(by='score')\n",
    "params_error_df.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Neural Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.978484Z",
     "iopub.status.idle": "2022-01-17T12:48:56.979002Z",
     "shell.execute_reply": "2022-01-17T12:48:56.978731Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.978702Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "evaluation_size = 100\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer': [tf.keras.optimizers.RMSprop], #[tf.keras.optimizers.SGD, tf.optimizers.Adam, tf.keras.optimizers.RMSprop, tf.keras.optimizers.Adadelta]\n",
    "    'lr': [0.02], #[0.5, 0.25, 0.1, 0.05, 0.025]\n",
    "    'max_steps': [5000],#100,\n",
    "    'early_stopping': [10],\n",
    "    'restarts': [3],\n",
    "    'per_network_dataset_size': [5000],\n",
    "}\n",
    "\n",
    "#param_iterator = ParameterSampler(per_network_hyperparams, n_iter=60, random_state=RANDOM_SEED)\n",
    "param_iterator = ParameterGrid(per_network_hyperparams)\n",
    "\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "printing = True if n_jobs == 1 else False\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.981120Z",
     "iopub.status.idle": "2022-01-17T12:48:56.981627Z",
     "shell.execute_reply": "2022-01-17T12:48:56.981362Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.981333Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "params_error_list = []\n",
    "for params in tqdm(param_iterator):\n",
    "    parallel_per_network = Parallel(n_jobs=n_jobs, verbose=0, backend='loky')\n",
    "\n",
    "    result_list = parallel_per_network(delayed(per_network_poly_optimization_tf)(params['per_network_dataset_size'], \n",
    "                                                                                  lambda_network_weights, \n",
    "                                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                                  config,\n",
    "                                                                                  optimizer = params['optimizer'],\n",
    "                                                                                  lr = params['lr'], \n",
    "                                                                                  max_steps = params['max_steps'], \n",
    "                                                                                  early_stopping = params['early_stopping'], \n",
    "                                                                                  restarts = params['restarts'],\n",
    "                                                                                  printing = printing,\n",
    "                                                                                  return_error = True) for lambda_network_weights in lambda_network_weights_list[:evaluation_size])  \n",
    "    \n",
    "    \n",
    "    per_network_optimization_errors = [result[0] for result in result_list]\n",
    "    per_network_optimization_polynomials = [result[1] for result in result_list]\n",
    "        \n",
    "    params_score = np.mean(per_network_optimization_errors)\n",
    "    \n",
    "    evaluation_result = list(params.values())\n",
    "    evaluation_result.append(params_score)\n",
    "    \n",
    "    params_error_list.append(evaluation_result)\n",
    "        \n",
    "    del parallel_per_network\n",
    "\n",
    "columns = list(params.keys())\n",
    "columns.append('score')\n",
    "params_error_df = pd.DataFrame(data=params_error_list, columns=columns).sort_values(by='score')\n",
    "params_error_df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-17T12:48:56.983252Z",
     "iopub.status.idle": "2022-01-17T12:48:56.983908Z",
     "shell.execute_reply": "2022-01-17T12:48:56.983662Z",
     "shell.execute_reply.started": "2022-01-17T12:48:56.983632Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
