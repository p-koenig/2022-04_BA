{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:31.080239Z",
     "iopub.status.busy": "2021-09-25T15:37:31.079978Z",
     "iopub.status.idle": "2021-09-25T15:37:31.095014Z",
     "shell.execute_reply": "2021-09-25T15:37:31.094246Z",
     "shell.execute_reply.started": "2021-09-25T15:37:31.080169Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "config = {\n",
    "    'data': {\n",
    "        'd': 3, #degree\n",
    "        'n': 5, #number of variables\n",
    "        'monomial_vars': None, #int or None\n",
    "        'laurent': False, #use Laurent polynomials (negative degree with up to -d)  \n",
    "        'neg_d': 0,#int or None\n",
    "        'neg_d_prob': 0,\n",
    "        'sparsity': None,\n",
    "        'sample_sparsity': 5,\n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        'a_max': 1,\n",
    "        'a_min': -1,\n",
    "        'lambda_nets_total': 50000,\n",
    "        'noise': 0,\n",
    "        'noise_distrib': 'normal', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        \n",
    "        'shift_polynomial': False,\n",
    "        \n",
    "        'border_min': 0.2, # defines an intervall. Value is randomly chosen and defines the minimum gap between x_min / x_max and the outermost stationary points => two values (left and right gap will be generated per variable)\n",
    "        'border_max': 0.4,\n",
    "        'lower_degree_prob': 0.5, # probability that the degree of the whole polynomial will be reduced\n",
    "        'a_random_prob': 0.5, # probability that a random generated function is used without adjustement\n",
    "                \n",
    "        'global_stationary_prob': 1, # probability that all variables are used for adjustement (0 recommended for higher number of variables)\n",
    "        'bulge_min': 1, # bulge_min and bulge_max define an intervall of how much the function is bulged\n",
    "        'bulge_max': 4,\n",
    "        'min_variables_used': 2, # defines an Intervall of how many variables are used to get stationary points and therefore adjust the function\n",
    "        'max_variables_used': 6,\n",
    "        'max_monomials': 7, # maximum number of monomials, before adjusting the function (monomial of degree 0 is always defined, but is included in this number)\n",
    "        'max_monomials_random': 10, #maximum number of monomials for random generated functions\n",
    "        \n",
    "        'same_training_all_lambda_nets': False,\n",
    "\n",
    "        'fixed_seed_lambda_training': True,\n",
    "        'fixed_initialization_lambda_training': False,\n",
    "        'number_different_lambda_trainings': 1,\n",
    "    },\n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True,  #if early stopping is used, multi_epoch_analysis is deactivated\n",
    "        'early_stopping_min_delta_lambda': 1e-4,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout': 0,\n",
    "        'lambda_network_layers': [5*'sample_sparsity'],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'mae',\n",
    "        'number_of_lambda_weights': None,\n",
    "        'lambda_dataset_size': 5000,\n",
    "    },\n",
    "    'i_net': {\n",
    "        'optimizer': 'custom',#adam\n",
    "        'inet_loss': 'mae',\n",
    "        'inet_metrics': ['r2'],\n",
    "        'dropout': 0,\n",
    "        'dropout_output': 0,\n",
    "        'epochs': 2000, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "        'dense_layers': [2048],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'interpretation_dataset_size': 50000,\n",
    "                \n",
    "        'interpretation_net_output_monomials': 5, #(None, int) #CONSTANT IS NOT INCLUDED\n",
    "        'interpretation_net_output_shape': None, #calculated automatically later\n",
    "        'test_size': 100, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'normalize_inet_data': False,\n",
    "        'inet_training_without_noise': False, #dataset size without noise hardcoded to 50k in generate_paths\n",
    "        'sparse_poly_representation_version': 1, #(1, 2); 1=old, 2=new\n",
    "\n",
    "        'evaluate_with_real_function': False, #False\n",
    "        'consider_labels_training': False, #False\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 100,\n",
    "    },\n",
    "    'evaluation': {   \n",
    "        'inet_holdout_seed_evaluation': False,\n",
    "        \n",
    "        #set if multi_epoch_analysis should be performed\n",
    "        'multi_epoch_analysis': True,\n",
    "        'each_epochs_save_lambda': 100,\n",
    "        'epoch_start': 0, #use to skip first epochs in multi_epoch_analysis\n",
    "        \n",
    "        #set if samples analysis should be performed\n",
    "        'samples_list': None,#[100, 500, 750, 1000, 2500, 5000, 7500, 10000, 15000, 20000, 25000, 28125] \n",
    "       \n",
    "        'random_evaluation_dataset_size': 500,\n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "        \n",
    "        'adjusted_symbolic_metamodeling_code': False,\n",
    "        'symbolic_metamodeling_evaluation': False,\n",
    "        'symbolic_metamodeling_poly_evaluation': False,\n",
    "        'symbolic_metamodeling_function_evaluation': False,\n",
    "        'symbolic_metamodeling_poly_function_evaluation': False,\n",
    "        \n",
    "        \n",
    "        'symbolic_regression_evaluation': False,\n",
    "        'per_network_evaluation': False,\n",
    "    },\n",
    "    'computation':{\n",
    "        'train_model': True,\n",
    "        'n_jobs': 10,\n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '0',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:31.096261Z",
     "iopub.status.busy": "2021-09-25T15:37:31.095915Z",
     "iopub.status.idle": "2021-09-25T15:37:31.114261Z",
     "shell.execute_reply": "2021-09-25T15:37:31.113701Z",
     "shell.execute_reply.started": "2021-09-25T15:37:31.096238Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:31.116568Z",
     "iopub.status.busy": "2021-09-25T15:37:31.116336Z",
     "iopub.status.idle": "2021-09-25T15:37:34.185920Z",
     "shell.execute_reply": "2021-09-25T15:37:34.185300Z",
     "shell.execute_reply.started": "2021-09-25T15:37:31.116539Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 17:37:32.150800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "tf.autograph.set_verbosity(2)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import colored\n",
    "import math\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random \n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:34.187117Z",
     "iopub.status.busy": "2021-09-25T15:37:34.186886Z",
     "iopub.status.idle": "2021-09-25T15:37:34.192846Z",
     "shell.execute_reply": "2021-09-25T15:37:34.192367Z",
     "shell.execute_reply.started": "2021-09-25T15:37:34.187095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:34.194014Z",
     "iopub.status.busy": "2021-09-25T15:37:34.193812Z",
     "iopub.status.idle": "2021-09-25T15:37:34.205690Z",
     "shell.execute_reply": "2021-09-25T15:37:34.205143Z",
     "shell.execute_reply.started": "2021-09-25T15:37:34.193977Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "\n",
    "n_jobs = min((epochs_lambda//each_epochs_save_lambda+1, n_jobs)) if multi_epoch_analysis else min(len(samples_list), n_jobs) if samples_list!=None else 1\n",
    "\n",
    "multi_epoch_analysis = False if early_stopping_lambda else multi_epoch_analysis #deactivate multi_epoch_analysis if early stopping is used\n",
    "\n",
    "each_epochs_save_lambda = each_epochs_save_lambda if multi_epoch_analysis else epochs_lambda\n",
    "epochs_save_range_lambda = range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda) if each_epochs_save_lambda == 1 else range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda+1) if multi_epoch_analysis else range(1,2)\n",
    "\n",
    "data_reshape_version = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/lib/cuda-10.1'\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:34.206641Z",
     "iopub.status.busy": "2021-09-25T15:37:34.206474Z",
     "iopub.status.idle": "2021-09-25T15:37:35.036060Z",
     "shell.execute_reply": "2021-09-25T15:37:35.035366Z",
     "shell.execute_reply.started": "2021-09-25T15:37:34.206619Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 10\n",
      "[[3, 0], [2, 1], [2, 0], [1, 2], [1, 1], [1, 0], [0, 3], [0, 2], [0, 1], [0, 0]]\n"
     ]
    }
   ],
   "source": [
    "from utilities.utility_functions import flatten, rec_gen, gen_monomial_identifier_list\n",
    "\n",
    "list_of_monomial_identifiers_extended = []\n",
    "\n",
    "if laurent:\n",
    "    variable_sets = [list(flatten([[_d for _d in range(d+1)], [-_d for _d in range(1, neg_d+1)]])) for _ in range(n)]\n",
    "    list_of_monomial_identifiers_extended = rec_gen(variable_sets)    \n",
    "        \n",
    "    print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "    #print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "    #print('Sparsity:' + str(sparsity))\n",
    "    if len(list_of_monomial_identifiers_extended) < 500:\n",
    "        print(list_of_monomial_identifiers_extended)     \n",
    "        \n",
    "    list_of_monomial_identifiers = []\n",
    "    for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "        if np.sum(monomial_identifier) <= d:\n",
    "            if monomial_vars == None or len(list(filter(lambda x: x != 0, monomial_identifier))) <= monomial_vars:\n",
    "                list_of_monomial_identifiers.append(monomial_identifier)        \n",
    "else:\n",
    "    variable_list = ['x'+ str(i) for i in range(n)]\n",
    "    list_of_monomial_identifiers = gen_monomial_identifier_list(variable_list, d, n)\n",
    "            \n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "#print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "#print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:35.037419Z",
     "iopub.status.busy": "2021-09-25T15:37:35.037216Z",
     "iopub.status.idle": "2021-09-25T15:37:35.159410Z",
     "shell.execute_reply": "2021-09-25T15:37:35.158670Z",
     "shell.execute_reply.started": "2021-09-25T15:37:35.037396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape:  22\n"
     ]
    }
   ],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "config['evaluation']['multi_epoch_analysis'] = multi_epoch_analysis\n",
    "config['evaluation']['each_epochs_save_lambda'] = each_epochs_save_lambda\n",
    "config['i_net']['data_reshape_version'] = data_reshape_version\n",
    "\n",
    "config['data']['sparsity'] = nCr(config['data']['n']+config['data']['d'], config['data']['d']) if not laurent else len(list_of_monomial_identifiers)\n",
    "config['data']['sample_sparsity'] = config['data']['sparsity'] if config['data']['sample_sparsity'] == None else config['data']['sample_sparsity']\n",
    "\n",
    "config['i_net']['interpretation_net_output_shape'] = config['data']['sparsity'] if config['i_net']['interpretation_net_output_monomials'] is None else config['data']['sparsity']*config['i_net']['interpretation_net_output_monomials']+config['i_net']['interpretation_net_output_monomials'] if config['i_net']['sparse_poly_representation_version'] == 1 else config['data']['n']*(config['data']['d']+1)*config['i_net']['interpretation_net_output_monomials']+config['i_net']['interpretation_net_output_monomials']  \n",
    "print('Output Shape: ', config['i_net']['interpretation_net_output_shape'])\n",
    "\n",
    "transformed_layers = []\n",
    "for layer in config['lambda_net']['lambda_network_layers']:\n",
    "    if type(layer) == str:\n",
    "        transformed_layers.append(layer.count('sample_sparsity')*config['data']['sample_sparsity'])\n",
    "    else:\n",
    "        transformed_layers.append(layer)\n",
    "config['lambda_net']['lambda_network_layers'] = transformed_layers\n",
    "\n",
    "layers_with_input_output = list(flatten([[config['data']['n']], config['lambda_net']['lambda_network_layers'], [1]]))\n",
    "number_of_lambda_weights = 0\n",
    "for i in range(len(layers_with_input_output)-1):\n",
    "    number_of_lambda_weights += (layers_with_input_output[i]+1)*layers_with_input_output[i+1]  \n",
    "config['lambda_net']['number_of_lambda_weights'] = number_of_lambda_weights\n",
    "    \n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "\n",
    "\n",
    "initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "initialize_metrics_config_from_curent_notebook(config)\n",
    "initialize_utility_functions_config_from_curent_notebook(config)\n",
    "initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(path_type='interpretation_net'))\n",
    "create_folders_inet()\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:35.160620Z",
     "iopub.status.busy": "2021-09-25T15:37:35.160417Z",
     "iopub.status.idle": "2021-09-25T15:37:35.164602Z",
     "shell.execute_reply": "2021-09-25T15:37:35.164081Z",
     "shell.execute_reply.started": "2021-09-25T15:37:35.160596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inet_dense2048-output_22_drop0e2000b256_custom/lnets_10000_10-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_2_d_3_negd_0_prob_0_spars_2_amin_-1_amax_1_xdist_uniform_noise_normal_0bmin0.2bmax0.4lowd0.5azero0.25arand0.1\n",
      "lnets_10000_10-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_2_d_3_negd_0_prob_0_spars_2_amin_-1_amax_1_xdist_uniform_noise_normal_0bmin0.2bmax0.4lowd0.5azero0.25arand0.1\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net_data)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:35.165755Z",
     "iopub.status.busy": "2021-09-25T15:37:35.165571Z",
     "iopub.status.idle": "2021-09-25T15:37:35.237652Z",
     "shell.execute_reply": "2021-09-25T15:37:35.237092Z",
     "shell.execute_reply.started": "2021-09-25T15:37:35.165732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 17:37:35.168090: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:35.239117Z",
     "iopub.status.busy": "2021-09-25T15:37:35.238904Z",
     "iopub.status.idle": "2021-09-25T15:37:35.250097Z",
     "shell.execute_reply": "2021-09-25T15:37:35.248760Z",
     "shell.execute_reply.started": "2021-09-25T15:37:35.239078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 17:37:35.169648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-25 17:37:35.216609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-09-25 17:37:35.216656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-25 17:37:35.225140: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-25 17:37:35.225192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-25 17:37:35.226858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-25 17:37:35.227613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-25 17:37:35.229956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-25 17:37:35.231735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-25 17:37:35.231886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-25 17:37:35.233759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "def load_lambda_nets(index, no_noise=False):\n",
    "    \n",
    "    if psutil.virtual_memory().percent > 80:\n",
    "        raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    path_identifier_lambda_net_data_loading = None \n",
    "                \n",
    "    if no_noise==True:\n",
    "        path_identifier_lambda_net_data_loading = generate_paths(path_type='interpretation_net_no_noise')['path_identifier_lambda_net_data']\n",
    "    else:\n",
    "        path_identifier_lambda_net_data_loading = path_identifier_lambda_net_data \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_identifier_lambda_net_data_loading + '/'\n",
    "    path_weights = directory + 'weights_epoch_' + str(index).zfill(3) + '.txt'\n",
    "    path_X_data = directory + 'lambda_X_test_data.txt'\n",
    "    path_y_data = directory + 'lambda_y_test_data.txt'        \n",
    "    \n",
    "    weight_data = pd.read_csv(path_weights, sep=\",\", header=None)\n",
    "    weight_data = weight_data.sort_values(by=0).sample(frac=1, random_state=RANDOM_SEED)\n",
    "    if no_noise == False:\n",
    "        weight_data = weight_data.sort_values(by=0).sample(n=interpretation_dataset_size, random_state=RANDOM_SEED)\n",
    "    \n",
    "    lambda_X_test_data = pd.read_csv(path_X_data, sep=\",\", header=None)\n",
    "    lambda_X_test_data = lambda_X_test_data.sort_values(by=0).sample(frac=1, random_state=RANDOM_SEED)\n",
    "    if no_noise == False:\n",
    "        lambda_X_test_data = lambda_X_test_data.sort_values(by=0).sample(n=interpretation_dataset_size, random_state=RANDOM_SEED)\n",
    "    \n",
    "    lambda_y_test_data = pd.read_csv(path_y_data, sep=\",\", header=None)\n",
    "    lambda_y_test_data = lambda_y_test_data.sort_values(by=0).sample(frac=1, random_state=RANDOM_SEED)\n",
    "    if no_noise == False:\n",
    "        lambda_y_test_data = lambda_y_test_data.sort_values(by=0).sample(n=interpretation_dataset_size, random_state=RANDOM_SEED)\n",
    "        \n",
    "    lambda_nets = [None] * weight_data.shape[0]\n",
    "    for i, (row_weights, row_lambda_X_test_data, row_lambda_y_test_data) in enumerate(zip(weight_data.values, lambda_X_test_data.values, lambda_y_test_data.values)):        \n",
    "        lambda_net = LambdaNet(row_weights, row_lambda_X_test_data, row_lambda_y_test_data)\n",
    "        lambda_nets[i] = lambda_net\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-25T15:37:35.251226Z",
     "iopub.status.busy": "2021-09-25T15:37:35.250991Z",
     "iopub.status.idle": "2021-09-25T15:37:36.051072Z",
     "shell.execute_reply": "2021-09-25T15:37:36.047220Z",
     "shell.execute_reply.started": "2021-09-25T15:37:35.251204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend MultiprocessingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/weights/weights_lnets_10000_10-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_2_d_3_negd_0_prob_0_spars_2_amin_-1_amax_1_xdist_uniform_noise_normal_0bmin0.2bmax0.4lowd0.5azero0.25arand0.1/weights_epoch_1000.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_4449/1436617437.py\", line 18, in load_lambda_nets\n    weight_data = pd.read_csv(path_weights, sep=\",\", header=None)\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: './data/weights/weights_lnets_10000_10-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_2_d_3_negd_0_prob_0_spars_2_amin_-1_amax_1_xdist_uniform_noise_normal_0bmin0.2bmax0.4lowd0.5azero0.25arand0.1/weights_epoch_1000.txt'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4449/4138943624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minet_training_without_noise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiprocessing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlambda_net_dataset_list_without_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_lambda_nets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meach_epochs_save_lambda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0meach_epochs_save_lambda\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meach_epochs_save_lambda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0meach_epochs_save_lambda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs_save_range_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/weights/weights_lnets_10000_10-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_2_d_3_negd_0_prob_0_spars_2_amin_-1_amax_1_xdist_uniform_noise_normal_0bmin0.2bmax0.4lowd0.5azero0.25arand0.1/weights_epoch_1000.txt'"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if inet_training_without_noise:\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "    lambda_net_dataset_list_without_noise = parallel(delayed(load_lambda_nets)((i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1, no_noise=True) for i in epochs_save_range_lambda)  \n",
    "    del parallel\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "    lambda_net_dataset_list = parallel(delayed(load_lambda_nets)((i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1) for i in epochs_save_range_lambda)  \n",
    "    del parallel\n",
    "else:\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "    lambda_net_dataset_list = parallel(delayed(load_lambda_nets)((i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1) for i in epochs_save_range_lambda)  \n",
    "    del parallel\n",
    "\n",
    "lambda_net_dataset = lambda_net_dataset_list[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:30:49.711839Z",
     "start_time": "2021-01-05T09:29:48.873305Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.051903Z",
     "iopub.status.idle": "2021-09-25T15:37:36.052194Z",
     "shell.execute_reply": "2021-09-25T15:37:36.052057Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.052041Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset.as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:31:56.898548Z",
     "start_time": "2021-01-05T09:30:49.715497Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.053623Z",
     "iopub.status.idle": "2021-09-25T15:37:36.054002Z",
     "shell.execute_reply": "2021-09-25T15:37:36.053857Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.053839Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset.as_pandas().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.054982Z",
     "iopub.status.idle": "2021-09-25T15:37:36.055261Z",
     "shell.execute_reply": "2021-09-25T15:37:36.055125Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.055109Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset.X_test_data_list[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.056034Z",
     "iopub.status.idle": "2021-09-25T15:37:36.056436Z",
     "shell.execute_reply": "2021-09-25T15:37:36.056294Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.056276Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset.y_test_data_list[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets for Interpretation-Net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:32:09.782470Z",
     "start_time": "2021-01-05T09:31:56.901018Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.057318Z",
     "iopub.status.idle": "2021-09-25T15:37:36.057612Z",
     "shell.execute_reply": "2021-09-25T15:37:36.057475Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.057459Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate train, test and validation data for training\n",
    "\n",
    "lambda_net_train_dataset_list = []\n",
    "lambda_net_valid_dataset_list = []\n",
    "lambda_net_test_dataset_list = []\n",
    "\n",
    "\n",
    "if inet_training_without_noise:\n",
    "   \n",
    "    for lambda_net_dataset, lambda_net_dataset_without_noise in zip(lambda_net_dataset_list, lambda_net_dataset_list_without_noise):\n",
    "        if inet_holdout_seed_evaluation:\n",
    "            raise SystemExit('Holdout Evaluation not implemented with inet training without noise')\n",
    "            \n",
    "        else:\n",
    "            lambda_net_train_dataset, lambda_net_valid_dataset = split_LambdaNetDataset(lambda_net_dataset_without_noise, test_split=0.1)\n",
    "\n",
    "            _, lambda_net_test_dataset = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "\n",
    "            lambda_net_train_dataset_list.append(lambda_net_train_dataset)\n",
    "            lambda_net_valid_dataset_list.append(lambda_net_valid_dataset)\n",
    "            lambda_net_test_dataset_list.append(lambda_net_test_dataset)\n",
    "\n",
    "            del lambda_net_dataset, lambda_net_dataset_list_without_noise\n",
    "        \n",
    "else:\n",
    "\n",
    "    for lambda_net_dataset in lambda_net_dataset_list:\n",
    "\n",
    "        if inet_holdout_seed_evaluation:\n",
    "\n",
    "            complete_seed_list = list(set(lambda_net_dataset.train_settings_list['seed']))#list(weight_data.iloc[:,1].unique())\n",
    "\n",
    "            random.seed(RANDOM_SEED)\n",
    "\n",
    "            if isinstance(test_size, float):\n",
    "                test_size = int(len(complete_seed_list)-len(complete_seed_list)/(1/(1-test_size)))\n",
    "\n",
    "            test_seeds = random.sample(complete_seed_list, test_size)\n",
    "            lambda_net_test_dataset = lambda_net_dataset.get_lambda_nets_by_seed(test_seeds)\n",
    "            complete_seed_list = list(set(complete_seed_list) - set(test_seeds))#complete_seed_list.remove(test_seeds)\n",
    "\n",
    "            random.seed(RANDOM_SEED)\n",
    "            valid_seeds = random.sample(complete_seed_list, int(len(complete_seed_list)-len(complete_seed_list)/(1/(1-0.1))))\n",
    "            lambda_net_valid_dataset = lambda_net_dataset.get_lambda_nets_by_seed(valid_seeds)\n",
    "            complete_seed_list = list(set(complete_seed_list) - set(valid_seeds))\n",
    "\n",
    "            train_seeds = complete_seed_list\n",
    "            lambda_net_train_dataset = lambda_net_dataset.get_lambda_nets_by_seed(train_seeds)       \n",
    "\n",
    "            lambda_net_train_dataset_list.append(lambda_net_train_dataset)\n",
    "            lambda_net_valid_dataset_list.append(lambda_net_valid_dataset)\n",
    "            lambda_net_test_dataset_list.append(lambda_net_test_dataset)\n",
    "\n",
    "            del lambda_net_dataset\n",
    "        else:\n",
    "\n",
    "            lambda_net_train_with_valid_dataset, lambda_net_test_dataset = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "            lambda_net_train_dataset, lambda_net_valid_dataset = split_LambdaNetDataset(lambda_net_train_with_valid_dataset, test_split=0.1)\n",
    "\n",
    "            lambda_net_train_dataset_list.append(lambda_net_train_dataset)\n",
    "            lambda_net_valid_dataset_list.append(lambda_net_valid_dataset)\n",
    "            lambda_net_test_dataset_list.append(lambda_net_test_dataset)\n",
    "\n",
    "            del lambda_net_dataset, lambda_net_train_with_valid_dataset\n",
    "\n",
    "\n",
    "del lambda_net_dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:06.495716Z",
     "start_time": "2021-01-05T09:32:09.784760Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.058399Z",
     "iopub.status.idle": "2021-09-25T15:37:36.058752Z",
     "shell.execute_reply": "2021-09-25T15:37:36.058603Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.058586Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_train_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:08.945802Z",
     "start_time": "2021-01-05T09:33:06.499150Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.059596Z",
     "iopub.status.idle": "2021-09-25T15:37:36.059874Z",
     "shell.execute_reply": "2021-09-25T15:37:36.059743Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.059727Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_valid_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:11.543306Z",
     "start_time": "2021-01-05T09:33:08.947468Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.060786Z",
     "iopub.status.idle": "2021-09-25T15:37:36.061158Z",
     "shell.execute_reply": "2021-09-25T15:37:36.061018Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.061000Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_test_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.062053Z",
     "iopub.status.idle": "2021-09-25T15:37:36.062337Z",
     "shell.execute_reply": "2021-09-25T15:37:36.062195Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.062179Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_train_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.063220Z",
     "iopub.status.idle": "2021-09-25T15:37:36.063553Z",
     "shell.execute_reply": "2021-09-25T15:37:36.063414Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.063397Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_valid_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.064370Z",
     "iopub.status.idle": "2021-09-25T15:37:36.064750Z",
     "shell.execute_reply": "2021-09-25T15:37:36.064610Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.064592Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_test_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.065637Z",
     "iopub.status.idle": "2021-09-25T15:37:36.065912Z",
     "shell.execute_reply": "2021-09-25T15:37:36.065777Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.065761Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.066784Z",
     "iopub.status.idle": "2021-09-25T15:37:36.067123Z",
     "shell.execute_reply": "2021-09-25T15:37:36.066985Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.066968Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambda_net_train_dataset_list[0].weight_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.068060Z",
     "iopub.status.idle": "2021-09-25T15:37:36.068463Z",
     "shell.execute_reply": "2021-09-25T15:37:36.068321Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.068304Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "((X_valid_list, y_valid_list), \n",
    " (X_test_list, y_test_list),\n",
    " history_list, \n",
    "\n",
    " #scores_valid_list,\n",
    " #scores_test_list, \n",
    "\n",
    " #function_values_valid_list, \n",
    " #function_values_test_list, \n",
    "\n",
    " #polynomial_dict_valid_list,\n",
    " #polynomial_dict_test_list,\n",
    "\n",
    " #distrib_dict_valid_list,\n",
    " #distrib_dict_test_list,\n",
    "\n",
    " model_list) = interpretation_net_training(lambda_net_train_dataset_list, \n",
    "                                           lambda_net_valid_dataset_list, \n",
    "                                           lambda_net_test_dataset_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.069429Z",
     "iopub.status.idle": "2021-09-25T15:37:36.069784Z",
     "shell.execute_reply": "2021-09-25T15:37:36.069641Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.069624Z"
    }
   },
   "outputs": [],
   "source": [
    "inet_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.070493Z",
     "iopub.status.idle": "2021-09-25T15:37:36.070867Z",
     "shell.execute_reply": "2021-09-25T15:37:36.070703Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.070685Z"
    }
   },
   "outputs": [],
   "source": [
    "inet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.071751Z",
     "iopub.status.idle": "2021-09-25T15:37:36.072108Z",
     "shell.execute_reply": "2021-09-25T15:37:36.071968Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.071951Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.072854Z",
     "iopub.status.idle": "2021-09-25T15:37:36.073145Z",
     "shell.execute_reply": "2021-09-25T15:37:36.073009Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.072993Z"
    }
   },
   "outputs": [],
   "source": [
    "#polynomial_dict_valid_list = []\n",
    "polynomial_dict_test_list = []  \n",
    "\n",
    "\n",
    "for lambda_net_valid_dataset, lambda_net_test_dataset in zip(lambda_net_valid_dataset_list, lambda_net_test_dataset_list):\n",
    "\n",
    "    #polynomial_dict_valid = {'lstsq_lambda_pred_polynomials': lambda_net_valid_dataset.lstsq_lambda_pred_polynomial_list,\n",
    "    #                        'lstsq_target_polynomials': lambda_net_valid_dataset.lstsq_target_polynomial_list,\n",
    "    #                        'target_polynomials': lambda_net_valid_dataset.target_polynomial_list}    \n",
    "\n",
    "    polynomial_dict_test = {'lstsq_lambda_pred_polynomials': lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list,\n",
    "                            'lstsq_target_polynomials': lambda_net_test_dataset.lstsq_target_polynomial_list,\n",
    "                            'target_polynomials': lambda_net_test_dataset.target_polynomial_list}    \n",
    "\n",
    "    #polynomial_dict_valid_list.append(polynomial_dict_valid)  \n",
    "    polynomial_dict_test_list.append(polynomial_dict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.074159Z",
     "iopub.status.idle": "2021-09-25T15:37:36.074597Z",
     "shell.execute_reply": "2021-09-25T15:37:36.074454Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.074437Z"
    }
   },
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------- PREDICT INET ------------------------------------------------------')\n",
    "\n",
    "start = time.time() \n",
    "\n",
    "for i, (X_test, model) in enumerate(zip(X_test_list, model_list)):\n",
    "    #y_test_pred = model.predict(X_test)    \n",
    "    #print(model.summary())\n",
    "    #print(X_test.shape)\n",
    "    y_test_pred = make_inet_prediction(model, X_test, network_data=None, lambda_trained_normalized=False, inet_training_normalized=normalize_inet_data, normalization_parameter_dict=None)\n",
    "    #print(y_test_pred.shape)   \n",
    "    polynomial_dict_test_list[i]['inet_polynomials'] = y_test_pred\n",
    "\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('Predict Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.075365Z",
     "iopub.status.idle": "2021-09-25T15:37:36.075691Z",
     "shell.execute_reply": "2021-09-25T15:37:36.075554Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.075537Z"
    }
   },
   "outputs": [],
   "source": [
    "if symbolic_metamodeling_poly_evaluation:\n",
    "    print('-------------------------------------------------- CALCULATE METAMODEL POLY -----------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        \n",
    "        metamodel_functions_test = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=False, force_polynomial=True)\n",
    "        polynomial_dict_test_list[i]['metamodel_poly'] = metamodel_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Metamodel Poly Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.076585Z",
     "iopub.status.idle": "2021-09-25T15:37:36.076923Z",
     "shell.execute_reply": "2021-09-25T15:37:36.076787Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.076770Z"
    }
   },
   "outputs": [],
   "source": [
    "if symbolic_metamodeling_evaluation:\n",
    "    print('---------------------------------------------------- CALCULATE METAMODEL --------------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        metamodel_functions_test = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=False, force_polynomial=False)\n",
    "        polynomial_dict_test_list[i]['metamodel_functions'] = metamodel_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Metamodel Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.077784Z",
     "iopub.status.idle": "2021-09-25T15:37:36.078186Z",
     "shell.execute_reply": "2021-09-25T15:37:36.078045Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.078028Z"
    }
   },
   "outputs": [],
   "source": [
    "if symbolic_metamodeling_function_evaluation:\n",
    "    print('----------------------------------------------- CALCULATE METAMODEL FUNCTION ----------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        metamodel_functions_test = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=True)\n",
    "        polynomial_dict_test_list[i]['metamodel_functions_no_GD'] = metamodel_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Metamodel Function Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.079103Z",
     "iopub.status.idle": "2021-09-25T15:37:36.079391Z",
     "shell.execute_reply": "2021-09-25T15:37:36.079243Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.079227Z"
    }
   },
   "outputs": [],
   "source": [
    "if symbolic_regression_evaluation:\n",
    "    print('----------------------------------------- CALCULATE SYMBOLIC REGRESSION FUNCTION ------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        symbolic_regression_functions_test = symbolic_regression_function_generation(lambda_net_test_dataset)\n",
    "        polynomial_dict_test_list[i]['symbolic_regression_functions'] = symbolic_regression_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Symbolic Regression Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.080354Z",
     "iopub.status.idle": "2021-09-25T15:37:36.080667Z",
     "shell.execute_reply": "2021-09-25T15:37:36.080529Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.080512Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if per_network_evaluation:\n",
    "    print('------------------------------------------------ CALCULATE PER NETWORK POLY -----------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        per_network_poly_test = per_network_poly_generation(lambda_net_test_dataset, optimization_type='scipy')\n",
    "        polynomial_dict_test_list[i]['per_network_polynomials'] = per_network_poly_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Per Network Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.081634Z",
     "iopub.status.idle": "2021-09-25T15:37:36.081910Z",
     "shell.execute_reply": "2021-09-25T15:37:36.081774Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.081758Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.082757Z",
     "iopub.status.idle": "2021-09-25T15:37:36.083032Z",
     "shell.execute_reply": "2021-09-25T15:37:36.082898Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.082882Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "print('------------------------------------------------ CALCULATE FUNCTION VALUES ------------------------------------------------')                \n",
    "\n",
    "start = time.time() \n",
    "\n",
    "function_values_test_list = []\n",
    "for lambda_net_test_dataset, polynomial_dict_test in zip(lambda_net_test_dataset_list, polynomial_dict_test_list):\n",
    "    function_values_test = calculate_all_function_values(lambda_net_test_dataset, polynomial_dict_test)\n",
    "    function_values_test_list.append(function_values_test)\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('FV Calculation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.083903Z",
     "iopub.status.idle": "2021-09-25T15:37:36.084318Z",
     "shell.execute_reply": "2021-09-25T15:37:36.084178Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.084161Z"
    }
   },
   "outputs": [],
   "source": [
    "print('----------------------------------------------------- CALCULATE SCORES ----------------------------------------------------')                \n",
    "\n",
    "start = time.time() \n",
    "\n",
    "scores_test_list = []\n",
    "distrib_dict_test_list = []\n",
    "\n",
    "for function_values_test, polynomial_dict_test in zip(function_values_test_list, polynomial_dict_test_list):\n",
    "    scores_test, distrib_test = evaluate_all_predictions(function_values_test, polynomial_dict_test)\n",
    "    scores_test_list.append(scores_test)\n",
    "    distrib_dict_test_list.append(distrib_test)\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('Score Calculation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.085175Z",
     "iopub.status.idle": "2021-09-25T15:37:36.085440Z",
     "shell.execute_reply": "2021-09-25T15:37:36.085309Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.085294Z"
    }
   },
   "outputs": [],
   "source": [
    "identifier_type = 'epochs' if samples_list == None else 'samples'\n",
    "save_results(scores_list=scores_test_list, by=identifier_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Interpretation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.086418Z",
     "iopub.status.idle": "2021-09-25T15:37:36.086697Z",
     "shell.execute_reply": "2021-09-25T15:37:36.086559Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.086543Z"
    }
   },
   "outputs": [],
   "source": [
    "if nas:\n",
    "    for trial in history_list[-1]: \n",
    "        print(trial.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.087760Z",
     "iopub.status.idle": "2021-09-25T15:37:36.088234Z",
     "shell.execute_reply": "2021-09-25T15:37:36.088099Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.088066Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(model_list) >= 1:\n",
    "    print(model_list[-1].summary())\n",
    "    print(model_list[-1].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.088995Z",
     "iopub.status.idle": "2021-09-25T15:37:36.089255Z",
     "shell.execute_reply": "2021-09-25T15:37:36.089129Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.089114Z"
    }
   },
   "outputs": [],
   "source": [
    "if evaluate_with_real_function:\n",
    "    keys = ['inetPoly_VS_targetPoly_test', 'perNetworkPoly_VS_targetPoly_test', 'predLambda_VS_targetPoly_test', 'lstsqLambda_VS_targetPoly_test', 'lstsqTarget_VS_targetPoly_test']\n",
    "else:\n",
    "    keys = ['inetPoly_VS_predLambda_test', 'inetPoly_VS_lstsqLambda_test', 'perNetworkPoly_VS_predLambda_test', 'perNetworkPoly_VS_lstsqLambda_test', 'lstsqLambda_VS_predLambda_test', 'predLambda_VS_targetPoly_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.090126Z",
     "iopub.status.idle": "2021-09-25T15:37:36.090408Z",
     "shell.execute_reply": "2021-09-25T15:37:36.090259Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.090244Z"
    }
   },
   "outputs": [],
   "source": [
    "#0.183\t0.234\t3.604\t0.143\t0.687\t2.559\t0.215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.091420Z",
     "iopub.status.idle": "2021-09-25T15:37:36.091731Z",
     "shell.execute_reply": "2021-09-25T15:37:36.091602Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.091586Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_test_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.092503Z",
     "iopub.status.idle": "2021-09-25T15:37:36.092763Z",
     "shell.execute_reply": "2021-09-25T15:37:36.092636Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.092621Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.093662Z",
     "iopub.status.idle": "2021-09-25T15:37:36.094007Z",
     "shell.execute_reply": "2021-09-25T15:37:36.093876Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.093859Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_inet_polynomials'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:55.162513Z",
     "start_time": "2021-01-08T11:56:54.472198Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.094850Z",
     "iopub.status.idle": "2021-09-25T15:37:36.095162Z",
     "shell.execute_reply": "2021-09-25T15:37:36.094999Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.094982Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:56.434915Z",
     "start_time": "2021-01-08T11:56:55.669304Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.096137Z",
     "iopub.status.idle": "2021-09-25T15:37:36.096407Z",
     "shell.execute_reply": "2021-09-25T15:37:36.096279Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.096264Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T20:33:18.514683Z",
     "start_time": "2021-01-07T20:33:18.506614Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.097410Z",
     "iopub.status.idle": "2021-09-25T15:37:36.097792Z",
     "shell.execute_reply": "2021-09-25T15:37:36.097660Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.097643Z"
    }
   },
   "outputs": [],
   "source": [
    "index_min = int(np.argmin(distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials']))\n",
    "\n",
    "print(distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'][index_min])\n",
    "\n",
    "polynomial_lambda = lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list[index_min]\n",
    "print_polynomial_from_coefficients(polynomial_lambda, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:42.304392Z",
     "start_time": "2021-01-07T15:49:42.291475Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.098662Z",
     "iopub.status.idle": "2021-09-25T15:37:36.098993Z",
     "shell.execute_reply": "2021-09-25T15:37:36.098855Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.098839Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_values_inet = distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_inet_polynomials']\n",
    "print('Mean: ' + str(np.mean(r2_values_inet)) + ' (' + str(r2_values_inet.shape[0]) + ' Samples)')\n",
    "\n",
    "r2_values_positive_inet = r2_values_inet[r2_values_inet>0]\n",
    "print('Mean (only positive): ' + str(np.mean(r2_values_positive_inet)) + ' (' + str(r2_values_positive_inet.shape[0]) + ' Samples)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:42.833577Z",
     "start_time": "2021-01-07T15:49:42.821286Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.100055Z",
     "iopub.status.idle": "2021-09-25T15:37:36.100374Z",
     "shell.execute_reply": "2021-09-25T15:37:36.100205Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.100190Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_values_lstsq_lambda = distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials']\n",
    "print('Mean: ' + str(np.mean(r2_values_lstsq_lambda)) + ' (' + str(r2_values_inet.shape[0]) + ' Samples)')\n",
    "\n",
    "r2_values_positive_lstsq_lambda = r2_values_lstsq_lambda[r2_values_lstsq_lambda>0]\n",
    "print('Mean (only positive): ' + str(np.mean(r2_values_positive_lstsq_lambda)) + ' (' + str(r2_values_positive_lstsq_lambda.shape[0]) + ' Samples)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.101305Z",
     "iopub.status.idle": "2021-09-25T15:37:36.101587Z",
     "shell.execute_reply": "2021-09-25T15:37:36.101441Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.101426Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'] < 50], binwidth=0.1)\n",
    "#p.set(xlim=(0, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.102557Z",
     "iopub.status.idle": "2021-09-25T15:37:36.103040Z",
     "shell.execute_reply": "2021-09-25T15:37:36.102899Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.102881Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'] < 50], binwidth=0.1)\n",
    "p.set(xlim=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.103936Z",
     "iopub.status.idle": "2021-09-25T15:37:36.104227Z",
     "shell.execute_reply": "2021-09-25T15:37:36.104070Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.104054Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'] < 50], binwidth=0.1)\n",
    "#p.set(xlim=(0, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:44.179590Z",
     "start_time": "2021-01-07T15:49:43.001746Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.105205Z",
     "iopub.status.idle": "2021-09-25T15:37:36.105476Z",
     "shell.execute_reply": "2021-09-25T15:37:36.105340Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.105324Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'] < 50], binwidth=0.1)\n",
    "p.set(xlim=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.410283Z",
     "start_time": "2021-01-07T15:49:48.254228Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.106494Z",
     "iopub.status.idle": "2021-09-25T15:37:36.106823Z",
     "shell.execute_reply": "2021-09-25T15:37:36.106661Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.106646Z"
    }
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history[list(history.keys())[1]])\n",
    "    try:\n",
    "        plt.plot(history[list(history.keys())[len(history.keys())//2+1]]) \n",
    "    except:\n",
    "        pass\n",
    "    plt.title('model ' + list(history.keys())[1])\n",
    "    plt.ylabel('metric')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/metric_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.567983Z",
     "start_time": "2021-01-07T15:49:48.413234Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.107759Z",
     "iopub.status.idle": "2021-09-25T15:37:36.108073Z",
     "shell.execute_reply": "2021-09-25T15:37:36.107942Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.107926Z"
    }
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    try:\n",
    "        plt.plot(history['val_loss'])\n",
    "    except:\n",
    "        pass\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/loss_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Epoch/Sampes Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Comparison Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.108923Z",
     "iopub.status.idle": "2021-09-25T15:37:36.109208Z",
     "shell.execute_reply": "2021-09-25T15:37:36.109077Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.109061Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.110003Z",
     "iopub.status.idle": "2021-09-25T15:37:36.110372Z",
     "shell.execute_reply": "2021-09-25T15:37:36.110240Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.110223Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['MAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.111421Z",
     "iopub.status.idle": "2021-09-25T15:37:36.111851Z",
     "shell.execute_reply": "2021-09-25T15:37:36.111699Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.111681Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['R2 FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list, ylim=(-5, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate and Analyze Predictions for Random Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.112676Z",
     "iopub.status.idle": "2021-09-25T15:37:36.112989Z",
     "shell.execute_reply": "2021-09-25T15:37:36.112841Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.112825Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 6\n",
    "\n",
    "custom_representation_keys_fixed = ['target_polynomials', 'lstsq_target_polynomials', 'lstsq_lambda_pred_polynomials', 'lstsq_lambda_pred_polynomials']\n",
    "custom_representation_keys_dynamic = ['inet_polynomials', 'per_network_polynomials']\n",
    "sympy_representation_keys = ['metamodel_functions']\n",
    "\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "for key in polynomial_dict_test_list[-1].keys():\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print(key)\n",
    "    if key in custom_representation_keys_fixed:\n",
    "        print_polynomial_from_coefficients(polynomial_dict_test_list[-1][key][index], force_complete_poly_representation=True, round_digits=4)\n",
    "        print(polynomial_dict_test_list[-1][key][index])\n",
    "    elif key in custom_representation_keys_dynamic:\n",
    "        print_polynomial_from_coefficients(polynomial_dict_test_list[-1][key][index], round_digits=4)\n",
    "        print(polynomial_dict_test_list[-1][key][index])\n",
    "    else:\n",
    "        display(polynomial_dict_test_list[-1][key][index])\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:52.425282Z",
     "start_time": "2021-01-07T15:49:51.529992Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.113855Z",
     "iopub.status.idle": "2021-09-25T15:37:36.114194Z",
     "shell.execute_reply": "2021-09-25T15:37:36.114063Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.114047Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      polynomial_dict_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:57.631017Z",
     "start_time": "2021-01-07T15:49:52.427326Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.115015Z",
     "iopub.status.idle": "2021-09-25T15:37:36.115407Z",
     "shell.execute_reply": "2021-09-25T15:37:36.115239Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.115221Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      polynomial_dict_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.116269Z",
     "iopub.status.idle": "2021-09-25T15:37:36.116578Z",
     "shell.execute_reply": "2021-09-25T15:37:36.116433Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.116417Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      polynomial_dict_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.117583Z",
     "iopub.status.idle": "2021-09-25T15:37:36.117879Z",
     "shell.execute_reply": "2021-09-25T15:37:36.117730Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.117714Z"
    }
   },
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (RANDOM GUESS) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:50:04.140254Z",
     "start_time": "2021-01-07T15:50:03.647192Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.118869Z",
     "iopub.status.idle": "2021-09-25T15:37:36.119195Z",
     "shell.execute_reply": "2021-09-25T15:37:36.119015Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.118999Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_random_polynomials = np.random.uniform(low=-10, high=10, size=(len(lambda_net_test_dataset_list[-1]), sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.030192Z",
     "start_time": "2021-01-07T15:50:04.141837Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.120078Z",
     "iopub.status.idle": "2021-09-25T15:37:36.120439Z",
     "shell.execute_reply": "2021-09-25T15:37:36.120291Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.120273Z"
    }
   },
   "outputs": [],
   "source": [
    "true_fv_test = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)\n",
    "random_fv_test = parallel_fv_calculation_from_polynomial(list_of_random_polynomials, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.064612Z",
     "start_time": "2021-01-07T16:08:23.032372Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.121383Z",
     "iopub.status.idle": "2021-09-25T15:37:36.121668Z",
     "shell.execute_reply": "2021-09-25T15:37:36.121518Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.121502Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error Coefficients: ' + str(np.round(mean_absolute_error(lambda_net_test_dataset_list[-1].target_polynomial_list, list_of_random_polynomials), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.204426Z",
     "start_time": "2021-01-07T16:08:23.066205Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.122532Z",
     "iopub.status.idle": "2021-09-25T15:37:36.122950Z",
     "shell.execute_reply": "2021-09-25T15:37:36.122807Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.122790Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, random_fv_test), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (EDUCATED GUESS/MEAN PREDICTION) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:31.911007Z",
     "start_time": "2021-01-07T16:08:23.205879Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.123801Z",
     "iopub.status.idle": "2021-09-25T15:37:36.124072Z",
     "shell.execute_reply": "2021-09-25T15:37:36.123945Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.123930Z"
    }
   },
   "outputs": [],
   "source": [
    "true_fv_train = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)\n",
    "\n",
    "mean_fv = np.mean(true_fv_train)\n",
    "mean_fv_pred_test = [mean_fv for _ in range(true_fv_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.029945Z",
     "start_time": "2021-01-07T16:17:31.912980Z"
    },
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.125103Z",
     "iopub.status.idle": "2021-09-25T15:37:36.125398Z",
     "shell.execute_reply": "2021-09-25T15:37:36.125251Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.125235Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Educated Guess/Mean Prediction Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, mean_fv_pred_test), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.508984Z",
     "start_time": "2021-01-07T16:17:32.031355Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.126341Z",
     "iopub.status.idle": "2021-09-25T15:37:36.126685Z",
     "shell.execute_reply": "2021-09-25T15:37:36.126532Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.126515Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "base_model = generate_base_model()\n",
    "random_evaluation_dataset = np.random.uniform(low=x_min, high=x_max, size=(random_evaluation_dataset_size, n))\n",
    "#random_evaluation_dataset = lambda_train_input_train_split[0]#lambda_train_input[0] #JUST [0] HERE BECAUSE EVALUATION ALWAYS ON THE SAME DATASET FOR ALL!!\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)\n",
    "\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "#X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "\n",
    "seed_in_inet_training = False\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "seed_in_inet_training = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.127708Z",
     "iopub.status.idle": "2021-09-25T15:37:36.128028Z",
     "shell.execute_reply": "2021-09-25T15:37:36.127894Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.127877Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "current_jobs = 1\n",
    "\n",
    "lr=0.5\n",
    "max_steps = 100\n",
    "early_stopping=10\n",
    "restarts=2\n",
    "per_network_dataset_size = 500\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "if n_jobs != -1:\n",
    "    n_jobs_per_network = min(n_jobs, os.cpu_count() // current_jobs)\n",
    "else: \n",
    "    n_jobs_per_network = os.cpu_count() // current_jobs - 1\n",
    "\n",
    "printing = True if n_jobs_per_network == 1 else False\n",
    "\n",
    "\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "if evaluate_with_real_function: #target polynomial as inet target\n",
    "    poly_representation_list = np.array(lambda_net_test_dataset.target_polynomial_list)\n",
    "else: #lstsq lambda pred polynomial as inet target\n",
    "    poly_representation_list = np.array(lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list)\n",
    "\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         #'list_of_monomial_identifiers': list_of_monomial_identifiers,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "lambda_network_weights = lambda_network_weights_list[0]\n",
    "poly_representation = poly_representation_list[0]\n",
    "\n",
    "\n",
    "\n",
    "per_network_poly_optimization_tf(per_network_dataset_size, \n",
    "                                lambda_network_weights, \n",
    "                                  list_of_monomial_identifiers_numbers, \n",
    "                                  config, \n",
    "                                  lr=lr, \n",
    "                                  max_steps = max_steps, \n",
    "                                  early_stopping=early_stopping, \n",
    "                                  restarts=restarts, \n",
    "                                  printing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Real Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Auto MPG-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.128845Z",
     "iopub.status.idle": "2021-09-25T15:37:36.129263Z",
     "shell.execute_reply": "2021-09-25T15:37:36.129110Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.129093Z"
    }
   },
   "outputs": [],
   "source": [
    "interpretation_possible_autoMPG = False\n",
    "print_head_autoMPG = None\n",
    "\n",
    "url_autoMPG = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names_autoMPG = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset_autoMPG = pd.read_csv(url_autoMPG, names=column_names_autoMPG,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)\n",
    "\n",
    "dataset_autoMPG = raw_dataset_autoMPG.dropna()\n",
    "\n",
    "dataset_autoMPG['Origin'] = dataset_autoMPG['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset_autoMPG = pd.get_dummies(dataset_autoMPG, columns=['Origin'], prefix='', prefix_sep='')\n",
    "\n",
    "\n",
    "features_autoMPG = dataset_autoMPG.copy()\n",
    "\n",
    "labels_autoMPG = features_autoMPG.pop('MPG')\n",
    "\n",
    "features_autoMPG_normalized = (features_autoMPG-features_autoMPG.min())/(features_autoMPG.max()-features_autoMPG.min())\n",
    "\n",
    "#labels_autoMPG = (labels_autoMPG-labels_autoMPG.min())/(labels_autoMPG.max()-labels_autoMPG.min())\n",
    "\n",
    "\n",
    "if features_autoMPG_normalized.shape[1] >= n:\n",
    "    if n == 1:\n",
    "        features_autoMPG_model = features_autoMPG_normalized[['Horsepower']]\n",
    "    elif n == features_autoMPG_normalized.shape[1]:\n",
    "        features_autoMPG_model = features_autoMPG_normalized\n",
    "    else:\n",
    "        features_autoMPG_model = features_autoMPG_normalized.sample(n=n, axis='columns')\n",
    "        \n",
    "    print_head_autoMPG = features_autoMPG_model.head()\n",
    "    interpretation_possible_autoMPG = True\n",
    "\n",
    "print_head_autoMPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.130121Z",
     "iopub.status.idle": "2021-09-25T15:37:36.130416Z",
     "shell.execute_reply": "2021-09-25T15:37:36.130270Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.130254Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.131395Z",
     "iopub.status.idle": "2021-09-25T15:37:36.131926Z",
     "shell.execute_reply": "2021-09-25T15:37:36.131730Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.131711Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    ((lambda_index_autoMPG, \n",
    "     current_seed_autoMPG, \n",
    "     polynomial_autoMPG, \n",
    "     polynomial_lstsq_pred_list_autoMPG, \n",
    "     polynomial_lstsq_true_list_autoMPG), \n",
    "    scores_list_autoMPG, \n",
    "    pred_list_autoMPG, \n",
    "    history_autoMPG, \n",
    "    model_autoMPG) = train_nn(lambda_index=0, \n",
    "                              X_data_lambda=features_autoMPG_model.values, \n",
    "                              y_data_real_lambda=labels_autoMPG.values, \n",
    "                              polynomial=None, \n",
    "                              seed_list=[RANDOM_SEED], \n",
    "                              callbacks=[PlotLossesKerasTF()], \n",
    "                              return_history=True, \n",
    "                              each_epochs_save=None, \n",
    "                              printing=False, \n",
    "                              return_model=True)\n",
    "    \n",
    "    polynomial_lstsq_pred_autoMPG = polynomial_lstsq_pred_list_autoMPG[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.133219Z",
     "iopub.status.idle": "2021-09-25T15:37:36.133520Z",
     "shell.execute_reply": "2021-09-25T15:37:36.133352Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.133337Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and n==1:\n",
    "    x = tf.linspace(0.0, 250, 251)\n",
    "    y = model_autoMPG.predict(x)\n",
    "\n",
    "    plt.scatter(features_autoMPG_model['Horsepower'], labels_autoMPG, label='Data')\n",
    "    plt.plot(x, y, color='k', label='Predictions')\n",
    "    plt.xlabel('Horsepower')\n",
    "    plt.ylabel('MPG')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.134387Z",
     "iopub.status.idle": "2021-09-25T15:37:36.134834Z",
     "shell.execute_reply": "2021-09-25T15:37:36.134687Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.134669Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "        'n': n,\n",
    "        'd': d,\n",
    "        'inet_loss': inet_loss,\n",
    "        'sparsity': sparsity,\n",
    "        'lambda_network_layers': lambda_network_layers,\n",
    "        'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "        'RANDOM_SEED': RANDOM_SEED,\n",
    "        'nas': nas,\n",
    "        'number_of_lambda_weights': number_of_lambda_weights,\n",
    "        'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "        'fixed_initialization_lambda_training': fixed_initialization_lambda_training,\n",
    "        'dropout': dropout,\n",
    "        'lambda_network_layers': lambda_network_layers,\n",
    "        'optimizer_lambda': optimizer_lambda,\n",
    "        'loss_lambda': loss_lambda,        \n",
    "         #'list_of_monomial_identifiers': list_of_monomial_identifiers,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "weights_autoMPG = model_autoMPG.get_weights()\n",
    "\n",
    "weights_flat_autoMPG = []\n",
    "for layer_weights, biases in pairwise(weights_autoMPG):    #clf.get_weights()\n",
    "    for neuron in layer_weights:\n",
    "        for weight in neuron:\n",
    "            weights_flat_autoMPG.append(weight)\n",
    "    for bias in biases:\n",
    "        weights_flat_autoMPG.append(bias)\n",
    "        \n",
    "weights_flat_autoMPG = np.array(weights_flat_autoMPG)\n",
    "\n",
    "\n",
    "x = pred_list_autoMPG['X_test_lambda']\n",
    "y = pred_list_autoMPG['y_test_real_lambda']\n",
    "\n",
    "y_model_autoMPG = model_autoMPG.predict(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.135644Z",
     "iopub.status.idle": "2021-09-25T15:37:36.135920Z",
     "shell.execute_reply": "2021-09-25T15:37:36.135776Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.135760Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "    y_polynomial_lstsq_pred_autoMPG = calculate_function_values_from_polynomial(polynomial_lstsq_pred_autoMPG, x, force_complete_poly_representation=True)\n",
    "\n",
    "    mae_model_polynomial_lstsq_pred_autoMPGy = mean_absolute_error(y_model_autoMPG, y_polynomial_lstsq_pred_autoMPG)\n",
    "    mae_data_polynomial_lstsq_pred_autoMPG = mean_absolute_error(y, y_polynomial_lstsq_pred_autoMPG)\n",
    "\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('LSTSQt Poly:')\n",
    "    print_polynomial_from_coefficients(y_polynomial_lstsq_pred_autoMPG, force_complete_poly_representation=True)\n",
    "    print('MAE Model: ', mae_model_polynomial_lstsq_pred_autoMPGy)\n",
    "    print('MAE Data: ', mae_data_polynomial_lstsq_pred_autoMPG)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.136848Z",
     "iopub.status.idle": "2021-09-25T15:37:36.137256Z",
     "shell.execute_reply": "2021-09-25T15:37:36.137119Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.137101Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    interpretation_net = model_list[-1]\n",
    "    \n",
    "    start = time.time() \n",
    "    \n",
    "    #interpretation_net_poly = interpretation_net.predict(np.array([weights_flat_autoMPG]))[0]\n",
    "    interpretation_net_poly = make_inet_prediction(interpretation_net, weights_flat_autoMPG, network_data=None, lambda_trained_normalized=False, inet_training_normalized=normalize_inet_data, normalization_parameter_dict=None)\n",
    "    \n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_interpretation_net_poly = calculate_function_values_from_polynomial(interpretation_net_poly, x, force_complete_poly_representation=False)\n",
    "    \n",
    "    mae_model_interpretation_net_poly = mean_absolute_error(y_model_autoMPG, y_interpretation_net_poly)\n",
    "    mae_data_interpretation_net_poly = mean_absolute_error(y, y_interpretation_net_poly)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Interpretation Net Poly:')\n",
    "    print_polynomial_from_coefficients(interpretation_net_poly, force_complete_poly_representation=False)\n",
    "    print('MAE Model: ', mae_model_interpretation_net_poly)\n",
    "    print('MAE Data: ', mae_data_interpretation_net_poly)    \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.138274Z",
     "iopub.status.idle": "2021-09-25T15:37:36.138568Z",
     "shell.execute_reply": "2021-09-25T15:37:36.138439Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.138423Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "\n",
    "    start = time.time() \n",
    "    \n",
    "    if False:\n",
    "        per_network_hyperparams = {\n",
    "            'optimizer':  'Powell',\n",
    "            'jac': 'fprime',\n",
    "            'max_steps': 5000,#100,\n",
    "            'restarts': 3,\n",
    "            'per_network_dataset_size': 500,\n",
    "        }      \n",
    "        \n",
    "        per_network_function =  per_network_poly_optimization_scipy(per_network_dataset_size, \n",
    "                                                                  weights_flat_autoMPG, \n",
    "                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                  config, \n",
    "                                                                  optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                  jac = per_network_hyperparams['jac'],\n",
    "                                                                  max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                  restarts=per_network_hyperparams['restarts'], \n",
    "                                                                  printing=True,\n",
    "                                                                  return_error=False)\n",
    "    else:\n",
    "        per_network_hyperparams = {\n",
    "            'optimizer': tf.keras.optimizers.RMSprop,\n",
    "            'lr': 0.02,\n",
    "            'max_steps': 500,\n",
    "            'early_stopping': 10,\n",
    "            'restarts': 3,\n",
    "            'per_network_dataset_size': 5000,\n",
    "        }   \n",
    "        \n",
    "        per_network_function =  per_network_poly_optimization_tf(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                              weights_flat_autoMPG, \n",
    "                                                              list_of_monomial_identifiers_numbers, \n",
    "                                                              config, \n",
    "                                                              optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                              lr=per_network_hyperparams['lr'], \n",
    "                                                              max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                              early_stopping=per_network_hyperparams['early_stopping'], \n",
    "                                                              restarts=per_network_hyperparams['restarts'], \n",
    "                                                              printing=True,\n",
    "                                                              return_error=False)\n",
    "            \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)  \n",
    "    \n",
    "    y_per_network_function = calculate_function_values_from_polynomial(per_network_function, x, force_complete_poly_representation=False)\n",
    "    \n",
    "    mae_model_interpretation_net_poly = mean_absolute_error(y_model_autoMPG, y_per_network_function)\n",
    "    mae_data_interpretation_net_poly = mean_absolute_error(y, y_per_network_function)    \n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Per Network Poly:')\n",
    "    print_polynomial_from_coefficients(per_network_function)\n",
    "    print('MAE Model: ', mae_model_interpretation_net_poly)\n",
    "    print('MAE Data: ', mae_data_interpretation_net_poly)       \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.139546Z",
     "iopub.status.idle": "2021-09-25T15:37:36.139816Z",
     "shell.execute_reply": "2021-09-25T15:37:36.139683Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.139667Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.140729Z",
     "iopub.status.idle": "2021-09-25T15:37:36.141026Z",
     "shell.execute_reply": "2021-09-25T15:37:36.140881Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.140866Z"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    \n",
    "    symbolic_regression_hyperparams = {\n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "\n",
    "    start = time.time() \n",
    "    \n",
    "    symbolic_regression_function =  symbolic_regression(model_autoMPG, \n",
    "                                                      config,\n",
    "                                                      symbolic_regression_hyperparams,\n",
    "                                                      #printing = True,\n",
    "                                                      return_error = False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    variable_names = ['X' + str(i) for i in range(n)]\n",
    "    \n",
    "    y_symbolic_regression_function = calculate_function_values_from_sympy(symbolic_regression_function, x, variable_names=variable_names)\n",
    "    \n",
    "    mae_model_symbolic_regression_function = mean_absolute_error(y_model_autoMPG, y_symbolic_regression_function)\n",
    "    mae_data_symbolic_regression_function = mean_absolute_error(y, y_symbolic_regression_function)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Symbolic Regression Poly:')    \n",
    "    display(symbolic_regression_function)\n",
    "    print('MAE Model: ', mae_model_symbolic_regression_function)\n",
    "    print('MAE Data: ', mae_data_symbolic_regression_function)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.141850Z",
     "iopub.status.idle": "2021-09-25T15:37:36.142526Z",
     "shell.execute_reply": "2021-09-25T15:37:36.142031Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.142010Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG and True:\n",
    "    metamodeling_hyperparams = {\n",
    "        'num_iter': 500,\n",
    "        'batch_size': None,\n",
    "        'learning_rate': 0.01,        \n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "    \n",
    "    start = time.time() \n",
    "\n",
    "    metamodel_function =  symbolic_metamodeling(model_autoMPG, \n",
    "                                              config,\n",
    "                                              metamodeling_hyperparams,\n",
    "                                              #printing = True,\n",
    "                                              return_error = False,\n",
    "                                              return_expression = 'approx', #'approx', #'exact',\n",
    "                                              function_metamodeling = False,\n",
    "                                              force_polynomial=False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_metamodel_function = calculate_function_values_from_sympy(metamodel_function, x)\n",
    "    \n",
    "    mae_model_metamodel_function = mean_absolute_error(y_model_autoMPG, y_metamodel_function)\n",
    "    mae_data_metamodel_function = mean_absolute_error(y, y_metamodel_function)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function:')    \n",
    "    display(metamodel_function)\n",
    "    print('MAE Model: ', mae_model_metamodel_function)\n",
    "    print('MAE Data: ', mae_data_metamodel_function)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.144628Z",
     "iopub.status.idle": "2021-09-25T15:37:36.145071Z",
     "shell.execute_reply": "2021-09-25T15:37:36.144920Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.144901Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and False:\n",
    "    metamodeling_hyperparams = {\n",
    "        'num_iter': 500,\n",
    "        'batch_size': None,\n",
    "        'learning_rate': 0.01,        \n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "    \n",
    "    start = time.time() \n",
    "\n",
    "    metamodel_function_basic =  symbolic_metamodeling(model_autoMPG, \n",
    "                                              config,\n",
    "                                              metamodeling_hyperparams,\n",
    "                                              #printing = True,\n",
    "                                              return_error = False,\n",
    "                                              return_expression = 'approx', #'approx', #'exact',\n",
    "                                              function_metamodeling = True,\n",
    "                                              force_polynomial=False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_metamodel_function_basic = calculate_function_values_from_sympy(metamodel_function_basic, x)\n",
    "    \n",
    "    mae_metamodel_function_basic = mean_absolute_error(y_model_autoMPG, y_metamodel_function_basic)\n",
    "    mae_metamodel_function_basic = mean_absolute_error(y, y_metamodel_function_basic)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function Basic:')    \n",
    "    display(metamodel_function_basic)\n",
    "    print('MAE Model: ', mae_metamodel_function_basic)\n",
    "    print('MAE Data: ', mae_metamodel_function_basic)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.146215Z",
     "iopub.status.idle": "2021-09-25T15:37:36.146599Z",
     "shell.execute_reply": "2021-09-25T15:37:36.146441Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.146423Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Interpretation Net Poly:')\n",
    "    print_polynomial_from_coefficients(interpretation_net_poly, force_complete_poly_representation=False)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Per Network Poly:')\n",
    "    print_polynomial_from_coefficients(per_network_function, force_complete_poly_representation=False)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('LSTSQ Poly:')\n",
    "    print_polynomial_from_coefficients(polynomial_lstsq_pred_autoMPG, force_complete_poly_representation=True)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Symbolic Regression Function:')\n",
    "    display(symbolic_regression_function)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function:')\n",
    "    display(metamodel_function)\n",
    "    #print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    #print('Metamodel Function Basic:')\n",
    "    #display(metamodel_function_basic)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.147508Z",
     "iopub.status.idle": "2021-09-25T15:37:36.147785Z",
     "shell.execute_reply": "2021-09-25T15:37:36.147659Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.147644Z"
    }
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and n==1:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
    "    \n",
    "    ax.set_ylim([0,50])\n",
    "    \n",
    "    plt.scatter(features_autoMPG_model['Horsepower'], labels_autoMPG, label='Data')\n",
    "    plt.scatter(x, y, label='Test Data')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_model_autoMPG))]) , label='Model Predictions')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_interpretation_net_poly))]) , label='Interpretation Net Poly')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_per_network_function))]) , label='Per Network Poly')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_polynomial_lstsq_pred_autoMPG))]) , label='LSTSQ Poly')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_symbolic_regression_function))]) , label='Symbolic Regression Function')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_metamodel_function))]) , label='Metamodel Function')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y))]) y_metamodel_function_basic, label='Metamodel Function Basic')\n",
    "    plt.xlabel('Horsepower')\n",
    "    plt.ylabel('MPG')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.149032Z",
     "iopub.status.idle": "2021-09-25T15:37:36.149372Z",
     "shell.execute_reply": "2021-09-25T15:37:36.149242Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.149226Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_data_X = np.array([i for i in range(1000)])\n",
    "sample_data_y = np.array([3*i for i in range(1000)])\n",
    "\n",
    "current_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.150218Z",
     "iopub.status.idle": "2021-09-25T15:37:36.150589Z",
     "shell.execute_reply": "2021-09-25T15:37:36.150392Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.150376Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.151575Z",
     "iopub.status.idle": "2021-09-25T15:37:36.151899Z",
     "shell.execute_reply": "2021-09-25T15:37:36.151775Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.151760Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y*1000,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.153072Z",
     "iopub.status.idle": "2021-09-25T15:37:36.153437Z",
     "shell.execute_reply": "2021-09-25T15:37:36.153281Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.153264Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y+1000,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.154402Z",
     "iopub.status.idle": "2021-09-25T15:37:36.154649Z",
     "shell.execute_reply": "2021-09-25T15:37:36.154528Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.154513Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_2_weights = model.get_weights()\n",
    "model_2_normalized_weights = model_2_weights #[weights/10 for weights in model_2_weights]\n",
    "\n",
    "\n",
    "model_2_normalized_weights[-6] = model_2_normalized_weights[-6]/10\n",
    "model_2_normalized_weights[-5] = model_2_normalized_weights[-5]/10\n",
    "\n",
    "model_2_normalized_weights[-4] = model_2_normalized_weights[-4]/10\n",
    "model_2_normalized_weights[-3] = model_2_normalized_weights[-3]/100\n",
    "\n",
    "model_2_normalized_weights[-2] = model_2_normalized_weights[-2]/10\n",
    "model_2_normalized_weights[-1] = model_2_normalized_weights[-1]/1000\n",
    "\n",
    "model_2.set_weights(model_2_normalized_weights)\n",
    "\n",
    "print(model_2.get_weights())\n",
    "print(model_2.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Per-Network Poly Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Optimization (Common Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.155827Z",
     "iopub.status.idle": "2021-09-25T15:37:36.156188Z",
     "shell.execute_reply": "2021-09-25T15:37:36.156059Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.156043Z"
    }
   },
   "outputs": [],
   "source": [
    "random_index = RANDOM_SEED\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer':  'Powell',\n",
    "    'jac': 'fprime',\n",
    "    'max_steps': 5000,#100,\n",
    "    'restarts': 3,\n",
    "    'per_network_dataset_size': 500,\n",
    "}\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "lambda_network_weights = lambda_network_weights_list[random_index]\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "printing = True\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "per_network_optimization_error, per_network_optimization_polynomial = per_network_poly_optimization_scipy(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                                                                      lambda_network_weights, \n",
    "                                                                                                      list_of_monomial_identifiers_numbers, \n",
    "                                                                                                      config,\n",
    "                                                                                                      optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                                                      jac = per_network_hyperparams['jac'],\n",
    "                                                                                                      max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                                                      restarts = per_network_hyperparams['restarts'],\n",
    "                                                                                                      printing = True,\n",
    "                                                                                                      return_error = True)\n",
    "\n",
    "print('\\n\\nError: ' + str(per_network_optimization_error))\n",
    "print_polynomial_from_coefficients(per_network_optimization_polynomial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Optimization (Neural Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.157170Z",
     "iopub.status.idle": "2021-09-25T15:37:36.157412Z",
     "shell.execute_reply": "2021-09-25T15:37:36.157293Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.157279Z"
    }
   },
   "outputs": [],
   "source": [
    "random_index = RANDOM_SEED\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer': tf.keras.optimizers.RMSprop,\n",
    "    'lr': 0.02,\n",
    "    'max_steps': 500,\n",
    "    'early_stopping': 10,\n",
    "    'restarts': 3,\n",
    "    'per_network_dataset_size': 5000,\n",
    "}\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "lambda_network_weights = lambda_network_weights_list[random_index]\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "printing = True\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "per_network_optimization_error, per_network_optimization_polynomial = per_network_poly_optimization_tf(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                                                                      lambda_network_weights, \n",
    "                                                                                                      list_of_monomial_identifiers_numbers, \n",
    "                                                                                                      config,\n",
    "                                                                                                      optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                                                      lr = per_network_hyperparams['lr'], \n",
    "                                                                                                      max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                                                      early_stopping = per_network_hyperparams['early_stopping'], \n",
    "                                                                                                      restarts = per_network_hyperparams['restarts'],\n",
    "                                                                                                      printing = True,\n",
    "                                                                                                      return_error = True)\n",
    "\n",
    "print('\\n\\nError: ' + str(per_network_optimization_error.numpy()))\n",
    "print_polynomial_from_coefficients(per_network_optimization_polynomial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Common Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.158475Z",
     "iopub.status.idle": "2021-09-25T15:37:36.158899Z",
     "shell.execute_reply": "2021-09-25T15:37:36.158756Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.158721Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "evaluation_size = 10\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer':  [\n",
    "                   'Nelder-Mead', \n",
    "                   'Powell', \n",
    "        \n",
    "                   'CG',\n",
    "                   'BFGS',\n",
    "                   'Newton-CG', \n",
    "                   #'L-BFGS-B', #'>' not supported between instances of 'int' and 'NoneType'\n",
    "                   'TNC', \n",
    "                   \n",
    "                   'COBYLA', \n",
    "                   'SLSQP', \n",
    "                   \n",
    "                   #'trust-constr', # TypeError: _minimize_trustregion_constr() got an unexpected keyword argument 'maxfun'\n",
    "                   #'dogleg', # ValueError: Hessian is required for dogleg minimization\n",
    "                   #'trust-ncg', #ValueError: Either the Hessian or the Hessian-vector product is required for Newton-CG trust-region minimization\n",
    "                   #'trust-exact', # ValueError: Hessian matrix is required for trust region exact minimization.\n",
    "                   #'trust-krylov' #ValueError: Either the Hessian or the Hessian-vector product is required for Krylov trust-region minimization\n",
    "                   ], \n",
    "    'jac': ['fprime'],\n",
    "    'max_steps': [5000],#100,\n",
    "    'restarts': [3],\n",
    "    'per_network_dataset_size': [500],\n",
    "}\n",
    "\n",
    "#param_iterator = ParameterSampler(per_network_hyperparams, n_iter=60, random_state=RANDOM_SEED)\n",
    "param_iterator = ParameterGrid(per_network_hyperparams)\n",
    "\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "printing = True if n_jobs == 1 else False\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.159853Z",
     "iopub.status.idle": "2021-09-25T15:37:36.160153Z",
     "shell.execute_reply": "2021-09-25T15:37:36.160031Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.160016Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "params_error_list = []\n",
    "for params in tqdm(param_iterator):\n",
    "    parallel_per_network = Parallel(n_jobs=n_jobs, verbose=0, backend='loky')\n",
    "\n",
    "    result_list = parallel_per_network(delayed(per_network_poly_optimization_scipy)(params['per_network_dataset_size'], \n",
    "                                                                                  lambda_network_weights, \n",
    "                                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                                  config,\n",
    "                                                                                  optimizer = params['optimizer'],\n",
    "                                                                                  jac = params['jac'],\n",
    "                                                                                  max_steps = params['max_steps'], \n",
    "                                                                                  restarts = params['restarts'],\n",
    "                                                                                  printing = printing,\n",
    "                                                                                  return_error = True) for lambda_network_weights in lambda_network_weights_list[:evaluation_size])  \n",
    "    \n",
    "    \n",
    "    per_network_optimization_errors = [result[0] for result in result_list]\n",
    "    per_network_optimization_polynomials = [result[1] for result in result_list]\n",
    "        \n",
    "    params_score = np.mean(per_network_optimization_errors)\n",
    "    \n",
    "    evaluation_result = list(params.values())\n",
    "    evaluation_result.append(params_score)\n",
    "    \n",
    "    params_error_list.append(evaluation_result)\n",
    "        \n",
    "    del parallel_per_network\n",
    "\n",
    "columns = list(params.keys())\n",
    "columns.append('score')\n",
    "params_error_df = pd.DataFrame(data=params_error_list, columns=columns).sort_values(by='score')\n",
    "params_error_df.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Neural Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.161082Z",
     "iopub.status.idle": "2021-09-25T15:37:36.161399Z",
     "shell.execute_reply": "2021-09-25T15:37:36.161239Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.161224Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "evaluation_size = 100\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer': [tf.keras.optimizers.RMSprop], #[tf.keras.optimizers.SGD, tf.optimizers.Adam, tf.keras.optimizers.RMSprop, tf.keras.optimizers.Adadelta]\n",
    "    'lr': [0.02], #[0.5, 0.25, 0.1, 0.05, 0.025]\n",
    "    'max_steps': [5000],#100,\n",
    "    'early_stopping': [10],\n",
    "    'restarts': [3],\n",
    "    'per_network_dataset_size': [5000],\n",
    "}\n",
    "\n",
    "#param_iterator = ParameterSampler(per_network_hyperparams, n_iter=60, random_state=RANDOM_SEED)\n",
    "param_iterator = ParameterGrid(per_network_hyperparams)\n",
    "\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "printing = True if n_jobs == 1 else False\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.167791Z",
     "iopub.status.idle": "2021-09-25T15:37:36.168106Z",
     "shell.execute_reply": "2021-09-25T15:37:36.167983Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.167968Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "params_error_list = []\n",
    "for params in tqdm(param_iterator):\n",
    "    parallel_per_network = Parallel(n_jobs=n_jobs, verbose=0, backend='loky')\n",
    "\n",
    "    result_list = parallel_per_network(delayed(per_network_poly_optimization_tf)(params['per_network_dataset_size'], \n",
    "                                                                                  lambda_network_weights, \n",
    "                                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                                  config,\n",
    "                                                                                  optimizer = params['optimizer'],\n",
    "                                                                                  lr = params['lr'], \n",
    "                                                                                  max_steps = params['max_steps'], \n",
    "                                                                                  early_stopping = params['early_stopping'], \n",
    "                                                                                  restarts = params['restarts'],\n",
    "                                                                                  printing = printing,\n",
    "                                                                                  return_error = True) for lambda_network_weights in lambda_network_weights_list[:evaluation_size])  \n",
    "    \n",
    "    \n",
    "    per_network_optimization_errors = [result[0] for result in result_list]\n",
    "    per_network_optimization_polynomials = [result[1] for result in result_list]\n",
    "        \n",
    "    params_score = np.mean(per_network_optimization_errors)\n",
    "    \n",
    "    evaluation_result = list(params.values())\n",
    "    evaluation_result.append(params_score)\n",
    "    \n",
    "    params_error_list.append(evaluation_result)\n",
    "        \n",
    "    del parallel_per_network\n",
    "\n",
    "columns = list(params.keys())\n",
    "columns.append('score')\n",
    "params_error_df = pd.DataFrame(data=params_error_list, columns=columns).sort_values(by='score')\n",
    "params_error_df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-25T15:37:36.169035Z",
     "iopub.status.idle": "2021-09-25T15:37:36.169353Z",
     "shell.execute_reply": "2021-09-25T15:37:36.169224Z",
     "shell.execute_reply.started": "2021-09-25T15:37:36.169209Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
