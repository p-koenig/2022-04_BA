{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Generation for the Training of Î»-Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T12:26:49.061308Z",
     "start_time": "2020-09-16T12:26:49.055692Z"
    }
   },
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'data': {\n",
    "        'd': 3, #degree\n",
    "        'n': 5, #number of variables\n",
    "        'monomial_vars': None, #int or None\n",
    "        'laurent': False, #use Laurent polynomials (negative degree with up to -d)\n",
    "        'neg_d': 0, #int or None\n",
    "        'neg_d_prob': 0, #probability before other adjustments\n",
    "        'sparsity': None,\n",
    "        'sample_sparsity': 5,\n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',\n",
    "        'a_max': 1,\n",
    "        'a_min': -1,\n",
    "        'polynomial_data_size': 50000, #number of polynomials to generate\n",
    "        'noise': 0, #fraction of mean(abs(y_data)) \n",
    "        'noise_distrib': 'normal', #'normal', 'uniform'\n",
    "        \n",
    "        'function_generation_type': 'polynomial',# 'friedman1', 'polynomial'\n",
    "        \n",
    "        'shift_polynomial': False,\n",
    "        \n",
    "        'border_min': 0.2, # defines an intervall. Value is randomly chosen and defines the minimum gap between x_min / x_max and the outermost stationary points => two values (left and right gap will be generated per variable)\n",
    "        'border_max': 0.4,\n",
    "        'lower_degree_prob': 0.5, # probability that the degree of the whole polynomial will be reduced\n",
    "        'a_random_prob': 0.5, # probability that a random generated function is used without adjustement\n",
    "                \n",
    "        'global_stationary_prob': 1, # probability that all variables are used for adjustement (0 recommended for higher number of variables)\n",
    "        'bulge_min': 1, # bulge_min and bulge_max define an intervall of how much the function is bulged\n",
    "        'bulge_max': 4,\n",
    "        'min_variables_used': 2, # defines an Intervall of how many variables are used to get stationary points and therefore adjust the function\n",
    "        'max_variables_used': 6,\n",
    "        'max_monomials': 7, # maximum number of monomials, before adjusting the function (monomial of degree 0 is always defined, but is included in this number)\n",
    "        'max_monomials_random': 10, #maximum number of monomials for random generated functions\n",
    "        \n",
    "        'same_training_all_lambda_nets': False,\n",
    "    },\n",
    "    'lambda_net': {\n",
    "        'lambda_dataset_size': 50000, #number of samples per polynomial\n",
    "    },    \n",
    "    'computation':{\n",
    "        'n_jobs': 10,\n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 1,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T12:26:58.879427Z",
     "start_time": "2020-09-16T12:26:58.874894Z"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T21:12:40.476681Z",
     "start_time": "2021-01-13T21:12:38.298249Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "tf.autograph.set_verbosity(2)\n",
    "\n",
    "from itertools import product       # forms cartesian products\n",
    "from more_itertools import random_product \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import random \n",
    "from random import sample \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sympy import Symbol, sympify\n",
    "\n",
    "        \n",
    "import seaborn as sns\n",
    "        \n",
    "import random \n",
    "\n",
    "import warnings\n",
    "\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n] \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 56\n",
      "[[3, 0, 0, 0, 0], [2, 1, 0, 0, 0], [2, 0, 1, 0, 0], [2, 0, 0, 1, 0], [2, 0, 0, 0, 1], [2, 0, 0, 0, 0], [1, 2, 0, 0, 0], [1, 1, 1, 0, 0], [1, 1, 0, 1, 0], [1, 1, 0, 0, 1], [1, 1, 0, 0, 0], [1, 0, 2, 0, 0], [1, 0, 1, 1, 0], [1, 0, 1, 0, 1], [1, 0, 1, 0, 0], [1, 0, 0, 2, 0], [1, 0, 0, 1, 1], [1, 0, 0, 1, 0], [1, 0, 0, 0, 2], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0], [0, 3, 0, 0, 0], [0, 2, 1, 0, 0], [0, 2, 0, 1, 0], [0, 2, 0, 0, 1], [0, 2, 0, 0, 0], [0, 1, 2, 0, 0], [0, 1, 1, 1, 0], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0], [0, 1, 0, 2, 0], [0, 1, 0, 1, 1], [0, 1, 0, 1, 0], [0, 1, 0, 0, 2], [0, 1, 0, 0, 1], [0, 1, 0, 0, 0], [0, 0, 3, 0, 0], [0, 0, 2, 1, 0], [0, 0, 2, 0, 1], [0, 0, 2, 0, 0], [0, 0, 1, 2, 0], [0, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 0, 1, 0, 2], [0, 0, 1, 0, 1], [0, 0, 1, 0, 0], [0, 0, 0, 3, 0], [0, 0, 0, 2, 1], [0, 0, 0, 2, 0], [0, 0, 0, 1, 2], [0, 0, 0, 1, 1], [0, 0, 0, 1, 0], [0, 0, 0, 0, 3], [0, 0, 0, 0, 2], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "from utilities.utility_functions import flatten, rec_gen, gen_monomial_identifier_list\n",
    "\n",
    "list_of_monomial_identifiers_extended = []\n",
    "\n",
    "if laurent:\n",
    "    variable_sets = [list(flatten([[_d for _d in range(d+1)], [-_d for _d in range(1, neg_d+1)]])) for _ in range(n)]\n",
    "    list_of_monomial_identifiers_extended = rec_gen(variable_sets)    \n",
    "        \n",
    "    print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "    #print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "    #print('Sparsity:' + str(sparsity))\n",
    "    if len(list_of_monomial_identifiers_extended) < 500:\n",
    "        print(list_of_monomial_identifiers_extended)     \n",
    "        \n",
    "    list_of_monomial_identifiers = []\n",
    "    for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "        if np.sum(monomial_identifier) <= d:\n",
    "            if monomial_vars == None or len(list(filter(lambda x: x != 0, monomial_identifier))) <= monomial_vars:\n",
    "                list_of_monomial_identifiers.append(monomial_identifier)        \n",
    "else:\n",
    "    variable_list = ['x'+ str(i) for i in range(n)]\n",
    "    list_of_monomial_identifiers = gen_monomial_identifier_list(variable_list, d, n)\n",
    "            \n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "#print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "#print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'KeyError'>\n",
      "<class 'KeyError'>\n"
     ]
    }
   ],
   "source": [
    "from utilities.utility_functions import *\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "config['data']['sparsity'] = nCr(config['data']['n']+config['data']['d'], config['data']['d']) if not laurent else len(list_of_monomial_identifiers)\n",
    "#nCr(config['data']['n']+config['data']['d'], config['data']['d']) if not laurent else (config['data']['d']*2+1)**config['data']['n'] - np.sum([i for i in range(1, config['data']['d']+1)])#- math.factorial(config['data']['d'])\n",
    "#nCr(config['data']['n']+config['data']['d'], config['data']['d']) if not laurent else nCr(config['data']['n']+config['data']['d']*2, config['data']['d']*2)\n",
    "\n",
    "config['data']['sample_sparsity'] = config['data']['sparsity'] if config['data']['sample_sparsity'] == None else config['data']['sample_sparsity']\n",
    "    \n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "initialize_utility_functions_config_from_curent_notebook(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(path_type='data_creation'))\n",
    "generate_directory_structure()\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly_50000_train_50000_var_5_d_3_negd_0_prob_0_spars_5_amin_-1_amax_1_xdist_uniform_noise_normal_0_polynomial_diffX\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_polynomial_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: 5 (abcde)\n",
      "Degree: 3\n",
      "Sparsity: 56\n",
      "Lambda-Net Dataset Size: 50000\n",
      "I-Net Dataset Size: 50000\n",
      "Coefficient Range: [-1, 1]\n",
      "Variable Range: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "##############DO NOT CHANGE###################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "    \n",
    "print('Variables: ' + str(n) + ' (' + variables + ')')\n",
    "print('Degree: ' + str(d))\n",
    "print('Sparsity: ' + str(sparsity)) \n",
    "print('Lambda-Net Dataset Size: ' + str(lambda_dataset_size))\n",
    "print('I-Net Dataset Size: ' + str(polynomial_data_size))\n",
    "      \n",
    "print('Coefficient Range: ' + '[' + str(a_min) + ', ' + str(a_max) + ']')\n",
    "print('Variable Range: ' + '[' + str(x_min) + ', ' + str(x_max) + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T12:28:46.853042Z",
     "start_time": "2020-09-16T12:28:46.848346Z"
    }
   },
   "source": [
    "# Function Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cc114f20294782978daca0679d7183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "(50000, 56)\n"
     ]
    }
   ],
   "source": [
    "if function_generation_type == 'polynomial':\n",
    "    if shift_polynomial:\n",
    "        all_sparsities = [nCr(n+i, i) for i in range(d+1)]\n",
    "        start = perf_counter()\n",
    "        parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "        list_of_polynomials = parallel(delayed(get_polynomial_basic)(all_sparsities)for i in range(polynomial_data_size))\n",
    "        list_of_polynomials = np.array(list_of_polynomials).astype('float64')\n",
    "        end = perf_counter()\n",
    "        print('Zeit zum generieren:', end-start, 'Sekunden')\n",
    "        print('Zeit zum generieren pro Funktion:', (end-start)/polynomial_data_size)\n",
    "    else:\n",
    "        list_of_polynomials = np.random.uniform(low=a_min, high=a_max, size=(polynomial_data_size, sparsity))   \n",
    "\n",
    "        if sample_sparsity < sparsity:\n",
    "            for polynomial in tqdm(list_of_polynomials):\n",
    "                sparsity_indices = np.random.choice(nCr(n+d, d), nCr(n+d, d)-sample_sparsity, replace=False)\n",
    "                for sparsity_index in sparsity_indices:                            \n",
    "                    polynomial[sparsity_index] = 0\n",
    "\n",
    "\n",
    "    list_of_monomial_identifiers_string = [''.join(str(e) for e in monomial_identifier) for monomial_identifier in list_of_monomial_identifiers] if n > 1 else [str(monomial_identifier[0]) for monomial_identifier in list_of_monomial_identifiers]\n",
    "    polynomials_list_df = pd.DataFrame(data=list_of_polynomials, columns=list_of_monomial_identifiers_string).astype('float64')\n",
    "\n",
    "    print(len(list_of_monomial_identifiers))\n",
    "    print(polynomials_list_df.shape)\n",
    "else:\n",
    "    list_of_polynomials = np.zeros(shape=(polynomial_data_size, sparsity))   \n",
    "    \n",
    "    list_of_monomial_identifiers_string = [''.join(str(e) for e in monomial_identifier) for monomial_identifier in list_of_monomial_identifiers] if n > 1 else [str(monomial_identifier[0]) for monomial_identifier in list_of_monomial_identifiers]\n",
    "    polynomials_list_df = pd.DataFrame(data=list_of_polynomials, columns=list_of_monomial_identifiers_string).astype('float64')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend MultiprocessingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=10)]: Done 233 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=10)]: Done 873 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=10)]: Done 1769 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=10)]: Done 2921 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=10)]: Done 4329 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=10)]: Done 5993 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=10)]: Done 8553 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=10)]: Done 12905 tasks      | elapsed:  1.9min\n"
     ]
    }
   ],
   "source": [
    "if same_training_all_lambda_nets:\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "    result_list = parallel(delayed(gen_regression_symbolic)(polynomial_array=list_of_polynomials[i], \n",
    "                                                               n_samples=lambda_dataset_size,\n",
    "                                                               noise=noise,\n",
    "                                                               noise_dist=noise_distrib, \n",
    "                                                               seed=RANDOM_SEED, \n",
    "                                                               sympy_calculation=False) for i in range(polynomial_data_size))  \n",
    "else:\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "    result_list = parallel(delayed(gen_regression_symbolic)(polynomial_array=list_of_polynomials[i], \n",
    "                                                               n_samples=lambda_dataset_size,\n",
    "                                                               noise=noise,\n",
    "                                                               noise_dist=noise_distrib, \n",
    "                                                               seed=RANDOM_SEED+i, \n",
    "                                                               sympy_calculation=False) for i in range(polynomial_data_size))\n",
    "\n",
    "X_data_list = [[pd.Series(result[0],  index=list_of_monomial_identifiers_string), pd.DataFrame(result[1].astype(float), columns=list(variables[:n]))] for result in result_list]\n",
    "y_data_list = [[pd.Series(result[0],  index=list_of_monomial_identifiers_string), pd.DataFrame(result[2].astype(float), columns=['result'])] for result in result_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_data_list\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_data_list' is not defined"
     ]
    }
   ],
   "source": [
    "X_data_list[0][0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_list[0][1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_list[0][0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_list[0][1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T12:59:22.156778Z",
     "start_time": "2021-01-14T12:57:34.187753Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_polynomials = './data/saved_polynomial_lists/polynomials_sample_' + path_identifier_polynomial_data + '.csv'\n",
    "polynomials_list_df.to_csv(path_polynomials, index=False)\n",
    "\n",
    "path_X_data = './data/saved_polynomial_lists/X_sample_' + path_identifier_polynomial_data + '.pkl'\n",
    "with open(path_X_data, 'wb') as f:\n",
    "    pickle.dump(X_data_list, f)#, protocol=2)\n",
    "    \n",
    "path_y_data = './data/saved_polynomial_lists/y_sample_' + path_identifier_polynomial_data + '.pkl'\n",
    "with open(path_y_data, 'wb') as f:\n",
    "    pickle.dump(y_data_list, f)#, protocol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myBA",
   "language": "python",
   "name": "myba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
