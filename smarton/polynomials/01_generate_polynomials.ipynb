{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Generation for the Training of Î»-Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package installation (uncommand first line to install packages at the beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:31.993410Z",
     "start_time": "2020-11-16T13:05:31.975622Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "#if some errors occur during the installation consider using \"sudo pip install\"\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install truth-table-generator\n",
    "!pip install more-itertools\n",
    "!pip install tqdm\n",
    "!pip install joblib\n",
    "!pip install scipy\n",
    "!pip install PrettyTable\n",
    "!pip install colored\n",
    "!pip install scikit-learn\n",
    "!pip install keras\n",
    "!pip install ipython\n",
    "!pip install livelossplot\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T12:26:49.061308Z",
     "start_time": "2020-09-16T12:26:49.055692Z"
    }
   },
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:32.003102Z",
     "start_time": "2020-11-16T13:05:31.997656Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def nCr(n,r):\n",
    "    f = math.factorial\n",
    "    return f(n) // f(r) // f(n-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:32.013322Z",
     "start_time": "2020-11-16T13:05:32.006844Z"
    }
   },
   "outputs": [],
   "source": [
    "d = 3  \n",
    "n = 4\n",
    "sparsity = nCr(n+d, d)\n",
    "\n",
    "\n",
    "x_max = 1 \n",
    "x_min = -1\n",
    "x_step = 0.01\n",
    "a_max = 10 \n",
    "a_min = -10\n",
    "a_step = 0.1\n",
    "\n",
    "n_jobs = -3\n",
    "\n",
    "lambda_dataset_size = 1000 #specify the number of data points to calculate the function values for (determines the lambda net training size)\n",
    "\n",
    "interpretation_dataset_size = 10000 #specifies the number of functions generated (specifies the interpretation-net dataset size)\n",
    "\n",
    "same_training_all_lambda_nets = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:32.028050Z",
     "start_time": "2020-11-16T13:05:32.016362Z"
    }
   },
   "outputs": [],
   "source": [
    "##############DO NOT CHANGE###################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "if same_training_all_lambda_nets:\n",
    "    training_string = '_same'\n",
    "else:\n",
    "    training_string = '_diverse'\n",
    "    \n",
    "print('Variables: ' + str(n) + ' (' + variables + ')')\n",
    "print('Degree: ' + str(d))\n",
    "print('Sparsity: ' + str(sparsity)) \n",
    "print('Lambda-Net Dataset Size: ' + str(lambda_dataset_size))\n",
    "print('I-Net Dataset Size: ' + str(interpretation_dataset_size))\n",
    "      \n",
    "print('Coefficient Range: ' + '[' + str(a_min) + ', ' + str(a_max) + ']')\n",
    "print('Variable Range: ' + '[' + str(x_min) + ', ' + str(x_max) + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T12:26:58.879427Z",
     "start_time": "2020-09-16T12:26:58.874894Z"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:34.057149Z",
     "start_time": "2020-11-16T13:05:32.030621Z"
    }
   },
   "outputs": [],
   "source": [
    "import ttg\n",
    "from itertools import product       # forms cartesian products\n",
    "from more_itertools import random_product \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import random \n",
    "from random import sample \n",
    "random.seed(42)\n",
    "\n",
    "import os\n",
    "\n",
    "directory_names = ['parameters', 'plotting', 'saved_polynomial_lists', 'results', 'saved_models', 'weights', 'weights_training']\n",
    "if not os.path.exists('./data'):\n",
    "    os.mkdir('./data')\n",
    "for directory_name in directory_names:\n",
    "    path = './data/' + directory_name\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "        \n",
    "import random \n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:34.064039Z",
     "start_time": "2020-11-16T13:05:34.059694Z"
    }
   },
   "outputs": [],
   "source": [
    "#test for exact equality\n",
    "def arreq_in_list(myarr, list_arrays):\n",
    "    return next((True for elem in list_arrays if np.array_equal(elem, myarr)), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:34.077413Z",
     "start_time": "2020-11-16T13:05:34.066338Z"
    }
   },
   "outputs": [],
   "source": [
    "ALPHABET = \\\n",
    "  \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "def encode (n):\n",
    "    try:\n",
    "        return ALPHABET [n]\n",
    "    except IndexError:\n",
    "        raise Exception (\"cannot encode: %s\" % n)\n",
    "\n",
    "def dec_to_base (dec = 0, base = 16):\n",
    "    if dec < base:\n",
    "        return encode (dec)\n",
    "    else:\n",
    "        return dec_to_base (dec // base, base) + encode (dec % base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T12:28:46.853042Z",
     "start_time": "2020-09-16T12:28:46.848346Z"
    }
   },
   "source": [
    "# Function Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:34.155551Z",
     "start_time": "2020-11-16T13:05:34.081446Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_monomial_identifiers_extended = []\n",
    "for i in tqdm(range((d+1)**n)):    \n",
    "    monomial_identifier = dec_to_base(i, base = (d+1)).zfill(n) \n",
    "    list_of_monomial_identifiers_extended.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers_extended)\n",
    "\n",
    "list_of_monomial_identifiers = []\n",
    "for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "    monomial_identifier_values = list(map(int, list(monomial_identifier)))\n",
    "    if sum(monomial_identifier_values) <= d:\n",
    "        list_of_monomial_identifiers.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:34.219740Z",
     "start_time": "2020-11-16T13:05:34.158353Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_polynomials = []\n",
    "\n",
    "if interpretation_dataset_size/((a_max-a_min)*10**int(-np.log10(a_step)))**(nCr(n+d, d)) <= 10e-4:\n",
    "    while len(list_of_polynomials) < interpretation_dataset_size:\n",
    "        random_polynomial = list(random_product([i*a_step for i in range(int(a_min*10**int(-np.log10(a_step))), int(a_max*10**int(-np.log10(a_step))))], repeat=nCr(n+d, d)))\n",
    "        if random_polynomial not in list_of_polynomials:\n",
    "            list_of_polynomials.append(random_polynomial)\n",
    "else:\n",
    "    all_polynomials_list = list(product([i*a_step for i in range(int(a_min*10**int(-np.log10(a_step))), int(a_max*10**int(-np.log10(a_step))))], repeat=nCr(n+d, d)))\n",
    "    list_of_polynomials = [all_polynomials_list[i] for i in np.random.choice(len(all_polynomials_list), interpretation_dataset_size, replace=False)]\n",
    "    del all_polynomials_list\n",
    "\n",
    "for polynomial in tqdm(list_of_polynomials):\n",
    "    sparsity_indices = np.random.choice(nCr(n+d, d), nCr(n+d, d)-sparsity, replace=False)\n",
    "    for sparsity_index in sparsity_indices:                            \n",
    "        polynomial[sparsity_index] = 0\n",
    "                                \n",
    "polynomials_list_df = pd.DataFrame(data=list_of_polynomials, columns=list_of_monomial_identifiers)\n",
    "\n",
    "    \n",
    "print(len(list_of_monomial_identifiers))\n",
    "print(polynomials_list_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:34.272321Z",
     "start_time": "2020-11-16T13:05:34.221796Z"
    }
   },
   "outputs": [],
   "source": [
    "polynomials_list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:39.937224Z",
     "start_time": "2020-11-16T13:05:34.274416Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if same_training_all_lambda_nets:\n",
    "    x_values_list = []\n",
    "    for i in tqdm(range(lambda_dataset_size)):\n",
    "        values = np.round(np.array(random_product(np.arange(x_min, x_max, x_step), repeat=n)), int(-np.log10(x_step)))\n",
    "        while arreq_in_list(values, x_values_list):\n",
    "                values = np.round(np.array(random_product(np.arange(x_min, x_max, x_step), repeat=n)), int(-np.log10(x_step)))         \n",
    "        x_values_list.append(values)\n",
    "else:\n",
    "    x_values_list = [[] for i in range(lambda_dataset_size)]\n",
    "    for i in tqdm(range(lambda_dataset_size)):\n",
    "        values = np.round(np.array(random_product(np.arange(x_min, x_max, x_step), repeat=n)), int(-np.log10(x_step)))\n",
    "        while arreq_in_list(values, x_values_list[i]):\n",
    "                values = np.round(np.array(random_product(np.arange(x_min, x_max, x_step), repeat=n)), int(-np.log10(x_step)))         \n",
    "        x_values_list[i].append(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:40.189896Z",
     "start_time": "2020-11-16T13:05:39.940071Z"
    }
   },
   "outputs": [],
   "source": [
    "x_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:40.199191Z",
     "start_time": "2020-11-16T13:05:40.192012Z"
    }
   },
   "outputs": [],
   "source": [
    "polynomials_list_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:40.212390Z",
     "start_time": "2020-11-16T13:05:40.201552Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def calcualate_function_with_data(coefficient_list, variable_values):\n",
    "    \n",
    "    result = 0    \n",
    "    for coefficient_value, coefficient_multipliers in zip(coefficient_list, list_of_monomial_identifiers):\n",
    "        partial_results = [variable_value**int(coefficient_multiplier) for coefficient_multiplier, variable_value in zip(coefficient_multipliers, variable_values)]\n",
    "        \n",
    "        result += coefficient_value * reduce(lambda x, y: x*y, partial_results)\n",
    "\n",
    "    return result, variable_values\n",
    " \n",
    "def calculate_function_values_from_polynomial(true_value_test, evaluation_dataset):\n",
    "\n",
    "    #print('method_call')\n",
    "\n",
    "    if isinstance(true_value_test, pd.DataFrame):\n",
    "        true_value_test = true_value_test.values\n",
    "        \n",
    "    true_value_fv = []\n",
    "    true_value_coeff = []\n",
    "    \n",
    "    #print('start_loop')\n",
    "    \n",
    "    for evaluation in evaluation_dataset:\n",
    "        true_function_value, true_coeff = calcualate_function_with_data(true_value_test, evaluation)\n",
    "       \n",
    "        true_value_fv.append(true_function_value) \n",
    "        true_value_coeff.append(true_coeff)\n",
    "\n",
    "\n",
    "    #print('end_loop')\n",
    "        \n",
    "    return [true_value_test, pd.DataFrame(np.array(true_value_coeff))], [true_value_test, pd.DataFrame(np.array(true_value_fv))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:09:50.875552Z",
     "start_time": "2020-11-16T13:09:42.312512Z"
    }
   },
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "polynomials_X_data_list = []\n",
    "polynomials_y_data_list = []\n",
    "    \n",
    "chunks = max(interpretation_dataset_size//1000, 1)\n",
    "\n",
    "for polynomials_list_df_chunk in tqdm(np.array_split(polynomials_list_df, chunks), total=chunks):\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    if same_training_all_lambda_nets:\n",
    "        result_sublist = parallel(delayed(calculate_function_values_from_polynomial)(polynomial, x_values_list) for _, polynomial in polynomials_list_df_chunk.iterrows())  \n",
    "    else:\n",
    "        result_sublist = parallel(delayed(calculate_function_values_from_polynomial)(polynomial, x_values) for (_, polynomial), x_values in zip(polynomials_list_df_chunk.iterrows(), x_values_list))  \n",
    "    result_list.extend(result_sublist)\n",
    "    del parallel\n",
    "\n",
    "polynomials_X_data_list = [result[0] for result in result_list]\n",
    "polynomials_y_data_list = [result[1] for result in result_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:09:50.887448Z",
     "start_time": "2020-11-16T13:09:50.878710Z"
    }
   },
   "outputs": [],
   "source": [
    "polynomials_X_data_list[0][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:09:50.907613Z",
     "start_time": "2020-11-16T13:09:50.891138Z"
    }
   },
   "outputs": [],
   "source": [
    "polynomials_X_data_list[0][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:09:50.919939Z",
     "start_time": "2020-11-16T13:09:50.911762Z"
    }
   },
   "outputs": [],
   "source": [
    "polynomials_y_data_list[0][0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:09:50.930954Z",
     "start_time": "2020-11-16T13:09:50.922749Z"
    }
   },
   "outputs": [],
   "source": [
    "polynomials_y_data_list[0][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:09:50.943996Z",
     "start_time": "2020-11-16T13:09:50.933639Z"
    }
   },
   "outputs": [],
   "source": [
    "polynomials_y_data_list[0][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:09:50.963701Z",
     "start_time": "2020-11-16T13:09:50.946392Z"
    }
   },
   "outputs": [],
   "source": [
    "polynomials_X_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:09:50.981153Z",
     "start_time": "2020-11-16T13:09:50.967683Z"
    }
   },
   "outputs": [],
   "source": [
    "polynomials_y_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:09:51.235848Z",
     "start_time": "2020-11-16T13:09:50.984427Z"
    }
   },
   "outputs": [],
   "source": [
    "path_polynomials = './data/saved_polynomial_lists/polynomials_sample' + str(interpretation_dataset_size) + '_variables_' + str(n) +  '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '.csv'\n",
    "polynomials_list_df.to_csv(path_polynomials, index=False)\n",
    "\n",
    "path_X_data = './data/saved_polynomial_lists/X_sample' + str(interpretation_dataset_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step) + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.pkl'\n",
    "with open(path_X_data, 'wb') as f:\n",
    "    pickle.dump(polynomials_X_data_list, f)#, protocol=2)\n",
    "    \n",
    "path_y_data = './data/saved_polynomial_lists/y_sample' + str(interpretation_dataset_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step) + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.pkl'\n",
    "with open(path_y_data, 'wb') as f:\n",
    "    pickle.dump(polynomials_y_data_list, f)#, protocol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
