{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Î»-Nets for I-Net training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:38.693541Z",
     "start_time": "2020-11-26T20:54:38.685071Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def nCr(n,r):\n",
    "    f = math.factorial\n",
    "    return f(n) // f(r) // f(n-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:38.708234Z",
     "start_time": "2020-11-26T20:54:38.697155Z"
    }
   },
   "outputs": [],
   "source": [
    "d = 3\n",
    "n = 4\n",
    "sparsity = nCr(n+d, d)\n",
    "\n",
    "\n",
    "x_max = 1#10 #this number excluded\n",
    "x_min = -1#-10\n",
    "x_step = 0.01#0.1\n",
    "a_max = 10 #this number excluded\n",
    "a_min = -10\n",
    "a_step = 0.1\n",
    "\n",
    "lambda_dataset_size = 1000 #specify the number of data points to train the lambda net on for loading (must be same as in previous notebook)\n",
    "\n",
    "number_formulas_load = 10000 #manually specify number of formulas for loading file (must be the same as used in the previous notebook)\n",
    "number_of_lambda_nets = number_formulas_load #use this parameter to select how many lambda nets should be generated (must be smaller or equal to number_formulas_load)\n",
    "\n",
    "\n",
    "#lambda net specifications \n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "lambda_network_layers = [5*sparsity]\n",
    "dropout = 0.0\n",
    "optimizer='SGD'\n",
    "\n",
    "each_epochs_save = 10  #specifies the number of epochs to checkpoint lambda network weights, if None no checkpointing\n",
    "\n",
    "same_training_all_lambda_nets = True\n",
    "fixed_seed_lambda_training = True\n",
    "\n",
    "\n",
    "n_jobs = -3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:38.723628Z",
     "start_time": "2020-11-26T20:54:38.710874Z"
    }
   },
   "outputs": [],
   "source": [
    "##############DO NOT CHANGE###################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "if each_epochs_save != None:\n",
    "    epochs_save_range = range(1, epochs//each_epochs_save+1) if each_epochs_save == 1 else range(epochs//each_epochs_save+1)\n",
    "else:\n",
    "    epochs_save_range = None\n",
    "    \n",
    "layers_str = ''.join([str(neurons) + '-' for neurons in lambda_network_layers])\n",
    "\n",
    "advanced_metric_dataset_size = 10#200\n",
    "\n",
    "if same_training_all_lambda_nets:\n",
    "    training_string = '_same'\n",
    "else:\n",
    "    training_string = '_diverse'\n",
    "\n",
    "generate_subset = True if number_of_lambda_nets < number_formulas_load else False\n",
    "\n",
    "    \n",
    "if generate_subset:\n",
    "    data_size = number_of_lambda_nets\n",
    "else:\n",
    "    data_size = number_formulas_load\n",
    "\n",
    "if fixed_seed_lambda_training:\n",
    "    seed_shuffle_string = '_SeedMethod'\n",
    "elif not fixed_seed_lambda_training:\n",
    "    seed_shuffle_string = '_NoSeedMethod'\n",
    "    \n",
    "use_gpu = False\n",
    "if use_gpu:\n",
    "    gpu_numbers = '0'\n",
    "else:\n",
    "    gpu_numbers = ''\n",
    "    \n",
    "structure = '_' + layers_str + str(epochs) + 'e' + str(batch_size) + 'b_' + optimizer \n",
    "    \n",
    "filename = seed_shuffle_string + '_' + str(RANDOM_SEED) + structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:45.401428Z",
     "start_time": "2020-11-26T20:54:38.727093Z"
    }
   },
   "outputs": [],
   "source": [
    "import ttg\n",
    "from itertools import product       # forms cartesian products\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from more_itertools import random_product \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import math\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "from IPython.display import Image\n",
    "\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import random \n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "#keras.backend.set_epsilon(10e-3)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:45.413004Z",
     "start_time": "2020-11-26T20:54:45.405477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:45.437963Z",
     "start_time": "2020-11-26T20:54:45.415851Z"
    }
   },
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s2, s3), (s4, s5), ...\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "def chunks(lst, chunksize):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), chunksize):\n",
    "        yield lst[i:i + chunksize]\n",
    "\n",
    "#test for exact equality\n",
    "def arreq_in_list(myarr, list_arrays):\n",
    "    return next((True for elem in list_arrays if np.array_equal(elem, myarr)), False)\n",
    "\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "\n",
    "ALPHABET = \\\n",
    "  \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "def encode (n):\n",
    "    try:\n",
    "        return ALPHABET [n]\n",
    "    except IndexError:\n",
    "        raise Exception (\"cannot encode: %s\" % n)\n",
    "        \n",
    "def dec_to_base (dec = 0, base = 16):\n",
    "    if dec < base:\n",
    "        return encode (dec)\n",
    "    else:\n",
    "        return dec_to_base (dec // base, base) + encode (dec % base)\n",
    "    \n",
    "    \n",
    "def mergeDict(dict1, dict2):\n",
    "    #Merge dictionaries and keep values of common keys in list\n",
    "    newDict = {**dict1, **dict2}\n",
    "    for key, value in newDict.items():\n",
    "        if key in dict1 and key in dict2:\n",
    "            if isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend(value)\n",
    "            elif isinstance(dict1[key], list) and not isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend([value])\n",
    "            elif not isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = [dict1[key]]\n",
    "                newDict[key].extend(value)\n",
    "            else:\n",
    "                newDict[key] = [dict1[key], value]\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss/Error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:45.451972Z",
     "start_time": "2020-11-26T20:54:45.440407Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def calcualate_function_value_with_X_data_entry(coefficient_list, X_data_entry):\n",
    "    \n",
    "    global list_of_monomial_identifiers\n",
    "     \n",
    "    result = 0    \n",
    "    for coefficient_value, coefficient_multipliers in zip(coefficient_list, list_of_monomial_identifiers):\n",
    "        partial_results = [X_data_value**int(coefficient_multiplier) for coefficient_multiplier, X_data_value in zip(coefficient_multipliers, X_data_entry)]\n",
    "        \n",
    "        result += coefficient_value * reduce(lambda x, y: x*y, partial_results)\n",
    "        \n",
    "    return result, np.append(X_data_entry, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:45.502856Z",
     "start_time": "2020-11-26T20:54:45.455286Z"
    },
    "code_folding": [
     0,
     20,
     43,
     66,
     88,
     91,
     103
    ]
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "        \n",
    "    if tf.is_tensor(y_true):\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    else:\n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    if tf.is_tensor(y_pred):\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "    else:\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "            \n",
    "            \n",
    "    return tf.math.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "def accuracy_multilabel(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    if 'float' in str(y_true[0].dtype):        \n",
    "        if tf.is_tensor(y_true):\n",
    "            y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "        else:\n",
    "            y_true = y_true.astype('float32')\n",
    "        if tf.is_tensor(y_pred):\n",
    "            y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        else:\n",
    "            y_pred = y_pred.astype('float32')\n",
    "            \n",
    "        n_digits = int(-np.log10(a_step))\n",
    "        \n",
    "        y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "        y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(tf.reduce_all(K.equal(y_true, y_pred), axis=1), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def accuracy_single(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    if 'float' in str(y_true[0].dtype):        \n",
    "        if tf.is_tensor(y_true):\n",
    "            y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "        else:\n",
    "            y_true = y_true.astype('float32')\n",
    "        if tf.is_tensor(y_pred):\n",
    "            y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        else:\n",
    "            y_pred = y_pred.astype('float32')\n",
    "            \n",
    "        n_digits = int(-np.log10(a_step))\n",
    "        \n",
    "        y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "        y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(K.equal(y_true, y_pred), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def mean_absolute_percentage_error_keras(y_true, y_pred, epsilon=10e-3): \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values    \n",
    "        \n",
    "    if tf.is_tensor(y_true):\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    else:\n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    if tf.is_tensor(y_pred):\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "    else:\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        \n",
    "    epsilon = tf.convert_to_tensor(epsilon)\n",
    "    epsilon = tf.dtypes.cast(epsilon, tf.float32)\n",
    "        \n",
    "    return tf.reduce_mean(tf.abs(tf.divide(tf.subtract(y_pred, y_true),(y_true + epsilon))))\n",
    "\n",
    "def huber_loss_delta_set(y_true, y_pred):\n",
    "    return keras.losses.huber_loss(y_true, y_pred, delta=0.3)\n",
    "\n",
    "def relative_absolute_average_error(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "       \n",
    "    #error value calculation    \n",
    "    result = np.sum(np.abs(y_true-y_pred))/(y_true.shape[0]*np.std(y_true)) #correct STD?\n",
    "    \n",
    "    return result\n",
    "\n",
    "def relative_maximum_average_error(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    #error value calculation    \n",
    "    result = np.max(y_true-y_pred)/np.std(y_true) #correct STD?\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of Monomial Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:45.600169Z",
     "start_time": "2020-11-26T20:54:45.505616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2df495a60b44758256157975dbd849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 256\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0013', '0020', '0021', '0022', '0023', '0030', '0031', '0032', '0033', '0100', '0101', '0102', '0103', '0110', '0111', '0112', '0113', '0120', '0121', '0122', '0123', '0130', '0131', '0132', '0133', '0200', '0201', '0202', '0203', '0210', '0211', '0212', '0213', '0220', '0221', '0222', '0223', '0230', '0231', '0232', '0233', '0300', '0301', '0302', '0303', '0310', '0311', '0312', '0313', '0320', '0321', '0322', '0323', '0330', '0331', '0332', '0333', '1000', '1001', '1002', '1003', '1010', '1011', '1012', '1013', '1020', '1021', '1022', '1023', '1030', '1031', '1032', '1033', '1100', '1101', '1102', '1103', '1110', '1111', '1112', '1113', '1120', '1121', '1122', '1123', '1130', '1131', '1132', '1133', '1200', '1201', '1202', '1203', '1210', '1211', '1212', '1213', '1220', '1221', '1222', '1223', '1230', '1231', '1232', '1233', '1300', '1301', '1302', '1303', '1310', '1311', '1312', '1313', '1320', '1321', '1322', '1323', '1330', '1331', '1332', '1333', '2000', '2001', '2002', '2003', '2010', '2011', '2012', '2013', '2020', '2021', '2022', '2023', '2030', '2031', '2032', '2033', '2100', '2101', '2102', '2103', '2110', '2111', '2112', '2113', '2120', '2121', '2122', '2123', '2130', '2131', '2132', '2133', '2200', '2201', '2202', '2203', '2210', '2211', '2212', '2213', '2220', '2221', '2222', '2223', '2230', '2231', '2232', '2233', '2300', '2301', '2302', '2303', '2310', '2311', '2312', '2313', '2320', '2321', '2322', '2323', '2330', '2331', '2332', '2333', '3000', '3001', '3002', '3003', '3010', '3011', '3012', '3013', '3020', '3021', '3022', '3023', '3030', '3031', '3032', '3033', '3100', '3101', '3102', '3103', '3110', '3111', '3112', '3113', '3120', '3121', '3122', '3123', '3130', '3131', '3132', '3133', '3200', '3201', '3202', '3203', '3210', '3211', '3212', '3213', '3220', '3221', '3222', '3223', '3230', '3231', '3232', '3233', '3300', '3301', '3302', '3303', '3310', '3311', '3312', '3313', '3320', '3321', '3322', '3323', '3330', '3331', '3332', '3333']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0f063a64f84500b30931594fad9c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 35\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0020', '0021', '0030', '0100', '0101', '0102', '0110', '0111', '0120', '0200', '0201', '0210', '0300', '1000', '1001', '1002', '1010', '1011', '1020', '1100', '1101', '1110', '1200', '2000', '2001', '2010', '2100', '3000']\n"
     ]
    }
   ],
   "source": [
    "list_of_monomial_identifiers_extended = []\n",
    "for i in tqdm(range((d+1)**n)):    \n",
    "    monomial_identifier = dec_to_base(i, base = (d+1)).zfill(n) \n",
    "    list_of_monomial_identifiers_extended.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers_extended)\n",
    "\n",
    "list_of_monomial_identifiers = []\n",
    "for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "    monomial_identifier_values = list(map(int, list(monomial_identifier)))\n",
    "    if sum(monomial_identifier_values) <= d:\n",
    "        list_of_monomial_identifiers.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.172127Z",
     "start_time": "2020-11-26T20:54:45.602527Z"
    }
   },
   "outputs": [],
   "source": [
    "path_polynomials = './data/saved_polynomial_lists/polynomials_sample' + str(number_formulas_load) + '_variables_' + str(n) +  '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step) + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '.csv'\n",
    "polynomials_list_df = pd.read_csv(path_polynomials)\n",
    "\n",
    "path_X_data = './data/saved_polynomial_lists/X_sample' + str(number_formulas_load) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) +  training_string + '.pkl'\n",
    "with open(path_X_data, 'rb') as f:\n",
    "    X_data_list = pickle.load(f)\n",
    "    \n",
    "path_y_data = './data/saved_polynomial_lists/y_sample' + str(number_formulas_load) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) +  training_string + '.pkl'\n",
    "with open(path_y_data, 'rb') as f:\n",
    "    y_data_list = pickle.load(f)\n",
    "    \n",
    "if generate_subset:\n",
    "    polynomials_list_df = polynomials_list_df.sample(n=number_of_lambda_nets, random_state=RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    X_data_list = random.sample(X_data_list, number_of_lambda_nets)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    y_data_list = random.sample(y_data_list, number_of_lambda_nets)\n",
    "    random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.220406Z",
     "start_time": "2020-11-26T20:54:58.175352Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#clear files\n",
    "if each_epochs_save != None:\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        \n",
    "        for i in epochs_save_range:\n",
    "            index = i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "            path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size)  + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(index).zfill(3)  + filename + '.txt'\n",
    "\n",
    "            with open(path, 'wt') as text_file:\n",
    "                text_file.truncate()   \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "else:\n",
    "    \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "\n",
    "        path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "        with open(path, 'wt') as text_file:\n",
    "            text_file.truncate()   \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.249175Z",
     "start_time": "2020-11-26T20:54:58.223266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.910</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.770</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3\n",
       "0 -0.640 -0.910 -1.000  0.940\n",
       "1  0.910 -0.020  0.540  0.610\n",
       "2 -0.080 -0.720 -0.020 -0.980\n",
       "3 -0.770  0.570  0.180 -0.150\n",
       "4  0.990  0.460  0.590 -0.590"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.263148Z",
     "start_time": "2020-11-26T20:54:58.253332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.910</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.770</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3\n",
       "0 -0.640 -0.910 -1.000  0.940\n",
       "1  0.910 -0.020  0.540  0.610\n",
       "2 -0.080 -0.720 -0.020 -0.980\n",
       "3 -0.770  0.570  0.180 -0.150\n",
       "4  0.990  0.460  0.590 -0.590"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[1][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.272886Z",
     "start_time": "2020-11-26T20:54:58.266606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000    6.300\n",
       "0001   -7.200\n",
       "0002   -9.400\n",
       "0003    8.900\n",
       "0010   -3.000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.280950Z",
     "start_time": "2020-11-26T20:54:58.275255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000   -9.900\n",
       "0001    9.400\n",
       "0002   -6.000\n",
       "0003    7.800\n",
       "0010    0.800\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[1][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T17:06:36.919643Z",
     "start_time": "2020-09-16T17:06:36.912904Z"
    }
   },
   "source": [
    "## Lambda Network Training + Weigh/Bias saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.332638Z",
     "start_time": "2020-11-26T20:54:58.283338Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate_lambda_net(identifier, \n",
    "                        X_data_real_lambda, \n",
    "                        y_data_real_lambda, \n",
    "                        y_data_pred_lambda, \n",
    "                        y_data_pred_lambda_poly_lstsq, \n",
    "                        y_data_real_lambda_poly_lstsq):\n",
    "    \n",
    "    mae_real_VS_predLambda = np.round(mean_absolute_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    mae_real_VS_predPolyLstsq = np.round(mean_absolute_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    mae_predLambda_VS_predPolyLstsq = np.round(mean_absolute_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    mae_real_VS_realPolyLstsq = np.round(mean_absolute_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)    \n",
    "\n",
    "    rmse_real_VS_predLambda = np.round(root_mean_squared_error(y_data_real_lambda, y_data_pred_lambda), 4)    \n",
    "    rmse_real_VS_predPolyLstsq = np.round(root_mean_squared_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)    \n",
    "    rmse_predLambda_VS_predPolyLstsq = np.round(root_mean_squared_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)    \n",
    "    rmse_real_VS_realPolyLstsq = np.round(root_mean_squared_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)    \n",
    "\n",
    "    mape_real_VS_predLambda = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_pred_lambda), 4)    \n",
    "    mape_real_VS_predPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)    \n",
    "    mape_predLambda_VS_predPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)    \n",
    "    mape_real_VS_realPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)            \n",
    "\n",
    "    r2_real_VS_predLambda = np.round(r2_score(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    r2_real_VS_predPolyLstsq = np.round(r2_score(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    r2_predLambda_VS_predPolyLstsq = np.round(r2_score(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    r2_real_VS_realPolyLstsq = np.round(r2_score(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    raae_real_VS_predLambda = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    raae_real_VS_predPolyLstsq = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    raae_predLambda_VS_predPolyLstsq = np.round(relative_absolute_average_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    raae_real_VS_realPolyLstsq = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    rmae_real_VS_predLambda = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    rmae_real_VS_predPolyLstsq = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    rmae_predLambda_VS_predPolyLstsq = np.round(relative_maximum_average_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    rmae_real_VS_realPolyLstsq = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    fd_real_VS_predLambda = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size]))), 4)\n",
    "    fd_real_VS_predPolyLstsq = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size]))), 4)\n",
    "    fd_predLambda_VS_predPolyLstsq = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size]))), 4)\n",
    "    fd_real_VS_realPolyLstsq = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda_poly_lstsq[:advanced_metric_dataset_size]))), 4)\n",
    "\n",
    "    dtw_real_VS_predLambda, dtw_complete_real_VS_predLambda = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size])))\n",
    "    dtw_real_VS_predLambda = np.round(dtw_real_VS_predLambda, 4)\n",
    "    dtw_real_VS_predPolyLstsq, dtw_complete_real_VS_predPolyLstsq = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size])))\n",
    "    dtw_real_VS_predPolyLstsq = np.round(dtw_real_VS_predPolyLstsq, 4)\n",
    "    dtw_predLambda_VS_predPolyLstsq, dtw_complete_predLambda_VS_predPolyLstsq = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size])))\n",
    "    dtw_predLambda_VS_predPolyLstsq = np.round(dtw_predLambda_VS_predPolyLstsq, 4)    \n",
    "    dtw_real_VS_realPolyLstsq, dtw_complete_real_VS_realPolyLstsq = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda_poly_lstsq[:advanced_metric_dataset_size])))\n",
    "    dtw_real_VS_realPolyLstsq = np.round(dtw_real_VS_realPolyLstsq, 4) \n",
    "        \n",
    "    std_data_real_lambda = np.round(np.std(y_data_real_lambda), 4) \n",
    "    std_data_pred_lambda = np.round(np.std(y_data_pred_lambda), 4) \n",
    "    std_data_pred_lambda_poly_lstsq = np.round(np.std(y_data_pred_lambda_poly_lstsq), 4) \n",
    "    std_data_real_lambda_poly_lstsq = np.round(np.std(y_data_real_lambda_poly_lstsq), 4) \n",
    "\n",
    "    mean_data_real_lambda = np.round(np.mean(y_data_real_lambda), 4) \n",
    "    mean_data_pred_lambda = np.round(np.mean(y_data_pred_lambda), 4) \n",
    "    mean_data_pred_lambda_poly_lstsq = np.round(np.mean(y_data_pred_lambda_poly_lstsq), 4) \n",
    "    mean_data_real_lambda_poly_lstsq = np.round(np.mean(y_data_real_lambda_poly_lstsq), 4) \n",
    "\n",
    "    return [{\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': mae_real_VS_predLambda,\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': mae_real_VS_predPolyLstsq,\n",
    "             'MAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': mae_predLambda_VS_predPolyLstsq,\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': mae_real_VS_realPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': rmse_real_VS_predLambda,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': rmse_real_VS_predPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': rmse_predLambda_VS_predPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': rmse_real_VS_realPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': mape_real_VS_predLambda,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': mape_real_VS_predPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': mape_predLambda_VS_predPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': mape_real_VS_realPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': r2_real_VS_predLambda,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': r2_real_VS_predPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': r2_predLambda_VS_predPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': r2_real_VS_realPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': raae_real_VS_predLambda,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': raae_real_VS_predPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': raae_predLambda_VS_predPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': raae_real_VS_realPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': rmae_real_VS_predLambda,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': rmae_real_VS_predPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': rmae_predLambda_VS_predPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': rmae_real_VS_realPolyLstsq,\n",
    "             'FD FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': fd_real_VS_predLambda,   \n",
    "             'FD FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': fd_real_VS_predPolyLstsq,   \n",
    "             'FD FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': fd_predLambda_VS_predPolyLstsq,   \n",
    "             'FD FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': fd_real_VS_realPolyLstsq,   \n",
    "             'DTW FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': dtw_real_VS_predLambda, \n",
    "             'DTW FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': dtw_real_VS_predPolyLstsq, \n",
    "             'DTW FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': dtw_predLambda_VS_predPolyLstsq, \n",
    "             'DTW FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': dtw_real_VS_realPolyLstsq, \n",
    "            },\n",
    "            {\n",
    "             'STD FV ' + identifier + ' REAL LAMBDA': std_data_real_lambda,\n",
    "             'STD FV ' + identifier + ' PRED LAMBDA': std_data_pred_lambda, \n",
    "             'STD FV ' + identifier + ' PRED LAMBDA POLY LSTSQ': std_data_pred_lambda_poly_lstsq, \n",
    "             'STD FV ' + identifier + ' REAL LAMBDA POLY LSTSQ': std_data_real_lambda_poly_lstsq, \n",
    "            },\n",
    "            {\n",
    "             'MEAN FV ' + identifier + ' REAL LAMBDA': mean_data_real_lambda,\n",
    "             'MEAN FV ' + identifier + ' PRED LAMBDA': mean_data_pred_lambda, \n",
    "             'MEAN FV ' + identifier + ' PRED LAMBDA POLY LSTSQ': mean_data_pred_lambda_poly_lstsq, \n",
    "             'MEAN FV ' + identifier + ' REAL LAMBDA POLY LSTSQ': mean_data_real_lambda_poly_lstsq, \n",
    "            }]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.342674Z",
     "start_time": "2020-11-26T20:54:58.334905Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_function_values_from_polynomial(X_data, polynomial):\n",
    "    function_value_list = []\n",
    "    for entry in X_data:\n",
    "        function_value, _ = calcualate_function_value_with_X_data_entry(polynomial, entry)\n",
    "        function_value_list.append(function_value)\n",
    "    function_value_array = np.array(function_value_list).reshape(len(function_value_list), 1)     \n",
    "\n",
    "    return function_value_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.353272Z",
     "start_time": "2020-11-26T20:54:58.345193Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_term_matric_for_lstsq(X_data, polynomial_indices):\n",
    "    term_list_all = []\n",
    "    y = 0\n",
    "    for term in list(polynomial_indices):\n",
    "        term_list = [int(value_mult) for value_mult in term]\n",
    "        term_list_all.append(term_list)\n",
    "    terms_matrix = []\n",
    "    for unknowns in X_data:\n",
    "        terms = []\n",
    "        for term_multipliers in term_list_all:\n",
    "            term_value = prod([unknown**multiplier for unknown, multiplier in zip(unknowns, term_multipliers)])\n",
    "            terms.append(term_value)\n",
    "        terms_matrix.append(np.array(terms))\n",
    "    terms_matrix = np.array(terms_matrix)\n",
    "    \n",
    "    return terms_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T20:54:58.428626Z",
     "start_time": "2020-11-26T20:54:58.356128Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "def train_nn(X_data_lambda, y_data_real_lambda, polynomial, callbacks=None, return_history=False, each_epochs_save=None, printing=False, return_model=False):\n",
    "    \n",
    "    if fixed_seed_lambda_training:\n",
    "        random.seed(RANDOM_SEED)\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        if int(tf.__version__[0]) >= 2:\n",
    "            tf.random.set_seed(RANDOM_SEED)\n",
    "        else:\n",
    "            tf.set_random_seed(RANDOM_SEED) \n",
    "        \n",
    "    if isinstance(X_data_lambda, pd.DataFrame):\n",
    "        X_data_lambda = X_data_lambda.values\n",
    "    if isinstance(y_data_real_lambda, pd.DataFrame):\n",
    "        y_data_real_lambda = y_data_real_lambda.values\n",
    "                \n",
    "    X_train_lambda_with_valid, X_test_lambda, y_train_real_lambda_with_valid, y_test_real_lambda = train_test_split(X_data_lambda, y_data_real_lambda, test_size=0.25, random_state=RANDOM_SEED)           \n",
    "    X_train_lambda, X_valid_lambda, y_train_real_lambda, y_valid_real_lambda = train_test_split(X_train_lambda_with_valid, y_train_real_lambda_with_valid, test_size=0.25, random_state=RANDOM_SEED)           \n",
    "     \n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(lambda_network_layers[0], activation='relu', input_dim=X_data_lambda.shape[1])) #1024\n",
    "    \n",
    "    if dropout > 0:\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    for neurons in lambda_network_layers[1:]:\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(dropout))   \n",
    "            \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=[mean_absolute_percentage_error_keras, root_mean_squared_error]\n",
    "                 )\n",
    "    \n",
    "    \n",
    "    weights = []\n",
    "    polynomial_lstsq_pred_list = []\n",
    "    polynomial_lstsq_true_list = []\n",
    "\n",
    "     \n",
    "    if each_epochs_save == None:   \n",
    "        model_history = model.fit(X_train_lambda, \n",
    "                      y_train_real_lambda, \n",
    "                      epochs=epochs, \n",
    "                      batch_size=batch_size, \n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=(X_valid_lambda, y_valid_real_lambda),\n",
    "                      verbose=0,\n",
    "                      workers=0)\n",
    "        weights.append(model.get_weights())\n",
    "        \n",
    "        history = model_history.history\n",
    "        \n",
    "        y_train_pred_lambda = model.predict(X_train_lambda) \n",
    "        y_valid_pred_lambda = model.predict(X_valid_lambda)                \n",
    "        y_test_pred_lambda = model.predict(X_test_lambda)\n",
    "    \n",
    "        terms_matrix = generate_term_matric_for_lstsq(X_train_lambda, list(polynomial.index))\n",
    "                \n",
    "        polynomial_lstsq_pred, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_pred_lambda.ravel(), rcond=-1)#[::-1]\n",
    "        polynomial_lstsq_true, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_real_lambda.ravel(), rcond=-1)#[::-1] \n",
    "        polynomial_lstsq_pred_list.append(polynomial_lstsq_pred)\n",
    "        polynomial_lstsq_true_list.append(polynomial_lstsq_true)\n",
    "        \n",
    "        y_train_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_pred)\n",
    "        y_train_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_true)\n",
    "        y_valid_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_pred)\n",
    "        y_valid_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_true)    \n",
    "        y_test_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_pred)\n",
    "        y_test_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_true)  \n",
    "        \n",
    "        pred_list = (y_train_real_lambda, \n",
    "                     y_train_pred_lambda, \n",
    "                     y_train_pred_lambda_poly_lstsq,\n",
    "                     #y_train_real_lambda_poly_lstsq,\n",
    "                     X_train_lambda, \n",
    "                     y_valid_real_lambda,\n",
    "                     y_valid_pred_lambda, \n",
    "                     y_valid_pred_lambda_poly_lstsq,\n",
    "                     #y_valid_real_lambda_poly_lstsq,\n",
    "                     X_valid_lambda, \n",
    "                     y_test_real_lambda, \n",
    "                     y_test_pred_lambda, \n",
    "                     y_test_pred_lambda_poly_lstsq, \n",
    "                     #y_test_real_lambda_poly_lstsq,\n",
    "                     X_test_lambda)\n",
    "\n",
    "        scores_train, std_train, mean_train = evaluate_lambda_net('TRAIN', X_train_lambda, y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, y_train_real_lambda_poly_lstsq)\n",
    "        scores_valid, std_valid, mean_valid = evaluate_lambda_net('VALID', X_valid_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, y_valid_real_lambda_poly_lstsq)\n",
    "        scores_test, std_test, mean_test = evaluate_lambda_net('TEST', X_test_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, y_test_real_lambda_poly_lstsq)\n",
    "\n",
    "        scores_std = {}\n",
    "        for aDict in (std_train, std_valid, std_test):\n",
    "            scores_std.update(aDict)      \n",
    "        scores_mean = {}\n",
    "        for aDict in (mean_train, mean_valid, mean_test):\n",
    "            scores_mean.update(aDict)\n",
    "        \n",
    "        scores_list =  [scores_train,\n",
    "                             scores_valid,\n",
    "                             scores_test,\n",
    "                             scores_std,\n",
    "                             scores_mean]            \n",
    "                            \n",
    "    else:\n",
    "        scores_list = []\n",
    "        pred_list = []\n",
    "        for i in epochs_save_range:\n",
    "            train_epochs_step = each_epochs_save if i > 1 else max(each_epochs_save-1, 1) if i==1 else 1\n",
    "            \n",
    "            model_history = model.fit(X_train_lambda, \n",
    "                      y_train_real_lambda, \n",
    "                      epochs=train_epochs_step, \n",
    "                      batch_size=batch_size, \n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=(X_valid_lambda, y_valid_real_lambda),\n",
    "                      verbose=0,\n",
    "                      workers=1,\n",
    "                      use_multiprocessing=False)\n",
    "            \n",
    "            #history adjustment for continuing training\n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                history = model_history.history\n",
    "            else:\n",
    "                history = mergeDict(history, model_history.history)\n",
    "                #for key_1 in history.keys():\n",
    "                #    for key_2 in model_history.history.keys():\n",
    "                #        if key_1 == key_2:\n",
    "                #            history[key_1] += model_history.history[key_2]  \n",
    "\n",
    "            weights.append(model.get_weights())\n",
    "            \n",
    "            y_train_pred_lambda = model.predict(X_train_lambda)                \n",
    "            y_valid_pred_lambda = model.predict(X_valid_lambda)                \n",
    "            y_test_pred_lambda = model.predict(X_test_lambda)        \n",
    "\n",
    "            terms_matrix = generate_term_matric_for_lstsq(X_train_lambda, list(polynomial.index))\n",
    "                        \n",
    "            polynomial_lstsq_pred, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_pred_lambda.ravel(), rcond=-1)#[::-1] \n",
    "            #does not change over time\n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                polynomial_lstsq_true, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_real_lambda.ravel(), rcond=-1)#[::-1] \n",
    "            polynomial_lstsq_pred_list.append(polynomial_lstsq_pred)\n",
    "            polynomial_lstsq_true_list.append(polynomial_lstsq_true)            \n",
    "\n",
    "            \n",
    "            y_train_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_pred)\n",
    "            y_valid_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_pred)\n",
    "            y_test_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_pred)           \n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                y_train_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_true)\n",
    "                y_valid_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_true)  \n",
    "                y_test_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_true)                    \n",
    "                \n",
    "            pred_list.append((y_train_real_lambda, \n",
    "                              y_train_pred_lambda, \n",
    "                              y_train_pred_lambda_poly_lstsq,\n",
    "                              #y_train_real_lambda_poly_lstsq,\n",
    "                              X_train_lambda, \n",
    "                              y_valid_real_lambda,\n",
    "                              y_valid_pred_lambda, \n",
    "                              y_valid_pred_lambda_poly_lstsq,\n",
    "                              #y_valid_real_lambda_poly_lstsq,\n",
    "                              X_valid_lambda, \n",
    "                              y_test_real_lambda, \n",
    "                              y_test_pred_lambda, \n",
    "                              y_test_pred_lambda_poly_lstsq, \n",
    "                              #y_test_real_lambda_poly_lstsq,\n",
    "                              X_test_lambda))\n",
    "    \n",
    "            scores_train, std_train, mean_train = evaluate_lambda_net('TRAIN', X_train_lambda, y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, y_train_real_lambda_poly_lstsq)\n",
    "            scores_valid, std_valid, mean_valid = evaluate_lambda_net('VALID', X_valid_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, y_valid_real_lambda_poly_lstsq)\n",
    "            scores_test, std_test, mean_test = evaluate_lambda_net('TEST', X_test_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, y_test_real_lambda_poly_lstsq)\n",
    "\n",
    "            scores_std = {}\n",
    "            for aDict in (std_train, std_valid, std_test):\n",
    "                scores_std.update(aDict)\n",
    "            scores_mean = {}\n",
    "            for aDict in (mean_train, mean_valid, mean_test):\n",
    "                scores_mean.update(aDict)\n",
    "\n",
    "            scores_list_single_epoch =  [scores_train,\n",
    "                                              scores_valid,\n",
    "                                              scores_test,\n",
    "                                              scores_std,\n",
    "                                              scores_mean]        \n",
    "                  \n",
    "            scores_list.append(scores_list_single_epoch)\n",
    "       \n",
    "\n",
    "        \n",
    "    if printing:        \n",
    "        for i, (weights_for_epoch, polynomial_lstsq_pred_for_epoch, polynomial_lstsq_true_for_epoch) in enumerate(zip(weights, polynomial_lstsq_pred_list, polynomial_lstsq_true_list)):        \n",
    "            if each_epochs_save == None:\n",
    "                path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "            else:\n",
    "                index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "                path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(index).zfill(3)  + filename + '.txt'\n",
    "            with open(path, 'a') as text_file: \n",
    "                for i, value in enumerate(polynomial.values):\n",
    "                    if i == 0:\n",
    "                        text_file.write(str(value))  \n",
    "                    else:\n",
    "                        text_file.write(', ' + str(value))   \n",
    "                for value in polynomial_lstsq_pred_for_epoch:\n",
    "                    text_file.write(', ' + str(value))\n",
    "                for value in polynomial_lstsq_true_for_epoch:\n",
    "                    text_file.write(', ' + str(value))\n",
    "                for layer_weights, biases in pairwise(weights_for_epoch):    #clf.get_weights()\n",
    "                    for neuron in layer_weights:\n",
    "                        for weight in neuron:\n",
    "                            text_file.write(', ' + str(weight))\n",
    "                    for bias in biases:\n",
    "                        text_file.write(', ' + str(bias))\n",
    "                text_file.write('\\n')\n",
    "\n",
    "            text_file.close() \n",
    "\n",
    "            \n",
    "    if return_model:\n",
    "        return (polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list, history, model\n",
    "    elif return_history:\n",
    "        return (polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list, history, #polynomial_lstsq_pred_list, polynomial_lstsq_true_list#, weights, history\n",
    "    else:\n",
    "        return (polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list#, weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T03:04:45.759588Z",
     "start_time": "2020-11-26T20:54:58.431054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    4.912, max:    9.824, cur:    4.912)\n",
      "\tvalidation       \t (min:    5.021, max:   10.134, cur:    5.021)\n",
      "mean_absolute_percentage_error_keras\n",
      "\ttraining         \t (min:    0.985, max:    1.333, cur:    1.090)\n",
      "\tvalidation       \t (min:    0.998, max:    1.575, cur:    1.459)\n",
      "root_mean_squared_error\n",
      "\ttraining         \t (min:    6.698, max:   12.544, cur:    6.756)\n",
      "\tvalidation       \t (min:    7.151, max:   13.063, cur:    7.151)\n"
     ]
    }
   ],
   "source": [
    "clf_list = []\n",
    "chunksize = 1000 if data_size > 10000 else max(data_size//10, min(50, data_size))\n",
    "X_data_list_splits = list(chunks(X_data_list, chunksize))\n",
    "y_data_list_splits = list(chunks(y_data_list, chunksize))\n",
    "\n",
    "for X_data_list_split, y_data_list_split in tqdm(zip(X_data_list_splits, y_data_list_splits), total=max(len(X_data_list_splits), len(y_data_list_splits))):\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    clf_sublist = parallel(delayed(train_nn)(X_data[1].values, y_data[1].values, X_data[0], return_history=True, each_epochs_save=each_epochs_save, printing=True) for X_data, y_data in zip(X_data_list_split, y_data_list_split))  \n",
    "    clf_list.extend(clf_sublist)\n",
    "    del parallel\n",
    "rand_index = np.random.randint(data_size)\n",
    "random_network = train_nn(X_data_list[rand_index][1], y_data_list[rand_index][1], X_data_list[rand_index][0], callbacks=[PlotLossesKerasTF()], return_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Lambda-Model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T03:04:55.816968Z",
     "start_time": "2020-11-27T03:04:45.762467Z"
    }
   },
   "outputs": [],
   "source": [
    "if each_epochs_save == None:\n",
    "    scores_list_train = [clf[1][0] for clf in clf_list]\n",
    "    scores_list_valid = [clf[1][1] for clf in clf_list]\n",
    "    scores_list_test = [clf[1][2] for clf in clf_list]\n",
    "    scores_list_stds = [clf[1][3] for clf in clf_list]\n",
    "    scores_list_means = [clf[1][4] for clf in clf_list]\n",
    "\n",
    "    scores_list_train_mean = pd.DataFrame(scores_list_train, columns=scores_list_train[0].keys()).mean()\n",
    "    df_mean_scores_train = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED', 'TRAIN POLY', 'TRAIN POLY PRED', 'TRAIN LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "\n",
    "    scores_list_valid_mean = pd.DataFrame(scores_list_valid, columns=scores_list_valid[0].keys()).mean()\n",
    "    df_mean_scores_valid = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED', 'VALID POLY', 'VALID POLY PRED', 'VALID LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "\n",
    "    scores_list_test_mean = pd.DataFrame(scores_list_test, columns=scores_list_test[0].keys()).mean()\n",
    "    df_mean_scores_test = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED', 'TEST POLY', 'TEST POLY PRED', 'TEST LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "\n",
    "    stds_mean = pd.DataFrame(scores_list_stds, columns=scores_list_stds[0].keys()).mean()\n",
    "    df_stds = pd.DataFrame(stds_mean, columns=['0'], index=stds_mean.index)\n",
    "    \n",
    "    means_mean = pd.DataFrame(scores_list_means, columns=scores_list_means[0].keys()).mean()\n",
    "    df_means = pd.DataFrame(means_mean, columns=['0'], index=means_mean.index)\n",
    "    \n",
    "    path_scores_train = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_train_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_valid = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_valid_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_test = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_test_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_stds = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/stds_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_means = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/means_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "   \n",
    "    df_mean_scores_train.to_csv(path_scores_train, sep=',')\n",
    "    df_mean_scores_valid.to_csv(path_scores_valid, sep=',')\n",
    "    df_mean_scores_test.to_csv(path_scores_test, sep=',')\n",
    "    df_stds.to_csv(path_stds, sep=',')\n",
    "    df_means.to_csv(path_means, sep=',')\n",
    "else:\n",
    "    scores_list = [clf[1] for clf in clf_list]\n",
    "    \n",
    "    scores_list_by_epochs = [[] for i in epochs_save_range]\n",
    "    for scores_list in scores_list:   \n",
    "        for index, scores in enumerate(scores_list):\n",
    "            scores_list_by_epochs[index].append(scores)\n",
    "            \n",
    "        \n",
    "    for i, scores_list_single_epoch in enumerate(scores_list_by_epochs):\n",
    "        index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "           \n",
    "        scores_list_train = [scores_list[0] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_valid = [scores_list[1] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_test = [scores_list[2] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_stds = [scores_list[3] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_means = [scores_list[4] for scores_list in scores_list_single_epoch]\n",
    "        \n",
    "        scores_list_train_mean = pd.DataFrame(scores_list_train, columns=scores_list_train[0].keys()).mean()  \n",
    "        scores_list_valid_mean = pd.DataFrame(scores_list_valid, columns=scores_list_valid[0].keys()).mean()  \n",
    "        scores_list_test_mean = pd.DataFrame(scores_list_test, columns=scores_list_test[0].keys()).mean()\n",
    "        stds_mean = pd.DataFrame(scores_list_stds, columns=scores_list_stds[0].keys()).mean()\n",
    "        means_mean = pd.DataFrame(scores_list_means, columns=scores_list_means[0].keys()).mean()\n",
    "\n",
    "        if index == 1:\n",
    "            df_mean_scores_train = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED E' + str(index), 'TRAIN POLY E' + str(index), 'TRAIN POLY PRED E' + str(index), 'TRAIN LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_valid = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index), 'VALID POLY PRED E' + str(index), 'VALID LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_test = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index), 'TEST POLY PRED E' + str(index), 'TEST LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_stds = pd.DataFrame(stds_mean, columns=['E' + str(index)], index=stds_mean.index)   \n",
    "            df_means = pd.DataFrame(means_mean, columns=['E' + str(index)], index=means_mean.index)   \n",
    "        else:\n",
    "            df_mean_scores_train_new = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED E' + str(index), 'TRAIN POLY E' + str(index), 'TRAIN POLY PRED E' + str(index), 'TRAIN LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_train = pd.concat([df_mean_scores_train, df_mean_scores_train_new],axis=1)  \n",
    "            \n",
    "            df_mean_scores_valid_new = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index), 'VALID POLY PRED E' + str(index), 'VALID LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_valid = pd.concat([df_mean_scores_valid, df_mean_scores_valid_new],axis=1)  \n",
    "\n",
    "            df_mean_scores_test_new = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index), 'TEST POLY PRED E' + str(index), 'TEST LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_test = pd.concat([df_mean_scores_test, df_mean_scores_test_new],axis=1)  \n",
    "\n",
    "            df_stds_new = pd.DataFrame(stds_mean, columns=['E' + str(index)], index=stds_mean.index)\n",
    "            df_stds = pd.concat([df_stds, df_stds_new],axis=1)  \n",
    "            \n",
    "            df_means_new = pd.DataFrame(means_mean, columns=['E' + str(index)], index=means_mean.index)\n",
    "            df_means = pd.concat([df_means, df_means_new],axis=1)     \n",
    "\n",
    "    path_scores_train = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_train_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_valid = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_valid_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_test = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_test_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_stds = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/stds_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_means = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/means_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "    df_mean_scores_train.to_csv(path_scores_train, sep=',')\n",
    "    df_mean_scores_valid.to_csv(path_scores_valid, sep=',')\n",
    "    df_mean_scores_test.to_csv(path_scores_test, sep=',')\n",
    "    df_stds.to_csv(path_stds, sep=',')\n",
    "    df_means.to_csv(path_means, sep=',')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T03:04:55.846997Z",
     "start_time": "2020-11-27T03:04:55.819566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN PRED E1</th>\n",
       "      <th>TRAIN POLY E1</th>\n",
       "      <th>TRAIN POLY PRED E1</th>\n",
       "      <th>TRAIN LSTSQ E1</th>\n",
       "      <th>TRAIN PRED E10</th>\n",
       "      <th>TRAIN POLY E10</th>\n",
       "      <th>TRAIN POLY PRED E10</th>\n",
       "      <th>TRAIN LSTSQ E10</th>\n",
       "      <th>TRAIN PRED E20</th>\n",
       "      <th>TRAIN POLY E20</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAIN POLY PRED E180</th>\n",
       "      <th>TRAIN LSTSQ E180</th>\n",
       "      <th>TRAIN PRED E190</th>\n",
       "      <th>TRAIN POLY E190</th>\n",
       "      <th>TRAIN POLY PRED E190</th>\n",
       "      <th>TRAIN LSTSQ E190</th>\n",
       "      <th>TRAIN PRED E200</th>\n",
       "      <th>TRAIN POLY E200</th>\n",
       "      <th>TRAIN POLY PRED E200</th>\n",
       "      <th>TRAIN LSTSQ E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>10.188</td>\n",
       "      <td>10.188</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.701</td>\n",
       "      <td>9.702</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.930</td>\n",
       "      <td>8.932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.208</td>\n",
       "      <td>4.252</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.117</td>\n",
       "      <td>4.162</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>12.966</td>\n",
       "      <td>12.966</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.462</td>\n",
       "      <td>12.462</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.658</td>\n",
       "      <td>11.658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.939</td>\n",
       "      <td>5.914</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.824</td>\n",
       "      <td>5.795</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>1.150</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.546</td>\n",
       "      <td>1.547</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.290</td>\n",
       "      <td>2.296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.288</td>\n",
       "      <td>3.372</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.233</td>\n",
       "      <td>3.331</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>-0.415</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>0.976</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>3.444</td>\n",
       "      <td>3.443</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.414</td>\n",
       "      <td>3.413</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.349</td>\n",
       "      <td>3.348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.283</td>\n",
       "      <td>2.216</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.253</td>\n",
       "      <td>2.181</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD FV</th>\n",
       "      <td>26.441</td>\n",
       "      <td>26.442</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.656</td>\n",
       "      <td>25.655</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.296</td>\n",
       "      <td>24.293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.095</td>\n",
       "      <td>11.980</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.882</td>\n",
       "      <td>11.761</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW FV</th>\n",
       "      <td>110.867</td>\n",
       "      <td>110.862</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.000</td>\n",
       "      <td>105.997</td>\n",
       "      <td>105.977</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.185</td>\n",
       "      <td>98.186</td>\n",
       "      <td>...</td>\n",
       "      <td>3.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45.702</td>\n",
       "      <td>45.727</td>\n",
       "      <td>3.626</td>\n",
       "      <td>0.000</td>\n",
       "      <td>44.764</td>\n",
       "      <td>44.793</td>\n",
       "      <td>3.849</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRAIN PRED E1  TRAIN POLY E1  TRAIN POLY PRED E1  TRAIN LSTSQ E1  \\\n",
       "MAE FV          10.188         10.188               0.011           0.000   \n",
       "RMSE FV         12.966         12.966               0.014           0.000   \n",
       "MAPE FV          1.150          1.150               0.373           0.000   \n",
       "R2 FV           -0.415         -0.415               0.976           1.000   \n",
       "RAAE FV          0.923          0.923               0.123           0.000   \n",
       "RMAE FV          3.444          3.443               0.415           0.000   \n",
       "FD FV           26.441         26.442               0.037           0.000   \n",
       "DTW FV         110.867        110.862               0.109           0.000   \n",
       "\n",
       "         TRAIN PRED E10  TRAIN POLY E10  TRAIN POLY PRED E10  TRAIN LSTSQ E10  \\\n",
       "MAE FV            9.701           9.702                0.013            0.000   \n",
       "RMSE FV          12.462          12.462                0.017            0.000   \n",
       "MAPE FV           1.546           1.547                0.144            0.000   \n",
       "R2 FV            -0.293          -0.293                0.994            1.000   \n",
       "RAAE FV           0.877           0.877                0.059            0.000   \n",
       "RMAE FV           3.414           3.413                0.270            0.000   \n",
       "FD FV            25.656          25.655                0.036            0.000   \n",
       "DTW FV          105.997         105.977                0.109            0.000   \n",
       "\n",
       "         TRAIN PRED E20  TRAIN POLY E20  ...  TRAIN POLY PRED E180  \\\n",
       "MAE FV            8.930           8.932  ...                 0.379   \n",
       "RMSE FV          11.658          11.658  ...                 0.486   \n",
       "MAPE FV           2.290           2.296  ...                 0.441   \n",
       "R2 FV            -0.111          -0.111  ...                 0.995   \n",
       "RAAE FV           0.804           0.804  ...                 0.050   \n",
       "RMAE FV           3.349           3.348  ...                 0.250   \n",
       "FD FV            24.296          24.293  ...                 0.832   \n",
       "DTW FV           98.185          98.186  ...                 3.400   \n",
       "\n",
       "         TRAIN LSTSQ E180  TRAIN PRED E190  TRAIN POLY E190  \\\n",
       "MAE FV              0.000            4.208            4.252   \n",
       "RMSE FV             0.000            5.939            5.914   \n",
       "MAPE FV             0.000            3.288            3.372   \n",
       "R2 FV               1.000            0.687            0.689   \n",
       "RAAE FV             0.000            0.389            0.393   \n",
       "RMAE FV             0.000            2.283            2.216   \n",
       "FD FV               0.000           12.095           11.980   \n",
       "DTW FV              0.000           45.702           45.727   \n",
       "\n",
       "         TRAIN POLY PRED E190  TRAIN LSTSQ E190  TRAIN PRED E200  \\\n",
       "MAE FV                  0.406             0.000            4.117   \n",
       "RMSE FV                 0.519             0.000            5.824   \n",
       "MAPE FV                 0.655             0.000            3.233   \n",
       "R2 FV                   0.995             1.000            0.698   \n",
       "RAAE FV                 0.053             0.000            0.381   \n",
       "RMAE FV                 0.261             0.000            2.253   \n",
       "FD FV                   0.885             0.000           11.882   \n",
       "DTW FV                  3.626             0.000           44.764   \n",
       "\n",
       "         TRAIN POLY E200  TRAIN POLY PRED E200  TRAIN LSTSQ E200  \n",
       "MAE FV             4.162                 0.432             0.000  \n",
       "RMSE FV            5.795                 0.552             0.000  \n",
       "MAPE FV            3.331                 0.471             0.000  \n",
       "R2 FV              0.701                 0.994             1.000  \n",
       "RAAE FV            0.385                 0.056             0.000  \n",
       "RMAE FV            2.181                 0.272             0.000  \n",
       "FD FV             11.761                 0.939             0.000  \n",
       "DTW FV            44.793                 3.849             0.000  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T03:04:55.881314Z",
     "start_time": "2020-11-27T03:04:55.849301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALID PRED E1</th>\n",
       "      <th>VALID POLY E1</th>\n",
       "      <th>VALID POLY PRED E1</th>\n",
       "      <th>VALID LSTSQ E1</th>\n",
       "      <th>VALID PRED E10</th>\n",
       "      <th>VALID POLY E10</th>\n",
       "      <th>VALID POLY PRED E10</th>\n",
       "      <th>VALID LSTSQ E10</th>\n",
       "      <th>VALID PRED E20</th>\n",
       "      <th>VALID POLY E20</th>\n",
       "      <th>...</th>\n",
       "      <th>VALID POLY PRED E180</th>\n",
       "      <th>VALID LSTSQ E180</th>\n",
       "      <th>VALID PRED E190</th>\n",
       "      <th>VALID POLY E190</th>\n",
       "      <th>VALID POLY PRED E190</th>\n",
       "      <th>VALID LSTSQ E190</th>\n",
       "      <th>VALID PRED E200</th>\n",
       "      <th>VALID POLY E200</th>\n",
       "      <th>VALID POLY PRED E200</th>\n",
       "      <th>VALID LSTSQ E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>10.376</td>\n",
       "      <td>10.376</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.894</td>\n",
       "      <td>9.895</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.132</td>\n",
       "      <td>9.133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.406</td>\n",
       "      <td>4.425</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.315</td>\n",
       "      <td>4.334</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>13.149</td>\n",
       "      <td>13.149</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.646</td>\n",
       "      <td>12.645</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.844</td>\n",
       "      <td>11.843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.108</td>\n",
       "      <td>6.065</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.993</td>\n",
       "      <td>5.945</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>1.159</td>\n",
       "      <td>1.161</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.485</td>\n",
       "      <td>1.487</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.153</td>\n",
       "      <td>2.156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.980</td>\n",
       "      <td>4.073</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.867</td>\n",
       "      <td>3.966</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>-0.418</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.976</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>2.944</td>\n",
       "      <td>2.944</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.916</td>\n",
       "      <td>2.915</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.853</td>\n",
       "      <td>2.853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.879</td>\n",
       "      <td>1.828</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.852</td>\n",
       "      <td>1.797</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD FV</th>\n",
       "      <td>24.444</td>\n",
       "      <td>24.444</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.659</td>\n",
       "      <td>23.656</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.277</td>\n",
       "      <td>22.272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.435</td>\n",
       "      <td>10.280</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.262</td>\n",
       "      <td>10.099</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW FV</th>\n",
       "      <td>104.049</td>\n",
       "      <td>104.049</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.199</td>\n",
       "      <td>99.189</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>91.519</td>\n",
       "      <td>91.513</td>\n",
       "      <td>...</td>\n",
       "      <td>3.798</td>\n",
       "      <td>0.000</td>\n",
       "      <td>41.495</td>\n",
       "      <td>41.528</td>\n",
       "      <td>4.058</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.653</td>\n",
       "      <td>40.677</td>\n",
       "      <td>4.312</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VALID PRED E1  VALID POLY E1  VALID POLY PRED E1  VALID LSTSQ E1  \\\n",
       "MAE FV          10.376         10.376               0.012           0.000   \n",
       "RMSE FV         13.149         13.149               0.015           0.000   \n",
       "MAPE FV          1.159          1.161               0.460           0.000   \n",
       "R2 FV           -0.418         -0.418               0.976           1.000   \n",
       "RAAE FV          0.928          0.928               0.122           0.000   \n",
       "RMAE FV          2.944          2.944               0.370           0.000   \n",
       "FD FV           24.444         24.444               0.032           0.000   \n",
       "DTW FV         104.049        104.049               0.130           0.000   \n",
       "\n",
       "         VALID PRED E10  VALID POLY E10  VALID POLY PRED E10  VALID LSTSQ E10  \\\n",
       "MAE FV            9.894           9.895                0.014            0.000   \n",
       "RMSE FV          12.646          12.645                0.018            0.000   \n",
       "MAPE FV           1.485           1.487                0.124            0.000   \n",
       "R2 FV            -0.297          -0.297                0.993            1.000   \n",
       "RAAE FV           0.883           0.883                0.061            0.000   \n",
       "RMAE FV           2.916           2.915                0.252            0.000   \n",
       "FD FV            23.659          23.656                0.034            0.000   \n",
       "DTW FV           99.199          99.189                0.144            0.000   \n",
       "\n",
       "         VALID PRED E20  VALID POLY E20  ...  VALID POLY PRED E180  \\\n",
       "MAE FV            9.132           9.133  ...                 0.391   \n",
       "RMSE FV          11.844          11.843  ...                 0.503   \n",
       "MAPE FV           2.153           2.156  ...                 0.686   \n",
       "R2 FV            -0.117          -0.117  ...                 0.995   \n",
       "RAAE FV           0.811           0.811  ...                 0.051   \n",
       "RMAE FV           2.853           2.853  ...                 0.213   \n",
       "FD FV            22.277          22.272  ...                 0.908   \n",
       "DTW FV           91.519          91.513  ...                 3.798   \n",
       "\n",
       "         VALID LSTSQ E180  VALID PRED E190  VALID POLY E190  \\\n",
       "MAE FV              0.000            4.406            4.425   \n",
       "RMSE FV             0.000            6.108            6.065   \n",
       "MAPE FV             0.000            3.980            4.073   \n",
       "R2 FV               1.000            0.676            0.681   \n",
       "RAAE FV             0.000            0.402            0.404   \n",
       "RMAE FV             0.000            1.879            1.828   \n",
       "FD FV               0.000           10.435           10.280   \n",
       "DTW FV              0.000           41.495           41.528   \n",
       "\n",
       "         VALID POLY PRED E190  VALID LSTSQ E190  VALID PRED E200  \\\n",
       "MAE FV                  0.418             0.000            4.315   \n",
       "RMSE FV                 0.537             0.000            5.993   \n",
       "MAPE FV                 0.466             0.000            3.867   \n",
       "R2 FV                   0.995             1.000            0.688   \n",
       "RAAE FV                 0.054             0.000            0.394   \n",
       "RMAE FV                 0.223             0.000            1.852   \n",
       "FD FV                   0.967             0.000           10.262   \n",
       "DTW FV                  4.058             0.000           40.653   \n",
       "\n",
       "         VALID POLY E200  VALID POLY PRED E200  VALID LSTSQ E200  \n",
       "MAE FV             4.334                 0.445             0.000  \n",
       "RMSE FV            5.945                 0.570             0.000  \n",
       "MAPE FV            3.966                 0.579             0.000  \n",
       "R2 FV              0.693                 0.994             1.000  \n",
       "RAAE FV            0.396                 0.057             0.000  \n",
       "RMAE FV            1.797                 0.233             0.000  \n",
       "FD FV             10.099                 1.025             0.000  \n",
       "DTW FV            40.677                 4.312             0.000  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T03:04:55.911363Z",
     "start_time": "2020-11-27T03:04:55.883439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST PRED E1</th>\n",
       "      <th>TEST POLY E1</th>\n",
       "      <th>TEST POLY PRED E1</th>\n",
       "      <th>TEST LSTSQ E1</th>\n",
       "      <th>TEST PRED E10</th>\n",
       "      <th>TEST POLY E10</th>\n",
       "      <th>TEST POLY PRED E10</th>\n",
       "      <th>TEST LSTSQ E10</th>\n",
       "      <th>TEST PRED E20</th>\n",
       "      <th>TEST POLY E20</th>\n",
       "      <th>...</th>\n",
       "      <th>TEST POLY PRED E180</th>\n",
       "      <th>TEST LSTSQ E180</th>\n",
       "      <th>TEST PRED E190</th>\n",
       "      <th>TEST POLY E190</th>\n",
       "      <th>TEST POLY PRED E190</th>\n",
       "      <th>TEST LSTSQ E190</th>\n",
       "      <th>TEST PRED E200</th>\n",
       "      <th>TEST POLY E200</th>\n",
       "      <th>TEST POLY PRED E200</th>\n",
       "      <th>TEST LSTSQ E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>10.059</td>\n",
       "      <td>10.059</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.573</td>\n",
       "      <td>9.573</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.804</td>\n",
       "      <td>8.806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.272</td>\n",
       "      <td>4.287</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.186</td>\n",
       "      <td>4.201</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>12.823</td>\n",
       "      <td>12.823</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.322</td>\n",
       "      <td>12.322</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.524</td>\n",
       "      <td>11.524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.992</td>\n",
       "      <td>5.938</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.884</td>\n",
       "      <td>5.823</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>1.111</td>\n",
       "      <td>1.110</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.314</td>\n",
       "      <td>1.315</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.721</td>\n",
       "      <td>1.722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.091</td>\n",
       "      <td>3.158</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.098</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>3.153</td>\n",
       "      <td>3.153</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.123</td>\n",
       "      <td>3.123</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.059</td>\n",
       "      <td>3.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.052</td>\n",
       "      <td>1.987</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.024</td>\n",
       "      <td>1.954</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD FV</th>\n",
       "      <td>24.990</td>\n",
       "      <td>24.994</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.216</td>\n",
       "      <td>24.208</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.845</td>\n",
       "      <td>22.834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.566</td>\n",
       "      <td>11.421</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.381</td>\n",
       "      <td>11.228</td>\n",
       "      <td>1.052</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW FV</th>\n",
       "      <td>103.657</td>\n",
       "      <td>103.655</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.943</td>\n",
       "      <td>98.929</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.000</td>\n",
       "      <td>91.467</td>\n",
       "      <td>91.453</td>\n",
       "      <td>...</td>\n",
       "      <td>3.786</td>\n",
       "      <td>0.000</td>\n",
       "      <td>43.543</td>\n",
       "      <td>43.770</td>\n",
       "      <td>4.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>42.719</td>\n",
       "      <td>42.951</td>\n",
       "      <td>4.287</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TEST PRED E1  TEST POLY E1  TEST POLY PRED E1  TEST LSTSQ E1  \\\n",
       "MAE FV         10.059        10.059              0.013          0.000   \n",
       "RMSE FV        12.823        12.823              0.016          0.000   \n",
       "MAPE FV         1.111         1.110              0.465          0.000   \n",
       "R2 FV          -0.427        -0.427              0.975          1.000   \n",
       "RAAE FV         0.926         0.926              0.125          0.000   \n",
       "RMAE FV         3.153         3.153              0.475          0.000   \n",
       "FD FV          24.990        24.994              0.029          0.000   \n",
       "DTW FV        103.657       103.655              0.163          0.000   \n",
       "\n",
       "         TEST PRED E10  TEST POLY E10  TEST POLY PRED E10  TEST LSTSQ E10  \\\n",
       "MAE FV           9.573          9.573               0.014           0.000   \n",
       "RMSE FV         12.322         12.322               0.018           0.000   \n",
       "MAPE FV          1.314          1.315               0.144           0.000   \n",
       "R2 FV           -0.303         -0.303               0.992           1.000   \n",
       "RAAE FV          0.879          0.879               0.064           0.000   \n",
       "RMAE FV          3.123          3.123               0.262           0.000   \n",
       "FD FV           24.216         24.208               0.036           0.000   \n",
       "DTW FV          98.943         98.929               0.163           0.000   \n",
       "\n",
       "         TEST PRED E20  TEST POLY E20  ...  TEST POLY PRED E180  \\\n",
       "MAE FV           8.804          8.806  ...                0.409   \n",
       "RMSE FV         11.524         11.524  ...                0.538   \n",
       "MAPE FV          1.721          1.722  ...                0.519   \n",
       "R2 FV           -0.119         -0.119  ...                0.994   \n",
       "RAAE FV          0.805          0.805  ...                0.055   \n",
       "RMAE FV          3.059          3.059  ...                0.273   \n",
       "FD FV           22.845         22.834  ...                0.930   \n",
       "DTW FV          91.467         91.453  ...                3.786   \n",
       "\n",
       "         TEST LSTSQ E180  TEST PRED E190  TEST POLY E190  TEST POLY PRED E190  \\\n",
       "MAE FV             0.000           4.272           4.287                0.438   \n",
       "RMSE FV            0.000           5.992           5.938                0.575   \n",
       "MAPE FV            0.000           3.091           3.158                0.526   \n",
       "R2 FV              1.000           0.672           0.678                0.993   \n",
       "RAAE FV            0.000           0.401           0.402                0.058   \n",
       "RMAE FV            0.000           2.052           1.987                0.286   \n",
       "FD FV              0.000          11.566          11.421                0.991   \n",
       "DTW FV             0.000          43.543          43.770                4.038   \n",
       "\n",
       "         TEST LSTSQ E190  TEST PRED E200  TEST POLY E200  TEST POLY PRED E200  \\\n",
       "MAE FV             0.000           4.186           4.201                0.466   \n",
       "RMSE FV            0.000           5.884           5.823                0.611   \n",
       "MAPE FV            0.000           3.022           3.098                0.760   \n",
       "R2 FV              1.000           0.683           0.689                0.993   \n",
       "RAAE FV            0.000           0.393           0.394                0.061   \n",
       "RMAE FV            0.000           2.024           1.954                0.300   \n",
       "FD FV              0.000          11.381          11.228                1.052   \n",
       "DTW FV             0.000          42.719          42.951                4.287   \n",
       "\n",
       "         TEST LSTSQ E200  \n",
       "MAE FV             0.000  \n",
       "RMSE FV            0.000  \n",
       "MAPE FV            0.000  \n",
       "R2 FV              1.000  \n",
       "RAAE FV            0.000  \n",
       "RMAE FV            0.000  \n",
       "FD FV              0.000  \n",
       "DTW FV             0.000  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T03:04:55.943425Z",
     "start_time": "2020-11-27T03:04:55.914001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E1</th>\n",
       "      <th>E10</th>\n",
       "      <th>E20</th>\n",
       "      <th>E30</th>\n",
       "      <th>E40</th>\n",
       "      <th>E50</th>\n",
       "      <th>E60</th>\n",
       "      <th>E70</th>\n",
       "      <th>E80</th>\n",
       "      <th>E90</th>\n",
       "      <th>...</th>\n",
       "      <th>E110</th>\n",
       "      <th>E120</th>\n",
       "      <th>E130</th>\n",
       "      <th>E140</th>\n",
       "      <th>E150</th>\n",
       "      <th>E160</th>\n",
       "      <th>E170</th>\n",
       "      <th>E180</th>\n",
       "      <th>E190</th>\n",
       "      <th>E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN REAL LAMBDA</th>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>...</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN PRED LAMBDA</th>\n",
       "      <td>0.094</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.607</td>\n",
       "      <td>1.376</td>\n",
       "      <td>2.529</td>\n",
       "      <td>3.730</td>\n",
       "      <td>4.797</td>\n",
       "      <td>5.678</td>\n",
       "      <td>6.338</td>\n",
       "      <td>6.795</td>\n",
       "      <td>...</td>\n",
       "      <td>7.321</td>\n",
       "      <td>7.479</td>\n",
       "      <td>7.602</td>\n",
       "      <td>7.706</td>\n",
       "      <td>7.799</td>\n",
       "      <td>7.884</td>\n",
       "      <td>7.966</td>\n",
       "      <td>8.045</td>\n",
       "      <td>8.123</td>\n",
       "      <td>8.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.093</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.607</td>\n",
       "      <td>1.375</td>\n",
       "      <td>2.529</td>\n",
       "      <td>3.728</td>\n",
       "      <td>4.795</td>\n",
       "      <td>5.675</td>\n",
       "      <td>6.335</td>\n",
       "      <td>6.791</td>\n",
       "      <td>...</td>\n",
       "      <td>7.315</td>\n",
       "      <td>7.472</td>\n",
       "      <td>7.594</td>\n",
       "      <td>7.697</td>\n",
       "      <td>7.788</td>\n",
       "      <td>7.872</td>\n",
       "      <td>7.951</td>\n",
       "      <td>8.029</td>\n",
       "      <td>8.105</td>\n",
       "      <td>8.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>...</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "      <td>11.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID REAL LAMBDA</th>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>...</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID PRED LAMBDA</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.612</td>\n",
       "      <td>1.386</td>\n",
       "      <td>2.549</td>\n",
       "      <td>3.758</td>\n",
       "      <td>4.834</td>\n",
       "      <td>5.722</td>\n",
       "      <td>6.389</td>\n",
       "      <td>6.851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.383</td>\n",
       "      <td>7.543</td>\n",
       "      <td>7.668</td>\n",
       "      <td>7.774</td>\n",
       "      <td>7.867</td>\n",
       "      <td>7.954</td>\n",
       "      <td>8.036</td>\n",
       "      <td>8.116</td>\n",
       "      <td>8.194</td>\n",
       "      <td>8.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.612</td>\n",
       "      <td>1.387</td>\n",
       "      <td>2.550</td>\n",
       "      <td>3.759</td>\n",
       "      <td>4.836</td>\n",
       "      <td>5.725</td>\n",
       "      <td>6.392</td>\n",
       "      <td>6.854</td>\n",
       "      <td>...</td>\n",
       "      <td>7.386</td>\n",
       "      <td>7.545</td>\n",
       "      <td>7.669</td>\n",
       "      <td>7.773</td>\n",
       "      <td>7.866</td>\n",
       "      <td>7.951</td>\n",
       "      <td>8.031</td>\n",
       "      <td>8.110</td>\n",
       "      <td>8.187</td>\n",
       "      <td>8.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>...</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST REAL LAMBDA</th>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>...</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST PRED LAMBDA</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.597</td>\n",
       "      <td>1.352</td>\n",
       "      <td>2.486</td>\n",
       "      <td>3.669</td>\n",
       "      <td>4.724</td>\n",
       "      <td>5.595</td>\n",
       "      <td>6.248</td>\n",
       "      <td>6.700</td>\n",
       "      <td>...</td>\n",
       "      <td>7.218</td>\n",
       "      <td>7.372</td>\n",
       "      <td>7.492</td>\n",
       "      <td>7.592</td>\n",
       "      <td>7.681</td>\n",
       "      <td>7.763</td>\n",
       "      <td>7.840</td>\n",
       "      <td>7.916</td>\n",
       "      <td>7.991</td>\n",
       "      <td>8.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.104</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.597</td>\n",
       "      <td>1.351</td>\n",
       "      <td>2.485</td>\n",
       "      <td>3.666</td>\n",
       "      <td>4.718</td>\n",
       "      <td>5.587</td>\n",
       "      <td>6.238</td>\n",
       "      <td>6.689</td>\n",
       "      <td>...</td>\n",
       "      <td>7.206</td>\n",
       "      <td>7.360</td>\n",
       "      <td>7.480</td>\n",
       "      <td>7.581</td>\n",
       "      <td>7.669</td>\n",
       "      <td>7.751</td>\n",
       "      <td>7.829</td>\n",
       "      <td>7.904</td>\n",
       "      <td>7.978</td>\n",
       "      <td>8.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>...</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "      <td>10.984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        E1    E10    E20    E30    E40    E50  \\\n",
       "STD FV TRAIN REAL LAMBDA            11.146 11.146 11.146 11.146 11.146 11.146   \n",
       "STD FV TRAIN PRED LAMBDA             0.094  0.237  0.607  1.376  2.529  3.730   \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  0.093  0.236  0.607  1.375  2.529  3.728   \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.146 11.146 11.146 11.146 11.146 11.146   \n",
       "STD FV VALID REAL LAMBDA            11.300 11.300 11.300 11.300 11.300 11.300   \n",
       "STD FV VALID PRED LAMBDA             0.097  0.239  0.612  1.386  2.549  3.758   \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  0.097  0.239  0.612  1.387  2.550  3.759   \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.300 11.300 11.300 11.300 11.300 11.300   \n",
       "STD FV TEST REAL LAMBDA             10.984 10.984 10.984 10.984 10.984 10.984   \n",
       "STD FV TEST PRED LAMBDA              0.105  0.236  0.597  1.352  2.486  3.669   \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   0.104  0.235  0.597  1.351  2.485  3.666   \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  10.984 10.984 10.984 10.984 10.984 10.984   \n",
       "\n",
       "                                       E60    E70    E80    E90  ...   E110  \\\n",
       "STD FV TRAIN REAL LAMBDA            11.146 11.146 11.146 11.146  ... 11.146   \n",
       "STD FV TRAIN PRED LAMBDA             4.797  5.678  6.338  6.795  ...  7.321   \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  4.795  5.675  6.335  6.791  ...  7.315   \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.146 11.146 11.146 11.146  ... 11.146   \n",
       "STD FV VALID REAL LAMBDA            11.300 11.300 11.300 11.300  ... 11.300   \n",
       "STD FV VALID PRED LAMBDA             4.834  5.722  6.389  6.851  ...  7.383   \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  4.836  5.725  6.392  6.854  ...  7.386   \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.300 11.300 11.300 11.300  ... 11.300   \n",
       "STD FV TEST REAL LAMBDA             10.984 10.984 10.984 10.984  ... 10.984   \n",
       "STD FV TEST PRED LAMBDA              4.724  5.595  6.248  6.700  ...  7.218   \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   4.718  5.587  6.238  6.689  ...  7.206   \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  10.984 10.984 10.984 10.984  ... 10.984   \n",
       "\n",
       "                                      E120   E130   E140   E150   E160   E170  \\\n",
       "STD FV TRAIN REAL LAMBDA            11.146 11.146 11.146 11.146 11.146 11.146   \n",
       "STD FV TRAIN PRED LAMBDA             7.479  7.602  7.706  7.799  7.884  7.966   \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  7.472  7.594  7.697  7.788  7.872  7.951   \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.146 11.146 11.146 11.146 11.146 11.146   \n",
       "STD FV VALID REAL LAMBDA            11.300 11.300 11.300 11.300 11.300 11.300   \n",
       "STD FV VALID PRED LAMBDA             7.543  7.668  7.774  7.867  7.954  8.036   \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  7.545  7.669  7.773  7.866  7.951  8.031   \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.300 11.300 11.300 11.300 11.300 11.300   \n",
       "STD FV TEST REAL LAMBDA             10.984 10.984 10.984 10.984 10.984 10.984   \n",
       "STD FV TEST PRED LAMBDA              7.372  7.492  7.592  7.681  7.763  7.840   \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   7.360  7.480  7.581  7.669  7.751  7.829   \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  10.984 10.984 10.984 10.984 10.984 10.984   \n",
       "\n",
       "                                      E180   E190   E200  \n",
       "STD FV TRAIN REAL LAMBDA            11.146 11.146 11.146  \n",
       "STD FV TRAIN PRED LAMBDA             8.045  8.123  8.201  \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  8.029  8.105  8.180  \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.146 11.146 11.146  \n",
       "STD FV VALID REAL LAMBDA            11.300 11.300 11.300  \n",
       "STD FV VALID PRED LAMBDA             8.116  8.194  8.273  \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  8.110  8.187  8.263  \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.300 11.300 11.300  \n",
       "STD FV TEST REAL LAMBDA             10.984 10.984 10.984  \n",
       "STD FV TEST PRED LAMBDA              7.916  7.991  8.065  \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   7.904  7.978  8.052  \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  10.984 10.984 10.984  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T03:04:55.975753Z",
     "start_time": "2020-11-27T03:04:55.945475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E1</th>\n",
       "      <th>E10</th>\n",
       "      <th>E20</th>\n",
       "      <th>E30</th>\n",
       "      <th>E40</th>\n",
       "      <th>E50</th>\n",
       "      <th>E60</th>\n",
       "      <th>E70</th>\n",
       "      <th>E80</th>\n",
       "      <th>E90</th>\n",
       "      <th>...</th>\n",
       "      <th>E110</th>\n",
       "      <th>E120</th>\n",
       "      <th>E130</th>\n",
       "      <th>E140</th>\n",
       "      <th>E150</th>\n",
       "      <th>E160</th>\n",
       "      <th>E170</th>\n",
       "      <th>E180</th>\n",
       "      <th>E190</th>\n",
       "      <th>E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN REAL LAMBDA</th>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN PRED LAMBDA</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID REAL LAMBDA</th>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID PRED LAMBDA</th>\n",
       "      <td>0.190</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.189</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST REAL LAMBDA</th>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST PRED LAMBDA</th>\n",
       "      <td>0.194</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.195</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         E1    E10    E20    E30    E40  \\\n",
       "MEAN FV TRAIN REAL LAMBDA            -0.090 -0.090 -0.090 -0.090 -0.090   \n",
       "MEAN FV TRAIN PRED LAMBDA             0.185  0.205  0.329  0.431  0.317   \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ  0.185  0.205  0.329  0.431  0.317   \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.090 -0.090 -0.090 -0.090 -0.090   \n",
       "MEAN FV VALID REAL LAMBDA            -0.078 -0.078 -0.078 -0.078 -0.078   \n",
       "MEAN FV VALID PRED LAMBDA             0.190  0.209  0.334  0.436  0.324   \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ  0.189  0.208  0.333  0.436  0.324   \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.078 -0.078 -0.078 -0.078 -0.078   \n",
       "MEAN FV TEST REAL LAMBDA             -0.068 -0.068 -0.068 -0.068 -0.068   \n",
       "MEAN FV TEST PRED LAMBDA              0.194  0.214  0.341  0.445  0.333   \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ   0.195  0.215  0.341  0.445  0.332   \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.068 -0.068 -0.068 -0.068 -0.068   \n",
       "\n",
       "                                        E50    E60    E70    E80    E90  ...  \\\n",
       "MEAN FV TRAIN REAL LAMBDA            -0.090 -0.090 -0.090 -0.090 -0.090  ...   \n",
       "MEAN FV TRAIN PRED LAMBDA             0.184  0.100  0.052  0.023  0.006  ...   \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ  0.184  0.100  0.052  0.023  0.006  ...   \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.090 -0.090 -0.090 -0.090 -0.090  ...   \n",
       "MEAN FV VALID REAL LAMBDA            -0.078 -0.078 -0.078 -0.078 -0.078  ...   \n",
       "MEAN FV VALID PRED LAMBDA             0.193  0.110  0.062  0.033  0.016  ...   \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ  0.193  0.110  0.062  0.033  0.015  ...   \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.078 -0.078 -0.078 -0.078 -0.078  ...   \n",
       "MEAN FV TEST REAL LAMBDA             -0.068 -0.068 -0.068 -0.068 -0.068  ...   \n",
       "MEAN FV TEST PRED LAMBDA              0.199  0.114  0.065  0.035  0.018  ...   \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ   0.199  0.114  0.065  0.036  0.018  ...   \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.068 -0.068 -0.068 -0.068 -0.068  ...   \n",
       "\n",
       "                                       E110   E120   E130   E140   E150  \\\n",
       "MEAN FV TRAIN REAL LAMBDA            -0.090 -0.090 -0.090 -0.090 -0.090   \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.009 -0.013 -0.015 -0.016 -0.016   \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.009 -0.013 -0.015 -0.016 -0.016   \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.090 -0.090 -0.090 -0.090 -0.090   \n",
       "MEAN FV VALID REAL LAMBDA            -0.078 -0.078 -0.078 -0.078 -0.078   \n",
       "MEAN FV VALID PRED LAMBDA            -0.001 -0.005 -0.007 -0.008 -0.008   \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.001 -0.005 -0.008 -0.008 -0.009   \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.078 -0.078 -0.078 -0.078 -0.078   \n",
       "MEAN FV TEST REAL LAMBDA             -0.068 -0.068 -0.068 -0.068 -0.068   \n",
       "MEAN FV TEST PRED LAMBDA              0.002 -0.001 -0.003 -0.003 -0.003   \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ   0.003 -0.001 -0.003 -0.003 -0.003   \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.068 -0.068 -0.068 -0.068 -0.068   \n",
       "\n",
       "                                       E160   E170   E180   E190   E200  \n",
       "MEAN FV TRAIN REAL LAMBDA            -0.090 -0.090 -0.090 -0.090 -0.090  \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.017 -0.017 -0.017 -0.018 -0.019  \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.017 -0.017 -0.017 -0.018 -0.019  \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.090 -0.090 -0.090 -0.090 -0.090  \n",
       "MEAN FV VALID REAL LAMBDA            -0.078 -0.078 -0.078 -0.078 -0.078  \n",
       "MEAN FV VALID PRED LAMBDA            -0.009 -0.009 -0.009 -0.009 -0.010  \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.009 -0.009 -0.009 -0.010 -0.010  \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.078 -0.078 -0.078 -0.078 -0.078  \n",
       "MEAN FV TEST REAL LAMBDA             -0.068 -0.068 -0.068 -0.068 -0.068  \n",
       "MEAN FV TEST PRED LAMBDA             -0.003 -0.003 -0.003 -0.003 -0.004  \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  -0.003 -0.003 -0.003 -0.003 -0.004  \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.068 -0.068 -0.068 -0.068 -0.068  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Lambda-Net Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:09.905602Z",
     "start_time": "2020-11-27T03:04:55.978460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f3aaf86f7041448e5bf36b37c8cefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffd9905221f41de9ab5ab77e62f68e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if each_epochs_save == None:\n",
    "    \n",
    "    variable_names = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    variable_names_list = [variable + '_' for variable in variable_names[:n]]\n",
    "    variable_names_list.append('FV_')\n",
    "    \n",
    "    polynomial_real_list = [clf[0][0] for clf in clf_list] \n",
    "    polynomial_lstsq_pred_lambda_list = [clf[0][1] for clf in clf_list] \n",
    "    polynomial_lstsq_real_lambda_list = [clf[0][2] for clf in clf_list] \n",
    "    \n",
    "    polynomial_real_df = pd.DataFrame(polynomial_real_list)\n",
    "\n",
    "    y_train_real_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][0])))\n",
    "    y_train_pred_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][1])))\n",
    "    y_train_pred_lambda_poly_lstsq_list = np.zeros((len(clf_list), len(clf_list[0][2][2])))\n",
    "    X_train_lambda_list = np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][3].shape)]][0])\n",
    "    y_valid_real_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][4])))\n",
    "    y_valid_pred_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][5])))\n",
    "    y_valid_pred_lambda_poly_lstsq_list = np.zeros((len(clf_list), len(clf_list[0][2][6])))\n",
    "    X_valid_lambda_list = np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][7].shape)]][0])\n",
    "    y_test_real_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][8])))\n",
    "    y_test_pred_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][9])))\n",
    "    y_test_pred_lambda_poly_lstsq_list = np.zeros((len(clf_list), len(clf_list[0][2][10])))\n",
    "    X_test_lambda_list = np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][11].shape)]][0])\n",
    "\n",
    "    for index, (y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, X_train_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, X_valid_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, X_test_lambda) in enumerate([clf[2] for clf in clf_list]):\n",
    "        y_train_real_lambda_list[index] = y_train_real_lambda.ravel()\n",
    "        y_train_pred_lambda_list[index] = y_train_pred_lambda.ravel()\n",
    "        y_train_pred_lambda_poly_lstsq_list[index] = y_train_pred_lambda_poly_lstsq.ravel()\n",
    "        X_train_lambda_list[index] = X_train_lambda#.ravel()\n",
    "\n",
    "        y_valid_real_lambda_list[index] = y_valid_real_lambda.ravel()\n",
    "        y_valid_pred_lambda_list[index] = y_valid_pred_lambda.ravel()\n",
    "        y_valid_pred_lambda_poly_lstsq_list[index] = y_valid_pred_lambda_poly_lstsq.ravel()\n",
    "        X_valid_lambda_list[index] = X_valid_lambda#.ravel()\n",
    "\n",
    "        y_test_real_lambda_list[index] = y_test_real_lambda.ravel()\n",
    "        y_test_pred_lambda_list[index] = y_test_pred_lambda.ravel()\n",
    "        y_test_pred_lambda_poly_lstsq_list[index] = y_test_pred_lambda_poly_lstsq.ravel()\n",
    "        X_test_lambda_list[index] = X_test_lambda#.ravel()\n",
    "    \n",
    "    #add x_data before each pred\n",
    "    y_train_real_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_real_lambda.reshape(len(y_train_real_lambda),1)], axis=1).ravel() for X_train_lambda, y_train_real_lambda in zip(X_train_lambda_list, y_train_real_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_list[0].shape[0])]).ravel())\n",
    "    y_valid_real_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_real_lambda.reshape(len(y_valid_real_lambda),1)], axis=1).ravel() for X_valid_lambda, y_valid_real_lambda in zip(X_valid_lambda_list, y_valid_real_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_list[0].shape[0])]).ravel())\n",
    "    y_test_real_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_real_lambda.reshape(len(y_test_real_lambda),1)], axis=1).ravel() for X_test_lambda, y_test_real_lambda in zip(X_test_lambda_list, y_test_real_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_list[0].shape[0])]).ravel())\n",
    "    y_train_pred_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda.reshape(len(y_train_pred_lambda),1)], axis=1).ravel() for X_train_lambda, y_train_pred_lambda in zip(X_train_lambda_list, y_train_pred_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_list[0].shape[0])]).ravel())\n",
    "    y_valid_pred_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda.reshape(len(y_valid_pred_lambda),1)], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda in zip(X_valid_lambda_list, y_valid_pred_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_list[0].shape[0])]).ravel())\n",
    "    y_test_pred_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda.reshape(len(y_test_pred_lambda),1)], axis=1).ravel() for X_test_lambda, y_test_pred_lambda in zip(X_test_lambda_list, y_test_pred_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_list[0].shape[0])]).ravel())\n",
    "    y_train_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda_poly_lstsq.reshape(len(y_train_pred_lambda_poly_lstsq),1)], axis=1).ravel() for X_train_lambda, y_train_pred_lambda_poly_lstsq in zip(X_train_lambda_list, y_train_pred_lambda_poly_lstsq_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_list[0].shape[0])]).ravel())\n",
    "    y_valid_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda_poly_lstsq.reshape(len(y_valid_pred_lambda_poly_lstsq),1)], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda_poly_lstsq in zip(X_valid_lambda_list, y_valid_pred_lambda_poly_lstsq_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_list[0].shape[0])]).ravel())\n",
    "    y_test_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda_poly_lstsq.reshape(len(y_test_pred_lambda_poly_lstsq),1)], axis=1).ravel() for X_test_lambda, y_test_pred_lambda_poly_lstsq in zip(X_test_lambda_list, y_test_pred_lambda_poly_lstsq_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_list[0].shape[0])]).ravel())    \n",
    "    \n",
    "    y_train_real_lambda_df = pd.concat([polynomial_real_df, y_train_real_lambda_df], axis=1)\n",
    "    y_valid_real_lambda_df = pd.concat([polynomial_real_df, y_valid_real_lambda_df], axis=1)\n",
    "    y_test_real_lambda_df = pd.concat([polynomial_real_df, y_test_real_lambda_df], axis=1)\n",
    "    y_train_pred_lambda_df = pd.concat([polynomial_real_df, y_train_pred_lambda_df], axis=1)\n",
    "    y_valid_pred_lambda_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_df], axis=1)\n",
    "    y_test_pred_lambda_df = pd.concat([polynomial_real_df, y_test_pred_lambda_df], axis=1)\n",
    "    y_train_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_train_pred_lambda_poly_lstsq_df], axis=1)\n",
    "    y_valid_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_poly_lstsq_df], axis=1)\n",
    "    y_test_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_test_pred_lambda_poly_lstsq_df], axis=1)\n",
    "       \n",
    "    path_y_train_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_real_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_valid_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_real_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_test_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_real_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_train_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_valid_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_test_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_train_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_poly_lstsq_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_valid_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_poly_lstsq_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_test_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_poly_lstsq_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "   \n",
    "    y_train_real_lambda_df.to_csv(path_y_train_real_lambda, sep=',', index=False)\n",
    "    y_valid_real_lambda_df.to_csv(path_y_valid_real_lambda, sep=',', index=False)\n",
    "    y_test_real_lambda_df.to_csv(path_y_test_real_lambda, sep=',', index=False)\n",
    "    y_train_pred_lambda_df.to_csv(path_y_train_pred_lambda, sep=',', index=False)\n",
    "    y_valid_pred_lambda_df.to_csv(path_y_valid_pred_lambda, sep=',', index=False)\n",
    "    y_test_pred_lambda_df.to_csv(path_y_test_pred_lambda, sep=',', index=False)\n",
    "    y_train_pred_lambda_poly_lstsq_df.to_csv(path_y_train_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "    y_valid_pred_lambda_poly_lstsq_df.to_csv(path_y_valid_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "    y_test_pred_lambda_poly_lstsq_df.to_csv(path_y_test_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    variable_names = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    variable_names_list = [variable + '_' for variable in variable_names[:n]]\n",
    "    variable_names_list.append('FV_')\n",
    "    \n",
    "    polynomial_real_list = [clf[0][0] for clf in clf_list]\n",
    "    polynomial_lstsq_pred_lambda_list = [clf[0][1] for clf in clf_list]\n",
    "    polynomial_lstsq_real_lambda_list = [clf[0][2] for clf in clf_list]\n",
    "    \n",
    "    polynomial_real_df = pd.DataFrame(polynomial_real_list)\n",
    "    \n",
    "    y_train_real_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][0]), 1)) for i in epochs_save_range]\n",
    "    y_train_pred_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][1]), 1)) for i in epochs_save_range]\n",
    "    y_train_pred_lambda_poly_lstsq_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][2]), 1)) for i in epochs_save_range]\n",
    "    X_train_lambda_list = [np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][0][3].shape)]][0]) for i in epochs_save_range]\n",
    "    y_valid_real_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][4]), 1)) for i in epochs_save_range]\n",
    "    y_valid_pred_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][5]), 1)) for i in epochs_save_range]\n",
    "    y_valid_pred_lambda_poly_lstsq_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][6]), 1)) for i in epochs_save_range]\n",
    "    X_valid_lambda_list = [np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][0][7].shape)]][0]) for i in epochs_save_range]\n",
    "    y_test_real_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][8]), 1)) for i in epochs_save_range]\n",
    "    y_test_pred_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][9]), 1)) for i in epochs_save_range]\n",
    "    y_test_pred_lambda_poly_lstsq_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][10]), 1)) for i in epochs_save_range]\n",
    "    X_test_lambda_list = [np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][0][11].shape)]][0]) for i in epochs_save_range]\n",
    "    \n",
    "    for i, y_data_list_per_epoch in tqdm(enumerate([clf[2] for clf in clf_list]), total=len(clf_list)):\n",
    "        \n",
    "        for index, (y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, X_train_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, X_valid_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, X_test_lambda) in enumerate(y_data_list_per_epoch):\n",
    "            y_train_real_lambda_list[index][i] = y_train_real_lambda#.ravel()\n",
    "            y_train_pred_lambda_list[index][i] = y_train_pred_lambda#.ravel()\n",
    "            y_train_pred_lambda_poly_lstsq_list[index][i] = y_train_pred_lambda_poly_lstsq#.ravel()\n",
    "            X_train_lambda_list[index][i] = X_train_lambda#.ravel()\n",
    "            \n",
    "            y_valid_real_lambda_list[index][i] = y_valid_real_lambda#.ravel()\n",
    "            y_valid_pred_lambda_list[index][i] = y_valid_pred_lambda#.ravel()\n",
    "            y_valid_pred_lambda_poly_lstsq_list[index][i] = y_valid_pred_lambda_poly_lstsq#.ravel()\n",
    "            X_valid_lambda_list[index][i] = X_valid_lambda#.ravel()\n",
    "            \n",
    "            y_test_real_lambda_list[index][i] = y_test_real_lambda#.ravel()\n",
    "            y_test_pred_lambda_list[index][i] = y_test_pred_lambda#.ravel()\n",
    "            y_test_pred_lambda_poly_lstsq_list[index][i] = y_test_pred_lambda_poly_lstsq#.ravel()\n",
    "            X_test_lambda_list[index][i] = X_test_lambda#.ravel()\n",
    "    \n",
    "    for i, (y_train_real_lambda_by_epoch, y_train_pred_lambda_by_epoch, y_train_pred_lambda_poly_lstsq_by_epoch, X_train_lambda_by_epoch, y_valid_real_lambda_by_epoch, y_valid_pred_lambda_by_epoch, y_valid_pred_lambda_poly_lstsq_by_epoch, X_valid_lambda_by_epoch, y_test_real_lambda_by_epoch, y_test_pred_lambda_by_epoch, y_test_pred_lambda_poly_lstsq_by_epoch, X_test_lambda_by_epoch) in tqdm(enumerate(zip(y_train_real_lambda_list, y_train_pred_lambda_list, y_train_pred_lambda_poly_lstsq_list, X_train_lambda_list, y_valid_real_lambda_list, y_valid_pred_lambda_list, y_valid_pred_lambda_poly_lstsq_list, X_valid_lambda_list, y_test_real_lambda_list, y_test_pred_lambda_list, y_test_pred_lambda_poly_lstsq_list, X_test_lambda_list)), total=len(y_train_pred_lambda_list)):\n",
    "        index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "        \n",
    "        y_train_real_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_real_lambda], axis=1).ravel() for X_train_lambda, y_train_real_lambda in zip(X_train_lambda_by_epoch, y_train_real_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_valid_real_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_real_lambda], axis=1).ravel() for X_valid_lambda, y_valid_real_lambda in zip(X_valid_lambda_by_epoch, y_valid_real_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_test_real_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_real_lambda], axis=1).ravel() for X_test_lambda, y_test_real_lambda in zip(X_test_lambda_by_epoch, y_test_real_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_train_pred_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda], axis=1).ravel() for X_train_lambda, y_train_pred_lambda in zip(X_train_lambda_by_epoch, y_train_pred_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_valid_pred_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda in zip(X_valid_lambda_by_epoch, y_valid_pred_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_test_pred_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda], axis=1).ravel() for X_test_lambda, y_test_pred_lambda in zip(X_test_lambda_by_epoch, y_test_pred_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_train_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda_poly_lstsq], axis=1).ravel() for X_train_lambda, y_train_pred_lambda_poly_lstsq in zip(X_train_lambda_by_epoch, y_train_pred_lambda_poly_lstsq_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_valid_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda_poly_lstsq], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda_poly_lstsq in zip(X_valid_lambda_by_epoch, y_valid_pred_lambda_poly_lstsq_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_test_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda_poly_lstsq], axis=1).ravel() for X_test_lambda, y_test_pred_lambda_poly_lstsq in zip(X_test_lambda_by_epoch, y_test_pred_lambda_poly_lstsq_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_by_epoch[0].shape[0])]).ravel())    \n",
    "\n",
    "        y_train_real_lambda_df = pd.concat([polynomial_real_df, y_train_real_lambda_df], axis=1)\n",
    "        y_valid_real_lambda_df = pd.concat([polynomial_real_df, y_valid_real_lambda_df], axis=1)\n",
    "        y_test_real_lambda_df = pd.concat([polynomial_real_df, y_test_real_lambda_df], axis=1)\n",
    "        y_train_pred_lambda_df = pd.concat([polynomial_real_df, y_train_pred_lambda_df], axis=1)\n",
    "        y_valid_pred_lambda_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_df], axis=1)\n",
    "        y_test_pred_lambda_df = pd.concat([polynomial_real_df, y_test_pred_lambda_df], axis=1)\n",
    "        y_train_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_train_pred_lambda_poly_lstsq_df], axis=1)\n",
    "        y_valid_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_poly_lstsq_df], axis=1)\n",
    "        y_test_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_test_pred_lambda_poly_lstsq_df], axis=1)\n",
    "\n",
    "        path_y_train_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_real_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_valid_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_real_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_test_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_real_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_train_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_valid_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_test_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_train_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_poly_lstsq_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_valid_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_poly_lstsq_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_test_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_poly_lstsq_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "        y_train_real_lambda_df.to_csv(path_y_train_real_lambda, sep=',', index=False)\n",
    "        y_valid_real_lambda_df.to_csv(path_y_valid_real_lambda, sep=',', index=False)\n",
    "        y_test_real_lambda_df.to_csv(path_y_test_real_lambda, sep=',', index=False)         \n",
    "        y_train_pred_lambda_df.to_csv(path_y_train_pred_lambda, sep=',', index=False)\n",
    "        y_valid_pred_lambda_df.to_csv(path_y_valid_pred_lambda, sep=',', index=False)\n",
    "        y_test_pred_lambda_df.to_csv(path_y_test_pred_lambda, sep=',', index=False)    \n",
    "        y_train_pred_lambda_poly_lstsq_df.to_csv(path_y_train_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "        y_valid_pred_lambda_poly_lstsq_df.to_csv(path_y_valid_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "        y_test_pred_lambda_poly_lstsq_df.to_csv(path_y_test_pred_lambda_poly_lstsq, sep=',', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:09.943704Z",
     "start_time": "2020-11-27T04:45:09.909398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0012</th>\n",
       "      <th>0020</th>\n",
       "      <th>0021</th>\n",
       "      <th>0030</th>\n",
       "      <th>...</th>\n",
       "      <th>a_249</th>\n",
       "      <th>b_249</th>\n",
       "      <th>c_249</th>\n",
       "      <th>d_249</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>a_250</th>\n",
       "      <th>b_250</th>\n",
       "      <th>c_250</th>\n",
       "      <th>d_250</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>-9.400</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-7.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-29.468</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>1.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.900</td>\n",
       "      <td>9.400</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>7.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-6.100</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>9.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>8.772</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-13.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>9.700</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.100</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-22.832</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-39.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.800</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>6.268</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>9.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-13.346</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>3.627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0000   0001   0002   0003   0010   0011   0012   0020   0021   0030  ...  \\\n",
       "0  6.300 -7.200 -9.400  8.900 -3.000 -3.800 -4.300 -6.500  8.800 -7.400  ...   \n",
       "1 -9.900  9.400 -6.000  7.800  0.800 -1.300 -2.900 -6.100 -4.500  9.500  ...   \n",
       "2 -8.900  6.900 -4.200  9.700 -2.600 -8.000 -4.100 -7.500 -0.300 -2.900  ...   \n",
       "3  4.200 -4.400  7.500 -1.700  9.600  9.800 -8.600 -4.200 -9.200 -2.000  ...   \n",
       "4  0.200 -0.800 -4.400 -6.500  3.000  2.600 -7.700  9.300 -8.800 -7.200  ...   \n",
       "\n",
       "   a_249  b_249  c_249  d_249  FV_249  a_250  b_250  c_250  d_250  FV_250  \n",
       "0  0.250 -0.960  0.540  0.460 -29.468  0.400 -0.980 -0.440 -0.730   1.088  \n",
       "1  0.250 -0.960  0.540  0.460   8.772  0.400 -0.980 -0.440 -0.730 -13.959  \n",
       "2  0.250 -0.960  0.540  0.460 -22.832  0.400 -0.980 -0.440 -0.730 -39.214  \n",
       "3  0.250 -0.960  0.540  0.460   6.268  0.400 -0.980 -0.440 -0.730   9.685  \n",
       "4  0.250 -0.960  0.540  0.460 -13.346  0.400 -0.980 -0.440 -0.730   3.627  \n",
       "\n",
       "[5 rows x 1285 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_real_lambda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:11.365260Z",
     "start_time": "2020-11-27T04:45:09.946526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0012</th>\n",
       "      <th>0020</th>\n",
       "      <th>0021</th>\n",
       "      <th>0030</th>\n",
       "      <th>...</th>\n",
       "      <th>a_249</th>\n",
       "      <th>b_249</th>\n",
       "      <th>c_249</th>\n",
       "      <th>d_249</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>a_250</th>\n",
       "      <th>b_250</th>\n",
       "      <th>c_250</th>\n",
       "      <th>d_250</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>-9.400</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-7.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-15.914</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-4.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.900</td>\n",
       "      <td>9.400</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>7.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-6.100</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>9.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>1.477</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-21.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>9.700</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.100</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-16.859</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-26.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.800</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>8.104</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>5.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-3.081</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>12.858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0000   0001   0002   0003   0010   0011   0012   0020   0021   0030  ...  \\\n",
       "0  6.300 -7.200 -9.400  8.900 -3.000 -3.800 -4.300 -6.500  8.800 -7.400  ...   \n",
       "1 -9.900  9.400 -6.000  7.800  0.800 -1.300 -2.900 -6.100 -4.500  9.500  ...   \n",
       "2 -8.900  6.900 -4.200  9.700 -2.600 -8.000 -4.100 -7.500 -0.300 -2.900  ...   \n",
       "3  4.200 -4.400  7.500 -1.700  9.600  9.800 -8.600 -4.200 -9.200 -2.000  ...   \n",
       "4  0.200 -0.800 -4.400 -6.500  3.000  2.600 -7.700  9.300 -8.800 -7.200  ...   \n",
       "\n",
       "   a_249  b_249  c_249  d_249  FV_249  a_250  b_250  c_250  d_250  FV_250  \n",
       "0  0.250 -0.960  0.540  0.460 -15.914  0.400 -0.980 -0.440 -0.730  -4.734  \n",
       "1  0.250 -0.960  0.540  0.460   1.477  0.400 -0.980 -0.440 -0.730 -21.541  \n",
       "2  0.250 -0.960  0.540  0.460 -16.859  0.400 -0.980 -0.440 -0.730 -26.536  \n",
       "3  0.250 -0.960  0.540  0.460   8.104  0.400 -0.980 -0.440 -0.730   5.145  \n",
       "4  0.250 -0.960  0.540  0.460  -3.081  0.400 -0.980 -0.440 -0.730  12.858  \n",
       "\n",
       "[5 rows x 1285 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_lambda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:11.397018Z",
     "start_time": "2020-11-27T04:45:11.368009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0012</th>\n",
       "      <th>0020</th>\n",
       "      <th>0021</th>\n",
       "      <th>0030</th>\n",
       "      <th>...</th>\n",
       "      <th>a_249</th>\n",
       "      <th>b_249</th>\n",
       "      <th>c_249</th>\n",
       "      <th>d_249</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>a_250</th>\n",
       "      <th>b_250</th>\n",
       "      <th>c_250</th>\n",
       "      <th>d_250</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>-9.400</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-7.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-16.372</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-5.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.900</td>\n",
       "      <td>9.400</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>7.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-6.100</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>9.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>1.316</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-21.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>9.700</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.100</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-16.230</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-27.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.800</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>7.278</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>4.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-2.972</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>11.981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0000   0001   0002   0003   0010   0011   0012   0020   0021   0030  ...  \\\n",
       "0  6.300 -7.200 -9.400  8.900 -3.000 -3.800 -4.300 -6.500  8.800 -7.400  ...   \n",
       "1 -9.900  9.400 -6.000  7.800  0.800 -1.300 -2.900 -6.100 -4.500  9.500  ...   \n",
       "2 -8.900  6.900 -4.200  9.700 -2.600 -8.000 -4.100 -7.500 -0.300 -2.900  ...   \n",
       "3  4.200 -4.400  7.500 -1.700  9.600  9.800 -8.600 -4.200 -9.200 -2.000  ...   \n",
       "4  0.200 -0.800 -4.400 -6.500  3.000  2.600 -7.700  9.300 -8.800 -7.200  ...   \n",
       "\n",
       "   a_249  b_249  c_249  d_249  FV_249  a_250  b_250  c_250  d_250  FV_250  \n",
       "0  0.250 -0.960  0.540  0.460 -16.372  0.400 -0.980 -0.440 -0.730  -5.164  \n",
       "1  0.250 -0.960  0.540  0.460   1.316  0.400 -0.980 -0.440 -0.730 -21.828  \n",
       "2  0.250 -0.960  0.540  0.460 -16.230  0.400 -0.980 -0.440 -0.730 -27.138  \n",
       "3  0.250 -0.960  0.540  0.460   7.278  0.400 -0.980 -0.440 -0.730   4.249  \n",
       "4  0.250 -0.960  0.540  0.460  -2.972  0.400 -0.980 -0.440 -0.730  11.981  \n",
       "\n",
       "[5 rows x 1285 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_lambda_poly_lstsq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:15.161141Z",
     "start_time": "2020-11-27T04:45:11.399883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e45d9ab36f47b4b9e676ae7028e68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list_total = []\n",
    "metric_list_total = []\n",
    "\n",
    "val_loss_list_total = []\n",
    "val_metric_list_total = []\n",
    "\n",
    "for _, entry in tqdm(enumerate(clf_list)):\n",
    "    entry = entry[3]\n",
    "    loss_list = []\n",
    "    metric_list = []\n",
    "    val_loss_list = []\n",
    "    val_metric_list = []\n",
    "    for i in range(epochs):  \n",
    "        loss_list.append(entry['loss'][i])\n",
    "        metric_list.append(entry['mean_absolute_percentage_error_keras'][i])\n",
    "        val_loss_list.append(entry['val_loss'][i])\n",
    "        val_metric_list.append(entry['val_mean_absolute_percentage_error_keras'][i])\n",
    "    loss_list_total.append(loss_list)\n",
    "    metric_list_total.append(metric_list)\n",
    "    val_loss_list_total.append(val_loss_list)\n",
    "    val_metric_list_total.append(val_metric_list)\n",
    "\n",
    "loss_df = pd.DataFrame(data=loss_list_total, columns=['loss_epoch_' + str(i+1) for i in range(epochs)])\n",
    "metric_df = pd.DataFrame(data=metric_list_total, columns=['metric_epoch_' + str(i+1) for i in range(epochs)]) \n",
    "val_loss_df = pd.DataFrame(data=val_loss_list_total, columns=['val_loss_epoch_' + str(i+1) for i in range(epochs)])\n",
    "val_metric_df = pd.DataFrame(data=val_metric_list_total, columns=['val_metric_epoch_' + str(i+1) for i in range(epochs)]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:33.815921Z",
     "start_time": "2020-11-27T04:45:15.163816Z"
    }
   },
   "outputs": [],
   "source": [
    "path_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_val_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_val_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "loss_df.to_csv(path_loss, index=None, sep=',')\n",
    "metric_df.to_csv(path_metric, index=None, sep=',')\n",
    "val_loss_df.to_csv(path_val_loss, index=None, sep=',')\n",
    "val_metric_df.to_csv(path_val_metric, index=None, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:34.607882Z",
     "start_time": "2020-11-27T04:45:33.818525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_epoch_1</th>\n",
       "      <th>loss_epoch_2</th>\n",
       "      <th>loss_epoch_3</th>\n",
       "      <th>loss_epoch_4</th>\n",
       "      <th>loss_epoch_5</th>\n",
       "      <th>loss_epoch_6</th>\n",
       "      <th>loss_epoch_7</th>\n",
       "      <th>loss_epoch_8</th>\n",
       "      <th>loss_epoch_9</th>\n",
       "      <th>loss_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_epoch_191</th>\n",
       "      <th>loss_epoch_192</th>\n",
       "      <th>loss_epoch_193</th>\n",
       "      <th>loss_epoch_194</th>\n",
       "      <th>loss_epoch_195</th>\n",
       "      <th>loss_epoch_196</th>\n",
       "      <th>loss_epoch_197</th>\n",
       "      <th>loss_epoch_198</th>\n",
       "      <th>loss_epoch_199</th>\n",
       "      <th>loss_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.218</td>\n",
       "      <td>10.166</td>\n",
       "      <td>10.114</td>\n",
       "      <td>10.062</td>\n",
       "      <td>10.010</td>\n",
       "      <td>9.958</td>\n",
       "      <td>9.904</td>\n",
       "      <td>9.850</td>\n",
       "      <td>9.793</td>\n",
       "      <td>9.735</td>\n",
       "      <td>...</td>\n",
       "      <td>4.208</td>\n",
       "      <td>4.199</td>\n",
       "      <td>4.190</td>\n",
       "      <td>4.181</td>\n",
       "      <td>4.172</td>\n",
       "      <td>4.163</td>\n",
       "      <td>4.153</td>\n",
       "      <td>4.144</td>\n",
       "      <td>4.135</td>\n",
       "      <td>4.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.331</td>\n",
       "      <td>2.308</td>\n",
       "      <td>2.285</td>\n",
       "      <td>2.263</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.217</td>\n",
       "      <td>2.194</td>\n",
       "      <td>2.169</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.526</td>\n",
       "      <td>4.519</td>\n",
       "      <td>4.512</td>\n",
       "      <td>4.505</td>\n",
       "      <td>4.498</td>\n",
       "      <td>4.492</td>\n",
       "      <td>4.485</td>\n",
       "      <td>4.478</td>\n",
       "      <td>4.471</td>\n",
       "      <td>4.465</td>\n",
       "      <td>...</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.234</td>\n",
       "      <td>2.229</td>\n",
       "      <td>2.226</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.215</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.206</td>\n",
       "      <td>2.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.506</td>\n",
       "      <td>8.471</td>\n",
       "      <td>8.436</td>\n",
       "      <td>8.403</td>\n",
       "      <td>8.362</td>\n",
       "      <td>8.321</td>\n",
       "      <td>8.283</td>\n",
       "      <td>8.251</td>\n",
       "      <td>8.211</td>\n",
       "      <td>8.170</td>\n",
       "      <td>...</td>\n",
       "      <td>3.867</td>\n",
       "      <td>3.859</td>\n",
       "      <td>3.851</td>\n",
       "      <td>3.842</td>\n",
       "      <td>3.834</td>\n",
       "      <td>3.825</td>\n",
       "      <td>3.816</td>\n",
       "      <td>3.808</td>\n",
       "      <td>3.799</td>\n",
       "      <td>3.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.943</td>\n",
       "      <td>9.898</td>\n",
       "      <td>9.849</td>\n",
       "      <td>9.806</td>\n",
       "      <td>9.754</td>\n",
       "      <td>9.706</td>\n",
       "      <td>9.658</td>\n",
       "      <td>9.615</td>\n",
       "      <td>9.564</td>\n",
       "      <td>9.510</td>\n",
       "      <td>...</td>\n",
       "      <td>4.199</td>\n",
       "      <td>4.190</td>\n",
       "      <td>4.181</td>\n",
       "      <td>4.172</td>\n",
       "      <td>4.164</td>\n",
       "      <td>4.154</td>\n",
       "      <td>4.144</td>\n",
       "      <td>4.135</td>\n",
       "      <td>4.127</td>\n",
       "      <td>4.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.635</td>\n",
       "      <td>11.566</td>\n",
       "      <td>11.508</td>\n",
       "      <td>11.447</td>\n",
       "      <td>11.386</td>\n",
       "      <td>11.326</td>\n",
       "      <td>11.266</td>\n",
       "      <td>11.199</td>\n",
       "      <td>11.132</td>\n",
       "      <td>11.063</td>\n",
       "      <td>...</td>\n",
       "      <td>4.543</td>\n",
       "      <td>4.533</td>\n",
       "      <td>4.525</td>\n",
       "      <td>4.515</td>\n",
       "      <td>4.505</td>\n",
       "      <td>4.495</td>\n",
       "      <td>4.484</td>\n",
       "      <td>4.474</td>\n",
       "      <td>4.465</td>\n",
       "      <td>4.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.204</td>\n",
       "      <td>21.031</td>\n",
       "      <td>20.858</td>\n",
       "      <td>20.685</td>\n",
       "      <td>20.508</td>\n",
       "      <td>20.329</td>\n",
       "      <td>20.143</td>\n",
       "      <td>19.951</td>\n",
       "      <td>19.748</td>\n",
       "      <td>19.532</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122</td>\n",
       "      <td>6.117</td>\n",
       "      <td>6.109</td>\n",
       "      <td>6.102</td>\n",
       "      <td>6.094</td>\n",
       "      <td>6.088</td>\n",
       "      <td>6.080</td>\n",
       "      <td>6.071</td>\n",
       "      <td>6.063</td>\n",
       "      <td>6.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss_epoch_1  loss_epoch_2  loss_epoch_3  loss_epoch_4  loss_epoch_5  \\\n",
       "count     10000.000     10000.000     10000.000     10000.000     10000.000   \n",
       "mean         10.218        10.166        10.114        10.062        10.010   \n",
       "std           2.331         2.308         2.285         2.263         2.240   \n",
       "min           4.526         4.519         4.512         4.505         4.498   \n",
       "25%           8.506         8.471         8.436         8.403         8.362   \n",
       "50%           9.943         9.898         9.849         9.806         9.754   \n",
       "75%          11.635        11.566        11.508        11.447        11.386   \n",
       "max          21.204        21.031        20.858        20.685        20.508   \n",
       "\n",
       "       loss_epoch_6  loss_epoch_7  loss_epoch_8  loss_epoch_9  loss_epoch_10  \\\n",
       "count     10000.000     10000.000     10000.000     10000.000      10000.000   \n",
       "mean          9.958         9.904         9.850         9.793          9.735   \n",
       "std           2.217         2.194         2.169         2.145          2.119   \n",
       "min           4.492         4.485         4.478         4.471          4.465   \n",
       "25%           8.321         8.283         8.251         8.211          8.170   \n",
       "50%           9.706         9.658         9.615         9.564          9.510   \n",
       "75%          11.326        11.266        11.199        11.132         11.063   \n",
       "max          20.329        20.143        19.951        19.748         19.532   \n",
       "\n",
       "       ...  loss_epoch_191  loss_epoch_192  loss_epoch_193  loss_epoch_194  \\\n",
       "count  ...       10000.000       10000.000       10000.000       10000.000   \n",
       "mean   ...           4.208           4.199           4.190           4.181   \n",
       "std    ...           0.499           0.499           0.498           0.497   \n",
       "min    ...           2.244           2.240           2.234           2.229   \n",
       "25%    ...           3.867           3.859           3.851           3.842   \n",
       "50%    ...           4.199           4.190           4.181           4.172   \n",
       "75%    ...           4.543           4.533           4.525           4.515   \n",
       "max    ...           6.122           6.117           6.109           6.102   \n",
       "\n",
       "       loss_epoch_195  loss_epoch_196  loss_epoch_197  loss_epoch_198  \\\n",
       "count       10000.000       10000.000       10000.000       10000.000   \n",
       "mean            4.172           4.163           4.153           4.144   \n",
       "std             0.496           0.496           0.495           0.494   \n",
       "min             2.226           2.219           2.215           2.211   \n",
       "25%             3.834           3.825           3.816           3.808   \n",
       "50%             4.164           4.154           4.144           4.135   \n",
       "75%             4.505           4.495           4.484           4.474   \n",
       "max             6.094           6.088           6.080           6.071   \n",
       "\n",
       "       loss_epoch_199  loss_epoch_200  \n",
       "count       10000.000       10000.000  \n",
       "mean            4.135           4.126  \n",
       "std             0.493           0.492  \n",
       "min             2.206           2.201  \n",
       "25%             3.799           3.791  \n",
       "50%             4.127           4.117  \n",
       "75%             4.465           4.455  \n",
       "max             6.063           6.055  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:35.369474Z",
     "start_time": "2020-11-27T04:45:34.610536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss_epoch_1</th>\n",
       "      <th>val_loss_epoch_2</th>\n",
       "      <th>val_loss_epoch_3</th>\n",
       "      <th>val_loss_epoch_4</th>\n",
       "      <th>val_loss_epoch_5</th>\n",
       "      <th>val_loss_epoch_6</th>\n",
       "      <th>val_loss_epoch_7</th>\n",
       "      <th>val_loss_epoch_8</th>\n",
       "      <th>val_loss_epoch_9</th>\n",
       "      <th>val_loss_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>val_loss_epoch_191</th>\n",
       "      <th>val_loss_epoch_192</th>\n",
       "      <th>val_loss_epoch_193</th>\n",
       "      <th>val_loss_epoch_194</th>\n",
       "      <th>val_loss_epoch_195</th>\n",
       "      <th>val_loss_epoch_196</th>\n",
       "      <th>val_loss_epoch_197</th>\n",
       "      <th>val_loss_epoch_198</th>\n",
       "      <th>val_loss_epoch_199</th>\n",
       "      <th>val_loss_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.376</td>\n",
       "      <td>10.325</td>\n",
       "      <td>10.274</td>\n",
       "      <td>10.223</td>\n",
       "      <td>10.171</td>\n",
       "      <td>10.118</td>\n",
       "      <td>10.065</td>\n",
       "      <td>10.010</td>\n",
       "      <td>9.953</td>\n",
       "      <td>9.894</td>\n",
       "      <td>...</td>\n",
       "      <td>4.396</td>\n",
       "      <td>4.387</td>\n",
       "      <td>4.378</td>\n",
       "      <td>4.369</td>\n",
       "      <td>4.360</td>\n",
       "      <td>4.351</td>\n",
       "      <td>4.342</td>\n",
       "      <td>4.333</td>\n",
       "      <td>4.324</td>\n",
       "      <td>4.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.414</td>\n",
       "      <td>2.392</td>\n",
       "      <td>2.370</td>\n",
       "      <td>2.348</td>\n",
       "      <td>2.326</td>\n",
       "      <td>2.303</td>\n",
       "      <td>2.280</td>\n",
       "      <td>2.256</td>\n",
       "      <td>2.232</td>\n",
       "      <td>2.206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.713</td>\n",
       "      <td>4.706</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.694</td>\n",
       "      <td>4.688</td>\n",
       "      <td>4.682</td>\n",
       "      <td>4.676</td>\n",
       "      <td>4.670</td>\n",
       "      <td>4.661</td>\n",
       "      <td>4.592</td>\n",
       "      <td>...</td>\n",
       "      <td>2.360</td>\n",
       "      <td>2.356</td>\n",
       "      <td>2.350</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.342</td>\n",
       "      <td>2.337</td>\n",
       "      <td>2.332</td>\n",
       "      <td>2.326</td>\n",
       "      <td>2.323</td>\n",
       "      <td>2.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.616</td>\n",
       "      <td>8.576</td>\n",
       "      <td>8.544</td>\n",
       "      <td>8.509</td>\n",
       "      <td>8.466</td>\n",
       "      <td>8.430</td>\n",
       "      <td>8.394</td>\n",
       "      <td>8.356</td>\n",
       "      <td>8.320</td>\n",
       "      <td>8.274</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.991</td>\n",
       "      <td>3.984</td>\n",
       "      <td>3.976</td>\n",
       "      <td>3.967</td>\n",
       "      <td>3.958</td>\n",
       "      <td>3.951</td>\n",
       "      <td>3.943</td>\n",
       "      <td>3.935</td>\n",
       "      <td>3.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.097</td>\n",
       "      <td>10.056</td>\n",
       "      <td>10.007</td>\n",
       "      <td>9.961</td>\n",
       "      <td>9.914</td>\n",
       "      <td>9.864</td>\n",
       "      <td>9.815</td>\n",
       "      <td>9.756</td>\n",
       "      <td>9.704</td>\n",
       "      <td>9.653</td>\n",
       "      <td>...</td>\n",
       "      <td>4.373</td>\n",
       "      <td>4.365</td>\n",
       "      <td>4.356</td>\n",
       "      <td>4.347</td>\n",
       "      <td>4.338</td>\n",
       "      <td>4.329</td>\n",
       "      <td>4.320</td>\n",
       "      <td>4.311</td>\n",
       "      <td>4.302</td>\n",
       "      <td>4.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.863</td>\n",
       "      <td>11.789</td>\n",
       "      <td>11.720</td>\n",
       "      <td>11.657</td>\n",
       "      <td>11.597</td>\n",
       "      <td>11.531</td>\n",
       "      <td>11.473</td>\n",
       "      <td>11.403</td>\n",
       "      <td>11.337</td>\n",
       "      <td>11.266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.785</td>\n",
       "      <td>4.776</td>\n",
       "      <td>4.767</td>\n",
       "      <td>4.758</td>\n",
       "      <td>4.748</td>\n",
       "      <td>4.740</td>\n",
       "      <td>4.730</td>\n",
       "      <td>4.721</td>\n",
       "      <td>4.710</td>\n",
       "      <td>4.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.523</td>\n",
       "      <td>21.407</td>\n",
       "      <td>21.292</td>\n",
       "      <td>21.177</td>\n",
       "      <td>21.061</td>\n",
       "      <td>20.944</td>\n",
       "      <td>20.824</td>\n",
       "      <td>20.700</td>\n",
       "      <td>20.571</td>\n",
       "      <td>20.438</td>\n",
       "      <td>...</td>\n",
       "      <td>6.609</td>\n",
       "      <td>6.593</td>\n",
       "      <td>6.585</td>\n",
       "      <td>6.567</td>\n",
       "      <td>6.552</td>\n",
       "      <td>6.538</td>\n",
       "      <td>6.528</td>\n",
       "      <td>6.510</td>\n",
       "      <td>6.497</td>\n",
       "      <td>6.478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val_loss_epoch_1  val_loss_epoch_2  val_loss_epoch_3  val_loss_epoch_4  \\\n",
       "count         10000.000         10000.000         10000.000         10000.000   \n",
       "mean             10.376            10.325            10.274            10.223   \n",
       "std               2.414             2.392             2.370             2.348   \n",
       "min               4.713             4.706             4.700             4.694   \n",
       "25%               8.616             8.576             8.544             8.509   \n",
       "50%              10.097            10.056            10.007             9.961   \n",
       "75%              11.863            11.789            11.720            11.657   \n",
       "max              21.523            21.407            21.292            21.177   \n",
       "\n",
       "       val_loss_epoch_5  val_loss_epoch_6  val_loss_epoch_7  val_loss_epoch_8  \\\n",
       "count         10000.000         10000.000         10000.000         10000.000   \n",
       "mean             10.171            10.118            10.065            10.010   \n",
       "std               2.326             2.303             2.280             2.256   \n",
       "min               4.688             4.682             4.676             4.670   \n",
       "25%               8.466             8.430             8.394             8.356   \n",
       "50%               9.914             9.864             9.815             9.756   \n",
       "75%              11.597            11.531            11.473            11.403   \n",
       "max              21.061            20.944            20.824            20.700   \n",
       "\n",
       "       val_loss_epoch_9  val_loss_epoch_10  ...  val_loss_epoch_191  \\\n",
       "count         10000.000          10000.000  ...           10000.000   \n",
       "mean              9.953              9.894  ...               4.396   \n",
       "std               2.232              2.206  ...               0.581   \n",
       "min               4.661              4.592  ...               2.360   \n",
       "25%               8.320              8.274  ...               4.000   \n",
       "50%               9.704              9.653  ...               4.373   \n",
       "75%              11.337             11.266  ...               4.785   \n",
       "max              20.571             20.438  ...               6.609   \n",
       "\n",
       "       val_loss_epoch_192  val_loss_epoch_193  val_loss_epoch_194  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                4.387               4.378               4.369   \n",
       "std                 0.580               0.579               0.578   \n",
       "min                 2.356               2.350               2.346   \n",
       "25%                 3.991               3.984               3.976   \n",
       "50%                 4.365               4.356               4.347   \n",
       "75%                 4.776               4.767               4.758   \n",
       "max                 6.593               6.585               6.567   \n",
       "\n",
       "       val_loss_epoch_195  val_loss_epoch_196  val_loss_epoch_197  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                4.360               4.351               4.342   \n",
       "std                 0.577               0.576               0.575   \n",
       "min                 2.342               2.337               2.332   \n",
       "25%                 3.967               3.958               3.951   \n",
       "50%                 4.338               4.329               4.320   \n",
       "75%                 4.748               4.740               4.730   \n",
       "max                 6.552               6.538               6.528   \n",
       "\n",
       "       val_loss_epoch_198  val_loss_epoch_199  val_loss_epoch_200  \n",
       "count           10000.000           10000.000           10000.000  \n",
       "mean                4.333               4.324               4.315  \n",
       "std                 0.574               0.573               0.572  \n",
       "min                 2.326               2.323               2.320  \n",
       "25%                 3.943               3.935               3.926  \n",
       "50%                 4.311               4.302               4.293  \n",
       "75%                 4.721               4.710               4.700  \n",
       "max                 6.510               6.497               6.478  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:36.129028Z",
     "start_time": "2020-11-27T04:45:35.371683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_epoch_1</th>\n",
       "      <th>metric_epoch_2</th>\n",
       "      <th>metric_epoch_3</th>\n",
       "      <th>metric_epoch_4</th>\n",
       "      <th>metric_epoch_5</th>\n",
       "      <th>metric_epoch_6</th>\n",
       "      <th>metric_epoch_7</th>\n",
       "      <th>metric_epoch_8</th>\n",
       "      <th>metric_epoch_9</th>\n",
       "      <th>metric_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>metric_epoch_191</th>\n",
       "      <th>metric_epoch_192</th>\n",
       "      <th>metric_epoch_193</th>\n",
       "      <th>metric_epoch_194</th>\n",
       "      <th>metric_epoch_195</th>\n",
       "      <th>metric_epoch_196</th>\n",
       "      <th>metric_epoch_197</th>\n",
       "      <th>metric_epoch_198</th>\n",
       "      <th>metric_epoch_199</th>\n",
       "      <th>metric_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.170</td>\n",
       "      <td>1.144</td>\n",
       "      <td>1.146</td>\n",
       "      <td>1.168</td>\n",
       "      <td>1.248</td>\n",
       "      <td>1.279</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1.401</td>\n",
       "      <td>1.446</td>\n",
       "      <td>1.508</td>\n",
       "      <td>...</td>\n",
       "      <td>3.273</td>\n",
       "      <td>3.272</td>\n",
       "      <td>3.276</td>\n",
       "      <td>3.364</td>\n",
       "      <td>3.276</td>\n",
       "      <td>3.260</td>\n",
       "      <td>3.266</td>\n",
       "      <td>3.233</td>\n",
       "      <td>3.230</td>\n",
       "      <td>3.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.267</td>\n",
       "      <td>1.915</td>\n",
       "      <td>1.521</td>\n",
       "      <td>1.976</td>\n",
       "      <td>5.136</td>\n",
       "      <td>4.718</td>\n",
       "      <td>6.523</td>\n",
       "      <td>8.596</td>\n",
       "      <td>9.295</td>\n",
       "      <td>10.753</td>\n",
       "      <td>...</td>\n",
       "      <td>24.610</td>\n",
       "      <td>24.740</td>\n",
       "      <td>24.754</td>\n",
       "      <td>30.350</td>\n",
       "      <td>24.887</td>\n",
       "      <td>24.789</td>\n",
       "      <td>25.355</td>\n",
       "      <td>24.391</td>\n",
       "      <td>24.330</td>\n",
       "      <td>24.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.012</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.179</td>\n",
       "      <td>1.177</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.172</td>\n",
       "      <td>1.170</td>\n",
       "      <td>1.166</td>\n",
       "      <td>1.162</td>\n",
       "      <td>1.163</td>\n",
       "      <td>1.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.030</td>\n",
       "      <td>1.022</td>\n",
       "      <td>1.019</td>\n",
       "      <td>1.021</td>\n",
       "      <td>1.026</td>\n",
       "      <td>1.033</td>\n",
       "      <td>1.040</td>\n",
       "      <td>1.049</td>\n",
       "      <td>1.057</td>\n",
       "      <td>1.067</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597</td>\n",
       "      <td>1.596</td>\n",
       "      <td>1.590</td>\n",
       "      <td>1.590</td>\n",
       "      <td>1.585</td>\n",
       "      <td>1.583</td>\n",
       "      <td>1.580</td>\n",
       "      <td>1.574</td>\n",
       "      <td>1.570</td>\n",
       "      <td>1.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.070</td>\n",
       "      <td>1.064</td>\n",
       "      <td>1.067</td>\n",
       "      <td>1.076</td>\n",
       "      <td>1.090</td>\n",
       "      <td>1.108</td>\n",
       "      <td>1.128</td>\n",
       "      <td>1.149</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.195</td>\n",
       "      <td>...</td>\n",
       "      <td>2.310</td>\n",
       "      <td>2.296</td>\n",
       "      <td>2.299</td>\n",
       "      <td>2.291</td>\n",
       "      <td>2.285</td>\n",
       "      <td>2.292</td>\n",
       "      <td>2.278</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.271</td>\n",
       "      <td>2.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>234.138</td>\n",
       "      <td>135.536</td>\n",
       "      <td>91.074</td>\n",
       "      <td>146.388</td>\n",
       "      <td>432.000</td>\n",
       "      <td>351.570</td>\n",
       "      <td>545.626</td>\n",
       "      <td>593.450</td>\n",
       "      <td>741.305</td>\n",
       "      <td>858.381</td>\n",
       "      <td>...</td>\n",
       "      <td>1520.412</td>\n",
       "      <td>1550.325</td>\n",
       "      <td>1495.657</td>\n",
       "      <td>2018.983</td>\n",
       "      <td>1541.250</td>\n",
       "      <td>1608.500</td>\n",
       "      <td>1530.395</td>\n",
       "      <td>1569.302</td>\n",
       "      <td>1558.654</td>\n",
       "      <td>1670.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       metric_epoch_1  metric_epoch_2  metric_epoch_3  metric_epoch_4  \\\n",
       "count       10000.000       10000.000       10000.000       10000.000   \n",
       "mean            1.170           1.144           1.146           1.168   \n",
       "std             3.267           1.915           1.521           1.976   \n",
       "min             0.964           0.947           0.933           0.918   \n",
       "25%             1.012           1.005           1.001           0.999   \n",
       "50%             1.030           1.022           1.019           1.021   \n",
       "75%             1.070           1.064           1.067           1.076   \n",
       "max           234.138         135.536          91.074         146.388   \n",
       "\n",
       "       metric_epoch_5  metric_epoch_6  metric_epoch_7  metric_epoch_8  \\\n",
       "count       10000.000       10000.000       10000.000       10000.000   \n",
       "mean            1.248           1.279           1.335           1.401   \n",
       "std             5.136           4.718           6.523           8.596   \n",
       "min             0.907           0.894           0.877           0.858   \n",
       "25%             0.999           1.001           1.002           1.005   \n",
       "50%             1.026           1.033           1.040           1.049   \n",
       "75%             1.090           1.108           1.128           1.149   \n",
       "max           432.000         351.570         545.626         593.450   \n",
       "\n",
       "       metric_epoch_9  metric_epoch_10  ...  metric_epoch_191  \\\n",
       "count       10000.000        10000.000  ...         10000.000   \n",
       "mean            1.446            1.508  ...             3.273   \n",
       "std             9.295           10.753  ...            24.610   \n",
       "min             0.839            0.816  ...             0.212   \n",
       "25%             1.008            1.011  ...             1.179   \n",
       "50%             1.057            1.067  ...             1.597   \n",
       "75%             1.173            1.195  ...             2.310   \n",
       "max           741.305          858.381  ...          1520.412   \n",
       "\n",
       "       metric_epoch_192  metric_epoch_193  metric_epoch_194  metric_epoch_195  \\\n",
       "count         10000.000         10000.000         10000.000         10000.000   \n",
       "mean              3.272             3.276             3.364             3.276   \n",
       "std              24.740            24.754            30.350            24.887   \n",
       "min               0.211             0.214             0.212             0.211   \n",
       "25%               1.177             1.173             1.173             1.172   \n",
       "50%               1.596             1.590             1.590             1.585   \n",
       "75%               2.296             2.299             2.291             2.285   \n",
       "max            1550.325          1495.657          2018.983          1541.250   \n",
       "\n",
       "       metric_epoch_196  metric_epoch_197  metric_epoch_198  metric_epoch_199  \\\n",
       "count         10000.000         10000.000         10000.000         10000.000   \n",
       "mean              3.260             3.266             3.233             3.230   \n",
       "std              24.789            25.355            24.391            24.330   \n",
       "min               0.210             0.209             0.209             0.208   \n",
       "25%               1.170             1.166             1.162             1.163   \n",
       "50%               1.583             1.580             1.574             1.570   \n",
       "75%               2.292             2.278             2.269             2.271   \n",
       "max            1608.500          1530.395          1569.302          1558.654   \n",
       "\n",
       "       metric_epoch_200  \n",
       "count         10000.000  \n",
       "mean              3.232  \n",
       "std              24.955  \n",
       "min               0.208  \n",
       "25%               1.160  \n",
       "50%               1.572  \n",
       "75%               2.259  \n",
       "max            1670.714  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:36.892182Z",
     "start_time": "2020-11-27T04:45:36.131279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_metric_epoch_1</th>\n",
       "      <th>val_metric_epoch_2</th>\n",
       "      <th>val_metric_epoch_3</th>\n",
       "      <th>val_metric_epoch_4</th>\n",
       "      <th>val_metric_epoch_5</th>\n",
       "      <th>val_metric_epoch_6</th>\n",
       "      <th>val_metric_epoch_7</th>\n",
       "      <th>val_metric_epoch_8</th>\n",
       "      <th>val_metric_epoch_9</th>\n",
       "      <th>val_metric_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>val_metric_epoch_191</th>\n",
       "      <th>val_metric_epoch_192</th>\n",
       "      <th>val_metric_epoch_193</th>\n",
       "      <th>val_metric_epoch_194</th>\n",
       "      <th>val_metric_epoch_195</th>\n",
       "      <th>val_metric_epoch_196</th>\n",
       "      <th>val_metric_epoch_197</th>\n",
       "      <th>val_metric_epoch_198</th>\n",
       "      <th>val_metric_epoch_199</th>\n",
       "      <th>val_metric_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.159</td>\n",
       "      <td>1.164</td>\n",
       "      <td>1.181</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.236</td>\n",
       "      <td>1.279</td>\n",
       "      <td>1.329</td>\n",
       "      <td>1.380</td>\n",
       "      <td>1.434</td>\n",
       "      <td>1.489</td>\n",
       "      <td>...</td>\n",
       "      <td>3.970</td>\n",
       "      <td>3.956</td>\n",
       "      <td>3.948</td>\n",
       "      <td>3.936</td>\n",
       "      <td>3.924</td>\n",
       "      <td>3.914</td>\n",
       "      <td>3.902</td>\n",
       "      <td>3.889</td>\n",
       "      <td>3.876</td>\n",
       "      <td>3.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.797</td>\n",
       "      <td>2.517</td>\n",
       "      <td>2.560</td>\n",
       "      <td>2.907</td>\n",
       "      <td>3.456</td>\n",
       "      <td>4.124</td>\n",
       "      <td>4.858</td>\n",
       "      <td>5.641</td>\n",
       "      <td>6.459</td>\n",
       "      <td>7.318</td>\n",
       "      <td>...</td>\n",
       "      <td>68.494</td>\n",
       "      <td>68.074</td>\n",
       "      <td>68.022</td>\n",
       "      <td>67.737</td>\n",
       "      <td>67.456</td>\n",
       "      <td>67.171</td>\n",
       "      <td>66.715</td>\n",
       "      <td>66.478</td>\n",
       "      <td>66.108</td>\n",
       "      <td>65.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.001</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.989</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.007</td>\n",
       "      <td>1.007</td>\n",
       "      <td>1.004</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.014</td>\n",
       "      <td>1.009</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.009</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.016</td>\n",
       "      <td>1.021</td>\n",
       "      <td>1.026</td>\n",
       "      <td>1.032</td>\n",
       "      <td>1.039</td>\n",
       "      <td>...</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1.403</td>\n",
       "      <td>1.402</td>\n",
       "      <td>1.398</td>\n",
       "      <td>1.396</td>\n",
       "      <td>1.395</td>\n",
       "      <td>1.392</td>\n",
       "      <td>1.389</td>\n",
       "      <td>1.389</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.048</td>\n",
       "      <td>1.046</td>\n",
       "      <td>1.052</td>\n",
       "      <td>1.061</td>\n",
       "      <td>1.074</td>\n",
       "      <td>1.089</td>\n",
       "      <td>1.105</td>\n",
       "      <td>1.122</td>\n",
       "      <td>1.141</td>\n",
       "      <td>1.161</td>\n",
       "      <td>...</td>\n",
       "      <td>2.110</td>\n",
       "      <td>2.108</td>\n",
       "      <td>2.103</td>\n",
       "      <td>2.103</td>\n",
       "      <td>2.100</td>\n",
       "      <td>2.097</td>\n",
       "      <td>2.095</td>\n",
       "      <td>2.089</td>\n",
       "      <td>2.087</td>\n",
       "      <td>2.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>198.920</td>\n",
       "      <td>153.539</td>\n",
       "      <td>107.733</td>\n",
       "      <td>164.411</td>\n",
       "      <td>222.351</td>\n",
       "      <td>279.524</td>\n",
       "      <td>336.164</td>\n",
       "      <td>393.660</td>\n",
       "      <td>450.961</td>\n",
       "      <td>510.942</td>\n",
       "      <td>...</td>\n",
       "      <td>5929.676</td>\n",
       "      <td>5904.206</td>\n",
       "      <td>5911.400</td>\n",
       "      <td>5905.622</td>\n",
       "      <td>5887.156</td>\n",
       "      <td>5869.643</td>\n",
       "      <td>5832.383</td>\n",
       "      <td>5833.429</td>\n",
       "      <td>5812.672</td>\n",
       "      <td>5804.667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val_metric_epoch_1  val_metric_epoch_2  val_metric_epoch_3  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                1.159               1.164               1.181   \n",
       "std                 2.797               2.517               2.560   \n",
       "min                 0.944               0.928               0.912   \n",
       "25%                 1.001               0.995               0.992   \n",
       "50%                 1.014               1.009               1.008   \n",
       "75%                 1.048               1.046               1.052   \n",
       "max               198.920             153.539             107.733   \n",
       "\n",
       "       val_metric_epoch_4  val_metric_epoch_5  val_metric_epoch_6  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                1.206               1.236               1.279   \n",
       "std                 2.907               3.456               4.124   \n",
       "min                 0.894               0.878               0.862   \n",
       "25%                 0.990               0.989               0.988   \n",
       "50%                 1.009               1.012               1.016   \n",
       "75%                 1.061               1.074               1.089   \n",
       "max               164.411             222.351             279.524   \n",
       "\n",
       "       val_metric_epoch_7  val_metric_epoch_8  val_metric_epoch_9  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                1.329               1.380               1.434   \n",
       "std                 4.858               5.641               6.459   \n",
       "min                 0.845               0.825               0.803   \n",
       "25%                 0.988               0.988               0.988   \n",
       "50%                 1.021               1.026               1.032   \n",
       "75%                 1.105               1.122               1.141   \n",
       "max               336.164             393.660             450.961   \n",
       "\n",
       "       val_metric_epoch_10  ...  val_metric_epoch_191  val_metric_epoch_192  \\\n",
       "count            10000.000  ...             10000.000             10000.000   \n",
       "mean                 1.489  ...                 3.970                 3.956   \n",
       "std                  7.318  ...                68.494                68.074   \n",
       "min                  0.777  ...                 0.203                 0.202   \n",
       "25%                  0.989  ...                 1.012                 1.010   \n",
       "50%                  1.039  ...                 1.405                 1.403   \n",
       "75%                  1.161  ...                 2.110                 2.108   \n",
       "max                510.942  ...              5929.676              5904.206   \n",
       "\n",
       "       val_metric_epoch_193  val_metric_epoch_194  val_metric_epoch_195  \\\n",
       "count             10000.000             10000.000             10000.000   \n",
       "mean                  3.948                 3.936                 3.924   \n",
       "std                  68.022                67.737                67.456   \n",
       "min                   0.202                 0.202                 0.201   \n",
       "25%                   1.007                 1.007                 1.004   \n",
       "50%                   1.402                 1.398                 1.396   \n",
       "75%                   2.103                 2.103                 2.100   \n",
       "max                5911.400              5905.622              5887.156   \n",
       "\n",
       "       val_metric_epoch_196  val_metric_epoch_197  val_metric_epoch_198  \\\n",
       "count             10000.000             10000.000             10000.000   \n",
       "mean                  3.914                 3.902                 3.889   \n",
       "std                  67.171                66.715                66.478   \n",
       "min                   0.201                 0.201                 0.200   \n",
       "25%                   1.003                 1.001                 1.000   \n",
       "50%                   1.395                 1.392                 1.389   \n",
       "75%                   2.097                 2.095                 2.089   \n",
       "max                5869.643              5832.383              5833.429   \n",
       "\n",
       "       val_metric_epoch_199  val_metric_epoch_200  \n",
       "count             10000.000             10000.000  \n",
       "mean                  3.876                 3.867  \n",
       "std                  66.108                65.952  \n",
       "min                   0.198                 0.198  \n",
       "25%                   0.998                 0.996  \n",
       "50%                   1.389                 1.385  \n",
       "75%                   2.087                 2.084  \n",
       "max                5812.672              5804.667  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:38.725722Z",
     "start_time": "2020-11-27T04:45:36.894483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for metric\n",
    "path = './data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.png'\n",
    "\n",
    "adjustment_threshold_metric = 0#100\n",
    "    \n",
    "metric_df_adjusted = metric_df.copy(deep=True)\n",
    "if adjustment_threshold_metric > 0:\n",
    "    metric_df_adjusted[metric_df_adjusted.columns] = np.where(metric_df_adjusted[metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, metric_df_adjusted[metric_df_adjusted.columns])\n",
    "    \n",
    "val_metric_df_adjusted = val_metric_df.copy(deep=True)\n",
    "if adjustment_threshold_metric > 0:\n",
    "    val_metric_df_adjusted[val_metric_df_adjusted.columns] = np.where(val_metric_df_adjusted[val_metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, val_metric_df_adjusted[val_metric_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model metric')\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T04:45:40.507226Z",
     "start_time": "2020-11-27T04:45:38.727944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "path = './data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/loss_' + str(data_size) +  '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_amax_' + str(a_max) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.png'\n",
    "\n",
    "adjustment_threshold_loss = 0#10000\n",
    "    \n",
    "loss_df_adjusted = loss_df.copy(deep=True)\n",
    "\n",
    "if adjustment_threshold_loss > 0:\n",
    "    loss_df_adjusted[loss_df_adjusted.columns] = np.where(loss_df_adjusted[loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, loss_df_adjusted[loss_df_adjusted.columns])\n",
    "    \n",
    "val_loss_df_adjusted = val_loss_df.copy(deep=True)\n",
    "if adjustment_threshold_loss > 0:\n",
    "    val_loss_df_adjusted[val_loss_df_adjusted.columns] = np.where(val_loss_df_adjusted[val_loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, val_loss_df_adjusted[val_loss_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
