{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Î»-Nets for I-Net training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:45:56.909278Z",
     "start_time": "2020-12-29T14:45:56.905603Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def nCr(n,r):\n",
    "    f = math.factorial\n",
    "    return f(n) // f(r) // f(n-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:45:56.927922Z",
     "start_time": "2020-12-29T14:45:56.921934Z"
    }
   },
   "outputs": [],
   "source": [
    "d = 3\n",
    "n = 4\n",
    "sparsity = nCr(n+d, d)\n",
    "\n",
    "\n",
    "x_max = 1#10 #this number excluded\n",
    "x_min = -1#-10\n",
    "x_step = 0.01#0.1\n",
    "a_max = 10 #this number excluded\n",
    "a_min = -10\n",
    "a_step = 0.1\n",
    "\n",
    "lambda_dataset_size = 1000 #specify the number of data points to train the lambda net on for loading (must be same as in previous notebook)\n",
    "\n",
    "number_formulas_load = 500000 #manually specify number of formulas for loading file (must be the same as used in the previous notebook)\n",
    "number_of_lambda_nets = number_formulas_load #use this parameter to select how many lambda nets should be generated (must be smaller or equal to number_formulas_load)\n",
    "\n",
    "\n",
    "#lambda net specifications \n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "lambda_network_layers = [5*sparsity]\n",
    "dropout = 0.0\n",
    "optimizer='SGD' \n",
    "\n",
    "each_epochs_save = 10  #specifies the number of epochs to checkpoint lambda network weights, if None no checkpointing\n",
    "\n",
    "same_training_all_lambda_nets = False\n",
    "\n",
    "fixed_seed_lambda_training = False\n",
    "fixed_initialization_lambda_training = False\n",
    "number_different_lambda_trainings = 0\n",
    "\n",
    "n_jobs = -3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:45:56.938094Z",
     "start_time": "2020-12-29T14:45:56.930021Z"
    }
   },
   "outputs": [],
   "source": [
    "##############DO NOT CHANGE###################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "if each_epochs_save != None:\n",
    "    epochs_save_range = range(1, epochs//each_epochs_save+1) if each_epochs_save == 1 else range(epochs//each_epochs_save+1)\n",
    "else:\n",
    "    epochs_save_range = None\n",
    "    \n",
    "layers_str = ''.join([str(neurons) + '-' for neurons in lambda_network_layers])\n",
    "\n",
    "advanced_metric_dataset_size = 10#200\n",
    "\n",
    "if same_training_all_lambda_nets:\n",
    "    training_string = '_same'\n",
    "else:\n",
    "    training_string = '_diverse'\n",
    "\n",
    "generate_subset = True if number_of_lambda_nets < number_formulas_load else False\n",
    "\n",
    "    \n",
    "if generate_subset:\n",
    "    data_size = number_of_lambda_nets\n",
    "else:\n",
    "    data_size = number_formulas_load\n",
    "\n",
    "if fixed_seed_lambda_training:\n",
    "    seed_shuffle_string = '_' + str(number_different_lambda_trainings) + '-FixedSeed'\n",
    "else:\n",
    "    seed_shuffle_string = '_NoFixedSeed'\n",
    "    \n",
    "if fixed_initialization_lambda_training:\n",
    "    seed_shuffle_string += '_' + str(number_different_lambda_trainings) + '-FixedEvaluation'\n",
    "else:\n",
    "    seed_shuffle_string += '_NoFixedEvaluation'\n",
    "    \n",
    "    \n",
    "use_gpu = False\n",
    "if use_gpu:\n",
    "    gpu_numbers = '0'\n",
    "else:\n",
    "    gpu_numbers = ''\n",
    "    \n",
    "structure = '_' + layers_str + str(epochs) + 'e' + str(batch_size) + 'b_' + optimizer \n",
    "    \n",
    "filename = seed_shuffle_string + '_' + str(RANDOM_SEED) + structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:46:01.466383Z",
     "start_time": "2020-12-29T14:45:56.940504Z"
    }
   },
   "outputs": [],
   "source": [
    "import ttg\n",
    "from itertools import product       # forms cartesian products\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from more_itertools import random_product \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import math\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "from IPython.display import Image\n",
    "\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import random \n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "#keras.backend.set_epsilon(10e-3)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:46:01.473152Z",
     "start_time": "2020-12-29T14:46:01.468723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:46:01.486730Z",
     "start_time": "2020-12-29T14:46:01.474758Z"
    }
   },
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s2, s3), (s4, s5), ...\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "def chunks(lst, chunksize):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), chunksize):\n",
    "        yield lst[i:i + chunksize]\n",
    "\n",
    "#test for exact equality\n",
    "def arreq_in_list(myarr, list_arrays):\n",
    "    return next((True for elem in list_arrays if np.array_equal(elem, myarr)), False)\n",
    "\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "\n",
    "ALPHABET = \\\n",
    "  \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "def encode (n):\n",
    "    try:\n",
    "        return ALPHABET [n]\n",
    "    except IndexError:\n",
    "        raise Exception (\"cannot encode: %s\" % n)\n",
    "        \n",
    "def dec_to_base (dec = 0, base = 16):\n",
    "    if dec < base:\n",
    "        return encode (dec)\n",
    "    else:\n",
    "        return dec_to_base (dec // base, base) + encode (dec % base)\n",
    "    \n",
    "    \n",
    "def mergeDict(dict1, dict2):\n",
    "    #Merge dictionaries and keep values of common keys in list\n",
    "    newDict = {**dict1, **dict2}\n",
    "    for key, value in newDict.items():\n",
    "        if key in dict1 and key in dict2:\n",
    "            if isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend(value)\n",
    "            elif isinstance(dict1[key], list) and not isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend([value])\n",
    "            elif not isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = [dict1[key]]\n",
    "                newDict[key].extend(value)\n",
    "            else:\n",
    "                newDict[key] = [dict1[key], value]\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss/Error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:46:01.494835Z",
     "start_time": "2020-12-29T14:46:01.488384Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def calcualate_function_value_with_X_data_entry(coefficient_list, X_data_entry):\n",
    "    \n",
    "    global list_of_monomial_identifiers\n",
    "     \n",
    "    result = 0    \n",
    "    for coefficient_value, coefficient_multipliers in zip(coefficient_list, list_of_monomial_identifiers):\n",
    "        partial_results = [X_data_value**int(coefficient_multiplier) for coefficient_multiplier, X_data_value in zip(coefficient_multipliers, X_data_entry)]\n",
    "        \n",
    "        result += coefficient_value * reduce(lambda x, y: x*y, partial_results)\n",
    "        \n",
    "    return result, np.append(X_data_entry, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:46:01.520163Z",
     "start_time": "2020-12-29T14:46:01.496584Z"
    },
    "code_folding": [
     0,
     20,
     43,
     66,
     88,
     91,
     103
    ]
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "        \n",
    "    if tf.is_tensor(y_true):\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    else:\n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    if tf.is_tensor(y_pred):\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "    else:\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "            \n",
    "            \n",
    "    return tf.math.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "def accuracy_multilabel(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    if 'float' in str(y_true[0].dtype):        \n",
    "        if tf.is_tensor(y_true):\n",
    "            y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "        else:\n",
    "            y_true = y_true.astype('float32')\n",
    "        if tf.is_tensor(y_pred):\n",
    "            y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        else:\n",
    "            y_pred = y_pred.astype('float32')\n",
    "            \n",
    "        n_digits = int(-np.log10(a_step))\n",
    "        \n",
    "        y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "        y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(tf.reduce_all(K.equal(y_true, y_pred), axis=1), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def accuracy_single(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    if 'float' in str(y_true[0].dtype):        \n",
    "        if tf.is_tensor(y_true):\n",
    "            y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "        else:\n",
    "            y_true = y_true.astype('float32')\n",
    "        if tf.is_tensor(y_pred):\n",
    "            y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        else:\n",
    "            y_pred = y_pred.astype('float32')\n",
    "            \n",
    "        n_digits = int(-np.log10(a_step))\n",
    "        \n",
    "        y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "        y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(K.equal(y_true, y_pred), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def mean_absolute_percentage_error_keras(y_true, y_pred, epsilon=10e-3): \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values    \n",
    "        \n",
    "    if tf.is_tensor(y_true):\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    else:\n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    if tf.is_tensor(y_pred):\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "    else:\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        \n",
    "    epsilon = tf.convert_to_tensor(epsilon)\n",
    "    epsilon = tf.dtypes.cast(epsilon, tf.float32)\n",
    "        \n",
    "    return tf.reduce_mean(tf.abs(tf.divide(tf.subtract(y_pred, y_true),(y_true + epsilon))))\n",
    "\n",
    "def huber_loss_delta_set(y_true, y_pred):\n",
    "    return keras.losses.huber_loss(y_true, y_pred, delta=0.3)\n",
    "\n",
    "def relative_absolute_average_error(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "       \n",
    "    #error value calculation    \n",
    "    result = np.sum(np.abs(y_true-y_pred))/(y_true.shape[0]*np.std(y_true)) #correct STD?\n",
    "    \n",
    "    return result\n",
    "\n",
    "def relative_maximum_average_error(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    #error value calculation    \n",
    "    result = np.max(y_true-y_pred)/np.std(y_true) #correct STD?\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of Monomial Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:46:01.573582Z",
     "start_time": "2020-12-29T14:46:01.522430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065c7af59b64400db98cda24dc501a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 256\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0013', '0020', '0021', '0022', '0023', '0030', '0031', '0032', '0033', '0100', '0101', '0102', '0103', '0110', '0111', '0112', '0113', '0120', '0121', '0122', '0123', '0130', '0131', '0132', '0133', '0200', '0201', '0202', '0203', '0210', '0211', '0212', '0213', '0220', '0221', '0222', '0223', '0230', '0231', '0232', '0233', '0300', '0301', '0302', '0303', '0310', '0311', '0312', '0313', '0320', '0321', '0322', '0323', '0330', '0331', '0332', '0333', '1000', '1001', '1002', '1003', '1010', '1011', '1012', '1013', '1020', '1021', '1022', '1023', '1030', '1031', '1032', '1033', '1100', '1101', '1102', '1103', '1110', '1111', '1112', '1113', '1120', '1121', '1122', '1123', '1130', '1131', '1132', '1133', '1200', '1201', '1202', '1203', '1210', '1211', '1212', '1213', '1220', '1221', '1222', '1223', '1230', '1231', '1232', '1233', '1300', '1301', '1302', '1303', '1310', '1311', '1312', '1313', '1320', '1321', '1322', '1323', '1330', '1331', '1332', '1333', '2000', '2001', '2002', '2003', '2010', '2011', '2012', '2013', '2020', '2021', '2022', '2023', '2030', '2031', '2032', '2033', '2100', '2101', '2102', '2103', '2110', '2111', '2112', '2113', '2120', '2121', '2122', '2123', '2130', '2131', '2132', '2133', '2200', '2201', '2202', '2203', '2210', '2211', '2212', '2213', '2220', '2221', '2222', '2223', '2230', '2231', '2232', '2233', '2300', '2301', '2302', '2303', '2310', '2311', '2312', '2313', '2320', '2321', '2322', '2323', '2330', '2331', '2332', '2333', '3000', '3001', '3002', '3003', '3010', '3011', '3012', '3013', '3020', '3021', '3022', '3023', '3030', '3031', '3032', '3033', '3100', '3101', '3102', '3103', '3110', '3111', '3112', '3113', '3120', '3121', '3122', '3123', '3130', '3131', '3132', '3133', '3200', '3201', '3202', '3203', '3210', '3211', '3212', '3213', '3220', '3221', '3222', '3223', '3230', '3231', '3232', '3233', '3300', '3301', '3302', '3303', '3310', '3311', '3312', '3313', '3320', '3321', '3322', '3323', '3330', '3331', '3332', '3333']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01d064102b649ee872b663edeeed551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 35\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0020', '0021', '0030', '0100', '0101', '0102', '0110', '0111', '0120', '0200', '0201', '0210', '0300', '1000', '1001', '1002', '1010', '1011', '1020', '1100', '1101', '1110', '1200', '2000', '2001', '2010', '2100', '3000']\n"
     ]
    }
   ],
   "source": [
    "list_of_monomial_identifiers_extended = []\n",
    "for i in tqdm(range((d+1)**n)):    \n",
    "    monomial_identifier = dec_to_base(i, base = (d+1)).zfill(n) \n",
    "    list_of_monomial_identifiers_extended.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers_extended)\n",
    "\n",
    "list_of_monomial_identifiers = []\n",
    "for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "    monomial_identifier_values = list(map(int, list(monomial_identifier)))\n",
    "    if sum(monomial_identifier_values) <= d:\n",
    "        list_of_monomial_identifiers.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.156849Z",
     "start_time": "2020-12-29T14:46:01.575514Z"
    }
   },
   "outputs": [],
   "source": [
    "path_polynomials = './data/saved_polynomial_lists/polynomials_sample' + str(number_formulas_load) + '_variables_' + str(n) +  '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step) + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '.csv'\n",
    "polynomials_list_df = pd.read_csv(path_polynomials)\n",
    "\n",
    "path_X_data = './data/saved_polynomial_lists/X_sample' + str(number_formulas_load) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) +  training_string + '.pkl'\n",
    "with open(path_X_data, 'rb') as f:\n",
    "    X_data_list = pickle.load(f)\n",
    "    \n",
    "path_y_data = './data/saved_polynomial_lists/y_sample' + str(number_formulas_load) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) +  training_string + '.pkl'\n",
    "with open(path_y_data, 'rb') as f:\n",
    "    y_data_list = pickle.load(f)\n",
    "    \n",
    "if generate_subset:\n",
    "    polynomials_list_df = polynomials_list_df.sample(n=number_of_lambda_nets, random_state=RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    X_data_list = random.sample(X_data_list, number_of_lambda_nets)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    y_data_list = random.sample(y_data_list, number_of_lambda_nets)\n",
    "    random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.257077Z",
     "start_time": "2020-12-29T14:47:54.178975Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#clear files\n",
    "if each_epochs_save != None:\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        \n",
    "        for i in epochs_save_range:\n",
    "            index = i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "            path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size)  + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(index).zfill(3)  + filename + '.txt'\n",
    "\n",
    "            with open(path, 'wt') as text_file:\n",
    "                text_file.truncate()   \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "else:\n",
    "    \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "\n",
    "        path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "        with open(path, 'wt') as text_file:\n",
    "            text_file.truncate()   \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.277868Z",
     "start_time": "2020-12-29T14:47:54.258581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.160</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>0.720</td>\n",
       "      <td>-0.590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3\n",
       "0  0.660  0.850  0.690  0.240\n",
       "1 -0.270  0.270 -0.280  0.630\n",
       "2 -0.160  0.810  0.600 -0.660\n",
       "3  0.100 -0.640  0.910  0.090\n",
       "4 -0.200 -0.570  0.720 -0.590"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.286337Z",
     "start_time": "2020-12-29T14:47:54.279279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.770</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.450</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1      2      3\n",
       "0  0.550 0.750  0.250 -0.070\n",
       "1  0.910 0.960  0.810  0.670\n",
       "2 -0.320 0.380  0.380  0.610\n",
       "3  0.830 0.770 -0.700 -0.850\n",
       "4 -0.240 0.450 -0.050  0.930"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[1][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.292130Z",
     "start_time": "2020-12-29T14:47:54.287765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000    6.300\n",
       "0001   -7.200\n",
       "0002   -9.400\n",
       "0003    8.900\n",
       "0010   -3.000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.297630Z",
     "start_time": "2020-12-29T14:47:54.293542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000   -9.900\n",
       "0001    9.400\n",
       "0002   -6.000\n",
       "0003    7.800\n",
       "0010    0.800\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[1][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T17:06:36.919643Z",
     "start_time": "2020-09-16T17:06:36.912904Z"
    }
   },
   "source": [
    "## Lambda Network Training + Weigh/Bias saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.324117Z",
     "start_time": "2020-12-29T14:47:54.299344Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate_lambda_net(identifier, \n",
    "                        X_data_real_lambda, \n",
    "                        y_data_real_lambda, \n",
    "                        y_data_pred_lambda, \n",
    "                        y_data_pred_lambda_poly_lstsq, \n",
    "                        y_data_real_lambda_poly_lstsq):\n",
    "    \n",
    "    mae_real_VS_predLambda = np.round(mean_absolute_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    mae_real_VS_predPolyLstsq = np.round(mean_absolute_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    mae_predLambda_VS_predPolyLstsq = np.round(mean_absolute_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    mae_real_VS_realPolyLstsq = np.round(mean_absolute_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)    \n",
    "\n",
    "    rmse_real_VS_predLambda = np.round(root_mean_squared_error(y_data_real_lambda, y_data_pred_lambda), 4)    \n",
    "    rmse_real_VS_predPolyLstsq = np.round(root_mean_squared_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)    \n",
    "    rmse_predLambda_VS_predPolyLstsq = np.round(root_mean_squared_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)    \n",
    "    rmse_real_VS_realPolyLstsq = np.round(root_mean_squared_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)    \n",
    "\n",
    "    mape_real_VS_predLambda = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_pred_lambda), 4)    \n",
    "    mape_real_VS_predPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)    \n",
    "    mape_predLambda_VS_predPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)    \n",
    "    mape_real_VS_realPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)            \n",
    "\n",
    "    r2_real_VS_predLambda = np.round(r2_score(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    r2_real_VS_predPolyLstsq = np.round(r2_score(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    r2_predLambda_VS_predPolyLstsq = np.round(r2_score(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    r2_real_VS_realPolyLstsq = np.round(r2_score(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    raae_real_VS_predLambda = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    raae_real_VS_predPolyLstsq = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    raae_predLambda_VS_predPolyLstsq = np.round(relative_absolute_average_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    raae_real_VS_realPolyLstsq = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    rmae_real_VS_predLambda = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    rmae_real_VS_predPolyLstsq = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    rmae_predLambda_VS_predPolyLstsq = np.round(relative_maximum_average_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    rmae_real_VS_realPolyLstsq = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "        \n",
    "    std_data_real_lambda = np.round(np.std(y_data_real_lambda), 4) \n",
    "    std_data_pred_lambda = np.round(np.std(y_data_pred_lambda), 4) \n",
    "    std_data_pred_lambda_poly_lstsq = np.round(np.std(y_data_pred_lambda_poly_lstsq), 4) \n",
    "    std_data_real_lambda_poly_lstsq = np.round(np.std(y_data_real_lambda_poly_lstsq), 4) \n",
    "\n",
    "    mean_data_real_lambda = np.round(np.mean(y_data_real_lambda), 4) \n",
    "    mean_data_pred_lambda = np.round(np.mean(y_data_pred_lambda), 4) \n",
    "    mean_data_pred_lambda_poly_lstsq = np.round(np.mean(y_data_pred_lambda_poly_lstsq), 4) \n",
    "    mean_data_real_lambda_poly_lstsq = np.round(np.mean(y_data_real_lambda_poly_lstsq), 4) \n",
    "\n",
    "    return [{\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': mae_real_VS_predLambda,\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': mae_real_VS_predPolyLstsq,\n",
    "             'MAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': mae_predLambda_VS_predPolyLstsq,\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': mae_real_VS_realPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': rmse_real_VS_predLambda,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': rmse_real_VS_predPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': rmse_predLambda_VS_predPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': rmse_real_VS_realPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': mape_real_VS_predLambda,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': mape_real_VS_predPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': mape_predLambda_VS_predPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': mape_real_VS_realPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': r2_real_VS_predLambda,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': r2_real_VS_predPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': r2_predLambda_VS_predPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': r2_real_VS_realPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': raae_real_VS_predLambda,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': raae_real_VS_predPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': raae_predLambda_VS_predPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': raae_real_VS_realPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': rmae_real_VS_predLambda,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': rmae_real_VS_predPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': rmae_predLambda_VS_predPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': rmae_real_VS_realPolyLstsq,\n",
    "            },\n",
    "            {\n",
    "             'STD FV ' + identifier + ' REAL LAMBDA': std_data_real_lambda,\n",
    "             'STD FV ' + identifier + ' PRED LAMBDA': std_data_pred_lambda, \n",
    "             'STD FV ' + identifier + ' PRED LAMBDA POLY LSTSQ': std_data_pred_lambda_poly_lstsq, \n",
    "             'STD FV ' + identifier + ' REAL LAMBDA POLY LSTSQ': std_data_real_lambda_poly_lstsq, \n",
    "            },\n",
    "            {\n",
    "             'MEAN FV ' + identifier + ' REAL LAMBDA': mean_data_real_lambda,\n",
    "             'MEAN FV ' + identifier + ' PRED LAMBDA': mean_data_pred_lambda, \n",
    "             'MEAN FV ' + identifier + ' PRED LAMBDA POLY LSTSQ': mean_data_pred_lambda_poly_lstsq, \n",
    "             'MEAN FV ' + identifier + ' REAL LAMBDA POLY LSTSQ': mean_data_real_lambda_poly_lstsq, \n",
    "            }]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.330591Z",
     "start_time": "2020-12-29T14:47:54.325546Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_function_values_from_polynomial(X_data, polynomial):\n",
    "    function_value_list = []\n",
    "    for entry in X_data:\n",
    "        function_value, _ = calcualate_function_value_with_X_data_entry(polynomial, entry)\n",
    "        function_value_list.append(function_value)\n",
    "    function_value_array = np.array(function_value_list).reshape(len(function_value_list), 1)     \n",
    "\n",
    "    return function_value_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.336894Z",
     "start_time": "2020-12-29T14:47:54.332015Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_term_matric_for_lstsq(X_data, polynomial_indices):\n",
    "    term_list_all = []\n",
    "    y = 0\n",
    "    for term in list(polynomial_indices):\n",
    "        term_list = [int(value_mult) for value_mult in term]\n",
    "        term_list_all.append(term_list)\n",
    "    terms_matrix = []\n",
    "    for unknowns in X_data:\n",
    "        terms = []\n",
    "        for term_multipliers in term_list_all:\n",
    "            term_value = prod([unknown**multiplier for unknown, multiplier in zip(unknowns, term_multipliers)])\n",
    "            terms.append(term_value)\n",
    "        terms_matrix.append(np.array(terms))\n",
    "    terms_matrix = np.array(terms_matrix)\n",
    "    \n",
    "    return terms_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T14:47:54.388380Z",
     "start_time": "2020-12-29T14:47:54.338420Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_nn(lambda_index, X_data_lambda, y_data_real_lambda, polynomial, seed_list, callbacks=None, return_history=False, each_epochs_save=None, printing=False, return_model=False):\n",
    "    \n",
    "    current_seed = seed_list[lambda_index%number_different_lambda_trainings]\n",
    "    \n",
    "    if fixed_seed_lambda_training:\n",
    "        random.seed(current_seed)\n",
    "        np.random.seed(current_seed)\n",
    "        if int(tf.__version__[0]) >= 2:\n",
    "            tf.random.set_seed(current_seed)\n",
    "        else:\n",
    "            tf.set_random_seed(current_seed) \n",
    "        \n",
    "    if isinstance(X_data_lambda, pd.DataFrame):\n",
    "        X_data_lambda = X_data_lambda.values\n",
    "    if isinstance(y_data_real_lambda, pd.DataFrame):\n",
    "        y_data_real_lambda = y_data_real_lambda.values\n",
    "                \n",
    "    X_train_lambda_with_valid, X_test_lambda, y_train_real_lambda_with_valid, y_test_real_lambda = train_test_split(X_data_lambda, y_data_real_lambda, test_size=0.25, random_state=current_seed)           \n",
    "    X_train_lambda, X_valid_lambda, y_train_real_lambda, y_valid_real_lambda = train_test_split(X_train_lambda_with_valid, y_train_real_lambda_with_valid, test_size=0.25, random_state=current_seed)           \n",
    "     \n",
    "        \n",
    "    model = Sequential()\n",
    "    \n",
    "    #kerase defaults: kernel_initializer='glorot_uniform', bias_initializer='zeros'               \n",
    "    if fixed_initialization_lambda_training:\n",
    "        model.add(Dense(lambda_network_layers[0], activation='relu', input_dim=X_data_lambda.shape[1], kernel_initializer=tf.keras.initializers.GlorotUniform(seed=current_seed), bias_initializer='zeros')) #1024\n",
    "    else:\n",
    "        model.add(Dense(lambda_network_layers[0], activation='relu', input_dim=X_data_lambda.shape[1])) #1024\n",
    "        \n",
    "    if dropout > 0:\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    for neurons in lambda_network_layers[1:]:\n",
    "        if fixed_initialization_lambda_training:\n",
    "            model.add(Dense(neurons, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=current_seed), bias_initializer='zeros'))\n",
    "        else:\n",
    "            model.add(Dense(neurons, activation='relu'))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(dropout))   \n",
    "    \n",
    "    if fixed_initialization_lambda_training:\n",
    "        model.add(Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=current_seed), bias_initializer='zeros'))\n",
    "    else:\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=[mean_absolute_percentage_error_keras, root_mean_squared_error]\n",
    "                 )\n",
    "    \n",
    "    \n",
    "    weights = []\n",
    "    polynomial_lstsq_pred_list = []\n",
    "    polynomial_lstsq_true_list = []\n",
    "\n",
    "     \n",
    "    if each_epochs_save == None:   \n",
    "        model_history = model.fit(X_train_lambda, \n",
    "                      y_train_real_lambda, \n",
    "                      epochs=epochs, \n",
    "                      batch_size=batch_size, \n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=(X_valid_lambda, y_valid_real_lambda),\n",
    "                      verbose=0,\n",
    "                      workers=0)\n",
    "        weights.append(model.get_weights())\n",
    "        \n",
    "        history = model_history.history\n",
    "        \n",
    "        y_train_pred_lambda = model.predict(X_train_lambda) \n",
    "        y_valid_pred_lambda = model.predict(X_valid_lambda)                \n",
    "        y_test_pred_lambda = model.predict(X_test_lambda)\n",
    "    \n",
    "        terms_matrix = generate_term_matric_for_lstsq(X_train_lambda, list(polynomial.index))\n",
    "                \n",
    "        polynomial_lstsq_pred, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_pred_lambda.ravel(), rcond=-1)#[::-1]\n",
    "        polynomial_lstsq_true, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_real_lambda.ravel(), rcond=-1)#[::-1] \n",
    "        polynomial_lstsq_pred_list.append(polynomial_lstsq_pred)\n",
    "        polynomial_lstsq_true_list.append(polynomial_lstsq_true)\n",
    "        \n",
    "        y_train_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_pred)\n",
    "        y_train_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_true)\n",
    "        y_valid_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_pred)\n",
    "        y_valid_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_true)    \n",
    "        y_test_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_pred)\n",
    "        y_test_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_true)  \n",
    "        \n",
    "        pred_list = (lambda_index,\n",
    "                     y_train_real_lambda, \n",
    "                     y_train_pred_lambda, \n",
    "                     y_train_pred_lambda_poly_lstsq,\n",
    "                     #y_train_real_lambda_poly_lstsq,\n",
    "                     X_train_lambda, \n",
    "                     y_valid_real_lambda,\n",
    "                     y_valid_pred_lambda, \n",
    "                     y_valid_pred_lambda_poly_lstsq,\n",
    "                     #y_valid_real_lambda_poly_lstsq,\n",
    "                     X_valid_lambda, \n",
    "                     y_test_real_lambda, \n",
    "                     y_test_pred_lambda, \n",
    "                     y_test_pred_lambda_poly_lstsq, \n",
    "                     #y_test_real_lambda_poly_lstsq,\n",
    "                     X_test_lambda)\n",
    "\n",
    "        scores_train, std_train, mean_train = evaluate_lambda_net('TRAIN', X_train_lambda, y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, y_train_real_lambda_poly_lstsq)\n",
    "        scores_valid, std_valid, mean_valid = evaluate_lambda_net('VALID', X_valid_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, y_valid_real_lambda_poly_lstsq)\n",
    "        scores_test, std_test, mean_test = evaluate_lambda_net('TEST', X_test_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, y_test_real_lambda_poly_lstsq)\n",
    "\n",
    "        scores_std = {}\n",
    "        for aDict in (std_train, std_valid, std_test):\n",
    "            scores_std.update(aDict)      \n",
    "        scores_mean = {}\n",
    "        for aDict in (mean_train, mean_valid, mean_test):\n",
    "            scores_mean.update(aDict)\n",
    "        \n",
    "        scores_list = [lambda_index,\n",
    "                     scores_train,\n",
    "                     scores_valid,\n",
    "                     scores_test,\n",
    "                     scores_std,\n",
    "                     scores_mean]            \n",
    "                            \n",
    "    else:\n",
    "        scores_list = []\n",
    "        pred_list = []\n",
    "        for i in epochs_save_range:\n",
    "            train_epochs_step = each_epochs_save if i > 1 else max(each_epochs_save-1, 1) if i==1 else 1\n",
    "            \n",
    "            model_history = model.fit(X_train_lambda, \n",
    "                      y_train_real_lambda, \n",
    "                      epochs=train_epochs_step, \n",
    "                      batch_size=batch_size, \n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=(X_valid_lambda, y_valid_real_lambda),\n",
    "                      verbose=0,\n",
    "                      workers=1,\n",
    "                      use_multiprocessing=False)\n",
    "            \n",
    "            #history adjustment for continuing training\n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                history = model_history.history\n",
    "            else:\n",
    "                history = mergeDict(history, model_history.history)\n",
    "\n",
    "            weights.append(model.get_weights())\n",
    "            \n",
    "            y_train_pred_lambda = model.predict(X_train_lambda)                \n",
    "            y_valid_pred_lambda = model.predict(X_valid_lambda)                \n",
    "            y_test_pred_lambda = model.predict(X_test_lambda)        \n",
    "\n",
    "            terms_matrix = generate_term_matric_for_lstsq(X_train_lambda, list(polynomial.index))\n",
    "                        \n",
    "            polynomial_lstsq_pred, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_pred_lambda.ravel(), rcond=-1)#[::-1] \n",
    "            #does not change over time\n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                polynomial_lstsq_true, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_real_lambda.ravel(), rcond=-1)#[::-1] \n",
    "            polynomial_lstsq_pred_list.append(polynomial_lstsq_pred)\n",
    "            polynomial_lstsq_true_list.append(polynomial_lstsq_true)            \n",
    "\n",
    "            \n",
    "            y_train_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_pred)\n",
    "            y_valid_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_pred)\n",
    "            y_test_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_pred)           \n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                y_train_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_true)\n",
    "                y_valid_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_true)  \n",
    "                y_test_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_true)                    \n",
    "                \n",
    "            pred_list.append((lambda_index,\n",
    "                              y_train_real_lambda, \n",
    "                              y_train_pred_lambda, \n",
    "                              y_train_pred_lambda_poly_lstsq,\n",
    "                              #y_train_real_lambda_poly_lstsq,\n",
    "                              X_train_lambda, \n",
    "                              y_valid_real_lambda,\n",
    "                              y_valid_pred_lambda, \n",
    "                              y_valid_pred_lambda_poly_lstsq,\n",
    "                              #y_valid_real_lambda_poly_lstsq,\n",
    "                              X_valid_lambda, \n",
    "                              y_test_real_lambda, \n",
    "                              y_test_pred_lambda, \n",
    "                              y_test_pred_lambda_poly_lstsq, \n",
    "                              #y_test_real_lambda_poly_lstsq,\n",
    "                              X_test_lambda))\n",
    "    \n",
    "            scores_train, std_train, mean_train = evaluate_lambda_net('TRAIN', X_train_lambda, y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, y_train_real_lambda_poly_lstsq)\n",
    "            scores_valid, std_valid, mean_valid = evaluate_lambda_net('VALID', X_valid_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, y_valid_real_lambda_poly_lstsq)\n",
    "            scores_test, std_test, mean_test = evaluate_lambda_net('TEST', X_test_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, y_test_real_lambda_poly_lstsq)\n",
    "\n",
    "            scores_std = {}\n",
    "            for aDict in (std_train, std_valid, std_test):\n",
    "                scores_std.update(aDict)\n",
    "            scores_mean = {}\n",
    "            for aDict in (mean_train, mean_valid, mean_test):\n",
    "                scores_mean.update(aDict)\n",
    "\n",
    "            scores_list_single_epoch =  [lambda_index,\n",
    "                                         scores_train,\n",
    "                                          scores_valid,\n",
    "                                          scores_test,\n",
    "                                          scores_std,\n",
    "                                          scores_mean]        \n",
    "                  \n",
    "            scores_list.append(scores_list_single_epoch)\n",
    "       \n",
    "\n",
    "        \n",
    "    if printing:        \n",
    "        for i, (weights_for_epoch, polynomial_lstsq_pred_for_epoch, polynomial_lstsq_true_for_epoch) in enumerate(zip(weights, polynomial_lstsq_pred_list, polynomial_lstsq_true_list)):        \n",
    "            if each_epochs_save == None:\n",
    "                path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "            else:\n",
    "                index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "                path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(index).zfill(3)  + filename + '.txt'\n",
    "            with open(path, 'a') as text_file: \n",
    "                text_file.write(str(lambda_index))\n",
    "                text_file.write(', ' + str(current_seed))\n",
    "                for i, value in enumerate(polynomial.values): \n",
    "                    text_file.write(', ' + str(value))   \n",
    "                for value in polynomial_lstsq_pred_for_epoch:\n",
    "                    text_file.write(', ' + str(value))\n",
    "                for value in polynomial_lstsq_true_for_epoch:\n",
    "                    text_file.write(', ' + str(value))\n",
    "                for layer_weights, biases in pairwise(weights_for_epoch):    #clf.get_weights()\n",
    "                    for neuron in layer_weights:\n",
    "                        for weight in neuron:\n",
    "                            text_file.write(', ' + str(weight))\n",
    "                    for bias in biases:\n",
    "                        text_file.write(', ' + str(bias))\n",
    "                text_file.write('\\n')\n",
    "\n",
    "        text_file.close() \n",
    "\n",
    "        directory = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/'\n",
    "        path = directory + 'lambda_' + str(lambda_index) + '_test_data'\n",
    "        np.save(path, X_test_lambda)\n",
    "            \n",
    "    if return_model:\n",
    "        return (lambda_index, current_seed, polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list, history, model\n",
    "    elif return_history:\n",
    "        return (lambda_index, current_seed, polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list, history, #polynomial_lstsq_pred_list, polynomial_lstsq_true_list#, weights, history\n",
    "    else:\n",
    "        return (lambda_index, current_seed, polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list#, weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T18:59:40.569655Z",
     "start_time": "2020-12-29T14:47:54.389725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    3.808, max:   17.312, cur:    3.808)\n",
      "\tvalidation       \t (min:    4.520, max:   17.806, cur:    4.520)\n",
      "mean_absolute_percentage_error_keras\n",
      "\ttraining         \t (min:    0.677, max:    2.819, cur:    0.681)\n",
      "\tvalidation       \t (min:    1.002, max:    2.204, cur:    1.114)\n",
      "root_mean_squared_error\n",
      "\ttraining         \t (min:    5.170, max:   20.839, cur:    5.170)\n",
      "\tvalidation       \t (min:    5.947, max:   21.494, cur:    5.947)\n"
     ]
    }
   ],
   "source": [
    "clf_list = []\n",
    "chunksize = 1000 if data_size > 10000 else max(data_size//10, min(50, data_size))\n",
    "X_data_list_splits = list(chunks(X_data_list, chunksize))\n",
    "y_data_list_splits = list(chunks(y_data_list, chunksize))\n",
    "\n",
    "max_seed = 2**32 - 1\n",
    "seed_list = random.sample(range(0, max_seed), number_different_lambda_trainings)\n",
    "chunk_multiplier = 0\n",
    "\n",
    "for X_data_list_split, y_data_list_split in tqdm(zip(X_data_list_splits, y_data_list_splits), total=max(len(X_data_list_splits), len(y_data_list_splits))):\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    clf_sublist = parallel(delayed(train_nn)(chunksize*chunk_multiplier+index, X_data[1].values, y_data[1].values, X_data[0], seed_list, return_history=True, each_epochs_save=each_epochs_save, printing=True) for index, (X_data, y_data) in enumerate(zip(X_data_list_split, y_data_list_split)))  \n",
    "    clf_list.extend(clf_sublist)\n",
    "    del parallel\n",
    "    chunk_multiplier +=1\n",
    "rand_index = np.random.randint(data_size)\n",
    "random_network = train_nn(rand_index, X_data_list[rand_index][1], y_data_list[rand_index][1], X_data_list[rand_index][0], seed_list, callbacks=[PlotLossesKerasTF()], return_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Lambda-Model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:02:09.281050Z",
     "start_time": "2020-12-30T18:59:40.571757Z"
    }
   },
   "outputs": [],
   "source": [
    "if each_epochs_save == None:\n",
    "    scores_list_train = [clf[1][1] for clf in clf_list]\n",
    "    scores_list_valid = [clf[1][2] for clf in clf_list]\n",
    "    scores_list_test = [clf[1][3] for clf in clf_list]\n",
    "    scores_list_stds = [clf[1][4] for clf in clf_list]\n",
    "    scores_list_means = [clf[1][5] for clf in clf_list]\n",
    "\n",
    "    scores_list_train_mean = pd.DataFrame(scores_list_train, columns=scores_list_train[0].keys()).mean()\n",
    "    df_mean_scores_train = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED', 'TRAIN POLY', 'TRAIN POLY PRED', 'TRAIN LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV'])\n",
    "\n",
    "    scores_list_valid_mean = pd.DataFrame(scores_list_valid, columns=scores_list_valid[0].keys()).mean()\n",
    "    df_mean_scores_valid = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED', 'VALID POLY', 'VALID POLY PRED', 'VALID LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV'])\n",
    "\n",
    "    scores_list_test_mean = pd.DataFrame(scores_list_test, columns=scores_list_test[0].keys()).mean()\n",
    "    df_mean_scores_test = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED', 'TEST POLY', 'TEST POLY PRED', 'TEST LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV'])\n",
    "\n",
    "    stds_mean = pd.DataFrame(scores_list_stds, columns=scores_list_stds[0].keys()).mean()\n",
    "    df_stds = pd.DataFrame(stds_mean, columns=['0'], index=stds_mean.index)\n",
    "    \n",
    "    means_mean = pd.DataFrame(scores_list_means, columns=scores_list_means[0].keys()).mean()\n",
    "    df_means = pd.DataFrame(means_mean, columns=['0'], index=means_mean.index)\n",
    "    \n",
    "    path_scores_train = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_train_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_valid = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_valid_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_test = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_test_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_stds = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/stds_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_means = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/means_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "   \n",
    "    df_mean_scores_train.to_csv(path_scores_train, sep=',')\n",
    "    df_mean_scores_valid.to_csv(path_scores_valid, sep=',')\n",
    "    df_mean_scores_test.to_csv(path_scores_test, sep=',')\n",
    "    df_stds.to_csv(path_stds, sep=',')\n",
    "    df_means.to_csv(path_means, sep=',')\n",
    "else:\n",
    "    scores_list = [clf[1] for clf in clf_list]\n",
    "    \n",
    "    scores_list_by_epochs = [[] for i in epochs_save_range]\n",
    "    for scores_list in scores_list:   \n",
    "        for index, scores in enumerate(scores_list):\n",
    "            scores_list_by_epochs[index].append(scores)\n",
    "            \n",
    "        \n",
    "    for i, scores_list_single_epoch in enumerate(scores_list_by_epochs):\n",
    "        index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "           \n",
    "        scores_list_train = [scores_list[1] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_valid = [scores_list[2] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_test = [scores_list[3] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_stds = [scores_list[4] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_means = [scores_list[5] for scores_list in scores_list_single_epoch]\n",
    "        \n",
    "        scores_list_train_mean = pd.DataFrame(scores_list_train, columns=scores_list_train[0].keys()).mean()  \n",
    "        scores_list_valid_mean = pd.DataFrame(scores_list_valid, columns=scores_list_valid[0].keys()).mean()  \n",
    "        scores_list_test_mean = pd.DataFrame(scores_list_test, columns=scores_list_test[0].keys()).mean()\n",
    "        stds_mean = pd.DataFrame(scores_list_stds, columns=scores_list_stds[0].keys()).mean()\n",
    "        means_mean = pd.DataFrame(scores_list_means, columns=scores_list_means[0].keys()).mean()\n",
    "\n",
    "        if index == 1:\n",
    "            df_mean_scores_train = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED E' + str(index), 'TRAIN POLY E' + str(index), 'TRAIN POLY PRED E' + str(index), 'TRAIN LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV'])\n",
    "            df_mean_scores_valid = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index), 'VALID POLY PRED E' + str(index), 'VALID LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV'])\n",
    "            df_mean_scores_test = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index), 'TEST POLY PRED E' + str(index), 'TEST LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV'])\n",
    "            df_stds = pd.DataFrame(stds_mean, columns=['E' + str(index)], index=stds_mean.index)   \n",
    "            df_means = pd.DataFrame(means_mean, columns=['E' + str(index)], index=means_mean.index)   \n",
    "        else:\n",
    "            df_mean_scores_train_new = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED E' + str(index), 'TRAIN POLY E' + str(index), 'TRAIN POLY PRED E' + str(index), 'TRAIN LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV'])\n",
    "            df_mean_scores_train = pd.concat([df_mean_scores_train, df_mean_scores_train_new],axis=1)  \n",
    "            \n",
    "            df_mean_scores_valid_new = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index), 'VALID POLY PRED E' + str(index), 'VALID LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV'])\n",
    "            df_mean_scores_valid = pd.concat([df_mean_scores_valid, df_mean_scores_valid_new],axis=1)  \n",
    "\n",
    "            df_mean_scores_test_new = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index), 'TEST POLY PRED E' + str(index), 'TEST LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV'])\n",
    "            df_mean_scores_test = pd.concat([df_mean_scores_test, df_mean_scores_test_new],axis=1)  \n",
    "\n",
    "            df_stds_new = pd.DataFrame(stds_mean, columns=['E' + str(index)], index=stds_mean.index)\n",
    "            df_stds = pd.concat([df_stds, df_stds_new],axis=1)  \n",
    "            \n",
    "            df_means_new = pd.DataFrame(means_mean, columns=['E' + str(index)], index=means_mean.index)\n",
    "            df_means = pd.concat([df_means, df_means_new],axis=1)     \n",
    "\n",
    "    path_scores_train = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_train_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_valid = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_valid_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_test = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_test_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_stds = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/stds_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_means = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/means_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "    df_mean_scores_train.to_csv(path_scores_train, sep=',')\n",
    "    df_mean_scores_valid.to_csv(path_scores_valid, sep=',')\n",
    "    df_mean_scores_test.to_csv(path_scores_test, sep=',')\n",
    "    df_stds.to_csv(path_stds, sep=',')\n",
    "    df_means.to_csv(path_means, sep=',')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:02:09.305067Z",
     "start_time": "2020-12-30T19:02:09.283712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN PRED E1</th>\n",
       "      <th>TRAIN POLY E1</th>\n",
       "      <th>TRAIN POLY PRED E1</th>\n",
       "      <th>TRAIN LSTSQ E1</th>\n",
       "      <th>TRAIN PRED E10</th>\n",
       "      <th>TRAIN POLY E10</th>\n",
       "      <th>TRAIN POLY PRED E10</th>\n",
       "      <th>TRAIN LSTSQ E10</th>\n",
       "      <th>TRAIN PRED E20</th>\n",
       "      <th>TRAIN POLY E20</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAIN POLY PRED E180</th>\n",
       "      <th>TRAIN LSTSQ E180</th>\n",
       "      <th>TRAIN PRED E190</th>\n",
       "      <th>TRAIN POLY E190</th>\n",
       "      <th>TRAIN POLY PRED E190</th>\n",
       "      <th>TRAIN LSTSQ E190</th>\n",
       "      <th>TRAIN PRED E200</th>\n",
       "      <th>TRAIN POLY E200</th>\n",
       "      <th>TRAIN POLY PRED E200</th>\n",
       "      <th>TRAIN LSTSQ E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>10.185</td>\n",
       "      <td>10.185</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.684</td>\n",
       "      <td>9.684</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.877</td>\n",
       "      <td>8.879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.189</td>\n",
       "      <td>4.233</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.098</td>\n",
       "      <td>4.142</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>12.979</td>\n",
       "      <td>12.979</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.460</td>\n",
       "      <td>12.460</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.621</td>\n",
       "      <td>11.621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.927</td>\n",
       "      <td>5.900</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.812</td>\n",
       "      <td>5.781</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>1.088</td>\n",
       "      <td>1.086</td>\n",
       "      <td>1.369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.459</td>\n",
       "      <td>1.459</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.093</td>\n",
       "      <td>2.098</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.736</td>\n",
       "      <td>3.708</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.690</td>\n",
       "      <td>3.660</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>-0.411</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.972</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>3.461</td>\n",
       "      <td>3.461</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.432</td>\n",
       "      <td>3.432</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.379</td>\n",
       "      <td>3.379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.252</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.284</td>\n",
       "      <td>2.217</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRAIN PRED E1  TRAIN POLY E1  TRAIN POLY PRED E1  TRAIN LSTSQ E1  \\\n",
       "MAE FV          10.185         10.185               0.012           0.000   \n",
       "RMSE FV         12.979         12.979               0.015           0.000   \n",
       "MAPE FV          1.088          1.086               1.369           0.000   \n",
       "R2 FV           -0.411         -0.411               0.972           1.000   \n",
       "RAAE FV          0.921          0.921               0.128           0.000   \n",
       "RMAE FV          3.461          3.461               0.530           0.000   \n",
       "\n",
       "         TRAIN PRED E10  TRAIN POLY E10  TRAIN POLY PRED E10  TRAIN LSTSQ E10  \\\n",
       "MAE FV            9.684           9.684                0.014            0.000   \n",
       "RMSE FV          12.460          12.460                0.017            0.000   \n",
       "MAPE FV           1.459           1.459                0.196            0.000   \n",
       "R2 FV            -0.287          -0.287                0.994            1.000   \n",
       "RAAE FV           0.874           0.874                0.058            0.000   \n",
       "RMAE FV           3.432           3.432                0.264            0.000   \n",
       "\n",
       "         TRAIN PRED E20  TRAIN POLY E20  ...  TRAIN POLY PRED E180  \\\n",
       "MAE FV            8.877           8.879  ...                 0.386   \n",
       "RMSE FV          11.621          11.621  ...                 0.495   \n",
       "MAPE FV           2.093           2.098  ...                 1.340   \n",
       "R2 FV            -0.098          -0.098  ...                 0.995   \n",
       "RAAE FV           0.797           0.798  ...                 0.051   \n",
       "RMAE FV           3.379           3.379  ...                 0.247   \n",
       "\n",
       "         TRAIN LSTSQ E180  TRAIN PRED E190  TRAIN POLY E190  \\\n",
       "MAE FV              0.000            4.189            4.233   \n",
       "RMSE FV             0.000            5.927            5.900   \n",
       "MAPE FV             0.000            3.736            3.708   \n",
       "R2 FV               1.000            0.689            0.692   \n",
       "RAAE FV             0.000            0.387            0.391   \n",
       "RMAE FV             0.000            2.314            2.252   \n",
       "\n",
       "         TRAIN POLY PRED E190  TRAIN LSTSQ E190  TRAIN PRED E200  \\\n",
       "MAE FV                  0.413             0.000            4.098   \n",
       "RMSE FV                 0.528             0.000            5.812   \n",
       "MAPE FV                 0.694             0.000            3.690   \n",
       "R2 FV                   0.995             1.000            0.701   \n",
       "RAAE FV                 0.054             0.000            0.378   \n",
       "RMAE FV                 0.257             0.000            2.284   \n",
       "\n",
       "         TRAIN POLY E200  TRAIN POLY PRED E200  TRAIN LSTSQ E200  \n",
       "MAE FV             4.142                 0.439             0.000  \n",
       "RMSE FV            5.781                 0.561             0.000  \n",
       "MAPE FV            3.660                 0.712             0.000  \n",
       "R2 FV              0.704                 0.994             1.000  \n",
       "RAAE FV            0.383                 0.057             0.000  \n",
       "RMAE FV            2.217                 0.268             0.000  \n",
       "\n",
       "[6 rows x 84 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:02:09.324122Z",
     "start_time": "2020-12-30T19:02:09.306539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALID PRED E1</th>\n",
       "      <th>VALID POLY E1</th>\n",
       "      <th>VALID POLY PRED E1</th>\n",
       "      <th>VALID LSTSQ E1</th>\n",
       "      <th>VALID PRED E10</th>\n",
       "      <th>VALID POLY E10</th>\n",
       "      <th>VALID POLY PRED E10</th>\n",
       "      <th>VALID LSTSQ E10</th>\n",
       "      <th>VALID PRED E20</th>\n",
       "      <th>VALID POLY E20</th>\n",
       "      <th>...</th>\n",
       "      <th>VALID POLY PRED E180</th>\n",
       "      <th>VALID LSTSQ E180</th>\n",
       "      <th>VALID PRED E190</th>\n",
       "      <th>VALID POLY E190</th>\n",
       "      <th>VALID POLY PRED E190</th>\n",
       "      <th>VALID LSTSQ E190</th>\n",
       "      <th>VALID PRED E200</th>\n",
       "      <th>VALID POLY E200</th>\n",
       "      <th>VALID POLY PRED E200</th>\n",
       "      <th>VALID LSTSQ E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>10.190</td>\n",
       "      <td>10.190</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.696</td>\n",
       "      <td>9.696</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.900</td>\n",
       "      <td>8.901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.330</td>\n",
       "      <td>4.350</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.243</td>\n",
       "      <td>4.261</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>12.970</td>\n",
       "      <td>12.970</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.457</td>\n",
       "      <td>12.456</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.626</td>\n",
       "      <td>11.625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.049</td>\n",
       "      <td>6.001</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.938</td>\n",
       "      <td>5.884</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>1.076</td>\n",
       "      <td>1.076</td>\n",
       "      <td>1.705</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.458</td>\n",
       "      <td>1.460</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.102</td>\n",
       "      <td>2.103</td>\n",
       "      <td>...</td>\n",
       "      <td>3.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.572</td>\n",
       "      <td>3.641</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.501</td>\n",
       "      <td>3.571</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.966</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>3.029</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.002</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.950</td>\n",
       "      <td>2.950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.961</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.935</td>\n",
       "      <td>1.877</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VALID PRED E1  VALID POLY E1  VALID POLY PRED E1  VALID LSTSQ E1  \\\n",
       "MAE FV          10.190         10.190               0.012           0.000   \n",
       "RMSE FV         12.970         12.970               0.016           0.000   \n",
       "MAPE FV          1.076          1.076               1.705           0.000   \n",
       "R2 FV           -0.420         -0.420               0.966           1.000   \n",
       "RAAE FV          0.925          0.925               0.138           0.000   \n",
       "RMAE FV          3.029          3.029               0.533           0.000   \n",
       "\n",
       "         VALID PRED E10  VALID POLY E10  VALID POLY PRED E10  VALID LSTSQ E10  \\\n",
       "MAE FV            9.696           9.696                0.015            0.000   \n",
       "RMSE FV          12.457          12.456                0.019            0.000   \n",
       "MAPE FV           1.458           1.460                0.152            0.000   \n",
       "R2 FV            -0.295          -0.295                0.993            1.000   \n",
       "RAAE FV           0.878           0.878                0.063            0.000   \n",
       "RMAE FV           3.002           3.002                0.261            0.000   \n",
       "\n",
       "         VALID PRED E20  VALID POLY E20  ...  VALID POLY PRED E180  \\\n",
       "MAE FV            8.900           8.901  ...                 0.411   \n",
       "RMSE FV          11.626          11.625  ...                 0.535   \n",
       "MAPE FV           2.102           2.103  ...                 3.430   \n",
       "R2 FV            -0.106          -0.106  ...                 0.994   \n",
       "RAAE FV           0.802           0.802  ...                 0.054   \n",
       "RMAE FV           2.950           2.950  ...                 0.234   \n",
       "\n",
       "         VALID LSTSQ E180  VALID PRED E190  VALID POLY E190  \\\n",
       "MAE FV              0.000            4.330            4.350   \n",
       "RMSE FV             0.000            6.049            6.001   \n",
       "MAPE FV             0.000            3.572            3.641   \n",
       "R2 FV               1.000            0.674            0.679   \n",
       "RAAE FV             0.000            0.401            0.403   \n",
       "RMAE FV             0.000            1.961            1.908   \n",
       "\n",
       "         VALID POLY PRED E190  VALID LSTSQ E190  VALID PRED E200  \\\n",
       "MAE FV                  0.439             0.000            4.243   \n",
       "RMSE FV                 0.571             0.000            5.938   \n",
       "MAPE FV                 0.751             0.000            3.501   \n",
       "R2 FV                   0.994             1.000            0.686   \n",
       "RAAE FV                 0.058             0.000            0.393   \n",
       "RMAE FV                 0.245             0.000            1.935   \n",
       "\n",
       "         VALID POLY E200  VALID POLY PRED E200  VALID LSTSQ E200  \n",
       "MAE FV             4.261                 0.467             0.000  \n",
       "RMSE FV            5.884                 0.606             0.000  \n",
       "MAPE FV            3.571                 0.619             0.000  \n",
       "R2 FV              0.691                 0.993             1.000  \n",
       "RAAE FV            0.395                 0.061             0.000  \n",
       "RMAE FV            1.877                 0.256             0.000  \n",
       "\n",
       "[6 rows x 84 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:02:09.345332Z",
     "start_time": "2020-12-30T19:02:09.327680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST PRED E1</th>\n",
       "      <th>TEST POLY E1</th>\n",
       "      <th>TEST POLY PRED E1</th>\n",
       "      <th>TEST LSTSQ E1</th>\n",
       "      <th>TEST PRED E10</th>\n",
       "      <th>TEST POLY E10</th>\n",
       "      <th>TEST POLY PRED E10</th>\n",
       "      <th>TEST LSTSQ E10</th>\n",
       "      <th>TEST PRED E20</th>\n",
       "      <th>TEST POLY E20</th>\n",
       "      <th>...</th>\n",
       "      <th>TEST POLY PRED E180</th>\n",
       "      <th>TEST LSTSQ E180</th>\n",
       "      <th>TEST PRED E190</th>\n",
       "      <th>TEST POLY E190</th>\n",
       "      <th>TEST POLY PRED E190</th>\n",
       "      <th>TEST LSTSQ E190</th>\n",
       "      <th>TEST PRED E200</th>\n",
       "      <th>TEST POLY E200</th>\n",
       "      <th>TEST POLY PRED E200</th>\n",
       "      <th>TEST LSTSQ E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>10.189</td>\n",
       "      <td>10.189</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.694</td>\n",
       "      <td>9.694</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.898</td>\n",
       "      <td>8.899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.328</td>\n",
       "      <td>4.348</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.241</td>\n",
       "      <td>4.260</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>12.975</td>\n",
       "      <td>12.975</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.462</td>\n",
       "      <td>12.462</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.631</td>\n",
       "      <td>11.631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.052</td>\n",
       "      <td>6.003</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.941</td>\n",
       "      <td>5.886</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>1.064</td>\n",
       "      <td>1.063</td>\n",
       "      <td>1.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.388</td>\n",
       "      <td>1.388</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.945</td>\n",
       "      <td>1.948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.177</td>\n",
       "      <td>3.238</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.114</td>\n",
       "      <td>3.179</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>-0.417</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>0.966</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>3.152</td>\n",
       "      <td>3.152</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.124</td>\n",
       "      <td>3.124</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.072</td>\n",
       "      <td>3.072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.061</td>\n",
       "      <td>2.003</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.033</td>\n",
       "      <td>1.971</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TEST PRED E1  TEST POLY E1  TEST POLY PRED E1  TEST LSTSQ E1  \\\n",
       "MAE FV         10.189        10.189              0.012          0.000   \n",
       "RMSE FV        12.975        12.975              0.016          0.000   \n",
       "MAPE FV         1.064         1.063              1.222          0.000   \n",
       "R2 FV          -0.417        -0.417              0.966          1.000   \n",
       "RAAE FV         0.923         0.923              0.138          0.000   \n",
       "RMAE FV         3.152         3.152              0.559          0.000   \n",
       "\n",
       "         TEST PRED E10  TEST POLY E10  TEST POLY PRED E10  TEST LSTSQ E10  \\\n",
       "MAE FV           9.694          9.694               0.015           0.000   \n",
       "RMSE FV         12.462         12.462               0.019           0.000   \n",
       "MAPE FV          1.388          1.388               0.415           0.000   \n",
       "R2 FV           -0.292         -0.292               0.993           1.000   \n",
       "RAAE FV          0.876          0.876               0.063           0.000   \n",
       "RMAE FV          3.124          3.124               0.275           0.000   \n",
       "\n",
       "         TEST PRED E20  TEST POLY E20  ...  TEST POLY PRED E180  \\\n",
       "MAE FV           8.898          8.899  ...                0.411   \n",
       "RMSE FV         11.631         11.631  ...                0.536   \n",
       "MAPE FV          1.945          1.948  ...                0.944   \n",
       "R2 FV           -0.105         -0.104  ...                0.994   \n",
       "RAAE FV          0.801          0.801  ...                0.054   \n",
       "RMAE FV          3.072          3.072  ...                0.250   \n",
       "\n",
       "         TEST LSTSQ E180  TEST PRED E190  TEST POLY E190  TEST POLY PRED E190  \\\n",
       "MAE FV             0.000           4.328           4.348                0.439   \n",
       "RMSE FV            0.000           6.052           6.003                0.572   \n",
       "MAPE FV            0.000           3.177           3.238                0.509   \n",
       "R2 FV              1.000           0.675           0.680                0.994   \n",
       "RAAE FV            0.000           0.400           0.402                0.058   \n",
       "RMAE FV            0.000           2.061           2.003                0.262   \n",
       "\n",
       "         TEST LSTSQ E190  TEST PRED E200  TEST POLY E200  TEST POLY PRED E200  \\\n",
       "MAE FV             0.000           4.241           4.260                0.467   \n",
       "RMSE FV            0.000           5.941           5.886                0.607   \n",
       "MAPE FV            0.000           3.114           3.179                0.675   \n",
       "R2 FV              1.000           0.687           0.692                0.993   \n",
       "RAAE FV            0.000           0.392           0.394                0.061   \n",
       "RMAE FV            0.000           2.033           1.971                0.274   \n",
       "\n",
       "         TEST LSTSQ E200  \n",
       "MAE FV             0.000  \n",
       "RMSE FV            0.000  \n",
       "MAPE FV            0.000  \n",
       "R2 FV              1.000  \n",
       "RAAE FV            0.000  \n",
       "RMAE FV            0.000  \n",
       "\n",
       "[6 rows x 84 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:02:09.367475Z",
     "start_time": "2020-12-30T19:02:09.347208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E1</th>\n",
       "      <th>E10</th>\n",
       "      <th>E20</th>\n",
       "      <th>E30</th>\n",
       "      <th>E40</th>\n",
       "      <th>E50</th>\n",
       "      <th>E60</th>\n",
       "      <th>E70</th>\n",
       "      <th>E80</th>\n",
       "      <th>E90</th>\n",
       "      <th>...</th>\n",
       "      <th>E110</th>\n",
       "      <th>E120</th>\n",
       "      <th>E130</th>\n",
       "      <th>E140</th>\n",
       "      <th>E150</th>\n",
       "      <th>E160</th>\n",
       "      <th>E170</th>\n",
       "      <th>E180</th>\n",
       "      <th>E190</th>\n",
       "      <th>E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN REAL LAMBDA</th>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>...</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN PRED LAMBDA</th>\n",
       "      <td>0.098</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1.453</td>\n",
       "      <td>2.626</td>\n",
       "      <td>3.820</td>\n",
       "      <td>4.877</td>\n",
       "      <td>5.744</td>\n",
       "      <td>6.387</td>\n",
       "      <td>6.832</td>\n",
       "      <td>...</td>\n",
       "      <td>7.346</td>\n",
       "      <td>7.502</td>\n",
       "      <td>7.625</td>\n",
       "      <td>7.729</td>\n",
       "      <td>7.821</td>\n",
       "      <td>7.907</td>\n",
       "      <td>7.989</td>\n",
       "      <td>8.068</td>\n",
       "      <td>8.147</td>\n",
       "      <td>8.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1.452</td>\n",
       "      <td>2.625</td>\n",
       "      <td>3.818</td>\n",
       "      <td>4.875</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.384</td>\n",
       "      <td>6.828</td>\n",
       "      <td>...</td>\n",
       "      <td>7.340</td>\n",
       "      <td>7.495</td>\n",
       "      <td>7.617</td>\n",
       "      <td>7.719</td>\n",
       "      <td>7.810</td>\n",
       "      <td>7.894</td>\n",
       "      <td>7.974</td>\n",
       "      <td>8.051</td>\n",
       "      <td>8.128</td>\n",
       "      <td>8.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>...</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "      <td>11.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID REAL LAMBDA</th>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>...</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID PRED LAMBDA</th>\n",
       "      <td>0.098</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.640</td>\n",
       "      <td>1.440</td>\n",
       "      <td>2.604</td>\n",
       "      <td>3.791</td>\n",
       "      <td>4.843</td>\n",
       "      <td>5.706</td>\n",
       "      <td>6.348</td>\n",
       "      <td>6.791</td>\n",
       "      <td>...</td>\n",
       "      <td>7.303</td>\n",
       "      <td>7.457</td>\n",
       "      <td>7.579</td>\n",
       "      <td>7.681</td>\n",
       "      <td>7.771</td>\n",
       "      <td>7.855</td>\n",
       "      <td>7.935</td>\n",
       "      <td>8.012</td>\n",
       "      <td>8.089</td>\n",
       "      <td>8.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.640</td>\n",
       "      <td>1.440</td>\n",
       "      <td>2.604</td>\n",
       "      <td>3.790</td>\n",
       "      <td>4.841</td>\n",
       "      <td>5.703</td>\n",
       "      <td>6.344</td>\n",
       "      <td>6.788</td>\n",
       "      <td>...</td>\n",
       "      <td>7.298</td>\n",
       "      <td>7.451</td>\n",
       "      <td>7.572</td>\n",
       "      <td>7.673</td>\n",
       "      <td>7.763</td>\n",
       "      <td>7.845</td>\n",
       "      <td>7.924</td>\n",
       "      <td>8.001</td>\n",
       "      <td>8.076</td>\n",
       "      <td>8.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>...</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "      <td>11.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST REAL LAMBDA</th>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>...</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST PRED LAMBDA</th>\n",
       "      <td>0.098</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.641</td>\n",
       "      <td>1.441</td>\n",
       "      <td>2.606</td>\n",
       "      <td>3.794</td>\n",
       "      <td>4.847</td>\n",
       "      <td>5.711</td>\n",
       "      <td>6.353</td>\n",
       "      <td>6.797</td>\n",
       "      <td>...</td>\n",
       "      <td>7.309</td>\n",
       "      <td>7.464</td>\n",
       "      <td>7.586</td>\n",
       "      <td>7.688</td>\n",
       "      <td>7.779</td>\n",
       "      <td>7.863</td>\n",
       "      <td>7.943</td>\n",
       "      <td>8.020</td>\n",
       "      <td>8.097</td>\n",
       "      <td>8.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.641</td>\n",
       "      <td>1.441</td>\n",
       "      <td>2.606</td>\n",
       "      <td>3.793</td>\n",
       "      <td>4.845</td>\n",
       "      <td>5.708</td>\n",
       "      <td>6.349</td>\n",
       "      <td>6.793</td>\n",
       "      <td>...</td>\n",
       "      <td>7.304</td>\n",
       "      <td>7.458</td>\n",
       "      <td>7.580</td>\n",
       "      <td>7.681</td>\n",
       "      <td>7.771</td>\n",
       "      <td>7.853</td>\n",
       "      <td>7.933</td>\n",
       "      <td>8.009</td>\n",
       "      <td>8.085</td>\n",
       "      <td>8.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>...</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "      <td>11.152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        E1    E10    E20    E30    E40    E50  \\\n",
       "STD FV TRAIN REAL LAMBDA            11.168 11.168 11.168 11.168 11.168 11.168   \n",
       "STD FV TRAIN PRED LAMBDA             0.098  0.253  0.646  1.453  2.626  3.820   \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  0.097  0.252  0.646  1.452  2.625  3.818   \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.168 11.168 11.168 11.168 11.168 11.168   \n",
       "STD FV VALID REAL LAMBDA            11.139 11.139 11.139 11.139 11.139 11.139   \n",
       "STD FV VALID PRED LAMBDA             0.098  0.251  0.640  1.440  2.604  3.791   \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  0.097  0.250  0.640  1.440  2.604  3.790   \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.139 11.139 11.139 11.139 11.139 11.139   \n",
       "STD FV TEST REAL LAMBDA             11.152 11.152 11.152 11.152 11.152 11.152   \n",
       "STD FV TEST PRED LAMBDA              0.098  0.251  0.641  1.441  2.606  3.794   \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   0.097  0.250  0.641  1.441  2.606  3.793   \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  11.152 11.152 11.152 11.152 11.152 11.152   \n",
       "\n",
       "                                       E60    E70    E80    E90  ...   E110  \\\n",
       "STD FV TRAIN REAL LAMBDA            11.168 11.168 11.168 11.168  ... 11.168   \n",
       "STD FV TRAIN PRED LAMBDA             4.877  5.744  6.387  6.832  ...  7.346   \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  4.875  5.741  6.384  6.828  ...  7.340   \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.168 11.168 11.168 11.168  ... 11.168   \n",
       "STD FV VALID REAL LAMBDA            11.139 11.139 11.139 11.139  ... 11.139   \n",
       "STD FV VALID PRED LAMBDA             4.843  5.706  6.348  6.791  ...  7.303   \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  4.841  5.703  6.344  6.788  ...  7.298   \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.139 11.139 11.139 11.139  ... 11.139   \n",
       "STD FV TEST REAL LAMBDA             11.152 11.152 11.152 11.152  ... 11.152   \n",
       "STD FV TEST PRED LAMBDA              4.847  5.711  6.353  6.797  ...  7.309   \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   4.845  5.708  6.349  6.793  ...  7.304   \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  11.152 11.152 11.152 11.152  ... 11.152   \n",
       "\n",
       "                                      E120   E130   E140   E150   E160   E170  \\\n",
       "STD FV TRAIN REAL LAMBDA            11.168 11.168 11.168 11.168 11.168 11.168   \n",
       "STD FV TRAIN PRED LAMBDA             7.502  7.625  7.729  7.821  7.907  7.989   \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  7.495  7.617  7.719  7.810  7.894  7.974   \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.168 11.168 11.168 11.168 11.168 11.168   \n",
       "STD FV VALID REAL LAMBDA            11.139 11.139 11.139 11.139 11.139 11.139   \n",
       "STD FV VALID PRED LAMBDA             7.457  7.579  7.681  7.771  7.855  7.935   \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  7.451  7.572  7.673  7.763  7.845  7.924   \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.139 11.139 11.139 11.139 11.139 11.139   \n",
       "STD FV TEST REAL LAMBDA             11.152 11.152 11.152 11.152 11.152 11.152   \n",
       "STD FV TEST PRED LAMBDA              7.464  7.586  7.688  7.779  7.863  7.943   \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   7.458  7.580  7.681  7.771  7.853  7.933   \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  11.152 11.152 11.152 11.152 11.152 11.152   \n",
       "\n",
       "                                      E180   E190   E200  \n",
       "STD FV TRAIN REAL LAMBDA            11.168 11.168 11.168  \n",
       "STD FV TRAIN PRED LAMBDA             8.068  8.147  8.224  \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  8.051  8.128  8.203  \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.168 11.168 11.168  \n",
       "STD FV VALID REAL LAMBDA            11.139 11.139 11.139  \n",
       "STD FV VALID PRED LAMBDA             8.012  8.089  8.164  \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  8.001  8.076  8.151  \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.139 11.139 11.139  \n",
       "STD FV TEST REAL LAMBDA             11.152 11.152 11.152  \n",
       "STD FV TEST PRED LAMBDA              8.020  8.097  8.173  \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   8.009  8.085  8.160  \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  11.152 11.152 11.152  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:02:09.389047Z",
     "start_time": "2020-12-30T19:02:09.368930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E1</th>\n",
       "      <th>E10</th>\n",
       "      <th>E20</th>\n",
       "      <th>E30</th>\n",
       "      <th>E40</th>\n",
       "      <th>E50</th>\n",
       "      <th>E60</th>\n",
       "      <th>E70</th>\n",
       "      <th>E80</th>\n",
       "      <th>E90</th>\n",
       "      <th>...</th>\n",
       "      <th>E110</th>\n",
       "      <th>E120</th>\n",
       "      <th>E130</th>\n",
       "      <th>E140</th>\n",
       "      <th>E150</th>\n",
       "      <th>E160</th>\n",
       "      <th>E170</th>\n",
       "      <th>E180</th>\n",
       "      <th>E190</th>\n",
       "      <th>E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN REAL LAMBDA</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN PRED LAMBDA</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID REAL LAMBDA</th>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID PRED LAMBDA</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST REAL LAMBDA</th>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST PRED LAMBDA</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         E1    E10    E20    E30    E40  \\\n",
       "MEAN FV TRAIN REAL LAMBDA            -0.107 -0.107 -0.107 -0.107 -0.107   \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.001 -0.013 -0.036 -0.072 -0.092   \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.001 -0.013 -0.036 -0.072 -0.092   \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.107 -0.107 -0.107 -0.107 -0.107   \n",
       "MEAN FV VALID REAL LAMBDA            -0.113 -0.113 -0.113 -0.113 -0.113   \n",
       "MEAN FV VALID PRED LAMBDA            -0.001 -0.013 -0.036 -0.072 -0.092   \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.001 -0.013 -0.036 -0.072 -0.092   \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.113 -0.113 -0.113 -0.113 -0.113   \n",
       "MEAN FV TEST REAL LAMBDA             -0.104 -0.104 -0.104 -0.104 -0.104   \n",
       "MEAN FV TEST PRED LAMBDA             -0.001 -0.013 -0.036 -0.071 -0.091   \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  -0.001 -0.013 -0.036 -0.071 -0.091   \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.104 -0.104 -0.104 -0.104 -0.104   \n",
       "\n",
       "                                        E50    E60    E70    E80    E90  ...  \\\n",
       "MEAN FV TRAIN REAL LAMBDA            -0.107 -0.107 -0.107 -0.107 -0.107  ...   \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.097 -0.099 -0.100 -0.100 -0.100  ...   \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.097 -0.099 -0.100 -0.100 -0.100  ...   \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.107 -0.107 -0.107 -0.107 -0.107  ...   \n",
       "MEAN FV VALID REAL LAMBDA            -0.113 -0.113 -0.113 -0.113 -0.113  ...   \n",
       "MEAN FV VALID PRED LAMBDA            -0.098 -0.099 -0.101 -0.102 -0.102  ...   \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.098 -0.099 -0.101 -0.102 -0.102  ...   \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.113 -0.113 -0.113 -0.113 -0.113  ...   \n",
       "MEAN FV TEST REAL LAMBDA             -0.104 -0.104 -0.104 -0.104 -0.104  ...   \n",
       "MEAN FV TEST PRED LAMBDA             -0.096 -0.097 -0.098 -0.098 -0.098  ...   \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  -0.096 -0.097 -0.098 -0.098 -0.098  ...   \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.104 -0.104 -0.104 -0.104 -0.104  ...   \n",
       "\n",
       "                                       E110   E120   E130   E140   E150  \\\n",
       "MEAN FV TRAIN REAL LAMBDA            -0.107 -0.107 -0.107 -0.107 -0.107   \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.101 -0.101 -0.101 -0.101 -0.101   \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.101 -0.101 -0.101 -0.101 -0.101   \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.107 -0.107 -0.107 -0.107 -0.107   \n",
       "MEAN FV VALID REAL LAMBDA            -0.113 -0.113 -0.113 -0.113 -0.113   \n",
       "MEAN FV VALID PRED LAMBDA            -0.102 -0.103 -0.103 -0.103 -0.103   \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.103 -0.103 -0.103 -0.103 -0.103   \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.113 -0.113 -0.113 -0.113 -0.113   \n",
       "MEAN FV TEST REAL LAMBDA             -0.104 -0.104 -0.104 -0.104 -0.104   \n",
       "MEAN FV TEST PRED LAMBDA             -0.099 -0.099 -0.099 -0.099 -0.099   \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  -0.099 -0.099 -0.099 -0.099 -0.099   \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.104 -0.104 -0.104 -0.104 -0.104   \n",
       "\n",
       "                                       E160   E170   E180   E190   E200  \n",
       "MEAN FV TRAIN REAL LAMBDA            -0.107 -0.107 -0.107 -0.107 -0.107  \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.101 -0.102 -0.102 -0.102 -0.102  \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.101 -0.102 -0.102 -0.102 -0.102  \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.107 -0.107 -0.107 -0.107 -0.107  \n",
       "MEAN FV VALID REAL LAMBDA            -0.113 -0.113 -0.113 -0.113 -0.113  \n",
       "MEAN FV VALID PRED LAMBDA            -0.103 -0.103 -0.104 -0.104 -0.104  \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.103 -0.104 -0.104 -0.104 -0.104  \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.113 -0.113 -0.113 -0.113 -0.113  \n",
       "MEAN FV TEST REAL LAMBDA             -0.104 -0.104 -0.104 -0.104 -0.104  \n",
       "MEAN FV TEST PRED LAMBDA             -0.100 -0.100 -0.100 -0.100 -0.101  \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  -0.099 -0.100 -0.100 -0.100 -0.100  \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.104 -0.104 -0.104 -0.104 -0.104  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Lambda-Net Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:02:56.456921Z",
     "start_time": "2020-12-30T19:02:09.390515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f06a9179e5489fad8b6c2c2ddc5c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list_total = []\n",
    "metric_list_total = []\n",
    "\n",
    "val_loss_list_total = []\n",
    "val_metric_list_total = []\n",
    "\n",
    "for _, entry in tqdm(enumerate(clf_list)):\n",
    "    entry = entry[3]\n",
    "    loss_list = []\n",
    "    metric_list = []\n",
    "    val_loss_list = []\n",
    "    val_metric_list = []\n",
    "    for i in range(epochs):  \n",
    "        loss_list.append(entry['loss'][i])\n",
    "        metric_list.append(entry['mean_absolute_percentage_error_keras'][i])\n",
    "        val_loss_list.append(entry['val_loss'][i])\n",
    "        val_metric_list.append(entry['val_mean_absolute_percentage_error_keras'][i])\n",
    "    loss_list_total.append(loss_list)\n",
    "    metric_list_total.append(metric_list)\n",
    "    val_loss_list_total.append(val_loss_list)\n",
    "    val_metric_list_total.append(val_metric_list)\n",
    "\n",
    "loss_df = pd.DataFrame(data=loss_list_total, columns=['loss_epoch_' + str(i+1) for i in range(epochs)])\n",
    "metric_df = pd.DataFrame(data=metric_list_total, columns=['metric_epoch_' + str(i+1) for i in range(epochs)]) \n",
    "val_loss_df = pd.DataFrame(data=val_loss_list_total, columns=['val_loss_epoch_' + str(i+1) for i in range(epochs)])\n",
    "val_metric_df = pd.DataFrame(data=val_metric_list_total, columns=['val_metric_epoch_' + str(i+1) for i in range(epochs)]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:05:23.876966Z",
     "start_time": "2020-12-30T19:02:56.459260Z"
    }
   },
   "outputs": [],
   "source": [
    "path_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_val_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_val_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "loss_df.to_csv(path_loss, index=None, sep=',')\n",
    "metric_df.to_csv(path_metric, index=None, sep=',')\n",
    "val_loss_df.to_csv(path_val_loss, index=None, sep=',')\n",
    "val_metric_df.to_csv(path_val_metric, index=None, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:05:25.228525Z",
     "start_time": "2020-12-30T19:05:23.880606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_epoch_1</th>\n",
       "      <th>loss_epoch_2</th>\n",
       "      <th>loss_epoch_3</th>\n",
       "      <th>loss_epoch_4</th>\n",
       "      <th>loss_epoch_5</th>\n",
       "      <th>loss_epoch_6</th>\n",
       "      <th>loss_epoch_7</th>\n",
       "      <th>loss_epoch_8</th>\n",
       "      <th>loss_epoch_9</th>\n",
       "      <th>loss_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_epoch_191</th>\n",
       "      <th>loss_epoch_192</th>\n",
       "      <th>loss_epoch_193</th>\n",
       "      <th>loss_epoch_194</th>\n",
       "      <th>loss_epoch_195</th>\n",
       "      <th>loss_epoch_196</th>\n",
       "      <th>loss_epoch_197</th>\n",
       "      <th>loss_epoch_198</th>\n",
       "      <th>loss_epoch_199</th>\n",
       "      <th>loss_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.215</td>\n",
       "      <td>10.162</td>\n",
       "      <td>10.109</td>\n",
       "      <td>10.056</td>\n",
       "      <td>10.003</td>\n",
       "      <td>9.949</td>\n",
       "      <td>9.894</td>\n",
       "      <td>9.837</td>\n",
       "      <td>9.779</td>\n",
       "      <td>9.719</td>\n",
       "      <td>...</td>\n",
       "      <td>4.189</td>\n",
       "      <td>4.180</td>\n",
       "      <td>4.171</td>\n",
       "      <td>4.161</td>\n",
       "      <td>4.152</td>\n",
       "      <td>4.143</td>\n",
       "      <td>4.134</td>\n",
       "      <td>4.125</td>\n",
       "      <td>4.116</td>\n",
       "      <td>4.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.348</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.301</td>\n",
       "      <td>2.278</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.230</td>\n",
       "      <td>2.205</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.153</td>\n",
       "      <td>2.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.198</td>\n",
       "      <td>4.195</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.186</td>\n",
       "      <td>4.172</td>\n",
       "      <td>4.158</td>\n",
       "      <td>4.144</td>\n",
       "      <td>4.130</td>\n",
       "      <td>4.115</td>\n",
       "      <td>4.101</td>\n",
       "      <td>...</td>\n",
       "      <td>2.049</td>\n",
       "      <td>2.041</td>\n",
       "      <td>2.031</td>\n",
       "      <td>2.020</td>\n",
       "      <td>2.010</td>\n",
       "      <td>2.002</td>\n",
       "      <td>1.992</td>\n",
       "      <td>1.983</td>\n",
       "      <td>1.975</td>\n",
       "      <td>1.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.501</td>\n",
       "      <td>8.465</td>\n",
       "      <td>8.429</td>\n",
       "      <td>8.392</td>\n",
       "      <td>8.356</td>\n",
       "      <td>8.319</td>\n",
       "      <td>8.281</td>\n",
       "      <td>8.242</td>\n",
       "      <td>8.202</td>\n",
       "      <td>8.160</td>\n",
       "      <td>...</td>\n",
       "      <td>3.844</td>\n",
       "      <td>3.836</td>\n",
       "      <td>3.827</td>\n",
       "      <td>3.818</td>\n",
       "      <td>3.810</td>\n",
       "      <td>3.801</td>\n",
       "      <td>3.792</td>\n",
       "      <td>3.784</td>\n",
       "      <td>3.775</td>\n",
       "      <td>3.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.952</td>\n",
       "      <td>9.907</td>\n",
       "      <td>9.858</td>\n",
       "      <td>9.809</td>\n",
       "      <td>9.760</td>\n",
       "      <td>9.712</td>\n",
       "      <td>9.662</td>\n",
       "      <td>9.610</td>\n",
       "      <td>9.557</td>\n",
       "      <td>9.503</td>\n",
       "      <td>...</td>\n",
       "      <td>4.182</td>\n",
       "      <td>4.172</td>\n",
       "      <td>4.163</td>\n",
       "      <td>4.154</td>\n",
       "      <td>4.145</td>\n",
       "      <td>4.135</td>\n",
       "      <td>4.126</td>\n",
       "      <td>4.117</td>\n",
       "      <td>4.108</td>\n",
       "      <td>4.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.639</td>\n",
       "      <td>11.575</td>\n",
       "      <td>11.508</td>\n",
       "      <td>11.442</td>\n",
       "      <td>11.379</td>\n",
       "      <td>11.316</td>\n",
       "      <td>11.248</td>\n",
       "      <td>11.178</td>\n",
       "      <td>11.108</td>\n",
       "      <td>11.036</td>\n",
       "      <td>...</td>\n",
       "      <td>4.523</td>\n",
       "      <td>4.513</td>\n",
       "      <td>4.503</td>\n",
       "      <td>4.494</td>\n",
       "      <td>4.484</td>\n",
       "      <td>4.475</td>\n",
       "      <td>4.465</td>\n",
       "      <td>4.455</td>\n",
       "      <td>4.446</td>\n",
       "      <td>4.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.404</td>\n",
       "      <td>22.273</td>\n",
       "      <td>22.139</td>\n",
       "      <td>22.002</td>\n",
       "      <td>21.859</td>\n",
       "      <td>21.712</td>\n",
       "      <td>21.558</td>\n",
       "      <td>21.397</td>\n",
       "      <td>21.225</td>\n",
       "      <td>21.040</td>\n",
       "      <td>...</td>\n",
       "      <td>6.653</td>\n",
       "      <td>6.645</td>\n",
       "      <td>6.636</td>\n",
       "      <td>6.626</td>\n",
       "      <td>6.616</td>\n",
       "      <td>6.605</td>\n",
       "      <td>6.597</td>\n",
       "      <td>6.587</td>\n",
       "      <td>6.577</td>\n",
       "      <td>6.568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss_epoch_1  loss_epoch_2  loss_epoch_3  loss_epoch_4  loss_epoch_5  \\\n",
       "count    100000.000    100000.000    100000.000    100000.000    100000.000   \n",
       "mean         10.215        10.162        10.109        10.056        10.003   \n",
       "std           2.348         2.325         2.301         2.278         2.254   \n",
       "min           4.198         4.195         4.192         4.186         4.172   \n",
       "25%           8.501         8.465         8.429         8.392         8.356   \n",
       "50%           9.952         9.907         9.858         9.809         9.760   \n",
       "75%          11.639        11.575        11.508        11.442        11.379   \n",
       "max          22.404        22.273        22.139        22.002        21.859   \n",
       "\n",
       "       loss_epoch_6  loss_epoch_7  loss_epoch_8  loss_epoch_9  loss_epoch_10  \\\n",
       "count    100000.000    100000.000    100000.000    100000.000     100000.000   \n",
       "mean          9.949         9.894         9.837         9.779          9.719   \n",
       "std           2.230         2.205         2.180         2.153          2.126   \n",
       "min           4.158         4.144         4.130         4.115          4.101   \n",
       "25%           8.319         8.281         8.242         8.202          8.160   \n",
       "50%           9.712         9.662         9.610         9.557          9.503   \n",
       "75%          11.316        11.248        11.178        11.108         11.036   \n",
       "max          21.712        21.558        21.397        21.225         21.040   \n",
       "\n",
       "       ...  loss_epoch_191  loss_epoch_192  loss_epoch_193  loss_epoch_194  \\\n",
       "count  ...      100000.000      100000.000      100000.000      100000.000   \n",
       "mean   ...           4.189           4.180           4.171           4.161   \n",
       "std    ...           0.503           0.502           0.501           0.500   \n",
       "min    ...           2.049           2.041           2.031           2.020   \n",
       "25%    ...           3.844           3.836           3.827           3.818   \n",
       "50%    ...           4.182           4.172           4.163           4.154   \n",
       "75%    ...           4.523           4.513           4.503           4.494   \n",
       "max    ...           6.653           6.645           6.636           6.626   \n",
       "\n",
       "       loss_epoch_195  loss_epoch_196  loss_epoch_197  loss_epoch_198  \\\n",
       "count      100000.000      100000.000      100000.000      100000.000   \n",
       "mean            4.152           4.143           4.134           4.125   \n",
       "std             0.500           0.499           0.498           0.497   \n",
       "min             2.010           2.002           1.992           1.983   \n",
       "25%             3.810           3.801           3.792           3.784   \n",
       "50%             4.145           4.135           4.126           4.117   \n",
       "75%             4.484           4.475           4.465           4.455   \n",
       "max             6.616           6.605           6.597           6.587   \n",
       "\n",
       "       loss_epoch_199  loss_epoch_200  \n",
       "count      100000.000      100000.000  \n",
       "mean            4.116           4.107  \n",
       "std             0.496           0.495  \n",
       "min             1.975           1.965  \n",
       "25%             3.775           3.767  \n",
       "50%             4.108           4.099  \n",
       "75%             4.446           4.436  \n",
       "max             6.577           6.568  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:05:26.546193Z",
     "start_time": "2020-12-30T19:05:25.230113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss_epoch_1</th>\n",
       "      <th>val_loss_epoch_2</th>\n",
       "      <th>val_loss_epoch_3</th>\n",
       "      <th>val_loss_epoch_4</th>\n",
       "      <th>val_loss_epoch_5</th>\n",
       "      <th>val_loss_epoch_6</th>\n",
       "      <th>val_loss_epoch_7</th>\n",
       "      <th>val_loss_epoch_8</th>\n",
       "      <th>val_loss_epoch_9</th>\n",
       "      <th>val_loss_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>val_loss_epoch_191</th>\n",
       "      <th>val_loss_epoch_192</th>\n",
       "      <th>val_loss_epoch_193</th>\n",
       "      <th>val_loss_epoch_194</th>\n",
       "      <th>val_loss_epoch_195</th>\n",
       "      <th>val_loss_epoch_196</th>\n",
       "      <th>val_loss_epoch_197</th>\n",
       "      <th>val_loss_epoch_198</th>\n",
       "      <th>val_loss_epoch_199</th>\n",
       "      <th>val_loss_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.190</td>\n",
       "      <td>10.138</td>\n",
       "      <td>10.086</td>\n",
       "      <td>10.033</td>\n",
       "      <td>9.980</td>\n",
       "      <td>9.926</td>\n",
       "      <td>9.871</td>\n",
       "      <td>9.815</td>\n",
       "      <td>9.756</td>\n",
       "      <td>9.696</td>\n",
       "      <td>...</td>\n",
       "      <td>4.321</td>\n",
       "      <td>4.313</td>\n",
       "      <td>4.304</td>\n",
       "      <td>4.295</td>\n",
       "      <td>4.286</td>\n",
       "      <td>4.277</td>\n",
       "      <td>4.269</td>\n",
       "      <td>4.260</td>\n",
       "      <td>4.251</td>\n",
       "      <td>4.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.385</td>\n",
       "      <td>2.362</td>\n",
       "      <td>2.339</td>\n",
       "      <td>2.316</td>\n",
       "      <td>2.292</td>\n",
       "      <td>2.268</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.218</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.980</td>\n",
       "      <td>3.975</td>\n",
       "      <td>3.970</td>\n",
       "      <td>3.965</td>\n",
       "      <td>3.959</td>\n",
       "      <td>3.954</td>\n",
       "      <td>3.949</td>\n",
       "      <td>3.944</td>\n",
       "      <td>3.939</td>\n",
       "      <td>3.934</td>\n",
       "      <td>...</td>\n",
       "      <td>2.098</td>\n",
       "      <td>2.094</td>\n",
       "      <td>2.085</td>\n",
       "      <td>2.078</td>\n",
       "      <td>2.071</td>\n",
       "      <td>2.069</td>\n",
       "      <td>2.061</td>\n",
       "      <td>2.058</td>\n",
       "      <td>2.050</td>\n",
       "      <td>2.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.454</td>\n",
       "      <td>8.419</td>\n",
       "      <td>8.384</td>\n",
       "      <td>8.348</td>\n",
       "      <td>8.311</td>\n",
       "      <td>8.274</td>\n",
       "      <td>8.237</td>\n",
       "      <td>8.199</td>\n",
       "      <td>8.159</td>\n",
       "      <td>8.118</td>\n",
       "      <td>...</td>\n",
       "      <td>3.917</td>\n",
       "      <td>3.909</td>\n",
       "      <td>3.901</td>\n",
       "      <td>3.893</td>\n",
       "      <td>3.885</td>\n",
       "      <td>3.877</td>\n",
       "      <td>3.869</td>\n",
       "      <td>3.861</td>\n",
       "      <td>3.853</td>\n",
       "      <td>3.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.918</td>\n",
       "      <td>9.870</td>\n",
       "      <td>9.823</td>\n",
       "      <td>9.774</td>\n",
       "      <td>9.728</td>\n",
       "      <td>9.681</td>\n",
       "      <td>9.631</td>\n",
       "      <td>9.579</td>\n",
       "      <td>9.524</td>\n",
       "      <td>9.469</td>\n",
       "      <td>...</td>\n",
       "      <td>4.301</td>\n",
       "      <td>4.292</td>\n",
       "      <td>4.283</td>\n",
       "      <td>4.274</td>\n",
       "      <td>4.266</td>\n",
       "      <td>4.257</td>\n",
       "      <td>4.249</td>\n",
       "      <td>4.240</td>\n",
       "      <td>4.231</td>\n",
       "      <td>4.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.635</td>\n",
       "      <td>11.573</td>\n",
       "      <td>11.513</td>\n",
       "      <td>11.450</td>\n",
       "      <td>11.387</td>\n",
       "      <td>11.319</td>\n",
       "      <td>11.250</td>\n",
       "      <td>11.182</td>\n",
       "      <td>11.108</td>\n",
       "      <td>11.036</td>\n",
       "      <td>...</td>\n",
       "      <td>4.703</td>\n",
       "      <td>4.694</td>\n",
       "      <td>4.684</td>\n",
       "      <td>4.675</td>\n",
       "      <td>4.666</td>\n",
       "      <td>4.656</td>\n",
       "      <td>4.647</td>\n",
       "      <td>4.638</td>\n",
       "      <td>4.628</td>\n",
       "      <td>4.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.357</td>\n",
       "      <td>22.204</td>\n",
       "      <td>22.049</td>\n",
       "      <td>21.893</td>\n",
       "      <td>21.734</td>\n",
       "      <td>21.570</td>\n",
       "      <td>21.399</td>\n",
       "      <td>21.223</td>\n",
       "      <td>21.038</td>\n",
       "      <td>20.845</td>\n",
       "      <td>...</td>\n",
       "      <td>7.052</td>\n",
       "      <td>7.042</td>\n",
       "      <td>7.027</td>\n",
       "      <td>7.020</td>\n",
       "      <td>7.011</td>\n",
       "      <td>7.005</td>\n",
       "      <td>6.993</td>\n",
       "      <td>6.978</td>\n",
       "      <td>6.971</td>\n",
       "      <td>6.955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val_loss_epoch_1  val_loss_epoch_2  val_loss_epoch_3  val_loss_epoch_4  \\\n",
       "count        100000.000        100000.000        100000.000        100000.000   \n",
       "mean             10.190            10.138            10.086            10.033   \n",
       "std               2.385             2.362             2.339             2.316   \n",
       "min               3.980             3.975             3.970             3.965   \n",
       "25%               8.454             8.419             8.384             8.348   \n",
       "50%               9.918             9.870             9.823             9.774   \n",
       "75%              11.635            11.573            11.513            11.450   \n",
       "max              22.357            22.204            22.049            21.893   \n",
       "\n",
       "       val_loss_epoch_5  val_loss_epoch_6  val_loss_epoch_7  val_loss_epoch_8  \\\n",
       "count        100000.000        100000.000        100000.000        100000.000   \n",
       "mean              9.980             9.926             9.871             9.815   \n",
       "std               2.292             2.268             2.244             2.218   \n",
       "min               3.959             3.954             3.949             3.944   \n",
       "25%               8.311             8.274             8.237             8.199   \n",
       "50%               9.728             9.681             9.631             9.579   \n",
       "75%              11.387            11.319            11.250            11.182   \n",
       "max              21.734            21.570            21.399            21.223   \n",
       "\n",
       "       val_loss_epoch_9  val_loss_epoch_10  ...  val_loss_epoch_191  \\\n",
       "count        100000.000         100000.000  ...          100000.000   \n",
       "mean              9.756              9.696  ...               4.321   \n",
       "std               2.192              2.164  ...               0.583   \n",
       "min               3.939              3.934  ...               2.098   \n",
       "25%               8.159              8.118  ...               3.917   \n",
       "50%               9.524              9.469  ...               4.301   \n",
       "75%              11.108             11.036  ...               4.703   \n",
       "max              21.038             20.845  ...               7.052   \n",
       "\n",
       "       val_loss_epoch_192  val_loss_epoch_193  val_loss_epoch_194  \\\n",
       "count          100000.000          100000.000          100000.000   \n",
       "mean                4.313               4.304               4.295   \n",
       "std                 0.582               0.581               0.580   \n",
       "min                 2.094               2.085               2.078   \n",
       "25%                 3.909               3.901               3.893   \n",
       "50%                 4.292               4.283               4.274   \n",
       "75%                 4.694               4.684               4.675   \n",
       "max                 7.042               7.027               7.020   \n",
       "\n",
       "       val_loss_epoch_195  val_loss_epoch_196  val_loss_epoch_197  \\\n",
       "count          100000.000          100000.000          100000.000   \n",
       "mean                4.286               4.277               4.269   \n",
       "std                 0.579               0.578               0.577   \n",
       "min                 2.071               2.069               2.061   \n",
       "25%                 3.885               3.877               3.869   \n",
       "50%                 4.266               4.257               4.249   \n",
       "75%                 4.666               4.656               4.647   \n",
       "max                 7.011               7.005               6.993   \n",
       "\n",
       "       val_loss_epoch_198  val_loss_epoch_199  val_loss_epoch_200  \n",
       "count          100000.000          100000.000          100000.000  \n",
       "mean                4.260               4.251               4.243  \n",
       "std                 0.576               0.575               0.574  \n",
       "min                 2.058               2.050               2.043  \n",
       "25%                 3.861               3.853               3.845  \n",
       "50%                 4.240               4.231               4.223  \n",
       "75%                 4.638               4.628               4.619  \n",
       "max                 6.978               6.971               6.955  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:05:27.856447Z",
     "start_time": "2020-12-30T19:05:26.547728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_epoch_1</th>\n",
       "      <th>metric_epoch_2</th>\n",
       "      <th>metric_epoch_3</th>\n",
       "      <th>metric_epoch_4</th>\n",
       "      <th>metric_epoch_5</th>\n",
       "      <th>metric_epoch_6</th>\n",
       "      <th>metric_epoch_7</th>\n",
       "      <th>metric_epoch_8</th>\n",
       "      <th>metric_epoch_9</th>\n",
       "      <th>metric_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>metric_epoch_191</th>\n",
       "      <th>metric_epoch_192</th>\n",
       "      <th>metric_epoch_193</th>\n",
       "      <th>metric_epoch_194</th>\n",
       "      <th>metric_epoch_195</th>\n",
       "      <th>metric_epoch_196</th>\n",
       "      <th>metric_epoch_197</th>\n",
       "      <th>metric_epoch_198</th>\n",
       "      <th>metric_epoch_199</th>\n",
       "      <th>metric_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.080</td>\n",
       "      <td>1.098</td>\n",
       "      <td>1.129</td>\n",
       "      <td>1.165</td>\n",
       "      <td>1.205</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.294</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1.382</td>\n",
       "      <td>1.428</td>\n",
       "      <td>...</td>\n",
       "      <td>3.727</td>\n",
       "      <td>3.711</td>\n",
       "      <td>3.720</td>\n",
       "      <td>3.725</td>\n",
       "      <td>3.706</td>\n",
       "      <td>3.713</td>\n",
       "      <td>3.741</td>\n",
       "      <td>3.731</td>\n",
       "      <td>3.727</td>\n",
       "      <td>3.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.486</td>\n",
       "      <td>4.587</td>\n",
       "      <td>4.579</td>\n",
       "      <td>4.868</td>\n",
       "      <td>5.325</td>\n",
       "      <td>5.742</td>\n",
       "      <td>6.860</td>\n",
       "      <td>7.159</td>\n",
       "      <td>8.042</td>\n",
       "      <td>8.871</td>\n",
       "      <td>...</td>\n",
       "      <td>69.278</td>\n",
       "      <td>69.241</td>\n",
       "      <td>70.441</td>\n",
       "      <td>72.345</td>\n",
       "      <td>71.502</td>\n",
       "      <td>72.758</td>\n",
       "      <td>79.665</td>\n",
       "      <td>81.008</td>\n",
       "      <td>79.284</td>\n",
       "      <td>73.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.012</td>\n",
       "      <td>...</td>\n",
       "      <td>1.177</td>\n",
       "      <td>1.176</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.170</td>\n",
       "      <td>1.168</td>\n",
       "      <td>1.166</td>\n",
       "      <td>1.164</td>\n",
       "      <td>1.161</td>\n",
       "      <td>1.159</td>\n",
       "      <td>1.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.009</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.016</td>\n",
       "      <td>1.022</td>\n",
       "      <td>1.030</td>\n",
       "      <td>1.038</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.057</td>\n",
       "      <td>1.068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.585</td>\n",
       "      <td>1.581</td>\n",
       "      <td>1.578</td>\n",
       "      <td>1.575</td>\n",
       "      <td>1.572</td>\n",
       "      <td>1.569</td>\n",
       "      <td>1.566</td>\n",
       "      <td>1.564</td>\n",
       "      <td>1.560</td>\n",
       "      <td>1.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.028</td>\n",
       "      <td>1.032</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.060</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.098</td>\n",
       "      <td>1.119</td>\n",
       "      <td>1.142</td>\n",
       "      <td>1.166</td>\n",
       "      <td>1.191</td>\n",
       "      <td>...</td>\n",
       "      <td>2.274</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.259</td>\n",
       "      <td>2.256</td>\n",
       "      <td>2.253</td>\n",
       "      <td>2.245</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.239</td>\n",
       "      <td>2.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1362.852</td>\n",
       "      <td>1348.627</td>\n",
       "      <td>1209.645</td>\n",
       "      <td>1158.800</td>\n",
       "      <td>1083.120</td>\n",
       "      <td>1003.175</td>\n",
       "      <td>1133.827</td>\n",
       "      <td>1094.842</td>\n",
       "      <td>1365.855</td>\n",
       "      <td>1507.149</td>\n",
       "      <td>...</td>\n",
       "      <td>12168.191</td>\n",
       "      <td>12104.181</td>\n",
       "      <td>12648.434</td>\n",
       "      <td>13400.329</td>\n",
       "      <td>13366.910</td>\n",
       "      <td>13353.757</td>\n",
       "      <td>17493.268</td>\n",
       "      <td>18204.928</td>\n",
       "      <td>14905.922</td>\n",
       "      <td>14596.217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       metric_epoch_1  metric_epoch_2  metric_epoch_3  metric_epoch_4  \\\n",
       "count      100000.000      100000.000      100000.000      100000.000   \n",
       "mean            1.080           1.098           1.129           1.165   \n",
       "std             4.486           4.587           4.579           4.868   \n",
       "min             0.966           0.945           0.930           0.910   \n",
       "25%             1.000           0.997           0.997           0.997   \n",
       "50%             1.009           1.008           1.011           1.016   \n",
       "75%             1.028           1.032           1.044           1.060   \n",
       "max          1362.852        1348.627        1209.645        1158.800   \n",
       "\n",
       "       metric_epoch_5  metric_epoch_6  metric_epoch_7  metric_epoch_8  \\\n",
       "count      100000.000      100000.000      100000.000      100000.000   \n",
       "mean            1.205           1.246           1.294           1.335   \n",
       "std             5.325           5.742           6.860           7.159   \n",
       "min             0.889           0.867           0.854           0.830   \n",
       "25%             0.998           1.000           1.002           1.005   \n",
       "50%             1.022           1.030           1.038           1.047   \n",
       "75%             1.078           1.098           1.119           1.142   \n",
       "max          1083.120        1003.175        1133.827        1094.842   \n",
       "\n",
       "       metric_epoch_9  metric_epoch_10  ...  metric_epoch_191  \\\n",
       "count      100000.000       100000.000  ...        100000.000   \n",
       "mean            1.382            1.428  ...             3.727   \n",
       "std             8.042            8.871  ...            69.278   \n",
       "min             0.813            0.790  ...             0.197   \n",
       "25%             1.008            1.012  ...             1.177   \n",
       "50%             1.057            1.068  ...             1.585   \n",
       "75%             1.166            1.191  ...             2.274   \n",
       "max          1365.855         1507.149  ...         12168.191   \n",
       "\n",
       "       metric_epoch_192  metric_epoch_193  metric_epoch_194  metric_epoch_195  \\\n",
       "count        100000.000        100000.000        100000.000        100000.000   \n",
       "mean              3.711             3.720             3.725             3.706   \n",
       "std              69.241            70.441            72.345            71.502   \n",
       "min               0.197             0.196             0.196             0.194   \n",
       "25%               1.176             1.173             1.170             1.168   \n",
       "50%               1.581             1.578             1.575             1.572   \n",
       "75%               2.269             2.265             2.259             2.256   \n",
       "max           12104.181         12648.434         13400.329         13366.910   \n",
       "\n",
       "       metric_epoch_196  metric_epoch_197  metric_epoch_198  metric_epoch_199  \\\n",
       "count        100000.000        100000.000        100000.000        100000.000   \n",
       "mean              3.713             3.741             3.731             3.727   \n",
       "std              72.758            79.665            81.008            79.284   \n",
       "min               0.192             0.195             0.192             0.190   \n",
       "25%               1.166             1.164             1.161             1.159   \n",
       "50%               1.569             1.566             1.564             1.560   \n",
       "75%               2.253             2.245             2.242             2.239   \n",
       "max           13353.757         17493.268         18204.928         14905.922   \n",
       "\n",
       "       metric_epoch_200  \n",
       "count        100000.000  \n",
       "mean              3.689  \n",
       "std              73.285  \n",
       "min               0.190  \n",
       "25%               1.157  \n",
       "50%               1.557  \n",
       "75%               2.235  \n",
       "max           14596.217  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:05:29.166606Z",
     "start_time": "2020-12-30T19:05:27.858012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_metric_epoch_1</th>\n",
       "      <th>val_metric_epoch_2</th>\n",
       "      <th>val_metric_epoch_3</th>\n",
       "      <th>val_metric_epoch_4</th>\n",
       "      <th>val_metric_epoch_5</th>\n",
       "      <th>val_metric_epoch_6</th>\n",
       "      <th>val_metric_epoch_7</th>\n",
       "      <th>val_metric_epoch_8</th>\n",
       "      <th>val_metric_epoch_9</th>\n",
       "      <th>val_metric_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>val_metric_epoch_191</th>\n",
       "      <th>val_metric_epoch_192</th>\n",
       "      <th>val_metric_epoch_193</th>\n",
       "      <th>val_metric_epoch_194</th>\n",
       "      <th>val_metric_epoch_195</th>\n",
       "      <th>val_metric_epoch_196</th>\n",
       "      <th>val_metric_epoch_197</th>\n",
       "      <th>val_metric_epoch_198</th>\n",
       "      <th>val_metric_epoch_199</th>\n",
       "      <th>val_metric_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.076</td>\n",
       "      <td>1.105</td>\n",
       "      <td>1.141</td>\n",
       "      <td>1.180</td>\n",
       "      <td>1.222</td>\n",
       "      <td>1.266</td>\n",
       "      <td>1.312</td>\n",
       "      <td>1.359</td>\n",
       "      <td>1.409</td>\n",
       "      <td>1.459</td>\n",
       "      <td>...</td>\n",
       "      <td>3.568</td>\n",
       "      <td>3.559</td>\n",
       "      <td>3.553</td>\n",
       "      <td>3.544</td>\n",
       "      <td>3.537</td>\n",
       "      <td>3.532</td>\n",
       "      <td>3.526</td>\n",
       "      <td>3.518</td>\n",
       "      <td>3.510</td>\n",
       "      <td>3.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.415</td>\n",
       "      <td>3.345</td>\n",
       "      <td>4.485</td>\n",
       "      <td>5.712</td>\n",
       "      <td>6.998</td>\n",
       "      <td>8.312</td>\n",
       "      <td>9.662</td>\n",
       "      <td>11.046</td>\n",
       "      <td>12.475</td>\n",
       "      <td>13.962</td>\n",
       "      <td>...</td>\n",
       "      <td>71.541</td>\n",
       "      <td>71.220</td>\n",
       "      <td>70.899</td>\n",
       "      <td>70.533</td>\n",
       "      <td>70.248</td>\n",
       "      <td>70.207</td>\n",
       "      <td>70.175</td>\n",
       "      <td>69.717</td>\n",
       "      <td>69.556</td>\n",
       "      <td>69.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.943</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.987</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.006</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.002</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.004</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.017</td>\n",
       "      <td>1.022</td>\n",
       "      <td>1.028</td>\n",
       "      <td>1.035</td>\n",
       "      <td>...</td>\n",
       "      <td>1.404</td>\n",
       "      <td>1.401</td>\n",
       "      <td>1.399</td>\n",
       "      <td>1.397</td>\n",
       "      <td>1.394</td>\n",
       "      <td>1.392</td>\n",
       "      <td>1.390</td>\n",
       "      <td>1.388</td>\n",
       "      <td>1.385</td>\n",
       "      <td>1.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.019</td>\n",
       "      <td>1.025</td>\n",
       "      <td>1.035</td>\n",
       "      <td>1.049</td>\n",
       "      <td>1.064</td>\n",
       "      <td>1.080</td>\n",
       "      <td>1.098</td>\n",
       "      <td>1.116</td>\n",
       "      <td>1.135</td>\n",
       "      <td>1.156</td>\n",
       "      <td>...</td>\n",
       "      <td>2.085</td>\n",
       "      <td>2.081</td>\n",
       "      <td>2.078</td>\n",
       "      <td>2.074</td>\n",
       "      <td>2.070</td>\n",
       "      <td>2.067</td>\n",
       "      <td>2.064</td>\n",
       "      <td>2.060</td>\n",
       "      <td>2.057</td>\n",
       "      <td>2.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>428.249</td>\n",
       "      <td>676.813</td>\n",
       "      <td>923.575</td>\n",
       "      <td>1170.849</td>\n",
       "      <td>1423.072</td>\n",
       "      <td>1675.310</td>\n",
       "      <td>1931.698</td>\n",
       "      <td>2190.271</td>\n",
       "      <td>2452.786</td>\n",
       "      <td>2725.717</td>\n",
       "      <td>...</td>\n",
       "      <td>16108.671</td>\n",
       "      <td>16087.579</td>\n",
       "      <td>15984.409</td>\n",
       "      <td>15915.147</td>\n",
       "      <td>15846.126</td>\n",
       "      <td>15836.391</td>\n",
       "      <td>15864.684</td>\n",
       "      <td>15731.683</td>\n",
       "      <td>15731.523</td>\n",
       "      <td>15705.777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val_metric_epoch_1  val_metric_epoch_2  val_metric_epoch_3  \\\n",
       "count          100000.000          100000.000          100000.000   \n",
       "mean                1.076               1.105               1.141   \n",
       "std                 2.415               3.345               4.485   \n",
       "min                 0.943               0.918               0.902   \n",
       "25%                 0.993               0.990               0.988   \n",
       "50%                 1.002               1.001               1.002   \n",
       "75%                 1.019               1.025               1.035   \n",
       "max               428.249             676.813             923.575   \n",
       "\n",
       "       val_metric_epoch_4  val_metric_epoch_5  val_metric_epoch_6  \\\n",
       "count          100000.000          100000.000          100000.000   \n",
       "mean                1.180               1.222               1.266   \n",
       "std                 5.712               6.998               8.312   \n",
       "min                 0.889               0.866               0.843   \n",
       "25%                 0.987               0.986               0.986   \n",
       "50%                 1.004               1.008               1.012   \n",
       "75%                 1.049               1.064               1.080   \n",
       "max              1170.849            1423.072            1675.310   \n",
       "\n",
       "       val_metric_epoch_7  val_metric_epoch_8  val_metric_epoch_9  \\\n",
       "count          100000.000          100000.000          100000.000   \n",
       "mean                1.312               1.359               1.409   \n",
       "std                 9.662              11.046              12.475   \n",
       "min                 0.822               0.800               0.777   \n",
       "25%                 0.986               0.986               0.986   \n",
       "50%                 1.017               1.022               1.028   \n",
       "75%                 1.098               1.116               1.135   \n",
       "max              1931.698            2190.271            2452.786   \n",
       "\n",
       "       val_metric_epoch_10  ...  val_metric_epoch_191  val_metric_epoch_192  \\\n",
       "count           100000.000  ...            100000.000            100000.000   \n",
       "mean                 1.459  ...                 3.568                 3.559   \n",
       "std                 13.962  ...                71.541                71.220   \n",
       "min                  0.749  ...                 0.208                 0.208   \n",
       "25%                  0.987  ...                 1.015                 1.013   \n",
       "50%                  1.035  ...                 1.404                 1.401   \n",
       "75%                  1.156  ...                 2.085                 2.081   \n",
       "max               2725.717  ...             16108.671             16087.579   \n",
       "\n",
       "       val_metric_epoch_193  val_metric_epoch_194  val_metric_epoch_195  \\\n",
       "count            100000.000            100000.000            100000.000   \n",
       "mean                  3.553                 3.544                 3.537   \n",
       "std                  70.899                70.533                70.248   \n",
       "min                   0.207                 0.207                 0.206   \n",
       "25%                   1.012                 1.010                 1.008   \n",
       "50%                   1.399                 1.397                 1.394   \n",
       "75%                   2.078                 2.074                 2.070   \n",
       "max               15984.409             15915.147             15846.126   \n",
       "\n",
       "       val_metric_epoch_196  val_metric_epoch_197  val_metric_epoch_198  \\\n",
       "count            100000.000            100000.000            100000.000   \n",
       "mean                  3.532                 3.526                 3.518   \n",
       "std                  70.207                70.175                69.717   \n",
       "min                   0.206                 0.204                 0.204   \n",
       "25%                   1.006                 1.005                 1.003   \n",
       "50%                   1.392                 1.390                 1.388   \n",
       "75%                   2.067                 2.064                 2.060   \n",
       "max               15836.391             15864.684             15731.683   \n",
       "\n",
       "       val_metric_epoch_199  val_metric_epoch_200  \n",
       "count            100000.000            100000.000  \n",
       "mean                  3.510                 3.503  \n",
       "std                  69.556                69.278  \n",
       "min                   0.204                 0.204  \n",
       "25%                   1.001                 0.999  \n",
       "50%                   1.385                 1.383  \n",
       "75%                   2.057                 2.053  \n",
       "max               15731.523             15705.777  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:05:32.320412Z",
     "start_time": "2020-12-30T19:05:29.168132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for metric\n",
    "path = './data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.png'\n",
    "\n",
    "adjustment_threshold_metric = 0#100\n",
    "    \n",
    "metric_df_adjusted = metric_df.copy(deep=True)\n",
    "if adjustment_threshold_metric > 0:\n",
    "    metric_df_adjusted[metric_df_adjusted.columns] = np.where(metric_df_adjusted[metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, metric_df_adjusted[metric_df_adjusted.columns])\n",
    "    \n",
    "val_metric_df_adjusted = val_metric_df.copy(deep=True)\n",
    "if adjustment_threshold_metric > 0:\n",
    "    val_metric_df_adjusted[val_metric_df_adjusted.columns] = np.where(val_metric_df_adjusted[val_metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, val_metric_df_adjusted[val_metric_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model metric')\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T19:05:35.284421Z",
     "start_time": "2020-12-30T19:05:32.322050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "path = './data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/loss_' + str(data_size) +  '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_amax_' + str(a_max) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.png'\n",
    "\n",
    "adjustment_threshold_loss = 0#10000\n",
    "    \n",
    "loss_df_adjusted = loss_df.copy(deep=True)\n",
    "\n",
    "if adjustment_threshold_loss > 0:\n",
    "    loss_df_adjusted[loss_df_adjusted.columns] = np.where(loss_df_adjusted[loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, loss_df_adjusted[loss_df_adjusted.columns])\n",
    "    \n",
    "val_loss_df_adjusted = val_loss_df.copy(deep=True)\n",
    "if adjustment_threshold_loss > 0:\n",
    "    val_loss_df_adjusted[val_loss_df_adjusted.columns] = np.where(val_loss_df_adjusted[val_loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, val_loss_df_adjusted[val_loss_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['trainover', 'valid'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
