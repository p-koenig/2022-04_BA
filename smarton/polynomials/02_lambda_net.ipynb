{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Î»-Nets for I-Net training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:40:59.747550Z",
     "start_time": "2020-11-23T18:40:59.740976Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def nCr(n,r):\n",
    "    f = math.factorial\n",
    "    return f(n) // f(r) // f(n-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:40:59.770391Z",
     "start_time": "2020-11-23T18:40:59.756857Z"
    }
   },
   "outputs": [],
   "source": [
    "d = 3\n",
    "n = 4\n",
    "sparsity = nCr(n+d, d)\n",
    "\n",
    "\n",
    "x_max = 1#10 #this number excluded\n",
    "x_min = -1#-10\n",
    "x_step = 0.01#0.1\n",
    "a_max = 10 #this number excluded\n",
    "a_min = -10\n",
    "a_step = 0.1\n",
    "\n",
    "lambda_dataset_size = 1000 #specify the number of data points to train the lambda net on for loading (must be same as in previous notebook)\n",
    "\n",
    "number_formulas_load = 100 #manually specify number of formulas for loading file (must be the same as used in the previous notebook)\n",
    "number_of_lambda_nets = number_formulas_load #use this parameter to select how many lambda nets should be generated (must be smaller or equal to number_formulas_load)\n",
    "\n",
    "\n",
    "#lambda net specifications \n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "lambda_network_layers = [5*sparsity]\n",
    "dropout = 0.0\n",
    "optimizer='SGD'\n",
    "\n",
    "each_epochs_save = None#10  #specifies the number of epochs to checkpoint lambda network weights, if None no checkpointing\n",
    "\n",
    "same_training_all_lambda_nets = False\n",
    "fixed_seed_lambda_training = True\n",
    "\n",
    "\n",
    "n_jobs = -3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:40:59.788651Z",
     "start_time": "2020-11-23T18:40:59.773637Z"
    }
   },
   "outputs": [],
   "source": [
    "##############DO NOT CHANGE###################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "if each_epochs_save != None:\n",
    "    epochs_save_range = range(1, epochs//each_epochs_save+1) if each_epochs_save == 1 else range(epochs//each_epochs_save+1)\n",
    "else:\n",
    "    epochs_save_range = None\n",
    "    \n",
    "layers_str = ''.join([str(neurons) + '-' for neurons in lambda_network_layers])\n",
    "\n",
    "advanced_metric_dataset_size = 10#200\n",
    "\n",
    "if same_training_all_lambda_nets:\n",
    "    training_string = '_same'\n",
    "else:\n",
    "    training_string = '_diverse'\n",
    "\n",
    "generate_subset = True if number_of_lambda_nets < number_formulas_load else False\n",
    "\n",
    "    \n",
    "if generate_subset:\n",
    "    data_size = number_of_lambda_nets\n",
    "else:\n",
    "    data_size = number_formulas_load\n",
    "\n",
    "if fixed_seed_lambda_training:\n",
    "    seed_shuffle_string = '_SeedMethod'\n",
    "elif not fixed_seed_lambda_training:\n",
    "    seed_shuffle_string = '_NoSeedMethod'\n",
    "    \n",
    "use_gpu = False\n",
    "if use_gpu:\n",
    "    gpu_numbers = '0'\n",
    "else:\n",
    "    gpu_numbers = ''\n",
    "    \n",
    "structure = '_' + layers_str + str(epochs) + 'e' + str(batch_size) + 'b_' + optimizer \n",
    "    \n",
    "filename = seed_shuffle_string + '_' + str(RANDOM_SEED) + structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:06.752236Z",
     "start_time": "2020-11-23T18:40:59.791824Z"
    }
   },
   "outputs": [],
   "source": [
    "import ttg\n",
    "from itertools import product       # forms cartesian products\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from more_itertools import random_product \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import math\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "from IPython.display import Image\n",
    "\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import random \n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "#keras.backend.set_epsilon(10e-3)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:06.763778Z",
     "start_time": "2020-11-23T18:41:06.756140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:06.788904Z",
     "start_time": "2020-11-23T18:41:06.766572Z"
    }
   },
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s2, s3), (s4, s5), ...\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "def chunks(lst, chunksize):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), chunksize):\n",
    "        yield lst[i:i + chunksize]\n",
    "\n",
    "#test for exact equality\n",
    "def arreq_in_list(myarr, list_arrays):\n",
    "    return next((True for elem in list_arrays if np.array_equal(elem, myarr)), False)\n",
    "\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "\n",
    "ALPHABET = \\\n",
    "  \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "def encode (n):\n",
    "    try:\n",
    "        return ALPHABET [n]\n",
    "    except IndexError:\n",
    "        raise Exception (\"cannot encode: %s\" % n)\n",
    "        \n",
    "def dec_to_base (dec = 0, base = 16):\n",
    "    if dec < base:\n",
    "        return encode (dec)\n",
    "    else:\n",
    "        return dec_to_base (dec // base, base) + encode (dec % base)\n",
    "    \n",
    "    \n",
    "def mergeDict(dict1, dict2):\n",
    "    #Merge dictionaries and keep values of common keys in list\n",
    "    newDict = {**dict1, **dict2}\n",
    "    for key, value in newDict.items():\n",
    "        if key in dict1 and key in dict2:\n",
    "            if isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend(value)\n",
    "            elif isinstance(dict1[key], list) and not isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend([value])\n",
    "            elif not isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = [dict1[key]]\n",
    "                newDict[key].extend(value)\n",
    "            else:\n",
    "                newDict[key] = [dict1[key], value]\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss/Error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:06.802375Z",
     "start_time": "2020-11-23T18:41:06.791248Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def calcualate_function_value_with_X_data_entry(coefficient_list, X_data_entry):\n",
    "    \n",
    "    global list_of_monomial_identifiers\n",
    "     \n",
    "    result = 0    \n",
    "    for coefficient_value, coefficient_multipliers in zip(coefficient_list, list_of_monomial_identifiers):\n",
    "        partial_results = [X_data_value**int(coefficient_multiplier) for coefficient_multiplier, X_data_value in zip(coefficient_multipliers, X_data_entry)]\n",
    "        \n",
    "        result += coefficient_value * reduce(lambda x, y: x*y, partial_results)\n",
    "        \n",
    "    return result, np.append(X_data_entry, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:06.854383Z",
     "start_time": "2020-11-23T18:41:06.806352Z"
    },
    "code_folding": [
     0,
     20,
     43,
     66,
     88,
     91,
     103
    ]
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "        \n",
    "    if tf.is_tensor(y_true):\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    else:\n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    if tf.is_tensor(y_pred):\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "    else:\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "            \n",
    "            \n",
    "    return tf.math.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "def accuracy_multilabel(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    if 'float' in str(y_true[0].dtype):        \n",
    "        if tf.is_tensor(y_true):\n",
    "            y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "        else:\n",
    "            y_true = y_true.astype('float32')\n",
    "        if tf.is_tensor(y_pred):\n",
    "            y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        else:\n",
    "            y_pred = y_pred.astype('float32')\n",
    "            \n",
    "        n_digits = int(-np.log10(a_step))\n",
    "        \n",
    "        y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "        y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(tf.reduce_all(K.equal(y_true, y_pred), axis=1), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def accuracy_single(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    if 'float' in str(y_true[0].dtype):        \n",
    "        if tf.is_tensor(y_true):\n",
    "            y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "        else:\n",
    "            y_true = y_true.astype('float32')\n",
    "        if tf.is_tensor(y_pred):\n",
    "            y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        else:\n",
    "            y_pred = y_pred.astype('float32')\n",
    "            \n",
    "        n_digits = int(-np.log10(a_step))\n",
    "        \n",
    "        y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "        y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(K.equal(y_true, y_pred), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def mean_absolute_percentage_error_keras(y_true, y_pred, epsilon=10e-3): \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values    \n",
    "        \n",
    "    if tf.is_tensor(y_true):\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    else:\n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    if tf.is_tensor(y_pred):\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "    else:\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        \n",
    "    epsilon = tf.convert_to_tensor(epsilon)\n",
    "    epsilon = tf.dtypes.cast(epsilon, tf.float32)\n",
    "        \n",
    "    return tf.reduce_mean(tf.abs(tf.divide(tf.subtract(y_pred, y_true),(y_true + epsilon))))\n",
    "\n",
    "def huber_loss_delta_set(y_true, y_pred):\n",
    "    return keras.losses.huber_loss(y_true, y_pred, delta=0.3)\n",
    "\n",
    "def relative_absolute_average_error(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "       \n",
    "    #error value calculation    \n",
    "    result = np.sum(np.abs(y_true-y_pred))/(y_true.shape[0]*np.std(y_true)) #correct STD?\n",
    "    \n",
    "    return result\n",
    "\n",
    "def relative_maximum_average_error(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    #error value calculation    \n",
    "    result = np.max(y_true-y_pred)/np.std(y_true) #correct STD?\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of Monomial Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:06.947508Z",
     "start_time": "2020-11-23T18:41:06.858119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f77745e7f5424dad99736484c63e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 256\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0013', '0020', '0021', '0022', '0023', '0030', '0031', '0032', '0033', '0100', '0101', '0102', '0103', '0110', '0111', '0112', '0113', '0120', '0121', '0122', '0123', '0130', '0131', '0132', '0133', '0200', '0201', '0202', '0203', '0210', '0211', '0212', '0213', '0220', '0221', '0222', '0223', '0230', '0231', '0232', '0233', '0300', '0301', '0302', '0303', '0310', '0311', '0312', '0313', '0320', '0321', '0322', '0323', '0330', '0331', '0332', '0333', '1000', '1001', '1002', '1003', '1010', '1011', '1012', '1013', '1020', '1021', '1022', '1023', '1030', '1031', '1032', '1033', '1100', '1101', '1102', '1103', '1110', '1111', '1112', '1113', '1120', '1121', '1122', '1123', '1130', '1131', '1132', '1133', '1200', '1201', '1202', '1203', '1210', '1211', '1212', '1213', '1220', '1221', '1222', '1223', '1230', '1231', '1232', '1233', '1300', '1301', '1302', '1303', '1310', '1311', '1312', '1313', '1320', '1321', '1322', '1323', '1330', '1331', '1332', '1333', '2000', '2001', '2002', '2003', '2010', '2011', '2012', '2013', '2020', '2021', '2022', '2023', '2030', '2031', '2032', '2033', '2100', '2101', '2102', '2103', '2110', '2111', '2112', '2113', '2120', '2121', '2122', '2123', '2130', '2131', '2132', '2133', '2200', '2201', '2202', '2203', '2210', '2211', '2212', '2213', '2220', '2221', '2222', '2223', '2230', '2231', '2232', '2233', '2300', '2301', '2302', '2303', '2310', '2311', '2312', '2313', '2320', '2321', '2322', '2323', '2330', '2331', '2332', '2333', '3000', '3001', '3002', '3003', '3010', '3011', '3012', '3013', '3020', '3021', '3022', '3023', '3030', '3031', '3032', '3033', '3100', '3101', '3102', '3103', '3110', '3111', '3112', '3113', '3120', '3121', '3122', '3123', '3130', '3131', '3132', '3133', '3200', '3201', '3202', '3203', '3210', '3211', '3212', '3213', '3220', '3221', '3222', '3223', '3230', '3231', '3232', '3233', '3300', '3301', '3302', '3303', '3310', '3311', '3312', '3313', '3320', '3321', '3322', '3323', '3330', '3331', '3332', '3333']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e080099d964102af82aa57cf8d4cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 35\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0020', '0021', '0030', '0100', '0101', '0102', '0110', '0111', '0120', '0200', '0201', '0210', '0300', '1000', '1001', '1002', '1010', '1011', '1020', '1100', '1101', '1110', '1200', '2000', '2001', '2010', '2100', '3000']\n"
     ]
    }
   ],
   "source": [
    "list_of_monomial_identifiers_extended = []\n",
    "for i in tqdm(range((d+1)**n)):    \n",
    "    monomial_identifier = dec_to_base(i, base = (d+1)).zfill(n) \n",
    "    list_of_monomial_identifiers_extended.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers_extended)\n",
    "\n",
    "list_of_monomial_identifiers = []\n",
    "for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "    monomial_identifier_values = list(map(int, list(monomial_identifier)))\n",
    "    if sum(monomial_identifier_values) <= d:\n",
    "        list_of_monomial_identifiers.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.115692Z",
     "start_time": "2020-11-23T18:41:06.949837Z"
    }
   },
   "outputs": [],
   "source": [
    "path_polynomials = './data/saved_polynomial_lists/polynomials_sample' + str(number_formulas_load) + '_variables_' + str(n) +  '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step) + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '.csv'\n",
    "polynomials_list_df = pd.read_csv(path_polynomials)\n",
    "\n",
    "path_X_data = './data/saved_polynomial_lists/X_sample' + str(number_formulas_load) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) +  training_string + '.pkl'\n",
    "with open(path_X_data, 'rb') as f:\n",
    "    X_data_list = pickle.load(f)\n",
    "    \n",
    "path_y_data = './data/saved_polynomial_lists/y_sample' + str(number_formulas_load) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) +  training_string + '.pkl'\n",
    "with open(path_y_data, 'rb') as f:\n",
    "    y_data_list = pickle.load(f)\n",
    "    \n",
    "if generate_subset:\n",
    "    polynomials_list_df = polynomials_list_df.sample(n=number_of_lambda_nets, random_state=RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    X_data_list = random.sample(X_data_list, number_of_lambda_nets)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    y_data_list = random.sample(y_data_list, number_of_lambda_nets)\n",
    "    random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.158270Z",
     "start_time": "2020-11-23T18:41:07.118623Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#clear files\n",
    "if each_epochs_save != None:\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        \n",
    "        for i in epochs_save_range:\n",
    "            index = i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "            path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size)  + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(index).zfill(3)  + filename + '.txt'\n",
    "\n",
    "            with open(path, 'wt') as text_file:\n",
    "                text_file.truncate()   \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "else:\n",
    "    \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "\n",
    "        path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "        with open(path, 'wt') as text_file:\n",
    "            text_file.truncate()   \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.183101Z",
     "start_time": "2020-11-23T18:41:07.161153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.180</td>\n",
       "      <td>0.720</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>-0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.880</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3\n",
       "0 -0.490 -0.360 -0.170 -0.490\n",
       "1  0.820  0.110 -0.700  0.520\n",
       "2  0.180  0.720 -0.560 -0.390\n",
       "3  0.710  0.880 -0.490 -0.880\n",
       "4 -0.300 -0.210 -0.480 -0.030"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.197178Z",
     "start_time": "2020-11-23T18:41:07.185531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.240</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3\n",
       "0 0.300  0.860  0.870  0.490\n",
       "1 0.380  0.600 -0.090 -0.870\n",
       "2 0.230 -0.280  0.170 -0.300\n",
       "3 0.590 -0.200 -0.170 -0.820\n",
       "4 0.240  0.260  0.100  0.170"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[1][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.206897Z",
     "start_time": "2020-11-23T18:41:07.199740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000    6.300\n",
       "0001   -7.200\n",
       "0002   -9.400\n",
       "0003    8.900\n",
       "0010   -3.000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.215627Z",
     "start_time": "2020-11-23T18:41:07.209508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000   -9.900\n",
       "0001    9.400\n",
       "0002   -6.000\n",
       "0003    7.800\n",
       "0010    0.800\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[1][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T17:06:36.919643Z",
     "start_time": "2020-09-16T17:06:36.912904Z"
    }
   },
   "source": [
    "## Lambda Network Training + Weigh/Bias saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.277778Z",
     "start_time": "2020-11-23T18:41:07.218106Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate_lambda_net(identifier, \n",
    "                        X_data_real_lambda, \n",
    "                        y_data_real_lambda, \n",
    "                        y_data_pred_lambda, \n",
    "                        y_data_pred_lambda_poly_lstsq, \n",
    "                        y_data_real_lambda_poly_lstsq):\n",
    "    \n",
    "    mae_real_VS_predLambda = np.round(mean_absolute_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    mae_real_VS_predPolyLstsq = np.round(mean_absolute_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    mae_predLambda_VS_predPolyLstsq = np.round(mean_absolute_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    mae_real_VS_realPolyLstsq = np.round(mean_absolute_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)    \n",
    "\n",
    "    rmse_real_VS_predLambda = np.round(root_mean_squared_error(y_data_real_lambda, y_data_pred_lambda), 4)    \n",
    "    rmse_real_VS_predPolyLstsq = np.round(root_mean_squared_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)    \n",
    "    rmse_predLambda_VS_predPolyLstsq = np.round(root_mean_squared_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)    \n",
    "    rmse_real_VS_realPolyLstsq = np.round(root_mean_squared_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)    \n",
    "\n",
    "    mape_real_VS_predLambda = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_pred_lambda), 4)    \n",
    "    mape_real_VS_predPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)    \n",
    "    mape_predLambda_VS_predPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)    \n",
    "    mape_real_VS_realPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)            \n",
    "\n",
    "    r2_real_VS_predLambda = np.round(r2_score(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    r2_real_VS_predPolyLstsq = np.round(r2_score(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    r2_predLambda_VS_predPolyLstsq = np.round(r2_score(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    r2_real_VS_realPolyLstsq = np.round(r2_score(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    raae_real_VS_predLambda = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    raae_real_VS_predPolyLstsq = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    raae_predLambda_VS_predPolyLstsq = np.round(relative_absolute_average_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    raae_real_VS_realPolyLstsq = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    rmae_real_VS_predLambda = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    rmae_real_VS_predPolyLstsq = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    rmae_predLambda_VS_predPolyLstsq = np.round(relative_maximum_average_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    rmae_real_VS_realPolyLstsq = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    fd_real_VS_predLambda = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size]))), 4)\n",
    "    fd_real_VS_predPolyLstsq = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size]))), 4)\n",
    "    fd_predLambda_VS_predPolyLstsq = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size]))), 4)\n",
    "    fd_real_VS_realPolyLstsq = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda_poly_lstsq[:advanced_metric_dataset_size]))), 4)\n",
    "\n",
    "    dtw_real_VS_predLambda, dtw_complete_real_VS_predLambda = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size])))\n",
    "    dtw_real_VS_predLambda = np.round(dtw_real_VS_predLambda, 4)\n",
    "    dtw_real_VS_predPolyLstsq, dtw_complete_real_VS_predPolyLstsq = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size])))\n",
    "    dtw_real_VS_predPolyLstsq = np.round(dtw_real_VS_predPolyLstsq, 4)\n",
    "    dtw_predLambda_VS_predPolyLstsq, dtw_complete_predLambda_VS_predPolyLstsq = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size])))\n",
    "    dtw_predLambda_VS_predPolyLstsq = np.round(dtw_predLambda_VS_predPolyLstsq, 4)    \n",
    "    dtw_real_VS_realPolyLstsq, dtw_complete_real_VS_realPolyLstsq = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda_poly_lstsq[:advanced_metric_dataset_size])))\n",
    "    dtw_real_VS_realPolyLstsq = np.round(dtw_real_VS_realPolyLstsq, 4) \n",
    "        \n",
    "    std_data_real_lambda = np.round(np.std(y_data_real_lambda), 4) \n",
    "    std_data_pred_lambda = np.round(np.std(y_data_pred_lambda), 4) \n",
    "    std_data_pred_lambda_poly_lstsq = np.round(np.std(y_data_pred_lambda_poly_lstsq), 4) \n",
    "    std_data_real_lambda_poly_lstsq = np.round(np.std(y_data_real_lambda_poly_lstsq), 4) \n",
    "\n",
    "    mean_data_real_lambda = np.round(np.mean(y_data_real_lambda), 4) \n",
    "    mean_data_pred_lambda = np.round(np.mean(y_data_pred_lambda), 4) \n",
    "    mean_data_pred_lambda_poly_lstsq = np.round(np.mean(y_data_pred_lambda_poly_lstsq), 4) \n",
    "    mean_data_real_lambda_poly_lstsq = np.round(np.mean(y_data_real_lambda_poly_lstsq), 4) \n",
    "\n",
    "    return [{\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': mae_real_VS_predLambda,\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': mae_real_VS_predPolyLstsq,\n",
    "             'MAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': mae_predLambda_VS_predPolyLstsq,\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': mae_real_VS_realPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': rmse_real_VS_predLambda,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': rmse_real_VS_predPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': rmse_predLambda_VS_predPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': rmse_real_VS_realPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': mape_real_VS_predLambda,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': mape_real_VS_predPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': mape_predLambda_VS_predPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': mape_real_VS_realPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': r2_real_VS_predLambda,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': r2_real_VS_predPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': r2_predLambda_VS_predPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': r2_real_VS_realPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': raae_real_VS_predLambda,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': raae_real_VS_predPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': raae_predLambda_VS_predPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': raae_real_VS_realPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': rmae_real_VS_predLambda,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': rmae_real_VS_predPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': rmae_predLambda_VS_predPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': rmae_real_VS_realPolyLstsq,\n",
    "             'FD FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': fd_real_VS_predLambda,   \n",
    "             'FD FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': fd_real_VS_predPolyLstsq,   \n",
    "             'FD FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': fd_predLambda_VS_predPolyLstsq,   \n",
    "             'FD FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': fd_real_VS_realPolyLstsq,   \n",
    "             'DTW FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': dtw_real_VS_predLambda, \n",
    "             'DTW FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': dtw_real_VS_predPolyLstsq, \n",
    "             'DTW FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': dtw_predLambda_VS_predPolyLstsq, \n",
    "             'DTW FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': dtw_real_VS_realPolyLstsq, \n",
    "            },\n",
    "            {\n",
    "             'STD FV ' + identifier + ' REAL LAMBDA': std_data_real_lambda,\n",
    "             'STD FV ' + identifier + ' PRED LAMBDA': std_data_pred_lambda, \n",
    "             'STD FV ' + identifier + ' PRED LAMBDA POLY LSTSQ': std_data_pred_lambda_poly_lstsq, \n",
    "             'STD FV ' + identifier + ' REAL LAMBDA POLY LSTSQ': std_data_real_lambda_poly_lstsq, \n",
    "            },\n",
    "            {\n",
    "             'MEAN FV ' + identifier + ' REAL LAMBDA': mean_data_real_lambda,\n",
    "             'MEAN FV ' + identifier + ' PRED LAMBDA': mean_data_pred_lambda, \n",
    "             'MEAN FV ' + identifier + ' PRED LAMBDA POLY LSTSQ': mean_data_pred_lambda_poly_lstsq, \n",
    "             'MEAN FV ' + identifier + ' REAL LAMBDA POLY LSTSQ': mean_data_real_lambda_poly_lstsq, \n",
    "            }]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.289711Z",
     "start_time": "2020-11-23T18:41:07.280243Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_function_values_from_polynomial(X_data, polynomial):\n",
    "    function_value_list = []\n",
    "    for entry in X_data:\n",
    "        function_value, _ = calcualate_function_value_with_X_data_entry(polynomial, entry)\n",
    "        function_value_list.append(function_value)\n",
    "    function_value_array = np.array(function_value_list).reshape(len(function_value_list), 1)     \n",
    "\n",
    "    return function_value_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.304645Z",
     "start_time": "2020-11-23T18:41:07.293584Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_term_matric_for_lstsq(X_data, polynomial_indices):\n",
    "    term_list_all = []\n",
    "    y = 0\n",
    "    for term in list(polynomial_indices):\n",
    "        term_list = [int(value_mult) for value_mult in term]\n",
    "        term_list_all.append(term_list)\n",
    "    terms_matrix = []\n",
    "    for unknowns in X_data:\n",
    "        terms = []\n",
    "        for term_multipliers in term_list_all:\n",
    "            term_value = prod([unknown**multiplier for unknown, multiplier in zip(unknowns, term_multipliers)])\n",
    "            terms.append(term_value)\n",
    "        terms_matrix.append(np.array(terms))\n",
    "    terms_matrix = np.array(terms_matrix)\n",
    "    \n",
    "    return terms_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:41:07.398614Z",
     "start_time": "2020-11-23T18:41:07.310438Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "def train_nn(X_data_lambda, y_data_real_lambda, polynomial, callbacks=None, return_history=False, each_epochs_save=None, printing=False, return_model=False):\n",
    "    \n",
    "    if fixed_seed_lambda_training:\n",
    "        random.seed(RANDOM_SEED)\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        if int(tf.__version__[0]) >= 2:\n",
    "            tf.random.set_seed(RANDOM_SEED)\n",
    "        else:\n",
    "            tf.set_random_seed(RANDOM_SEED) \n",
    "        \n",
    "    if isinstance(X_data_lambda, pd.DataFrame):\n",
    "        X_data_lambda = X_data_lambda.values\n",
    "    if isinstance(y_data_real_lambda, pd.DataFrame):\n",
    "        y_data_real_lambda = y_data_real_lambda.values\n",
    "                \n",
    "    X_train_lambda_with_valid, X_test_lambda, y_train_real_lambda_with_valid, y_test_real_lambda = train_test_split(X_data_lambda, y_data_real_lambda, test_size=0.25, random_state=RANDOM_SEED)           \n",
    "    X_train_lambda, X_valid_lambda, y_train_real_lambda, y_valid_real_lambda = train_test_split(X_train_lambda_with_valid, y_train_real_lambda_with_valid, test_size=0.25, random_state=RANDOM_SEED)           \n",
    "     \n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(lambda_network_layers[0], activation='relu', input_dim=X_data_lambda.shape[1])) #1024\n",
    "    \n",
    "    if dropout > 0:\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    for neurons in lambda_network_layers[1:]:\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(dropout))   \n",
    "            \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=[mean_absolute_percentage_error_keras, root_mean_squared_error]\n",
    "                 )\n",
    "    \n",
    "    \n",
    "    weights = []\n",
    "    polynomial_lstsq_pred_list = []\n",
    "    polynomial_lstsq_true_list = []\n",
    "\n",
    "     \n",
    "    if each_epochs_save == None:   \n",
    "        model_history = model.fit(X_train_lambda, \n",
    "                      y_train_real_lambda, \n",
    "                      epochs=epochs, \n",
    "                      batch_size=batch_size, \n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=(X_valid_lambda, y_valid_real_lambda),\n",
    "                      verbose=0,\n",
    "                      workers=0)\n",
    "        weights.append(model.get_weights())\n",
    "        \n",
    "        history = model_history.history\n",
    "        \n",
    "        y_train_pred_lambda = model.predict(X_train_lambda) \n",
    "        y_valid_pred_lambda = model.predict(X_valid_lambda)                \n",
    "        y_test_pred_lambda = model.predict(X_test_lambda)\n",
    "    \n",
    "        terms_matrix = generate_term_matric_for_lstsq(X_train_lambda, list(polynomial.index))\n",
    "                \n",
    "        polynomial_lstsq_pred, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_pred_lambda.ravel(), rcond=-1)#[::-1]\n",
    "        polynomial_lstsq_true, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_real_lambda.ravel(), rcond=-1)#[::-1] \n",
    "        polynomial_lstsq_pred_list.append(polynomial_lstsq_pred)\n",
    "        polynomial_lstsq_true_list.append(polynomial_lstsq_true)\n",
    "        \n",
    "        y_train_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_pred)\n",
    "        y_train_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_true)\n",
    "        y_valid_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_pred)\n",
    "        y_valid_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_true)    \n",
    "        y_test_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_pred)\n",
    "        y_test_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_true)  \n",
    "        \n",
    "        pred_list = (y_train_real_lambda, \n",
    "                     y_train_pred_lambda, \n",
    "                     y_train_pred_lambda_poly_lstsq,\n",
    "                     #y_train_real_lambda_poly_lstsq,\n",
    "                     X_train_lambda, \n",
    "                     y_valid_real_lambda,\n",
    "                     y_valid_pred_lambda, \n",
    "                     y_valid_pred_lambda_poly_lstsq,\n",
    "                     #y_valid_real_lambda_poly_lstsq,\n",
    "                     X_valid_lambda, \n",
    "                     y_test_real_lambda, \n",
    "                     y_test_pred_lambda, \n",
    "                     y_test_pred_lambda_poly_lstsq, \n",
    "                     #y_test_real_lambda_poly_lstsq,\n",
    "                     X_test_lambda)\n",
    "\n",
    "        scores_train, std_train, mean_train = evaluate_lambda_net('TRAIN', X_train_lambda, y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, y_train_real_lambda_poly_lstsq)\n",
    "        scores_valid, std_valid, mean_valid = evaluate_lambda_net('VALID', X_valid_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, y_valid_real_lambda_poly_lstsq)\n",
    "        scores_test, std_test, mean_test = evaluate_lambda_net('TEST', X_test_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, y_test_real_lambda_poly_lstsq)\n",
    "\n",
    "        scores_std = {}\n",
    "        for aDict in (std_train, std_valid, std_test):\n",
    "            scores_std.update(aDict)      \n",
    "        scores_mean = {}\n",
    "        for aDict in (mean_train, mean_valid, mean_test):\n",
    "            scores_mean.update(aDict)\n",
    "        \n",
    "        scores_list =  [scores_train,\n",
    "                             scores_valid,\n",
    "                             scores_test,\n",
    "                             scores_std,\n",
    "                             scores_mean]            \n",
    "                            \n",
    "    else:\n",
    "        scores_list = []\n",
    "        pred_list = []\n",
    "        for i in epochs_save_range:\n",
    "            train_epochs_step = each_epochs_save if i > 1 else max(each_epochs_save-1, 1) if i==1 else 1\n",
    "            \n",
    "            model_history = model.fit(X_train_lambda, \n",
    "                      y_train_real_lambda, \n",
    "                      epochs=train_epochs_step, \n",
    "                      batch_size=batch_size, \n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=(X_valid_lambda, y_valid_real_lambda),\n",
    "                      verbose=0,\n",
    "                      workers=1,\n",
    "                      use_multiprocessing=False)\n",
    "            \n",
    "            #history adjustment for continuing training\n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                history = model_history.history\n",
    "            else:\n",
    "                history = mergeDict(history, model_history.history)\n",
    "                #for key_1 in history.keys():\n",
    "                #    for key_2 in model_history.history.keys():\n",
    "                #        if key_1 == key_2:\n",
    "                #            history[key_1] += model_history.history[key_2]  \n",
    "\n",
    "            weights.append(model.get_weights())\n",
    "            \n",
    "            y_train_pred_lambda = model.predict(X_train_lambda)                \n",
    "            y_valid_pred_lambda = model.predict(X_valid_lambda)                \n",
    "            y_test_pred_lambda = model.predict(X_test_lambda)        \n",
    "\n",
    "            terms_matrix = generate_term_matric_for_lstsq(X_train_lambda, list(polynomial.index))\n",
    "                        \n",
    "            polynomial_lstsq_pred, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_pred_lambda.ravel(), rcond=-1)#[::-1] \n",
    "            #does not change over time\n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                polynomial_lstsq_true, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_real_lambda.ravel(), rcond=-1)#[::-1] \n",
    "            polynomial_lstsq_pred_list.append(polynomial_lstsq_pred)\n",
    "            polynomial_lstsq_true_list.append(polynomial_lstsq_true)            \n",
    "\n",
    "            \n",
    "            y_train_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_pred)\n",
    "            y_valid_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_pred)\n",
    "            y_test_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_pred)           \n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                y_train_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_true)\n",
    "                y_valid_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_true)  \n",
    "                y_test_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_true)                    \n",
    "                \n",
    "            pred_list.append((y_train_real_lambda, \n",
    "                              y_train_pred_lambda, \n",
    "                              y_train_pred_lambda_poly_lstsq,\n",
    "                              #y_train_real_lambda_poly_lstsq,\n",
    "                              X_train_lambda, \n",
    "                              y_valid_real_lambda,\n",
    "                              y_valid_pred_lambda, \n",
    "                              y_valid_pred_lambda_poly_lstsq,\n",
    "                              #y_valid_real_lambda_poly_lstsq,\n",
    "                              X_valid_lambda, \n",
    "                              y_test_real_lambda, \n",
    "                              y_test_pred_lambda, \n",
    "                              y_test_pred_lambda_poly_lstsq, \n",
    "                              #y_test_real_lambda_poly_lstsq,\n",
    "                              X_test_lambda))\n",
    "    \n",
    "            scores_train, std_train, mean_train = evaluate_lambda_net('TRAIN', X_train_lambda, y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, y_train_real_lambda_poly_lstsq)\n",
    "            scores_valid, std_valid, mean_valid = evaluate_lambda_net('VALID', X_valid_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, y_valid_real_lambda_poly_lstsq)\n",
    "            scores_test, std_test, mean_test = evaluate_lambda_net('TEST', X_test_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, y_test_real_lambda_poly_lstsq)\n",
    "\n",
    "            scores_std = {}\n",
    "            for aDict in (std_train, std_valid, std_test):\n",
    "                scores_std.update(aDict)\n",
    "            scores_mean = {}\n",
    "            for aDict in (mean_train, mean_valid, mean_test):\n",
    "                scores_mean.update(aDict)\n",
    "\n",
    "            scores_list_single_epoch =  [scores_train,\n",
    "                                              scores_valid,\n",
    "                                              scores_test,\n",
    "                                              scores_std,\n",
    "                                              scores_mean]        \n",
    "                  \n",
    "            scores_list.append(scores_list_single_epoch)\n",
    "       \n",
    "\n",
    "        \n",
    "    if printing:        \n",
    "        for i, (weights_for_epoch, polynomial_lstsq_pred_for_epoch, polynomial_lstsq_true_for_epoch) in enumerate(zip(weights, polynomial_lstsq_pred_list, polynomial_lstsq_true_list)):        \n",
    "            if each_epochs_save == None:\n",
    "                path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "            else:\n",
    "                index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "                path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(index).zfill(3)  + filename + '.txt'\n",
    "            with open(path, 'a') as text_file: \n",
    "                for i, value in enumerate(polynomial.values):\n",
    "                    if i == 0:\n",
    "                        text_file.write(str(value))  \n",
    "                    else:\n",
    "                        text_file.write(', ' + str(value))   \n",
    "                for value in polynomial_lstsq_pred_for_epoch:\n",
    "                    text_file.write(', ' + str(value))\n",
    "                for value in polynomial_lstsq_true_for_epoch:\n",
    "                    text_file.write(', ' + str(value))\n",
    "                for layer_weights, biases in pairwise(weights_for_epoch):    #clf.get_weights()\n",
    "                    for neuron in layer_weights:\n",
    "                        for weight in neuron:\n",
    "                            text_file.write(', ' + str(weight))\n",
    "                    for bias in biases:\n",
    "                        text_file.write(', ' + str(bias))\n",
    "                text_file.write('\\n')\n",
    "\n",
    "            text_file.close() \n",
    "\n",
    "            \n",
    "    if return_model:\n",
    "        return (polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list, history, model\n",
    "    elif return_history:\n",
    "        return (polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list, history, #polynomial_lstsq_pred_list, polynomial_lstsq_true_list#, weights, history\n",
    "    else:\n",
    "        return (polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list#, weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:12.274032Z",
     "start_time": "2020-11-23T18:41:07.403048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    4.436, max:    7.652, cur:    4.436)\n",
      "\tvalidation       \t (min:    4.046, max:    6.485, cur:    4.046)\n",
      "mean_absolute_percentage_error_keras\n",
      "\ttraining         \t (min:    1.002, max:    1.785, cur:    1.579)\n",
      "\tvalidation       \t (min:    1.224, max:    3.841, cur:    3.830)\n",
      "root_mean_squared_error\n",
      "\ttraining         \t (min:    6.141, max:    9.898, cur:    6.141)\n",
      "\tvalidation       \t (min:    5.575, max:    8.653, cur:    5.575)\n"
     ]
    }
   ],
   "source": [
    "clf_list = []\n",
    "chunksize = 1000 if data_size > 10000 else max(data_size//10, min(50, data_size))\n",
    "X_data_list_splits = list(chunks(X_data_list, chunksize))\n",
    "y_data_list_splits = list(chunks(y_data_list, chunksize))\n",
    "\n",
    "for X_data_list_split, y_data_list_split in tqdm(zip(X_data_list_splits, y_data_list_splits), total=max(len(X_data_list_splits), len(y_data_list_splits))):\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    clf_sublist = parallel(delayed(train_nn)(X_data[1].values, y_data[1].values, X_data[0], return_history=True, each_epochs_save=each_epochs_save, printing=True) for X_data, y_data in zip(X_data_list_split, y_data_list_split))  \n",
    "    clf_list.extend(clf_sublist)\n",
    "    del parallel\n",
    "rand_index = np.random.randint(data_size)\n",
    "random_network = train_nn(X_data_list[rand_index][1], y_data_list[rand_index][1], X_data_list[rand_index][0], callbacks=[PlotLossesKerasTF()], return_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Lambda-Model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:12.438149Z",
     "start_time": "2020-11-23T18:46:12.277817Z"
    }
   },
   "outputs": [],
   "source": [
    "if each_epochs_save == None:\n",
    "    scores_list_train = [clf[1][0] for clf in clf_list]\n",
    "    scores_list_valid = [clf[1][1] for clf in clf_list]\n",
    "    scores_list_test = [clf[1][2] for clf in clf_list]\n",
    "    scores_list_stds = [clf[1][3] for clf in clf_list]\n",
    "    scores_list_means = [clf[1][4] for clf in clf_list]\n",
    "\n",
    "    scores_list_train_mean = pd.DataFrame(scores_list_train, columns=scores_list_train[0].keys()).mean()\n",
    "    df_mean_scores_train = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED', 'TRAIN POLY', 'TRAIN POLY PRED', 'TRAIN LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "\n",
    "    scores_list_valid_mean = pd.DataFrame(scores_list_valid, columns=scores_list_valid[0].keys()).mean()\n",
    "    df_mean_scores_valid = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED', 'VALID POLY', 'VALID POLY PRED', 'VALID LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "\n",
    "    scores_list_test_mean = pd.DataFrame(scores_list_test, columns=scores_list_test[0].keys()).mean()\n",
    "    df_mean_scores_test = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED', 'TEST POLY', 'TEST POLY PRED', 'TEST LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "\n",
    "    stds_mean = pd.DataFrame(scores_list_stds, columns=scores_list_stds[0].keys()).mean()\n",
    "    df_stds = pd.DataFrame(stds_mean, columns=['0'], index=stds_mean.index)\n",
    "    \n",
    "    means_mean = pd.DataFrame(scores_list_means, columns=scores_list_means[0].keys()).mean()\n",
    "    df_means = pd.DataFrame(means_mean, columns=['0'], index=means_mean.index)\n",
    "    \n",
    "    path_scores_train = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_train_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_valid = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_valid_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_test = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_test_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_stds = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/stds_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_means = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/means_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "   \n",
    "    df_mean_scores_train.to_csv(path_scores_train, sep=',')\n",
    "    df_mean_scores_valid.to_csv(path_scores_valid, sep=',')\n",
    "    df_mean_scores_test.to_csv(path_scores_test, sep=',')\n",
    "    df_stds.to_csv(path_stds, sep=',')\n",
    "    df_means.to_csv(path_means, sep=',')\n",
    "else:\n",
    "    scores_list = [clf[1] for clf in clf_list]\n",
    "    \n",
    "    scores_list_by_epochs = [[] for i in epochs_save_range]\n",
    "    for scores_list in scores_list:   \n",
    "        for index, scores in enumerate(scores_list):\n",
    "            scores_list_by_epochs[index].append(scores)\n",
    "            \n",
    "        \n",
    "    for i, scores_list_single_epoch in enumerate(scores_list_by_epochs):\n",
    "        index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "           \n",
    "        scores_list_train = [scores_list[0] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_valid = [scores_list[1] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_test = [scores_list[2] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_stds = [scores_list[3] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_means = [scores_list[4] for scores_list in scores_list_single_epoch]\n",
    "        \n",
    "        scores_list_train_mean = pd.DataFrame(scores_list_train, columns=scores_list_train[0].keys()).mean()  \n",
    "        scores_list_valid_mean = pd.DataFrame(scores_list_valid, columns=scores_list_valid[0].keys()).mean()  \n",
    "        scores_list_test_mean = pd.DataFrame(scores_list_test, columns=scores_list_test[0].keys()).mean()\n",
    "        stds_mean = pd.DataFrame(scores_list_stds, columns=scores_list_stds[0].keys()).mean()\n",
    "        means_mean = pd.DataFrame(scores_list_means, columns=scores_list_means[0].keys()).mean()\n",
    "\n",
    "        if index == 1:\n",
    "            df_mean_scores_train = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED E' + str(index), 'TRAIN POLY E' + str(index), 'TRAIN POLY PRED E' + str(index), 'TRAIN LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_valid = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index), 'VALID POLY PRED E' + str(index), 'VALID LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_test = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index), 'TEST POLY PRED E' + str(index), 'TEST LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_stds = pd.DataFrame(stds_mean, columns=['E' + str(index)], index=stds_mean.index)   \n",
    "            df_means = pd.DataFrame(means_mean, columns=['E' + str(index)], index=means_mean.index)   \n",
    "        else:\n",
    "            df_mean_scores_train_new = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED E' + str(index), 'TRAIN POLY E' + str(index), 'TRAIN POLY PRED E' + str(index), 'TRAIN LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_train = pd.concat([df_mean_scores_train, df_mean_scores_train_new],axis=1)  \n",
    "            \n",
    "            df_mean_scores_valid_new = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index), 'VALID POLY PRED E' + str(index), 'VALID LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_valid = pd.concat([df_mean_scores_valid, df_mean_scores_valid_new],axis=1)  \n",
    "\n",
    "            df_mean_scores_test_new = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index), 'TEST POLY PRED E' + str(index), 'TEST LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_test = pd.concat([df_mean_scores_test, df_mean_scores_test_new],axis=1)  \n",
    "\n",
    "            df_stds_new = pd.DataFrame(stds_mean, columns=['E' + str(index)], index=stds_mean.index)\n",
    "            df_stds = pd.concat([df_stds, df_stds_new],axis=1)  \n",
    "            \n",
    "            df_means_new = pd.DataFrame(means_mean, columns=['E' + str(index)], index=means_mean.index)\n",
    "            df_means = pd.concat([df_means, df_means_new],axis=1)     \n",
    "\n",
    "    path_scores_train = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_train_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_valid = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_valid_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_test = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_test_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_stds = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/stds_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_means = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/means_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "    df_mean_scores_train.to_csv(path_scores_train, sep=',')\n",
    "    df_mean_scores_valid.to_csv(path_scores_valid, sep=',')\n",
    "    df_mean_scores_test.to_csv(path_scores_test, sep=',')\n",
    "    df_stds.to_csv(path_stds, sep=',')\n",
    "    df_means.to_csv(path_means, sep=',')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:12.453029Z",
     "start_time": "2020-11-23T18:46:12.441069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN PRED</th>\n",
       "      <th>TRAIN POLY</th>\n",
       "      <th>TRAIN POLY PRED</th>\n",
       "      <th>TRAIN LSTSQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>4.142</td>\n",
       "      <td>4.189</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>5.903</td>\n",
       "      <td>5.876</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>2.390</td>\n",
       "      <td>2.349</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.378</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>2.317</td>\n",
       "      <td>2.240</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD FV</th>\n",
       "      <td>10.387</td>\n",
       "      <td>10.280</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW FV</th>\n",
       "      <td>39.903</td>\n",
       "      <td>40.203</td>\n",
       "      <td>4.306</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRAIN PRED  TRAIN POLY  TRAIN POLY PRED  TRAIN LSTSQ\n",
       "MAE FV        4.142       4.189            0.420        0.000\n",
       "RMSE FV       5.903       5.876            0.538        0.000\n",
       "MAPE FV       2.390       2.349            0.398        0.000\n",
       "R2 FV         0.698       0.701            0.995        1.000\n",
       "RAAE FV       0.378       0.382            0.054        0.000\n",
       "RMAE FV       2.317       2.240            0.270        0.000\n",
       "FD FV        10.387      10.280            1.047        0.000\n",
       "DTW FV       39.903      40.203            4.306        0.000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:12.473415Z",
     "start_time": "2020-11-23T18:46:12.455775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALID PRED</th>\n",
       "      <th>VALID POLY</th>\n",
       "      <th>VALID POLY PRED</th>\n",
       "      <th>VALID LSTSQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>4.245</td>\n",
       "      <td>4.265</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>5.966</td>\n",
       "      <td>5.923</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>2.412</td>\n",
       "      <td>2.506</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>0.687</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.391</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>1.961</td>\n",
       "      <td>1.898</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD FV</th>\n",
       "      <td>10.995</td>\n",
       "      <td>10.954</td>\n",
       "      <td>1.109</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW FV</th>\n",
       "      <td>39.946</td>\n",
       "      <td>40.416</td>\n",
       "      <td>4.435</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VALID PRED  VALID POLY  VALID POLY PRED  VALID LSTSQ\n",
       "MAE FV        4.245       4.265            0.450        0.000\n",
       "RMSE FV       5.966       5.923            0.584        0.000\n",
       "MAPE FV       2.412       2.506            0.483        0.000\n",
       "R2 FV         0.687       0.691            0.994        1.000\n",
       "RAAE FV       0.391       0.393            0.058        0.000\n",
       "RMAE FV       1.961       1.898            0.259        0.000\n",
       "FD FV        10.995      10.954            1.109        0.000\n",
       "DTW FV       39.946      40.416            4.435        0.000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:12.487502Z",
     "start_time": "2020-11-23T18:46:12.476209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST PRED</th>\n",
       "      <th>TEST POLY</th>\n",
       "      <th>TEST POLY PRED</th>\n",
       "      <th>TEST LSTSQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>4.283</td>\n",
       "      <td>4.309</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>5.992</td>\n",
       "      <td>5.943</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>4.491</td>\n",
       "      <td>4.419</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>0.685</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>1.989</td>\n",
       "      <td>1.922</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD FV</th>\n",
       "      <td>11.293</td>\n",
       "      <td>11.191</td>\n",
       "      <td>1.058</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW FV</th>\n",
       "      <td>41.721</td>\n",
       "      <td>41.871</td>\n",
       "      <td>4.255</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TEST PRED  TEST POLY  TEST POLY PRED  TEST LSTSQ\n",
       "MAE FV       4.283      4.309           0.451       0.000\n",
       "RMSE FV      5.992      5.943           0.587       0.000\n",
       "MAPE FV      4.491      4.419           0.349       0.000\n",
       "R2 FV        0.685      0.689           0.994       1.000\n",
       "RAAE FV      0.395      0.398           0.058       0.000\n",
       "RMAE FV      1.989      1.922           0.287       0.000\n",
       "FD FV       11.293     11.191           1.058       0.000\n",
       "DTW FV      41.721     41.871           4.255       0.000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:12.499623Z",
     "start_time": "2020-11-23T18:46:12.490248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN REAL LAMBDA</th>\n",
       "      <td>11.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN PRED LAMBDA</th>\n",
       "      <td>8.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>8.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID REAL LAMBDA</th>\n",
       "      <td>11.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID PRED LAMBDA</th>\n",
       "      <td>8.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>8.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST REAL LAMBDA</th>\n",
       "      <td>11.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST PRED LAMBDA</th>\n",
       "      <td>8.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>8.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0\n",
       "STD FV TRAIN REAL LAMBDA            11.284\n",
       "STD FV TRAIN PRED LAMBDA             8.281\n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  8.261\n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.284\n",
       "STD FV VALID REAL LAMBDA            11.175\n",
       "STD FV VALID PRED LAMBDA             8.220\n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  8.206\n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.175\n",
       "STD FV TEST REAL LAMBDA             11.205\n",
       "STD FV TEST PRED LAMBDA              8.244\n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   8.227\n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  11.205"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:12.512698Z",
     "start_time": "2020-11-23T18:46:12.502495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN REAL LAMBDA</th>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN PRED LAMBDA</th>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID REAL LAMBDA</th>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID PRED LAMBDA</th>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST REAL LAMBDA</th>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST PRED LAMBDA</th>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0\n",
       "MEAN FV TRAIN REAL LAMBDA            0.187\n",
       "MEAN FV TRAIN PRED LAMBDA            0.255\n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ 0.255\n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ 0.187\n",
       "MEAN FV VALID REAL LAMBDA            0.107\n",
       "MEAN FV VALID PRED LAMBDA            0.211\n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ 0.211\n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ 0.107\n",
       "MEAN FV TEST REAL LAMBDA             0.081\n",
       "MEAN FV TEST PRED LAMBDA             0.144\n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  0.148\n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  0.081"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Lambda-Net Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:17.151503Z",
     "start_time": "2020-11-23T18:46:12.515946Z"
    }
   },
   "outputs": [],
   "source": [
    "if each_epochs_save == None:\n",
    "    \n",
    "    variable_names = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    variable_names_list = [variable + '_' for variable in variable_names[:n]]\n",
    "    variable_names_list.append('FV_')\n",
    "    \n",
    "    polynomial_real_list = [clf[0][0] for clf in clf_list] \n",
    "    polynomial_lstsq_pred_lambda_list = [clf[0][1] for clf in clf_list] \n",
    "    polynomial_lstsq_real_lambda_list = [clf[0][2] for clf in clf_list] \n",
    "    \n",
    "    polynomial_real_df = pd.DataFrame(polynomial_real_list)\n",
    "\n",
    "    y_train_real_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][0])))\n",
    "    y_train_pred_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][1])))\n",
    "    y_train_pred_lambda_poly_lstsq_list = np.zeros((len(clf_list), len(clf_list[0][2][2])))\n",
    "    X_train_lambda_list = np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][3].shape)]][0])\n",
    "    y_valid_real_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][4])))\n",
    "    y_valid_pred_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][5])))\n",
    "    y_valid_pred_lambda_poly_lstsq_list = np.zeros((len(clf_list), len(clf_list[0][2][6])))\n",
    "    X_valid_lambda_list = np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][7].shape)]][0])\n",
    "    y_test_real_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][8])))\n",
    "    y_test_pred_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][9])))\n",
    "    y_test_pred_lambda_poly_lstsq_list = np.zeros((len(clf_list), len(clf_list[0][2][10])))\n",
    "    X_test_lambda_list = np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][11].shape)]][0])\n",
    "\n",
    "    for index, (y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, X_train_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, X_valid_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, X_test_lambda) in enumerate([clf[2] for clf in clf_list]):\n",
    "        y_train_real_lambda_list[index] = y_train_real_lambda.ravel()\n",
    "        y_train_pred_lambda_list[index] = y_train_pred_lambda.ravel()\n",
    "        y_train_pred_lambda_poly_lstsq_list[index] = y_train_pred_lambda_poly_lstsq.ravel()\n",
    "        X_train_lambda_list[index] = X_train_lambda#.ravel()\n",
    "\n",
    "        y_valid_real_lambda_list[index] = y_valid_real_lambda.ravel()\n",
    "        y_valid_pred_lambda_list[index] = y_valid_pred_lambda.ravel()\n",
    "        y_valid_pred_lambda_poly_lstsq_list[index] = y_valid_pred_lambda_poly_lstsq.ravel()\n",
    "        X_valid_lambda_list[index] = X_valid_lambda#.ravel()\n",
    "\n",
    "        y_test_real_lambda_list[index] = y_test_real_lambda.ravel()\n",
    "        y_test_pred_lambda_list[index] = y_test_pred_lambda.ravel()\n",
    "        y_test_pred_lambda_poly_lstsq_list[index] = y_test_pred_lambda_poly_lstsq.ravel()\n",
    "        X_test_lambda_list[index] = X_test_lambda#.ravel()\n",
    "    \n",
    "    #add x_data before each pred\n",
    "    y_train_real_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_real_lambda.reshape(len(y_train_real_lambda),1)], axis=1).ravel() for X_train_lambda, y_train_real_lambda in zip(X_train_lambda_list, y_train_real_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_list[0].shape[0])]).ravel())\n",
    "    y_valid_real_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_real_lambda.reshape(len(y_valid_real_lambda),1)], axis=1).ravel() for X_valid_lambda, y_valid_real_lambda in zip(X_valid_lambda_list, y_valid_real_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_list[0].shape[0])]).ravel())\n",
    "    y_test_real_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_real_lambda.reshape(len(y_test_real_lambda),1)], axis=1).ravel() for X_test_lambda, y_test_real_lambda in zip(X_test_lambda_list, y_test_real_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_list[0].shape[0])]).ravel())\n",
    "    y_train_pred_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda.reshape(len(y_train_pred_lambda),1)], axis=1).ravel() for X_train_lambda, y_train_pred_lambda in zip(X_train_lambda_list, y_train_pred_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_list[0].shape[0])]).ravel())\n",
    "    y_valid_pred_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda.reshape(len(y_valid_pred_lambda),1)], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda in zip(X_valid_lambda_list, y_valid_pred_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_list[0].shape[0])]).ravel())\n",
    "    y_test_pred_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda.reshape(len(y_test_pred_lambda),1)], axis=1).ravel() for X_test_lambda, y_test_pred_lambda in zip(X_test_lambda_list, y_test_pred_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_list[0].shape[0])]).ravel())\n",
    "    y_train_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda_poly_lstsq.reshape(len(y_train_pred_lambda_poly_lstsq),1)], axis=1).ravel() for X_train_lambda, y_train_pred_lambda_poly_lstsq in zip(X_train_lambda_list, y_train_pred_lambda_poly_lstsq_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_list[0].shape[0])]).ravel())\n",
    "    y_valid_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda_poly_lstsq.reshape(len(y_valid_pred_lambda_poly_lstsq),1)], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda_poly_lstsq in zip(X_valid_lambda_list, y_valid_pred_lambda_poly_lstsq_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_list[0].shape[0])]).ravel())\n",
    "    y_test_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda_poly_lstsq.reshape(len(y_test_pred_lambda_poly_lstsq),1)], axis=1).ravel() for X_test_lambda, y_test_pred_lambda_poly_lstsq in zip(X_test_lambda_list, y_test_pred_lambda_poly_lstsq_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_list[0].shape[0])]).ravel())    \n",
    "    \n",
    "    y_train_real_lambda_df = pd.concat([polynomial_real_df, y_train_real_lambda_df], axis=1)\n",
    "    y_valid_real_lambda_df = pd.concat([polynomial_real_df, y_valid_real_lambda_df], axis=1)\n",
    "    y_test_real_lambda_df = pd.concat([polynomial_real_df, y_test_real_lambda_df], axis=1)\n",
    "    y_train_pred_lambda_df = pd.concat([polynomial_real_df, y_train_pred_lambda_df], axis=1)\n",
    "    y_valid_pred_lambda_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_df], axis=1)\n",
    "    y_test_pred_lambda_df = pd.concat([polynomial_real_df, y_test_pred_lambda_df], axis=1)\n",
    "    y_train_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_train_pred_lambda_poly_lstsq_df], axis=1)\n",
    "    y_valid_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_poly_lstsq_df], axis=1)\n",
    "    y_test_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_test_pred_lambda_poly_lstsq_df], axis=1)\n",
    "       \n",
    "    path_y_train_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_real_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_valid_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_real_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_test_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_real_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_train_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_valid_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_test_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_train_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_poly_lstsq_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_valid_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_poly_lstsq_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_test_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_poly_lstsq_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "   \n",
    "    y_train_real_lambda_df.to_csv(path_y_train_real_lambda, sep=',', index=False)\n",
    "    y_valid_real_lambda_df.to_csv(path_y_valid_real_lambda, sep=',', index=False)\n",
    "    y_test_real_lambda_df.to_csv(path_y_test_real_lambda, sep=',', index=False)\n",
    "    y_train_pred_lambda_df.to_csv(path_y_train_pred_lambda, sep=',', index=False)\n",
    "    y_valid_pred_lambda_df.to_csv(path_y_valid_pred_lambda, sep=',', index=False)\n",
    "    y_test_pred_lambda_df.to_csv(path_y_test_pred_lambda, sep=',', index=False)\n",
    "    y_train_pred_lambda_poly_lstsq_df.to_csv(path_y_train_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "    y_valid_pred_lambda_poly_lstsq_df.to_csv(path_y_valid_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "    y_test_pred_lambda_poly_lstsq_df.to_csv(path_y_test_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    variable_names = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    variable_names_list = [variable + '_' for variable in variable_names[:n]]\n",
    "    variable_names_list.append('FV_')\n",
    "    \n",
    "    polynomial_real_list = [clf[0][0] for clf in clf_list]\n",
    "    polynomial_lstsq_pred_lambda_list = [clf[0][1] for clf in clf_list]\n",
    "    polynomial_lstsq_real_lambda_list = [clf[0][2] for clf in clf_list]\n",
    "    \n",
    "    polynomial_real_df = pd.DataFrame(polynomial_real_list)\n",
    "    \n",
    "    y_train_real_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][0]), 1)) for i in epochs_save_range]\n",
    "    y_train_pred_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][1]), 1)) for i in epochs_save_range]\n",
    "    y_train_pred_lambda_poly_lstsq_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][2]), 1)) for i in epochs_save_range]\n",
    "    X_train_lambda_list = [np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][0][3].shape)]][0]) for i in epochs_save_range]\n",
    "    y_valid_real_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][4]), 1)) for i in epochs_save_range]\n",
    "    y_valid_pred_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][5]), 1)) for i in epochs_save_range]\n",
    "    y_valid_pred_lambda_poly_lstsq_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][6]), 1)) for i in epochs_save_range]\n",
    "    X_valid_lambda_list = [np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][0][7].shape)]][0]) for i in epochs_save_range]\n",
    "    y_test_real_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][8]), 1)) for i in epochs_save_range]\n",
    "    y_test_pred_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][9]), 1)) for i in epochs_save_range]\n",
    "    y_test_pred_lambda_poly_lstsq_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][10]), 1)) for i in epochs_save_range]\n",
    "    X_test_lambda_list = [np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][0][11].shape)]][0]) for i in epochs_save_range]\n",
    "    \n",
    "    for i, y_data_list_per_epoch in tqdm(enumerate([clf[2] for clf in clf_list]), total=len(clf_list)):\n",
    "        \n",
    "        for index, (y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, X_train_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, X_valid_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, X_test_lambda) in enumerate(y_data_list_per_epoch):\n",
    "            y_train_real_lambda_list[index][i] = y_train_real_lambda#.ravel()\n",
    "            y_train_pred_lambda_list[index][i] = y_train_pred_lambda#.ravel()\n",
    "            y_train_pred_lambda_poly_lstsq_list[index][i] = y_train_pred_lambda_poly_lstsq#.ravel()\n",
    "            X_train_lambda_list[index][i] = X_train_lambda#.ravel()\n",
    "            \n",
    "            y_valid_real_lambda_list[index][i] = y_valid_real_lambda#.ravel()\n",
    "            y_valid_pred_lambda_list[index][i] = y_valid_pred_lambda#.ravel()\n",
    "            y_valid_pred_lambda_poly_lstsq_list[index][i] = y_valid_pred_lambda_poly_lstsq#.ravel()\n",
    "            X_valid_lambda_list[index][i] = X_valid_lambda#.ravel()\n",
    "            \n",
    "            y_test_real_lambda_list[index][i] = y_test_real_lambda#.ravel()\n",
    "            y_test_pred_lambda_list[index][i] = y_test_pred_lambda#.ravel()\n",
    "            y_test_pred_lambda_poly_lstsq_list[index][i] = y_test_pred_lambda_poly_lstsq#.ravel()\n",
    "            X_test_lambda_list[index][i] = X_test_lambda#.ravel()\n",
    "    \n",
    "    for i, (y_train_real_lambda_by_epoch, y_train_pred_lambda_by_epoch, y_train_pred_lambda_poly_lstsq_by_epoch, X_train_lambda_by_epoch, y_valid_real_lambda_by_epoch, y_valid_pred_lambda_by_epoch, y_valid_pred_lambda_poly_lstsq_by_epoch, X_valid_lambda_by_epoch, y_test_real_lambda_by_epoch, y_test_pred_lambda_by_epoch, y_test_pred_lambda_poly_lstsq_by_epoch, X_test_lambda_by_epoch) in tqdm(enumerate(zip(y_train_real_lambda_list, y_train_pred_lambda_list, y_train_pred_lambda_poly_lstsq_list, X_train_lambda_list, y_valid_real_lambda_list, y_valid_pred_lambda_list, y_valid_pred_lambda_poly_lstsq_list, X_valid_lambda_list, y_test_real_lambda_list, y_test_pred_lambda_list, y_test_pred_lambda_poly_lstsq_list, X_test_lambda_list)), total=len(y_train_pred_lambda_list)):\n",
    "        index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "        \n",
    "        y_train_real_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_real_lambda], axis=1).ravel() for X_train_lambda, y_train_real_lambda in zip(X_train_lambda_by_epoch, y_train_real_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_valid_real_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_real_lambda], axis=1).ravel() for X_valid_lambda, y_valid_real_lambda in zip(X_valid_lambda_by_epoch, y_valid_real_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_test_real_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_real_lambda], axis=1).ravel() for X_test_lambda, y_test_real_lambda in zip(X_test_lambda_by_epoch, y_test_real_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_train_pred_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda], axis=1).ravel() for X_train_lambda, y_train_pred_lambda in zip(X_train_lambda_by_epoch, y_train_pred_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_valid_pred_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda in zip(X_valid_lambda_by_epoch, y_valid_pred_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_test_pred_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda], axis=1).ravel() for X_test_lambda, y_test_pred_lambda in zip(X_test_lambda_by_epoch, y_test_pred_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_train_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda_poly_lstsq], axis=1).ravel() for X_train_lambda, y_train_pred_lambda_poly_lstsq in zip(X_train_lambda_by_epoch, y_train_pred_lambda_poly_lstsq_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_valid_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda_poly_lstsq], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda_poly_lstsq in zip(X_valid_lambda_by_epoch, y_valid_pred_lambda_poly_lstsq_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_test_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda_poly_lstsq], axis=1).ravel() for X_test_lambda, y_test_pred_lambda_poly_lstsq in zip(X_test_lambda_by_epoch, y_test_pred_lambda_poly_lstsq_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_by_epoch[0].shape[0])]).ravel())    \n",
    "\n",
    "        y_train_real_lambda_df = pd.concat([polynomial_real_df, y_train_real_lambda_df], axis=1)\n",
    "        y_valid_real_lambda_df = pd.concat([polynomial_real_df, y_valid_real_lambda_df], axis=1)\n",
    "        y_test_real_lambda_df = pd.concat([polynomial_real_df, y_test_real_lambda_df], axis=1)\n",
    "        y_train_pred_lambda_df = pd.concat([polynomial_real_df, y_train_pred_lambda_df], axis=1)\n",
    "        y_valid_pred_lambda_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_df], axis=1)\n",
    "        y_test_pred_lambda_df = pd.concat([polynomial_real_df, y_test_pred_lambda_df], axis=1)\n",
    "        y_train_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_train_pred_lambda_poly_lstsq_df], axis=1)\n",
    "        y_valid_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_poly_lstsq_df], axis=1)\n",
    "        y_test_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_test_pred_lambda_poly_lstsq_df], axis=1)\n",
    "\n",
    "        path_y_train_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_real_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_valid_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_real_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_test_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_real_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_train_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_valid_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_test_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_train_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_poly_lstsq_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_valid_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_poly_lstsq_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_test_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_poly_lstsq_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "        y_train_real_lambda_df.to_csv(path_y_train_real_lambda, sep=',', index=False)\n",
    "        y_valid_real_lambda_df.to_csv(path_y_valid_real_lambda, sep=',', index=False)\n",
    "        y_test_real_lambda_df.to_csv(path_y_test_real_lambda, sep=',', index=False)         \n",
    "        y_train_pred_lambda_df.to_csv(path_y_train_pred_lambda, sep=',', index=False)\n",
    "        y_valid_pred_lambda_df.to_csv(path_y_valid_pred_lambda, sep=',', index=False)\n",
    "        y_test_pred_lambda_df.to_csv(path_y_test_pred_lambda, sep=',', index=False)    \n",
    "        y_train_pred_lambda_poly_lstsq_df.to_csv(path_y_train_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "        y_valid_pred_lambda_poly_lstsq_df.to_csv(path_y_valid_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "        y_test_pred_lambda_poly_lstsq_df.to_csv(path_y_test_pred_lambda_poly_lstsq, sep=',', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:17.186552Z",
     "start_time": "2020-11-23T18:46:17.155926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0012</th>\n",
       "      <th>0020</th>\n",
       "      <th>0021</th>\n",
       "      <th>0030</th>\n",
       "      <th>...</th>\n",
       "      <th>a_249</th>\n",
       "      <th>b_249</th>\n",
       "      <th>c_249</th>\n",
       "      <th>d_249</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>a_250</th>\n",
       "      <th>b_250</th>\n",
       "      <th>c_250</th>\n",
       "      <th>d_250</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>-9.400</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-7.400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>4.807</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-14.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.900</td>\n",
       "      <td>9.400</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>7.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-6.100</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>9.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-10.854</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>-25.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>9.700</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.100</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1.345</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.230</td>\n",
       "      <td>3.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.800</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.560</td>\n",
       "      <td>4.548</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.800</td>\n",
       "      <td>3.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>1.497</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.880</td>\n",
       "      <td>7.357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0000   0001   0002   0003   0010   0011   0012   0020   0021   0030  ...  \\\n",
       "0  6.300 -7.200 -9.400  8.900 -3.000 -3.800 -4.300 -6.500  8.800 -7.400  ...   \n",
       "1 -9.900  9.400 -6.000  7.800  0.800 -1.300 -2.900 -6.100 -4.500  9.500  ...   \n",
       "2 -8.900  6.900 -4.200  9.700 -2.600 -8.000 -4.100 -7.500 -0.300 -2.900  ...   \n",
       "3  4.200 -4.400  7.500 -1.700  9.600  9.800 -8.600 -4.200 -9.200 -2.000  ...   \n",
       "4  0.200 -0.800 -4.400 -6.500  3.000  2.600 -7.700  9.300 -8.800 -7.200  ...   \n",
       "\n",
       "   a_249  b_249  c_249  d_249  FV_249  a_250  b_250  c_250  d_250  FV_250  \n",
       "0 -0.380 -0.230  0.730 -0.260   4.807  0.900 -0.190  0.310  0.600 -14.130  \n",
       "1  0.430 -0.930  0.190 -0.350 -10.854 -0.270 -0.390  0.900 -0.890 -25.191  \n",
       "2 -0.280  0.460 -0.970  0.400   1.345  0.910  0.040  0.540  0.230   3.068  \n",
       "3 -0.490  0.870  0.530  0.560   4.548  0.210  0.370  0.060  0.800   3.677  \n",
       "4 -0.440 -0.610  0.660 -0.060   1.497 -0.150 -0.860  0.110 -0.880   7.357  \n",
       "\n",
       "[5 rows x 1285 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_real_lambda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:17.214186Z",
     "start_time": "2020-11-23T18:46:17.188934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0012</th>\n",
       "      <th>0020</th>\n",
       "      <th>0021</th>\n",
       "      <th>0030</th>\n",
       "      <th>...</th>\n",
       "      <th>a_249</th>\n",
       "      <th>b_249</th>\n",
       "      <th>c_249</th>\n",
       "      <th>d_249</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>a_250</th>\n",
       "      <th>b_250</th>\n",
       "      <th>c_250</th>\n",
       "      <th>d_250</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>-9.400</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-7.400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>-2.672</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-13.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.900</td>\n",
       "      <td>9.400</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>7.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-6.100</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>9.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-13.245</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>-25.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>9.700</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.100</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>0.400</td>\n",
       "      <td>3.849</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-7.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.800</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.560</td>\n",
       "      <td>6.692</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.880</td>\n",
       "      <td>9.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0000   0001   0002   0003   0010   0011   0012   0020   0021   0030  ...  \\\n",
       "0  6.300 -7.200 -9.400  8.900 -3.000 -3.800 -4.300 -6.500  8.800 -7.400  ...   \n",
       "1 -9.900  9.400 -6.000  7.800  0.800 -1.300 -2.900 -6.100 -4.500  9.500  ...   \n",
       "2 -8.900  6.900 -4.200  9.700 -2.600 -8.000 -4.100 -7.500 -0.300 -2.900  ...   \n",
       "3  4.200 -4.400  7.500 -1.700  9.600  9.800 -8.600 -4.200 -9.200 -2.000  ...   \n",
       "4  0.200 -0.800 -4.400 -6.500  3.000  2.600 -7.700  9.300 -8.800 -7.200  ...   \n",
       "\n",
       "   a_249  b_249  c_249  d_249  FV_249  a_250  b_250  c_250  d_250  FV_250  \n",
       "0 -0.380 -0.230  0.730 -0.260  -2.672  0.900 -0.190  0.310  0.600 -13.195  \n",
       "1  0.430 -0.930  0.190 -0.350 -13.245 -0.270 -0.390  0.900 -0.890 -25.272  \n",
       "2 -0.280  0.460 -0.970  0.400   3.849  0.910  0.040  0.540  0.230  -7.879  \n",
       "3 -0.490  0.870  0.530  0.560   6.692  0.210  0.370  0.060  0.800   1.897  \n",
       "4 -0.440 -0.610  0.660 -0.060   0.329 -0.150 -0.860  0.110 -0.880   9.064  \n",
       "\n",
       "[5 rows x 1285 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_lambda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:17.241719Z",
     "start_time": "2020-11-23T18:46:17.216643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0012</th>\n",
       "      <th>0020</th>\n",
       "      <th>0021</th>\n",
       "      <th>0030</th>\n",
       "      <th>...</th>\n",
       "      <th>a_249</th>\n",
       "      <th>b_249</th>\n",
       "      <th>c_249</th>\n",
       "      <th>d_249</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>a_250</th>\n",
       "      <th>b_250</th>\n",
       "      <th>c_250</th>\n",
       "      <th>d_250</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>-9.400</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-7.400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>-3.667</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-12.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.900</td>\n",
       "      <td>9.400</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>7.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-6.100</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>9.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-12.590</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>-25.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>9.700</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.100</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>0.400</td>\n",
       "      <td>3.140</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-8.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.800</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.560</td>\n",
       "      <td>6.337</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.880</td>\n",
       "      <td>8.936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0000   0001   0002   0003   0010   0011   0012   0020   0021   0030  ...  \\\n",
       "0  6.300 -7.200 -9.400  8.900 -3.000 -3.800 -4.300 -6.500  8.800 -7.400  ...   \n",
       "1 -9.900  9.400 -6.000  7.800  0.800 -1.300 -2.900 -6.100 -4.500  9.500  ...   \n",
       "2 -8.900  6.900 -4.200  9.700 -2.600 -8.000 -4.100 -7.500 -0.300 -2.900  ...   \n",
       "3  4.200 -4.400  7.500 -1.700  9.600  9.800 -8.600 -4.200 -9.200 -2.000  ...   \n",
       "4  0.200 -0.800 -4.400 -6.500  3.000  2.600 -7.700  9.300 -8.800 -7.200  ...   \n",
       "\n",
       "   a_249  b_249  c_249  d_249  FV_249  a_250  b_250  c_250  d_250  FV_250  \n",
       "0 -0.380 -0.230  0.730 -0.260  -3.667  0.900 -0.190  0.310  0.600 -12.564  \n",
       "1  0.430 -0.930  0.190 -0.350 -12.590 -0.270 -0.390  0.900 -0.890 -25.364  \n",
       "2 -0.280  0.460 -0.970  0.400   3.140  0.910  0.040  0.540  0.230  -8.213  \n",
       "3 -0.490  0.870  0.530  0.560   6.337  0.210  0.370  0.060  0.800   1.330  \n",
       "4 -0.440 -0.610  0.660 -0.060   0.323 -0.150 -0.860  0.110 -0.880   8.936  \n",
       "\n",
       "[5 rows x 1285 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_lambda_poly_lstsq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:17.404342Z",
     "start_time": "2020-11-23T18:46:17.243974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25af1da37bc492aa80e9241ba1f5c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list_total = []\n",
    "metric_list_total = []\n",
    "\n",
    "val_loss_list_total = []\n",
    "val_metric_list_total = []\n",
    "\n",
    "for _, entry in tqdm(enumerate(clf_list)):\n",
    "    entry = entry[3]\n",
    "    loss_list = []\n",
    "    metric_list = []\n",
    "    val_loss_list = []\n",
    "    val_metric_list = []\n",
    "    for i in range(epochs):  \n",
    "        loss_list.append(entry['loss'][i])\n",
    "        metric_list.append(entry['mean_absolute_percentage_error_keras'][i])\n",
    "        val_loss_list.append(entry['val_loss'][i])\n",
    "        val_metric_list.append(entry['val_mean_absolute_percentage_error_keras'][i])\n",
    "    loss_list_total.append(loss_list)\n",
    "    metric_list_total.append(metric_list)\n",
    "    val_loss_list_total.append(val_loss_list)\n",
    "    val_metric_list_total.append(val_metric_list)\n",
    "\n",
    "loss_df = pd.DataFrame(data=loss_list_total, columns=['loss_epoch_' + str(i+1) for i in range(epochs)])\n",
    "metric_df = pd.DataFrame(data=metric_list_total, columns=['metric_epoch_' + str(i+1) for i in range(epochs)]) \n",
    "val_loss_df = pd.DataFrame(data=val_loss_list_total, columns=['val_loss_epoch_' + str(i+1) for i in range(epochs)])\n",
    "val_metric_df = pd.DataFrame(data=val_metric_list_total, columns=['val_metric_epoch_' + str(i+1) for i in range(epochs)]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:17.644714Z",
     "start_time": "2020-11-23T18:46:17.406932Z"
    }
   },
   "outputs": [],
   "source": [
    "path_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_val_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_val_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "loss_df.to_csv(path_loss, index=None, sep=',')\n",
    "metric_df.to_csv(path_metric, index=None, sep=',')\n",
    "val_loss_df.to_csv(path_val_loss, index=None, sep=',')\n",
    "val_metric_df.to_csv(path_val_metric, index=None, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:18.362768Z",
     "start_time": "2020-11-23T18:46:17.647323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_epoch_1</th>\n",
       "      <th>loss_epoch_2</th>\n",
       "      <th>loss_epoch_3</th>\n",
       "      <th>loss_epoch_4</th>\n",
       "      <th>loss_epoch_5</th>\n",
       "      <th>loss_epoch_6</th>\n",
       "      <th>loss_epoch_7</th>\n",
       "      <th>loss_epoch_8</th>\n",
       "      <th>loss_epoch_9</th>\n",
       "      <th>loss_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_epoch_191</th>\n",
       "      <th>loss_epoch_192</th>\n",
       "      <th>loss_epoch_193</th>\n",
       "      <th>loss_epoch_194</th>\n",
       "      <th>loss_epoch_195</th>\n",
       "      <th>loss_epoch_196</th>\n",
       "      <th>loss_epoch_197</th>\n",
       "      <th>loss_epoch_198</th>\n",
       "      <th>loss_epoch_199</th>\n",
       "      <th>loss_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.330</td>\n",
       "      <td>10.280</td>\n",
       "      <td>10.229</td>\n",
       "      <td>10.179</td>\n",
       "      <td>10.128</td>\n",
       "      <td>10.077</td>\n",
       "      <td>10.024</td>\n",
       "      <td>9.971</td>\n",
       "      <td>9.915</td>\n",
       "      <td>9.858</td>\n",
       "      <td>...</td>\n",
       "      <td>4.234</td>\n",
       "      <td>4.225</td>\n",
       "      <td>4.216</td>\n",
       "      <td>4.206</td>\n",
       "      <td>4.197</td>\n",
       "      <td>4.188</td>\n",
       "      <td>4.179</td>\n",
       "      <td>4.170</td>\n",
       "      <td>4.160</td>\n",
       "      <td>4.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.636</td>\n",
       "      <td>2.612</td>\n",
       "      <td>2.589</td>\n",
       "      <td>2.565</td>\n",
       "      <td>2.541</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.491</td>\n",
       "      <td>2.465</td>\n",
       "      <td>2.437</td>\n",
       "      <td>2.409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.586</td>\n",
       "      <td>6.561</td>\n",
       "      <td>6.536</td>\n",
       "      <td>6.512</td>\n",
       "      <td>6.489</td>\n",
       "      <td>6.466</td>\n",
       "      <td>6.443</td>\n",
       "      <td>6.421</td>\n",
       "      <td>6.400</td>\n",
       "      <td>6.379</td>\n",
       "      <td>...</td>\n",
       "      <td>3.168</td>\n",
       "      <td>3.160</td>\n",
       "      <td>3.151</td>\n",
       "      <td>3.144</td>\n",
       "      <td>3.134</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.117</td>\n",
       "      <td>3.108</td>\n",
       "      <td>3.099</td>\n",
       "      <td>3.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.090</td>\n",
       "      <td>8.055</td>\n",
       "      <td>8.021</td>\n",
       "      <td>7.990</td>\n",
       "      <td>7.963</td>\n",
       "      <td>7.937</td>\n",
       "      <td>7.911</td>\n",
       "      <td>7.886</td>\n",
       "      <td>7.865</td>\n",
       "      <td>7.822</td>\n",
       "      <td>...</td>\n",
       "      <td>3.858</td>\n",
       "      <td>3.851</td>\n",
       "      <td>3.842</td>\n",
       "      <td>3.833</td>\n",
       "      <td>3.827</td>\n",
       "      <td>3.817</td>\n",
       "      <td>3.807</td>\n",
       "      <td>3.800</td>\n",
       "      <td>3.795</td>\n",
       "      <td>3.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.573</td>\n",
       "      <td>9.506</td>\n",
       "      <td>9.438</td>\n",
       "      <td>9.370</td>\n",
       "      <td>9.302</td>\n",
       "      <td>9.233</td>\n",
       "      <td>9.165</td>\n",
       "      <td>9.104</td>\n",
       "      <td>9.043</td>\n",
       "      <td>8.980</td>\n",
       "      <td>...</td>\n",
       "      <td>4.156</td>\n",
       "      <td>4.145</td>\n",
       "      <td>4.137</td>\n",
       "      <td>4.126</td>\n",
       "      <td>4.116</td>\n",
       "      <td>4.103</td>\n",
       "      <td>4.095</td>\n",
       "      <td>4.086</td>\n",
       "      <td>4.080</td>\n",
       "      <td>4.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.340</td>\n",
       "      <td>12.224</td>\n",
       "      <td>12.110</td>\n",
       "      <td>11.987</td>\n",
       "      <td>11.891</td>\n",
       "      <td>11.817</td>\n",
       "      <td>11.742</td>\n",
       "      <td>11.665</td>\n",
       "      <td>11.603</td>\n",
       "      <td>11.530</td>\n",
       "      <td>...</td>\n",
       "      <td>4.615</td>\n",
       "      <td>4.603</td>\n",
       "      <td>4.592</td>\n",
       "      <td>4.579</td>\n",
       "      <td>4.567</td>\n",
       "      <td>4.555</td>\n",
       "      <td>4.540</td>\n",
       "      <td>4.529</td>\n",
       "      <td>4.514</td>\n",
       "      <td>4.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.455</td>\n",
       "      <td>17.362</td>\n",
       "      <td>17.271</td>\n",
       "      <td>17.180</td>\n",
       "      <td>17.090</td>\n",
       "      <td>16.999</td>\n",
       "      <td>16.908</td>\n",
       "      <td>16.816</td>\n",
       "      <td>16.719</td>\n",
       "      <td>16.619</td>\n",
       "      <td>...</td>\n",
       "      <td>5.481</td>\n",
       "      <td>5.469</td>\n",
       "      <td>5.458</td>\n",
       "      <td>5.446</td>\n",
       "      <td>5.436</td>\n",
       "      <td>5.425</td>\n",
       "      <td>5.413</td>\n",
       "      <td>5.403</td>\n",
       "      <td>5.392</td>\n",
       "      <td>5.381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss_epoch_1  loss_epoch_2  loss_epoch_3  loss_epoch_4  loss_epoch_5  \\\n",
       "count       100.000       100.000       100.000       100.000       100.000   \n",
       "mean         10.330        10.280        10.229        10.179        10.128   \n",
       "std           2.636         2.612         2.589         2.565         2.541   \n",
       "min           6.586         6.561         6.536         6.512         6.489   \n",
       "25%           8.090         8.055         8.021         7.990         7.963   \n",
       "50%           9.573         9.506         9.438         9.370         9.302   \n",
       "75%          12.340        12.224        12.110        11.987        11.891   \n",
       "max          17.455        17.362        17.271        17.180        17.090   \n",
       "\n",
       "       loss_epoch_6  loss_epoch_7  loss_epoch_8  loss_epoch_9  loss_epoch_10  \\\n",
       "count       100.000       100.000       100.000       100.000        100.000   \n",
       "mean         10.077        10.024         9.971         9.915          9.858   \n",
       "std           2.516         2.491         2.465         2.437          2.409   \n",
       "min           6.466         6.443         6.421         6.400          6.379   \n",
       "25%           7.937         7.911         7.886         7.865          7.822   \n",
       "50%           9.233         9.165         9.104         9.043          8.980   \n",
       "75%          11.817        11.742        11.665        11.603         11.530   \n",
       "max          16.999        16.908        16.816        16.719         16.619   \n",
       "\n",
       "       ...  loss_epoch_191  loss_epoch_192  loss_epoch_193  loss_epoch_194  \\\n",
       "count  ...         100.000         100.000         100.000         100.000   \n",
       "mean   ...           4.234           4.225           4.216           4.206   \n",
       "std    ...           0.528           0.527           0.526           0.525   \n",
       "min    ...           3.168           3.160           3.151           3.144   \n",
       "25%    ...           3.858           3.851           3.842           3.833   \n",
       "50%    ...           4.156           4.145           4.137           4.126   \n",
       "75%    ...           4.615           4.603           4.592           4.579   \n",
       "max    ...           5.481           5.469           5.458           5.446   \n",
       "\n",
       "       loss_epoch_195  loss_epoch_196  loss_epoch_197  loss_epoch_198  \\\n",
       "count         100.000         100.000         100.000         100.000   \n",
       "mean            4.197           4.188           4.179           4.170   \n",
       "std             0.524           0.523           0.522           0.521   \n",
       "min             3.134           3.125           3.117           3.108   \n",
       "25%             3.827           3.817           3.807           3.800   \n",
       "50%             4.116           4.103           4.095           4.086   \n",
       "75%             4.567           4.555           4.540           4.529   \n",
       "max             5.436           5.425           5.413           5.403   \n",
       "\n",
       "       loss_epoch_199  loss_epoch_200  \n",
       "count         100.000         100.000  \n",
       "mean            4.160           4.151  \n",
       "std             0.520           0.519  \n",
       "min             3.099           3.091  \n",
       "25%             3.795           3.783  \n",
       "50%             4.080           4.074  \n",
       "75%             4.514           4.502  \n",
       "max             5.392           5.381  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:19.074641Z",
     "start_time": "2020-11-23T18:46:18.365191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss_epoch_1</th>\n",
       "      <th>val_loss_epoch_2</th>\n",
       "      <th>val_loss_epoch_3</th>\n",
       "      <th>val_loss_epoch_4</th>\n",
       "      <th>val_loss_epoch_5</th>\n",
       "      <th>val_loss_epoch_6</th>\n",
       "      <th>val_loss_epoch_7</th>\n",
       "      <th>val_loss_epoch_8</th>\n",
       "      <th>val_loss_epoch_9</th>\n",
       "      <th>val_loss_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>val_loss_epoch_191</th>\n",
       "      <th>val_loss_epoch_192</th>\n",
       "      <th>val_loss_epoch_193</th>\n",
       "      <th>val_loss_epoch_194</th>\n",
       "      <th>val_loss_epoch_195</th>\n",
       "      <th>val_loss_epoch_196</th>\n",
       "      <th>val_loss_epoch_197</th>\n",
       "      <th>val_loss_epoch_198</th>\n",
       "      <th>val_loss_epoch_199</th>\n",
       "      <th>val_loss_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.271</td>\n",
       "      <td>10.220</td>\n",
       "      <td>10.170</td>\n",
       "      <td>10.119</td>\n",
       "      <td>10.068</td>\n",
       "      <td>10.016</td>\n",
       "      <td>9.963</td>\n",
       "      <td>9.909</td>\n",
       "      <td>9.852</td>\n",
       "      <td>9.794</td>\n",
       "      <td>...</td>\n",
       "      <td>4.324</td>\n",
       "      <td>4.316</td>\n",
       "      <td>4.307</td>\n",
       "      <td>4.298</td>\n",
       "      <td>4.289</td>\n",
       "      <td>4.280</td>\n",
       "      <td>4.271</td>\n",
       "      <td>4.263</td>\n",
       "      <td>4.254</td>\n",
       "      <td>4.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.646</td>\n",
       "      <td>2.622</td>\n",
       "      <td>2.599</td>\n",
       "      <td>2.575</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.474</td>\n",
       "      <td>2.446</td>\n",
       "      <td>2.418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.059</td>\n",
       "      <td>6.046</td>\n",
       "      <td>6.033</td>\n",
       "      <td>6.021</td>\n",
       "      <td>6.009</td>\n",
       "      <td>5.997</td>\n",
       "      <td>5.985</td>\n",
       "      <td>5.973</td>\n",
       "      <td>5.961</td>\n",
       "      <td>5.948</td>\n",
       "      <td>...</td>\n",
       "      <td>3.008</td>\n",
       "      <td>2.995</td>\n",
       "      <td>2.983</td>\n",
       "      <td>2.977</td>\n",
       "      <td>2.964</td>\n",
       "      <td>2.952</td>\n",
       "      <td>2.940</td>\n",
       "      <td>2.934</td>\n",
       "      <td>2.922</td>\n",
       "      <td>2.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.073</td>\n",
       "      <td>8.041</td>\n",
       "      <td>8.014</td>\n",
       "      <td>7.990</td>\n",
       "      <td>7.951</td>\n",
       "      <td>7.921</td>\n",
       "      <td>7.892</td>\n",
       "      <td>7.846</td>\n",
       "      <td>7.818</td>\n",
       "      <td>7.779</td>\n",
       "      <td>...</td>\n",
       "      <td>3.902</td>\n",
       "      <td>3.890</td>\n",
       "      <td>3.879</td>\n",
       "      <td>3.871</td>\n",
       "      <td>3.862</td>\n",
       "      <td>3.854</td>\n",
       "      <td>3.849</td>\n",
       "      <td>3.843</td>\n",
       "      <td>3.835</td>\n",
       "      <td>3.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.586</td>\n",
       "      <td>9.540</td>\n",
       "      <td>9.510</td>\n",
       "      <td>9.478</td>\n",
       "      <td>9.433</td>\n",
       "      <td>9.389</td>\n",
       "      <td>9.344</td>\n",
       "      <td>9.299</td>\n",
       "      <td>9.254</td>\n",
       "      <td>9.216</td>\n",
       "      <td>...</td>\n",
       "      <td>4.227</td>\n",
       "      <td>4.220</td>\n",
       "      <td>4.212</td>\n",
       "      <td>4.206</td>\n",
       "      <td>4.200</td>\n",
       "      <td>4.193</td>\n",
       "      <td>4.187</td>\n",
       "      <td>4.180</td>\n",
       "      <td>4.175</td>\n",
       "      <td>4.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.413</td>\n",
       "      <td>12.336</td>\n",
       "      <td>12.238</td>\n",
       "      <td>12.162</td>\n",
       "      <td>12.086</td>\n",
       "      <td>11.974</td>\n",
       "      <td>11.912</td>\n",
       "      <td>11.854</td>\n",
       "      <td>11.778</td>\n",
       "      <td>11.673</td>\n",
       "      <td>...</td>\n",
       "      <td>4.709</td>\n",
       "      <td>4.697</td>\n",
       "      <td>4.683</td>\n",
       "      <td>4.674</td>\n",
       "      <td>4.669</td>\n",
       "      <td>4.662</td>\n",
       "      <td>4.656</td>\n",
       "      <td>4.649</td>\n",
       "      <td>4.643</td>\n",
       "      <td>4.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.887</td>\n",
       "      <td>17.790</td>\n",
       "      <td>17.692</td>\n",
       "      <td>17.595</td>\n",
       "      <td>17.497</td>\n",
       "      <td>17.398</td>\n",
       "      <td>17.297</td>\n",
       "      <td>17.193</td>\n",
       "      <td>17.087</td>\n",
       "      <td>16.975</td>\n",
       "      <td>...</td>\n",
       "      <td>5.770</td>\n",
       "      <td>5.757</td>\n",
       "      <td>5.740</td>\n",
       "      <td>5.726</td>\n",
       "      <td>5.713</td>\n",
       "      <td>5.700</td>\n",
       "      <td>5.686</td>\n",
       "      <td>5.672</td>\n",
       "      <td>5.658</td>\n",
       "      <td>5.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val_loss_epoch_1  val_loss_epoch_2  val_loss_epoch_3  val_loss_epoch_4  \\\n",
       "count           100.000           100.000           100.000           100.000   \n",
       "mean             10.271            10.220            10.170            10.119   \n",
       "std               2.646             2.622             2.599             2.575   \n",
       "min               6.059             6.046             6.033             6.021   \n",
       "25%               8.073             8.041             8.014             7.990   \n",
       "50%               9.586             9.540             9.510             9.478   \n",
       "75%              12.413            12.336            12.238            12.162   \n",
       "max              17.887            17.790            17.692            17.595   \n",
       "\n",
       "       val_loss_epoch_5  val_loss_epoch_6  val_loss_epoch_7  val_loss_epoch_8  \\\n",
       "count           100.000           100.000           100.000           100.000   \n",
       "mean             10.068            10.016             9.963             9.909   \n",
       "std               2.551             2.526             2.500             2.474   \n",
       "min               6.009             5.997             5.985             5.973   \n",
       "25%               7.951             7.921             7.892             7.846   \n",
       "50%               9.433             9.389             9.344             9.299   \n",
       "75%              12.086            11.974            11.912            11.854   \n",
       "max              17.497            17.398            17.297            17.193   \n",
       "\n",
       "       val_loss_epoch_9  val_loss_epoch_10  ...  val_loss_epoch_191  \\\n",
       "count           100.000            100.000  ...             100.000   \n",
       "mean              9.852              9.794  ...               4.324   \n",
       "std               2.446              2.418  ...               0.592   \n",
       "min               5.961              5.948  ...               3.008   \n",
       "25%               7.818              7.779  ...               3.902   \n",
       "50%               9.254              9.216  ...               4.227   \n",
       "75%              11.778             11.673  ...               4.709   \n",
       "max              17.087             16.975  ...               5.770   \n",
       "\n",
       "       val_loss_epoch_192  val_loss_epoch_193  val_loss_epoch_194  \\\n",
       "count             100.000             100.000             100.000   \n",
       "mean                4.316               4.307               4.298   \n",
       "std                 0.591               0.591               0.589   \n",
       "min                 2.995               2.983               2.977   \n",
       "25%                 3.890               3.879               3.871   \n",
       "50%                 4.220               4.212               4.206   \n",
       "75%                 4.697               4.683               4.674   \n",
       "max                 5.757               5.740               5.726   \n",
       "\n",
       "       val_loss_epoch_195  val_loss_epoch_196  val_loss_epoch_197  \\\n",
       "count             100.000             100.000             100.000   \n",
       "mean                4.289               4.280               4.271   \n",
       "std                 0.588               0.588               0.587   \n",
       "min                 2.964               2.952               2.940   \n",
       "25%                 3.862               3.854               3.849   \n",
       "50%                 4.200               4.193               4.187   \n",
       "75%                 4.669               4.662               4.656   \n",
       "max                 5.713               5.700               5.686   \n",
       "\n",
       "       val_loss_epoch_198  val_loss_epoch_199  val_loss_epoch_200  \n",
       "count             100.000             100.000             100.000  \n",
       "mean                4.263               4.254               4.245  \n",
       "std                 0.586               0.585               0.584  \n",
       "min                 2.934               2.922               2.914  \n",
       "25%                 3.843               3.835               3.826  \n",
       "50%                 4.180               4.175               4.168  \n",
       "75%                 4.649               4.643               4.635  \n",
       "max                 5.672               5.658               5.645  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:19.782773Z",
     "start_time": "2020-11-23T18:46:19.077080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_epoch_1</th>\n",
       "      <th>metric_epoch_2</th>\n",
       "      <th>metric_epoch_3</th>\n",
       "      <th>metric_epoch_4</th>\n",
       "      <th>metric_epoch_5</th>\n",
       "      <th>metric_epoch_6</th>\n",
       "      <th>metric_epoch_7</th>\n",
       "      <th>metric_epoch_8</th>\n",
       "      <th>metric_epoch_9</th>\n",
       "      <th>metric_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>metric_epoch_191</th>\n",
       "      <th>metric_epoch_192</th>\n",
       "      <th>metric_epoch_193</th>\n",
       "      <th>metric_epoch_194</th>\n",
       "      <th>metric_epoch_195</th>\n",
       "      <th>metric_epoch_196</th>\n",
       "      <th>metric_epoch_197</th>\n",
       "      <th>metric_epoch_198</th>\n",
       "      <th>metric_epoch_199</th>\n",
       "      <th>metric_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.339</td>\n",
       "      <td>1.296</td>\n",
       "      <td>1.321</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.412</td>\n",
       "      <td>1.451</td>\n",
       "      <td>1.632</td>\n",
       "      <td>1.680</td>\n",
       "      <td>1.602</td>\n",
       "      <td>1.654</td>\n",
       "      <td>...</td>\n",
       "      <td>2.530</td>\n",
       "      <td>2.493</td>\n",
       "      <td>2.468</td>\n",
       "      <td>2.455</td>\n",
       "      <td>2.507</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.470</td>\n",
       "      <td>2.461</td>\n",
       "      <td>2.466</td>\n",
       "      <td>2.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.674</td>\n",
       "      <td>2.262</td>\n",
       "      <td>2.481</td>\n",
       "      <td>2.884</td>\n",
       "      <td>3.048</td>\n",
       "      <td>3.290</td>\n",
       "      <td>4.885</td>\n",
       "      <td>5.145</td>\n",
       "      <td>4.190</td>\n",
       "      <td>4.505</td>\n",
       "      <td>...</td>\n",
       "      <td>5.261</td>\n",
       "      <td>4.981</td>\n",
       "      <td>4.934</td>\n",
       "      <td>4.457</td>\n",
       "      <td>5.296</td>\n",
       "      <td>4.491</td>\n",
       "      <td>5.124</td>\n",
       "      <td>5.010</td>\n",
       "      <td>5.018</td>\n",
       "      <td>5.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.015</td>\n",
       "      <td>1.006</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175</td>\n",
       "      <td>1.169</td>\n",
       "      <td>1.188</td>\n",
       "      <td>1.172</td>\n",
       "      <td>1.189</td>\n",
       "      <td>1.163</td>\n",
       "      <td>1.160</td>\n",
       "      <td>1.164</td>\n",
       "      <td>1.172</td>\n",
       "      <td>1.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.031</td>\n",
       "      <td>1.023</td>\n",
       "      <td>1.023</td>\n",
       "      <td>1.022</td>\n",
       "      <td>1.024</td>\n",
       "      <td>1.025</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.049</td>\n",
       "      <td>1.059</td>\n",
       "      <td>1.073</td>\n",
       "      <td>...</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1.533</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1.546</td>\n",
       "      <td>1.556</td>\n",
       "      <td>1.550</td>\n",
       "      <td>1.552</td>\n",
       "      <td>1.543</td>\n",
       "      <td>1.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.055</td>\n",
       "      <td>1.060</td>\n",
       "      <td>1.062</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.110</td>\n",
       "      <td>1.140</td>\n",
       "      <td>1.153</td>\n",
       "      <td>1.169</td>\n",
       "      <td>1.190</td>\n",
       "      <td>...</td>\n",
       "      <td>2.022</td>\n",
       "      <td>2.033</td>\n",
       "      <td>2.023</td>\n",
       "      <td>2.043</td>\n",
       "      <td>2.031</td>\n",
       "      <td>2.061</td>\n",
       "      <td>2.016</td>\n",
       "      <td>2.028</td>\n",
       "      <td>2.031</td>\n",
       "      <td>2.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.789</td>\n",
       "      <td>23.648</td>\n",
       "      <td>25.829</td>\n",
       "      <td>29.861</td>\n",
       "      <td>31.473</td>\n",
       "      <td>33.921</td>\n",
       "      <td>49.903</td>\n",
       "      <td>52.508</td>\n",
       "      <td>42.928</td>\n",
       "      <td>46.086</td>\n",
       "      <td>...</td>\n",
       "      <td>49.250</td>\n",
       "      <td>46.672</td>\n",
       "      <td>46.879</td>\n",
       "      <td>39.748</td>\n",
       "      <td>50.906</td>\n",
       "      <td>42.080</td>\n",
       "      <td>49.103</td>\n",
       "      <td>47.747</td>\n",
       "      <td>47.858</td>\n",
       "      <td>49.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       metric_epoch_1  metric_epoch_2  metric_epoch_3  metric_epoch_4  \\\n",
       "count         100.000         100.000         100.000         100.000   \n",
       "mean            1.339           1.296           1.321           1.375   \n",
       "std             2.674           2.262           2.481           2.884   \n",
       "min             0.981           0.977           0.976           0.973   \n",
       "25%             1.015           1.006           1.003           1.000   \n",
       "50%             1.031           1.023           1.023           1.022   \n",
       "75%             1.055           1.060           1.062           1.069   \n",
       "max            27.789          23.648          25.829          29.861   \n",
       "\n",
       "       metric_epoch_5  metric_epoch_6  metric_epoch_7  metric_epoch_8  \\\n",
       "count         100.000         100.000         100.000         100.000   \n",
       "mean            1.412           1.451           1.632           1.680   \n",
       "std             3.048           3.290           4.885           5.145   \n",
       "min             0.970           0.969           0.967           0.971   \n",
       "25%             0.999           1.003           1.005           1.005   \n",
       "50%             1.024           1.025           1.034           1.049   \n",
       "75%             1.100           1.110           1.140           1.153   \n",
       "max            31.473          33.921          49.903          52.508   \n",
       "\n",
       "       metric_epoch_9  metric_epoch_10  ...  metric_epoch_191  \\\n",
       "count         100.000          100.000  ...           100.000   \n",
       "mean            1.602            1.654  ...             2.530   \n",
       "std             4.190            4.505  ...             5.261   \n",
       "min             0.978            0.975  ...             0.483   \n",
       "25%             1.005            1.011  ...             1.175   \n",
       "50%             1.059            1.073  ...             1.540   \n",
       "75%             1.169            1.190  ...             2.022   \n",
       "max            42.928           46.086  ...            49.250   \n",
       "\n",
       "       metric_epoch_192  metric_epoch_193  metric_epoch_194  metric_epoch_195  \\\n",
       "count           100.000           100.000           100.000           100.000   \n",
       "mean              2.493             2.468             2.455             2.507   \n",
       "std               4.981             4.934             4.457             5.296   \n",
       "min               0.480             0.497             0.483             0.486   \n",
       "25%               1.169             1.188             1.172             1.189   \n",
       "50%               1.533             1.541             1.541             1.546   \n",
       "75%               2.033             2.023             2.043             2.031   \n",
       "max              46.672            46.879            39.748            50.906   \n",
       "\n",
       "       metric_epoch_196  metric_epoch_197  metric_epoch_198  metric_epoch_199  \\\n",
       "count           100.000           100.000           100.000           100.000   \n",
       "mean              2.410             2.470             2.461             2.466   \n",
       "std               4.491             5.124             5.010             5.018   \n",
       "min               0.497             0.483             0.483             0.478   \n",
       "25%               1.163             1.160             1.164             1.172   \n",
       "50%               1.556             1.550             1.552             1.543   \n",
       "75%               2.061             2.016             2.028             2.031   \n",
       "max              42.080            49.103            47.747            47.858   \n",
       "\n",
       "       metric_epoch_200  \n",
       "count           100.000  \n",
       "mean              2.474  \n",
       "std               5.186  \n",
       "min               0.479  \n",
       "25%               1.162  \n",
       "50%               1.546  \n",
       "75%               2.041  \n",
       "max              49.708  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:20.541408Z",
     "start_time": "2020-11-23T18:46:19.785382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_metric_epoch_1</th>\n",
       "      <th>val_metric_epoch_2</th>\n",
       "      <th>val_metric_epoch_3</th>\n",
       "      <th>val_metric_epoch_4</th>\n",
       "      <th>val_metric_epoch_5</th>\n",
       "      <th>val_metric_epoch_6</th>\n",
       "      <th>val_metric_epoch_7</th>\n",
       "      <th>val_metric_epoch_8</th>\n",
       "      <th>val_metric_epoch_9</th>\n",
       "      <th>val_metric_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>val_metric_epoch_191</th>\n",
       "      <th>val_metric_epoch_192</th>\n",
       "      <th>val_metric_epoch_193</th>\n",
       "      <th>val_metric_epoch_194</th>\n",
       "      <th>val_metric_epoch_195</th>\n",
       "      <th>val_metric_epoch_196</th>\n",
       "      <th>val_metric_epoch_197</th>\n",
       "      <th>val_metric_epoch_198</th>\n",
       "      <th>val_metric_epoch_199</th>\n",
       "      <th>val_metric_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.076</td>\n",
       "      <td>1.073</td>\n",
       "      <td>1.074</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.094</td>\n",
       "      <td>1.115</td>\n",
       "      <td>1.138</td>\n",
       "      <td>1.162</td>\n",
       "      <td>1.187</td>\n",
       "      <td>1.214</td>\n",
       "      <td>...</td>\n",
       "      <td>2.435</td>\n",
       "      <td>2.431</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.425</td>\n",
       "      <td>2.421</td>\n",
       "      <td>2.417</td>\n",
       "      <td>2.415</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.406</td>\n",
       "      <td>2.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.263</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.634</td>\n",
       "      <td>...</td>\n",
       "      <td>5.095</td>\n",
       "      <td>5.078</td>\n",
       "      <td>5.072</td>\n",
       "      <td>5.063</td>\n",
       "      <td>5.062</td>\n",
       "      <td>5.048</td>\n",
       "      <td>5.046</td>\n",
       "      <td>5.027</td>\n",
       "      <td>5.029</td>\n",
       "      <td>5.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.010</td>\n",
       "      <td>1.004</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.006</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.006</td>\n",
       "      <td>1.007</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.223</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.234</td>\n",
       "      <td>1.241</td>\n",
       "      <td>1.240</td>\n",
       "      <td>1.237</td>\n",
       "      <td>1.231</td>\n",
       "      <td>1.229</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.055</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.055</td>\n",
       "      <td>1.052</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.072</td>\n",
       "      <td>1.088</td>\n",
       "      <td>1.104</td>\n",
       "      <td>1.116</td>\n",
       "      <td>1.134</td>\n",
       "      <td>...</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1.956</td>\n",
       "      <td>1.948</td>\n",
       "      <td>1.941</td>\n",
       "      <td>1.931</td>\n",
       "      <td>1.930</td>\n",
       "      <td>1.927</td>\n",
       "      <td>1.928</td>\n",
       "      <td>1.923</td>\n",
       "      <td>1.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.259</td>\n",
       "      <td>2.565</td>\n",
       "      <td>2.764</td>\n",
       "      <td>3.084</td>\n",
       "      <td>3.415</td>\n",
       "      <td>3.750</td>\n",
       "      <td>4.091</td>\n",
       "      <td>4.430</td>\n",
       "      <td>4.774</td>\n",
       "      <td>5.126</td>\n",
       "      <td>...</td>\n",
       "      <td>46.233</td>\n",
       "      <td>46.069</td>\n",
       "      <td>45.998</td>\n",
       "      <td>45.907</td>\n",
       "      <td>45.914</td>\n",
       "      <td>45.736</td>\n",
       "      <td>45.723</td>\n",
       "      <td>45.504</td>\n",
       "      <td>45.596</td>\n",
       "      <td>45.538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val_metric_epoch_1  val_metric_epoch_2  val_metric_epoch_3  \\\n",
       "count             100.000             100.000             100.000   \n",
       "mean                1.076               1.073               1.074   \n",
       "std                 0.263               0.234               0.232   \n",
       "min                 0.959               0.951               0.942   \n",
       "25%                 1.000               0.994               0.990   \n",
       "50%                 1.010               1.004               1.002   \n",
       "75%                 1.055               1.053               1.055   \n",
       "max                 3.259               2.565               2.764   \n",
       "\n",
       "       val_metric_epoch_4  val_metric_epoch_5  val_metric_epoch_6  \\\n",
       "count             100.000             100.000             100.000   \n",
       "mean                1.078               1.094               1.115   \n",
       "std                 0.258               0.302               0.357   \n",
       "min                 0.934               0.926               0.917   \n",
       "25%                 0.983               0.983               0.982   \n",
       "50%                 1.005               1.006               1.005   \n",
       "75%                 1.052               1.068               1.072   \n",
       "max                 3.084               3.415               3.750   \n",
       "\n",
       "       val_metric_epoch_7  val_metric_epoch_8  val_metric_epoch_9  \\\n",
       "count             100.000             100.000             100.000   \n",
       "mean                1.138               1.162               1.187   \n",
       "std                 0.419               0.486               0.558   \n",
       "min                 0.908               0.900               0.893   \n",
       "25%                 0.983               0.982               0.982   \n",
       "50%                 1.006               1.007               1.015   \n",
       "75%                 1.088               1.104               1.116   \n",
       "max                 4.091               4.430               4.774   \n",
       "\n",
       "       val_metric_epoch_10  ...  val_metric_epoch_191  val_metric_epoch_192  \\\n",
       "count              100.000  ...               100.000               100.000   \n",
       "mean                 1.214  ...                 2.435                 2.431   \n",
       "std                  0.634  ...                 5.095                 5.078   \n",
       "min                  0.886  ...                 0.390                 0.392   \n",
       "25%                  0.982  ...                 0.937                 0.936   \n",
       "50%                  1.018  ...                 1.223                 1.225   \n",
       "75%                  1.134  ...                 1.960                 1.956   \n",
       "max                  5.126  ...                46.233                46.069   \n",
       "\n",
       "       val_metric_epoch_193  val_metric_epoch_194  val_metric_epoch_195  \\\n",
       "count               100.000               100.000               100.000   \n",
       "mean                  2.428                 2.425                 2.421   \n",
       "std                   5.072                 5.063                 5.062   \n",
       "min                   0.393                 0.394                 0.395   \n",
       "25%                   0.934                 0.932                 0.931   \n",
       "50%                   1.234                 1.241                 1.240   \n",
       "75%                   1.948                 1.941                 1.931   \n",
       "max                  45.998                45.907                45.914   \n",
       "\n",
       "       val_metric_epoch_196  val_metric_epoch_197  val_metric_epoch_198  \\\n",
       "count               100.000               100.000               100.000   \n",
       "mean                  2.417                 2.415                 2.410   \n",
       "std                   5.048                 5.046                 5.027   \n",
       "min                   0.396                 0.398                 0.399   \n",
       "25%                   0.930                 0.929                 0.928   \n",
       "50%                   1.237                 1.231                 1.229   \n",
       "75%                   1.930                 1.927                 1.928   \n",
       "max                  45.736                45.723                45.504   \n",
       "\n",
       "       val_metric_epoch_199  val_metric_epoch_200  \n",
       "count               100.000               100.000  \n",
       "mean                  2.406                 2.403  \n",
       "std                   5.029                 5.024  \n",
       "min                   0.399                 0.402  \n",
       "25%                   0.928                 0.925  \n",
       "50%                   1.225                 1.221  \n",
       "75%                   1.923                 1.924  \n",
       "max                  45.596                45.538  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:22.448057Z",
     "start_time": "2020-11-23T18:46:20.544386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for metric\n",
    "path = './data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.png'\n",
    "\n",
    "adjustment_threshold_metric = 0#100\n",
    "    \n",
    "metric_df_adjusted = metric_df.copy(deep=True)\n",
    "if adjustment_threshold_metric > 0:\n",
    "    metric_df_adjusted[metric_df_adjusted.columns] = np.where(metric_df_adjusted[metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, metric_df_adjusted[metric_df_adjusted.columns])\n",
    "    \n",
    "val_metric_df_adjusted = val_metric_df.copy(deep=True)\n",
    "if adjustment_threshold_metric > 0:\n",
    "    val_metric_df_adjusted[val_metric_df_adjusted.columns] = np.where(val_metric_df_adjusted[val_metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, val_metric_df_adjusted[val_metric_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model metric')\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:46:24.276748Z",
     "start_time": "2020-11-23T18:46:22.450408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "path = './data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/loss_' + str(data_size) +  '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_amax_' + str(a_max) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.png'\n",
    "\n",
    "adjustment_threshold_loss = 0#10000\n",
    "    \n",
    "loss_df_adjusted = loss_df.copy(deep=True)\n",
    "\n",
    "if adjustment_threshold_loss > 0:\n",
    "    loss_df_adjusted[loss_df_adjusted.columns] = np.where(loss_df_adjusted[loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, loss_df_adjusted[loss_df_adjusted.columns])\n",
    "    \n",
    "val_loss_df_adjusted = val_loss_df.copy(deep=True)\n",
    "if adjustment_threshold_loss > 0:\n",
    "    val_loss_df_adjusted[val_loss_df_adjusted.columns] = np.where(val_loss_df_adjusted[val_loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, val_loss_df_adjusted[val_loss_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
