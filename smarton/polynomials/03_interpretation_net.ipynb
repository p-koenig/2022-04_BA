{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training\n",
    "\n",
    "# Experiment 1: I-Net Performance for Different Algebras and Complexities\n",
    "# Experiment 2: I-Net Performance Comparison for Î»-Nets with Different Training Levels\n",
    "# Experiment 3: I-Net Performance Comparison Different Training Data Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:41:53.483060Z",
     "start_time": "2020-11-24T18:41:53.472391Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def nCr(n,r):\n",
    "    f = math.factorial\n",
    "    return f(n) // f(r) // f(n-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:41:53.650673Z",
     "start_time": "2020-11-24T18:41:53.635973Z"
    }
   },
   "outputs": [],
   "source": [
    "d = 3  \n",
    "n = 4\n",
    "sparsity = nCr(n+d, d)\n",
    "\n",
    "x_max = 1#10 #this number excluded\n",
    "x_min = -1#-10\n",
    "x_step = 0.01#0.1\n",
    "a_max = 10 #this number excluded\n",
    "a_min = -10\n",
    "a_step = 0.1\n",
    "\n",
    "n_jobs = -3\n",
    "\n",
    "\n",
    "data_size = 100 #for loading lambda models\n",
    "\n",
    "#specify interpretation net structure\n",
    "optimizer = 'adam'\n",
    "dropout = 0\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "interpretation_network_layers = [2048]\n",
    "\n",
    "random_evaluation_dataset_size = 500\n",
    "\n",
    "#lambda net specifications for loading (need to be set according to lambda net training to load correct weights)\n",
    "epochs_lambda = 200\n",
    "batch_lambda = 64\n",
    "lambda_network_layers = [5*sparsity]\n",
    "optimizer_lambda = '_' + 'SGD'\n",
    "\n",
    "\n",
    "lambda_dataset_size = 1000\n",
    "\n",
    "#set if multi_epoch_analysis should be performed\n",
    "multi_epoch_analysis = True\n",
    "each_epochs_save_lambda = 10 #None if no checkpointing (otherwise set according to lambda-net training)\n",
    "epoch_start = 0 #use to skip first epochs in multi_epoch_analysis\n",
    "\n",
    "#set if samples analysis should be performed\n",
    "samples_list = None#[100, 500, 750, 1000, 2500, 5000, 7500, 10000, 15000, 20000, 25000, 28125] \n",
    "\n",
    "evaluate_with_real_function = False\n",
    "consider_labels_training = False\n",
    "\n",
    "same_training_all_lambda_nets = False\n",
    "fixed_seed_lambda_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:41:53.848920Z",
     "start_time": "2020-11-24T18:41:53.836795Z"
    }
   },
   "outputs": [],
   "source": [
    "##############DO NOT CHANGE###################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n] \n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "epochs_save_range_lambda = range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda) if each_epochs_save_lambda == 1 else range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda+1)\n",
    "\n",
    "advanced_metric_dataset_size = 10#200\n",
    "\n",
    "use_gpu = False\n",
    "if use_gpu:\n",
    "    gpu_numbers = '0'\n",
    "else:\n",
    "    gpu_numbers = ''\n",
    "\n",
    "if fixed_seed_lambda_training:\n",
    "    seed_shuffle_string = '_SeedMethod'\n",
    "elif not fixed_seed_lambda_training:\n",
    "    seed_shuffle_string = '_NoSeedMethod'\n",
    "\n",
    "if same_training_all_lambda_nets:\n",
    "    training_string = '_same'\n",
    "else:\n",
    "    training_string = '_diverse'\n",
    "\n",
    "layers_str = ''.join([str(neurons) + '-' for neurons in lambda_network_layers])\n",
    "\n",
    "structure = '_' + layers_str + str(epochs_lambda) + 'e' + str(batch_lambda) + 'b' + optimizer_lambda\n",
    "filename = seed_shuffle_string + '_' + str(RANDOM_SEED) + structure\n",
    "\n",
    "interpretation_network_string = 'drop' + str(dropout) + 'e' + str(epochs) + 'b' + str(batch_size) + '_' + str(interpretation_network_layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:01.508228Z",
     "start_time": "2020-11-24T18:41:54.109719Z"
    }
   },
   "outputs": [],
   "source": [
    "import ttg\n",
    "from itertools import product       # forms cartesian products\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "\n",
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import colored\n",
    "import math\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "import keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import random \n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:01.521163Z",
     "start_time": "2020-11-24T18:42:01.512266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:42:56.243472Z",
     "start_time": "2020-11-25T08:42:56.210613Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Utility Functions\n",
    "\n",
    "ALPHABET = \\\n",
    "  \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "def encode (n):\n",
    "    try:\n",
    "        return ALPHABET [n]\n",
    "    except IndexError:\n",
    "        raise Exception (\"cannot encode: %s\" % n)\n",
    "        \n",
    "def dec_to_base (dec = 0, base = 16):\n",
    "    if dec < base:\n",
    "        return encode (dec)\n",
    "    else:\n",
    "        return dec_to_base (dec // base, base) + encode (dec % base)\n",
    "\n",
    "def return_float_tensor_representation(some_representation, dtype=tf.float32):\n",
    "    if tf.is_tensor(some_representation):\n",
    "        some_representation = tf.dtypes.cast(some_representation, dtype) \n",
    "    else:\n",
    "        some_representation = tf.convert_to_tensor(some_representation)\n",
    "        some_representation = tf.dtypes.cast(some_representation, dtype) \n",
    "        \n",
    "    if not tf.is_tensor(some_representation):\n",
    "        raise SystemExit('Given variable is no instance of ' + str(dtype) + ':' + str(some_representation))\n",
    "     \n",
    "    return some_representation\n",
    "\n",
    "\n",
    "def return_numpy_representation(some_representation):\n",
    "    if isinstance(some_representation, pd.DataFrame):\n",
    "        some_representation = some_representation.values\n",
    "        \n",
    "    if isinstance(some_representation, list):\n",
    "        some_representation = np.array(some_representation)\n",
    "    \n",
    "    if not isinstance(some_representation, np.ndarray):\n",
    "        raise SystemExit('Given variable is no instance of ' + str(np.ndarray) + ':' + str(some_representation))\n",
    "    \n",
    "    return some_representation\n",
    "\n",
    "def mergeDict(dict1, dict2):\n",
    "    #Merge dictionaries and keep values of common keys in list\n",
    "    newDict = {**dict1, **dict2}\n",
    "    for key, value in newDict.items():\n",
    "        if key in dict1 and key in dict2:\n",
    "            if isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend(value)\n",
    "            elif isinstance(dict1[key], list) and not isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend([value])\n",
    "            elif not isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = [dict1[key]]\n",
    "                newDict[key].extend(value)\n",
    "            else:\n",
    "                newDict[key] = [dict1[key], value]\n",
    "    return newDict\n",
    "\n",
    "def return_callbacks_from_string(callback_string_list):\n",
    "    callbacks = [] if len(callback_string_list) > 0 else None\n",
    "    if 'plot_losses_callback' in callback_string_list:\n",
    "        callbacks.append(PlotLossesKerasTF())\n",
    "    if 'reduce_lr_loss' in callback_string_list:\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=epochs/10, verbose=0, min_delta=0, mode='min') #epsilon\n",
    "        callbacks.append(reduce_lr_loss)\n",
    "    if 'early_stopping' in callback_string_list:\n",
    "        earlyStopping = EarlyStopping(monitor='val_loss', patience=10, min_delta=0, verbose=0, mode='min')\n",
    "        callbacks.append(earlyStopping)\n",
    "        \n",
    "    if not multi_epoch_analysis and samples_list == None: \n",
    "        callbacks.append(TQDMNotebookCallback())\n",
    "        \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of Monomial Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:01.665585Z",
     "start_time": "2020-11-24T18:42:01.571164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79ea990bfa043168f79c22ea43290c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 256\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0013', '0020', '0021', '0022', '0023', '0030', '0031', '0032', '0033', '0100', '0101', '0102', '0103', '0110', '0111', '0112', '0113', '0120', '0121', '0122', '0123', '0130', '0131', '0132', '0133', '0200', '0201', '0202', '0203', '0210', '0211', '0212', '0213', '0220', '0221', '0222', '0223', '0230', '0231', '0232', '0233', '0300', '0301', '0302', '0303', '0310', '0311', '0312', '0313', '0320', '0321', '0322', '0323', '0330', '0331', '0332', '0333', '1000', '1001', '1002', '1003', '1010', '1011', '1012', '1013', '1020', '1021', '1022', '1023', '1030', '1031', '1032', '1033', '1100', '1101', '1102', '1103', '1110', '1111', '1112', '1113', '1120', '1121', '1122', '1123', '1130', '1131', '1132', '1133', '1200', '1201', '1202', '1203', '1210', '1211', '1212', '1213', '1220', '1221', '1222', '1223', '1230', '1231', '1232', '1233', '1300', '1301', '1302', '1303', '1310', '1311', '1312', '1313', '1320', '1321', '1322', '1323', '1330', '1331', '1332', '1333', '2000', '2001', '2002', '2003', '2010', '2011', '2012', '2013', '2020', '2021', '2022', '2023', '2030', '2031', '2032', '2033', '2100', '2101', '2102', '2103', '2110', '2111', '2112', '2113', '2120', '2121', '2122', '2123', '2130', '2131', '2132', '2133', '2200', '2201', '2202', '2203', '2210', '2211', '2212', '2213', '2220', '2221', '2222', '2223', '2230', '2231', '2232', '2233', '2300', '2301', '2302', '2303', '2310', '2311', '2312', '2313', '2320', '2321', '2322', '2323', '2330', '2331', '2332', '2333', '3000', '3001', '3002', '3003', '3010', '3011', '3012', '3013', '3020', '3021', '3022', '3023', '3030', '3031', '3032', '3033', '3100', '3101', '3102', '3103', '3110', '3111', '3112', '3113', '3120', '3121', '3122', '3123', '3130', '3131', '3132', '3133', '3200', '3201', '3202', '3203', '3210', '3211', '3212', '3213', '3220', '3221', '3222', '3223', '3230', '3231', '3232', '3233', '3300', '3301', '3302', '3303', '3310', '3311', '3312', '3313', '3320', '3321', '3322', '3323', '3330', '3331', '3332', '3333']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d09e26d3976440f94e2af4918ee79d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 35\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0020', '0021', '0030', '0100', '0101', '0102', '0110', '0111', '0120', '0200', '0201', '0210', '0300', '1000', '1001', '1002', '1010', '1011', '1020', '1100', '1101', '1110', '1200', '2000', '2001', '2010', '2100', '3000']\n"
     ]
    }
   ],
   "source": [
    "list_of_monomial_identifiers_extended = []\n",
    "for i in tqdm(range((d+1)**n)):    \n",
    "    monomial_identifier = dec_to_base(i, base = (d+1)).zfill(n) \n",
    "    list_of_monomial_identifiers_extended.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers_extended)\n",
    "\n",
    "list_of_monomial_identifiers = []\n",
    "for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "    monomial_identifier_values = list(map(int, list(monomial_identifier)))\n",
    "    if sum(monomial_identifier_values) <= d:\n",
    "        list_of_monomial_identifiers.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss/Error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:01.683883Z",
     "start_time": "2020-11-24T18:42:01.668808Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Manual TF Loss function for comparison with polynomials on function value basis\n",
    "\n",
    "def calculate_mae_fv(polynomial_true_pred):\n",
    "    polynomial_true = polynomial_true_pred[0]\n",
    "    polynomial_pred = polynomial_true_pred[1]\n",
    "    \n",
    "    global lambda_train_input\n",
    "    lambda_input = lambda_train_input\n",
    "    \n",
    "    for index, lambda_input_entry in enumerate(lambda_input):\n",
    "\n",
    "        value_without_coefficient = np.array([reduce(lambda x, y: x*y, [lambda_input_value**int(coefficient_multiplier) for coefficient_multiplier, lambda_input_value in zip(coefficient_multiplier_term, lambda_input_entry)]) for coefficient_multiplier_term in list_of_monomial_identifiers], dtype='float32')\n",
    "            \n",
    "        polynomial_true_value_per_term = tf.vectorized_map(lambda x: x[0]*x[1], (value_without_coefficient, polynomial_true))\n",
    "        polynomial_true_fv = tf.reduce_sum(polynomial_true_value_per_term)\n",
    "\n",
    "        polynomial_pred_value_per_term = tf.vectorized_map(lambda x: x[0]*x[1], (value_without_coefficient, polynomial_pred))\n",
    "        polynomial_pred_fv = tf.reduce_sum(polynomial_pred_value_per_term)\n",
    "        \n",
    "        if index == 0:   \n",
    "            result = tf.math.abs(tf.math.subtract(polynomial_true_fv, polynomial_pred_fv))\n",
    "        else:           \n",
    "            current_valiue = tf.math.abs(tf.math.subtract(polynomial_true_fv, polynomial_pred_fv))\n",
    "            result = tf.math.add(result, current_valiue)    \n",
    "            \n",
    "    return  tf.math.divide(result, lambda_input.shape[0]) #tf.random.uniform(shape=[1], minval=0.1, maxval=10.0)\n",
    "\n",
    "def mean_absolute_error_tf_fv(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.vectorized_map(calculate_mae_fv, (y_true, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T11:00:43.264095Z",
     "start_time": "2020-11-24T11:00:43.249095Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array([reduce(lambda x, y: x*y, [evaluation_value**int(coefficient_multiplier) for coefficient_multiplier, evaluation_value in zip(coefficient_multiplier_term, evaluation_entry)]) for coefficient_multiplier_term in list_of_monomial_identifiers], dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:47:21.206044Z",
     "start_time": "2020-11-24T18:47:21.193881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.34 -0.68  0.88  0.64]\n",
      " [ 0.85  0.73  0.25 -0.37]\n",
      " [ 0.57 -0.76 -0.52 -0.57]\n",
      " ...\n",
      " [ 0.28  0.01  0.55  0.22]\n",
      " [ 0.59  0.34  0.16 -0.88]\n",
      " [ 0.92  0.86  0.67 -0.14]]\n",
      "[[-0.34 -0.68  0.88  0.64]\n",
      " [ 0.85  0.73  0.25 -0.37]\n",
      " [ 0.57 -0.76 -0.52 -0.57]\n",
      " ...\n",
      " [ 0.28  0.01  0.55  0.22]\n",
      " [ 0.59  0.34  0.16 -0.88]\n",
      " [ 0.92  0.86  0.67 -0.14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-0.34, -0.68,  0.88,  0.64]),\n",
       " array([0.7225, 0.5329, 0.0625, 0.1369]),\n",
       " array([ 0.185193, -0.438976, -0.140608, -0.185193]),\n",
       " array([2.0736000e-04, 4.0960000e-05, 8.4934656e-01, 4.9787136e-01])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_entry = lambda_train_input[0]\n",
    "print(evaluation_entry)\n",
    "coefficient_multiplier_term = [1,2,3,4]\n",
    "print(evaluation_entry)\n",
    "[evaluation_value**int(coefficient_multiplier) for coefficient_multiplier, evaluation_value in zip(coefficient_multiplier_term, evaluation_entry)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mae_fv_lambda_wrapper(evaluation_dataset, list_of_monomial_identifiers)(polynomial_true, polynomial_pred, lambda_fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:55:18.875588Z",
     "start_time": "2020-11-24T18:55:18.860996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(35, 4), dtype=float64, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 2.],\n",
       "       [0., 0., 0., 3.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 2., 0.],\n",
       "       [0., 0., 2., 1.],\n",
       "       [0., 0., 3., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [0., 1., 0., 2.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [0., 1., 1., 1.],\n",
       "       [0., 1., 2., 0.],\n",
       "       [0., 2., 0., 0.],\n",
       "       [0., 2., 0., 1.],\n",
       "       [0., 2., 1., 0.],\n",
       "       [0., 3., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 0., 0., 2.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 1.],\n",
       "       [1., 0., 2., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 2., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [2., 0., 0., 1.],\n",
       "       [2., 0., 1., 0.],\n",
       "       [2., 1., 0., 0.],\n",
       "       [3., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_monomial_identifiers_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.vectorized_map(calculate_fv_from_data_wrapper(list_of_monomial_identifiers, polynomial_pred), (evaluation_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:57:48.219585Z",
     "start_time": "2020-11-24T18:57:48.130586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.34 -0.68  0.88  0.64], shape=(4,), dtype=float32)\n",
      "tf.Tensor([1. 2. 3. 4.], shape=(4,), dtype=float32)\n",
      "calculate_value_without_coefficient_wrapper\n",
      "(4,)\n",
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.017974824>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_entry = tf.constant(lambda_train_input[0][0], tf.float32)\n",
    "print(evaluation_entry)\n",
    "coefficient_multiplier_term = tf.constant([1.0,2.0,3.0,4.0], tf.float32)\n",
    "print(coefficient_multiplier_term)\n",
    "calculate_value_without_coefficient_wrapper(evaluation_entry)(coefficient_multiplier_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:59:00.595608Z",
     "start_time": "2020-11-24T18:59:00.584128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.02843450e+01, -2.43461197e+00,  9.36263804e-01, -2.26335769e-01,\n",
       "       -1.29452200e+01, -5.79299579e-01,  2.78989860e-01,  7.56058328e-01,\n",
       "        9.47982839e-01,  8.96193137e-01,  3.11938798e+00,  3.08603460e+00,\n",
       "        3.12727280e-02,  4.35735082e-01,  2.96634370e-01, -2.70302487e-01,\n",
       "        1.45772577e+00,  1.67981372e-01,  8.97095978e-01, -8.94430634e-02,\n",
       "        5.52497645e+00, -5.49232391e-01,  3.70975567e-03,  2.29478658e+00,\n",
       "       -1.22997219e-01, -8.06895410e-01, -1.86962550e-01, -2.41871049e-01,\n",
       "        7.98170054e-01, -4.36566528e-01,  1.77331870e+00,  2.97839577e-02,\n",
       "        5.82040971e-01, -4.25621960e-01, -6.21066911e-02])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:00:21.998316Z",
     "start_time": "2020-11-24T19:00:21.983000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(35, 4), dtype=float64, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 2.],\n",
       "       [0., 0., 0., 3.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 2., 0.],\n",
       "       [0., 0., 2., 1.],\n",
       "       [0., 0., 3., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [0., 1., 0., 2.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [0., 1., 1., 1.],\n",
       "       [0., 1., 2., 0.],\n",
       "       [0., 2., 0., 0.],\n",
       "       [0., 2., 0., 1.],\n",
       "       [0., 2., 1., 0.],\n",
       "       [0., 3., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 0., 0., 2.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 1.],\n",
       "       [1., 0., 2., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 2., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [2., 0., 0., 1.],\n",
       "       [2., 0., 1., 0.],\n",
       "       [2., 1., 0., 0.],\n",
       "       [3., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_monomial_identifiers_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:02:55.431253Z",
     "start_time": "2020-11-24T19:02:55.186607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.34 -0.68  0.88  0.64], shape=(4,), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 2. 1.]\n",
      " [0. 0. 3. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 2.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 2. 0. 1.]\n",
      " [0. 2. 1. 0.]\n",
      " [0. 3. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 0. 0. 2.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 2. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 2. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [2. 0. 0. 1.]\n",
      " [2. 0. 1. 0.]\n",
      " [2. 1. 0. 0.]\n",
      " [3. 0. 0. 0.]], shape=(35, 4), dtype=float64)\n",
      "calculate_fv_from_data_wrapper\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 2. 1.]\n",
      " [0. 0. 3. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 2.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 2. 0. 1.]\n",
      " [0. 2. 1. 0.]\n",
      " [0. 3. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 0. 0. 2.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 2. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 2. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [2. 0. 0. 1.]\n",
      " [2. 0. 1. 0.]\n",
      " [2. 1. 0. 0.]\n",
      " [3. 0. 0. 0.]], shape=(35, 4), dtype=float64)\n",
      "(35, 4)\n",
      "tf.Tensor(\n",
      "[ 1.02843450e+01 -2.43461197e+00  9.36263804e-01 -2.26335769e-01\n",
      " -1.29452200e+01 -5.79299579e-01  2.78989860e-01  7.56058328e-01\n",
      "  9.47982839e-01  8.96193137e-01  3.11938798e+00  3.08603460e+00\n",
      "  3.12727280e-02  4.35735082e-01  2.96634370e-01 -2.70302487e-01\n",
      "  1.45772577e+00  1.67981372e-01  8.97095978e-01 -8.94430634e-02\n",
      "  5.52497645e+00 -5.49232391e-01  3.70975567e-03  2.29478658e+00\n",
      " -1.22997219e-01 -8.06895410e-01 -1.86962550e-01 -2.41871049e-01\n",
      "  7.98170054e-01 -4.36566528e-01  1.77331870e+00  2.97839577e-02\n",
      "  5.82040971e-01 -4.25621960e-01 -6.21066911e-02], shape=(35,), dtype=float64)\n",
      "(35,)\n",
      "calculate_fv_from_data\n",
      "tf.Tensor([-0.34 -0.68  0.88  0.64], shape=(4,), dtype=float64)\n",
      "(4,)\n",
      "calculate_value_without_coefficient_wrapper\n",
      "(4,)\n",
      "(4,)\n",
      "tf.Tensor(\n",
      "[ 1.        0.64      0.4096    0.262144  0.88      0.5632    0.360448\n",
      "  0.7744    0.495616  0.681472 -0.68     -0.4352   -0.278528 -0.5984\n",
      " -0.382976 -0.526592  0.4624    0.295936  0.406912 -0.314432 -0.34\n",
      " -0.2176   -0.139264 -0.2992   -0.191488 -0.263296  0.2312    0.147968\n",
      "  0.203456 -0.157216  0.1156    0.073984  0.101728 -0.078608 -0.039304], shape=(35,), dtype=float64)\n",
      "(35,)\n",
      "tf.Tensor(\n",
      "[ 1.02843450e+01 -1.55815166e+00  3.83493654e-01 -5.93325639e-02\n",
      " -1.13917936e+01 -3.26261523e-01  1.00561337e-01  5.85491569e-01\n",
      "  4.69835463e-01  6.10730529e-01 -2.12118382e+00 -1.34304226e+00\n",
      " -8.71033037e-03 -2.60743873e-01 -1.13603845e-01  1.42339127e-01\n",
      "  6.74052395e-01  4.97117354e-02  3.65039119e-01  2.81237613e-02\n",
      " -1.87849199e+00  1.19512968e-01 -5.16635414e-04 -6.86600144e-01\n",
      "  2.35524915e-02  2.12452334e-01 -4.32257416e-02 -3.57891755e-02\n",
      "  1.62392487e-01  6.86352433e-02  2.04995642e-01  2.20353633e-03\n",
      "  5.92098639e-02  3.34572910e-02  2.44104139e-03], shape=(35,), dtype=float64)\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-5.244870550884016>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_entry = tf.constant(lambda_train_input[0][0], tf.float64)\n",
    "print(evaluation_entry)\n",
    "polynomial_pred = tf.constant(y_train.iloc[0].values, tf.float64)\n",
    "list_of_monomial_identifiers_here = tf.constant(list_of_monomial_identifiers_numbers, tf.float64)\n",
    "print(list_of_monomial_identifiers_numbers)\n",
    "calculate_fv_from_data_wrapper(list_of_monomial_identifiers_here, polynomial_pred)(evaluation_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:09:26.235728Z",
     "start_time": "2020-11-24T19:09:25.815584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.34 -0.68  0.88  0.64]\n",
      " [ 0.85  0.73  0.25 -0.37]\n",
      " [ 0.57 -0.76 -0.52 -0.57]\n",
      " ...\n",
      " [ 0.28  0.01  0.55  0.22]\n",
      " [ 0.59  0.34  0.16 -0.88]\n",
      " [ 0.92  0.86  0.67 -0.14]], shape=(562, 4), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 2. 1.]\n",
      " [0. 0. 3. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 2.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 2. 0. 1.]\n",
      " [0. 2. 1. 0.]\n",
      " [0. 3. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 0. 0. 2.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 2. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 2. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [2. 0. 0. 1.]\n",
      " [2. 0. 1. 0.]\n",
      " [2. 1. 0. 0.]\n",
      " [3. 0. 0. 0.]], shape=(35, 4), dtype=float64)\n",
      "calculate_mae_fv_lambda\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 2. 1.]\n",
      " [0. 0. 3. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 2.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 2. 0. 1.]\n",
      " [0. 2. 1. 0.]\n",
      " [0. 3. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 0. 0. 2.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 2. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 2. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [2. 0. 0. 1.]\n",
      " [2. 0. 1. 0.]\n",
      " [2. 1. 0. 0.]\n",
      " [3. 0. 0. 0.]], shape=(35, 4), dtype=float64)\n",
      "(35, 4)\n",
      "tf.Tensor(\n",
      "[ 1.02843450e+01 -2.43461197e+00  9.36263804e-01 -2.26335769e-01\n",
      " -1.29452200e+01 -5.79299579e-01  2.78989860e-01  7.56058328e-01\n",
      "  9.47982839e-01  8.96193137e-01  3.11938798e+00  3.08603460e+00\n",
      "  3.12727280e-02  4.35735082e-01  2.96634370e-01 -2.70302487e-01\n",
      "  1.45772577e+00  1.67981372e-01  8.97095978e-01 -8.94430634e-02\n",
      "  5.52497645e+00 -5.49232391e-01  3.70975567e-03  2.29478658e+00\n",
      " -1.22997219e-01 -8.06895410e-01 -1.86962550e-01 -2.41871049e-01\n",
      "  7.98170054e-01 -4.36566528e-01  1.77331870e+00  2.97839577e-02\n",
      "  5.82040971e-01 -4.25621960e-01 -6.21066911e-02], shape=(35,), dtype=float64)\n",
      "(35,)\n",
      "tf.Tensor(\n",
      "[[-0.34 -0.68  0.88  0.64]\n",
      " [ 0.85  0.73  0.25 -0.37]\n",
      " [ 0.57 -0.76 -0.52 -0.57]\n",
      " ...\n",
      " [ 0.28  0.01  0.55  0.22]\n",
      " [ 0.59  0.34  0.16 -0.88]\n",
      " [ 0.92  0.86  0.67 -0.14]], shape=(562, 4), dtype=float64)\n",
      "(562, 4)\n",
      "calculate_fv_from_data_wrapper\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 2. 1.]\n",
      " [0. 0. 3. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 2.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 2. 0. 1.]\n",
      " [0. 2. 1. 0.]\n",
      " [0. 3. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 0. 0. 2.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 2. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 2. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [2. 0. 0. 1.]\n",
      " [2. 0. 1. 0.]\n",
      " [2. 1. 0. 0.]\n",
      " [3. 0. 0. 0.]], shape=(35, 4), dtype=float64)\n",
      "(35, 4)\n",
      "tf.Tensor(\n",
      "[ 1.02843450e+01 -2.43461197e+00  9.36263804e-01 -2.26335769e-01\n",
      " -1.29452200e+01 -5.79299579e-01  2.78989860e-01  7.56058328e-01\n",
      "  9.47982839e-01  8.96193137e-01  3.11938798e+00  3.08603460e+00\n",
      "  3.12727280e-02  4.35735082e-01  2.96634370e-01 -2.70302487e-01\n",
      "  1.45772577e+00  1.67981372e-01  8.97095978e-01 -8.94430634e-02\n",
      "  5.52497645e+00 -5.49232391e-01  3.70975567e-03  2.29478658e+00\n",
      " -1.22997219e-01 -8.06895410e-01 -1.86962550e-01 -2.41871049e-01\n",
      "  7.98170054e-01 -4.36566528e-01  1.77331870e+00  2.97839577e-02\n",
      "  5.82040971e-01 -4.25621960e-01 -6.21066911e-02], shape=(35,), dtype=float64)\n",
      "(35,)\n",
      "calculate_fv_from_data\n",
      "Tensor(\"loop_body/GatherV2:0\", shape=(4,), dtype=float64)\n",
      "(4,)\n",
      "calculate_value_without_coefficient_wrapper\n",
      "(4,)\n",
      "(4,)\n",
      "Tensor(\"loop_body/loop_body/Prod/pfor/Prod:0\", shape=(35,), dtype=float64)\n",
      "(35,)\n",
      "Tensor(\"loop_body/loop_body_1/mul/pfor/Mul:0\", shape=(35,), dtype=float64)\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=13.49151651164427>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset = tf.constant(lambda_train_input[0], tf.float64)\n",
    "print(evaluation_dataset)\n",
    "polynomial_pred = tf.constant(y_train.iloc[0].values, tf.float64)\n",
    "list_of_monomial_identifiers_here = tf.constant(list_of_monomial_identifiers_numbers, tf.float64)\n",
    "print(list_of_monomial_identifiers_here)\n",
    "calculate_mae_fv_lambda_wrapper(evaluation_dataset, list_of_monomial_identifiers_here)((polynomial_pred, polynomial_pred, lambda_train_fv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:43:08.835775Z",
     "start_time": "2020-11-25T08:43:08.376179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.34 -0.68  0.88  0.64]\n",
      " [ 0.85  0.73  0.25 -0.37]\n",
      " [ 0.57 -0.76 -0.52 -0.57]\n",
      " ...\n",
      " [ 0.28  0.01  0.55  0.22]\n",
      " [ 0.59  0.34  0.16 -0.88]\n",
      " [ 0.92  0.86  0.67 -0.14]], shape=(562, 4), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 2. 1.]\n",
      " [0. 0. 3. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 2.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 2. 0. 1.]\n",
      " [0. 2. 1. 0.]\n",
      " [0. 3. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 0. 0. 2.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 2. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 2. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [2. 0. 0. 1.]\n",
      " [2. 0. 1. 0.]\n",
      " [2. 1. 0. 0.]\n",
      " [3. 0. 0. 0.]], shape=(35, 4), dtype=float64)\n",
      "calculate_value_without_coefficient_wrapper\n",
      "(4,)\n",
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=11.651098697200096>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset = tf.constant(lambda_train_input[0], tf.float64)\n",
    "print(evaluation_dataset)\n",
    "polynomial_pred = tf.constant(np.array([y_train.iloc[0].values, y_train.iloc[0].values]), tf.float64)\n",
    "polynomial_pred_with_lambda_fv = np.array([np.hstack((y_train.iloc[0].values, lambda_train_fv_train_split_list[0].iloc[0].values)), np.hstack((y_train.iloc[0].values, lambda_train_fv_train_split_list[0].iloc[0].values))])\n",
    "list_of_monomial_identifiers_here = tf.constant(list_of_monomial_identifiers_numbers, tf.float64)\n",
    "print(list_of_monomial_identifiers_here)\n",
    "\n",
    "mean_absolute_error_tf_fv_lambda_extended_wrapper(evaluation_dataset, list_of_monomial_identifiers_here)(polynomial_pred_with_lambda_fv, polynomial_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-25T13:00:17.092Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.34 -0.68  0.88  0.64]\n",
      " [ 0.85  0.73  0.25 -0.37]\n",
      " [ 0.57 -0.76 -0.52 -0.57]\n",
      " ...\n",
      " [ 0.28  0.01  0.55  0.22]\n",
      " [ 0.59  0.34  0.16 -0.88]\n",
      " [ 0.92  0.86  0.67 -0.14]], shape=(562, 4), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 2. 1.]\n",
      " [0. 0. 3. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 2.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 2. 0. 1.]\n",
      " [0. 2. 1. 0.]\n",
      " [0. 3. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 0. 0. 2.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 2. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 2. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [2. 0. 0. 1.]\n",
      " [2. 0. 1. 0.]\n",
      " [2. 1. 0. 0.]\n",
      " [3. 0. 0. 0.]], shape=(35, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "base_model = generate_base_model()\n",
    "\n",
    "evaluation_dataset = tf.constant(lambda_train_input[0], tf.float64)\n",
    "print(evaluation_dataset)\n",
    "polynomial_pred = tf.constant(np.array([y_train.iloc[0].values, y_train.iloc[0].values]), tf.float64)\n",
    "polynomial_pred_with_X_data = np.array([np.hstack((y_train.iloc[0].values, X_train.iloc[0].values)), np.hstack((y_train.iloc[0].values, X_train.iloc[0].values))])\n",
    "list_of_monomial_identifiers_here = tf.constant(list_of_monomial_identifiers_numbers, tf.float64)\n",
    "print(list_of_monomial_identifiers_here)\n",
    "\n",
    "mean_absolute_error_tf_fv_lambda_extended_wrapper(evaluation_dataset, list_of_monomial_identifiers_here, base_model)(polynomial_pred_with_X_data, polynomial_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T13:00:14.548763Z",
     "start_time": "2020-11-25T13:00:14.511390Z"
    }
   },
   "outputs": [],
   "source": [
    "#Manual TF Loss function for comparison with pre-saved lambda-net predictions\n",
    "\n",
    "#extended means that the lambda-net predictions are appended to y_true \n",
    "#in order to get them into the loss function without loosing the allocation\n",
    "\n",
    "\n",
    "def mean_absolute_error_tf_fv_lambda_extended_wrapper(evaluation_dataset, list_of_monomial_identifiers, base_model):\n",
    "    \n",
    "    evaluation_dataset = return_float_tensor_representation(evaluation_dataset)\n",
    "    list_of_monomial_identifiers = return_float_tensor_representation(list_of_monomial_identifiers)    \n",
    "    \n",
    "    model_lambda_placeholder = keras.models.clone_model(base_model)  \n",
    "    \n",
    "    weights_structure = base_model.get_weights()\n",
    "    dims = [np_arrays.shape for np_arrays in weights_structure]\n",
    "    \n",
    "    def mean_absolute_error_tf_fv_lambda_extended(polynomial_true_with_lambda_fv, polynomial_pred):\n",
    "\n",
    "        network_parameters = polynomial_true_with_lambda_fv[:,sparsity:]\n",
    "        polynomial_true = polynomial_true_with_lambda_fv[:,:sparsity]\n",
    "\n",
    "        network_parameters = return_float_tensor_representation(network_parameters)\n",
    "        polynomial_true = return_float_tensor_representation(polynomial_true)\n",
    "        polynomial_pred = return_float_tensor_representation(polynomial_pred)\n",
    "        return tf.math.reduce_mean(tf.map_fn(calculate_mae_fv_lambda_wrapper(evaluation_dataset, list_of_monomial_identifiers, dims, model_lambda_placeholder), (polynomial_pred, network_parameters), fn_output_signature=tf.float32))\n",
    "    return mean_absolute_error_tf_fv_lambda_extended\n",
    "\n",
    "\n",
    "#CHANGES NEEDED\n",
    "def calculate_mae_fv_lambda_wrapper(evaluation_dataset, list_of_monomial_identifiers, dims, model_lambda_placeholder):\n",
    "\n",
    "    def calculate_mae_fv_lambda(input_list):\n",
    "\n",
    "        #single polynomials\n",
    "        #polynomial_true = input_list[0]\n",
    "        polynomial_pred = input_list[0]\n",
    "        network_parameters = input_list[1]\n",
    "        \n",
    "        polynomial_pred_fv_list = tf.vectorized_map(calculate_fv_from_data_wrapper(list_of_monomial_identifiers, polynomial_pred), (evaluation_dataset))\n",
    "\n",
    "        #CALCULATE LAMBDA FV HERE FOR EVALUATION DATASET\n",
    "        # build models\n",
    "        start = 0\n",
    "        layers = []\n",
    "        for i in range(len(dims)//2):\n",
    "            \n",
    "            # set weights of layer\n",
    "            index = i*2\n",
    "            size = np.product(dims[index])\n",
    "            weights_tf_true = tf.reshape(network_parameters[start:start+size], dims[index])\n",
    "            model_lambda_placeholder.layers[i].weights[0].assign(weights_tf_true)\n",
    "            start += size\n",
    "            \n",
    "            # set biases of layer\n",
    "            index += 1\n",
    "            size = np.product(dims[index])\n",
    "            biases_tf_true = tf.reshape(network_parameters[start:start+size], dims[index])\n",
    "            model_lambda_placeholder.layers[i].weights[1].assign(biases_tf_true)\n",
    "            start += size\n",
    "\n",
    "        \n",
    "        lambda_fv = tf.keras.backend.flatten(model_lambda_placeholder(evaluation_dataset))\n",
    "        \n",
    "        return tf.math.reduce_mean(tf.vectorized_map(calculate_mae_single_input, (lambda_fv, polynomial_pred_fv_list)))\n",
    "    \n",
    "    return calculate_mae_fv_lambda\n",
    "\n",
    "#nothing to change here (just fv calculation for evaluation entry for single polynomial)\n",
    "def calculate_fv_from_data_wrapper(list_of_monomial_identifiers, polynomial_pred):\n",
    "\n",
    "\n",
    "    def calculate_fv_from_data(evaluation_entry):\n",
    "\n",
    "\n",
    "        value_without_coefficient = tf.vectorized_map(calculate_value_without_coefficient_wrapper(evaluation_entry), (list_of_monomial_identifiers))\n",
    "        polynomial_pred_value_per_term = tf.vectorized_map(lambda x: x[0]*x[1], (value_without_coefficient, polynomial_pred))\n",
    "        \n",
    "        polynomial_pred_fv = tf.reduce_sum(polynomial_pred_value_per_term)     \n",
    "        \n",
    "        return polynomial_pred_fv\n",
    "    return calculate_fv_from_data\n",
    "\n",
    "#MAKE CALCULATUIB HERE\n",
    "def calculate_lambda_net_fv_from_data_wrapper(list_of_monomial_identifiers, polynomial_pred):\n",
    "\n",
    "\n",
    "    def calculate_lambda_net_fv_from_data(evaluation_entry):\n",
    "\n",
    "\n",
    "        #value_without_coefficient = tf.vectorized_map(calculate_value_without_coefficient_wrapper(evaluation_entry), (list_of_monomial_identifiers))\n",
    "        #polynomial_pred_value_per_term = tf.vectorized_map(lambda x: x[0]*x[1], (value_without_coefficient, polynomial_pred))\n",
    "        \n",
    "        #polynomial_pred_fv = tf.reduce_sum(polynomial_pred_value_per_term)     \n",
    "        \n",
    "        return #polynomial_pred_fv\n",
    "    return calculate_fv_from_data\n",
    "\n",
    "#calculate intermediate term (without coefficient multiplication)\n",
    "def calculate_value_without_coefficient_wrapper(evaluation_entry):\n",
    "    def calculate_value_without_coefficient(coefficient_multiplier_term):      \n",
    "   \n",
    "        return tf.math.reduce_prod(tf.vectorized_map(lambda x: x[0]**x[1], (evaluation_entry, coefficient_multiplier_term)))\n",
    "    return calculate_value_without_coefficient\n",
    "\n",
    "#calculate MAE at the end ---> general:REPLACE FUNCTION WITH LOSS CALL OR LAMBDA\n",
    "def calculate_mae_single_input(input_list):\n",
    "    true_fv = input_list[0]\n",
    "    pred_fv = input_list[1]\n",
    "\n",
    "    return tf.math.abs(tf.math.subtract(true_fv, pred_fv))\n",
    "\n",
    "\n",
    "def mean_absolute_error_extended(polynomial_true_with_lambda_fv, polynomial_pred): \n",
    "    polynomial_true = polynomial_true_with_lambda_fv[:,:sparsity]\n",
    "    return tf.keras.losses.MAE(polynomial_true, polynomial_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:50:18.123294Z",
     "start_time": "2020-11-25T08:50:18.094093Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "#Manual TF Loss function for comparison with pre-saved lambda-net predictions\n",
    "\n",
    "#extended means that the lambda-net predictions are appended to y_true \n",
    "#in order to get them into the loss function without loosing the allocation\n",
    "\n",
    "\n",
    "def calculate_mae_single_input(input_list):\n",
    "    true_fv = input_list[0]\n",
    "    pred_fv = input_list[1]\n",
    "\n",
    "    return tf.math.abs(tf.math.subtract(true_fv, pred_fv))\n",
    "\n",
    "\n",
    "def calculate_value_without_coefficient_wrapper(evaluation_entry):\n",
    "    def calculate_value_without_coefficient(coefficient_multiplier_term):      \n",
    "        #return tf.math.reduce_prod(tf.vectorized_map(calculate_single_value_without_coefficient, (tf.strings.to_number(tf.strings.bytes_split(coefficient_multiplier_term), tf.float64), evaluation_entry)))\n",
    "        \n",
    "\n",
    "        \n",
    "        #coefficient_multiplier_term_integers = tf.reshape(tf.strings.to_number(tf.strings.bytes_split(coefficient_multiplier_term), tf.float64), [n,])\n",
    "        \n",
    "        print('calculate_value_without_coefficient_wrapper')\n",
    "        print(coefficient_multiplier_term.get_shape())\n",
    "        print(evaluation_entry.get_shape())\n",
    "        \n",
    "        return tf.math.reduce_prod(tf.vectorized_map(lambda x: x[0]**x[1], (evaluation_entry, coefficient_multiplier_term)))\n",
    "    return calculate_value_without_coefficient\n",
    "\n",
    "\n",
    "def calculate_fv_from_data_wrapper(list_of_monomial_identifiers, polynomial_pred):\n",
    "    \n",
    "    #print('calculate_fv_from_data_wrapper')\n",
    "    #print(list_of_monomial_identifiers)\n",
    "    #print(list_of_monomial_identifiers.get_shape())\n",
    "    #print(polynomial_pred)\n",
    "    #print(polynomial_pred.get_shape())\n",
    "\n",
    "    def calculate_fv_from_data(evaluation_entry):\n",
    "        \n",
    "        #print('calculate_fv_from_data')\n",
    "        #print(evaluation_entry)\n",
    "        #print(evaluation_entry.get_shape())\n",
    "\n",
    "        value_without_coefficient = tf.vectorized_map(calculate_value_without_coefficient_wrapper(evaluation_entry), (list_of_monomial_identifiers))\n",
    "        \n",
    "        #print(value_without_coefficient)\n",
    "        #print(value_without_coefficient.get_shape())\n",
    "        \n",
    "        polynomial_pred_value_per_term = tf.vectorized_map(lambda x: x[0]*x[1], (value_without_coefficient, polynomial_pred))\n",
    "        \n",
    "        #print(polynomial_pred_value_per_term)\n",
    "        #print(polynomial_pred_value_per_term.get_shape().ndims)\n",
    "        \n",
    "        polynomial_pred_fv = tf.reduce_sum(polynomial_pred_value_per_term)     \n",
    "        \n",
    "        return polynomial_pred_fv\n",
    "    return calculate_fv_from_data\n",
    "\n",
    "def calculate_mae_fv_lambda_wrapper(evaluation_dataset, list_of_monomial_identifiers):\n",
    "\n",
    "    def calculate_mae_fv_lambda(input_list):\n",
    "\n",
    "        polynomial_true = input_list[0]\n",
    "        polynomial_pred = input_list[1]\n",
    "        lambda_fv = input_list[2]\n",
    "        #evaluation_dataset = input_list[3]\n",
    "        #list_of_monomial_identifiers = input_list[4]\n",
    "\n",
    "        #print('calculate_mae_fv_lambda')\n",
    "        #print(list_of_monomial_identifiers)\n",
    "        #print(list_of_monomial_identifiers.get_shape())\n",
    "        #print(polynomial_pred)\n",
    "        #print(polynomial_pred.get_shape())\n",
    "        #print(evaluation_dataset)\n",
    "        #print(evaluation_dataset.get_shape())\n",
    "\n",
    "        \n",
    "        polynomial_pred_fv_list = tf.vectorized_map(calculate_fv_from_data_wrapper(list_of_monomial_identifiers, polynomial_pred), (evaluation_dataset))\n",
    "\n",
    "        return tf.math.reduce_mean(tf.vectorized_map(calculate_mae_single_input, (lambda_fv, polynomial_pred_fv_list)))\n",
    "    \n",
    "    return calculate_mae_fv_lambda\n",
    "    \n",
    "def mean_absolute_error_tf_fv_lambda_extended_wrapper(evaluation_dataset, list_of_monomial_identifiers):\n",
    "    \n",
    "    evaluation_dataset = return_float_tensor_representation(evaluation_dataset, tf.float64)\n",
    "    list_of_monomial_identifiers = return_float_tensor_representation(list_of_monomial_identifiers, tf.float64)    \n",
    "    \n",
    "    def mean_absolute_error_tf_fv_lambda_extended(polynomial_true_with_lambda_fv, polynomial_pred):\n",
    "\n",
    "        lambda_fv = polynomial_true_with_lambda_fv[:,sparsity:]\n",
    "        polynomial_true = polynomial_true_with_lambda_fv[:,:sparsity]\n",
    "\n",
    "        lambda_fv = return_float_tensor_representation(lambda_fv, tf.float64)\n",
    "        polynomial_true = return_float_tensor_representation(polynomial_true, tf.float64)\n",
    "        polynomial_pred = return_float_tensor_representation(polynomial_pred, tf.float64)\n",
    "        #return tf.math.reduce_mean(tf.vectorized_map(calculate_mae_fv_lambda_wrapper(evaluation_dataset, list_of_monomial_identifiers), (polynomial_true, polynomial_pred, lambda_fv)))\n",
    "        return tf.math.reduce_mean(tf.vectorized_map(calculate_mae_fv_lambda_wrapper(evaluation_dataset, list_of_monomial_identifiers), (polynomial_true, polynomial_pred, lambda_fv)))\n",
    "    return mean_absolute_error_tf_fv_lambda_extended\n",
    "\n",
    "def mean_absolute_error_extended(polynomial_true_with_lambda_fv, polynomial_pred): \n",
    "    polynomial_true = polynomial_true_with_lambda_fv[:,:sparsity]\n",
    "    return tf.keras.losses.MAE(polynomial_true, polynomial_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:05.725244Z",
     "start_time": "2020-11-24T18:42:05.701382Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Basic Keras/TF Loss functions\n",
    "def root_mean_squared_error(y_true, y_pred):   \n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "        \n",
    "    y_true =  return_float_tensor_representation(y_true)\n",
    "    y_pred =  return_float_tensor_representation(y_pred)           \n",
    "            \n",
    "    return tf.math.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "def accuracy_multilabel(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "    \n",
    "    y_true =  return_float_tensor_representation(y_true)\n",
    "    y_pred =  return_float_tensor_representation(y_pred) \n",
    "            \n",
    "    n_digits = int(-np.log10(a_step))      \n",
    "    y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "    y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(tf.reduce_all(K.equal(y_true, y_pred), axis=1), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def accuracy_single(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "    \n",
    "    y_true =  return_float_tensor_representation(y_true)\n",
    "    y_pred =  return_float_tensor_representation(y_pred) \n",
    "            \n",
    "    n_digits = int(-np.log10(a_step))\n",
    "        \n",
    "    y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "    y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(K.equal(y_true, y_pred), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def mean_absolute_percentage_error_keras(y_true, y_pred, epsilon=10e-3): \n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "    \n",
    "    y_true =  return_float_tensor_representation(y_true)\n",
    "    y_pred =  return_float_tensor_representation(y_pred)        \n",
    "    epsilon = return_float_tensor_representation(epsilon)\n",
    "        \n",
    "    return tf.reduce_mean(tf.abs(tf.divide(tf.subtract(y_pred, y_true),(y_true + epsilon))))\n",
    "\n",
    "def huber_loss_delta_set(y_true, y_pred):\n",
    "    return keras.losses.huber_loss(y_true, y_pred, delta=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:06.120459Z",
     "start_time": "2020-11-24T18:42:06.104573Z"
    }
   },
   "outputs": [],
   "source": [
    "#Manual calculations for comparison of polynomials based on function values (no TF!)\n",
    "\n",
    "def calcualate_function_value(coefficient_list, lambda_input_entry):\n",
    "    \n",
    "    global list_of_monomial_identifiers\n",
    "    \n",
    "    result = 0   \n",
    "        \n",
    "    for coefficient_value, coefficient_multipliers in zip(coefficient_list, list_of_monomial_identifiers):\n",
    "        value_without_coefficient = [lambda_input_value**int(coefficient_multiplier) for coefficient_multiplier, lambda_input_value in zip(coefficient_multipliers, lambda_input_entry)]\n",
    "        result += coefficient_value * reduce(lambda x, y: x*y, value_without_coefficient)\n",
    "\n",
    "    return result\n",
    "\n",
    "def calculate_function_values_from_polynomial(polynomial, lambda_input_data):\n",
    "    polynomial = return_numpy_representation(polynomial)\n",
    "    \n",
    "    function_value_list = []\n",
    "        \n",
    "    for lambda_input_entry in lambda_input_data:\n",
    "        function_value = calcualate_function_value(polynomial, lambda_input_entry)\n",
    "        function_value_list.append(function_value)\n",
    "\n",
    "    return np.array(function_value_list)\n",
    "\n",
    "\n",
    "def parallel_fv_calculation_from_polynomial(polynomial_list, lambda_input_list):\n",
    "    parallel = Parallel(n_jobs=10, verbose=0, backend='threading')\n",
    "    polynomial_true_fv = parallel(delayed(calculate_function_values_from_polynomial)(polynomial, lambda_input_list) for polynomial in polynomial_list)  \n",
    "    del parallel   \n",
    "    \n",
    "    return np.array(polynomial_true_fv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:06.539751Z",
     "start_time": "2020-11-24T18:42:06.499709Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Standard Metrics (no TF!)\n",
    "\n",
    "def mean_absolute_error_function_values(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)      \n",
    "    \n",
    "    result_list = []\n",
    "    for true_values, pred_values in zip(y_true, y_pred):\n",
    "        result_list.append(np.mean(np.abs(true_values-pred_values)))\n",
    "    \n",
    "    return np.mean(np.array(result_list))  \n",
    "\n",
    "def root_mean_squared_error_function_values(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)         \n",
    "    \n",
    "    result_list = []\n",
    "    for true_values, pred_values in zip(y_true, y_pred):\n",
    "        result_list.append(np.sqrt(np.mean((true_values-pred_values)**2)))\n",
    "    \n",
    "    return np.mean(np.array(result_list)) \n",
    "\n",
    "def mean_absolute_percentage_error_function_values(y_true, y_pred, epsilon=10e-3):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred) \n",
    "    \n",
    "    result_list = []\n",
    "    for true_values, pred_values in zip(y_true, y_pred):\n",
    "        result_list.append(np.mean(np.abs(((true_values-pred_values)/(true_values+epsilon)))))\n",
    "\n",
    "    return np.mean(np.array(result_list))\n",
    "\n",
    "def r2_score_function_values(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "    \n",
    "    result_list = []\n",
    "    for true_values, pred_values in zip(y_true, y_pred):\n",
    "        result_list.append(r2_score(true_values, pred_values))\n",
    "    \n",
    "    return np.mean(np.array(result_list))\n",
    "\n",
    "def relative_absolute_average_error_function_values(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "    \n",
    "    result_list = []\n",
    "    \n",
    "    for true_values, pred_values in zip(y_true, y_pred):\n",
    "        result_list.append(np.sum(np.abs(true_values-pred_values))/(true_values.shape[0]*np.std(true_values)))\n",
    "    \n",
    "    return np.mean(np.array(result_list))\n",
    "\n",
    "def relative_maximum_average_error_function_values(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "    \n",
    "    result_list = []\n",
    "    for true_values, pred_values in zip(y_true, y_pred):\n",
    "        result_list.append(np.max(true_values-pred_values)/np.std(true_values))\n",
    "    \n",
    "    return np.mean(np.array(result_list))\n",
    "\n",
    "def mean_area_between_two_curves_function_values(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "      \n",
    "    assert(number_of_variables==1)\n",
    "    \n",
    "    result_list = []\n",
    "    for true_values, pred_values in zip(y_true, y_pred):\n",
    "        result_list.append(area_between_two_curves(true_values, pred_values))\n",
    " \n",
    "    return np.mean(np.array(result_list))\n",
    "\n",
    "def mean_dtw_function_values(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "\n",
    "    result_list_single = []\n",
    "    result_list_array = []\n",
    "    \n",
    "    for true_values, pred_values in zip(y_true, y_pred):\n",
    "        result_single_value, result_single_array = dtw(true_values, pred_values)\n",
    "        result_list_single.append(result_single_value)\n",
    "        result_list_array.append(result_single_array)\n",
    "    \n",
    "    return np.mean(np.array(result_list_single)), np.mean(np.array(result_list_array), axis=1)\n",
    "\n",
    "def mean_frechet_dist_function_values(y_true, y_pred):\n",
    "    y_true = return_numpy_representation(y_true)\n",
    "    y_pred = return_numpy_representation(y_pred)\n",
    "    \n",
    "    result_list = []\n",
    "    for true_values, pred_values in zip(y_true, y_pred):\n",
    "        result_list.append(frechet_dist(true_values, pred_values))\n",
    "    \n",
    "    return np.mean(np.array(result_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:06.842822Z",
     "start_time": "2020-11-24T18:42:06.823780Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate_interpretation_net(y_data_real, \n",
    "                                y_data_pred, \n",
    "                                polynomial_true_fv, \n",
    "                                polynomial_pred_inet_fv):\n",
    "    \n",
    "    mae_coeff = np.round(mean_absolute_error(y_data_real, y_data_pred), 4)\n",
    "    rmse_coeff = np.round(root_mean_squared_error(y_data_real, y_data_pred), 4)\n",
    "    mape_coeff = np.round(mean_absolute_percentage_error_keras(y_data_real, y_data_pred), 4)\n",
    "    accuracy_coeff = np.round(accuracy_single(y_data_real, y_data_pred), 4)\n",
    "    accuracy_multi_coeff = np.round(accuracy_multilabel(y_data_real, y_data_pred), 4)\n",
    "    \n",
    "    mae_fv = np.round(mean_absolute_error_function_values(polynomial_true_fv, polynomial_pred_inet_fv), 4)\n",
    "    rmse_fv = np.round(root_mean_squared_error_function_values(polynomial_true_fv, polynomial_pred_inet_fv), 4)\n",
    "    mape_fv = np.round(mean_absolute_percentage_error_function_values(polynomial_true_fv, polynomial_pred_inet_fv), 4)\n",
    "    r2_fv = np.round(r2_score_function_values(polynomial_true_fv, polynomial_pred_inet_fv), 4)\n",
    "    raae_fv = np.round(relative_absolute_average_error_function_values(polynomial_true_fv, polynomial_pred_inet_fv), 4)\n",
    "    rmae_fv = np.round(relative_maximum_average_error_function_values(polynomial_true_fv, polynomial_pred_inet_fv), 4) \n",
    "\n",
    "    std_fv = np.std(polynomial_pred_inet_fv)\n",
    "    mean_fv = np.mean(polynomial_pred_inet_fv)\n",
    "\n",
    "    return {\n",
    "             'MAE': mae_coeff,\n",
    "             'RMSE': rmse_coeff, \n",
    "             'MAPE': mape_coeff,\n",
    "             'Accuracy': accuracy_coeff, \n",
    "             'Accuracy Multilabel': accuracy_multi_coeff, \n",
    "\n",
    "             'MAE FV': mae_fv,\n",
    "             'RMSE FV': rmse_fv,\n",
    "             'MAPE FV': mape_fv,\n",
    "             'R2 FV': r2_fv,\n",
    "             'RAAE FV': raae_fv,\n",
    "             'RMAE FV': rmae_fv,         \n",
    "             'STD FV PRED': std_fv,   \n",
    "             'MEAN FV PRED': mean_fv\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:07.111562Z",
     "start_time": "2020-11-24T18:42:07.094036Z"
    }
   },
   "outputs": [],
   "source": [
    "def arreq_in_list(myarr, list_arrays):\n",
    "    return next((True for elem in list_arrays if np.array_equal(elem, myarr)), False)\n",
    "\n",
    "def generate_random_x_values(size, x_max, x_min, x_step, numnber_of_variables):\n",
    "    x_values_list = []\n",
    "    \n",
    "    for j in range(size):\n",
    "        values = np.round(np.array(random_product(np.arange(x_min, x_max, x_step), repeat=numnber_of_variables)), int(-np.log10(x_step)))\n",
    "        while arreq_in_list(values, x_values_list):\n",
    "                values = np.round(np.array(random_product(np.arange(x_min, x_max, x_step), repeat=numnber_of_variables)), int(-np.log10(x_step)))         \n",
    "        x_values_list.append(values)\n",
    "    \n",
    "    return np.array(x_values_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:42:08.655864Z",
     "start_time": "2020-11-24T18:42:07.175261Z"
    }
   },
   "outputs": [],
   "source": [
    "random_evaluation_dataset = generate_random_x_values(random_evaluation_dataset_size, x_max, x_min, x_step, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:46:08.074021Z",
     "start_time": "2020-11-25T08:46:08.065440Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_model_1 = y_train[:5].values\n",
    "y_train_model_2 = np.hstack((y_train[5:10], lambda_train_fv_train_split[5:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:56:26.149479Z",
     "start_time": "2020-11-25T08:56:26.141085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(562, 4)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_train_input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:56:45.088391Z",
     "start_time": "2020-11-25T08:56:45.082934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_evaluation_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:56:51.257363Z",
     "start_time": "2020-11-25T08:56:50.524320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_value_without_coefficient_wrapper\n",
      "(4,)\n",
      "(4,)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[0,500] = 500 is not in [0, 500)\n\t [[node loop_body/loop_body_1/GatherV2_1/pfor/GatherV2/pfor/GatherV2 (defined at <ipython-input-134-3fc3e3c6dc91>:98) ]] [Op:__inference_f_10813]\n\nFunction call stack:\nf\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-484fadc3c627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist_of_monomial_identifiers_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonomial_identifiers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmonomial_identifiers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_monomial_identifiers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error_tf_fv_lambda_extended_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_evaluation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_monomial_identifiers_numbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_model_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_model_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-3fc3e3c6dc91>\u001b[0m in \u001b[0;36mmean_absolute_error_tf_fv_lambda_extended\u001b[0;34m(polynomial_true_with_lambda_fv, polynomial_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mpolynomial_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_float_tensor_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolynomial_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m#return tf.math.reduce_mean(tf.vectorized_map(calculate_mae_fv_lambda_wrapper(evaluation_dataset, list_of_monomial_identifiers), (polynomial_true, polynomial_pred, lambda_fv)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorized_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_mae_fv_lambda_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_monomial_identifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpolynomial_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolynomial_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_fv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean_absolute_error_tf_fv_lambda_extended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\u001b[0m in \u001b[0;36mvectorized_map\u001b[0;34m(fn, elems, fallback_to_while_loop)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_elem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m   return pfor(loop_fn, batch_size,\n\u001b[0;32m--> 432\u001b[0;31m               fallback_to_while_loop=fallback_to_while_loop)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\u001b[0m in \u001b[0;36mpfor\u001b[0;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations)\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_functions_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfunctions_run_eagerly\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_functions_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions_run_eagerly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[0,500] = 500 is not in [0, 500)\n\t [[node loop_body/loop_body_1/GatherV2_1/pfor/GatherV2/pfor/GatherV2 (defined at <ipython-input-134-3fc3e3c6dc91>:98) ]] [Op:__inference_f_10813]\n\nFunction call stack:\nf\n"
     ]
    }
   ],
   "source": [
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)\n",
    "result = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers)(y_train_model_2, y_train_model_1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:47:00.761027Z",
     "start_time": "2020-11-24T18:47:00.743126Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_data(index):\n",
    "    \n",
    "    if psutil.virtual_memory().percent > 80:\n",
    "        raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    path = './data/weights/' + foldername + 'weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(index).zfill(3) + filename + '.txt'\n",
    "\n",
    "    weight_data = pd.read_csv(path, sep=\",\", header=None)\n",
    "    weight_data = weight_data.sort_values(by=[i for i in range(nCr(n+d, d))]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "    return weight_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:47:03.497190Z",
     "start_time": "2020-11-24T18:47:00.963096Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done   2 out of  21 | elapsed:    2.1s remaining:   20.2s\n",
      "[Parallel(n_jobs=-3)]: Done  10 out of  21 | elapsed:    2.3s remaining:    2.6s\n",
      "[Parallel(n_jobs=-3)]: Done  18 out of  21 | elapsed:    2.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-3)]: Done  21 out of  21 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if multi_epoch_analysis:  \n",
    "    weight_data_list = []\n",
    "    \n",
    "    foldername = 'weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/'\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    weight_data_list = parallel(delayed(load_data)((i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1) for i in epochs_save_range_lambda)  \n",
    "    del parallel\n",
    "    \n",
    "    weight_data = weight_data_list[-1]\n",
    "else:\n",
    "\n",
    "    foldername = 'weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/'\n",
    "                \n",
    "    path = './data/weights/' + foldername + 'weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3) + filename + '.txt'\n",
    "\n",
    "    weight_data = pd.read_csv(path, sep=\",\", header=None)\n",
    "    weight_data = weight_data.sort_values(by=[i for i in range(nCr(n+d, d))]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:47:21.149259Z",
     "start_time": "2020-11-24T18:47:03.510184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38913a74865447e4bfbc0ed11f4d0ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if multi_epoch_analysis == False:\n",
    "    path_lambda_train_fv = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_' + 'epoch_' + str(epochs_lambda).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "    path_lambda_valid_fv = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_' + 'epoch_' + str(epochs_lambda).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "    path_lambda_test_fv = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_' + 'epoch_' + str(epochs_lambda).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "\n",
    "    lambda_train_fv_with_lambda_input = pd.read_csv(path_lambda_train_fv, sep=',').sort_values(by=list_of_monomial_identifiers).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True).drop(list_of_monomial_identifiers, axis=1)\n",
    "    lambda_valid_fv_with_lambda_input = pd.read_csv(path_lambda_valid_fv, sep=',').sort_values(by=list_of_monomial_identifiers).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True).drop(list_of_monomial_identifiers, axis=1)\n",
    "    lambda_test_fv_with_lambda_input = pd.read_csv(path_lambda_test_fv, sep=',').sort_values(by=list_of_monomial_identifiers).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True).drop(list_of_monomial_identifiers, axis=1)\n",
    "    \n",
    "    lambda_train_fv = lambda_train_fv_with_lambda_input[lambda_train_fv_with_lambda_input.columns[n::n+1]]\n",
    "    lambda_valid_fv = lambda_valid_fv_with_lambda_input[lambda_valid_fv_with_lambda_input.columns[n::n+1]]\n",
    "    lambda_test_fv = lambda_test_fv_with_lambda_input[lambda_test_fv_with_lambda_input.columns[n::n+1]]\n",
    "    \n",
    "    lambda_train_input = lambda_train_fv_with_lambda_input.drop(lambda_train_fv_with_lambda_input.columns[n::n+1], axis=1).values.reshape(lambda_train_fv_with_lambda_input.shape[0], int((lambda_train_fv_with_lambda_input.shape[1]*(n/(n+1)))/n), n)\n",
    "    lambda_valid_input = lambda_valid_fv_with_lambda_input.drop(lambda_valid_fv_with_lambda_input.columns[n::n+1], axis=1).values.reshape(lambda_valid_fv_with_lambda_input.shape[0], int((lambda_valid_fv_with_lambda_input.shape[1]*(n/(n+1)))/n), n)\n",
    "    lambda_test_input = lambda_test_fv_with_lambda_input.drop(lambda_test_fv_with_lambda_input.columns[n::n+1], axis=1).values.reshape(lambda_test_fv_with_lambda_input.shape[0], int((lambda_test_fv_with_lambda_input.shape[1]*(n/(n+1)))/n), n)\n",
    "\n",
    "else:\n",
    "    lambda_train_fv_list = []\n",
    "    lambda_valid_fv_list = []\n",
    "    lambda_test_fv_list = []\n",
    "\n",
    "    for i in tqdm(epochs_save_range_lambda):  \n",
    "        index = (i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1\n",
    "        path_lambda_train_fv = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "        path_lambda_valid_fv = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "        path_lambda_test_fv = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "\n",
    "        lambda_train_fv_with_lambda_input = pd.read_csv(path_lambda_train_fv, sep=',').sort_values(by=list_of_monomial_identifiers).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True).drop(list_of_monomial_identifiers, axis=1)\n",
    "        lambda_valid_fv_with_lambda_input = pd.read_csv(path_lambda_valid_fv, sep=',').sort_values(by=list_of_monomial_identifiers).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True).drop(list_of_monomial_identifiers, axis=1)\n",
    "        lambda_test_fv_with_lambda_input = pd.read_csv(path_lambda_test_fv, sep=',').sort_values(by=list_of_monomial_identifiers).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True).drop(list_of_monomial_identifiers, axis=1)\n",
    "\n",
    "        lambda_train_fv = lambda_train_fv_with_lambda_input[lambda_train_fv_with_lambda_input.columns[n::n+1]]\n",
    "        lambda_valid_fv = lambda_valid_fv_with_lambda_input[lambda_valid_fv_with_lambda_input.columns[n::n+1]]\n",
    "        lambda_test_fv = lambda_test_fv_with_lambda_input[lambda_test_fv_with_lambda_input.columns[n::n+1]]\n",
    "\n",
    "        if i == 0:\n",
    "            lambda_train_input = lambda_train_fv_with_lambda_input.drop(lambda_train_fv_with_lambda_input.columns[n::n+1], axis=1).values.reshape(lambda_train_fv_with_lambda_input.shape[0], int((lambda_train_fv_with_lambda_input.shape[1]*(n/(n+1)))/n), n)\n",
    "            lambda_valid_input = lambda_valid_fv_with_lambda_input.drop(lambda_valid_fv_with_lambda_input.columns[n::n+1], axis=1).values.reshape(lambda_valid_fv_with_lambda_input.shape[0], int((lambda_valid_fv_with_lambda_input.shape[1]*(n/(n+1)))/n), n)\n",
    "            lambda_test_input = lambda_test_fv_with_lambda_input.drop(lambda_test_fv_with_lambda_input.columns[n::n+1], axis=1).values.reshape(lambda_test_fv_with_lambda_input.shape[0], int((lambda_test_fv_with_lambda_input.shape[1]*(n/(n+1)))/n), n)\n",
    "\n",
    "        lambda_train_fv_list.append(lambda_train_fv)\n",
    "        lambda_valid_fv_list.append(lambda_valid_fv)\n",
    "        lambda_test_fv_list.append(lambda_test_fv)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:47:21.190853Z",
     "start_time": "2020-11-24T18:47:21.153638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FV_1</th>\n",
       "      <th>FV_2</th>\n",
       "      <th>FV_3</th>\n",
       "      <th>FV_4</th>\n",
       "      <th>FV_5</th>\n",
       "      <th>FV_6</th>\n",
       "      <th>FV_7</th>\n",
       "      <th>FV_8</th>\n",
       "      <th>FV_9</th>\n",
       "      <th>FV_10</th>\n",
       "      <th>...</th>\n",
       "      <th>FV_553</th>\n",
       "      <th>FV_554</th>\n",
       "      <th>FV_555</th>\n",
       "      <th>FV_556</th>\n",
       "      <th>FV_557</th>\n",
       "      <th>FV_558</th>\n",
       "      <th>FV_559</th>\n",
       "      <th>FV_560</th>\n",
       "      <th>FV_561</th>\n",
       "      <th>FV_562</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.951</td>\n",
       "      <td>15.606</td>\n",
       "      <td>4.990</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>1.946</td>\n",
       "      <td>8.909</td>\n",
       "      <td>12.277</td>\n",
       "      <td>1.950</td>\n",
       "      <td>9.194</td>\n",
       "      <td>6.634</td>\n",
       "      <td>...</td>\n",
       "      <td>7.067</td>\n",
       "      <td>17.944</td>\n",
       "      <td>12.276</td>\n",
       "      <td>-6.835</td>\n",
       "      <td>8.298</td>\n",
       "      <td>3.209</td>\n",
       "      <td>9.222</td>\n",
       "      <td>2.589</td>\n",
       "      <td>8.456</td>\n",
       "      <td>15.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.600</td>\n",
       "      <td>1.181</td>\n",
       "      <td>21.490</td>\n",
       "      <td>5.654</td>\n",
       "      <td>5.064</td>\n",
       "      <td>9.026</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>1.127</td>\n",
       "      <td>1.689</td>\n",
       "      <td>3.676</td>\n",
       "      <td>...</td>\n",
       "      <td>19.761</td>\n",
       "      <td>18.285</td>\n",
       "      <td>4.620</td>\n",
       "      <td>-1.954</td>\n",
       "      <td>1.962</td>\n",
       "      <td>13.634</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>5.233</td>\n",
       "      <td>2.837</td>\n",
       "      <td>-1.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.883</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>10.150</td>\n",
       "      <td>21.020</td>\n",
       "      <td>11.436</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>1.106</td>\n",
       "      <td>-2.585</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>...</td>\n",
       "      <td>6.232</td>\n",
       "      <td>4.038</td>\n",
       "      <td>12.435</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>10.893</td>\n",
       "      <td>3.448</td>\n",
       "      <td>11.973</td>\n",
       "      <td>4.189</td>\n",
       "      <td>0.902</td>\n",
       "      <td>11.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.521</td>\n",
       "      <td>-7.067</td>\n",
       "      <td>-3.005</td>\n",
       "      <td>-9.257</td>\n",
       "      <td>15.999</td>\n",
       "      <td>1.229</td>\n",
       "      <td>-8.037</td>\n",
       "      <td>10.463</td>\n",
       "      <td>-5.991</td>\n",
       "      <td>3.136</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.309</td>\n",
       "      <td>-0.580</td>\n",
       "      <td>-10.226</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>12.240</td>\n",
       "      <td>9.094</td>\n",
       "      <td>6.850</td>\n",
       "      <td>-17.644</td>\n",
       "      <td>-2.814</td>\n",
       "      <td>4.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.464</td>\n",
       "      <td>0.573</td>\n",
       "      <td>-7.392</td>\n",
       "      <td>7.916</td>\n",
       "      <td>9.716</td>\n",
       "      <td>-5.251</td>\n",
       "      <td>0.238</td>\n",
       "      <td>10.764</td>\n",
       "      <td>13.035</td>\n",
       "      <td>-4.795</td>\n",
       "      <td>...</td>\n",
       "      <td>2.346</td>\n",
       "      <td>14.943</td>\n",
       "      <td>0.648</td>\n",
       "      <td>13.565</td>\n",
       "      <td>-5.710</td>\n",
       "      <td>11.789</td>\n",
       "      <td>15.837</td>\n",
       "      <td>12.519</td>\n",
       "      <td>-0.557</td>\n",
       "      <td>-5.637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FV_1   FV_2   FV_3   FV_4   FV_5   FV_6   FV_7   FV_8   FV_9  FV_10  ...  \\\n",
       "0 -4.951 15.606  4.990 -0.175  1.946  8.909 12.277  1.950  9.194  6.634  ...   \n",
       "1 -2.600  1.181 21.490  5.654  5.064  9.026 -0.185  1.127  1.689  3.676  ...   \n",
       "2  2.883 -0.129 10.150 21.020 11.436 -0.111 -0.433  1.106 -2.585 -0.085  ...   \n",
       "3 -2.521 -7.067 -3.005 -9.257 15.999  1.229 -8.037 10.463 -5.991  3.136  ...   \n",
       "4 15.464  0.573 -7.392  7.916  9.716 -5.251  0.238 10.764 13.035 -4.795  ...   \n",
       "\n",
       "   FV_553  FV_554  FV_555  FV_556  FV_557  FV_558  FV_559  FV_560  FV_561  \\\n",
       "0   7.067  17.944  12.276  -6.835   8.298   3.209   9.222   2.589   8.456   \n",
       "1  19.761  18.285   4.620  -1.954   1.962  13.634  -0.362   5.233   2.837   \n",
       "2   6.232   4.038  12.435  -0.325  10.893   3.448  11.973   4.189   0.902   \n",
       "3  -9.309  -0.580 -10.226  -0.542  12.240   9.094   6.850 -17.644  -2.814   \n",
       "4   2.346  14.943   0.648  13.565  -5.710  11.789  15.837  12.519  -0.557   \n",
       "\n",
       "   FV_562  \n",
       "0  15.179  \n",
       "1  -1.613  \n",
       "2  11.103  \n",
       "3   4.051  \n",
       "4  -5.637  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_train_fv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:48:15.203558Z",
     "start_time": "2020-11-24T18:48:15.188700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.34, -0.68,  0.88,  0.64],\n",
       "        [ 0.85,  0.73,  0.25, -0.37],\n",
       "        [ 0.57, -0.76, -0.52, -0.57],\n",
       "        ...,\n",
       "        [ 0.28,  0.01,  0.55,  0.22],\n",
       "        [ 0.59,  0.34,  0.16, -0.88],\n",
       "        [ 0.92,  0.86,  0.67, -0.14]],\n",
       "\n",
       "       [[-0.84, -0.31, -0.86,  0.77],\n",
       "        [ 0.99, -0.33,  0.66, -0.19],\n",
       "        [-0.01,  0.55,  0.52, -0.64],\n",
       "        ...,\n",
       "        [-0.64,  0.98,  0.05,  0.75],\n",
       "        [-0.11, -0.95,  0.73,  0.4 ],\n",
       "        [ 0.02, -0.13, -0.29,  0.15]],\n",
       "\n",
       "       [[ 0.11,  0.06,  0.1 ,  0.14],\n",
       "        [ 0.98,  0.37,  0.27,  0.54],\n",
       "        [-0.55, -0.19,  0.17, -0.77],\n",
       "        ...,\n",
       "        [-0.42,  0.86, -0.81, -0.16],\n",
       "        [ 0.41,  0.51, -0.88,  0.57],\n",
       "        [-0.93,  0.18, -0.06, -0.79]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.33,  0.83,  0.8 ,  0.63],\n",
       "        [-0.5 , -0.06,  0.9 , -0.46],\n",
       "        [ 0.89, -0.03, -0.71,  0.56],\n",
       "        ...,\n",
       "        [ 0.63, -0.93, -0.96,  0.48],\n",
       "        [-0.93, -0.17,  0.49,  0.29],\n",
       "        [ 0.34,  0.76,  0.77,  0.23]],\n",
       "\n",
       "       [[ 0.  , -0.64, -0.01,  0.16],\n",
       "        [ 0.74,  0.38, -0.77,  0.38],\n",
       "        [-0.93, -0.9 , -0.32,  0.3 ],\n",
       "        ...,\n",
       "        [ 0.9 ,  0.75, -0.39,  0.3 ],\n",
       "        [ 0.25,  0.97, -0.95,  0.96],\n",
       "        [ 0.66, -0.25, -0.33,  0.27]],\n",
       "\n",
       "       [[-0.83,  0.38,  0.91, -0.9 ],\n",
       "        [ 0.74,  0.65, -0.11,  0.3 ],\n",
       "        [-0.73, -0.32,  0.72, -0.46],\n",
       "        ...,\n",
       "        [-0.02,  0.23,  0.55, -0.21],\n",
       "        [-0.72,  0.12,  0.92, -0.57],\n",
       "        [-0.79, -0.26,  0.43,  0.92]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_train_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:48:15.573842Z",
     "start_time": "2020-11-24T18:48:15.537678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "      <th>1148</th>\n",
       "      <th>1149</th>\n",
       "      <th>1150</th>\n",
       "      <th>1151</th>\n",
       "      <th>1152</th>\n",
       "      <th>1153</th>\n",
       "      <th>1154</th>\n",
       "      <th>1155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.100</td>\n",
       "      <td>4.300</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>2.200</td>\n",
       "      <td>-4.700</td>\n",
       "      <td>-1.500</td>\n",
       "      <td>-2.300</td>\n",
       "      <td>-9.700</td>\n",
       "      <td>-4.600</td>\n",
       "      <td>-5.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.500</td>\n",
       "      <td>-3.400</td>\n",
       "      <td>9.200</td>\n",
       "      <td>-3.700</td>\n",
       "      <td>6.300</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.900</td>\n",
       "      <td>3.300</td>\n",
       "      <td>2.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.300</td>\n",
       "      <td>7.100</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-8.200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-9.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>-9.600</td>\n",
       "      <td>1.700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>3.500</td>\n",
       "      <td>-6.800</td>\n",
       "      <td>8.600</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-10.000</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-9.500</td>\n",
       "      <td>-2.400</td>\n",
       "      <td>1.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.619</td>\n",
       "      <td>1.013</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.200</td>\n",
       "      <td>-1.400</td>\n",
       "      <td>-5.300</td>\n",
       "      <td>2.700</td>\n",
       "      <td>7.700</td>\n",
       "      <td>2.700</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>3.200</td>\n",
       "      <td>-3.200</td>\n",
       "      <td>-7.900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1      2      3      4       5      6      7      8      9     ...  \\\n",
       "0  7.100  4.300 -4.500  2.200 -4.700  -1.500 -2.300 -9.700 -4.600 -5.200  ...   \n",
       "1  1.500 -3.400  9.200 -3.700  6.300  -3.000  9.600  9.900  3.300  2.400  ...   \n",
       "2  4.300  7.100 -1.000 -8.200  0.100   8.900 -9.000  1.100 -9.600  1.700  ...   \n",
       "3  0.000  3.500 -6.800  8.600 -4.300 -10.000  9.300 -9.500 -2.400  1.800  ...   \n",
       "4 -0.200 -1.400 -5.300  2.700  7.700   2.700 -0.600  3.200 -3.200 -7.900  ...   \n",
       "\n",
       "   1146  1147   1148  1149   1150   1151   1152  1153  1154   1155  \n",
       "0 0.261 0.313 -0.334 0.410 -0.242 -0.110 -0.839 0.526 0.539  0.532  \n",
       "1 0.423 0.274 -0.131 0.133 -0.215  0.392 -0.252 0.719 0.181  0.594  \n",
       "2 0.285 0.191 -0.056 0.160  0.104  0.173  0.115 0.546 0.517  0.892  \n",
       "3 0.231 0.098 -0.141 0.008 -0.200 -0.287 -0.619 1.013 0.365 -0.748  \n",
       "4 0.388 0.088 -0.053 0.114  0.207  0.042 -0.168 0.772 0.400  0.223  \n",
       "\n",
       "[5 rows x 1156 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:48:15.769911Z",
     "start_time": "2020-11-24T18:48:15.735390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FV_1</th>\n",
       "      <th>FV_2</th>\n",
       "      <th>FV_3</th>\n",
       "      <th>FV_4</th>\n",
       "      <th>FV_5</th>\n",
       "      <th>FV_6</th>\n",
       "      <th>FV_7</th>\n",
       "      <th>FV_8</th>\n",
       "      <th>FV_9</th>\n",
       "      <th>FV_10</th>\n",
       "      <th>...</th>\n",
       "      <th>FV_241</th>\n",
       "      <th>FV_242</th>\n",
       "      <th>FV_243</th>\n",
       "      <th>FV_244</th>\n",
       "      <th>FV_245</th>\n",
       "      <th>FV_246</th>\n",
       "      <th>FV_247</th>\n",
       "      <th>FV_248</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.881</td>\n",
       "      <td>11.380</td>\n",
       "      <td>0.109</td>\n",
       "      <td>3.194</td>\n",
       "      <td>-3.499</td>\n",
       "      <td>15.960</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>6.602</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>8.063</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.715</td>\n",
       "      <td>9.532</td>\n",
       "      <td>13.552</td>\n",
       "      <td>10.270</td>\n",
       "      <td>-14.005</td>\n",
       "      <td>15.210</td>\n",
       "      <td>8.642</td>\n",
       "      <td>14.340</td>\n",
       "      <td>5.384</td>\n",
       "      <td>-3.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.162</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>5.091</td>\n",
       "      <td>6.428</td>\n",
       "      <td>1.942</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>11.418</td>\n",
       "      <td>14.439</td>\n",
       "      <td>9.498</td>\n",
       "      <td>6.137</td>\n",
       "      <td>...</td>\n",
       "      <td>10.565</td>\n",
       "      <td>-2.338</td>\n",
       "      <td>2.972</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-1.130</td>\n",
       "      <td>6.034</td>\n",
       "      <td>10.796</td>\n",
       "      <td>5.012</td>\n",
       "      <td>3.832</td>\n",
       "      <td>3.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.933</td>\n",
       "      <td>13.306</td>\n",
       "      <td>0.150</td>\n",
       "      <td>10.762</td>\n",
       "      <td>16.411</td>\n",
       "      <td>2.209</td>\n",
       "      <td>6.656</td>\n",
       "      <td>15.933</td>\n",
       "      <td>2.520</td>\n",
       "      <td>0.970</td>\n",
       "      <td>...</td>\n",
       "      <td>16.471</td>\n",
       "      <td>6.594</td>\n",
       "      <td>3.300</td>\n",
       "      <td>12.032</td>\n",
       "      <td>2.487</td>\n",
       "      <td>13.257</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>3.379</td>\n",
       "      <td>0.664</td>\n",
       "      <td>1.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.478</td>\n",
       "      <td>-11.535</td>\n",
       "      <td>-9.354</td>\n",
       "      <td>4.199</td>\n",
       "      <td>2.892</td>\n",
       "      <td>-6.789</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>6.479</td>\n",
       "      <td>-9.510</td>\n",
       "      <td>-6.239</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.036</td>\n",
       "      <td>7.107</td>\n",
       "      <td>-5.450</td>\n",
       "      <td>-8.182</td>\n",
       "      <td>-2.617</td>\n",
       "      <td>-7.381</td>\n",
       "      <td>-4.115</td>\n",
       "      <td>7.643</td>\n",
       "      <td>10.119</td>\n",
       "      <td>4.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.508</td>\n",
       "      <td>-4.920</td>\n",
       "      <td>-4.010</td>\n",
       "      <td>-1.363</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.888</td>\n",
       "      <td>10.471</td>\n",
       "      <td>-3.454</td>\n",
       "      <td>3.463</td>\n",
       "      <td>2.060</td>\n",
       "      <td>...</td>\n",
       "      <td>19.394</td>\n",
       "      <td>7.745</td>\n",
       "      <td>-2.683</td>\n",
       "      <td>-3.631</td>\n",
       "      <td>8.324</td>\n",
       "      <td>-1.342</td>\n",
       "      <td>17.275</td>\n",
       "      <td>-10.202</td>\n",
       "      <td>-4.529</td>\n",
       "      <td>12.978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FV_1    FV_2   FV_3   FV_4   FV_5   FV_6   FV_7   FV_8   FV_9  FV_10  ...  \\\n",
       "0  5.881  11.380  0.109  3.194 -3.499 15.960 -0.954  6.602 -0.159  8.063  ...   \n",
       "1 -1.162  -0.860  5.091  6.428  1.942 -1.361 11.418 14.439  9.498  6.137  ...   \n",
       "2  6.933  13.306  0.150 10.762 16.411  2.209  6.656 15.933  2.520  0.970  ...   \n",
       "3 -6.478 -11.535 -9.354  4.199  2.892 -6.789 -0.367  6.479 -9.510 -6.239  ...   \n",
       "4 -5.508  -4.920 -4.010 -1.363  0.047  0.888 10.471 -3.454  3.463  2.060  ...   \n",
       "\n",
       "   FV_241  FV_242  FV_243  FV_244  FV_245  FV_246  FV_247  FV_248  FV_249  \\\n",
       "0  -2.715   9.532  13.552  10.270 -14.005  15.210   8.642  14.340   5.384   \n",
       "1  10.565  -2.338   2.972  -0.974  -1.130   6.034  10.796   5.012   3.832   \n",
       "2  16.471   6.594   3.300  12.032   2.487  13.257  -0.047   3.379   0.664   \n",
       "3 -15.036   7.107  -5.450  -8.182  -2.617  -7.381  -4.115   7.643  10.119   \n",
       "4  19.394   7.745  -2.683  -3.631   8.324  -1.342  17.275 -10.202  -4.529   \n",
       "\n",
       "   FV_250  \n",
       "0  -3.084  \n",
       "1   3.109  \n",
       "2   1.021  \n",
       "3   4.186  \n",
       "4  12.978  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_test_fv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:48:15.964862Z",
     "start_time": "2020-11-24T18:48:15.930597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FV_1</th>\n",
       "      <th>FV_2</th>\n",
       "      <th>FV_3</th>\n",
       "      <th>FV_4</th>\n",
       "      <th>FV_5</th>\n",
       "      <th>FV_6</th>\n",
       "      <th>FV_7</th>\n",
       "      <th>FV_8</th>\n",
       "      <th>FV_9</th>\n",
       "      <th>FV_10</th>\n",
       "      <th>...</th>\n",
       "      <th>FV_179</th>\n",
       "      <th>FV_180</th>\n",
       "      <th>FV_181</th>\n",
       "      <th>FV_182</th>\n",
       "      <th>FV_183</th>\n",
       "      <th>FV_184</th>\n",
       "      <th>FV_185</th>\n",
       "      <th>FV_186</th>\n",
       "      <th>FV_187</th>\n",
       "      <th>FV_188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.358</td>\n",
       "      <td>15.069</td>\n",
       "      <td>14.570</td>\n",
       "      <td>-1.030</td>\n",
       "      <td>2.898</td>\n",
       "      <td>10.726</td>\n",
       "      <td>7.045</td>\n",
       "      <td>-5.846</td>\n",
       "      <td>9.923</td>\n",
       "      <td>8.888</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.813</td>\n",
       "      <td>14.433</td>\n",
       "      <td>17.990</td>\n",
       "      <td>6.138</td>\n",
       "      <td>9.548</td>\n",
       "      <td>11.632</td>\n",
       "      <td>1.658</td>\n",
       "      <td>3.483</td>\n",
       "      <td>13.373</td>\n",
       "      <td>-1.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.531</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>7.630</td>\n",
       "      <td>1.974</td>\n",
       "      <td>1.891</td>\n",
       "      <td>1.683</td>\n",
       "      <td>5.909</td>\n",
       "      <td>2.118</td>\n",
       "      <td>29.357</td>\n",
       "      <td>10.092</td>\n",
       "      <td>...</td>\n",
       "      <td>18.614</td>\n",
       "      <td>6.935</td>\n",
       "      <td>15.357</td>\n",
       "      <td>20.148</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-2.621</td>\n",
       "      <td>3.223</td>\n",
       "      <td>14.303</td>\n",
       "      <td>0.438</td>\n",
       "      <td>3.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.579</td>\n",
       "      <td>10.271</td>\n",
       "      <td>0.871</td>\n",
       "      <td>6.128</td>\n",
       "      <td>13.769</td>\n",
       "      <td>23.931</td>\n",
       "      <td>3.142</td>\n",
       "      <td>5.301</td>\n",
       "      <td>1.317</td>\n",
       "      <td>5.992</td>\n",
       "      <td>...</td>\n",
       "      <td>2.973</td>\n",
       "      <td>4.183</td>\n",
       "      <td>9.986</td>\n",
       "      <td>2.712</td>\n",
       "      <td>10.458</td>\n",
       "      <td>2.659</td>\n",
       "      <td>2.555</td>\n",
       "      <td>1.657</td>\n",
       "      <td>3.125</td>\n",
       "      <td>19.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.462</td>\n",
       "      <td>-7.571</td>\n",
       "      <td>-3.530</td>\n",
       "      <td>-10.828</td>\n",
       "      <td>1.330</td>\n",
       "      <td>1.753</td>\n",
       "      <td>2.734</td>\n",
       "      <td>-8.226</td>\n",
       "      <td>-13.892</td>\n",
       "      <td>10.439</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.369</td>\n",
       "      <td>-14.358</td>\n",
       "      <td>-3.588</td>\n",
       "      <td>-11.561</td>\n",
       "      <td>-5.084</td>\n",
       "      <td>3.753</td>\n",
       "      <td>-5.203</td>\n",
       "      <td>5.693</td>\n",
       "      <td>-10.272</td>\n",
       "      <td>5.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.281</td>\n",
       "      <td>-1.675</td>\n",
       "      <td>-2.959</td>\n",
       "      <td>7.560</td>\n",
       "      <td>12.420</td>\n",
       "      <td>1.733</td>\n",
       "      <td>-2.345</td>\n",
       "      <td>-3.311</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>14.586</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.634</td>\n",
       "      <td>1.669</td>\n",
       "      <td>-3.310</td>\n",
       "      <td>9.909</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>8.331</td>\n",
       "      <td>-5.423</td>\n",
       "      <td>-3.626</td>\n",
       "      <td>-6.916</td>\n",
       "      <td>9.615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FV_1   FV_2   FV_3    FV_4   FV_5   FV_6   FV_7   FV_8    FV_9  FV_10  \\\n",
       "0  -0.358 15.069 14.570  -1.030  2.898 10.726  7.045 -5.846   9.923  8.888   \n",
       "1   1.531 -0.140  7.630   1.974  1.891  1.683  5.909  2.118  29.357 10.092   \n",
       "2   4.579 10.271  0.871   6.128 13.769 23.931  3.142  5.301   1.317  5.992   \n",
       "3 -13.462 -7.571 -3.530 -10.828  1.330  1.753  2.734 -8.226 -13.892 10.439   \n",
       "4 -10.281 -1.675 -2.959   7.560 12.420  1.733 -2.345 -3.311  -0.816 14.586   \n",
       "\n",
       "   ...  FV_179  FV_180  FV_181  FV_182  FV_183  FV_184  FV_185  FV_186  \\\n",
       "0  ... -11.813  14.433  17.990   6.138   9.548  11.632   1.658   3.483   \n",
       "1  ...  18.614   6.935  15.357  20.148  -0.057  -2.621   3.223  14.303   \n",
       "2  ...   2.973   4.183   9.986   2.712  10.458   2.659   2.555   1.657   \n",
       "3  ...  -1.369 -14.358  -3.588 -11.561  -5.084   3.753  -5.203   5.693   \n",
       "4  ...  -5.634   1.669  -3.310   9.909  -0.134   8.331  -5.423  -3.626   \n",
       "\n",
       "   FV_187  FV_188  \n",
       "0  13.373  -1.385  \n",
       "1   0.438   3.634  \n",
       "2   3.125  19.546  \n",
       "3 -10.272   5.397  \n",
       "4  -6.916   9.615  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_valid_fv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:48:20.177552Z",
     "start_time": "2020-11-24T18:48:16.238006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "      <th>1148</th>\n",
       "      <th>1149</th>\n",
       "      <th>1150</th>\n",
       "      <th>1151</th>\n",
       "      <th>1152</th>\n",
       "      <th>1153</th>\n",
       "      <th>1154</th>\n",
       "      <th>1155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>0.585</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.671</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.701</td>\n",
       "      <td>5.490</td>\n",
       "      <td>5.825</td>\n",
       "      <td>5.783</td>\n",
       "      <td>5.458</td>\n",
       "      <td>5.951</td>\n",
       "      <td>6.125</td>\n",
       "      <td>6.281</td>\n",
       "      <td>5.772</td>\n",
       "      <td>5.952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-10.000</td>\n",
       "      <td>-9.900</td>\n",
       "      <td>-9.700</td>\n",
       "      <td>-9.600</td>\n",
       "      <td>-9.700</td>\n",
       "      <td>-10.000</td>\n",
       "      <td>-9.700</td>\n",
       "      <td>-9.700</td>\n",
       "      <td>-9.800</td>\n",
       "      <td>-10.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.759</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-1.004</td>\n",
       "      <td>-0.509</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-2.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.900</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-5.450</td>\n",
       "      <td>-3.850</td>\n",
       "      <td>-4.875</td>\n",
       "      <td>-4.625</td>\n",
       "      <td>-4.150</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>-3.975</td>\n",
       "      <td>-5.225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.696</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>1.300</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.186</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.925</td>\n",
       "      <td>4.525</td>\n",
       "      <td>4.200</td>\n",
       "      <td>5.025</td>\n",
       "      <td>4.225</td>\n",
       "      <td>4.900</td>\n",
       "      <td>6.550</td>\n",
       "      <td>5.025</td>\n",
       "      <td>4.675</td>\n",
       "      <td>5.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.800</td>\n",
       "      <td>9.800</td>\n",
       "      <td>9.700</td>\n",
       "      <td>9.900</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.900</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.900</td>\n",
       "      <td>9.500</td>\n",
       "      <td>9.900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.188</td>\n",
       "      <td>1.041</td>\n",
       "      <td>1.204</td>\n",
       "      <td>1.702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 1156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8     \\\n",
       "count 100.000 100.000 100.000 100.000 100.000 100.000 100.000 100.000 100.000   \n",
       "mean    0.401   0.173  -0.249   0.585  -0.343  -0.045   0.671  -0.583   0.245   \n",
       "std     5.701   5.490   5.825   5.783   5.458   5.951   6.125   6.281   5.772   \n",
       "min   -10.000  -9.900  -9.700  -9.600  -9.700 -10.000  -9.700  -9.700  -9.800   \n",
       "25%    -3.900  -4.400  -5.450  -3.850  -4.875  -4.625  -4.150  -6.500  -3.975   \n",
       "50%     0.800   0.900  -0.300   1.300  -0.950   0.650   0.250  -0.450   0.200   \n",
       "75%     4.925   4.525   4.200   5.025   4.225   4.900   6.550   5.025   4.675   \n",
       "max     9.800   9.800   9.700   9.900   9.600   9.900   9.600   9.900   9.500   \n",
       "\n",
       "         9     ...    1146    1147    1148    1149    1150    1151    1152  \\\n",
       "count 100.000  ... 100.000 100.000 100.000 100.000 100.000 100.000 100.000   \n",
       "mean    0.016  ...   0.017   0.324  -0.299   0.269  -0.263   0.117  -0.430   \n",
       "std     5.952  ...   0.322   0.168   0.165   0.170   0.260   0.291   0.348   \n",
       "min   -10.000  ...  -0.671   0.083  -0.759  -0.014  -1.004  -0.509  -1.295   \n",
       "25%    -5.225  ...  -0.253   0.200  -0.399   0.130  -0.433  -0.144  -0.696   \n",
       "50%    -0.600  ...   0.035   0.304  -0.285   0.247  -0.240   0.186  -0.388   \n",
       "75%     5.500  ...   0.237   0.425  -0.182   0.425  -0.076   0.336  -0.166   \n",
       "max     9.900  ...   0.648   0.769  -0.020   0.699   0.207   0.701   0.188   \n",
       "\n",
       "         1153    1154    1155  \n",
       "count 100.000 100.000 100.000  \n",
       "mean    0.438   0.452  -0.135  \n",
       "std     0.243   0.235   0.837  \n",
       "min     0.070   0.067  -2.159  \n",
       "25%     0.242   0.270  -0.725  \n",
       "50%     0.407   0.431  -0.122  \n",
       "75%     0.625   0.614   0.515  \n",
       "max     1.041   1.204   1.702  \n",
       "\n",
       "[8 rows x 1156 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets for Interpretation-Net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T18:48:20.839456Z",
     "start_time": "2020-11-24T18:48:20.181591Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce9261fd7a944d5982fe347448f6f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#generate train, test and validation data for training\n",
    "if multi_epoch_analysis:    \n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    \n",
    "    X_valid_list = []\n",
    "    y_valid_list = []\n",
    "    \n",
    "    X_test_list = []\n",
    "    y_test_list = []\n",
    "    \n",
    "    lambda_test_fv_valid_split_list = []\n",
    "    lambda_test_fv_test_split_list = []\n",
    "    lambda_test_fv_train_split_list = []\n",
    "    \n",
    "    lambda_valid_fv_valid_split_list = []\n",
    "    lambda_valid_fv_test_split_list = []\n",
    "    lambda_valid_fv_train_split_list = []\n",
    "    \n",
    "    lambda_train_fv_valid_split_list = []\n",
    "    lambda_train_fv_test_split_list = []\n",
    "    lambda_train_fv_train_split_list = []\n",
    "    \n",
    "    for weight_data, lambda_train_fv, lambda_valid_fv, lambda_test_fv in tqdm(zip(weight_data_list, lambda_train_fv_list, lambda_valid_fv_list, lambda_test_fv_list), total=len(weight_data_list)): \n",
    "        \n",
    "        if psutil.virtual_memory().percent > 80:\n",
    "            raise SystemExit(\"Out of RAM!\")\n",
    "        \n",
    "        X_data = weight_data.sample(n=data_size, random_state=RANDOM_SEED).drop([i for i in range(nCr(n+d, d)*3)], axis=1)\n",
    "        y_data = weight_data.sample(n=data_size, random_state=RANDOM_SEED)[[i for i in range(nCr(n+d, d)*3)]].astype(float)\n",
    "        \n",
    "        lambda_train_fv = lambda_train_fv.sample(n=data_size, random_state=RANDOM_SEED)\n",
    "        lambda_valid_fv = lambda_valid_fv.sample(n=data_size, random_state=RANDOM_SEED)\n",
    "        lambda_test_fv = lambda_test_fv.sample(n=data_size, random_state=RANDOM_SEED)\n",
    "        \n",
    "        y_data_polynomial_true = y_data[[i for i in range(nCr(n+d, d))]]\n",
    "        y_data_polynomial_lstsq_pred = y_data[[i for i in range(nCr(n+d, d), nCr(n+d, d)*2)]]\n",
    "        y_data_polynomial_lstsq_true = y_data.drop([i for i in range(nCr(n+d, d)*2)], axis=1)      \n",
    "        \n",
    "        #y_data_polynomial = y_data_polynomial_true\n",
    "        #y_data_polynomial_pred_lstsq = y_data_polynomial_lstsq_pred\n",
    "        #y_data_polynomial_true_lstsq = y_data_polynomial_lstsq_true\n",
    "        \n",
    "        if evaluate_with_real_function:\n",
    "            y_data = y_data_polynomial_true\n",
    "        else:\n",
    "            y_data = y_data_polynomial_lstsq_pred  \n",
    "                                         \n",
    "        X_train_with_valid, X_test, y_train_with_valid, y_test = train_test_split(X_data, y_data, test_size=0.25, random_state=RANDOM_SEED)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train_with_valid, y_train_with_valid, test_size=0.25, random_state=RANDOM_SEED)           \n",
    "    \n",
    "        X_train_list.append(X_train)\n",
    "        y_train_list.append(y_train)\n",
    "\n",
    "        X_valid_list.append(X_valid)\n",
    "        y_valid_list.append(y_valid)\n",
    "\n",
    "        X_test_list.append(X_test)\n",
    "        y_test_list.append(y_test)   \n",
    "        \n",
    "\n",
    "        lambda_train_fv_with_valid_split, lambda_train_fv_test_split = train_test_split(lambda_train_fv, test_size=0.25, random_state=RANDOM_SEED)\n",
    "        lambda_train_fv_train_split, lambda_train_fv_valid_split = train_test_split(lambda_train_fv_with_valid_split, test_size=0.25, random_state=RANDOM_SEED)               \n",
    "        \n",
    "        lambda_train_fv_valid_split_list.append(lambda_train_fv_valid_split)\n",
    "        lambda_train_fv_test_split_list.append(lambda_train_fv_test_split)\n",
    "        lambda_train_fv_train_split_list.append(lambda_train_fv_train_split)\n",
    "        \n",
    "        \n",
    "        lambda_valid_fv_with_valid_split, lambda_valid_fv_test_split = train_test_split(lambda_valid_fv, test_size=0.25, random_state=RANDOM_SEED)\n",
    "        lambda_valid_fv_train_split, lambda_valid_fv_valid_split = train_test_split(lambda_valid_fv_with_valid_split, test_size=0.25, random_state=RANDOM_SEED)               \n",
    "        \n",
    "        lambda_valid_fv_valid_split_list.append(lambda_valid_fv_valid_split)\n",
    "        lambda_valid_fv_test_split_list.append(lambda_valid_fv_test_split)\n",
    "        lambda_valid_fv_train_split_list.append(lambda_valid_fv_train_split)\n",
    "        \n",
    "        \n",
    "        lambda_test_fv_with_valid_split, lambda_test_fv_test_split = train_test_split(lambda_test_fv, test_size=0.25, random_state=RANDOM_SEED)\n",
    "        lambda_test_fv_train_split, lambda_test_fv_valid_split = train_test_split(lambda_test_fv_with_valid_split, test_size=0.25, random_state=RANDOM_SEED)               \n",
    "        \n",
    "        lambda_test_fv_valid_split_list.append(lambda_test_fv_valid_split)\n",
    "        lambda_test_fv_test_split_list.append(lambda_test_fv_test_split)\n",
    "        lambda_test_fv_train_split_list.append(lambda_test_fv_train_split)   \n",
    "            \n",
    "else:    \n",
    "    lambda_test_fv_valid_split_list = []\n",
    "    lambda_test_fv_test_split_list = []\n",
    "    lambda_test_fv_train_split_list = []\n",
    "    \n",
    "    lambda_valid_fv_valid_split_list = []\n",
    "    lambda_valid_fv_test_split_list = []\n",
    "    lambda_valid_fv_train_split_list = []\n",
    "    \n",
    "    lambda_train_fv_valid_split_list = []\n",
    "    lambda_train_fv_test_split_list = []\n",
    "    lambda_train_fv_train_split_list = []\n",
    "    \n",
    "    X_data = weight_data.sample(n=data_size, random_state=RANDOM_SEED).drop([i for i in range(nCr(n+d, d)*3)], axis=1)\n",
    "    y_data = weight_data.sample(n=data_size, random_state=RANDOM_SEED)[[i for i in range(nCr(n+d, d)*3)]].astype(float)\n",
    "    \n",
    "    y_data_polynomial_true = y_data[[i for i in range(nCr(n+d, d))]]\n",
    "    y_data_polynomial_lstsq_pred = y_data[[i for i in range(nCr(n+d, d), nCr(n+d, d)*2)]]\n",
    "    y_data_polynomial_lstsq_true = y_data.drop([i for i in range(nCr(n+d, d)*2)], axis=1)\n",
    "    \n",
    "    lambda_train_fv = lambda_train_fv.sample(n=data_size, random_state=RANDOM_SEED)\n",
    "    lambda_valid_fv = lambda_valid_fv.sample(n=data_size, random_state=RANDOM_SEED)\n",
    "    lambda_test_fv = lambda_test_fv.sample(n=data_size, random_state=RANDOM_SEED)\n",
    "    \n",
    "    if evaluate_with_real_function:\n",
    "        y_data = y_data_polynomial_true\n",
    "    else:\n",
    "        y_data = y_data_polynomial_lstsq_pred                                     \n",
    "    \n",
    "        lambda_train_fv_with_valid_split, lambda_train_fv_test_split = train_test_split(lambda_train_fv, test_size=0.25, random_state=RANDOM_SEED)\n",
    "        lambda_train_fv_train_split, lambda_train_fv_valid_split = train_test_split(lambda_train_fv_with_valid_split, test_size=0.25, random_state=RANDOM_SEED)               \n",
    "        \n",
    "        lambda_valid_fv_with_valid_split, lambda_valid_fv_test_split = train_test_split(lambda_valid_fv, test_size=0.25, random_state=RANDOM_SEED)\n",
    "        lambda_valid_fv_train_split, lambda_valid_fv_valid_split = train_test_split(lambda_valid_fv_with_valid_split, test_size=0.25, random_state=RANDOM_SEED)               \n",
    "\n",
    "        lambda_test_fv_with_valid_split, lambda_test_fv_test_split = train_test_split(lambda_test_fv, test_size=0.25, random_state=RANDOM_SEED)\n",
    "        lambda_test_fv_train_split, lambda_test_fv_valid_split = train_test_split(lambda_test_fv_with_valid_split, test_size=0.25, random_state=RANDOM_SEED)               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:36:53.764023Z",
     "start_time": "2020-11-25T08:36:53.724549Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>...</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "      <th>1148</th>\n",
       "      <th>1149</th>\n",
       "      <th>1150</th>\n",
       "      <th>1151</th>\n",
       "      <th>1152</th>\n",
       "      <th>1153</th>\n",
       "      <th>1154</th>\n",
       "      <th>1155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.490</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.503</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.620</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.370</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>1.006</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.676</td>\n",
       "      <td>1.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.204</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     105    106    107    108    109    110   111   112    113    114   ...  \\\n",
       "98  0.136 -0.032 -0.017 -0.187 -0.307  0.239 0.182 0.189 -0.181 -0.076  ...   \n",
       "24  0.259 -0.051  0.267 -0.055 -0.116  0.474 0.537 0.503 -0.166 -0.105  ...   \n",
       "68 -0.177 -0.028 -0.052 -0.443 -0.425 -0.326 0.091 0.070 -0.086 -0.103  ...   \n",
       "93  0.058 -0.066 -0.087 -0.073 -0.404  0.063 0.030 0.068 -0.171 -0.133  ...   \n",
       "14  0.025 -0.020  0.188 -0.023 -0.224  0.165 0.285 0.203 -0.093 -0.136  ...   \n",
       "\n",
       "     1146  1147   1148  1149   1150   1151   1152  1153  1154  1155  \n",
       "98  0.072 0.418 -0.319 0.490 -0.229  0.283 -0.653 0.556 0.555 0.859  \n",
       "24  0.052 0.620 -0.298 0.478 -0.118  0.419  0.116 0.340 0.700 0.896  \n",
       "68  0.402 0.119 -0.344 0.370 -0.370 -0.102 -0.915 1.006 0.696 0.390  \n",
       "93  0.245 0.482 -0.210 0.515  0.151  0.029 -0.240 0.681 0.676 1.196  \n",
       "14 -0.219 0.411 -0.216 0.204 -0.141  0.324 -0.221 0.322 0.342 0.841  \n",
       "\n",
       "[5 rows x 1051 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if multi_epoch_analysis:\n",
    "    print_head = X_train_list[-1].head()\n",
    "else:\n",
    "    print_head = X_train.head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:36:53.989443Z",
     "start_time": "2020-11-25T08:36:53.954084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10.284</td>\n",
       "      <td>-2.435</td>\n",
       "      <td>0.936</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-12.945</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>1.773</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.212</td>\n",
       "      <td>-5.663</td>\n",
       "      <td>1.789</td>\n",
       "      <td>0.172</td>\n",
       "      <td>4.503</td>\n",
       "      <td>0.349</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>1.959</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>-2.074</td>\n",
       "      <td>1.208</td>\n",
       "      <td>-2.042</td>\n",
       "      <td>2.039</td>\n",
       "      <td>0.963</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>2.224</td>\n",
       "      <td>-0.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4.026</td>\n",
       "      <td>-3.754</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-13.420</td>\n",
       "      <td>1.261</td>\n",
       "      <td>0.350</td>\n",
       "      <td>5.732</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>1.515</td>\n",
       "      <td>-5.307</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-1.476</td>\n",
       "      <td>1.038</td>\n",
       "      <td>1.085</td>\n",
       "      <td>0.157</td>\n",
       "      <td>1.172</td>\n",
       "      <td>-1.180</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9.406</td>\n",
       "      <td>7.322</td>\n",
       "      <td>3.457</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-9.102</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>0.081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>1.954</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>1.987</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.664</td>\n",
       "      <td>-6.767</td>\n",
       "      <td>1.547</td>\n",
       "      <td>0.465</td>\n",
       "      <td>3.236</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>0.517</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       35     36    37     38      39     40     41     42     43    44  ...  \\\n",
       "98 10.284 -2.435 0.936 -0.226 -12.945 -0.579  0.279  0.756  0.948 0.896  ...   \n",
       "24  9.212 -5.663 1.789  0.172   4.503  0.349 -0.141  1.959  0.506 0.002  ...   \n",
       "68  4.026 -3.754 0.099  0.171 -13.420  1.261  0.350  5.732  0.878 0.862  ...   \n",
       "93  9.406  7.322 3.457  0.036  -9.102 -0.532  0.376 -0.614 -0.257 0.081  ...   \n",
       "14  6.664 -6.767 1.547  0.465   3.236 -0.528 -0.539  0.253  0.604 0.017  ...   \n",
       "\n",
       "       60     61     62     63     64    65    66     67     68     69  \n",
       "98 -0.807 -0.187 -0.242  0.798 -0.437 1.773 0.030  0.582 -0.426 -0.062  \n",
       "24 -0.245 -2.710 -2.074  1.208 -2.042 2.039 0.963 -0.302  2.224 -0.541  \n",
       "68  1.515 -5.307 -0.123 -1.476  1.038 1.085 0.157  1.172 -1.180  0.285  \n",
       "93 -0.056  1.954  0.148  0.108 -0.311 1.987 0.002 -0.108 -0.369 -0.328  \n",
       "14 -0.244  0.544 -0.665  0.517 -0.306 0.395 0.253 -0.150  0.111 -0.154  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if multi_epoch_analysis:\n",
    "    print_head = y_train_list[-1].head()\n",
    "else:\n",
    "    print_head = y_train.head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T12:55:38.612107Z",
     "start_time": "2020-11-25T12:55:38.598814Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_base_model():\n",
    "    base_model = Sequential()\n",
    "\n",
    "    base_model.add(Dense(lambda_network_layers[0], activation='relu', input_dim=lambda_train_input[0].shape[1])) #1024\n",
    "\n",
    "    if dropout > 0:\n",
    "        base_model.add(Dropout(dropout))\n",
    "\n",
    "    for neurons in lambda_network_layers[1:]:\n",
    "        base_model.add(Dense(neurons, activation='relu'))\n",
    "        if dropout > 0:\n",
    "            base_model.add(Dropout(dropout))   \n",
    "\n",
    "    base_model.add(Dense(1))\n",
    "    \n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:48:59.727537Z",
     "start_time": "2020-11-25T08:48:59.686484Z"
    },
    "code_folding": [
     94
    ]
   },
   "outputs": [],
   "source": [
    "def train_nn_and_pred(X_train, \n",
    "                      X_valid, \n",
    "                      X_test, \n",
    "                      y_train, \n",
    "                      y_valid, \n",
    "                      y_test,\n",
    "                      lambda_train_fv_valid_split, \n",
    "                      lambda_train_fv_test_split, \n",
    "                      lambda_train_fv_train_split, \n",
    "                      lambda_valid_fv_valid_split, \n",
    "                      lambda_valid_fv_test_split, \n",
    "                      lambda_valid_fv_train_split, \n",
    "                      lambda_test_fv_valid_split, \n",
    "                      lambda_test_fv_test_split, \n",
    "                      lambda_test_fv_train_split, \n",
    "                      callback_names=[], \n",
    "                      return_model=False):       \n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(interpretation_network_layers[0], activation='relu', input_dim=X_train.shape[1])) #1024\n",
    "    \n",
    "    if dropout > 0:\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    for neurons in interpretation_network_layers[1:]:\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "    model.add(Dense(nCr(n+d, d))) \n",
    "    \n",
    "    #decide whether to use lambda preds for evaluation or polynomial from lstsq lambda preds\n",
    "    if not consider_labels_training and not evaluate_with_real_function:\n",
    "        base_model = generate_base_model()\n",
    "  \n",
    "        list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)\n",
    "        \n",
    "        \n",
    "        loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(lambda_train_input[0], list_of_monomial_identifiers_numbers, base_model)      \n",
    "        metrics = [mean_absolute_error_tf_fv_lambda_extended_wrapper(lambda_train_input[0], list_of_monomial_identifiers_numbers, base_model), mean_absolute_error_extended]\n",
    "        #loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(lambda_train_input[0], list_of_monomial_identifiers_numbers)      \n",
    "        #metrics = [mean_absolute_error_tf_fv_lambda_extended_wrapper(lambda_train_input[0], list_of_monomial_identifiers_numbers), mean_absolute_error_extended]\n",
    "        valid_data = None\n",
    "        y_train_model = np.hstack((y_train, X_train))\n",
    "        #y_train_model = np.hstack((y_train, lambda_train_fv_train_split))\n",
    "        \n",
    "    else:\n",
    "        loss_function = mean_absolute_error_tf_fv\n",
    "        metrics = ['mean_absolute_error']\n",
    "        valid_data = (X_valid, y_valid)\n",
    "        y_train_model = y_train\n",
    "      \n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss_function,\n",
    "                  metrics=metrics\n",
    "                 )\n",
    "\n",
    "    #Callbacks\n",
    "    callbacks = return_callbacks_from_string(callback_names)\n",
    "        \n",
    "    history = model.fit(X_train,\n",
    "              y_train_model,\n",
    "              epochs=epochs, \n",
    "              batch_size=batch_size, \n",
    "              validation_data=valid_data,\n",
    "              callbacks=callbacks,\n",
    "              verbose=0)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    polynomial_true_valid_fv_valid_split = parallel_fv_calculation_from_polynomial(y_valid, lambda_valid_input)\n",
    "    polynomial_pred_inet_valid_fv_valid_split = parallel_fv_calculation_from_polynomial(y_valid_pred, lambda_valid_input)\n",
    "    \n",
    "    polynomial_true_valid_fv_test_split = parallel_fv_calculation_from_polynomial(y_test, lambda_valid_input)\n",
    "    polynomial_pred_inet_valid_fv_test_split = parallel_fv_calculation_from_polynomial(y_test_pred, lambda_valid_input)\n",
    "\n",
    "    \n",
    "    polynomial_true_test_fv_valid_split = parallel_fv_calculation_from_polynomial(y_valid, lambda_test_input)\n",
    "    polynomial_pred_inet_test_fv_valid_split = parallel_fv_calculation_from_polynomial(y_valid_pred, lambda_test_input)\n",
    "    \n",
    "    polynomial_true_test_fv_test_split = parallel_fv_calculation_from_polynomial(y_test, lambda_test_input)\n",
    "    polynomial_pred_inet_test_fv_test_split = parallel_fv_calculation_from_polynomial(y_test_pred, lambda_test_input)\n",
    "    \n",
    "    \n",
    "    polynomial_test_fv = [polynomial_true_test_fv_valid_split, \n",
    "                            polynomial_pred_inet_test_fv_valid_split, \n",
    "                            polynomial_true_test_fv_test_split, \n",
    "                            polynomial_pred_inet_test_fv_test_split]\n",
    "    \n",
    "    polynomial_valid_fv = [polynomial_true_valid_fv_valid_split, \n",
    "                             polynomial_pred_inet_valid_fv_valid_split, \n",
    "                             polynomial_true_valid_fv_test_split, \n",
    "                             polynomial_pred_inet_valid_fv_test_split]\n",
    "    \n",
    "    polynomial_fv = [polynomial_valid_fv, polynomial_test_fv]\n",
    "    \n",
    "    \n",
    "    scores_truePoly_VS_inetPoly_test_fv_valid_split = evaluate_interpretation_net(y_valid, \n",
    "                                y_valid_pred, \n",
    "                                polynomial_true_test_fv_valid_split, \n",
    "                                polynomial_pred_inet_test_fv_valid_split)\n",
    "    \n",
    "    scores_truePoly_VS_inetPoly_test_fv_test_split = evaluate_interpretation_net(y_test, \n",
    "                                y_test_pred, \n",
    "                                polynomial_true_test_fv_test_split, \n",
    "                                polynomial_pred_inet_test_fv_test_split)\n",
    "    \n",
    "    \n",
    "\n",
    "    scores_truePoly_VS_inetPoly_valid_fv_valid_split = evaluate_interpretation_net(y_valid, \n",
    "                                y_valid_pred, \n",
    "                                polynomial_true_valid_fv_valid_split, \n",
    "                                polynomial_pred_inet_valid_fv_valid_split)\n",
    "\n",
    "    scores_truePoly_VS_inetPoly_valid_fv_test_split = evaluate_interpretation_net(y_test, \n",
    "                                y_test_pred, \n",
    "                                polynomial_true_valid_fv_test_split, \n",
    "                                polynomial_pred_inet_valid_fv_test_split)\n",
    "\n",
    "    \n",
    "    scores_truePoly_VS_inetPoly_test_fv = mergeDict(scores_truePoly_VS_inetPoly_test_fv_valid_split, scores_truePoly_VS_inetPoly_test_fv_test_split)\n",
    "    scores_truePoly_VS_inetPoly_valid_fv = mergeDict(scores_truePoly_VS_inetPoly_valid_fv_valid_split, scores_truePoly_VS_inetPoly_valid_fv_test_split)\n",
    "    \n",
    "    if evaluate_with_real_function:\n",
    "        scores_dict = [scores_truePoly_VS_inetPoly_test_fv, scores_truePoly_VS_inetPoly_valid_fv]\n",
    "    else:   \n",
    "        scores_predLambda_VS_inetPoly_test_fv_valid_split = evaluate_interpretation_net(y_valid, \n",
    "                                    y_valid_pred, \n",
    "                                    lambda_test_fv_valid_split, \n",
    "                                    polynomial_pred_inet_test_fv_valid_split)\n",
    "\n",
    "        scores_predLambda_VS_inetPoly_test_fv_test_split = evaluate_interpretation_net(y_test, \n",
    "                                    y_test_pred, \n",
    "                                    lambda_test_fv_test_split, \n",
    "                                    polynomial_pred_inet_test_fv_test_split)\n",
    "\n",
    "\n",
    "        scores_predLambda_VS_inetPoly_valid_fv_valid_split = evaluate_interpretation_net(y_valid, \n",
    "                                    y_valid_pred, \n",
    "                                    lambda_valid_fv_valid_split, \n",
    "                                    polynomial_pred_inet_valid_fv_valid_split)\n",
    "\n",
    "        scores_predLambda_VS_inetPoly_valid_fv_test_split = evaluate_interpretation_net(y_test, \n",
    "                                    y_test_pred, \n",
    "                                    lambda_valid_fv_test_split, \n",
    "                                    polynomial_pred_inet_valid_fv_test_split)\n",
    "\n",
    "        metrics = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'STD FV PRED', 'MEAN FV PRED']\n",
    "\n",
    "        scores_predLambda_VS_inetPoly_test_fv = mergeDict(scores_predLambda_VS_inetPoly_test_fv_valid_split, scores_predLambda_VS_inetPoly_test_fv_test_split)\n",
    "        scores_predLambda_VS_inetPoly_test_fv = {key: scores_predLambda_VS_inetPoly_test_fv[key] for key in metrics}\n",
    "        scores_truePoly_and_predLambda_VS_inetPoly_test_fv = mergeDict(scores_truePoly_VS_inetPoly_test_fv, scores_predLambda_VS_inetPoly_test_fv)\n",
    "        \n",
    "        scores_predLambda_VS_inetPoly_valid_fv = mergeDict(scores_predLambda_VS_inetPoly_valid_fv_valid_split, scores_predLambda_VS_inetPoly_valid_fv_test_split)\n",
    "        scores_predLambda_VS_inetPoly_valid_fv = {key: scores_predLambda_VS_inetPoly_valid_fv[key] for key in metrics}\n",
    "        scores_truePoly_and_predLambda_VS_inetPoly_valid_fv =mergeDict(scores_truePoly_VS_inetPoly_valid_fv, scores_predLambda_VS_inetPoly_valid_fv)\n",
    "\n",
    "        scores_dict = [scores_truePoly_and_predLambda_VS_inetPoly_test_fv, scores_truePoly_and_predLambda_VS_inetPoly_valid_fv]\n",
    "\n",
    "    if return_model:\n",
    "        return history.history, scores_dict, polynomial_fv, model         \n",
    "    else: \n",
    "        return history.history, scores_dict, polynomial_fv       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T08:51:45.602093Z",
     "start_time": "2020-11-25T08:51:14.748011Z"
    },
    "code_folding": [
     2,
     47,
     142
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\tloss             \t (min:    6.350, max:    8.783, cur:    6.350)\n",
      "mean_absolute_error_extended\n",
      "\tmean_absolute_error_extended \t (min:    1.577, max:    1.761, cur:    1.760)\n",
      "mean_absolute_error_tf_fv_lambda_extended\n",
      "\tmean_absolute_error_tf_fv_lambda_extended \t (min:    6.350, max:    8.783, cur:    6.350)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-4cc0548801bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                 \u001b[0mlambda_test_fv_train_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                 \u001b[0mcallback_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_losses_callback'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'early_stopping'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                 return_model=True)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-132-dc73b2331f2c>\u001b[0m in \u001b[0;36mtrain_nn_and_pred\u001b[0;34m(X_train, X_valid, X_test, y_train, y_valid, y_test, lambda_train_fv_valid_split, lambda_train_fv_test_split, lambda_train_fv_train_split, lambda_valid_fv_valid_split, lambda_valid_fv_test_split, lambda_valid_fv_train_split, lambda_test_fv_valid_split, lambda_test_fv_test_split, lambda_test_fv_train_split, callback_names, return_model)\u001b[0m\n\u001b[1;32m     62\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m               verbose=0)\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/livelossplot/inputs/generic_keras.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \"\"\"\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliveplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliveplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/livelossplot/plot_losses.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"\"\"Method will send logs to every output class\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/livelossplot/outputs/matplotlib_plot.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, logger)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmax_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_plots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[1;32m   1186\u001b[0m                        \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m                        gridspec_kw=gridspec_kw)\n\u001b[0m\u001b[1;32m   1188\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(self, nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[1;32m   1367\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sharex\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msharex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sharey\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msharey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m                 \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;31m# turn off redundant tick labeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1255\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Illegal argument(s) to subplot: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# _axes_class is set in the subplot_class_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36mupdate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumRows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumCols\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self.get_subplotspec().get_position(self.figure,\n\u001b[0;32m--> 136\u001b[0;31m                                                 return_all=True)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_first_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/matplotlib/gridspec.py\u001b[0m in \u001b[0;36mget_position\u001b[0;34m(self, figure, return_all)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mfig_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig_lefts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mfig_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig_rights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mfigbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_extents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_bottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_top\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mfrom_extents\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \"\"\"\n\u001b[1;32m    841\u001b[0m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/masterthesos/lib/python3.6/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, points, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m                              '\"[[x0, y0], [x1, y1]]\".')\n\u001b[1;32m    789\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;31m# it is helpful in some contexts to know if the bbox is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not multi_epoch_analysis and samples_list == None or True: \n",
    "    \n",
    "    results = train_nn_and_pred(X_train.values, \n",
    "                                X_valid.values, \n",
    "                                X_test.values, \n",
    "                                y_train.values, \n",
    "                                y_valid.values, \n",
    "                                y_test.values, \n",
    "                                lambda_train_fv_valid_split.values, \n",
    "                                lambda_train_fv_test_split.values, \n",
    "                                lambda_train_fv_train_split.values, \n",
    "                                lambda_valid_fv_valid_split.values, \n",
    "                                lambda_valid_fv_test_split.values, \n",
    "                                lambda_valid_fv_train_split.values, \n",
    "                                lambda_test_fv_valid_split.values, \n",
    "                                lambda_test_fv_test_split.values, \n",
    "                                lambda_test_fv_train_split.values, \n",
    "                                callback_names=['plot_losses_callback', 'early_stopping'], \n",
    "                                return_model=True)\n",
    "    \n",
    "    history = results[0]\n",
    "    \n",
    "    scores_complete = results[1]\n",
    "    scores_with_valid_fv = scores_complete[0]\n",
    "    scores_with_test_fv = scores_complete[1]\n",
    "    \n",
    "    polynomial_fv_complete = results[2]\n",
    "    polynomial_valid_fv = polynomial_fv_complete[0]\n",
    "    polynomial_test_fv = polynomial_fv_complete[1]\n",
    "    \n",
    "    model = results[3]\n",
    "    \n",
    "    x = PrettyTable()\n",
    "\n",
    "    x.field_names = [\"Error Name\", \"Valid Error Int\", \"Test Error Int\"]\n",
    "\n",
    "    for error, value in scores_with_test_fv.items():\n",
    "\n",
    "        x.add_row([error, value[0], value[1]])\n",
    "\n",
    "    print(x)    \n",
    "    \n",
    "elif multi_epoch_analysis and samples_list == None: \n",
    "    \n",
    "    results_list = Parallel(n_jobs=n_jobs, \n",
    "                            verbose=11, \n",
    "                            backend='loky')(delayed(train_nn_and_pred)(X_train.values, \n",
    "                                                                      X_valid.values, \n",
    "                                                                      X_test.values, \n",
    "                                                                      y_train.values, \n",
    "                                                                      y_valid.values, \n",
    "                                                                      y_test.values, \n",
    "                                                                      lambda_train_fv_valid_split.values, \n",
    "                                                                      lambda_train_fv_test_split.values, \n",
    "                                                                      lambda_train_fv_train_split.values, \n",
    "                                                                      lambda_valid_fv_valid_split.values, \n",
    "                                                                      lambda_valid_fv_test_split.values, \n",
    "                                                                      lambda_valid_fv_train_split.values, \n",
    "                                                                      lambda_test_fv_valid_split.values, \n",
    "                                                                      lambda_test_fv_test_split.values, \n",
    "                                                                      lambda_test_fv_train_split.values, \n",
    "                                                                      callback_names=['early_stopping']) for X_train, \n",
    "                                                                                                               X_valid, \n",
    "                                                                                                               X_test, \n",
    "                                                                                                               y_train, \n",
    "                                                                                                               y_valid, \n",
    "                                                                                                               y_test, \n",
    "                                                                                                               lambda_train_fv_valid_split, \n",
    "                                                                                                               lambda_train_fv_test_split, \n",
    "                                                                                                               lambda_train_fv_train_split,                                            \n",
    "                                                                                                               lambda_valid_fv_valid_split, \n",
    "                                                                                                               lambda_valid_fv_test_split, \n",
    "                                                                                                               lambda_valid_fv_train_split, \n",
    "                                                                                                               lambda_test_fv_valid_split, \n",
    "                                                                                                               lambda_test_fv_test_split, \n",
    "                                                                                                               lambda_test_fv_train_split in zip(X_train_list, \n",
    "                                                                                                                                                 X_valid_list, \n",
    "                                                                                                                                                 X_test_list, \n",
    "                                                                                                                                                 y_train_list, \n",
    "                                                                                                                                                 y_valid_list, \n",
    "                                                                                                                                                 y_test_list, \n",
    "                                                                                                                                                 lambda_train_fv_valid_split_list, \n",
    "                                                                                                                                                 lambda_train_fv_test_split_list, \n",
    "                                                                                                                                                 lambda_train_fv_train_split_list,                                                                                                                                                  \n",
    "                                                                                                                                                 lambda_valid_fv_valid_split_list, \n",
    "                                                                                                                                                 lambda_valid_fv_test_split_list, \n",
    "                                                                                                                                                 lambda_valid_fv_train_split_list, \n",
    "                                                                                                                                                 lambda_test_fv_valid_split_list, \n",
    "                                                                                                                                                 lambda_test_fv_test_split_list, \n",
    "                                                                                                                                                 lambda_test_fv_train_split_list))      \n",
    "\n",
    "    history_list = [result[0] for result in results_list]\n",
    "    \n",
    "    scores_complete_list = [result[1] for result in results_list]\n",
    "    scores_with_valid_fv_list = [scores[0] for scores in scores_complete_list]\n",
    "    scores_with_test_fv_list = [scores[1] for scores in scores_complete_list]\n",
    "    \n",
    "    polynomial_fv_complete_list = [result[2] for result in results_list]\n",
    "    polynomial_valid_fv_list = [polynomial[0] for polynomial in polynomial_fv_complete_list]\n",
    "    polynomial_test_fv_list = [polynomial[1] for polynomial in polynomial_fv_complete_list]\n",
    "\n",
    "\n",
    "    for i, history in enumerate(history_list):  \n",
    "        index = (i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1\n",
    "\n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir('./data/results/' + interpretation_network_string + filename + '/')\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        plt.plot(history[list(history.keys())[1]])\n",
    "        if consider_labels_training or evaluate_with_real_function:\n",
    "            plt.plot(history[list(history.keys())[len(history.keys())//2+1]])\n",
    "        plt.title('model ' + list(history.keys())[len(history.keys())//2+1])\n",
    "        plt.ylabel('metric')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'valid'], loc='upper left')\n",
    "        plt.savefig('./data/results/' + interpretation_network_string + filename + '/' + list(history.keys())[len(history.keys())//2+1] +  '_' + interpretation_network_string + filename + '_epoch_' + str(index).zfill(3) + '.png')\n",
    "        plt.clf()\n",
    "        \n",
    "        plt.plot(history['loss'])\n",
    "        if consider_labels_training or evaluate_with_real_function:\n",
    "            plt.plot(history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'valid'], loc='upper left')\n",
    "        plt.savefig('./data/results/' + interpretation_network_string + filename + '/loss_' + interpretation_network_string + filename + '_epoch_' + str(index).zfill(3) + '.png')    \n",
    "        if i < len(history_list)-1:\n",
    "            plt.clf()\n",
    "    path = './data/results/' + interpretation_network_string + filename + '/history_' + interpretation_network_string + filename + '.pkl'\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(history_list, f, protocol=2)   \n",
    "        \n",
    "    path = './data/results/' + interpretation_network_string + filename + '/history_' + interpretation_network_string + filename + '.pkl'\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(scores_with_test_fv_list, f, protocol=2)   \n",
    "        \n",
    "elif not multi_epoch_analysis and  samples_list != None:\n",
    "    \n",
    "    results_list = Parallel(n_jobs=n_jobs, verbose=11, backend='loky')(delayed(train_nn_and_pred)(X_train.sample(n=samples, random_state=RANDOM_SEED).values, \n",
    "                                                                                                  X_valid.values, \n",
    "                                                                                                  X_test.values, \n",
    "                                                                                                  y_train.sample(n=samples, random_state=RANDOM_SEED).values, \n",
    "                                                                                                  y_valid.values, \n",
    "                                                                                                  y_test.values, \n",
    "                                                                                                  lambda_train_fv_valid_split.values, \n",
    "                                                                                                  lambda_train_fv_test_split.values, \n",
    "                                                                                                  lambda_train_fv_train_split.values, \n",
    "                                                                                                  lambda_valid_fv_valid_split.values, \n",
    "                                                                                                  lambda_valid_fv_test_split.values, \n",
    "                                                                                                  lambda_valid_fv_train_split.values, \n",
    "                                                                                                  lambda_test_fv_valid_split.values, \n",
    "                                                                                                  lambda_test_fv_test_split.values, \n",
    "                                                                                                  lambda_test_fv_train_split.values, \n",
    "                                                                                                  callback_names=['early_stopping']) for samples in samples_list)     \n",
    "    \n",
    "    history_list = [result[0] for result in results_list]\n",
    "     \n",
    "    scores_complete_list = [result[1] for result in results_list]\n",
    "    scores_with_valid_fv_list = [scores[0] for scores in scores_complete_list]\n",
    "    scores_with_test_fv_list = [scores[1] for scores in scores_complete_list]\n",
    "    \n",
    "    polynomial_fv_complete_list = [result[2] for result in results_list]\n",
    "    polynomial_valid_fv_list = [polynomial[0] for polynomial in polynomial_fv_complete_list]\n",
    "    polynomial_test_fv_list = [polynomial[1] for polynomial in polynomial_fv_complete_list]\n",
    "\n",
    "    for i, history in enumerate(history_list):       \n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir('./data/results/' + interpretation_network_string + filename + '/')\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        plt.plot(history[list(history.keys())[len(history.keys())//2+1]])\n",
    "        if consider_labels_training or evaluate_with_real_function:\n",
    "            plt.plot(history[list(history.keys())[1]])\n",
    "        plt.title('model ' + list(history.keys())[len(history.keys())//2+1])\n",
    "        plt.ylabel('metric')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'valid'], loc='upper left')\n",
    "        plt.savefig('./data/results/' + interpretation_network_string + filename + '/' + list(history.keys())[len(history.keys())//2+1] +  '_' + interpretation_network_string + filename + '_epoch_' + str(samples_list[i]).zfill(5) + '.png')\n",
    "        plt.clf()\n",
    "        \n",
    "        plt.plot(history['loss'])\n",
    "        if consider_labels_training or evaluate_with_real_function:\n",
    "            plt.plot(history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'valid'], loc='upper left')\n",
    "        plt.savefig('./data/results/' + interpretation_network_string + filename + '/loss_' + interpretation_network_string + filename + '_epoch_' + str(samples_list[i]).zfill(5) + '.png')    \n",
    "        if i < len(history_list)-1:\n",
    "            plt.clf()\n",
    "    path = './data/results/' + interpretation_network_string + filename + '/history_' + interpretation_network_string + filename + '.pkl'\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(history_list, f, protocol=2)   \n",
    "        \n",
    "    path = './data/results/' + interpretation_network_string + filename + '/history_' + interpretation_network_string + filename + '.pkl'\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(scores_with_test_fv_list, f, protocol=2)     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Interpretation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T11:51:49.592579Z",
     "start_time": "2020-11-24T11:51:15.632Z"
    }
   },
   "outputs": [],
   "source": [
    "printer = None\n",
    "if multi_epoch_analysis or samples_list != None:\n",
    "    printer = scores_with_valid_fv_list[-1]\n",
    "else:\n",
    "    printer = scores_with_valid_fv\n",
    "printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T11:51:49.594867Z",
     "start_time": "2020-11-24T11:51:15.755Z"
    }
   },
   "outputs": [],
   "source": [
    "printer = None\n",
    "if multi_epoch_analysis or samples_list != None:\n",
    "    printer = scores_with_test_fv_list[-1]\n",
    "else:\n",
    "    printer = scores_with_test_fv\n",
    "printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T11:51:49.597057Z",
     "start_time": "2020-11-24T11:51:16.016Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history[list(history.keys())[len(history.keys())//2+1]])\n",
    "if consider_labels_training or evaluate_with_real_function:\n",
    "    plt.plot(history[list(history.keys())[1]])\n",
    "plt.title('model ' + list(history.keys())[len(history.keys())//2+1])\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig('./data/results/' + interpretation_network_string + filename + '/metric_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T11:51:49.599183Z",
     "start_time": "2020-11-24T11:51:16.170Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "if consider_labels_training or evaluate_with_real_function:\n",
    "    plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig('./data/results/' + interpretation_network_string + filename + '/loss_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Epoch/Sampes Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T11:51:49.601297Z",
     "start_time": "2020-11-24T11:51:16.520Z"
    }
   },
   "outputs": [],
   "source": [
    "if multi_epoch_analysis and samples_list == None: \n",
    "    plot_history_loss = []\n",
    "    plot_history_metric = []\n",
    "    plot_history_val_loss = []\n",
    "    plot_history_val_metric = []\n",
    "        \n",
    "    for history in history_list:\n",
    "        plot_history_loss.append(history['loss'][-1])\n",
    "        plot_history_metric.append(history[list(history.keys())[1]][-1])\n",
    "\n",
    "        if consider_labels_training or evaluate_with_real_function:\n",
    "            plot_history_val_loss.append(history['val_loss'][-1])\n",
    "            plot_history_val_metric.append(history[list(history.keys())[len(history.keys())//2+1]][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.503115Z",
     "start_time": "2020-11-24T09:14:11.913Z"
    }
   },
   "outputs": [],
   "source": [
    "if multi_epoch_analysis and samples_list == None: \n",
    "    plot_history_loss_df = pd.DataFrame(data=plot_history_loss, index=[(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in range(len(plot_history_loss))])\n",
    "    if consider_labels_training or evaluate_with_real_function:\n",
    "        plot_history_val_loss_df = pd.DataFrame(data=plot_history_val_loss, index=[(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in range(len(plot_history_val_loss))])\n",
    "    \n",
    "    plt.plot(plot_history_loss_df)\n",
    "    if consider_labels_training or evaluate_with_real_function:\n",
    "        plt.plot(plot_history_val_loss_df)\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + interpretation_network_string + filename + '/loss_' + interpretation_network_string + filename + '_total.eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.504600Z",
     "start_time": "2020-11-24T09:14:12.108Z"
    }
   },
   "outputs": [],
   "source": [
    "if multi_epoch_analysis and samples_list == None: \n",
    "    plot_history_metric_df = pd.DataFrame(data=plot_history_metric, index=[(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in range(len(plot_history_metric))])\n",
    "    if consider_labels_training or evaluate_with_real_function:\n",
    "        plot_history_val_metric_df = pd.DataFrame(data=plot_history_val_metric, index=[(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in range(len(plot_history_val_metric))])\n",
    "    \n",
    "    plt.plot(plot_history_metric_df)\n",
    "    if consider_labels_training or evaluate_with_real_function:\n",
    "        plt.plot(plot_history_val_metric_df)\n",
    "    plt.title('Metric')\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + interpretation_network_string + filename + '/metric_' + interpretation_network_string + filename + '_total.eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure Interpretation-Net Socres for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.506512Z",
     "start_time": "2020-11-24T09:14:12.470Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_coeff_keys = ['MAE', 'RMSE', 'MAPE', 'Accuracy', 'Accuracy Multilabel']\n",
    "metrics_fv_keys = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV']\n",
    "\n",
    "new_row_identifiers_coeff = ['MAE', 'RMSE', 'MAPE', 'ACC', 'ACC MULT']\n",
    "new_row_identifiers_fv = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV']\n",
    "\n",
    "if multi_epoch_analysis and evaluate_with_real_function:\n",
    "\n",
    "    scores_coeff_valid = []\n",
    "    scores_coeff_test = []\n",
    "\n",
    "    scores_valid_list = []\n",
    "    scores_test_list = []\n",
    "    stds_list = []    \n",
    "    means_list = []    \n",
    "    for i, scores_int in enumerate(scores_with_test_fv_list):\n",
    "        index = (i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1\n",
    "\n",
    "        if i == 0:\n",
    "            scores_coeff_valid = pd.DataFrame([scores_int[score][0] for score in metrics_coeff_keys], columns=['VALID E' + str(index)], index=new_row_identifiers_coeff)\n",
    "            scores_coeff_test = pd.DataFrame([scores_int[score][1] for score in metrics_coeff_keys], columns=['TEST E' + str(index)], index=new_row_identifiers_coeff)\n",
    "            \n",
    "            scores_valid_list = pd.DataFrame([scores_int[score][0] for score in metrics_fv_keys], columns=['VALID PRED E' + str(index)], index=new_row_identifiers_fv)\n",
    "            scores_test_list = pd.DataFrame([scores_int[score][1] for score in metrics_fv_keys], columns=['TEST PRED E' + str(index)], index=new_row_identifiers_fv)\n",
    "            \n",
    "            stds_list = pd.DataFrame(scores_int['STD FV PRED'], columns=['E' + str(index)], index=['STD FUNC VALID PRED', 'STD FUNC TEST PRED'])\n",
    "\n",
    "            means_list = pd.DataFrame(scores_int['MEAN FV PRED'], columns=['E' + str(index)], index=['MEAN FUNC VALID PRED', 'MEAN FUNC TEST PRED'])\n",
    "  \n",
    "        else:\n",
    "            scores_coeff_valid_new = pd.DataFrame([scores_int[score][0] for score in metrics_coeff_keys], columns=['VALID E' + str(index)], index=new_row_identifiers_coeff)\n",
    "            scores_coeff_test_new = pd.DataFrame([scores_int[score][1] for score in metrics_coeff_keys], columns=['TEST E' + str(index)], index=new_row_identifiers_coeff)\n",
    "            \n",
    "            scores_valid_list_new = pd.DataFrame([scores_int[score][0] for score in metrics_fv_keys], columns=['VALID PRED E' + str(index)], index=new_row_identifiers_fv)\n",
    "            scores_test_list_new = pd.DataFrame([scores_int[score][1] for score in metrics_fv_keys], columns=['TEST PRED E' + str(index)], index=new_row_identifiers_fv)\n",
    "                       \n",
    "            stds_list_new = pd.DataFrame(scores_int['STD FV PRED'], columns=['E' + str(index)], index=['STD FUNC VALID PRED', 'STD FUNC TEST PRED'])\n",
    "            \n",
    "            means_list_new = pd.DataFrame(scores_int['MEAN FV PRED'], columns=['E' + str(index)], index=['MEAN FUNC VALID PRED', 'MEAN FUNC TEST PRED'])\n",
    "            \n",
    "            \n",
    "            scores_coeff_valid = pd.concat([scores_coeff_valid, scores_coeff_valid_new],axis=1)  \n",
    "            scores_coeff_test = pd.concat([scores_coeff_test, scores_coeff_test_new],axis=1)  \n",
    "            \n",
    "            scores_valid_list = pd.concat([scores_valid_list, scores_valid_list_new],axis=1)  \n",
    "            scores_test_list = pd.concat([scores_test_list, scores_test_list_new],axis=1)  \n",
    "\n",
    "            stds_list = pd.concat([stds_list, stds_list_new],axis=1)\n",
    "            \n",
    "            means_list = pd.concat([means_list, means_list_new],axis=1)  \n",
    "\n",
    "\n",
    "elif multi_epoch_analysis and not evaluate_with_real_function:\n",
    "\n",
    "    scores_coeff_valid = []\n",
    "    scores_coeff_test = []\n",
    "\n",
    "\n",
    "    scores_valid_list = []\n",
    "    scores_test_list = []\n",
    "    stds_list = []    \n",
    "    means_list = []    \n",
    "    for i, scores_int in enumerate(scores_with_test_fv_list):\n",
    "        index = (i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1\n",
    "\n",
    "        if i == 0:\n",
    "            scores_coeff_valid = pd.DataFrame([scores_int[score][0] for score in metrics_coeff_keys], columns=['VALID E' + str(index)], index=new_row_identifiers_coeff)\n",
    "            scores_coeff_test = pd.DataFrame([scores_int[score][1] for score in metrics_coeff_keys], columns=['TEST E' + str(index)], index=new_row_identifiers_coeff)\n",
    "            \n",
    "            scores_valid_list = pd.DataFrame([[scores_int[score][2], scores_int[score][0]] for score in metrics_fv_keys], columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index)], index=new_row_identifiers_fv)\n",
    "            scores_test_list = pd.DataFrame([[scores_int[score][3], scores_int[score][1]] for score in metrics_fv_keys], columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index)], index=new_row_identifiers_fv)\n",
    "            \n",
    "            stds_list = pd.DataFrame(scores_int['STD FV PRED'], columns=['E' + str(index)], index=['STD FUNC VALID PRED', 'STD FUNC TEST PRED', 'std_function_valid_pred_lambda_fv', 'std_function_test_pred_lambda_fv'])\n",
    "            \n",
    "            means_list = pd.DataFrame(scores_int['MEAN FV PRED'], columns=['E' + str(index)], index=['MEAN FUNC VALID PRED', 'MEAN FUNC TEST PRED', 'mean_function_valid_pred_lambda_fv', 'mean_function_test_pred_lambda_fv'])\n",
    "        else:\n",
    "            scores_coeff_valid_new = pd.DataFrame([scores_int[score][0] for score in metrics_coeff_keys], columns=['VALID E' + str(index)], index=new_row_identifiers_coeff)\n",
    "            scores_coeff_test_new = pd.DataFrame([scores_int[score][1] for score in metrics_coeff_keys], columns=['TEST E' + str(index)], index=new_row_identifiers_coeff)\n",
    "            \n",
    "            scores_valid_list_new = pd.DataFrame([[scores_int[score][2], scores_int[score][0]] for score in metrics_fv_keys], columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index)], index=new_row_identifiers_fv)\n",
    "            scores_test_list_new = pd.DataFrame([[scores_int[score][3], scores_int[score][1]] for score in metrics_fv_keys], columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index)], index=new_row_identifiers_fv)\n",
    "                       \n",
    "            stds_list_new = pd.DataFrame(scores_int['STD FV PRED'], columns=['E' + str(index)], index=['STD FUNC VALID PRED', 'STD FUNC TEST PRED', 'std_function_valid_pred_lambda_fv', 'std_function_test_pred_lambda_fv'])\n",
    "            \n",
    "            means_list_new = pd.DataFrame(scores_int['MEAN FV PRED'], columns=['E' + str(index)], index=['MEAN FUNC VALID PRED', 'MEAN FUNC TEST PRED', 'mean_function_valid_pred_lambda_fv', 'means_function_test_pred_lambda_fv'])\n",
    "            \n",
    "            \n",
    "            scores_coeff_valid = pd.concat([scores_coeff_valid, scores_coeff_valid_new],axis=1)  \n",
    "            scores_coeff_test = pd.concat([scores_coeff_test, scores_coeff_test_new],axis=1)  \n",
    "            \n",
    "            scores_valid_list = pd.concat([scores_valid_list, scores_valid_list_new],axis=1)  \n",
    "            scores_test_list = pd.concat([scores_test_list, scores_test_list_new],axis=1)  \n",
    "\n",
    "            stds_list = pd.concat([stds_list, stds_list_new],axis=1)  \n",
    "            \n",
    "            means_list = pd.concat([means_list, means_list_new],axis=1)  \n",
    "    \n",
    "elif not multi_epoch_analysis and samples_list != None and evaluate_with_real_function:\n",
    "    scores_coeff_valid = []\n",
    "    scores_coeff_test = []\n",
    "\n",
    "\n",
    "    scores_valid_list = []\n",
    "    scores_test_list = []\n",
    "    stds_list = []    \n",
    "    means_list = []    \n",
    "\n",
    "    for index, scores_int in enumerate(scores_with_test_fv_list):\n",
    "        index = samples_list[index]\n",
    "        \n",
    "        if index == samples_list[0]:\n",
    "            scores_coeff_valid = pd.DataFrame([scores_int[score][0] for score in metrics_coeff_keys], columns=['VALID S' + str(index)], index=new_row_identifiers_coeff)\n",
    "            scores_coeff_test = pd.DataFrame([scores_int[score][1] for score in metrics_coeff_keys], columns=['TEST S' + str(index)], index=new_row_identifiers_coeff)\n",
    "            \n",
    "            scores_valid_list = pd.DataFrame([scores_int[score][0] for score in metrics_fv_keys], columns=['VALID PRED S' + str(index)], index=new_row_identifiers_fv)\n",
    "            scores_test_list = pd.DataFrame([scores_int[score][1] for score in metrics_fv_keys], columns=['TEST PRED S' + str(index)], index=new_row_identifiers_fv)\n",
    "            \n",
    "            stds_list = pd.DataFrame(scores_int['STD FV PRED'], columns=['S' + str(index)], index=['STD FUNC VALID PRED', 'STD FUNC TEST PRED'])\n",
    "            \n",
    "            means_list = pd.DataFrame(scores_int['MEAN FV PRED'], columns=['S' + str(index)], index=['MEAN FUNC VALID PRED', 'MEAN FUNC TEST PRED'])\n",
    "        else:\n",
    "            scores_coeff_valid_new = pd.DataFrame([scores_int[score][0] for score in metrics_coeff_keys], columns=['VALID S' + str(index)], index=new_row_identifiers_coeff)\n",
    "            scores_coeff_test_new = pd.DataFrame([scores_int[score][1] for score in metrics_coeff_keys], columns=['TEST S' + str(index)], index=new_row_identifiers_coeff)\n",
    "            \n",
    "            scores_valid_list_new = pd.DataFrame([scores_int[score][0] for score in metrics_fv_keys], columns=['VALID PRED S' + str(index)], index=new_row_identifiers_fv)\n",
    "            scores_test_list_new = pd.DataFrame([scores_int[score][1] for score in metrics_fv_keys], columns=['TEST PRED S' + str(index)], index=new_row_identifiers_fv)\n",
    "                       \n",
    "            stds_list_new = pd.DataFrame(scores_int['STD FV PRED'], columns=['S' + str(index)], index=['STD FUNC VALID PRED', 'STD FUNC TEST PRED'])\n",
    "            \n",
    "            means_list_new = pd.DataFrame(scores_int['MEAN FV PRED'], columns=['S' + str(index)], index=['MEAN FUNC VALID PRED', 'MEAN FUNC TEST PRED'])\n",
    "\n",
    "            \n",
    "            scores_coeff_valid = pd.concat([scores_coeff_valid, scores_coeff_valid_new],axis=1)  \n",
    "            scores_coeff_test = pd.concat([scores_coeff_test, scores_coeff_test_new],axis=1)  \n",
    "            \n",
    "            scores_valid_list = pd.concat([scores_valid_list, scores_valid_list_new],axis=1)  \n",
    "            scores_test_list = pd.concat([scores_test_list, scores_test_list_new],axis=1)  \n",
    "\n",
    "            stds_list = pd.concat([stds_list, stds_list_new],axis=1) \n",
    "            \n",
    "            means_list = pd.concat([means_list, means_list_new],axis=1)     \n",
    "            \n",
    "elif not multi_epoch_analysis and  samples_list != None and not evaluate_with_real_function:\n",
    "\n",
    "    scores_coeff_valid = []\n",
    "    scores_coeff_test = []\n",
    "\n",
    "\n",
    "    scores_valid_list = []\n",
    "    scores_test_list = []\n",
    "    stds_list = []    \n",
    "    means_list = []    \n",
    "    for index, scores_int in enumerate(scores_with_test_fv_list):\n",
    "        index = samples_list[index]\n",
    "\n",
    "        if index == samples_list[0]:\n",
    "            scores_coeff_valid = pd.DataFrame([scores_int[score][0] for score in metrics_coeff_keys], columns=['VALID S' + str(index)], index=new_row_identifiers_coeff)\n",
    "            scores_coeff_test = pd.DataFrame([scores_int[score][1] for score in metrics_coeff_keys], columns=['TEST S' + str(index)], index=new_row_identifiers_coeff)\n",
    "            \n",
    "            scores_valid_list = pd.DataFrame([[scores_int[score][2], scores_int[score][0]] for score in metrics_fv_keys], columns=['VALID PRED S' + str(index), 'VALID POLY S' + str(index)], index=new_row_identifiers_fv)\n",
    "            scores_test_list = pd.DataFrame([[scores_int[score][3], scores_int[score][1]] for score in metrics_fv_keys], columns=['TEST PRED S' + str(index), 'TEST POLY S' + str(index)], index=new_row_identifiers_fv)\n",
    "            \n",
    "            stds_list = pd.DataFrame(scores_int['STD FV PRED'], columns=['S' + str(index)], index=['STD FUNC VALID PRED', 'STD FUNC TEST PRED', 'std_function_valid_pred_lambda_fv', 'std_function_test_pred_lambda_fv'])\n",
    "            \n",
    "            means_list = pd.DataFrame(scores_int['MEAN FV PRED'], columns=['S' + str(index)], index=['MEAN FUNC VALID PRED', 'MEAN FUNC TEST PRED', 'mean_function_valid_pred_lambda_fv', 'mean_function_test_pred_lambda_fv'])\n",
    "\n",
    "        else:\n",
    "            scores_coeff_valid_new = pd.DataFrame([scores_int[score][0] for score in metrics_coeff_keys], columns=['VALID S' + str(index)], index=['MAE', 'RMSE', 'MAPE', 'ACC', 'ACC MULT'])\n",
    "            scores_coeff_test_new = pd.DataFrame([scores_int[score][1] for score in metrics_coeff_keys], columns=['TEST S' + str(index)], index=['MAE', 'RMSE', 'MAPE', 'ACC', 'ACC MULT'])\n",
    "            \n",
    "            scores_valid_list_new = pd.DataFrame([[scores_int[score][2], scores_int[score][0]] for score in metrics_fv_keys], columns=['VALID PRED S' + str(index), 'VALID POLY S' + str(index)], index=new_row_identifiers_fv)\n",
    "            scores_test_list_new = pd.DataFrame([[scores_int[score][3], scores_int[score][1]] for score in metrics_fv_keys], columns=['TEST PRED S' + str(index), 'TEST POLY S' + str(index)], index=new_row_identifiers_fv)\n",
    "                       \n",
    "            stds_list_new = pd.DataFrame(scores_int['STD FV PRED'], columns=['S' + str(index)], index=['STD FUNC VALID PRED', 'STD FUNC TEST PRED', 'std_function_valid_pred_lambda_fv', 'std_function_test_pred_lambda_fv'])\n",
    "\n",
    "            means_list_new = pd.DataFrame(scores_int['MEAN FV PRED'], columns=['S' + str(index)], index=['MEAN FUNC VALID PRED', 'MEAN FUNC TEST PRED', 'mean_function_valid_pred_lambda_fv', 'mean_function_test_pred_lambda_fv'])\n",
    "            \n",
    "            \n",
    "            scores_coeff_valid = pd.concat([scores_coeff_valid, scores_coeff_valid_new],axis=1)  \n",
    "            scores_coeff_test = pd.concat([scores_coeff_test, scores_coeff_test_new],axis=1)  \n",
    "            \n",
    "            scores_valid_list = pd.concat([scores_valid_list, scores_valid_list_new],axis=1)  \n",
    "            scores_test_list = pd.concat([scores_test_list, scores_test_list_new],axis=1)  \n",
    "\n",
    "            stds_list = pd.concat([stds_list, stds_list_new],axis=1)      \n",
    "            \n",
    "            means_list = pd.concat([means_list, means_list_new],axis=1)    \n",
    "            \n",
    "if multi_epoch_analysis:            \n",
    "    path_scores_valid_coef_int = './data/results/' + interpretation_network_string + filename + '/scores_valid_multiepoch_coef_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "    path_scores_test_coef_int = './data/results/' + interpretation_network_string + filename + '/scores_test_multiepoch_coef_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "\n",
    "    path_scores_valid_int = './data/results/' + interpretation_network_string + filename + '/scores_valid_multiepoch_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "    path_scores_test_int = './data/results/' + interpretation_network_string + filename + '/scores_test_multiepoch_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "\n",
    "    path_stds_int = './data/results/' + interpretation_network_string + filename + '/stds_multiepoch_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "\n",
    "    path_means_int = './data/results/' + interpretation_network_string + filename + '/means_multiepoch_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "\n",
    "\n",
    "    scores_coeff_valid.to_csv(path_scores_valid_coef_int, sep=',')\n",
    "    scores_coeff_test.to_csv(path_scores_test_coef_int, sep=',') \n",
    "\n",
    "    scores_valid_list.to_csv(path_scores_valid_int, sep=',')\n",
    "    scores_test_list.to_csv(path_scores_test_int, sep=',')\n",
    "\n",
    "    stds_list.to_csv(path_stds_int, sep=',')  \n",
    "    means_list.to_csv(path_means_int, sep=',')  \n",
    "elif samples_list != None:            \n",
    "    path_scores_valid_coef_int = './data/results/' + interpretation_network_string + filename + '/scores_valid_samples_coef_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "    path_scores_test_coef_int = './data/results/' + interpretation_network_string + filename + '/scores_test_samples_coef_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "\n",
    "    path_scores_valid_int = './data/results/' + interpretation_network_string + filename + '/scores_samples_valid_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "    path_scores_test_int = './data/results/' + interpretation_network_string + filename + '/scores_samples_test_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "\n",
    "    path_stds_int = './data/results/' + interpretation_network_string + filename + '/stds_samples_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "\n",
    "    path_means_int = './data/results/' + interpretation_network_string + filename + '/means_samples_' + interpretation_network_string + filename + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "\n",
    "\n",
    "    scores_coeff_valid.to_csv(path_scores_valid_coef_int, sep=',')\n",
    "    scores_coeff_test.to_csv(path_scores_test_coef_int, sep=',') \n",
    "\n",
    "    scores_valid_list.to_csv(path_scores_valid_int, sep=',')\n",
    "    scores_test_list.to_csv(path_scores_test_int, sep=',')\n",
    "\n",
    "    stds_list.to_csv(path_stds_int, sep=',')  \n",
    "    means_list.to_csv(path_means_int, sep=',')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Lambda Scores for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.508324Z",
     "start_time": "2020-11-24T09:14:12.849Z"
    }
   },
   "outputs": [],
   "source": [
    "path_scores_valid_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_valid_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "path_scores_test_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_test_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "path_stds_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/stds_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "path_means_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/means_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "\n",
    "\n",
    "df_mean_scores_valid_lambda = pd.read_csv(path_scores_valid_lambda, sep=',', index_col=0)\n",
    "df_mean_scores_test_lambda = pd.read_csv(path_scores_test_lambda, sep=',', index_col=0)\n",
    "df_stds_lambda = pd.read_csv(path_stds_lambda, sep=',', index_col=0)\n",
    "df_means_lambda = pd.read_csv(path_means_lambda, sep=',', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.510218Z",
     "start_time": "2020-11-24T09:14:13.029Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mean_scores_test_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.512799Z",
     "start_time": "2020-11-24T09:14:13.214Z"
    }
   },
   "outputs": [],
   "source": [
    "df_stds_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.514363Z",
     "start_time": "2020-11-24T09:14:13.403Z"
    }
   },
   "outputs": [],
   "source": [
    "df_means_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Columns to Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.516044Z",
     "start_time": "2020-11-24T09:14:13.792Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if multi_epoch_analysis:\n",
    "    'Reduce the dfs to equal keys for plotting comparison'\n",
    "    plot_cols = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV']\n",
    "    scores_lambda = df_mean_scores_test_lambda.loc[plot_cols]\n",
    "    scores_int = scores_test_list.loc[plot_cols]    \n",
    "elif samples_list != None:\n",
    "    'Reduce the dfs to equal keys for plotting comparison'\n",
    "    plot_cols = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV']\n",
    "    scores_int = scores_test_list.loc[plot_cols] \n",
    "    scores_lambda = df_mean_scores_test_lambda.loc[plot_cols].iloc[:,-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.517482Z",
     "start_time": "2020-11-24T09:14:14.076Z"
    }
   },
   "outputs": [],
   "source": [
    "print_head = None\n",
    "if multi_epoch_analysis or samples_list != None:\n",
    "    print_head = scores_int\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.519061Z",
     "start_time": "2020-11-24T09:14:14.263Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_test_fv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.520660Z",
     "start_time": "2020-11-24T09:14:14.452Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_valid_fv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Comparison Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.522429Z",
     "start_time": "2020-11-24T09:14:14.814Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate plot TEST PRED\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir('./data/plotting/' + interpretation_network_string + filename + '/')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "if multi_epoch_analysis and evaluate_with_real_function:\n",
    "    #Plot Polynom, lamdba net, and Interpration net\n",
    "    length_plt = len(plot_cols)\n",
    "    subplot_number = 1\n",
    "    plt.figure(figsize=(12*2, 7*length_plt/2))\n",
    "\n",
    "    #For plotting of the int net, only second value of the tuple can be used for the comparison. Thus, always\n",
    "    #extract the second value from the scores_int df\n",
    "    for index in scores_lambda.index:\n",
    "\n",
    "        vals_int_real = scores_int.loc[index].values\n",
    "        vals_lambda_real = scores_lambda.loc[index].values[::4]\n",
    "        vals_lambda_lstsq = scores_lambda.loc[index].values[3::4]\n",
    "\n",
    "        ax = plt.subplot(length_plt//2+1, 2, subplot_number)\n",
    "        ax.set_title(index, fontsize=20)\n",
    "        ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_int_real, label='Error I-Net Poly vs. Real Poly')\n",
    "        ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_lambda_real, label='Error Lambda Model Preds vs. Real Poly')\n",
    "        ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_lambda_lstsq, label='Error LSTSQ Preds vs. Real Poly')\n",
    "        ax.legend(loc=\"bottom right\", fontsize=14)\n",
    "        ax.set_xlim([0, epochs_lambda])\n",
    "        \n",
    "        for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            label.set_fontsize(14)   \n",
    "            \n",
    "        #ax.set_xticks(np.arange(0, epochs, step=1))\n",
    "        subplot_number += 1\n",
    "    \n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file = 'multi_epoch_REAL_' + interpretation_network_string+  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "\n",
    "    path = location + folder + file\n",
    "    \n",
    "    plt.savefig(path, format='eps')\n",
    "    plt.show()\n",
    "    \n",
    "elif multi_epoch_analysis and not evaluate_with_real_function:\n",
    "    #Plot Polynom, lamdba net, and Interpration net\n",
    "    length_plt = len(plot_cols)\n",
    "    subplot_number = 1\n",
    "    plt.figure(figsize=(12*2, 7*length_plt/2))\n",
    "\n",
    "    #For plotting of the int net, only second value of the tuple can be used for the comparison. Thus, always\n",
    "    #extract the second value from the scores_int df\n",
    "    for index in scores_lambda.index:\n",
    "\n",
    "        vals_int_poly = scores_int.loc[index].values[1::2]\n",
    "        vals_int_preds = scores_int.loc[index].values[::2]\n",
    "        vals_lambda_poly_pred = scores_lambda.loc[index].values[2::4]\n",
    "\n",
    "        ax = plt.subplot(length_plt//2+1, 2, subplot_number)\n",
    "        ax.set_title(index, fontsize=20)\n",
    "        ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_int_poly, label='Error I-Net Poly vs Lambda Poly')\n",
    "        ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_int_preds, label='Error I-Net Poly vs Lambda Model Preds')\n",
    "        ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_lambda_poly_pred, label='Error Lambda Poly vs Lambda Model Preds')\n",
    "        ax.legend(loc=\"bottom right\", fontsize=14)\n",
    "        ax.set_xlim([0, epochs_lambda])\n",
    "        \n",
    "        \n",
    "        for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            label.set_fontsize(14)   \n",
    "                    \n",
    "        #ax.set_xticks(np.arange(0, epochs, step=1))\n",
    "        subplot_number += 1\n",
    "\n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file = 'multi_epoch_MODEL_' + interpretation_network_string +  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "\n",
    "    path = location + folder + file\n",
    "    \n",
    "    plt.savefig(path, format='eps')\n",
    "    plt.show()\n",
    "\n",
    "elif samples_list != None and evaluate_with_real_function:\n",
    "    length_plt = len(plot_cols)\n",
    "    subplot_number = 1\n",
    "    plt.figure(figsize=(12*2, 7*length_plt/2))\n",
    "\n",
    "    #For plotting of the int net, only second value of the tuple can be used for the comparison. Thus, always\n",
    "    #extract the second value from the scores_int df\n",
    "    for index in scores_int.index:\n",
    "\n",
    "        vals_int_real = scores_int.loc[index].values\n",
    "        vals_lambda_real = np.concatenate([scores_lambda.loc[index].values[::4] for i in samples_list], axis=None)\n",
    "        vals_lambda_lstsq = np.concatenate([scores_lambda.loc[index].values[3::4] for i in samples_list], axis=None)\n",
    "\n",
    "        ax = plt.subplot(length_plt//2+1, 2, subplot_number)\n",
    "        ax.set_title(index, fontsize=20)\n",
    "        ax.plot(samples_list, vals_int_real, label='Error I-Net Poly vs. Real Poly')\n",
    "        ax.plot(samples_list, vals_lambda_real, label='Error Lambda Model Preds vs. Real Poly')\n",
    "        ax.plot(samples_list, vals_lambda_lstsq, label='Error LSTSQ Preds vs. Real Poly')\n",
    "        ax.legend(loc=\"bottom right\", fontsize=14)\n",
    "        ax.set_xlim([0, samples_list[-1]])\n",
    "\n",
    "        for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            label.set_fontsize(14)   \n",
    "\n",
    "        #ax.set_xticks(np.arange(0, epochs, step=1))\n",
    "        subplot_number += 1\n",
    "    \n",
    "    \n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file = 'sample_list' + '-'.join([str(samples_list[0]), str(samples_list[-1])]) +'_REAL_' + interpretation_network_string +  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "\n",
    "    path = location + folder + file    \n",
    "    \n",
    "    plt.savefig(path, format='eps')\n",
    "    plt.show()\n",
    "\n",
    "elif samples_list != None and not evaluate_with_real_function:\n",
    "    length_plt = len(plot_cols)\n",
    "    subplot_number = 1\n",
    "    plt.figure(figsize=(12*2, 7*length_plt/2))\n",
    "\n",
    "    #For plotting of the int net, only second value of the tuple can be used for the comparison. Thus, always\n",
    "    #extract the second value from the scores_int df\n",
    "    for index in scores_int.index:\n",
    "\n",
    "        vals_int_poly = scores_int.loc[index].values[1::2]\n",
    "        vals_int_preds = scores_int.loc[index].values[::2]\n",
    "        vals_lambda_poly_pred = np.concatenate([scores_lambda.loc[index].values[2::4] for i in samples_list], axis=None)\n",
    "        \n",
    "        ax = plt.subplot(length_plt//2+1, 2, subplot_number)\n",
    "        ax.set_title(index, fontsize=20)\n",
    "        ax.plot(samples_list, vals_int_poly, label='Error I-Net Poly vs Lambda Poly')\n",
    "        ax.plot(samples_list, vals_int_preds, label='Error I-Net Poly vs Lambda Model Preds')\n",
    "        ax.plot(samples_list, vals_lambda_poly_pred, label='Error Lambda Poly vs Lambda Model Preds')\n",
    "        ax.legend(loc=\"bottom right\", fontsize=14)\n",
    "        ax.set_xlim([0, samples_list[-1]])\n",
    "\n",
    "        for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            label.set_fontsize(14)   \n",
    "\n",
    "        #ax.set_xticks(np.arange(0, epochs, step=1))\n",
    "        subplot_number += 1\n",
    "    \n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file = 'sample_list' + '-'.join([str(samples_list[0]), str(samples_list[-1])]) +'_MODEL_' + interpretation_network_string +  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "\n",
    "    path = location + folder + file    \n",
    "    \n",
    "    plt.savefig(path, format='eps')\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.524216Z",
     "start_time": "2020-11-24T09:14:15.020Z"
    }
   },
   "outputs": [],
   "source": [
    "if multi_epoch_analysis and evaluate_with_real_function:\n",
    "    index = 'MAE FV'\n",
    "\n",
    "    vals_int_real = scores_int.loc[index].values\n",
    "    vals_lambda_real = scores_lambda.loc[index].values[::4]\n",
    "    vals_lambda_lstsq = scores_lambda.loc[index].values[3::4]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    #ax.set_title('Accuracy Evaluation')\n",
    "\n",
    "    ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_int_real, label='Error I-Net Poly vs. Real Poly')\n",
    "    ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_lambda_real, label='Error Lambda Model Preds vs. Real Poly')\n",
    "    ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_lambda_lstsq, label='Error LSTSQ Preds vs. Real Poly')\n",
    "\n",
    "    ax.set_ylabel(index, fontsize=20)\n",
    "    ax.set_xlabel('Epochs', fontsize=20)\n",
    "\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(15)\n",
    "\n",
    "    ax.legend(loc=\"bottom right\", fontsize=15)\n",
    "    ax.set_xlim([0, epochs_lambda])\n",
    "    ax.set_ylim(bottom=0)\n",
    "    #ax.set_xticks(np.arange(0, epochs, step=1))\n",
    "    \n",
    "    \n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file = 'multi_epoch_REAL_' + index + '_' + interpretation_network_string+  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "\n",
    "    path = location + folder + file \n",
    "    \n",
    "    fig.savefig(path, format='eps')\n",
    "    \n",
    "elif multi_epoch_analysis and not evaluate_with_real_function:\n",
    "       \n",
    "    index = 'MAE FV'\n",
    "\n",
    "    vals_int_poly = scores_int.loc[index].values[1::2]\n",
    "    vals_int_preds = scores_int.loc[index].values[::2]\n",
    "    vals_lambda_poly_pred = scores_lambda.loc[index].values[2::4]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    #ax.set_title('Accuracy Evaluation')\n",
    "\n",
    "    ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_int_poly, label='Error I-Net Poly vs Lambda Poly')\n",
    "    ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_int_preds, label='Error I-Net Poly vs Lambda Model Preds')\n",
    "    ax.plot([(i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1 for i in epochs_save_range_lambda], vals_lambda_poly_pred, label='Error Lambda Poly vs Lambda Model Preds')\n",
    "\n",
    "    ax.set_ylabel(index, fontsize=20)\n",
    "    ax.set_xlabel('Epochs', fontsize=20)\n",
    "\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(15)\n",
    "\n",
    "    ax.legend(loc=\"bottom right\", fontsize=15)\n",
    "    ax.set_xlim([0, epochs_lambda])\n",
    "    ax.set_ylim(bottom=0)\n",
    "    \n",
    "    \n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file = 'multi_epoch_MODEL_' + index + '_' + interpretation_network_string+  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "\n",
    "    path = location + folder + file\n",
    "        \n",
    "    fig.savefig(path, format='eps')\n",
    "\n",
    "elif samples_list != None and evaluate_with_real_function:\n",
    "    index = 'MAE FV'\n",
    "\n",
    "    vals_int_real = scores_int.loc[index].values\n",
    "    vals_lambda_real = np.concatenate([scores_lambda.loc[index].values[::4] for i in samples_list], axis=None)\n",
    "    vals_lambda_lstsq = np.concatenate([scores_lambda.loc[index].values[3::4] for i in samples_list], axis=None)\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    ax.plot(samples_list, vals_int_real, label='Error I-Net Poly vs. Real Poly')\n",
    "    ax.plot(samples_list, vals_lambda_real, label='Error Lambda Model Preds vs. Real Poly')\n",
    "    ax.plot(samples_list, vals_lambda_lstsq, label='Error LSTSQ Preds vs. Real Poly')\n",
    "        \n",
    "    ax.set_ylabel(index, fontsize=20)\n",
    "    ax.set_xlabel('Training Set Size I-Net', fontsize=20)\n",
    "\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(15)   \n",
    "    \n",
    "    ax.legend(loc=\"bottom right\", fontsize=15)\n",
    "    ax.set_xlim([0, samples_list[-1]])\n",
    "    ax.set_ylim(bottom=0)\n",
    "    \n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file = 'sample_list_' + '-'.join([str(samples_list[0]), str(samples_list[-1])]) +'_REAL_' + index + '_' + interpretation_network_string+  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "\n",
    "    path = location + folder + file\n",
    "    \n",
    "    fig.savefig(path, format='eps')\n",
    "\n",
    "elif samples_list != None and not evaluate_with_real_function:\n",
    "    index = 'MAE FV'\n",
    "\n",
    "\n",
    "    vals_int_poly = scores_int.loc[index].values[1::2]\n",
    "    vals_int_preds = scores_int.loc[index].values[::2]\n",
    "    vals_lambda_poly_pred = np.concatenate([scores_lambda.loc[index].values[2::4] for i in samples_list], axis=None)\n",
    "\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "    ax.plot(samples_list, vals_int_poly, label='Error I-Net Poly vs Lambda Poly')\n",
    "    ax.plot(samples_list, vals_int_preds, label='Error I-Net Poly vs Lambda Model Preds')\n",
    "    ax.plot(samples_list, vals_lambda_poly_pred, label='Error Lambda Poly vs Lambda Model Preds')\n",
    "    \n",
    "    ax.set_ylabel(index, fontsize=20)\n",
    "    ax.set_xlabel('Training Set Size I-Net', fontsize=20)\n",
    "\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(15)   \n",
    "    \n",
    "    ax.legend(loc=\"bottom right\", fontsize=15)\n",
    "    ax.set_xlim([0, samples_list[-1]])\n",
    "    ax.set_ylim(bottom=0)\n",
    "    \n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file = 'sample_list_' + '-'.join([str(samples_list[0]), str(samples_list[-1])]) +'_MODEL_' + index + '_' + interpretation_network_string+  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "\n",
    "    path = location + folder + file\n",
    "        \n",
    "    fig.savefig(path, format='eps')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate and Analyze Predictions for Random Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.526132Z",
     "start_time": "2020-11-24T09:14:15.412Z"
    }
   },
   "outputs": [],
   "source": [
    "if multi_epoch_analysis:\n",
    "    plot_preds = polynomial_test_fv_list[-1]\n",
    "    plot_eval = lambda_test_fv_test_split_list[-1]\n",
    "elif samples_list != None:\n",
    "    plot_preds = polynomial_test_fv_list[-1]\n",
    "    plot_eval = lambda_test_fv_test_split\n",
    "else:\n",
    "    plot_preds = polynomial_test_fv\n",
    "    plot_eval = lambda_test_fv_test_split\n",
    "\n",
    "x_vars = ['x' + str(i) for i in range(1, n+1)]\n",
    "\n",
    "columns = x_vars.copy()\n",
    "columns.append('FVs')\n",
    "\n",
    "columns_single = x_vars.copy()\n",
    "columns_single.extend(['Real Poly FVs (Target)', 'Int Pred Poly FVs', 'Lambda Preds'])\n",
    "\n",
    "eval_size_plot = plot_preds[2].shape[1]\n",
    "rand_index = 2#42#random.randint(0, plot_preds[2].shape[0]-1)\n",
    "vars_plot = np.column_stack([lambda_test_input[::,i] for i in range(n)])\n",
    "plot_data_single = pd.DataFrame(data=np.column_stack([vars_plot, plot_preds[2][rand_index], plot_preds[3][rand_index], plot_eval.values[rand_index]]), columns=columns_single)\n",
    "\n",
    "vars_plot_all_preds = np.append(np.append(vars_plot, vars_plot, axis=0), vars_plot, axis=0)\n",
    "preds_plot_all = np.append(np.append(plot_preds[2][rand_index], plot_preds[3][rand_index], axis=0), plot_eval.values[rand_index], axis=0)\n",
    "\n",
    "if evaluate_with_real_function:\n",
    "    real_str = np.array(['Real Poly FVs (Target)' for i in range(eval_size_plot)])\n",
    "    int_str = np.array(['Int Pred Poly FVs' for i in range(eval_size_plot)])\n",
    "    lambda_str = np.array(['Lambda Preds' for i in range(eval_size_plot)])\n",
    "    #Add Lambda Poly Preds LSTSQ\n",
    "else:\n",
    "    real_str = np.array(['Lambda Poly FVs (Target)' for i in range(eval_size_plot)])\n",
    "    int_str = np.array(['Int Pred Poly FVs' for i in range(eval_size_plot)])\n",
    "    lambda_str = np.array(['Lambda Preds' for i in range(eval_size_plot)])\n",
    "    #Add Lambda Poly Preds\n",
    "    \n",
    "identifier = np.concatenate([real_str, int_str, lambda_str])\n",
    "\n",
    "plot_data = pd.DataFrame(data=np.column_stack([vars_plot_all_preds, preds_plot_all]), columns=columns)\n",
    "plot_data['Identifier'] = identifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.527738Z",
     "start_time": "2020-11-24T09:14:15.614Z"
    }
   },
   "outputs": [],
   "source": [
    "pp1 = sns.pairplot(data=plot_data,\n",
    "                  #kind='reg',\n",
    "                  hue='Identifier',\n",
    "                  y_vars=['FVs'],\n",
    "                  x_vars=x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.529347Z",
     "start_time": "2020-11-24T09:14:15.807Z"
    }
   },
   "outputs": [],
   "source": [
    "pp2 = sns.pairplot(data=plot_data,\n",
    "                  #kind='reg',\n",
    "                  hue='Identifier',\n",
    "                  #y_vars=['FVs'],\n",
    "                  #x_vars=x_vars\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.530969Z",
     "start_time": "2020-11-24T09:14:15.994Z"
    }
   },
   "outputs": [],
   "source": [
    "pp3 = sns.pairplot(data=plot_data_single,\n",
    "                  #kind='reg',\n",
    "                  y_vars=['Real Poly FVs (Target)', 'Int Pred Poly FVs', 'Lambda Preds'],\n",
    "                  x_vars=x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.532609Z",
     "start_time": "2020-11-24T09:14:16.204Z"
    }
   },
   "outputs": [],
   "source": [
    "if evaluate_with_real_function:\n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file1 = 'pp3in1_REAL_' + str(rand_index) + '_' + interpretation_network_string +  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "    file2 = 'pp3in1_extended_REAL_' + str(rand_index) + '_' + interpretation_network_string +  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "    file3 = 'pp1_REAL_' + str(rand_index) + '_' + interpretation_network_string+  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "    \n",
    "    path1 = location + folder + file1\n",
    "    path2 = location + folder + file2\n",
    "    path3 = location + folder + file3\n",
    "    \n",
    "    pp1.savefig(path1, format='eps')\n",
    "    pp2.savefig(path2, format='eps')\n",
    "    pp3.savefig(path3, format='eps')\n",
    "else:\n",
    "    location = './data/plotting/'\n",
    "    folder = interpretation_network_string + filename + '/'\n",
    "    file1 = 'pp3in1_PRED_' + str(rand_index) + '_' + interpretation_network_string +  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "    file2 = 'pp3in1_extended_PRED_' + str(rand_index) + '_' + interpretation_network_string +  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "    file3 = 'pp1_PRED_' + str(rand_index) + '_' + interpretation_network_string+  '_lambda_' + filename + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '.eps'\n",
    "    \n",
    "    path1 = location + folder + file1\n",
    "    path2 = location + folder + file2\n",
    "    path3 = location + folder + file3\n",
    "    \n",
    "    pp1.savefig(path1, format='eps')\n",
    "    pp2.savefig(path2, format='eps')\n",
    "    pp3.savefig(path3, format='eps')    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.534238Z",
     "start_time": "2020-11-24T09:14:16.584Z"
    }
   },
   "outputs": [],
   "source": [
    "if not multi_epoch_analysis and samples_list == None: \n",
    "    #%%script false --no-raise-error\n",
    "    path_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "    path_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n)+ '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "    path_val_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "    path_val_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs_lambda).zfill(3)  + filename + '.txt'\n",
    "\n",
    "\n",
    "    loss_df_lambda = pd.read_csv(path_loss, sep=',')\n",
    "    metric_df_lambda = pd.read_csv(path_metric, sep=',')\n",
    "    val_loss_df_lambda = pd.read_csv(path_val_loss, sep=',')\n",
    "    val_metric_df_lambda = pd.read_csv(path_val_metric, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.536054Z",
     "start_time": "2020-11-24T09:14:16.769Z"
    }
   },
   "outputs": [],
   "source": [
    "if not multi_epoch_analysis and samples_list == None: \n",
    "\n",
    "    #%%script false --no-raise-error\n",
    "    adjustment_threshold_metric = 0\n",
    "\n",
    "    metric_df_adjusted = metric_df_lambda.copy(deep=True)\n",
    "    metric_df_adjusted[metric_df_adjusted.columns] = np.where(metric_df_adjusted[metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, metric_df_adjusted[metric_df_adjusted.columns])\n",
    "\n",
    "    val_metric_df_adjusted = val_metric_df_lambda.copy(deep=True)\n",
    "    val_metric_df_adjusted[val_metric_df_adjusted.columns] = np.where(val_metric_df_adjusted[val_metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, val_metric_df_adjusted[val_metric_df_adjusted.columns])\n",
    "\n",
    "\n",
    "    plt.plot(metric_df_adjusted.describe().loc['mean'].values)\n",
    "    plt.plot(val_metric_df_adjusted.describe().loc['mean'].values)\n",
    "    #plt.plot(random_network[2].history['val_metric'])\n",
    "    plt.title('model metric')\n",
    "    plt.ylabel('metric')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.537490Z",
     "start_time": "2020-11-24T09:14:16.956Z"
    }
   },
   "outputs": [],
   "source": [
    "if not multi_epoch_analysis and samples_list == None: \n",
    "    #%%script false --no-raise-error\n",
    "    adjustment_threshold_loss = 1000\n",
    "\n",
    "    loss_df_adjusted = loss_df_lambda.copy(deep=True)\n",
    "    loss_df_adjusted[loss_df_adjusted.columns] = np.where(loss_df_adjusted[loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, loss_df_adjusted[loss_df_adjusted.columns])\n",
    "\n",
    "    val_loss_df_adjusted = val_loss_df_lambda.copy(deep=True)\n",
    "    val_loss_df_adjusted[val_loss_df_adjusted.columns] = np.where(val_loss_df_adjusted[val_loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, val_loss_df_adjusted[val_loss_df_adjusted.columns])\n",
    "\n",
    "\n",
    "    plt.plot(loss_df_adjusted.describe().loc['mean'].values)\n",
    "    plt.plot(val_loss_df_adjusted.describe().loc['mean'].values)\n",
    "    #plt.plot(random_network[2].history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.539297Z",
     "start_time": "2020-11-24T09:14:17.144Z"
    }
   },
   "outputs": [],
   "source": [
    "if not multi_epoch_analysis and samples_list == None: \n",
    "    preds = model.predict(X_test)\n",
    "    preds_rounded = np.round(preds, 1)\n",
    "    #preds_true = pd.DataFrame(data=[np.round(preds, 1), y_test.values])\n",
    "    for pred, y in tqdm(zip(preds_rounded, y_test.values)):\n",
    "        if (pred == y).all():\n",
    "            print(pred)\n",
    "    \n",
    "    #print(preds_rounded)\n",
    "    #print(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.540917Z",
     "start_time": "2020-11-24T09:14:17.340Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#summarize history for loss\n",
    "if not multi_epoch_analysis and samples_list == None: \n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    #plt.plot(random_network[2].history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/loss_' + interpretation_network_string + filename + '.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (RANDOM GUESS) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.542371Z",
     "start_time": "2020-11-24T09:14:17.757Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_random_polynomials = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    random_polynomial = list(random_product([i*a_step for i in range(int(a_min*10**int(-np.log10(a_step))), int(a_max*10**int(-np.log10(a_step))))], repeat=nCr(n+d, d)))\n",
    "    list_of_random_polynomials.append(random_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.544158Z",
     "start_time": "2020-11-24T09:14:17.935Z"
    }
   },
   "outputs": [],
   "source": [
    "true_fv_test = parallel_fv_calculation_from_polynomial(y_test.values, lambda_test_input)\n",
    "random_fv_test = parallel_fv_calculation_from_polynomial(list_of_random_polynomials, lambda_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.545660Z",
     "start_time": "2020-11-24T09:14:18.125Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Benchmark Error Coefficients: ' + str(np.round(mean_absolute_error(y_test, list_of_random_polynomials), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T09:14:21.547256Z",
     "start_time": "2020-11-24T09:14:18.315Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Benchmark Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, random_fv_test), 4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
