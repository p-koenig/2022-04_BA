{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training\n",
    "\n",
    "# Experiment 1: I-Net Performance for Different Algebras and Complexities\n",
    "# Experiment 2: I-Net Performance Comparison for Î»-Nets with Different Training Levels\n",
    "# Experiment 3: I-Net Performance Comparison Different Training Data Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'data': {\n",
    "        'd': 5, #degree\n",
    "        'n': 1, #number of variables\n",
    "        'sparsity': None,\n",
    "        'sample_sparsity': None,\n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        'a_max': 1,\n",
    "        'a_min': -1,\n",
    "        'lambda_nets_total': 10000,\n",
    "        'noise': 0.05,\n",
    "        'noise_distrib': 'normal', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        \n",
    "        'same_training_all_lambda_nets': False,\n",
    "\n",
    "        'fixed_seed_lambda_training': True,\n",
    "        'fixed_initialization_lambda_training': False,\n",
    "        'number_different_lambda_trainings': 1,\n",
    "    },\n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True,  #if early stopping is used, multi_epoch_analysis is deactivated\n",
    "        'batch_lambda': 64,\n",
    "        'dropout': 0,\n",
    "        'lambda_network_layers': [5*'sparsity'],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'mae',\n",
    "        'number_of_lambda_weights': None,\n",
    "        'lambda_dataset_size': 1000,\n",
    "    },\n",
    "    'i_net': {\n",
    "        'optimizer': 'custom',#adam\n",
    "        'inet_loss': 'mae',\n",
    "        'inet_metrics': ['r2'],\n",
    "        'dropout': 0.5,\n",
    "        'epochs': 500,\n",
    "        'early_stopping': True,\n",
    "        'batch_size': 512,\n",
    "        'dense_layers': [1024, 32],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'interpretation_dataset_size': 10000, #interpretation-net dataset size\n",
    "                \n",
    "        'interpretation_net_output_monomials': None, #(None, int)\n",
    "        'interpretation_net_output_shape': None, #calculated automatically later\n",
    "        \n",
    "        'evaluate_with_real_function': False,\n",
    "        'consider_labels_training': False,\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        'nas': False,\n",
    "        'nas_type': None, #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 0,\n",
    "    },\n",
    "    'evaluation': {   \n",
    "        'inet_holdout_seed_evaluation': False,\n",
    "        \n",
    "        #set if multi_epoch_analysis should be performed\n",
    "        'multi_epoch_analysis': False,\n",
    "        'each_epochs_save_lambda': 20,\n",
    "        'epoch_start': 0, #use to skip first epochs in multi_epoch_analysis\n",
    "        \n",
    "        #set if samples analysis should be performed\n",
    "        'samples_list': None,#[100, 500, 750, 1000, 2500, 5000, 7500, 10000, 15000, 20000, 25000, 28125] \n",
    "       \n",
    "        'random_evaluation_dataset_size': 500,\n",
    "    },\n",
    "    'computation':{\n",
    "        'n_jobs': 1,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '0',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "from itertools import product       \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import colored\n",
    "import math\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "import keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import random \n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "from IPython.display import display, Math, Latex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "\n",
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "\n",
    "n_jobs = min((epochs_lambda//each_epochs_save_lambda+1, n_jobs)) if multi_epoch_analysis else min(len(samples_list), n_jobs) if samples_list!=None else 1\n",
    "\n",
    "multi_epoch_analysis = False if early_stopping_lambda else multi_epoch_analysis #deactivate multi_epoch_analysis if early stopping is used\n",
    "\n",
    "each_epochs_save_lambda = each_epochs_save_lambda if multi_epoch_analysis else epochs_lambda\n",
    "epochs_save_range_lambda = range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda) if each_epochs_save_lambda == 1 else range(epoch_start//each_epochs_save_lambda, epochs_lambda//each_epochs_save_lambda+1) if multi_epoch_analysis else range(1,2)\n",
    "\n",
    "data_reshape_version = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "config['evaluation']['multi_epoch_analysis'] = multi_epoch_analysis\n",
    "config['evaluation']['each_epochs_save_lambda'] = each_epochs_save_lambda\n",
    "config['i_net']['data_reshape_version'] = data_reshape_version\n",
    "\n",
    "config['data']['sparsity'] = nCr(config['data']['n']+config['data']['d'], config['data']['d'])\n",
    "config['data']['sample_sparsity'] = config['data']['sparsity'] if config['data']['sample_sparsity'] == None else config['data']['sample_sparsity']\n",
    "\n",
    "config['i_net']['interpretation_net_output_shape'] = config['data']['sparsity'] if config['i_net']['interpretation_net_output_monomials'] is None else 2*config['i_net']['interpretation_net_output_monomials']\n",
    "\n",
    "\n",
    "transformed_layers = []\n",
    "for layer in config['lambda_net']['lambda_network_layers']:\n",
    "    if type(layer) == str:\n",
    "        transformed_layers.append(layer.count('sparsity')*config['data']['sparsity'])\n",
    "    else:\n",
    "        transformed_layers.append(layer)\n",
    "config['lambda_net']['lambda_network_layers'] = transformed_layers\n",
    "\n",
    "layers_with_input_output = list(flatten([[config['data']['n']], config['lambda_net']['lambda_network_layers'], [1]]))\n",
    "number_of_lambda_weights = 0\n",
    "for i in range(len(layers_with_input_output)-1):\n",
    "    number_of_lambda_weights += (layers_with_input_output[i]+1)*layers_with_input_output[i+1]  \n",
    "config['lambda_net']['number_of_lambda_weights'] = number_of_lambda_weights\n",
    "    \n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "\n",
    "\n",
    "initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "initialize_metrics_config_from_curent_notebook(config)\n",
    "initialize_utility_functions_config_from_curent_notebook(config)\n",
    "initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(path_type='interpretation_net'))\n",
    "create_folders_inet()\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inet_dense1024-32-output_6_drop0.5e500b512_custom/lnets_10000_30-1000eES64b_adam_mae_train_1000_diffX_1-FixSeed_42/var_1_d_5_sparsity_6_amin_-1_amax_1_xdist_uniform_noise_normal_0.05\n",
      "lnets_10000_30-1000eES64b_adam_mae_train_1000_diffX_1-FixSeed_42/var_1_d_5_sparsity_6_amin_-1_amax_1_xmin_0_xmax_1_xdist_uniform_noise_normal_0.05\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net_data)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of Monomial Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.789212Z",
     "start_time": "2021-01-05T08:33:49.725485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2b694b07414189bd93230dbb21f0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 6\n",
      "Number of monomials in a polynomial with 1 variables and degree 5: 6\n",
      "Sparsity: 6\n",
      "['0', '1', '2', '3', '4', '5']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cfd07db5be4ef786360b595232ccea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 6\n",
      "Number of monomials in a polynomial with 1 variables and degree 5: 6\n",
      "Sparsity: 6\n",
      "['0', '1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "list_of_monomial_identifiers_extended = []\n",
    "for i in tqdm(range((d+1)**n)):    \n",
    "    monomial_identifier = dec_to_base(i, base = (d+1)).zfill(n) \n",
    "    list_of_monomial_identifiers_extended.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers_extended)\n",
    "\n",
    "list_of_monomial_identifiers = []\n",
    "for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "    monomial_identifier_values = list(map(int, list(monomial_identifier)))\n",
    "    if sum(monomial_identifier_values) <= d:\n",
    "        list_of_monomial_identifiers.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)\n",
    "\n",
    "\n",
    "layers_with_input_output = list(flatten([[n], lambda_network_layers, [1]]))\n",
    "number_of_lambda_weights = 0\n",
    "for i in range(len(layers_with_input_output)-1):\n",
    "    number_of_lambda_weights += (layers_with_input_output[i]+1)*layers_with_input_output[i+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(index):\n",
    "    \n",
    "    if psutil.virtual_memory().percent > 80:\n",
    "        raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    path = './data/weights/' + 'weights_' + path_identifier_lambda_net_data + '/weights_' + '_epoch_' + str(index).zfill(3) + '.txt'\n",
    "\n",
    "    \n",
    "    weight_data = pd.read_csv(path, sep=\",\", header=None)\n",
    "    weight_data = weight_data.sort_values(by=0).sample(frac=1, random_state=RANDOM_SEED)\n",
    "    weight_data = weight_data.sort_values(by=0).sample(n=interpretation_dataset_size, random_state=RANDOM_SEED)\n",
    "\n",
    "    lambda_nets = []\n",
    "    for _, row in weight_data.iterrows():\n",
    "        lambda_net = LambdaNet(row.values)\n",
    "        lambda_nets.append(lambda_net)\n",
    "        \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/weights/weights_lnets_10000_30-1000eES64b_adam_mae_train_1000_diffX_1-FixSeed_42/var_1_d_5_sparsity_6_amin_-1_amax_1_xmin_0_xmax_1_xdist_uniform_noise_normal_0.05/weights__epoch_1000.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-74cdb1ab0aca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiprocessing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlambda_net_dataset_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_lambda_nets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meach_epochs_save_lambda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0meach_epochs_save_lambda\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meach_epochs_save_lambda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0meach_epochs_save_lambda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs_save_range_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-707d42e9f019>\u001b[0m in \u001b[0;36mload_lambda_nets\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mweight_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mweight_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANDOM_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mweight_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpretation_dataset_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANDOM_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \"\"\"\n\u001b[0;32m-> 1357\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    640\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/weights/weights_lnets_10000_30-1000eES64b_adam_mae_train_1000_diffX_1-FixSeed_42/var_1_d_5_sparsity_6_amin_-1_amax_1_xmin_0_xmax_1_xdist_uniform_noise_normal_0.05/weights__epoch_1000.txt'"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "\n",
    "parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "lambda_net_dataset_list = parallel(delayed(load_lambda_nets)((i+1)*each_epochs_save_lambda if each_epochs_save_lambda==1 else i*each_epochs_save_lambda if i > 1 else each_epochs_save_lambda if i==1 else 1) for i in epochs_save_range_lambda)  \n",
    "del parallel\n",
    "\n",
    "lambda_net_dataset = lambda_net_dataset_list[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:30:49.711839Z",
     "start_time": "2021-01-05T09:29:48.873305Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset.as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:31:56.898548Z",
     "start_time": "2021-01-05T09:30:49.715497Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset.as_pandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets for Interpretation-Net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:32:09.782470Z",
     "start_time": "2021-01-05T09:31:56.901018Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate train, test and validation data for training\n",
    "\n",
    "lambda_net_train_dataset_list = []\n",
    "lambda_net_valid_dataset_list = []\n",
    "lambda_net_test_dataset_list = []\n",
    "\n",
    "for lambda_net_dataset in lambda_net_dataset_list:\n",
    "    \n",
    "    \n",
    "    if inet_holdout_seed_evaluation:\n",
    "        complete_seed_list = list(set(lambda_net_dataset.train_settings_list['seed']))#list(weight_data.iloc[:,1].unique())\n",
    "\n",
    "        random.seed(RANDOM_SEED)\n",
    "        test_seeds = random.sample(complete_seed_list, int(len(complete_seed_list)-len(complete_seed_list)/(1/0.9)))\n",
    "        lambda_net_test_dataset = lambda_net_dataset.get_lambda_nets_by_seed(test_seeds)\n",
    "        complete_seed_list = list(set(complete_seed_list) - set(test_seeds))#complete_seed_list.remove(test_seeds)\n",
    "        \n",
    "        random.seed(RANDOM_SEED)\n",
    "        valid_seeds = random.sample(complete_seed_list, int(len(complete_seed_list)-len(complete_seed_list)/(1/0.9)))\n",
    "        lambda_net_valid_dataset = lambda_net_dataset.get_lambda_nets_by_seed(valid_seeds)\n",
    "        complete_seed_list = list(set(complete_seed_list) - set(valid_seeds))\n",
    "\n",
    "        train_seeds = complete_seed_list\n",
    "        lambda_net_train_dataset = lambda_net_dataset.get_lambda_nets_by_seed(train_seeds)       \n",
    "        \n",
    "        lambda_net_train_dataset_list.append(lambda_net_train_dataset)\n",
    "        lambda_net_valid_dataset_list.append(lambda_net_valid_dataset)\n",
    "        lambda_net_test_dataset_list.append(lambda_net_test_dataset)\n",
    "        \n",
    "        del lambda_net_dataset\n",
    "    else:\n",
    "        lambda_net_train_with_valid_dataset, lambda_net_test_dataset = split_LambdaNetDataset(lambda_net_dataset, test_split=0.1)\n",
    "        lambda_net_train_dataset, lambda_net_valid_dataset = split_LambdaNetDataset(lambda_net_train_with_valid_dataset, test_split=0.1)\n",
    "\n",
    "        lambda_net_train_dataset_list.append(lambda_net_train_dataset)\n",
    "        lambda_net_valid_dataset_list.append(lambda_net_valid_dataset)\n",
    "        lambda_net_test_dataset_list.append(lambda_net_test_dataset)\n",
    "    \n",
    "        del lambda_net_dataset, lambda_net_train_with_valid_dataset\n",
    "\n",
    "        \n",
    "del lambda_net_dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:06.495716Z",
     "start_time": "2021-01-05T09:32:09.784760Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_train_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:08.945802Z",
     "start_time": "2021-01-05T09:33:06.499150Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_valid_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:33:11.543306Z",
     "start_time": "2021-01-05T09:33:08.947468Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_test_dataset_list[-1].as_pandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_train_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_valid_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_test_dataset_list[-1].as_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(history_list, \n",
    "scores_list, \n",
    "\n",
    "function_values_complete_list, \n",
    "function_values_valid_list, \n",
    "function_values_test_list, \n",
    "\n",
    "inet_preds_list, \n",
    "inet_preds_valid_list, \n",
    "inet_preds_test_list, \n",
    "\n",
    "distrib_dict_list,\n",
    "model_list) = calculate_interpretation_net_results(lambda_net_train_dataset_list, \n",
    "                                                   lambda_net_valid_dataset_list, \n",
    "                                                   lambda_net_test_dataset_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Interpretation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nas:\n",
    "    for trial in history_list[-1]: \n",
    "        print(trial.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(model_list) >= 1:\n",
    "    print(model_list[-1].summary())\n",
    "    print(model_list[-1].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T15:23:49.656430Z",
     "start_time": "2021-01-05T15:23:49.578409Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:55.162513Z",
     "start_time": "2021-01-08T11:56:54.472198Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_list[-1]['MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:56.434915Z",
     "start_time": "2021-01-08T11:56:55.669304Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_list[-1]['R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T20:33:18.196958Z",
     "start_time": "2021-01-07T20:33:18.177611Z"
    }
   },
   "outputs": [],
   "source": [
    "index_min = int(np.argmin(distrib_dict_list[-1]['R2'].loc['predLambda_VS_lstsqTarget_test']))\n",
    "polynomial_inet = inet_preds_test_list[-1][index_min]\n",
    "\n",
    "print(distrib_dict_list[-1]['R2'].loc['inetPoly_VS_targetPoly_test'][index_min])\n",
    "\n",
    "print_polynomial_from_coefficients(polynomial_inet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T20:33:18.514683Z",
     "start_time": "2021-01-07T20:33:18.506614Z"
    }
   },
   "outputs": [],
   "source": [
    "index_min = int(np.argmin(distrib_dict_list[-1]['R2'].loc['predLambda_VS_lstsqTarget_test']))\n",
    "#polynomial_target = lambda_net_test_dataset.get_lambda_net_by_lambda_index(index_min).target_polynomial\n",
    "\n",
    "print(distrib_dict_list[-1]['R2'].loc['lstsqLambda_VS_targetPoly_test'][index_min])\n",
    "\n",
    "polynomial_lambda = lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list[index_min]\n",
    "print_polynomial_from_coefficients(polynomial_lambda, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T20:33:18.820457Z",
     "start_time": "2021-01-07T20:33:18.813628Z"
    }
   },
   "outputs": [],
   "source": [
    "index_min = int(np.argmin(distrib_dict_list[-1]['R2'].loc['predLambda_VS_lstsqTarget_test']))\n",
    "#polynomial_target = lambda_net_test_dataset.get_lambda_net_by_lambda_index(index_min).target_polynomial\n",
    "polynomial_target = lambda_net_test_dataset.target_polynomial_list[index_min]\n",
    "print_polynomial_from_coefficients(polynomial_target, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T20:33:22.149541Z",
     "start_time": "2021-01-07T20:33:22.141264Z"
    }
   },
   "outputs": [],
   "source": [
    "index_max = int(np.argmax(distrib_dict_list[-1]['R2'].loc['predLambda_VS_lstsqTarget_test']))\n",
    "polynomial_inet = inet_preds_test_list[-1][index_max]\n",
    "\n",
    "print(distrib_dict_list[-1]['R2'].loc['inetPoly_VS_targetPoly_test'][index_max])\n",
    "\n",
    "print_polynomial_from_coefficients(polynomial_inet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T20:33:22.526765Z",
     "start_time": "2021-01-07T20:33:22.518702Z"
    }
   },
   "outputs": [],
   "source": [
    "index_max = int(np.argmax(distrib_dict_list[-1]['R2'].loc['predLambda_VS_lstsqTarget_test']))\n",
    "#polynomial_target = lambda_net_test_dataset.get_lambda_net_by_lambda_index(index_min).target_polynomial\n",
    "\n",
    "print(distrib_dict_list[-1]['R2'].loc['lstsqLambda_VS_targetPoly_test'][index_max])\n",
    "\n",
    "polynomial_lambda = lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list[index_max]\n",
    "print_polynomial_from_coefficients(polynomial_lambda, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T20:33:23.155159Z",
     "start_time": "2021-01-07T20:33:23.146225Z"
    }
   },
   "outputs": [],
   "source": [
    "index_max = int(np.argmax(distrib_dict_list[-1]['R2'].loc['predLambda_VS_lstsqTarget_test']))\n",
    "#polynomial_target = lambda_net_test_dataset.get_lambda_net_by_lambda_index(index_min).target_polynomial\n",
    "polynomial_target = lambda_net_test_dataset.target_polynomial_list[index_max]\n",
    "print_polynomial_from_coefficients(polynomial_target, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:42.304392Z",
     "start_time": "2021-01-07T15:49:42.291475Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_values_inet = distrib_dict_list[-1]['R2'].loc['inetPoly_VS_targetPoly_test']\n",
    "print('Mean: ' + str(np.mean(r2_values_inet)) + ' (' + str(r2_values_inet.shape[0]) + ' Samples)')\n",
    "\n",
    "r2_values_positive_inet = r2_values_inet[r2_values_inet>0]\n",
    "print('Mean (only positive): ' + str(np.mean(r2_values_positive_inet)) + ' (' + str(r2_values_positive_inet.shape[0]) + ' Samples)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:42.833577Z",
     "start_time": "2021-01-07T15:49:42.821286Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_values_lstsq_lambda = distrib_dict_list[-1]['R2'].loc['lstsqLambda_VS_targetPoly_test']\n",
    "print('Mean: ' + str(np.mean(r2_values_lstsq_lambda)) + ' (' + str(r2_values_inet.shape[0]) + ' Samples)')\n",
    "\n",
    "r2_values_positive_lstsq_lambda = r2_values_lstsq_lambda[r2_values_lstsq_lambda>0]\n",
    "print('Mean (only positive): ' + str(np.mean(r2_values_positive_lstsq_lambda)) + ' (' + str(r2_values_positive_lstsq_lambda.shape[0]) + ' Samples)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:44.179590Z",
     "start_time": "2021-01-07T15:49:43.001746Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(distrib_dict_list[-1]['MAE'].loc['inetPoly_VS_targetPoly_test'][distrib_dict_list[-1]['R2'].loc['inetPoly_VS_targetPoly_test'] > -50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:44.417509Z",
     "start_time": "2021-01-07T15:49:44.181928Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(distrib_dict_list[-1]['MAE'].loc['lstsqLambda_VS_targetPoly_test'][distrib_dict_list[-1]['R2'].loc['lstsqLambda_VS_targetPoly_test'] > -50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:44.935810Z",
     "start_time": "2021-01-07T15:49:44.419772Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_list[-1]['R2'].loc['inetPoly_VS_targetPoly_test'][distrib_dict_list[-1]['R2'].loc['inetPoly_VS_targetPoly_test'] > -50], binwidth=0.2)\n",
    "p.set(xlim=(-30, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:45.795559Z",
     "start_time": "2021-01-07T15:49:44.938329Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_list[-1]['R2'].loc['inetPoly_VS_targetPoly_test'][distrib_dict_list[-1]['R2'].loc['inetPoly_VS_targetPoly_test'] > -50], binwidth=0.1)\n",
    "p.set(xlim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:47.784878Z",
     "start_time": "2021-01-07T15:49:45.797362Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_list[-1]['R2'].loc['lstsqLambda_VS_targetPoly_test'][distrib_dict_list[-1]['R2'].loc['lstsqLambda_VS_targetPoly_test'] > -50], binwidth=0.2)\n",
    "p.set(xlim=(-10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.252121Z",
     "start_time": "2021-01-07T15:49:47.786575Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_list[-1]['R2'].loc['lstsqLambda_VS_targetPoly_test'][distrib_dict_list[-1]['R2'].loc['lstsqLambda_VS_targetPoly_test'] > -50], binwidth=0.1)\n",
    "p.set(xlim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.410283Z",
     "start_time": "2021-01-07T15:49:48.254228Z"
    }
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history[list(history.keys())[1]])\n",
    "    if consider_labels_training or evaluate_with_real_function:\n",
    "        plt.plot(history[list(history.keys())[len(history.keys())//2+1]]) \n",
    "    plt.title('model ' + list(history.keys())[1])\n",
    "    plt.ylabel('metric')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/metric_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.567983Z",
     "start_time": "2021-01-07T15:49:48.413234Z"
    }
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    if consider_labels_training or evaluate_with_real_function:\n",
    "        plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/loss_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Epoch/Sampes Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Comparison Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(scores_list) > 1:\n",
    "    plot_metric_list = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(scores_list) > 1:\n",
    "    plot_metric_list = ['MAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(scores_list) > 1:\n",
    "    plot_metric_list = ['R2 FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_list, plot_metric_list, ylim=(-5, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate and Analyze Predictions for Random Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6\n",
    "\n",
    "polynomial_target = lambda_net_test_dataset.target_polynomial_list[index]\n",
    "polynomial_lstsq_target = lambda_net_test_dataset.lstsq_target_polynomial_list[index]\n",
    "polynomial_lstsq_lambda = lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list[index]\n",
    "polynomial_inet = inet_preds_test_list[-1][index]\n",
    "\n",
    "print('Target Poly:')\n",
    "print_polynomial_from_coefficients(polynomial_target, force_complete_poly_representation=True, round_digits=4)\n",
    "print('LSTSQ Target Poly:')\n",
    "print_polynomial_from_coefficients(polynomial_lstsq_target, force_complete_poly_representation=True, round_digits=4)\n",
    "print('LSTSQ Lambda Poly:')\n",
    "print_polynomial_from_coefficients(polynomial_lstsq_lambda, force_complete_poly_representation=True, round_digits=4)\n",
    "print('I-Net Poly:')\n",
    "print_polynomial_from_coefficients(polynomial_inet, round_digits=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, function_values_test_list, inet_preds_test_list, rand_index=1, plot_type=2):\n",
    "    \n",
    "    paths_dict = generate_paths(path_type = 'interpretation_net')\n",
    "    \n",
    "    polynomial_target = lambda_net_test_dataset_list[-1].target_polynomial_list[rand_index]\n",
    "    polynomial_lstsq_target = lambda_net_test_dataset_list[-1].lstsq_target_polynomial_list[rand_index]\n",
    "    polynomial_lstsq_lambda = lambda_net_test_dataset_list[-1].lstsq_lambda_pred_polynomial_list[rand_index]\n",
    "    polynomial_inet = inet_preds_test_list[-1][rand_index]\n",
    "    \n",
    "    polynomial_target_string = get_sympy_string_from_coefficients(polynomial_target, force_complete_poly_representation=True, round_digits=4)\n",
    "    polynomial_lstsq_target_string = get_sympy_string_from_coefficients(polynomial_lstsq_target, force_complete_poly_representation=True, round_digits=4)\n",
    "    polynomial_lstsq_lambda_string = get_sympy_string_from_coefficients(polynomial_lstsq_lambda, force_complete_poly_representation=True, round_digits=4)\n",
    "    polynomial_inet_string = get_sympy_string_from_coefficients(polynomial_inet, round_digits=4)\n",
    "    \n",
    "    #print('Target Poly:')\n",
    "    #print_polynomial_from_coefficients(polynomial_target, force_complete_poly_representation=True, round_digits=4)\n",
    "    #print('LSTSQ Target Poly:')\n",
    "    #print_polynomial_from_coefficients(polynomial_lstsq_target, force_complete_poly_representation=True, round_digits=4)\n",
    "    #print('LSTSQ Lambda Poly:')\n",
    "    #print_polynomial_from_coefficients(polynomial_lstsq_lambda, force_complete_poly_representation=True, round_digits=4)\n",
    "    #print('I-Net Poly:')\n",
    "    #print_polynomial_from_coefficients(polynomial_inet, round_digits=4)    \n",
    "    \n",
    "    real_poly_fvs = function_values_test_list[-1][1][rand_index]\n",
    "    lstsq_target_poly = function_values_test_list[-1][3][rand_index]\n",
    "    lambda_model_preds = function_values_test_list[-1][0][rand_index].ravel()\n",
    "    lstsq_lambda_preds_poly = function_values_test_list[-1][2][rand_index]\n",
    "    inet_poly_fvs = function_values_test_list[-1][4][rand_index]  \n",
    "    lambda_train_data = lambda_net_test_dataset_list[-1].y_test_data_list[rand_index]\n",
    "    \n",
    "    x_vars = ['x' + str(i) for i in range(1, n+1)]\n",
    "\n",
    "    columns = x_vars.copy()\n",
    "    columns.append('FVs')\n",
    "\n",
    "    columns_single = x_vars.copy()\n",
    "\n",
    "    eval_size_plot = inet_poly_fvs.shape[0]\n",
    "    lambda_train_data_size = lambda_train_data.shape[0]\n",
    "    vars_plot = lambda_net_test_dataset_list[-1].X_test_data_list[rand_index]    \n",
    "    \n",
    "    if evaluate_with_real_function:\n",
    "        columns_single.extend(['Target Poly FVs', 'Lambda Train Data', 'LSTSQ Target Poly FVs', 'I-Net Poly FVs', 'Lambda Model Preds', 'LSTSQ Lambda Poly FVs'])\n",
    "        plot_data_single = pd.DataFrame(data=np.column_stack([vars_plot, real_poly_fvs, lambda_train_data, lstsq_target_poly, inet_poly_fvs, lambda_model_preds, lstsq_lambda_preds_poly]), columns=columns_single)\n",
    "        preds_plot_all = np.vstack([real_poly_fvs, lambda_train_data, lstsq_target_poly, inet_poly_fvs, lambda_model_preds, lstsq_lambda_preds_poly]).ravel()\n",
    "        vars_plot_all_preds = np.vstack([vars_plot for i in range(len(columns_single[n:]))])\n",
    "\n",
    "        real_poly_fvs_str = np.array(['Target Poly FVs' for i in range(eval_size_plot)])\n",
    "        lambda_train_data_str = np.array(['Lambda Train Data' for i in range(lambda_train_data_size)])\n",
    "        lstsq_target_poly_str = np.array(['LSTSQ Target Poly FVs' for i in range(eval_size_plot)])\n",
    "        inet_poly_fvs_str = np.array(['I-Net Poly FVs' for i in range(eval_size_plot)])\n",
    "        lambda_model_preds_str = np.array(['Lambda Model Preds' for i in range(eval_size_plot)])\n",
    "        lstsq_lambda_preds_poly_str = np.array(['LSTSQ Lambda Poly FVs' for i in range(eval_size_plot)])\n",
    "\n",
    "        identifier = np.concatenate([real_poly_fvs_str, lambda_train_data_str, lstsq_target_poly_str, inet_poly_fvs_str, lambda_model_preds_str, lstsq_lambda_preds_poly_str])\n",
    "    else:\n",
    "        columns_single.extend(['Lambda Model Preds', 'LSTSQ Lambda Poly FVs', 'I-Net Poly FVs', 'Target Poly FVs', 'Lambda Train Data', 'LSTSQ Target Poly FVs'])\n",
    "        plot_data_single = pd.DataFrame(data=np.column_stack([vars_plot, lambda_model_preds, lstsq_lambda_preds_poly, inet_poly_fvs, real_poly_fvs, lambda_train_data, lstsq_target_poly]), columns=columns_single)\n",
    "        preds_plot_all = np.vstack([lambda_model_preds, lstsq_lambda_preds_poly, inet_poly_fvs, real_poly_fvs, lambda_train_data, lstsq_target_poly]).ravel()\n",
    "        vars_plot_all_preds = np.vstack([vars_plot for i in range(len(columns_single[n:]))])\n",
    "\n",
    "        lambda_model_preds_str = np.array(['Lambda Model Preds' for i in range(eval_size_plot)])\n",
    "        lstsq_lambda_preds_poly_str = np.array(['LSTSQ Lambda Poly FVs' for i in range(eval_size_plot)])        \n",
    "        inet_poly_fvs_str = np.array(['I-Net Poly FVs' for i in range(eval_size_plot)])\n",
    "        real_poly_fvs_str = np.array(['Target Poly FVs' for i in range(eval_size_plot)])\n",
    "        lambda_train_data_str = np.array(['Lambda Train Data' for i in range(lambda_train_data_size)])\n",
    "        lstsq_target_poly_str = np.array(['LSTSQ Target Poly FVs' for i in range(eval_size_plot)])\n",
    "\n",
    "        identifier = np.concatenate([lambda_model_preds_str, lstsq_lambda_preds_poly_str, inet_poly_fvs_str, real_poly_fvs_str, lambda_train_data_str, lstsq_target_poly_str])\n",
    "        \n",
    "    plot_data = pd.DataFrame(data=np.column_stack([vars_plot_all_preds, preds_plot_all]), columns=columns)\n",
    "    plot_data['Identifier'] = identifier       \n",
    "     \n",
    "    \n",
    "    location = './data/plotting/'\n",
    "    folder = paths_dict['path_identifier_interpretation_net_data'] + '/'\n",
    "        \n",
    "    if plot_type == 1:\n",
    "        \n",
    "        \n",
    "        pp = sns.pairplot(data=plot_data,\n",
    "                      #kind='reg',\n",
    "                      hue='Identifier',\n",
    "                      y_vars=['FVs'],\n",
    "                      x_vars=x_vars, \n",
    "                      height=7.5,\n",
    "                      aspect=2)\n",
    "        if evaluate_with_real_function:\n",
    "            file = 'pp3in1_REAL_' + str(rand_index) + '.pdf'        \n",
    "        else:\n",
    "            file = 'pp3in1_PRED_' + str(rand_index) + '.pdf'            \n",
    "        \n",
    "    elif plot_type == 2:\n",
    "\n",
    "        pp = sns.pairplot(data=plot_data,\n",
    "                          #kind='reg',\n",
    "                          hue='Identifier',\n",
    "                          #y_vars=['FVs'],\n",
    "                          #x_vars=x_vars, \n",
    "                          height=10//n)\n",
    "        \n",
    "        if evaluate_with_real_function:        \n",
    "            file = 'pp3in1_extended_REAL_' + str(rand_index) + '.pdf'        \n",
    "        else:\n",
    "            file = 'pp3in1_extended_PRED_' + str(rand_index) + '.pdf'  \n",
    "        \n",
    "    elif plot_type == 3:\n",
    "        \n",
    "        pp = sns.pairplot(data=plot_data_single,\n",
    "                          #kind='reg',\n",
    "                          y_vars=columns_single[n:],\n",
    "                          x_vars=x_vars, \n",
    "                          height=3,\n",
    "                          aspect=3)\n",
    "\n",
    "        if evaluate_with_real_function:        \n",
    "            file = 'pp1_REAL_' + str(rand_index) + '.pdf'        \n",
    "        else:\n",
    "            file = 'pp1_PRED_' + str(rand_index) + '.pdf'            \n",
    "        \n",
    "    path = location + folder + file\n",
    "    pp.savefig(path, format='pdf')\n",
    "    plt.show()    \n",
    "    \n",
    "    if evaluate_with_real_function:\n",
    "        real_poly_VS_lstsq_target_poly_mae = mean_absolute_error(real_poly_fvs, lstsq_target_poly)\n",
    "        real_poly_VS_lstsq_target_poly_r2 = r2_score(real_poly_fvs, lstsq_target_poly)        \n",
    "        \n",
    "        real_poly_VS_inet_poly_mae = mean_absolute_error(real_poly_fvs, inet_poly_fvs)\n",
    "        real_poly_VS_inet_poly_r2 = r2_score(real_poly_fvs, inet_poly_fvs)    \n",
    "        \n",
    "        real_poly_VS_lambda_model_preds_mae = mean_absolute_error(real_poly_fvs, lambda_model_preds)\n",
    "        real_poly_VS_lambda_model_preds_r2 = r2_score(real_poly_fvs, lambda_model_preds)\n",
    "        \n",
    "        real_poly_VS_lstsq_lambda_preds_poly_mae = mean_absolute_error(real_poly_fvs, lstsq_lambda_preds_poly)\n",
    "        real_poly_VS_lstsq_lambda_preds_poly_r2 = r2_score(real_poly_fvs, lstsq_lambda_preds_poly)   \n",
    "        \n",
    "        from prettytable import PrettyTable\n",
    "    \n",
    "        tab = PrettyTable()\n",
    "\n",
    "        tab.field_names = [\"Comparison\",  \"MAE\", \"R2-Score\", \"Poly 1\", \"Poly 2\"]\n",
    "        tab._max_width = {\"Poly 1\" : 50, \"Poly 2\" : 50}\n",
    "        \n",
    "        tab.add_row([\"Target Poly \\n vs. \\n LSTSQ Target Poly \\n\", real_poly_VS_lstsq_target_poly_mae, real_poly_VS_lstsq_target_poly_r2, polynomial_target_string, polynomial_lstsq_target_string])\n",
    "        tab.add_row([\"Target Poly \\n vs. \\n I-Net Poly \\n\", real_poly_VS_inet_poly_mae, real_poly_VS_inet_poly_r2, polynomial_target_string, polynomial_inet_string])\n",
    "        tab.add_row([\"Target Poly \\n vs. \\n Lambda Preds \\n\", real_poly_VS_lambda_model_preds_mae, real_poly_VS_lambda_model_preds_r2, polynomial_target_string, '-'])\n",
    "        tab.add_row([\"Target Poly \\n vs. \\n LSTSQ Lambda Preds Poly \\n\", real_poly_VS_lstsq_lambda_preds_poly_mae, real_poly_VS_lstsq_lambda_preds_poly_r2, polynomial_target_string, polynomial_lstsq_lambda_string])\n",
    "        \n",
    "        print(tab)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        lambda_model_preds_VS_lstsq_lambda_preds_poly_mae = mean_absolute_error(lambda_model_preds, lstsq_lambda_preds_poly)\n",
    "        lambda_model_preds_VS_lstsq_lambda_preds_poly_r2 = r2_score(lambda_model_preds, lstsq_lambda_preds_poly)\n",
    "        \n",
    "        lambda_model_preds_VS_inet_poly_mae = mean_absolute_error(lambda_model_preds, inet_poly_fvs)\n",
    "        lambda_model_preds_VS_inet_poly_r2 = r2_score(lambda_model_preds, inet_poly_fvs)\n",
    "        \n",
    "        lambda_model_preds_VS_real_poly_mae = mean_absolute_error(lambda_model_preds, real_poly_fvs)\n",
    "        lambda_model_preds_VS_real_poly_r2 = r2_score(lambda_model_preds, real_poly_fvs)\n",
    "        \n",
    "        lambda_model_preds_VS_lstsq_target_poly_mae = mean_absolute_error(lambda_model_preds, lstsq_target_poly)\n",
    "        lambda_model_preds_VS_lstsq_target_poly_r2 = r2_score(lambda_model_preds, lstsq_target_poly)    \n",
    "        \n",
    "        from prettytable import PrettyTable\n",
    "    \n",
    "        tab = PrettyTable()\n",
    "\n",
    "        tab.field_names = [\"Comparison\", \"MAE\", \"R2-Score\", \"Poly 1\", \"Poly 2\"]\n",
    "        tab._max_width = {\"Poly 1\" : 50, \"Poly 2\" : 50}\n",
    "        \n",
    "        tab.add_row([\"Lambda Preds \\n vs. \\n LSTSQ Lambda Preds Poly \\n\", lambda_model_preds_VS_lstsq_lambda_preds_poly_mae, lambda_model_preds_VS_lstsq_lambda_preds_poly_r2, '-', polynomial_lstsq_lambda_string])\n",
    "        tab.add_row([\"Lambda Preds \\n vs. \\n I-Net Poly \\n\", lambda_model_preds_VS_inet_poly_mae, lambda_model_preds_VS_inet_poly_r2, '-', polynomial_inet_string])\n",
    "        tab.add_row([\"Lambda Preds \\n vs. \\n Target Poly \\n\", lambda_model_preds_VS_real_poly_mae, lambda_model_preds_VS_real_poly_r2, '-', polynomial_target_string])\n",
    "        tab.add_row([\"Lambda Preds \\n vs. \\n LSTSQ Target Poly \\n\", lambda_model_preds_VS_lstsq_target_poly_mae, lambda_model_preds_VS_lstsq_target_poly_r2, '-', polynomial_lstsq_target_string])\n",
    "        \n",
    "        print(tab)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, function_values_test_list, inet_preds_test_list, rand_index=1, plot_type=2):\n",
    "    \n",
    "    paths_dict = generate_paths(path_type = 'interpretation_net')\n",
    "    \n",
    "    polynomial_target = lambda_net_test_dataset_list[-1].target_polynomial_list[rand_index]\n",
    "    polynomial_lstsq_target = lambda_net_test_dataset_list[-1].lstsq_target_polynomial_list[rand_index]\n",
    "    polynomial_lstsq_lambda = lambda_net_test_dataset_list[-1].lstsq_lambda_pred_polynomial_list[rand_index]\n",
    "    polynomial_inet = inet_preds_test_list[-1][rand_index]\n",
    "    \n",
    "    polynomial_target_string = get_sympy_string_from_coefficients(polynomial_target, force_complete_poly_representation=True, round_digits=4)\n",
    "    polynomial_lstsq_target_string = get_sympy_string_from_coefficients(polynomial_lstsq_target, force_complete_poly_representation=True, round_digits=4)\n",
    "    polynomial_lstsq_lambda_string = get_sympy_string_from_coefficients(polynomial_lstsq_lambda, force_complete_poly_representation=True, round_digits=4)\n",
    "    polynomial_inet_string = get_sympy_string_from_coefficients(polynomial_inet, round_digits=4)\n",
    "    \n",
    "    #print('Target Poly:')\n",
    "    #print_polynomial_from_coefficients(polynomial_target, force_complete_poly_representation=True, round_digits=4)\n",
    "    #print('LSTSQ Target Poly:')\n",
    "    #print_polynomial_from_coefficients(polynomial_lstsq_target, force_complete_poly_representation=True, round_digits=4)\n",
    "    #print('LSTSQ Lambda Poly:')\n",
    "    #print_polynomial_from_coefficients(polynomial_lstsq_lambda, force_complete_poly_representation=True, round_digits=4)\n",
    "    #print('I-Net Poly:')\n",
    "    #print_polynomial_from_coefficients(polynomial_inet, round_digits=4)    \n",
    "    \n",
    "    real_poly_fvs = function_values_test_list[-1][1][rand_index]\n",
    "    lstsq_target_poly = function_values_test_list[-1][3][rand_index]\n",
    "    lambda_model_preds = function_values_test_list[-1][0][rand_index].ravel()\n",
    "    lstsq_lambda_preds_poly = function_values_test_list[-1][2][rand_index]\n",
    "    inet_poly_fvs = function_values_test_list[-1][4][rand_index]  \n",
    "    lambda_train_data = lambda_net_test_dataset_list[-1].y_test_data_list[rand_index]\n",
    "    \n",
    "    x_vars = ['x' + str(i) for i in range(1, n+1)]\n",
    "\n",
    "    columns = x_vars.copy()\n",
    "    columns.append('FVs')\n",
    "\n",
    "    columns_single = x_vars.copy()\n",
    "\n",
    "    eval_size_plot = inet_poly_fvs.shape[0]\n",
    "    lambda_train_data_size = lambda_train_data.shape[0]\n",
    "    vars_plot = lambda_net_test_dataset_list[-1].X_test_data_list[rand_index]    \n",
    "    \n",
    "    if evaluate_with_real_function:\n",
    "        columns_single.extend(['Target Poly FVs', 'Lambda Train Data', 'LSTSQ Target Poly FVs', 'I-Net Poly FVs', 'Lambda Model Preds', 'LSTSQ Lambda Poly FVs'])\n",
    "        plot_data_single = pd.DataFrame(data=np.column_stack([vars_plot, real_poly_fvs, lambda_train_data, lstsq_target_poly, inet_poly_fvs, lambda_model_preds, lstsq_lambda_preds_poly]), columns=columns_single)\n",
    "        preds_plot_all = np.vstack([real_poly_fvs, lambda_train_data, lstsq_target_poly, inet_poly_fvs, lambda_model_preds, lstsq_lambda_preds_poly]).ravel()\n",
    "        vars_plot_all_preds = np.vstack([vars_plot for i in range(len(columns_single[n:]))])\n",
    "\n",
    "        real_poly_fvs_str = np.array(['Target Poly FVs' for i in range(eval_size_plot)])\n",
    "        lambda_train_data_str = np.array(['Lambda Train Data' for i in range(lambda_train_data_size)])\n",
    "        lstsq_target_poly_str = np.array(['LSTSQ Target Poly FVs' for i in range(eval_size_plot)])\n",
    "        inet_poly_fvs_str = np.array(['I-Net Poly FVs' for i in range(eval_size_plot)])\n",
    "        lambda_model_preds_str = np.array(['Lambda Model Preds' for i in range(eval_size_plot)])\n",
    "        lstsq_lambda_preds_poly_str = np.array(['LSTSQ Lambda Poly FVs' for i in range(eval_size_plot)])\n",
    "\n",
    "        identifier = np.concatenate([real_poly_fvs_str, lambda_train_data_str, lstsq_target_poly_str, inet_poly_fvs_str, lambda_model_preds_str, lstsq_lambda_preds_poly_str])\n",
    "    else:\n",
    "        columns_single.extend(['Lambda Model Preds', 'LSTSQ Lambda Poly FVs', 'I-Net Poly FVs', 'Target Poly FVs', 'Lambda Train Data', 'LSTSQ Target Poly FVs'])\n",
    "        #plot_data_single = pd.DataFrame(data=np.column_stack([vars_plot, lambda_model_preds, inet_poly_fvs, real_poly_fvs, lambda_train_data]), columns=columns_single)\n",
    "        #preds_plot_all = np.vstack([lambda_model_preds, inet_poly_fvs, real_poly_fvs, lambda_train_data]).ravel()\n",
    "        plot_data_single = pd.DataFrame(data=np.column_stack([vars_plot, lambda_model_preds, inet_poly_fvs, lambda_train_data]), columns=columns_single)\n",
    "        preds_plot_all = np.vstack([lambda_model_preds, inet_poly_fvs, lambda_train_data]).ravel()        \n",
    "        vars_plot_all_preds = np.vstack([vars_plot for i in range(len(columns_single[n:]))])\n",
    "\n",
    "        lambda_model_preds_str = np.array(['Lambda Model Preds' for i in range(eval_size_plot)])\n",
    "        inet_poly_fvs_str = np.array(['I-Net Poly FVs' for i in range(eval_size_plot)])\n",
    "        #real_poly_fvs_str = np.array(['Target Poly FVs' for i in range(eval_size_plot)])\n",
    "        lambda_train_data_str = np.array(['Lambda Train Data' for i in range(lambda_train_data_size)])\n",
    "\n",
    "        #identifier = np.concatenate([lambda_model_preds_str, inet_poly_fvs_str, real_poly_fvs_str, lambda_train_data_str])\n",
    "        identifier = np.concatenate([lambda_model_preds_str, inet_poly_fvs_str, lambda_train_data_str])\n",
    "        \n",
    "    plot_data = pd.DataFrame(data=np.column_stack([vars_plot_all_preds, preds_plot_all]), columns=columns)\n",
    "    plot_data['Identifier'] = identifier       \n",
    "     \n",
    "    \n",
    "    location = './data/plotting/'\n",
    "    folder = paths_dict['path_identifier_interpretation_net_data'] + '/'\n",
    "        \n",
    "    if plot_type == 1:\n",
    "        \n",
    "        \n",
    "        pp = sns.pairplot(data=plot_data,\n",
    "                      #kind='reg',\n",
    "                      hue='Identifier',\n",
    "                      y_vars=['FVs'],\n",
    "                      x_vars=x_vars, \n",
    "                      height=7.5,\n",
    "                      aspect=2)\n",
    "        if evaluate_with_real_function:\n",
    "            file = 'pp3in1_REAL_' + str(rand_index) + '.pdf'        \n",
    "        else:\n",
    "            file = 'pp3in1_PRED_' + str(rand_index) + '.pdf'            \n",
    "        \n",
    "    elif plot_type == 2:\n",
    "\n",
    "        pp = sns.pairplot(data=plot_data,\n",
    "                          #kind='reg',\n",
    "                          hue='Identifier',\n",
    "                          #y_vars=['FVs'],\n",
    "                          #x_vars=x_vars, \n",
    "                          height=10//n)\n",
    "        \n",
    "        if evaluate_with_real_function:        \n",
    "            file = 'pp3in1_extended_REAL_' + str(rand_index) + '.pdf'        \n",
    "        else:\n",
    "            file = 'pp3in1_extended_PRED_' + str(rand_index) + '.pdf'  \n",
    "        \n",
    "    elif plot_type == 3:\n",
    "        \n",
    "        pp = sns.pairplot(data=plot_data_single,\n",
    "                          #kind='reg',\n",
    "                          y_vars=columns_single[n:],\n",
    "                          x_vars=x_vars, \n",
    "                          height=3,\n",
    "                          aspect=3)\n",
    "\n",
    "        if evaluate_with_real_function:        \n",
    "            file = 'pp1_REAL_' + str(rand_index) + '.pdf'        \n",
    "        else:\n",
    "            file = 'pp1_PRED_' + str(rand_index) + '.pdf'            \n",
    "        \n",
    "    path = location + folder + file\n",
    "    pp.savefig(path, format='pdf')\n",
    "    plt.show()    \n",
    "    \n",
    "    if evaluate_with_real_function:\n",
    "        real_poly_VS_lstsq_target_poly_mae = mean_absolute_error(real_poly_fvs, lstsq_target_poly)\n",
    "        real_poly_VS_lstsq_target_poly_r2 = r2_score(real_poly_fvs, lstsq_target_poly)        \n",
    "        \n",
    "        real_poly_VS_inet_poly_mae = mean_absolute_error(real_poly_fvs, inet_poly_fvs)\n",
    "        real_poly_VS_inet_poly_r2 = r2_score(real_poly_fvs, inet_poly_fvs)    \n",
    "        \n",
    "        real_poly_VS_lambda_model_preds_mae = mean_absolute_error(real_poly_fvs, lambda_model_preds)\n",
    "        real_poly_VS_lambda_model_preds_r2 = r2_score(real_poly_fvs, lambda_model_preds)\n",
    "        \n",
    "        real_poly_VS_lstsq_lambda_preds_poly_mae = mean_absolute_error(real_poly_fvs, lstsq_lambda_preds_poly)\n",
    "        real_poly_VS_lstsq_lambda_preds_poly_r2 = r2_score(real_poly_fvs, lstsq_lambda_preds_poly)   \n",
    "        \n",
    "        from prettytable import PrettyTable\n",
    "    \n",
    "        tab = PrettyTable()\n",
    "\n",
    "        tab.field_names = [\"Comparison\",  \"MAE\", \"R2-Score\", \"Poly 1\", \"Poly 2\"]\n",
    "        tab._max_width = {\"Poly 1\" : 50, \"Poly 2\" : 50}\n",
    "        \n",
    "        tab.add_row([\"Target Poly \\n vs. \\n LSTSQ Target Poly \\n\", real_poly_VS_lstsq_target_poly_mae, real_poly_VS_lstsq_target_poly_r2, polynomial_target_string, polynomial_lstsq_target_string])\n",
    "        tab.add_row([\"Target Poly \\n vs. \\n I-Net Poly \\n\", real_poly_VS_inet_poly_mae, real_poly_VS_inet_poly_r2, polynomial_target_string, polynomial_inet_string])\n",
    "        tab.add_row([\"Target Poly \\n vs. \\n Lambda Preds \\n\", real_poly_VS_lambda_model_preds_mae, real_poly_VS_lambda_model_preds_r2, polynomial_target_string, '-'])\n",
    "        tab.add_row([\"Target Poly \\n vs. \\n LSTSQ Lambda Preds Poly \\n\", real_poly_VS_lstsq_lambda_preds_poly_mae, real_poly_VS_lstsq_lambda_preds_poly_r2, polynomial_target_string, polynomial_lstsq_lambda_string])\n",
    "        \n",
    "        print(tab)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        lambda_model_preds_VS_lstsq_lambda_preds_poly_mae = mean_absolute_error(lambda_model_preds, lstsq_lambda_preds_poly)\n",
    "        lambda_model_preds_VS_lstsq_lambda_preds_poly_r2 = r2_score(lambda_model_preds, lstsq_lambda_preds_poly)\n",
    "        \n",
    "        lambda_model_preds_VS_inet_poly_mae = mean_absolute_error(lambda_model_preds, inet_poly_fvs)\n",
    "        lambda_model_preds_VS_inet_poly_r2 = r2_score(lambda_model_preds, inet_poly_fvs)\n",
    "        \n",
    "        lambda_model_preds_VS_real_poly_mae = mean_absolute_error(lambda_model_preds, real_poly_fvs)\n",
    "        lambda_model_preds_VS_real_poly_r2 = r2_score(lambda_model_preds, real_poly_fvs)\n",
    "        \n",
    "        lambda_model_preds_VS_lstsq_target_poly_mae = mean_absolute_error(lambda_model_preds, lstsq_target_poly)\n",
    "        lambda_model_preds_VS_lstsq_target_poly_r2 = r2_score(lambda_model_preds, lstsq_target_poly)    \n",
    "        \n",
    "        from prettytable import PrettyTable\n",
    "    \n",
    "        tab = PrettyTable()\n",
    "\n",
    "        tab.field_names = [\"Comparison\", \"MAE\", \"R2-Score\", \"Poly 1\", \"Poly 2\"]\n",
    "        tab._max_width = {\"Poly 1\" : 50, \"Poly 2\" : 50}\n",
    "        \n",
    "        tab.add_row([\"Lambda Preds \\n vs. \\n LSTSQ Lambda Preds Poly \\n\", lambda_model_preds_VS_lstsq_lambda_preds_poly_mae, lambda_model_preds_VS_lstsq_lambda_preds_poly_r2, '-', polynomial_lstsq_lambda_string])\n",
    "        tab.add_row([\"Lambda Preds \\n vs. \\n I-Net Poly \\n\", lambda_model_preds_VS_inet_poly_mae, lambda_model_preds_VS_inet_poly_r2, '-', polynomial_inet_string])\n",
    "        tab.add_row([\"Lambda Preds \\n vs. \\n Target Poly \\n\", lambda_model_preds_VS_real_poly_mae, lambda_model_preds_VS_real_poly_r2, '-', polynomial_target_string])\n",
    "        tab.add_row([\"Lambda Preds \\n vs. \\n LSTSQ Target Poly \\n\", lambda_model_preds_VS_lstsq_target_poly_mae, lambda_model_preds_VS_lstsq_target_poly_r2, '-', polynomial_lstsq_target_string])\n",
    "        \n",
    "        print(tab)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:52.425282Z",
     "start_time": "2021-01-07T15:49:51.529992Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      inet_preds_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:57.631017Z",
     "start_time": "2021-01-07T15:49:52.427326Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      inet_preds_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:59.108419Z",
     "start_time": "2021-01-07T15:49:57.634294Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      inet_preds_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (RANDOM GUESS) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:50:04.140254Z",
     "start_time": "2021-01-07T15:50:03.647192Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_random_polynomials = np.random.uniform(low=-10, high=10, size=(len(lambda_net_test_dataset_list[-1]), sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.030192Z",
     "start_time": "2021-01-07T15:50:04.141837Z"
    }
   },
   "outputs": [],
   "source": [
    "true_fv_test = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].test_data_list, force_complete_poly_representation=True)\n",
    "random_fv_test = parallel_fv_calculation_from_polynomial(list_of_random_polynomials, lambda_net_test_dataset_list[-1].test_data_list, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.064612Z",
     "start_time": "2021-01-07T16:08:23.032372Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error Coefficients: ' + str(np.round(mean_absolute_error(lambda_net_test_dataset_list[-1].target_polynomial_list, list_of_random_polynomials), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.204426Z",
     "start_time": "2021-01-07T16:08:23.066205Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, random_fv_test), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (EDUCATED GUESS/MEAN PREDICTION) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:31.911007Z",
     "start_time": "2021-01-07T16:08:23.205879Z"
    }
   },
   "outputs": [],
   "source": [
    "true_fv_train = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].test_data_list, force_complete_poly_representation=True)\n",
    "\n",
    "mean_fv = np.mean(true_fv_train)\n",
    "mean_fv_pred_test = [mean_fv for _ in range(true_fv_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.029945Z",
     "start_time": "2021-01-07T16:17:31.912980Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Educated Guess/Mean Prediction Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, mean_fv_pred_test), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.508984Z",
     "start_time": "2021-01-07T16:17:32.031355Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "base_model = generate_base_model()\n",
    "random_evaluation_dataset = np.random.uniform(low=x_min, high=x_max, size=(random_evaluation_dataset_size, n))\n",
    "#random_evaluation_dataset = lambda_train_input_train_split[0]#lambda_train_input[0] #JUST [0] HERE BECAUSE EVALUATION ALWAYS ON THE SAME DATASET FOR ALL!!\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)\n",
    "\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "#X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "\n",
    "seed_in_inet_training = False\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "seed_in_inet_training = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
