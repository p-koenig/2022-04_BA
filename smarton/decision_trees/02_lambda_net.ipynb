{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Î»-Nets for I-Net training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'data': {\n",
    "        'd': 3, #degree\n",
    "        'n': 5, #number of variables\n",
    "        'monomial_vars': None, #int or None\n",
    "        'laurent': False, #use Laurent polynomials (negative degree with up to -d)\n",
    "        'neg_d': 0,#int or None\n",
    "        'neg_d_prob': 0,\n",
    "        'sparsity': None,\n",
    "        'sample_sparsity': 5,\n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        'a_max': 1,\n",
    "        'a_min': -1,\n",
    "        'polynomial_data_size': 50000,  #number of generated polynomials (for loading)\n",
    "        'lambda_nets_total': 50000, #number of lambda-nets to train\n",
    "        'noise': 0,\n",
    "        'noise_distrib': 'normal', #'normal', 'uniform', 'beta', 'Gamma', 'laplace'\n",
    "        \n",
    "        'border_min': 0.2, #needs to be between 0 and (x_max-x_min)/2\n",
    "        'border_max': 0.4,\n",
    "        'lower_degree_prob': 0.5,\n",
    "        'a_zero_prob': 0.25,\n",
    "        'a_random_prob': 0.1,         \n",
    "        \n",
    "        'same_training_all_lambda_nets': False,\n",
    "\n",
    "        'fixed_seed_lambda_training': True,\n",
    "        'fixed_initialization_lambda_training': False,\n",
    "        'number_different_lambda_trainings': 1,\n",
    "    },\n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, #if early stopping is used, multi_epoch_analysis is deactivated\n",
    "        'early_stopping_min_delta_lambda': 1e-4,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout': 0,\n",
    "        'lambda_network_layers': [5*'sample_sparsity'],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'mae',\n",
    "        'number_of_lambda_weights': None,\n",
    "        'lambda_dataset_size': 5000, #lambda-net training dataset size\n",
    "    },    \n",
    "    'evaluation': {   \n",
    "        'inet_holdout_seed_evaluation': False,\n",
    "        \n",
    "        #set if multi_epoch_analysis should be performed\n",
    "        'multi_epoch_analysis': False,\n",
    "        'each_epochs_save_lambda': 100,\n",
    "        'epoch_start': 0, #use to skip first epochs in multi_epoch_analysis\n",
    "    \n",
    "        'random_evaluation_dataset_size': 500,\n",
    "    },    \n",
    "    'computation':{\n",
    "        'n_jobs': -3,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '0',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product       # forms cartesian products\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from more_itertools import random_product \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import math\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "from IPython.display import Image\n",
    "\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import random \n",
    "\n",
    "\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n] \n",
    "\n",
    "multi_epoch_analysis = False if early_stopping_lambda else multi_epoch_analysis #deactivate multi_epoch_analysis if early stopping is used\n",
    "\n",
    "each_epochs_save_lambda = each_epochs_save_lambda if multi_epoch_analysis else epochs_lambda\n",
    "\n",
    "if same_training_all_lambda_nets:\n",
    "    training_string = '_same'\n",
    "else:\n",
    "    training_string = '_diverse'\n",
    "    \n",
    "    \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 56\n",
      "[[3, 0, 0, 0, 0], [2, 1, 0, 0, 0], [2, 0, 1, 0, 0], [2, 0, 0, 1, 0], [2, 0, 0, 0, 1], [2, 0, 0, 0, 0], [1, 2, 0, 0, 0], [1, 1, 1, 0, 0], [1, 1, 0, 1, 0], [1, 1, 0, 0, 1], [1, 1, 0, 0, 0], [1, 0, 2, 0, 0], [1, 0, 1, 1, 0], [1, 0, 1, 0, 1], [1, 0, 1, 0, 0], [1, 0, 0, 2, 0], [1, 0, 0, 1, 1], [1, 0, 0, 1, 0], [1, 0, 0, 0, 2], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0], [0, 3, 0, 0, 0], [0, 2, 1, 0, 0], [0, 2, 0, 1, 0], [0, 2, 0, 0, 1], [0, 2, 0, 0, 0], [0, 1, 2, 0, 0], [0, 1, 1, 1, 0], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0], [0, 1, 0, 2, 0], [0, 1, 0, 1, 1], [0, 1, 0, 1, 0], [0, 1, 0, 0, 2], [0, 1, 0, 0, 1], [0, 1, 0, 0, 0], [0, 0, 3, 0, 0], [0, 0, 2, 1, 0], [0, 0, 2, 0, 1], [0, 0, 2, 0, 0], [0, 0, 1, 2, 0], [0, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 0, 1, 0, 2], [0, 0, 1, 0, 1], [0, 0, 1, 0, 0], [0, 0, 0, 3, 0], [0, 0, 0, 2, 1], [0, 0, 0, 2, 0], [0, 0, 0, 1, 2], [0, 0, 0, 1, 1], [0, 0, 0, 1, 0], [0, 0, 0, 0, 3], [0, 0, 0, 0, 2], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "from utilities.utility_functions import flatten, rec_gen, gen_monomial_identifier_list\n",
    "\n",
    "list_of_monomial_identifiers_extended = []\n",
    "\n",
    "if laurent:\n",
    "    variable_sets = [list(flatten([[_d for _d in range(d+1)], [-_d for _d in range(1, neg_d+1)]])) for _ in range(n)]\n",
    "    list_of_monomial_identifiers_extended = rec_gen(variable_sets)    \n",
    "        \n",
    "    print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "    #print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "    #print('Sparsity:' + str(sparsity))\n",
    "    if len(list_of_monomial_identifiers_extended) < 500:\n",
    "        print(list_of_monomial_identifiers_extended)     \n",
    "        \n",
    "    list_of_monomial_identifiers = []\n",
    "    for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "        if np.sum(monomial_identifier) <= d:\n",
    "            if monomial_vars == None or len(list(filter(lambda x: x != 0, monomial_identifier))) <= monomial_vars:\n",
    "                list_of_monomial_identifiers.append(monomial_identifier)        \n",
    "else:\n",
    "    variable_list = ['x'+ str(i) for i in range(n)]\n",
    "    list_of_monomial_identifiers = gen_monomial_identifier_list(variable_list, d, n)\n",
    "            \n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "#print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(sparsity))\n",
    "#print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'KeyError'>\n",
      "<class 'KeyError'>\n",
      "<class 'KeyError'>\n"
     ]
    }
   ],
   "source": [
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "config['evaluation']['multi_epoch_analysis'] = multi_epoch_analysis\n",
    "\n",
    "config['evaluation']['each_epochs_save_lambda'] = each_epochs_save_lambda\n",
    "\n",
    "config['data']['sparsity'] = nCr(config['data']['n']+config['data']['d'], config['data']['d']) if not laurent else len(list_of_monomial_identifiers)\n",
    "\n",
    "config['data']['sample_sparsity'] = config['data']['sparsity'] if config['data']['sample_sparsity'] == None else config['data']['sample_sparsity']\n",
    "    \n",
    "transformed_layers = []\n",
    "for layer in config['lambda_net']['lambda_network_layers']:\n",
    "    if type(layer) == str:\n",
    "        transformed_layers.append(layer.count('sample_sparsity')*config['data']['sample_sparsity'])\n",
    "    else:\n",
    "        transformed_layers.append(layer)\n",
    "config['lambda_net']['lambda_network_layers'] = transformed_layers\n",
    "\n",
    "layers_with_input_output = list(flatten([[config['data']['n']], config['lambda_net']['lambda_network_layers'], [1]]))\n",
    "number_of_lambda_weights = 0\n",
    "for i in range(len(layers_with_input_output)-1):\n",
    "    number_of_lambda_weights += (layers_with_input_output[i]+1)*layers_with_input_output[i+1]  \n",
    "config['lambda_net']['number_of_lambda_weights'] = number_of_lambda_weights\n",
    "    \n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "initialize_utility_functions_config_from_curent_notebook(config)\n",
    "initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "initialize_metrics_config_from_curent_notebook(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(path_type='lambda_net'))\n",
    "generate_directory_structure()\n",
    "generate_lambda_net_directory()\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lnets_50000_25-1000e_ES0.0001_64b_adam_mae_train_5000_diffX_1-FixSeed_42/var_5_d_3_negd_0_prob_0_spars_5_amin_-1_amax_1_xdist_uniform_noise_normal_0bmin0.2bmax0.4lowd0.5azero0.25arand0.1\n",
      "poly_50000_train_5000_var_5_d_3_negd_0_prob_0_spars_5_amin_-1_amax_1_xdist_uniform_noise_normal_0bmin0.2bmax0.4lowd0.5azero0.25arand0.1_diffX\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_lambda_net_data)\n",
    "\n",
    "print(path_identifier_polynomial_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_network_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T09:46:11.182937Z",
     "start_time": "2021-01-17T09:44:31.797522Z"
    }
   },
   "outputs": [],
   "source": [
    "path_polynomials = './data/saved_polynomial_lists/polynomials_sample_' + path_identifier_polynomial_data + '.csv'\n",
    "polynomials_list_df = pd.read_csv(path_polynomials)\n",
    "\n",
    "path_X_data = './data/saved_polynomial_lists/X_sample_' + path_identifier_polynomial_data + '.pkl'\n",
    "with open(path_X_data, 'rb') as f:\n",
    "    X_data_list = pickle.load(f)\n",
    "    \n",
    "path_y_data = './data/saved_polynomial_lists/y_sample_' + path_identifier_polynomial_data + '.pkl'\n",
    "with open(path_y_data, 'rb') as f:\n",
    "    y_data_list = pickle.load(f)\n",
    "    \n",
    "if lambda_nets_total < polynomial_data_size:\n",
    "    polynomials_list_df = polynomials_list_df.sample(n=lambda_nets_total, random_state=RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    X_data_list = random.sample(X_data_list, lambda_nets_total)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    y_data_list = random.sample(y_data_list, lambda_nets_total)\n",
    "    random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T09:46:12.626401Z",
     "start_time": "2021-01-17T09:46:12.608200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.612</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.608</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.122</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.663</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a     b     c     d     e\n",
       "0 0.375 0.951 0.732 0.599 0.156\n",
       "1 0.156 0.058 0.866 0.601 0.708\n",
       "2 0.021 0.970 0.832 0.212 0.182\n",
       "3 0.183 0.304 0.525 0.432 0.291\n",
       "4 0.612 0.139 0.292 0.366 0.456\n",
       "5 0.785 0.200 0.514 0.592 0.046\n",
       "6 0.608 0.171 0.065 0.949 0.966\n",
       "7 0.808 0.305 0.098 0.684 0.440\n",
       "8 0.122 0.495 0.034 0.909 0.259\n",
       "9 0.663 0.312 0.520 0.547 0.185"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T09:46:12.636995Z",
     "start_time": "2021-01-17T09:46:12.629349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   result\n",
       "0   0.890\n",
       "1   0.471\n",
       "2   0.883\n",
       "3   0.095\n",
       "4   0.158\n",
       "5   0.329\n",
       "6   0.330\n",
       "7   0.396\n",
       "8   0.151\n",
       "9   0.249"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_list[0][1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00000   0.000\n",
       "00001   0.000\n",
       "00002   0.464\n",
       "00003   0.000\n",
       "00010   0.000\n",
       "00011   0.000\n",
       "00012   0.000\n",
       "00020   0.000\n",
       "00021   0.000\n",
       "00030   0.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00000   0.000\n",
       "00001   0.000\n",
       "00002   0.464\n",
       "00003   0.000\n",
       "00010   0.000\n",
       "00011   0.000\n",
       "00012   0.000\n",
       "00020   0.000\n",
       "00021   0.000\n",
       "00030   0.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_list[0][0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T17:06:36.919643Z",
     "start_time": "2020-09-16T17:06:36.912904Z"
    }
   },
   "source": [
    "## Lambda Network Training + Weigh/Bias saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca95feddf66b4584b73749bf12e3d8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.1min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 54.0min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 68.6min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 84.7min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 102.9min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 122.5min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 133.7min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.0min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 54.2min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 84.7min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 102.7min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 122.0min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 133.5min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 69.0min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 85.3min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 103.5min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 123.5min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 134.7min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 69.3min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 85.6min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 103.4min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 123.2min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 134.7min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68397207f0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68394cd790>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839590fd0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683975c400>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839c7d160>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68398ba250>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839f317f0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683955d700>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convertWARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839e9e1c0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683966e070>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68397a0400>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839bedca0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683a213310>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683954db20>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839f6b9d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839489640>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839f31880>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839419310>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839ba9fd0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839aa85e0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6839454c40>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68394f9820>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 54.3min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 69.0min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 85.3min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 103.2min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 123.1min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 134.5min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683645f370>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836472280>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683736b640>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836fdc7c0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836556f10>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836582cd0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836582550>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836c3a5e0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683650a430>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683654e6d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683705bf10>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836f5d1c0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836592f10>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836d3b0d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68364f0700>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68364cf310>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683627a310>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68364cf790>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683660b190>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836194640>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836456a60>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6836ad50d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.6min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 69.1min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 85.2min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 103.1min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 122.9min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 134.5min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683dc90b20>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d3a72b0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683dbcd4c0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d197dc0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d8b6d60>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683dd8a970>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d969820>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d81bd00>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d8ce5b0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d216f10>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683ddcc9a0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68322ea6d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683da12970>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d80b100>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d227880>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d237f70>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d174040>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d0fd070>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d0eba00>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d861af0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683d3eb4f0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683dcabdc0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 53.8min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 68.8min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 85.3min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 103.3min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 123.1min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 134.7min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f5db220>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f5ebdf0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f6b1ac0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f825670>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f5e3190>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682fe1b8e0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f3284c0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6830310b20>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682fd4d940>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f5eb6d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683001a4c0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f9bfc70>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682fd79640>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f98ce50>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f7858e0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f6626a0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f683015f0d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f551d00>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f58dfd0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6830310370>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f2ed550>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682f4c9df0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 54.1min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 69.2min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 85.1min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 103.1min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 122.8min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 134.4min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682c300e80>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682d42dfd0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682cd2ec10>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682cd1ee80>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682cf82940>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682c34b730>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682d093910>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682c3e5310>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682d42dc10>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682c388f10>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682c686d00>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682cd2e910>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682c665b50>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682d32b2e0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682cc62640>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682c287ac0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682d4792b0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682d20ad90>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682d0cd430>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682cdbe1f0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682cb059a0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682cb61520>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 54.8min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 70.0min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 86.2min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 104.4min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 123.8min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 135.7min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend MultiprocessingBackend with 22 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68292cf670>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682a0af520>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6829fa07f0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682a204cd0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68293896a0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6829f04c70>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68298a0970>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68296f1b80>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682a3d0910>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682a195160>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6829e30610>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682a016370>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6829877070>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68296805b0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6829cda970>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6829f8b9d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68298190d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f682a3a5b80>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6829f30a00>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6829e0ec40>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f68295ab4c0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f6829bdd0d0>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-3)]: Done 244 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-3)]: Done 468 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-3)]: Done 756 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-3)]: Done 1108 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-3)]: Done 1524 tasks      | elapsed: 41.6min\n",
      "[Parallel(n_jobs=-3)]: Done 2004 tasks      | elapsed: 54.3min\n",
      "[Parallel(n_jobs=-3)]: Done 2548 tasks      | elapsed: 69.5min\n",
      "[Parallel(n_jobs=-3)]: Done 3156 tasks      | elapsed: 85.7min\n",
      "[Parallel(n_jobs=-3)]: Done 3828 tasks      | elapsed: 103.6min\n",
      "[Parallel(n_jobs=-3)]: Done 4564 tasks      | elapsed: 123.6min\n",
      "[Parallel(n_jobs=-3)]: Done 5000 out of 5000 | elapsed: 135.4min finished\n"
     ]
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "clf_list = []\n",
    "chunksize = 5000 if lambda_nets_total > 50000 else max(lambda_nets_total//10, min(50, lambda_nets_total))\n",
    "X_data_list_splits = list(chunks(X_data_list, chunksize))\n",
    "y_data_list_splits = list(chunks(y_data_list, chunksize))\n",
    "\n",
    "max_seed = 2147483646\n",
    "seed_list = random.sample(range(0, max_seed), number_different_lambda_trainings)\n",
    "chunk_multiplier = 0\n",
    "\n",
    "for X_data_list_split, y_data_list_split in tqdm(zip(X_data_list_splits, y_data_list_splits), total=max(len(X_data_list_splits), len(y_data_list_splits))):\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='multiprocessing')\n",
    "    clf_sublist = parallel(delayed(train_nn)(chunksize*chunk_multiplier+index, X_data[1].values, y_data[1].values, X_data[0], seed_list, return_history=True, each_epochs_save=each_epochs_save_lambda, printing=True) for index, (X_data, y_data) in enumerate(zip(X_data_list_split, y_data_list_split)))  \n",
    "    clf_list.extend(clf_sublist)\n",
    "    del parallel\n",
    "    chunk_multiplier +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    0.015, max:    0.383, cur:    0.015)\n",
      "\tvalidation       \t (min:    0.015, max:    0.271, cur:    0.017)\n",
      "mae\n",
      "\ttraining         \t (min:    0.015, max:    0.383, cur:    0.015)\n",
      "\tvalidation       \t (min:    0.015, max:    0.271, cur:    0.017)\n",
      "r2_keras_loss\n",
      "\ttraining         \t (min:   -0.996, max:    1.043, cur:   -0.996)\n",
      "\tvalidation       \t (min:   -0.996, max:    0.066, cur:   -0.996)\n",
      "root_mean_squared_error\n",
      "\ttraining         \t (min:    0.020, max:    0.472, cur:    0.020)\n",
      "\tvalidation       \t (min:    0.020, max:    0.338, cur:    0.022)\n",
      "WARNING: AutoGraph could not transform <function calculate_monomial_without_coefficient_tf_wrapper at 0x7f68491cf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unknown node type <gast.gast.Assign object at 0x7f681fbcba60>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "rand_index = np.random.randint(lambda_nets_total)\n",
    "\n",
    "random_network = train_nn(rand_index, X_data_list[rand_index][1], y_data_list[rand_index][1], X_data_list[rand_index][0], seed_list, callbacks=[PlotLossesKerasTF()], return_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Plot Lambda-Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059bdfff8b5e4ac79763debc342a6787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb053fa8a96c45cf85d6078102b79439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_list_total = []\n",
    "metric_list_total = []\n",
    "\n",
    "val_loss_list_total = []\n",
    "val_metric_list_total = []\n",
    "\n",
    "index_list = []\n",
    "\n",
    "\n",
    "max_training_epochs = 0\n",
    "for _, entry in tqdm(enumerate(clf_list)):\n",
    "    history = entry[3]\n",
    "    \n",
    "    current_training_epochs = len(history[list(history.keys())[0]])\n",
    "    max_training_epochs = max(max_training_epochs, current_training_epochs)\n",
    "\n",
    "\n",
    "for _, entry in tqdm(enumerate(clf_list)):\n",
    "    history = entry[3]\n",
    "    index = entry[0][0]\n",
    "    \n",
    "    current_training_epochs = len(history[list(history.keys())[0]])\n",
    "    \n",
    "    loss_list = np.full(max_training_epochs, np.nan)\n",
    "    metric_list = np.full(max_training_epochs, np.nan)\n",
    "    val_loss_list = np.full(max_training_epochs, np.nan)\n",
    "    val_metric_list = np.full(max_training_epochs, np.nan) \n",
    "\n",
    "    for i in range(current_training_epochs):  \n",
    "        loss_list[i] = history[list(history.keys())[0]][i]\n",
    "        metric_list[i] = history[list(history.keys())[1]][i]\n",
    "        val_loss_list[i] = history[list(history.keys())[len(history.keys())//2]][i]\n",
    "        val_metric_list[i] = history[list(history.keys())[len(history.keys())//2+1]][i]\n",
    "    \n",
    "    index_list.append([index])\n",
    "    loss_list_total.append(loss_list)\n",
    "    metric_list_total.append(metric_list)\n",
    "    val_loss_list_total.append(val_loss_list)\n",
    "    val_metric_list_total.append(val_metric_list)\n",
    "\n",
    "loss_df = pd.DataFrame(data=np.hstack([index_list, loss_list_total]), columns=list(flatten(['index', [list(history.keys())[0] + '_epoch_' + str(i+1) for i in range(max_training_epochs)]])))\n",
    "#loss_df['index'] = loss_df['index'].astype(int)\n",
    "metric_df = pd.DataFrame(data=np.hstack([index_list, metric_list_total]), columns=list(flatten(['index', [list(history.keys())[1] + '_epoch_' + str(i+1) for i in range(max_training_epochs)]]))) \n",
    "#metric_df['index'] = metric_df['index'].astype(int)\n",
    "val_loss_df = pd.DataFrame(data=np.hstack([index_list, val_loss_list_total]), columns=list(flatten(['index', [list(history.keys())[len(history.keys())//2] + '_epoch_' + str(i+1) for i in range(max_training_epochs)]])))\n",
    "#val_loss_df['index'] = val_loss_df['index'].astype(int)\n",
    "val_metric_df = pd.DataFrame(data=np.hstack([index_list, val_metric_list_total]), columns=list(flatten(['index', [list(history.keys())[len(history.keys())//2+1] + '_epoch_' + str(i+1) for i in range(max_training_epochs)]]))) \n",
    "#val_metric_df['index'] = val_metric_df['index'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.875Z"
    }
   },
   "outputs": [],
   "source": [
    "path_loss = './data/weights/weights_' + path_identifier_lambda_net_data + '/history_' + list(history.keys())[0] + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "path_metric = './data/weights/weights_' + path_identifier_lambda_net_data + '/history_' + list(history.keys())[1] + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "path_val_loss = './data/weights/weights_' + path_identifier_lambda_net_data + '/history_' + list(history.keys())[len(history.keys())//2] + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "path_val_metric = './data/weights/weights_' + path_identifier_lambda_net_data + '/history_' + list(history.keys())[len(history.keys())//2+1] + '_epoch_' + str(epochs_lambda).zfill(3) + '.txt'\n",
    "\n",
    "loss_df.to_csv(path_loss, index=None, sep=',')\n",
    "metric_df.to_csv(path_metric, index=None, sep=',')\n",
    "val_loss_df.to_csv(path_val_loss, index=None, sep=',')\n",
    "val_metric_df.to_csv(path_val_metric, index=None, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>loss_epoch_1</th>\n",
       "      <th>loss_epoch_2</th>\n",
       "      <th>loss_epoch_3</th>\n",
       "      <th>loss_epoch_4</th>\n",
       "      <th>loss_epoch_5</th>\n",
       "      <th>loss_epoch_6</th>\n",
       "      <th>loss_epoch_7</th>\n",
       "      <th>loss_epoch_8</th>\n",
       "      <th>loss_epoch_9</th>\n",
       "      <th>loss_epoch_10</th>\n",
       "      <th>loss_epoch_11</th>\n",
       "      <th>loss_epoch_12</th>\n",
       "      <th>loss_epoch_13</th>\n",
       "      <th>loss_epoch_14</th>\n",
       "      <th>loss_epoch_15</th>\n",
       "      <th>loss_epoch_16</th>\n",
       "      <th>loss_epoch_17</th>\n",
       "      <th>loss_epoch_18</th>\n",
       "      <th>loss_epoch_19</th>\n",
       "      <th>loss_epoch_20</th>\n",
       "      <th>loss_epoch_21</th>\n",
       "      <th>loss_epoch_22</th>\n",
       "      <th>loss_epoch_23</th>\n",
       "      <th>loss_epoch_24</th>\n",
       "      <th>loss_epoch_25</th>\n",
       "      <th>loss_epoch_26</th>\n",
       "      <th>loss_epoch_27</th>\n",
       "      <th>loss_epoch_28</th>\n",
       "      <th>loss_epoch_29</th>\n",
       "      <th>loss_epoch_30</th>\n",
       "      <th>loss_epoch_31</th>\n",
       "      <th>loss_epoch_32</th>\n",
       "      <th>loss_epoch_33</th>\n",
       "      <th>loss_epoch_34</th>\n",
       "      <th>loss_epoch_35</th>\n",
       "      <th>loss_epoch_36</th>\n",
       "      <th>loss_epoch_37</th>\n",
       "      <th>loss_epoch_38</th>\n",
       "      <th>loss_epoch_39</th>\n",
       "      <th>loss_epoch_40</th>\n",
       "      <th>loss_epoch_41</th>\n",
       "      <th>loss_epoch_42</th>\n",
       "      <th>loss_epoch_43</th>\n",
       "      <th>loss_epoch_44</th>\n",
       "      <th>loss_epoch_45</th>\n",
       "      <th>loss_epoch_46</th>\n",
       "      <th>loss_epoch_47</th>\n",
       "      <th>loss_epoch_48</th>\n",
       "      <th>loss_epoch_49</th>\n",
       "      <th>loss_epoch_50</th>\n",
       "      <th>loss_epoch_51</th>\n",
       "      <th>loss_epoch_52</th>\n",
       "      <th>loss_epoch_53</th>\n",
       "      <th>loss_epoch_54</th>\n",
       "      <th>loss_epoch_55</th>\n",
       "      <th>loss_epoch_56</th>\n",
       "      <th>loss_epoch_57</th>\n",
       "      <th>loss_epoch_58</th>\n",
       "      <th>loss_epoch_59</th>\n",
       "      <th>loss_epoch_60</th>\n",
       "      <th>loss_epoch_61</th>\n",
       "      <th>loss_epoch_62</th>\n",
       "      <th>loss_epoch_63</th>\n",
       "      <th>loss_epoch_64</th>\n",
       "      <th>loss_epoch_65</th>\n",
       "      <th>loss_epoch_66</th>\n",
       "      <th>loss_epoch_67</th>\n",
       "      <th>loss_epoch_68</th>\n",
       "      <th>loss_epoch_69</th>\n",
       "      <th>loss_epoch_70</th>\n",
       "      <th>loss_epoch_71</th>\n",
       "      <th>loss_epoch_72</th>\n",
       "      <th>loss_epoch_73</th>\n",
       "      <th>loss_epoch_74</th>\n",
       "      <th>loss_epoch_75</th>\n",
       "      <th>loss_epoch_76</th>\n",
       "      <th>loss_epoch_77</th>\n",
       "      <th>loss_epoch_78</th>\n",
       "      <th>loss_epoch_79</th>\n",
       "      <th>loss_epoch_80</th>\n",
       "      <th>loss_epoch_81</th>\n",
       "      <th>loss_epoch_82</th>\n",
       "      <th>loss_epoch_83</th>\n",
       "      <th>loss_epoch_84</th>\n",
       "      <th>loss_epoch_85</th>\n",
       "      <th>loss_epoch_86</th>\n",
       "      <th>loss_epoch_87</th>\n",
       "      <th>loss_epoch_88</th>\n",
       "      <th>loss_epoch_89</th>\n",
       "      <th>loss_epoch_90</th>\n",
       "      <th>loss_epoch_91</th>\n",
       "      <th>loss_epoch_92</th>\n",
       "      <th>loss_epoch_93</th>\n",
       "      <th>loss_epoch_94</th>\n",
       "      <th>loss_epoch_95</th>\n",
       "      <th>loss_epoch_96</th>\n",
       "      <th>loss_epoch_97</th>\n",
       "      <th>loss_epoch_98</th>\n",
       "      <th>loss_epoch_99</th>\n",
       "      <th>loss_epoch_100</th>\n",
       "      <th>loss_epoch_101</th>\n",
       "      <th>loss_epoch_102</th>\n",
       "      <th>loss_epoch_103</th>\n",
       "      <th>loss_epoch_104</th>\n",
       "      <th>loss_epoch_105</th>\n",
       "      <th>loss_epoch_106</th>\n",
       "      <th>loss_epoch_107</th>\n",
       "      <th>loss_epoch_108</th>\n",
       "      <th>loss_epoch_109</th>\n",
       "      <th>loss_epoch_110</th>\n",
       "      <th>loss_epoch_111</th>\n",
       "      <th>loss_epoch_112</th>\n",
       "      <th>loss_epoch_113</th>\n",
       "      <th>loss_epoch_114</th>\n",
       "      <th>loss_epoch_115</th>\n",
       "      <th>loss_epoch_116</th>\n",
       "      <th>loss_epoch_117</th>\n",
       "      <th>loss_epoch_118</th>\n",
       "      <th>loss_epoch_119</th>\n",
       "      <th>loss_epoch_120</th>\n",
       "      <th>loss_epoch_121</th>\n",
       "      <th>loss_epoch_122</th>\n",
       "      <th>loss_epoch_123</th>\n",
       "      <th>loss_epoch_124</th>\n",
       "      <th>loss_epoch_125</th>\n",
       "      <th>loss_epoch_126</th>\n",
       "      <th>loss_epoch_127</th>\n",
       "      <th>loss_epoch_128</th>\n",
       "      <th>loss_epoch_129</th>\n",
       "      <th>loss_epoch_130</th>\n",
       "      <th>loss_epoch_131</th>\n",
       "      <th>loss_epoch_132</th>\n",
       "      <th>loss_epoch_133</th>\n",
       "      <th>loss_epoch_134</th>\n",
       "      <th>loss_epoch_135</th>\n",
       "      <th>loss_epoch_136</th>\n",
       "      <th>loss_epoch_137</th>\n",
       "      <th>loss_epoch_138</th>\n",
       "      <th>loss_epoch_139</th>\n",
       "      <th>loss_epoch_140</th>\n",
       "      <th>loss_epoch_141</th>\n",
       "      <th>loss_epoch_142</th>\n",
       "      <th>loss_epoch_143</th>\n",
       "      <th>loss_epoch_144</th>\n",
       "      <th>loss_epoch_145</th>\n",
       "      <th>loss_epoch_146</th>\n",
       "      <th>loss_epoch_147</th>\n",
       "      <th>loss_epoch_148</th>\n",
       "      <th>loss_epoch_149</th>\n",
       "      <th>loss_epoch_150</th>\n",
       "      <th>loss_epoch_151</th>\n",
       "      <th>loss_epoch_152</th>\n",
       "      <th>loss_epoch_153</th>\n",
       "      <th>loss_epoch_154</th>\n",
       "      <th>loss_epoch_155</th>\n",
       "      <th>loss_epoch_156</th>\n",
       "      <th>loss_epoch_157</th>\n",
       "      <th>loss_epoch_158</th>\n",
       "      <th>loss_epoch_159</th>\n",
       "      <th>loss_epoch_160</th>\n",
       "      <th>loss_epoch_161</th>\n",
       "      <th>loss_epoch_162</th>\n",
       "      <th>loss_epoch_163</th>\n",
       "      <th>loss_epoch_164</th>\n",
       "      <th>loss_epoch_165</th>\n",
       "      <th>loss_epoch_166</th>\n",
       "      <th>loss_epoch_167</th>\n",
       "      <th>loss_epoch_168</th>\n",
       "      <th>loss_epoch_169</th>\n",
       "      <th>loss_epoch_170</th>\n",
       "      <th>loss_epoch_171</th>\n",
       "      <th>loss_epoch_172</th>\n",
       "      <th>loss_epoch_173</th>\n",
       "      <th>loss_epoch_174</th>\n",
       "      <th>loss_epoch_175</th>\n",
       "      <th>loss_epoch_176</th>\n",
       "      <th>loss_epoch_177</th>\n",
       "      <th>loss_epoch_178</th>\n",
       "      <th>loss_epoch_179</th>\n",
       "      <th>loss_epoch_180</th>\n",
       "      <th>loss_epoch_181</th>\n",
       "      <th>loss_epoch_182</th>\n",
       "      <th>loss_epoch_183</th>\n",
       "      <th>loss_epoch_184</th>\n",
       "      <th>loss_epoch_185</th>\n",
       "      <th>loss_epoch_186</th>\n",
       "      <th>loss_epoch_187</th>\n",
       "      <th>loss_epoch_188</th>\n",
       "      <th>loss_epoch_189</th>\n",
       "      <th>loss_epoch_190</th>\n",
       "      <th>loss_epoch_191</th>\n",
       "      <th>loss_epoch_192</th>\n",
       "      <th>loss_epoch_193</th>\n",
       "      <th>loss_epoch_194</th>\n",
       "      <th>loss_epoch_195</th>\n",
       "      <th>loss_epoch_196</th>\n",
       "      <th>loss_epoch_197</th>\n",
       "      <th>loss_epoch_198</th>\n",
       "      <th>loss_epoch_199</th>\n",
       "      <th>loss_epoch_200</th>\n",
       "      <th>loss_epoch_201</th>\n",
       "      <th>loss_epoch_202</th>\n",
       "      <th>loss_epoch_203</th>\n",
       "      <th>loss_epoch_204</th>\n",
       "      <th>loss_epoch_205</th>\n",
       "      <th>loss_epoch_206</th>\n",
       "      <th>loss_epoch_207</th>\n",
       "      <th>loss_epoch_208</th>\n",
       "      <th>loss_epoch_209</th>\n",
       "      <th>loss_epoch_210</th>\n",
       "      <th>loss_epoch_211</th>\n",
       "      <th>loss_epoch_212</th>\n",
       "      <th>loss_epoch_213</th>\n",
       "      <th>loss_epoch_214</th>\n",
       "      <th>loss_epoch_215</th>\n",
       "      <th>loss_epoch_216</th>\n",
       "      <th>loss_epoch_217</th>\n",
       "      <th>loss_epoch_218</th>\n",
       "      <th>loss_epoch_219</th>\n",
       "      <th>loss_epoch_220</th>\n",
       "      <th>loss_epoch_221</th>\n",
       "      <th>loss_epoch_222</th>\n",
       "      <th>loss_epoch_223</th>\n",
       "      <th>loss_epoch_224</th>\n",
       "      <th>loss_epoch_225</th>\n",
       "      <th>loss_epoch_226</th>\n",
       "      <th>loss_epoch_227</th>\n",
       "      <th>loss_epoch_228</th>\n",
       "      <th>loss_epoch_229</th>\n",
       "      <th>loss_epoch_230</th>\n",
       "      <th>loss_epoch_231</th>\n",
       "      <th>loss_epoch_232</th>\n",
       "      <th>loss_epoch_233</th>\n",
       "      <th>loss_epoch_234</th>\n",
       "      <th>loss_epoch_235</th>\n",
       "      <th>loss_epoch_236</th>\n",
       "      <th>loss_epoch_237</th>\n",
       "      <th>loss_epoch_238</th>\n",
       "      <th>loss_epoch_239</th>\n",
       "      <th>loss_epoch_240</th>\n",
       "      <th>loss_epoch_241</th>\n",
       "      <th>loss_epoch_242</th>\n",
       "      <th>loss_epoch_243</th>\n",
       "      <th>loss_epoch_244</th>\n",
       "      <th>loss_epoch_245</th>\n",
       "      <th>loss_epoch_246</th>\n",
       "      <th>loss_epoch_247</th>\n",
       "      <th>loss_epoch_248</th>\n",
       "      <th>loss_epoch_249</th>\n",
       "      <th>loss_epoch_250</th>\n",
       "      <th>loss_epoch_251</th>\n",
       "      <th>loss_epoch_252</th>\n",
       "      <th>loss_epoch_253</th>\n",
       "      <th>loss_epoch_254</th>\n",
       "      <th>loss_epoch_255</th>\n",
       "      <th>loss_epoch_256</th>\n",
       "      <th>loss_epoch_257</th>\n",
       "      <th>loss_epoch_258</th>\n",
       "      <th>loss_epoch_259</th>\n",
       "      <th>loss_epoch_260</th>\n",
       "      <th>loss_epoch_261</th>\n",
       "      <th>loss_epoch_262</th>\n",
       "      <th>loss_epoch_263</th>\n",
       "      <th>loss_epoch_264</th>\n",
       "      <th>loss_epoch_265</th>\n",
       "      <th>loss_epoch_266</th>\n",
       "      <th>loss_epoch_267</th>\n",
       "      <th>loss_epoch_268</th>\n",
       "      <th>loss_epoch_269</th>\n",
       "      <th>loss_epoch_270</th>\n",
       "      <th>loss_epoch_271</th>\n",
       "      <th>loss_epoch_272</th>\n",
       "      <th>loss_epoch_273</th>\n",
       "      <th>loss_epoch_274</th>\n",
       "      <th>loss_epoch_275</th>\n",
       "      <th>loss_epoch_276</th>\n",
       "      <th>loss_epoch_277</th>\n",
       "      <th>loss_epoch_278</th>\n",
       "      <th>loss_epoch_279</th>\n",
       "      <th>loss_epoch_280</th>\n",
       "      <th>loss_epoch_281</th>\n",
       "      <th>loss_epoch_282</th>\n",
       "      <th>loss_epoch_283</th>\n",
       "      <th>loss_epoch_284</th>\n",
       "      <th>loss_epoch_285</th>\n",
       "      <th>loss_epoch_286</th>\n",
       "      <th>loss_epoch_287</th>\n",
       "      <th>loss_epoch_288</th>\n",
       "      <th>loss_epoch_289</th>\n",
       "      <th>loss_epoch_290</th>\n",
       "      <th>loss_epoch_291</th>\n",
       "      <th>loss_epoch_292</th>\n",
       "      <th>loss_epoch_293</th>\n",
       "      <th>loss_epoch_294</th>\n",
       "      <th>loss_epoch_295</th>\n",
       "      <th>loss_epoch_296</th>\n",
       "      <th>loss_epoch_297</th>\n",
       "      <th>loss_epoch_298</th>\n",
       "      <th>loss_epoch_299</th>\n",
       "      <th>loss_epoch_300</th>\n",
       "      <th>loss_epoch_301</th>\n",
       "      <th>loss_epoch_302</th>\n",
       "      <th>loss_epoch_303</th>\n",
       "      <th>loss_epoch_304</th>\n",
       "      <th>loss_epoch_305</th>\n",
       "      <th>loss_epoch_306</th>\n",
       "      <th>loss_epoch_307</th>\n",
       "      <th>loss_epoch_308</th>\n",
       "      <th>loss_epoch_309</th>\n",
       "      <th>loss_epoch_310</th>\n",
       "      <th>loss_epoch_311</th>\n",
       "      <th>loss_epoch_312</th>\n",
       "      <th>loss_epoch_313</th>\n",
       "      <th>loss_epoch_314</th>\n",
       "      <th>loss_epoch_315</th>\n",
       "      <th>loss_epoch_316</th>\n",
       "      <th>loss_epoch_317</th>\n",
       "      <th>loss_epoch_318</th>\n",
       "      <th>loss_epoch_319</th>\n",
       "      <th>loss_epoch_320</th>\n",
       "      <th>loss_epoch_321</th>\n",
       "      <th>loss_epoch_322</th>\n",
       "      <th>loss_epoch_323</th>\n",
       "      <th>loss_epoch_324</th>\n",
       "      <th>loss_epoch_325</th>\n",
       "      <th>loss_epoch_326</th>\n",
       "      <th>loss_epoch_327</th>\n",
       "      <th>loss_epoch_328</th>\n",
       "      <th>loss_epoch_329</th>\n",
       "      <th>loss_epoch_330</th>\n",
       "      <th>loss_epoch_331</th>\n",
       "      <th>loss_epoch_332</th>\n",
       "      <th>loss_epoch_333</th>\n",
       "      <th>loss_epoch_334</th>\n",
       "      <th>loss_epoch_335</th>\n",
       "      <th>loss_epoch_336</th>\n",
       "      <th>loss_epoch_337</th>\n",
       "      <th>loss_epoch_338</th>\n",
       "      <th>loss_epoch_339</th>\n",
       "      <th>loss_epoch_340</th>\n",
       "      <th>loss_epoch_341</th>\n",
       "      <th>loss_epoch_342</th>\n",
       "      <th>loss_epoch_343</th>\n",
       "      <th>loss_epoch_344</th>\n",
       "      <th>loss_epoch_345</th>\n",
       "      <th>loss_epoch_346</th>\n",
       "      <th>loss_epoch_347</th>\n",
       "      <th>loss_epoch_348</th>\n",
       "      <th>loss_epoch_349</th>\n",
       "      <th>loss_epoch_350</th>\n",
       "      <th>loss_epoch_351</th>\n",
       "      <th>loss_epoch_352</th>\n",
       "      <th>loss_epoch_353</th>\n",
       "      <th>loss_epoch_354</th>\n",
       "      <th>loss_epoch_355</th>\n",
       "      <th>loss_epoch_356</th>\n",
       "      <th>loss_epoch_357</th>\n",
       "      <th>loss_epoch_358</th>\n",
       "      <th>loss_epoch_359</th>\n",
       "      <th>loss_epoch_360</th>\n",
       "      <th>loss_epoch_361</th>\n",
       "      <th>loss_epoch_362</th>\n",
       "      <th>loss_epoch_363</th>\n",
       "      <th>loss_epoch_364</th>\n",
       "      <th>loss_epoch_365</th>\n",
       "      <th>loss_epoch_366</th>\n",
       "      <th>loss_epoch_367</th>\n",
       "      <th>loss_epoch_368</th>\n",
       "      <th>loss_epoch_369</th>\n",
       "      <th>loss_epoch_370</th>\n",
       "      <th>loss_epoch_371</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>49999.000</td>\n",
       "      <td>49999.000</td>\n",
       "      <td>49997.000</td>\n",
       "      <td>49997.000</td>\n",
       "      <td>49996.000</td>\n",
       "      <td>49996.000</td>\n",
       "      <td>49995.000</td>\n",
       "      <td>49994.000</td>\n",
       "      <td>49992.000</td>\n",
       "      <td>49992.000</td>\n",
       "      <td>49989.000</td>\n",
       "      <td>49984.000</td>\n",
       "      <td>49982.000</td>\n",
       "      <td>49980.000</td>\n",
       "      <td>49974.000</td>\n",
       "      <td>49970.000</td>\n",
       "      <td>49965.000</td>\n",
       "      <td>49960.000</td>\n",
       "      <td>49957.000</td>\n",
       "      <td>49949.000</td>\n",
       "      <td>49945.000</td>\n",
       "      <td>49935.000</td>\n",
       "      <td>49923.000</td>\n",
       "      <td>49905.000</td>\n",
       "      <td>49890.000</td>\n",
       "      <td>49876.000</td>\n",
       "      <td>49856.000</td>\n",
       "      <td>49835.000</td>\n",
       "      <td>49810.000</td>\n",
       "      <td>49785.000</td>\n",
       "      <td>49762.000</td>\n",
       "      <td>49727.000</td>\n",
       "      <td>49689.000</td>\n",
       "      <td>49646.000</td>\n",
       "      <td>49613.000</td>\n",
       "      <td>49576.000</td>\n",
       "      <td>49535.000</td>\n",
       "      <td>49483.000</td>\n",
       "      <td>49428.000</td>\n",
       "      <td>49357.000</td>\n",
       "      <td>49282.000</td>\n",
       "      <td>49198.000</td>\n",
       "      <td>49107.000</td>\n",
       "      <td>49000.000</td>\n",
       "      <td>48880.000</td>\n",
       "      <td>48770.000</td>\n",
       "      <td>48637.000</td>\n",
       "      <td>48489.000</td>\n",
       "      <td>48358.000</td>\n",
       "      <td>48202.000</td>\n",
       "      <td>48024.000</td>\n",
       "      <td>47845.000</td>\n",
       "      <td>47646.000</td>\n",
       "      <td>47447.000</td>\n",
       "      <td>47224.000</td>\n",
       "      <td>46989.000</td>\n",
       "      <td>46764.000</td>\n",
       "      <td>46530.000</td>\n",
       "      <td>46244.000</td>\n",
       "      <td>45959.000</td>\n",
       "      <td>45683.000</td>\n",
       "      <td>45352.000</td>\n",
       "      <td>45032.000</td>\n",
       "      <td>44725.000</td>\n",
       "      <td>44416.000</td>\n",
       "      <td>44045.000</td>\n",
       "      <td>43666.000</td>\n",
       "      <td>43276.000</td>\n",
       "      <td>42871.000</td>\n",
       "      <td>42516.000</td>\n",
       "      <td>42120.000</td>\n",
       "      <td>41681.000</td>\n",
       "      <td>41237.000</td>\n",
       "      <td>40781.000</td>\n",
       "      <td>40315.000</td>\n",
       "      <td>39829.000</td>\n",
       "      <td>39368.000</td>\n",
       "      <td>38884.000</td>\n",
       "      <td>38358.000</td>\n",
       "      <td>37875.000</td>\n",
       "      <td>37348.000</td>\n",
       "      <td>36860.000</td>\n",
       "      <td>36343.000</td>\n",
       "      <td>35791.000</td>\n",
       "      <td>35260.000</td>\n",
       "      <td>34687.000</td>\n",
       "      <td>34157.000</td>\n",
       "      <td>33582.000</td>\n",
       "      <td>33063.000</td>\n",
       "      <td>32504.000</td>\n",
       "      <td>31957.000</td>\n",
       "      <td>31392.000</td>\n",
       "      <td>30845.000</td>\n",
       "      <td>30268.000</td>\n",
       "      <td>29729.000</td>\n",
       "      <td>29168.000</td>\n",
       "      <td>28631.000</td>\n",
       "      <td>27983.000</td>\n",
       "      <td>27429.000</td>\n",
       "      <td>26867.000</td>\n",
       "      <td>26363.000</td>\n",
       "      <td>25806.000</td>\n",
       "      <td>25243.000</td>\n",
       "      <td>24678.000</td>\n",
       "      <td>24168.000</td>\n",
       "      <td>23634.000</td>\n",
       "      <td>23071.000</td>\n",
       "      <td>22521.000</td>\n",
       "      <td>21987.000</td>\n",
       "      <td>21456.000</td>\n",
       "      <td>20973.000</td>\n",
       "      <td>20467.000</td>\n",
       "      <td>19984.000</td>\n",
       "      <td>19485.000</td>\n",
       "      <td>19010.000</td>\n",
       "      <td>18544.000</td>\n",
       "      <td>18054.000</td>\n",
       "      <td>17599.000</td>\n",
       "      <td>17138.000</td>\n",
       "      <td>16695.000</td>\n",
       "      <td>16231.000</td>\n",
       "      <td>15795.000</td>\n",
       "      <td>15394.000</td>\n",
       "      <td>14973.000</td>\n",
       "      <td>14563.000</td>\n",
       "      <td>14150.000</td>\n",
       "      <td>13751.000</td>\n",
       "      <td>13347.000</td>\n",
       "      <td>12961.000</td>\n",
       "      <td>12579.000</td>\n",
       "      <td>12195.000</td>\n",
       "      <td>11826.000</td>\n",
       "      <td>11507.000</td>\n",
       "      <td>11169.000</td>\n",
       "      <td>10845.000</td>\n",
       "      <td>10467.000</td>\n",
       "      <td>10136.000</td>\n",
       "      <td>9816.000</td>\n",
       "      <td>9524.000</td>\n",
       "      <td>9211.000</td>\n",
       "      <td>8910.000</td>\n",
       "      <td>8632.000</td>\n",
       "      <td>8389.000</td>\n",
       "      <td>8105.000</td>\n",
       "      <td>7861.000</td>\n",
       "      <td>7574.000</td>\n",
       "      <td>7322.000</td>\n",
       "      <td>7087.000</td>\n",
       "      <td>6849.000</td>\n",
       "      <td>6618.000</td>\n",
       "      <td>6415.000</td>\n",
       "      <td>6201.000</td>\n",
       "      <td>5968.000</td>\n",
       "      <td>5776.000</td>\n",
       "      <td>5573.000</td>\n",
       "      <td>5374.000</td>\n",
       "      <td>5191.000</td>\n",
       "      <td>5013.000</td>\n",
       "      <td>4861.000</td>\n",
       "      <td>4688.000</td>\n",
       "      <td>4506.000</td>\n",
       "      <td>4349.000</td>\n",
       "      <td>4214.000</td>\n",
       "      <td>4077.000</td>\n",
       "      <td>3932.000</td>\n",
       "      <td>3783.000</td>\n",
       "      <td>3642.000</td>\n",
       "      <td>3509.000</td>\n",
       "      <td>3363.000</td>\n",
       "      <td>3234.000</td>\n",
       "      <td>3116.000</td>\n",
       "      <td>3004.000</td>\n",
       "      <td>2885.000</td>\n",
       "      <td>2773.000</td>\n",
       "      <td>2690.000</td>\n",
       "      <td>2584.000</td>\n",
       "      <td>2484.000</td>\n",
       "      <td>2386.000</td>\n",
       "      <td>2291.000</td>\n",
       "      <td>2205.000</td>\n",
       "      <td>2119.000</td>\n",
       "      <td>2034.000</td>\n",
       "      <td>1967.000</td>\n",
       "      <td>1896.000</td>\n",
       "      <td>1824.000</td>\n",
       "      <td>1753.000</td>\n",
       "      <td>1688.000</td>\n",
       "      <td>1610.000</td>\n",
       "      <td>1544.000</td>\n",
       "      <td>1481.000</td>\n",
       "      <td>1429.000</td>\n",
       "      <td>1376.000</td>\n",
       "      <td>1310.000</td>\n",
       "      <td>1262.000</td>\n",
       "      <td>1214.000</td>\n",
       "      <td>1160.000</td>\n",
       "      <td>1114.000</td>\n",
       "      <td>1058.000</td>\n",
       "      <td>1019.000</td>\n",
       "      <td>986.000</td>\n",
       "      <td>953.000</td>\n",
       "      <td>921.000</td>\n",
       "      <td>886.000</td>\n",
       "      <td>855.000</td>\n",
       "      <td>822.000</td>\n",
       "      <td>787.000</td>\n",
       "      <td>745.000</td>\n",
       "      <td>715.000</td>\n",
       "      <td>682.000</td>\n",
       "      <td>646.000</td>\n",
       "      <td>618.000</td>\n",
       "      <td>599.000</td>\n",
       "      <td>567.000</td>\n",
       "      <td>538.000</td>\n",
       "      <td>519.000</td>\n",
       "      <td>497.000</td>\n",
       "      <td>479.000</td>\n",
       "      <td>462.000</td>\n",
       "      <td>438.000</td>\n",
       "      <td>417.000</td>\n",
       "      <td>396.000</td>\n",
       "      <td>379.000</td>\n",
       "      <td>364.000</td>\n",
       "      <td>341.000</td>\n",
       "      <td>327.000</td>\n",
       "      <td>315.000</td>\n",
       "      <td>296.000</td>\n",
       "      <td>284.000</td>\n",
       "      <td>270.000</td>\n",
       "      <td>257.000</td>\n",
       "      <td>240.000</td>\n",
       "      <td>232.000</td>\n",
       "      <td>222.000</td>\n",
       "      <td>211.000</td>\n",
       "      <td>202.000</td>\n",
       "      <td>192.000</td>\n",
       "      <td>186.000</td>\n",
       "      <td>175.000</td>\n",
       "      <td>168.000</td>\n",
       "      <td>156.000</td>\n",
       "      <td>151.000</td>\n",
       "      <td>146.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>133.000</td>\n",
       "      <td>123.000</td>\n",
       "      <td>119.000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>114.000</td>\n",
       "      <td>108.000</td>\n",
       "      <td>104.000</td>\n",
       "      <td>102.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>89.000</td>\n",
       "      <td>87.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>79.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>71.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24999.500</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14433.901</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12499.750</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24999.500</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37499.250</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49999.000</td>\n",
       "      <td>1.722</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  loss_epoch_1  loss_epoch_2  loss_epoch_3  loss_epoch_4  \\\n",
       "count 50000.000     50000.000     50000.000     50000.000     50000.000   \n",
       "mean  24999.500         0.288         0.164         0.115         0.091   \n",
       "std   14433.901         0.146         0.070         0.050         0.037   \n",
       "min       0.000         0.062         0.033         0.022         0.016   \n",
       "25%   12499.750         0.193         0.113         0.080         0.066   \n",
       "50%   24999.500         0.252         0.149         0.103         0.084   \n",
       "75%   37499.250         0.338         0.199         0.137         0.107   \n",
       "max   49999.000         1.722         0.955         0.515         0.409   \n",
       "\n",
       "       loss_epoch_5  loss_epoch_6  loss_epoch_7  loss_epoch_8  loss_epoch_9  \\\n",
       "count     50000.000     50000.000     50000.000     50000.000     50000.000   \n",
       "mean          0.079         0.072         0.066         0.062         0.059   \n",
       "std           0.030         0.026         0.024         0.023         0.022   \n",
       "min           0.013         0.010         0.009         0.008         0.007   \n",
       "25%           0.058         0.053         0.049         0.046         0.043   \n",
       "50%           0.075         0.068         0.064         0.060         0.056   \n",
       "75%           0.094         0.086         0.080         0.076         0.072   \n",
       "max           0.305         0.247         0.217         0.188         0.177   \n",
       "\n",
       "       loss_epoch_10  loss_epoch_11  loss_epoch_12  loss_epoch_13  \\\n",
       "count      50000.000      50000.000      50000.000      50000.000   \n",
       "mean           0.056          0.053          0.051          0.049   \n",
       "std            0.021          0.020          0.020          0.019   \n",
       "min            0.007          0.007          0.006          0.005   \n",
       "25%            0.041          0.039          0.037          0.035   \n",
       "50%            0.053          0.051          0.048          0.046   \n",
       "75%            0.068          0.065          0.063          0.060   \n",
       "max            0.172          0.168          0.165          0.163   \n",
       "\n",
       "       loss_epoch_14  loss_epoch_15  loss_epoch_16  loss_epoch_17  \\\n",
       "count      50000.000      50000.000      50000.000      50000.000   \n",
       "mean           0.047          0.046          0.044          0.043   \n",
       "std            0.019          0.018          0.018          0.017   \n",
       "min            0.005          0.004          0.004          0.004   \n",
       "25%            0.034          0.033          0.031          0.030   \n",
       "50%            0.045          0.043          0.041          0.040   \n",
       "75%            0.058          0.056          0.054          0.052   \n",
       "max            0.161          0.159          0.157          0.155   \n",
       "\n",
       "       loss_epoch_18  loss_epoch_19  loss_epoch_20  loss_epoch_21  \\\n",
       "count      50000.000      50000.000      50000.000      50000.000   \n",
       "mean           0.041          0.040          0.039          0.038   \n",
       "std            0.017          0.016          0.016          0.015   \n",
       "min            0.004          0.004          0.003          0.003   \n",
       "25%            0.029          0.028          0.028          0.027   \n",
       "50%            0.038          0.037          0.036          0.035   \n",
       "75%            0.050          0.049          0.047          0.045   \n",
       "max            0.154          0.153          0.152          0.150   \n",
       "\n",
       "       loss_epoch_22  loss_epoch_23  loss_epoch_24  loss_epoch_25  \\\n",
       "count      50000.000      50000.000      50000.000      50000.000   \n",
       "mean           0.036          0.035          0.034          0.033   \n",
       "std            0.015          0.015          0.014          0.014   \n",
       "min            0.003          0.003          0.003          0.003   \n",
       "25%            0.026          0.025          0.024          0.024   \n",
       "50%            0.034          0.033          0.032          0.031   \n",
       "75%            0.044          0.043          0.041          0.040   \n",
       "max            0.149          0.149          0.148          0.147   \n",
       "\n",
       "       loss_epoch_26  loss_epoch_27  loss_epoch_28  loss_epoch_29  \\\n",
       "count      50000.000      50000.000      50000.000      50000.000   \n",
       "mean           0.032          0.032          0.031          0.030   \n",
       "std            0.013          0.013          0.013          0.012   \n",
       "min            0.003          0.003          0.002          0.003   \n",
       "25%            0.023          0.023          0.022          0.022   \n",
       "50%            0.030          0.029          0.028          0.028   \n",
       "75%            0.039          0.038          0.037          0.035   \n",
       "max            0.145          0.144          0.143          0.141   \n",
       "\n",
       "       loss_epoch_30  loss_epoch_31  loss_epoch_32  loss_epoch_33  \\\n",
       "count      50000.000      50000.000      50000.000      50000.000   \n",
       "mean           0.029          0.028          0.028          0.027   \n",
       "std            0.012          0.012          0.011          0.011   \n",
       "min            0.003          0.002          0.002          0.002   \n",
       "25%            0.021          0.021          0.020          0.020   \n",
       "50%            0.027          0.026          0.026          0.025   \n",
       "75%            0.035          0.034          0.033          0.032   \n",
       "max            0.141          0.139          0.138          0.137   \n",
       "\n",
       "       loss_epoch_34  loss_epoch_35  loss_epoch_36  loss_epoch_37  \\\n",
       "count      50000.000      50000.000      50000.000      50000.000   \n",
       "mean           0.027          0.026          0.025          0.025   \n",
       "std            0.011          0.011          0.010          0.010   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.019          0.019          0.019          0.018   \n",
       "50%            0.025          0.024          0.024          0.023   \n",
       "75%            0.031          0.030          0.030          0.029   \n",
       "max            0.135          0.133          0.132          0.130   \n",
       "\n",
       "       loss_epoch_38  loss_epoch_39  loss_epoch_40  loss_epoch_41  \\\n",
       "count      50000.000      49999.000      49999.000      49997.000   \n",
       "mean           0.024          0.024          0.024          0.023   \n",
       "std            0.010          0.010          0.009          0.009   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.018          0.018          0.017          0.017   \n",
       "50%            0.023          0.022          0.022          0.022   \n",
       "75%            0.029          0.028          0.027          0.027   \n",
       "max            0.129          0.128          0.126          0.125   \n",
       "\n",
       "       loss_epoch_42  loss_epoch_43  loss_epoch_44  loss_epoch_45  \\\n",
       "count      49997.000      49996.000      49996.000      49995.000   \n",
       "mean           0.023          0.022          0.022          0.022   \n",
       "std            0.009          0.009          0.009          0.009   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.017          0.017          0.016          0.016   \n",
       "50%            0.021          0.021          0.021          0.020   \n",
       "75%            0.026          0.026          0.026          0.025   \n",
       "max            0.124          0.122          0.120          0.119   \n",
       "\n",
       "       loss_epoch_46  loss_epoch_47  loss_epoch_48  loss_epoch_49  \\\n",
       "count      49994.000      49992.000      49992.000      49989.000   \n",
       "mean           0.021          0.021          0.021          0.020   \n",
       "std            0.008          0.008          0.008          0.008   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.016          0.016          0.016          0.015   \n",
       "50%            0.020          0.020          0.019          0.019   \n",
       "75%            0.025          0.025          0.024          0.024   \n",
       "max            0.118          0.116          0.114          0.114   \n",
       "\n",
       "       loss_epoch_50  loss_epoch_51  loss_epoch_52  loss_epoch_53  \\\n",
       "count      49984.000      49982.000      49980.000      49974.000   \n",
       "mean           0.020          0.020          0.020          0.019   \n",
       "std            0.008          0.008          0.008          0.007   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.015          0.015          0.015          0.015   \n",
       "50%            0.019          0.019          0.019          0.018   \n",
       "75%            0.024          0.023          0.023          0.023   \n",
       "max            0.112          0.110          0.108          0.107   \n",
       "\n",
       "       loss_epoch_54  loss_epoch_55  loss_epoch_56  loss_epoch_57  \\\n",
       "count      49970.000      49965.000      49960.000      49957.000   \n",
       "mean           0.019          0.019          0.019          0.019   \n",
       "std            0.007          0.007          0.007          0.007   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.015          0.014          0.014          0.014   \n",
       "50%            0.018          0.018          0.018          0.018   \n",
       "75%            0.022          0.022          0.022          0.022   \n",
       "max            0.106          0.106          0.106          0.106   \n",
       "\n",
       "       loss_epoch_58  loss_epoch_59  loss_epoch_60  loss_epoch_61  \\\n",
       "count      49949.000      49945.000      49935.000      49923.000   \n",
       "mean           0.018          0.018          0.018          0.018   \n",
       "std            0.007          0.007          0.007          0.007   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.014          0.014          0.014          0.014   \n",
       "50%            0.017          0.017          0.017          0.017   \n",
       "75%            0.022          0.021          0.021          0.021   \n",
       "max            0.105          0.105          0.106          0.106   \n",
       "\n",
       "       loss_epoch_62  loss_epoch_63  loss_epoch_64  loss_epoch_65  \\\n",
       "count      49905.000      49890.000      49876.000      49856.000   \n",
       "mean           0.018          0.018          0.017          0.017   \n",
       "std            0.007          0.006          0.006          0.006   \n",
       "min            0.002          0.002          0.002          0.003   \n",
       "25%            0.013          0.013          0.013          0.013   \n",
       "50%            0.017          0.017          0.017          0.016   \n",
       "75%            0.021          0.021          0.020          0.020   \n",
       "max            0.105          0.104          0.104          0.104   \n",
       "\n",
       "       loss_epoch_66  loss_epoch_67  loss_epoch_68  loss_epoch_69  \\\n",
       "count      49835.000      49810.000      49785.000      49762.000   \n",
       "mean           0.017          0.017          0.017          0.017   \n",
       "std            0.006          0.006          0.006          0.006   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.013          0.013          0.013          0.013   \n",
       "50%            0.016          0.016          0.016          0.016   \n",
       "75%            0.020          0.020          0.020          0.020   \n",
       "max            0.103          0.103          0.103          0.103   \n",
       "\n",
       "       loss_epoch_70  loss_epoch_71  loss_epoch_72  loss_epoch_73  \\\n",
       "count      49727.000      49689.000      49646.000      49613.000   \n",
       "mean           0.017          0.017          0.016          0.016   \n",
       "std            0.006          0.006          0.006          0.006   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.013          0.013          0.012          0.012   \n",
       "50%            0.016          0.016          0.016          0.015   \n",
       "75%            0.019          0.019          0.019          0.019   \n",
       "max            0.104          0.102          0.100          0.100   \n",
       "\n",
       "       loss_epoch_74  loss_epoch_75  loss_epoch_76  loss_epoch_77  \\\n",
       "count      49576.000      49535.000      49483.000      49428.000   \n",
       "mean           0.016          0.016          0.016          0.016   \n",
       "std            0.006          0.006          0.006          0.006   \n",
       "min            0.002          0.003          0.003          0.003   \n",
       "25%            0.012          0.012          0.012          0.012   \n",
       "50%            0.015          0.015          0.015          0.015   \n",
       "75%            0.019          0.019          0.019          0.019   \n",
       "max            0.100          0.098          0.098          0.097   \n",
       "\n",
       "       loss_epoch_78  loss_epoch_79  loss_epoch_80  loss_epoch_81  \\\n",
       "count      49357.000      49282.000      49198.000      49107.000   \n",
       "mean           0.016          0.016          0.016          0.015   \n",
       "std            0.006          0.006          0.006          0.005   \n",
       "min            0.002          0.002          0.002          0.003   \n",
       "25%            0.012          0.012          0.012          0.012   \n",
       "50%            0.015          0.015          0.015          0.015   \n",
       "75%            0.019          0.018          0.018          0.018   \n",
       "max            0.096          0.093          0.093          0.092   \n",
       "\n",
       "       loss_epoch_82  loss_epoch_83  loss_epoch_84  loss_epoch_85  \\\n",
       "count      49000.000      48880.000      48770.000      48637.000   \n",
       "mean           0.015          0.015          0.015          0.015   \n",
       "std            0.005          0.005          0.005          0.005   \n",
       "min            0.002          0.002          0.003          0.002   \n",
       "25%            0.012          0.012          0.012          0.012   \n",
       "50%            0.015          0.015          0.014          0.014   \n",
       "75%            0.018          0.018          0.018          0.018   \n",
       "max            0.090          0.088          0.085          0.083   \n",
       "\n",
       "       loss_epoch_86  loss_epoch_87  loss_epoch_88  loss_epoch_89  \\\n",
       "count      48489.000      48358.000      48202.000      48024.000   \n",
       "mean           0.015          0.015          0.015          0.015   \n",
       "std            0.005          0.005          0.005          0.005   \n",
       "min            0.003          0.002          0.002          0.002   \n",
       "25%            0.011          0.011          0.011          0.011   \n",
       "50%            0.014          0.014          0.014          0.014   \n",
       "75%            0.018          0.018          0.018          0.017   \n",
       "max            0.081          0.078          0.075          0.073   \n",
       "\n",
       "       loss_epoch_90  loss_epoch_91  loss_epoch_92  loss_epoch_93  \\\n",
       "count      47845.000      47646.000      47447.000      47224.000   \n",
       "mean           0.015          0.015          0.015          0.015   \n",
       "std            0.005          0.005          0.005          0.005   \n",
       "min            0.002          0.002          0.002          0.002   \n",
       "25%            0.011          0.011          0.011          0.011   \n",
       "50%            0.014          0.014          0.014          0.014   \n",
       "75%            0.017          0.017          0.017          0.017   \n",
       "max            0.074          0.073          0.072          0.072   \n",
       "\n",
       "       loss_epoch_94  loss_epoch_95  loss_epoch_96  loss_epoch_97  \\\n",
       "count      46989.000      46764.000      46530.000      46244.000   \n",
       "mean           0.015          0.014          0.014          0.014   \n",
       "std            0.005          0.005          0.005          0.005   \n",
       "min            0.002          0.003          0.002          0.002   \n",
       "25%            0.011          0.011          0.011          0.011   \n",
       "50%            0.014          0.014          0.014          0.014   \n",
       "75%            0.017          0.017          0.017          0.017   \n",
       "max            0.072          0.073          0.072          0.072   \n",
       "\n",
       "       loss_epoch_98  loss_epoch_99  loss_epoch_100  loss_epoch_101  \\\n",
       "count      45959.000      45683.000       45352.000       45032.000   \n",
       "mean           0.014          0.014           0.014           0.014   \n",
       "std            0.005          0.005           0.005           0.005   \n",
       "min            0.002          0.002           0.002           0.002   \n",
       "25%            0.011          0.011           0.011           0.011   \n",
       "50%            0.014          0.014           0.013           0.013   \n",
       "75%            0.017          0.017           0.017           0.017   \n",
       "max            0.071          0.071           0.071           0.071   \n",
       "\n",
       "       loss_epoch_102  loss_epoch_103  loss_epoch_104  loss_epoch_105  \\\n",
       "count       44725.000       44416.000       44045.000       43666.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.002           0.003           0.003           0.003   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.017           0.016           0.016           0.016   \n",
       "max             0.071           0.071           0.071           0.070   \n",
       "\n",
       "       loss_epoch_106  loss_epoch_107  loss_epoch_108  loss_epoch_109  \\\n",
       "count       43276.000       42871.000       42516.000       42120.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.070           0.070           0.070           0.069   \n",
       "\n",
       "       loss_epoch_110  loss_epoch_111  loss_epoch_112  loss_epoch_113  \\\n",
       "count       41681.000       41237.000       40781.000       40315.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.068           0.068           0.067           0.066   \n",
       "\n",
       "       loss_epoch_114  loss_epoch_115  loss_epoch_116  loss_epoch_117  \\\n",
       "count       39829.000       39368.000       38884.000       38358.000   \n",
       "mean            0.014           0.014           0.014           0.013   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.066           0.065           0.065           0.063   \n",
       "\n",
       "       loss_epoch_118  loss_epoch_119  loss_epoch_120  loss_epoch_121  \\\n",
       "count       37875.000       37348.000       36860.000       36343.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.061           0.060           0.058           0.057   \n",
       "\n",
       "       loss_epoch_122  loss_epoch_123  loss_epoch_124  loss_epoch_125  \\\n",
       "count       35791.000       35260.000       34687.000       34157.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.015   \n",
       "max             0.057           0.056           0.056           0.056   \n",
       "\n",
       "       loss_epoch_126  loss_epoch_127  loss_epoch_128  loss_epoch_129  \\\n",
       "count       33582.000       33063.000       32504.000       31957.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.005           0.005           0.005           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.056           0.057           0.056           0.054   \n",
       "\n",
       "       loss_epoch_130  loss_epoch_131  loss_epoch_132  loss_epoch_133  \\\n",
       "count       31392.000       30845.000       30268.000       29729.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.054           0.054           0.054           0.054   \n",
       "\n",
       "       loss_epoch_134  loss_epoch_135  loss_epoch_136  loss_epoch_137  \\\n",
       "count       29168.000       28631.000       27983.000       27429.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.053           0.053           0.053           0.053   \n",
       "\n",
       "       loss_epoch_138  loss_epoch_139  loss_epoch_140  loss_epoch_141  \\\n",
       "count       26867.000       26363.000       25806.000       25243.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.053           0.053           0.052           0.052   \n",
       "\n",
       "       loss_epoch_142  loss_epoch_143  loss_epoch_144  loss_epoch_145  \\\n",
       "count       24678.000       24168.000       23634.000       23071.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.002   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.052           0.052           0.051           0.051   \n",
       "\n",
       "       loss_epoch_146  loss_epoch_147  loss_epoch_148  loss_epoch_149  \\\n",
       "count       22521.000       21987.000       21456.000       20973.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.002           0.003           0.002   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.051           0.051           0.051           0.051   \n",
       "\n",
       "       loss_epoch_150  loss_epoch_151  loss_epoch_152  loss_epoch_153  \\\n",
       "count       20467.000       19984.000       19485.000       19010.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.002           0.002           0.002   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.051           0.050           0.050           0.050   \n",
       "\n",
       "       loss_epoch_154  loss_epoch_155  loss_epoch_156  loss_epoch_157  \\\n",
       "count       18544.000       18054.000       17599.000       17138.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.002           0.002           0.002   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.049           0.050           0.050           0.049   \n",
       "\n",
       "       loss_epoch_158  loss_epoch_159  loss_epoch_160  loss_epoch_161  \\\n",
       "count       16695.000       16231.000       15795.000       15394.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.002           0.002           0.002   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.049           0.049           0.049           0.049   \n",
       "\n",
       "       loss_epoch_162  loss_epoch_163  loss_epoch_164  loss_epoch_165  \\\n",
       "count       14973.000       14563.000       14150.000       13751.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.002           0.002           0.002   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.048           0.048           0.049           0.048   \n",
       "\n",
       "       loss_epoch_166  loss_epoch_167  loss_epoch_168  loss_epoch_169  \\\n",
       "count       13347.000       12961.000       12579.000       12195.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.002           0.002           0.002   \n",
       "25%             0.010           0.010           0.010           0.009   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.048           0.048           0.048           0.048   \n",
       "\n",
       "       loss_epoch_170  loss_epoch_171  loss_epoch_172  loss_epoch_173  \\\n",
       "count       11826.000       11507.000       11169.000       10845.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.002           0.002           0.002   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.047           0.048           0.047           0.047   \n",
       "\n",
       "       loss_epoch_174  loss_epoch_175  loss_epoch_176  loss_epoch_177  \\\n",
       "count       10467.000       10136.000        9816.000        9524.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.002           0.002           0.002   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.047           0.046           0.046           0.046   \n",
       "\n",
       "       loss_epoch_178  loss_epoch_179  loss_epoch_180  loss_epoch_181  \\\n",
       "count        9211.000        8910.000        8632.000        8389.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.002           0.002           0.002   \n",
       "25%             0.010           0.010           0.009           0.009   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.045           0.046           0.045           0.045   \n",
       "\n",
       "       loss_epoch_182  loss_epoch_183  loss_epoch_184  loss_epoch_185  \\\n",
       "count        8105.000        7861.000        7574.000        7322.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.009           0.009           0.010           0.009   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.045           0.045           0.045           0.045   \n",
       "\n",
       "       loss_epoch_186  loss_epoch_187  loss_epoch_188  loss_epoch_189  \\\n",
       "count        7087.000        6849.000        6618.000        6415.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.009           0.009           0.009           0.009   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.044           0.044           0.045           0.044   \n",
       "\n",
       "       loss_epoch_190  loss_epoch_191  loss_epoch_192  loss_epoch_193  \\\n",
       "count        6201.000        5968.000        5776.000        5573.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.009           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.044           0.043           0.045           0.044   \n",
       "\n",
       "       loss_epoch_194  loss_epoch_195  loss_epoch_196  loss_epoch_197  \\\n",
       "count        5374.000        5191.000        5013.000        4861.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.043           0.043           0.043           0.043   \n",
       "\n",
       "       loss_epoch_198  loss_epoch_199  loss_epoch_200  loss_epoch_201  \\\n",
       "count        4688.000        4506.000        4349.000        4214.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.042           0.042           0.042           0.042   \n",
       "\n",
       "       loss_epoch_202  loss_epoch_203  loss_epoch_204  loss_epoch_205  \\\n",
       "count        4077.000        3932.000        3783.000        3642.000   \n",
       "mean            0.012           0.013           0.013           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.002           0.003           0.002           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.042           0.041           0.041           0.041   \n",
       "\n",
       "       loss_epoch_206  loss_epoch_207  loss_epoch_208  loss_epoch_209  \\\n",
       "count        3509.000        3363.000        3234.000        3116.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.004           0.004   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.041           0.040           0.041           0.041   \n",
       "\n",
       "       loss_epoch_210  loss_epoch_211  loss_epoch_212  loss_epoch_213  \\\n",
       "count        3004.000        2885.000        2773.000        2690.000   \n",
       "mean            0.012           0.012           0.012           0.012   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.004           0.004           0.004           0.004   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.041           0.041           0.040           0.040   \n",
       "\n",
       "       loss_epoch_214  loss_epoch_215  loss_epoch_216  loss_epoch_217  \\\n",
       "count        2584.000        2484.000        2386.000        2291.000   \n",
       "mean            0.012           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.004           0.004           0.004           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.040           0.040           0.040           0.040   \n",
       "\n",
       "       loss_epoch_218  loss_epoch_219  loss_epoch_220  loss_epoch_221  \\\n",
       "count        2205.000        2119.000        2034.000        1967.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.004           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.040           0.039           0.039           0.039   \n",
       "\n",
       "       loss_epoch_222  loss_epoch_223  loss_epoch_224  loss_epoch_225  \\\n",
       "count        1896.000        1824.000        1753.000        1688.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.004           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.039           0.039           0.039           0.039   \n",
       "\n",
       "       loss_epoch_226  loss_epoch_227  loss_epoch_228  loss_epoch_229  \\\n",
       "count        1610.000        1544.000        1481.000        1429.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.004           0.004           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.039           0.039           0.038           0.038   \n",
       "\n",
       "       loss_epoch_230  loss_epoch_231  loss_epoch_232  loss_epoch_233  \\\n",
       "count        1376.000        1310.000        1262.000        1214.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.038           0.038           0.038           0.038   \n",
       "\n",
       "       loss_epoch_234  loss_epoch_235  loss_epoch_236  loss_epoch_237  \\\n",
       "count        1160.000        1114.000        1058.000        1019.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.038           0.038           0.038           0.037   \n",
       "\n",
       "       loss_epoch_238  loss_epoch_239  loss_epoch_240  loss_epoch_241  \\\n",
       "count         986.000         953.000         921.000         886.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.004           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.037           0.037           0.037           0.038   \n",
       "\n",
       "       loss_epoch_242  loss_epoch_243  loss_epoch_244  loss_epoch_245  \\\n",
       "count         855.000         822.000         787.000         745.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.003           0.003           0.003           0.003   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.037           0.037           0.037           0.037   \n",
       "\n",
       "       loss_epoch_246  loss_epoch_247  loss_epoch_248  loss_epoch_249  \\\n",
       "count         715.000         682.000         646.000         618.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.004           0.004           0.004           0.004   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.037           0.037           0.036           0.036   \n",
       "\n",
       "       loss_epoch_250  loss_epoch_251  loss_epoch_252  loss_epoch_253  \\\n",
       "count         599.000         567.000         538.000         519.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.004           0.004           0.004           0.004   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.012           0.012           0.012           0.013   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.036           0.036           0.036           0.036   \n",
       "\n",
       "       loss_epoch_254  loss_epoch_255  loss_epoch_256  loss_epoch_257  \\\n",
       "count         497.000         479.000         462.000         438.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.004           0.004           0.004           0.004   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.012           0.013           0.013   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.035           0.035           0.035           0.036   \n",
       "\n",
       "       loss_epoch_258  loss_epoch_259  loss_epoch_260  loss_epoch_261  \\\n",
       "count         417.000         396.000         379.000         364.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.004           0.004           0.004           0.004   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.036           0.035           0.036           0.035   \n",
       "\n",
       "       loss_epoch_262  loss_epoch_263  loss_epoch_264  loss_epoch_265  \\\n",
       "count         341.000         327.000         315.000         296.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.006           0.006           0.006           0.006   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.015           0.016           0.015           0.015   \n",
       "max             0.035           0.035           0.035           0.034   \n",
       "\n",
       "       loss_epoch_266  loss_epoch_267  loss_epoch_268  loss_epoch_269  \\\n",
       "count         284.000         270.000         257.000         240.000   \n",
       "mean            0.013           0.013           0.014           0.013   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.006           0.006           0.006           0.006   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.015           0.015           0.015           0.015   \n",
       "max             0.035           0.034           0.034           0.034   \n",
       "\n",
       "       loss_epoch_270  loss_epoch_271  loss_epoch_272  loss_epoch_273  \\\n",
       "count         232.000         222.000         211.000         202.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.004           0.004           0.004           0.005   \n",
       "min             0.006           0.005           0.006           0.006   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.015           0.016   \n",
       "max             0.034           0.034           0.034           0.034   \n",
       "\n",
       "       loss_epoch_274  loss_epoch_275  loss_epoch_276  loss_epoch_277  \\\n",
       "count         192.000         186.000         175.000         168.000   \n",
       "mean            0.013           0.013           0.014           0.014   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.005           0.005           0.006           0.006   \n",
       "25%             0.010           0.010           0.010           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.015           0.016           0.015           0.016   \n",
       "max             0.034           0.033           0.033           0.033   \n",
       "\n",
       "       loss_epoch_278  loss_epoch_279  loss_epoch_280  loss_epoch_281  \\\n",
       "count         156.000         151.000         146.000         139.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.005           0.005           0.004           0.004   \n",
       "min             0.005           0.005           0.005           0.005   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.034           0.033           0.033           0.033   \n",
       "\n",
       "       loss_epoch_282  loss_epoch_283  loss_epoch_284  loss_epoch_285  \\\n",
       "count         133.000         123.000         119.000         118.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.005           0.005           0.005           0.005   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.015   \n",
       "max             0.033           0.034           0.033           0.033   \n",
       "\n",
       "       loss_epoch_286  loss_epoch_287  loss_epoch_288  loss_epoch_289  \\\n",
       "count         114.000         108.000         104.000         102.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.004           0.005           0.005           0.005   \n",
       "min             0.005           0.005           0.005           0.005   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.033           0.033           0.033           0.033   \n",
       "\n",
       "       loss_epoch_290  loss_epoch_291  loss_epoch_292  loss_epoch_293  \\\n",
       "count          99.000          94.000          92.000          89.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.005           0.005           0.005           0.005   \n",
       "25%             0.011           0.011           0.011           0.010   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.033           0.033           0.033           0.032   \n",
       "\n",
       "       loss_epoch_294  loss_epoch_295  loss_epoch_296  loss_epoch_297  \\\n",
       "count          87.000          85.000          83.000          79.000   \n",
       "mean            0.014           0.014           0.014           0.013   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.005           0.005           0.005           0.005   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.033           0.033           0.032           0.032   \n",
       "\n",
       "       loss_epoch_298  loss_epoch_299  loss_epoch_300  loss_epoch_301  \\\n",
       "count          77.000          75.000          73.000          72.000   \n",
       "mean            0.013           0.014           0.014           0.014   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.005           0.007           0.007           0.007   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.015           0.016           0.016           0.016   \n",
       "max             0.033           0.032           0.033           0.033   \n",
       "\n",
       "       loss_epoch_302  loss_epoch_303  loss_epoch_304  loss_epoch_305  \\\n",
       "count          71.000          67.000          64.000          62.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.007           0.007           0.007           0.007   \n",
       "25%             0.011           0.011           0.010           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.015           0.015           0.015           0.016   \n",
       "max             0.033           0.032           0.032           0.032   \n",
       "\n",
       "       loss_epoch_306  loss_epoch_307  loss_epoch_308  loss_epoch_309  \\\n",
       "count          59.000          56.000          53.000          53.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.005           0.005           0.005           0.005   \n",
       "min             0.007           0.007           0.007           0.006   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.015           0.016           0.015           0.016   \n",
       "max             0.032           0.032           0.033           0.032   \n",
       "\n",
       "       loss_epoch_310  loss_epoch_311  loss_epoch_312  loss_epoch_313  \\\n",
       "count          50.000          49.000          47.000          46.000   \n",
       "mean            0.014           0.014           0.014           0.013   \n",
       "std             0.005           0.005           0.005           0.004   \n",
       "min             0.007           0.007           0.007           0.007   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.017           0.016           0.015   \n",
       "max             0.032           0.032           0.032           0.025   \n",
       "\n",
       "       loss_epoch_314  loss_epoch_315  loss_epoch_316  loss_epoch_317  \\\n",
       "count          39.000          37.000          35.000          35.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.007           0.007           0.008           0.009   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.017           0.017           0.017   \n",
       "max             0.025           0.025           0.025           0.025   \n",
       "\n",
       "       loss_epoch_318  loss_epoch_319  loss_epoch_320  loss_epoch_321  \\\n",
       "count          35.000          33.000          32.000          29.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.008           0.009           0.008           0.008   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.017           0.017           0.016           0.016   \n",
       "max             0.025           0.025           0.024           0.024   \n",
       "\n",
       "       loss_epoch_322  loss_epoch_323  loss_epoch_324  loss_epoch_325  \\\n",
       "count          27.000          25.000          22.000          20.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.008           0.008           0.008           0.009   \n",
       "25%             0.011           0.011           0.011           0.011   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.017           0.017           0.017           0.017   \n",
       "max             0.024           0.025           0.024           0.024   \n",
       "\n",
       "       loss_epoch_326  loss_epoch_327  loss_epoch_328  loss_epoch_329  \\\n",
       "count          19.000          19.000          18.000          17.000   \n",
       "mean            0.015           0.015           0.015           0.015   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.009           0.009           0.009           0.009   \n",
       "25%             0.012           0.012           0.012           0.012   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.017           0.017           0.017           0.017   \n",
       "max             0.025           0.024           0.025           0.024   \n",
       "\n",
       "       loss_epoch_330  loss_epoch_331  loss_epoch_332  loss_epoch_333  \\\n",
       "count          16.000          16.000          15.000          15.000   \n",
       "mean            0.015           0.015           0.015           0.015   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.009           0.009           0.009           0.009   \n",
       "25%             0.012           0.012           0.012           0.012   \n",
       "50%             0.013           0.014           0.013           0.013   \n",
       "75%             0.017           0.017           0.017           0.016   \n",
       "max             0.024           0.024           0.024           0.025   \n",
       "\n",
       "       loss_epoch_334  loss_epoch_335  loss_epoch_336  loss_epoch_337  \\\n",
       "count          15.000          14.000          14.000          13.000   \n",
       "mean            0.015           0.015           0.015           0.015   \n",
       "std             0.004           0.004           0.005           0.004   \n",
       "min             0.009           0.009           0.009           0.008   \n",
       "25%             0.012           0.012           0.012           0.013   \n",
       "50%             0.014           0.014           0.013           0.014   \n",
       "75%             0.017           0.017           0.016           0.017   \n",
       "max             0.024           0.024           0.024           0.024   \n",
       "\n",
       "       loss_epoch_338  loss_epoch_339  loss_epoch_340  loss_epoch_341  \\\n",
       "count          11.000          11.000          11.000          10.000   \n",
       "mean            0.015           0.016           0.015           0.014   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.011           0.011           0.011           0.011   \n",
       "25%             0.013           0.013           0.013           0.012   \n",
       "50%             0.013           0.013           0.014           0.013   \n",
       "75%             0.017           0.016           0.017           0.016   \n",
       "max             0.024           0.025           0.024           0.023   \n",
       "\n",
       "       loss_epoch_342  loss_epoch_343  loss_epoch_344  loss_epoch_345  \\\n",
       "count          10.000          10.000          10.000          10.000   \n",
       "mean            0.015           0.014           0.014           0.014   \n",
       "std             0.004           0.003           0.003           0.003   \n",
       "min             0.011           0.011           0.011           0.011   \n",
       "25%             0.012           0.012           0.012           0.012   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.024           0.022           0.022           0.023   \n",
       "\n",
       "       loss_epoch_346  loss_epoch_347  loss_epoch_348  loss_epoch_349  \\\n",
       "count          10.000          10.000          10.000          10.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.004           0.004           0.003           0.004   \n",
       "min             0.011           0.011           0.011           0.011   \n",
       "25%             0.012           0.012           0.013           0.012   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.016           0.016           0.015           0.016   \n",
       "max             0.022           0.023           0.022           0.023   \n",
       "\n",
       "       loss_epoch_350  loss_epoch_351  loss_epoch_352  loss_epoch_353  \\\n",
       "count           9.000           8.000           8.000           8.000   \n",
       "mean            0.014           0.014           0.014           0.014   \n",
       "std             0.004           0.004           0.004           0.004   \n",
       "min             0.011           0.011           0.011           0.011   \n",
       "25%             0.012           0.012           0.012           0.012   \n",
       "50%             0.013           0.013           0.013           0.013   \n",
       "75%             0.015           0.016           0.015           0.015   \n",
       "max             0.023           0.023           0.023           0.022   \n",
       "\n",
       "       loss_epoch_354  loss_epoch_355  loss_epoch_356  loss_epoch_357  \\\n",
       "count           6.000           6.000           6.000           6.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.002           0.002           0.002           0.002   \n",
       "min             0.011           0.011           0.012           0.011   \n",
       "25%             0.011           0.012           0.012           0.011   \n",
       "50%             0.012           0.012           0.012           0.012   \n",
       "75%             0.014           0.014           0.014           0.014   \n",
       "max             0.016           0.016           0.017           0.016   \n",
       "\n",
       "       loss_epoch_358  loss_epoch_359  loss_epoch_360  loss_epoch_361  \\\n",
       "count           6.000           5.000           4.000           3.000   \n",
       "mean            0.013           0.013           0.013           0.013   \n",
       "std             0.002           0.002           0.002           0.003   \n",
       "min             0.011           0.011           0.011           0.011   \n",
       "25%             0.011           0.011           0.012           0.012   \n",
       "50%             0.013           0.012           0.012           0.012   \n",
       "75%             0.014           0.013           0.013           0.014   \n",
       "max             0.016           0.016           0.016           0.016   \n",
       "\n",
       "       loss_epoch_362  loss_epoch_363  loss_epoch_364  loss_epoch_365  \\\n",
       "count           1.000           1.000           1.000           1.000   \n",
       "mean            0.016           0.016           0.016           0.017   \n",
       "std               NaN             NaN             NaN             NaN   \n",
       "min             0.016           0.016           0.016           0.017   \n",
       "25%             0.016           0.016           0.016           0.017   \n",
       "50%             0.016           0.016           0.016           0.017   \n",
       "75%             0.016           0.016           0.016           0.017   \n",
       "max             0.016           0.016           0.016           0.017   \n",
       "\n",
       "       loss_epoch_366  loss_epoch_367  loss_epoch_368  loss_epoch_369  \\\n",
       "count           1.000           1.000           1.000           1.000   \n",
       "mean            0.016           0.016           0.016           0.016   \n",
       "std               NaN             NaN             NaN             NaN   \n",
       "min             0.016           0.016           0.016           0.016   \n",
       "25%             0.016           0.016           0.016           0.016   \n",
       "50%             0.016           0.016           0.016           0.016   \n",
       "75%             0.016           0.016           0.016           0.016   \n",
       "max             0.016           0.016           0.016           0.016   \n",
       "\n",
       "       loss_epoch_370  loss_epoch_371  \n",
       "count           1.000           1.000  \n",
       "mean            0.016           0.016  \n",
       "std               NaN             NaN  \n",
       "min             0.016           0.016  \n",
       "25%             0.016           0.016  \n",
       "50%             0.016           0.016  \n",
       "75%             0.016           0.016  \n",
       "max             0.016           0.016  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>val_loss_epoch_1</th>\n",
       "      <th>val_loss_epoch_2</th>\n",
       "      <th>val_loss_epoch_3</th>\n",
       "      <th>val_loss_epoch_4</th>\n",
       "      <th>val_loss_epoch_5</th>\n",
       "      <th>val_loss_epoch_6</th>\n",
       "      <th>val_loss_epoch_7</th>\n",
       "      <th>val_loss_epoch_8</th>\n",
       "      <th>val_loss_epoch_9</th>\n",
       "      <th>val_loss_epoch_10</th>\n",
       "      <th>val_loss_epoch_11</th>\n",
       "      <th>val_loss_epoch_12</th>\n",
       "      <th>val_loss_epoch_13</th>\n",
       "      <th>val_loss_epoch_14</th>\n",
       "      <th>val_loss_epoch_15</th>\n",
       "      <th>val_loss_epoch_16</th>\n",
       "      <th>val_loss_epoch_17</th>\n",
       "      <th>val_loss_epoch_18</th>\n",
       "      <th>val_loss_epoch_19</th>\n",
       "      <th>val_loss_epoch_20</th>\n",
       "      <th>val_loss_epoch_21</th>\n",
       "      <th>val_loss_epoch_22</th>\n",
       "      <th>val_loss_epoch_23</th>\n",
       "      <th>val_loss_epoch_24</th>\n",
       "      <th>val_loss_epoch_25</th>\n",
       "      <th>val_loss_epoch_26</th>\n",
       "      <th>val_loss_epoch_27</th>\n",
       "      <th>val_loss_epoch_28</th>\n",
       "      <th>val_loss_epoch_29</th>\n",
       "      <th>val_loss_epoch_30</th>\n",
       "      <th>val_loss_epoch_31</th>\n",
       "      <th>val_loss_epoch_32</th>\n",
       "      <th>val_loss_epoch_33</th>\n",
       "      <th>val_loss_epoch_34</th>\n",
       "      <th>val_loss_epoch_35</th>\n",
       "      <th>val_loss_epoch_36</th>\n",
       "      <th>val_loss_epoch_37</th>\n",
       "      <th>val_loss_epoch_38</th>\n",
       "      <th>val_loss_epoch_39</th>\n",
       "      <th>val_loss_epoch_40</th>\n",
       "      <th>val_loss_epoch_41</th>\n",
       "      <th>val_loss_epoch_42</th>\n",
       "      <th>val_loss_epoch_43</th>\n",
       "      <th>val_loss_epoch_44</th>\n",
       "      <th>val_loss_epoch_45</th>\n",
       "      <th>val_loss_epoch_46</th>\n",
       "      <th>val_loss_epoch_47</th>\n",
       "      <th>val_loss_epoch_48</th>\n",
       "      <th>val_loss_epoch_49</th>\n",
       "      <th>val_loss_epoch_50</th>\n",
       "      <th>val_loss_epoch_51</th>\n",
       "      <th>val_loss_epoch_52</th>\n",
       "      <th>val_loss_epoch_53</th>\n",
       "      <th>val_loss_epoch_54</th>\n",
       "      <th>val_loss_epoch_55</th>\n",
       "      <th>val_loss_epoch_56</th>\n",
       "      <th>val_loss_epoch_57</th>\n",
       "      <th>val_loss_epoch_58</th>\n",
       "      <th>val_loss_epoch_59</th>\n",
       "      <th>val_loss_epoch_60</th>\n",
       "      <th>val_loss_epoch_61</th>\n",
       "      <th>val_loss_epoch_62</th>\n",
       "      <th>val_loss_epoch_63</th>\n",
       "      <th>val_loss_epoch_64</th>\n",
       "      <th>val_loss_epoch_65</th>\n",
       "      <th>val_loss_epoch_66</th>\n",
       "      <th>val_loss_epoch_67</th>\n",
       "      <th>val_loss_epoch_68</th>\n",
       "      <th>val_loss_epoch_69</th>\n",
       "      <th>val_loss_epoch_70</th>\n",
       "      <th>val_loss_epoch_71</th>\n",
       "      <th>val_loss_epoch_72</th>\n",
       "      <th>val_loss_epoch_73</th>\n",
       "      <th>val_loss_epoch_74</th>\n",
       "      <th>val_loss_epoch_75</th>\n",
       "      <th>val_loss_epoch_76</th>\n",
       "      <th>val_loss_epoch_77</th>\n",
       "      <th>val_loss_epoch_78</th>\n",
       "      <th>val_loss_epoch_79</th>\n",
       "      <th>val_loss_epoch_80</th>\n",
       "      <th>val_loss_epoch_81</th>\n",
       "      <th>val_loss_epoch_82</th>\n",
       "      <th>val_loss_epoch_83</th>\n",
       "      <th>val_loss_epoch_84</th>\n",
       "      <th>val_loss_epoch_85</th>\n",
       "      <th>val_loss_epoch_86</th>\n",
       "      <th>val_loss_epoch_87</th>\n",
       "      <th>val_loss_epoch_88</th>\n",
       "      <th>val_loss_epoch_89</th>\n",
       "      <th>val_loss_epoch_90</th>\n",
       "      <th>val_loss_epoch_91</th>\n",
       "      <th>val_loss_epoch_92</th>\n",
       "      <th>val_loss_epoch_93</th>\n",
       "      <th>val_loss_epoch_94</th>\n",
       "      <th>val_loss_epoch_95</th>\n",
       "      <th>val_loss_epoch_96</th>\n",
       "      <th>val_loss_epoch_97</th>\n",
       "      <th>val_loss_epoch_98</th>\n",
       "      <th>val_loss_epoch_99</th>\n",
       "      <th>val_loss_epoch_100</th>\n",
       "      <th>val_loss_epoch_101</th>\n",
       "      <th>val_loss_epoch_102</th>\n",
       "      <th>val_loss_epoch_103</th>\n",
       "      <th>val_loss_epoch_104</th>\n",
       "      <th>val_loss_epoch_105</th>\n",
       "      <th>val_loss_epoch_106</th>\n",
       "      <th>val_loss_epoch_107</th>\n",
       "      <th>val_loss_epoch_108</th>\n",
       "      <th>val_loss_epoch_109</th>\n",
       "      <th>val_loss_epoch_110</th>\n",
       "      <th>val_loss_epoch_111</th>\n",
       "      <th>val_loss_epoch_112</th>\n",
       "      <th>val_loss_epoch_113</th>\n",
       "      <th>val_loss_epoch_114</th>\n",
       "      <th>val_loss_epoch_115</th>\n",
       "      <th>val_loss_epoch_116</th>\n",
       "      <th>val_loss_epoch_117</th>\n",
       "      <th>val_loss_epoch_118</th>\n",
       "      <th>val_loss_epoch_119</th>\n",
       "      <th>val_loss_epoch_120</th>\n",
       "      <th>val_loss_epoch_121</th>\n",
       "      <th>val_loss_epoch_122</th>\n",
       "      <th>val_loss_epoch_123</th>\n",
       "      <th>val_loss_epoch_124</th>\n",
       "      <th>val_loss_epoch_125</th>\n",
       "      <th>val_loss_epoch_126</th>\n",
       "      <th>val_loss_epoch_127</th>\n",
       "      <th>val_loss_epoch_128</th>\n",
       "      <th>val_loss_epoch_129</th>\n",
       "      <th>val_loss_epoch_130</th>\n",
       "      <th>val_loss_epoch_131</th>\n",
       "      <th>val_loss_epoch_132</th>\n",
       "      <th>val_loss_epoch_133</th>\n",
       "      <th>val_loss_epoch_134</th>\n",
       "      <th>val_loss_epoch_135</th>\n",
       "      <th>val_loss_epoch_136</th>\n",
       "      <th>val_loss_epoch_137</th>\n",
       "      <th>val_loss_epoch_138</th>\n",
       "      <th>val_loss_epoch_139</th>\n",
       "      <th>val_loss_epoch_140</th>\n",
       "      <th>val_loss_epoch_141</th>\n",
       "      <th>val_loss_epoch_142</th>\n",
       "      <th>val_loss_epoch_143</th>\n",
       "      <th>val_loss_epoch_144</th>\n",
       "      <th>val_loss_epoch_145</th>\n",
       "      <th>val_loss_epoch_146</th>\n",
       "      <th>val_loss_epoch_147</th>\n",
       "      <th>val_loss_epoch_148</th>\n",
       "      <th>val_loss_epoch_149</th>\n",
       "      <th>val_loss_epoch_150</th>\n",
       "      <th>val_loss_epoch_151</th>\n",
       "      <th>val_loss_epoch_152</th>\n",
       "      <th>val_loss_epoch_153</th>\n",
       "      <th>val_loss_epoch_154</th>\n",
       "      <th>val_loss_epoch_155</th>\n",
       "      <th>val_loss_epoch_156</th>\n",
       "      <th>val_loss_epoch_157</th>\n",
       "      <th>val_loss_epoch_158</th>\n",
       "      <th>val_loss_epoch_159</th>\n",
       "      <th>val_loss_epoch_160</th>\n",
       "      <th>val_loss_epoch_161</th>\n",
       "      <th>val_loss_epoch_162</th>\n",
       "      <th>val_loss_epoch_163</th>\n",
       "      <th>val_loss_epoch_164</th>\n",
       "      <th>val_loss_epoch_165</th>\n",
       "      <th>val_loss_epoch_166</th>\n",
       "      <th>val_loss_epoch_167</th>\n",
       "      <th>val_loss_epoch_168</th>\n",
       "      <th>val_loss_epoch_169</th>\n",
       "      <th>val_loss_epoch_170</th>\n",
       "      <th>val_loss_epoch_171</th>\n",
       "      <th>val_loss_epoch_172</th>\n",
       "      <th>val_loss_epoch_173</th>\n",
       "      <th>val_loss_epoch_174</th>\n",
       "      <th>val_loss_epoch_175</th>\n",
       "      <th>val_loss_epoch_176</th>\n",
       "      <th>val_loss_epoch_177</th>\n",
       "      <th>val_loss_epoch_178</th>\n",
       "      <th>val_loss_epoch_179</th>\n",
       "      <th>val_loss_epoch_180</th>\n",
       "      <th>val_loss_epoch_181</th>\n",
       "      <th>val_loss_epoch_182</th>\n",
       "      <th>val_loss_epoch_183</th>\n",
       "      <th>val_loss_epoch_184</th>\n",
       "      <th>val_loss_epoch_185</th>\n",
       "      <th>val_loss_epoch_186</th>\n",
       "      <th>val_loss_epoch_187</th>\n",
       "      <th>val_loss_epoch_188</th>\n",
       "      <th>val_loss_epoch_189</th>\n",
       "      <th>val_loss_epoch_190</th>\n",
       "      <th>val_loss_epoch_191</th>\n",
       "      <th>val_loss_epoch_192</th>\n",
       "      <th>val_loss_epoch_193</th>\n",
       "      <th>val_loss_epoch_194</th>\n",
       "      <th>val_loss_epoch_195</th>\n",
       "      <th>val_loss_epoch_196</th>\n",
       "      <th>val_loss_epoch_197</th>\n",
       "      <th>val_loss_epoch_198</th>\n",
       "      <th>val_loss_epoch_199</th>\n",
       "      <th>val_loss_epoch_200</th>\n",
       "      <th>val_loss_epoch_201</th>\n",
       "      <th>val_loss_epoch_202</th>\n",
       "      <th>val_loss_epoch_203</th>\n",
       "      <th>val_loss_epoch_204</th>\n",
       "      <th>val_loss_epoch_205</th>\n",
       "      <th>val_loss_epoch_206</th>\n",
       "      <th>val_loss_epoch_207</th>\n",
       "      <th>val_loss_epoch_208</th>\n",
       "      <th>val_loss_epoch_209</th>\n",
       "      <th>val_loss_epoch_210</th>\n",
       "      <th>val_loss_epoch_211</th>\n",
       "      <th>val_loss_epoch_212</th>\n",
       "      <th>val_loss_epoch_213</th>\n",
       "      <th>val_loss_epoch_214</th>\n",
       "      <th>val_loss_epoch_215</th>\n",
       "      <th>val_loss_epoch_216</th>\n",
       "      <th>val_loss_epoch_217</th>\n",
       "      <th>val_loss_epoch_218</th>\n",
       "      <th>val_loss_epoch_219</th>\n",
       "      <th>val_loss_epoch_220</th>\n",
       "      <th>val_loss_epoch_221</th>\n",
       "      <th>val_loss_epoch_222</th>\n",
       "      <th>val_loss_epoch_223</th>\n",
       "      <th>val_loss_epoch_224</th>\n",
       "      <th>val_loss_epoch_225</th>\n",
       "      <th>val_loss_epoch_226</th>\n",
       "      <th>val_loss_epoch_227</th>\n",
       "      <th>val_loss_epoch_228</th>\n",
       "      <th>val_loss_epoch_229</th>\n",
       "      <th>val_loss_epoch_230</th>\n",
       "      <th>val_loss_epoch_231</th>\n",
       "      <th>val_loss_epoch_232</th>\n",
       "      <th>val_loss_epoch_233</th>\n",
       "      <th>val_loss_epoch_234</th>\n",
       "      <th>val_loss_epoch_235</th>\n",
       "      <th>val_loss_epoch_236</th>\n",
       "      <th>val_loss_epoch_237</th>\n",
       "      <th>val_loss_epoch_238</th>\n",
       "      <th>val_loss_epoch_239</th>\n",
       "      <th>val_loss_epoch_240</th>\n",
       "      <th>val_loss_epoch_241</th>\n",
       "      <th>val_loss_epoch_242</th>\n",
       "      <th>val_loss_epoch_243</th>\n",
       "      <th>val_loss_epoch_244</th>\n",
       "      <th>val_loss_epoch_245</th>\n",
       "      <th>val_loss_epoch_246</th>\n",
       "      <th>val_loss_epoch_247</th>\n",
       "      <th>val_loss_epoch_248</th>\n",
       "      <th>val_loss_epoch_249</th>\n",
       "      <th>val_loss_epoch_250</th>\n",
       "      <th>val_loss_epoch_251</th>\n",
       "      <th>val_loss_epoch_252</th>\n",
       "      <th>val_loss_epoch_253</th>\n",
       "      <th>val_loss_epoch_254</th>\n",
       "      <th>val_loss_epoch_255</th>\n",
       "      <th>val_loss_epoch_256</th>\n",
       "      <th>val_loss_epoch_257</th>\n",
       "      <th>val_loss_epoch_258</th>\n",
       "      <th>val_loss_epoch_259</th>\n",
       "      <th>val_loss_epoch_260</th>\n",
       "      <th>val_loss_epoch_261</th>\n",
       "      <th>val_loss_epoch_262</th>\n",
       "      <th>val_loss_epoch_263</th>\n",
       "      <th>val_loss_epoch_264</th>\n",
       "      <th>val_loss_epoch_265</th>\n",
       "      <th>val_loss_epoch_266</th>\n",
       "      <th>val_loss_epoch_267</th>\n",
       "      <th>val_loss_epoch_268</th>\n",
       "      <th>val_loss_epoch_269</th>\n",
       "      <th>val_loss_epoch_270</th>\n",
       "      <th>val_loss_epoch_271</th>\n",
       "      <th>val_loss_epoch_272</th>\n",
       "      <th>val_loss_epoch_273</th>\n",
       "      <th>val_loss_epoch_274</th>\n",
       "      <th>val_loss_epoch_275</th>\n",
       "      <th>val_loss_epoch_276</th>\n",
       "      <th>val_loss_epoch_277</th>\n",
       "      <th>val_loss_epoch_278</th>\n",
       "      <th>val_loss_epoch_279</th>\n",
       "      <th>val_loss_epoch_280</th>\n",
       "      <th>val_loss_epoch_281</th>\n",
       "      <th>val_loss_epoch_282</th>\n",
       "      <th>val_loss_epoch_283</th>\n",
       "      <th>val_loss_epoch_284</th>\n",
       "      <th>val_loss_epoch_285</th>\n",
       "      <th>val_loss_epoch_286</th>\n",
       "      <th>val_loss_epoch_287</th>\n",
       "      <th>val_loss_epoch_288</th>\n",
       "      <th>val_loss_epoch_289</th>\n",
       "      <th>val_loss_epoch_290</th>\n",
       "      <th>val_loss_epoch_291</th>\n",
       "      <th>val_loss_epoch_292</th>\n",
       "      <th>val_loss_epoch_293</th>\n",
       "      <th>val_loss_epoch_294</th>\n",
       "      <th>val_loss_epoch_295</th>\n",
       "      <th>val_loss_epoch_296</th>\n",
       "      <th>val_loss_epoch_297</th>\n",
       "      <th>val_loss_epoch_298</th>\n",
       "      <th>val_loss_epoch_299</th>\n",
       "      <th>val_loss_epoch_300</th>\n",
       "      <th>val_loss_epoch_301</th>\n",
       "      <th>val_loss_epoch_302</th>\n",
       "      <th>val_loss_epoch_303</th>\n",
       "      <th>val_loss_epoch_304</th>\n",
       "      <th>val_loss_epoch_305</th>\n",
       "      <th>val_loss_epoch_306</th>\n",
       "      <th>val_loss_epoch_307</th>\n",
       "      <th>val_loss_epoch_308</th>\n",
       "      <th>val_loss_epoch_309</th>\n",
       "      <th>val_loss_epoch_310</th>\n",
       "      <th>val_loss_epoch_311</th>\n",
       "      <th>val_loss_epoch_312</th>\n",
       "      <th>val_loss_epoch_313</th>\n",
       "      <th>val_loss_epoch_314</th>\n",
       "      <th>val_loss_epoch_315</th>\n",
       "      <th>val_loss_epoch_316</th>\n",
       "      <th>val_loss_epoch_317</th>\n",
       "      <th>val_loss_epoch_318</th>\n",
       "      <th>val_loss_epoch_319</th>\n",
       "      <th>val_loss_epoch_320</th>\n",
       "      <th>val_loss_epoch_321</th>\n",
       "      <th>val_loss_epoch_322</th>\n",
       "      <th>val_loss_epoch_323</th>\n",
       "      <th>val_loss_epoch_324</th>\n",
       "      <th>val_loss_epoch_325</th>\n",
       "      <th>val_loss_epoch_326</th>\n",
       "      <th>val_loss_epoch_327</th>\n",
       "      <th>val_loss_epoch_328</th>\n",
       "      <th>val_loss_epoch_329</th>\n",
       "      <th>val_loss_epoch_330</th>\n",
       "      <th>val_loss_epoch_331</th>\n",
       "      <th>val_loss_epoch_332</th>\n",
       "      <th>val_loss_epoch_333</th>\n",
       "      <th>val_loss_epoch_334</th>\n",
       "      <th>val_loss_epoch_335</th>\n",
       "      <th>val_loss_epoch_336</th>\n",
       "      <th>val_loss_epoch_337</th>\n",
       "      <th>val_loss_epoch_338</th>\n",
       "      <th>val_loss_epoch_339</th>\n",
       "      <th>val_loss_epoch_340</th>\n",
       "      <th>val_loss_epoch_341</th>\n",
       "      <th>val_loss_epoch_342</th>\n",
       "      <th>val_loss_epoch_343</th>\n",
       "      <th>val_loss_epoch_344</th>\n",
       "      <th>val_loss_epoch_345</th>\n",
       "      <th>val_loss_epoch_346</th>\n",
       "      <th>val_loss_epoch_347</th>\n",
       "      <th>val_loss_epoch_348</th>\n",
       "      <th>val_loss_epoch_349</th>\n",
       "      <th>val_loss_epoch_350</th>\n",
       "      <th>val_loss_epoch_351</th>\n",
       "      <th>val_loss_epoch_352</th>\n",
       "      <th>val_loss_epoch_353</th>\n",
       "      <th>val_loss_epoch_354</th>\n",
       "      <th>val_loss_epoch_355</th>\n",
       "      <th>val_loss_epoch_356</th>\n",
       "      <th>val_loss_epoch_357</th>\n",
       "      <th>val_loss_epoch_358</th>\n",
       "      <th>val_loss_epoch_359</th>\n",
       "      <th>val_loss_epoch_360</th>\n",
       "      <th>val_loss_epoch_361</th>\n",
       "      <th>val_loss_epoch_362</th>\n",
       "      <th>val_loss_epoch_363</th>\n",
       "      <th>val_loss_epoch_364</th>\n",
       "      <th>val_loss_epoch_365</th>\n",
       "      <th>val_loss_epoch_366</th>\n",
       "      <th>val_loss_epoch_367</th>\n",
       "      <th>val_loss_epoch_368</th>\n",
       "      <th>val_loss_epoch_369</th>\n",
       "      <th>val_loss_epoch_370</th>\n",
       "      <th>val_loss_epoch_371</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>49999.000</td>\n",
       "      <td>49999.000</td>\n",
       "      <td>49997.000</td>\n",
       "      <td>49997.000</td>\n",
       "      <td>49996.000</td>\n",
       "      <td>49996.000</td>\n",
       "      <td>49995.000</td>\n",
       "      <td>49994.000</td>\n",
       "      <td>49992.000</td>\n",
       "      <td>49992.000</td>\n",
       "      <td>49989.000</td>\n",
       "      <td>49984.000</td>\n",
       "      <td>49982.000</td>\n",
       "      <td>49980.000</td>\n",
       "      <td>49974.000</td>\n",
       "      <td>49970.000</td>\n",
       "      <td>49965.000</td>\n",
       "      <td>49960.000</td>\n",
       "      <td>49957.000</td>\n",
       "      <td>49949.000</td>\n",
       "      <td>49945.000</td>\n",
       "      <td>49935.000</td>\n",
       "      <td>49923.000</td>\n",
       "      <td>49905.000</td>\n",
       "      <td>49890.000</td>\n",
       "      <td>49876.000</td>\n",
       "      <td>49856.000</td>\n",
       "      <td>49835.000</td>\n",
       "      <td>49810.000</td>\n",
       "      <td>49785.000</td>\n",
       "      <td>49762.000</td>\n",
       "      <td>49727.000</td>\n",
       "      <td>49689.000</td>\n",
       "      <td>49646.000</td>\n",
       "      <td>49613.000</td>\n",
       "      <td>49576.000</td>\n",
       "      <td>49535.000</td>\n",
       "      <td>49483.000</td>\n",
       "      <td>49428.000</td>\n",
       "      <td>49357.000</td>\n",
       "      <td>49282.000</td>\n",
       "      <td>49198.000</td>\n",
       "      <td>49107.000</td>\n",
       "      <td>49000.000</td>\n",
       "      <td>48880.000</td>\n",
       "      <td>48770.000</td>\n",
       "      <td>48637.000</td>\n",
       "      <td>48489.000</td>\n",
       "      <td>48358.000</td>\n",
       "      <td>48202.000</td>\n",
       "      <td>48024.000</td>\n",
       "      <td>47845.000</td>\n",
       "      <td>47646.000</td>\n",
       "      <td>47447.000</td>\n",
       "      <td>47224.000</td>\n",
       "      <td>46989.000</td>\n",
       "      <td>46764.000</td>\n",
       "      <td>46530.000</td>\n",
       "      <td>46244.000</td>\n",
       "      <td>45959.000</td>\n",
       "      <td>45683.000</td>\n",
       "      <td>45352.000</td>\n",
       "      <td>45032.000</td>\n",
       "      <td>44725.000</td>\n",
       "      <td>44416.000</td>\n",
       "      <td>44045.000</td>\n",
       "      <td>43666.000</td>\n",
       "      <td>43276.000</td>\n",
       "      <td>42871.000</td>\n",
       "      <td>42516.000</td>\n",
       "      <td>42120.000</td>\n",
       "      <td>41681.000</td>\n",
       "      <td>41237.000</td>\n",
       "      <td>40781.000</td>\n",
       "      <td>40315.000</td>\n",
       "      <td>39829.000</td>\n",
       "      <td>39368.000</td>\n",
       "      <td>38884.000</td>\n",
       "      <td>38358.000</td>\n",
       "      <td>37875.000</td>\n",
       "      <td>37348.000</td>\n",
       "      <td>36860.000</td>\n",
       "      <td>36343.000</td>\n",
       "      <td>35791.000</td>\n",
       "      <td>35260.000</td>\n",
       "      <td>34687.000</td>\n",
       "      <td>34157.000</td>\n",
       "      <td>33582.000</td>\n",
       "      <td>33063.000</td>\n",
       "      <td>32504.000</td>\n",
       "      <td>31957.000</td>\n",
       "      <td>31392.000</td>\n",
       "      <td>30845.000</td>\n",
       "      <td>30268.000</td>\n",
       "      <td>29729.000</td>\n",
       "      <td>29168.000</td>\n",
       "      <td>28631.000</td>\n",
       "      <td>27983.000</td>\n",
       "      <td>27429.000</td>\n",
       "      <td>26867.000</td>\n",
       "      <td>26363.000</td>\n",
       "      <td>25806.000</td>\n",
       "      <td>25243.000</td>\n",
       "      <td>24678.000</td>\n",
       "      <td>24168.000</td>\n",
       "      <td>23634.000</td>\n",
       "      <td>23071.000</td>\n",
       "      <td>22521.000</td>\n",
       "      <td>21987.000</td>\n",
       "      <td>21456.000</td>\n",
       "      <td>20973.000</td>\n",
       "      <td>20467.000</td>\n",
       "      <td>19984.000</td>\n",
       "      <td>19485.000</td>\n",
       "      <td>19010.000</td>\n",
       "      <td>18544.000</td>\n",
       "      <td>18054.000</td>\n",
       "      <td>17599.000</td>\n",
       "      <td>17138.000</td>\n",
       "      <td>16695.000</td>\n",
       "      <td>16231.000</td>\n",
       "      <td>15795.000</td>\n",
       "      <td>15394.000</td>\n",
       "      <td>14973.000</td>\n",
       "      <td>14563.000</td>\n",
       "      <td>14150.000</td>\n",
       "      <td>13751.000</td>\n",
       "      <td>13347.000</td>\n",
       "      <td>12961.000</td>\n",
       "      <td>12579.000</td>\n",
       "      <td>12195.000</td>\n",
       "      <td>11826.000</td>\n",
       "      <td>11507.000</td>\n",
       "      <td>11169.000</td>\n",
       "      <td>10845.000</td>\n",
       "      <td>10467.000</td>\n",
       "      <td>10136.000</td>\n",
       "      <td>9816.000</td>\n",
       "      <td>9524.000</td>\n",
       "      <td>9211.000</td>\n",
       "      <td>8910.000</td>\n",
       "      <td>8632.000</td>\n",
       "      <td>8389.000</td>\n",
       "      <td>8105.000</td>\n",
       "      <td>7861.000</td>\n",
       "      <td>7574.000</td>\n",
       "      <td>7322.000</td>\n",
       "      <td>7087.000</td>\n",
       "      <td>6849.000</td>\n",
       "      <td>6618.000</td>\n",
       "      <td>6415.000</td>\n",
       "      <td>6201.000</td>\n",
       "      <td>5968.000</td>\n",
       "      <td>5776.000</td>\n",
       "      <td>5573.000</td>\n",
       "      <td>5374.000</td>\n",
       "      <td>5191.000</td>\n",
       "      <td>5013.000</td>\n",
       "      <td>4861.000</td>\n",
       "      <td>4688.000</td>\n",
       "      <td>4506.000</td>\n",
       "      <td>4349.000</td>\n",
       "      <td>4214.000</td>\n",
       "      <td>4077.000</td>\n",
       "      <td>3932.000</td>\n",
       "      <td>3783.000</td>\n",
       "      <td>3642.000</td>\n",
       "      <td>3509.000</td>\n",
       "      <td>3363.000</td>\n",
       "      <td>3234.000</td>\n",
       "      <td>3116.000</td>\n",
       "      <td>3004.000</td>\n",
       "      <td>2885.000</td>\n",
       "      <td>2773.000</td>\n",
       "      <td>2690.000</td>\n",
       "      <td>2584.000</td>\n",
       "      <td>2484.000</td>\n",
       "      <td>2386.000</td>\n",
       "      <td>2291.000</td>\n",
       "      <td>2205.000</td>\n",
       "      <td>2119.000</td>\n",
       "      <td>2034.000</td>\n",
       "      <td>1967.000</td>\n",
       "      <td>1896.000</td>\n",
       "      <td>1824.000</td>\n",
       "      <td>1753.000</td>\n",
       "      <td>1688.000</td>\n",
       "      <td>1610.000</td>\n",
       "      <td>1544.000</td>\n",
       "      <td>1481.000</td>\n",
       "      <td>1429.000</td>\n",
       "      <td>1376.000</td>\n",
       "      <td>1310.000</td>\n",
       "      <td>1262.000</td>\n",
       "      <td>1214.000</td>\n",
       "      <td>1160.000</td>\n",
       "      <td>1114.000</td>\n",
       "      <td>1058.000</td>\n",
       "      <td>1019.000</td>\n",
       "      <td>986.000</td>\n",
       "      <td>953.000</td>\n",
       "      <td>921.000</td>\n",
       "      <td>886.000</td>\n",
       "      <td>855.000</td>\n",
       "      <td>822.000</td>\n",
       "      <td>787.000</td>\n",
       "      <td>745.000</td>\n",
       "      <td>715.000</td>\n",
       "      <td>682.000</td>\n",
       "      <td>646.000</td>\n",
       "      <td>618.000</td>\n",
       "      <td>599.000</td>\n",
       "      <td>567.000</td>\n",
       "      <td>538.000</td>\n",
       "      <td>519.000</td>\n",
       "      <td>497.000</td>\n",
       "      <td>479.000</td>\n",
       "      <td>462.000</td>\n",
       "      <td>438.000</td>\n",
       "      <td>417.000</td>\n",
       "      <td>396.000</td>\n",
       "      <td>379.000</td>\n",
       "      <td>364.000</td>\n",
       "      <td>341.000</td>\n",
       "      <td>327.000</td>\n",
       "      <td>315.000</td>\n",
       "      <td>296.000</td>\n",
       "      <td>284.000</td>\n",
       "      <td>270.000</td>\n",
       "      <td>257.000</td>\n",
       "      <td>240.000</td>\n",
       "      <td>232.000</td>\n",
       "      <td>222.000</td>\n",
       "      <td>211.000</td>\n",
       "      <td>202.000</td>\n",
       "      <td>192.000</td>\n",
       "      <td>186.000</td>\n",
       "      <td>175.000</td>\n",
       "      <td>168.000</td>\n",
       "      <td>156.000</td>\n",
       "      <td>151.000</td>\n",
       "      <td>146.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>133.000</td>\n",
       "      <td>123.000</td>\n",
       "      <td>119.000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>114.000</td>\n",
       "      <td>108.000</td>\n",
       "      <td>104.000</td>\n",
       "      <td>102.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>89.000</td>\n",
       "      <td>87.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>79.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>71.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24999.500</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14433.901</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12499.750</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24999.500</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37499.250</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49999.000</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  val_loss_epoch_1  val_loss_epoch_2  val_loss_epoch_3  \\\n",
       "count 50000.000         50000.000         50000.000         50000.000   \n",
       "mean  24999.500             0.199             0.134             0.100   \n",
       "std   14433.901             0.089             0.059             0.043   \n",
       "min       0.000             0.041             0.028             0.018   \n",
       "25%   12499.750             0.140             0.091             0.071   \n",
       "50%   24999.500             0.182             0.120             0.091   \n",
       "75%   37499.250             0.237             0.164             0.117   \n",
       "max   49999.000             1.327             0.546             0.449   \n",
       "\n",
       "       val_loss_epoch_4  val_loss_epoch_5  val_loss_epoch_6  val_loss_epoch_7  \\\n",
       "count         50000.000         50000.000         50000.000         50000.000   \n",
       "mean              0.084             0.075             0.069             0.065   \n",
       "std               0.033             0.028             0.025             0.024   \n",
       "min               0.014             0.011             0.010             0.008   \n",
       "25%               0.062             0.056             0.051             0.048   \n",
       "50%               0.079             0.071             0.066             0.062   \n",
       "75%               0.099             0.090             0.083             0.078   \n",
       "max               0.341             0.278             0.237             0.205   \n",
       "\n",
       "       val_loss_epoch_8  val_loss_epoch_9  val_loss_epoch_10  \\\n",
       "count         50000.000         50000.000          50000.000   \n",
       "mean              0.061             0.058              0.055   \n",
       "std               0.022             0.022              0.021   \n",
       "min               0.008             0.007              0.007   \n",
       "25%               0.045             0.042              0.040   \n",
       "50%               0.058             0.055              0.052   \n",
       "75%               0.074             0.070              0.067   \n",
       "max               0.184             0.178              0.173   \n",
       "\n",
       "       val_loss_epoch_11  val_loss_epoch_12  val_loss_epoch_13  \\\n",
       "count          50000.000          50000.000          50000.000   \n",
       "mean               0.053              0.051              0.049   \n",
       "std                0.020              0.020              0.019   \n",
       "min                0.006              0.006              0.005   \n",
       "25%                0.038              0.036              0.035   \n",
       "50%                0.050              0.048              0.046   \n",
       "75%                0.064              0.062              0.060   \n",
       "max                0.168              0.163              0.158   \n",
       "\n",
       "       val_loss_epoch_14  val_loss_epoch_15  val_loss_epoch_16  \\\n",
       "count          50000.000          50000.000          50000.000   \n",
       "mean               0.047              0.045              0.044   \n",
       "std                0.019              0.018              0.018   \n",
       "min                0.005              0.005              0.005   \n",
       "25%                0.034              0.032              0.031   \n",
       "50%                0.044              0.043              0.041   \n",
       "75%                0.057              0.055              0.054   \n",
       "max                0.156              0.154              0.153   \n",
       "\n",
       "       val_loss_epoch_17  val_loss_epoch_18  val_loss_epoch_19  \\\n",
       "count          50000.000          50000.000          50000.000   \n",
       "mean               0.042              0.041              0.040   \n",
       "std                0.017              0.017              0.016   \n",
       "min                0.004              0.004              0.004   \n",
       "25%                0.030              0.029              0.028   \n",
       "50%                0.040              0.038              0.037   \n",
       "75%                0.052              0.050              0.048   \n",
       "max                0.151              0.151              0.150   \n",
       "\n",
       "       val_loss_epoch_20  val_loss_epoch_21  val_loss_epoch_22  \\\n",
       "count          50000.000          50000.000          50000.000   \n",
       "mean               0.039              0.037              0.036   \n",
       "std                0.016              0.015              0.015   \n",
       "min                0.004              0.003              0.003   \n",
       "25%                0.028              0.027              0.026   \n",
       "50%                0.036              0.035              0.034   \n",
       "75%                0.047              0.045              0.044   \n",
       "max                0.150              0.147              0.146   \n",
       "\n",
       "       val_loss_epoch_23  val_loss_epoch_24  val_loss_epoch_25  \\\n",
       "count          50000.000          50000.000          50000.000   \n",
       "mean               0.035              0.034              0.033   \n",
       "std                0.014              0.014              0.014   \n",
       "min                0.005              0.003              0.003   \n",
       "25%                0.025              0.025              0.024   \n",
       "50%                0.033              0.032              0.031   \n",
       "75%                0.043              0.041              0.040   \n",
       "max                0.145              0.141              0.139   \n",
       "\n",
       "       val_loss_epoch_26  val_loss_epoch_27  val_loss_epoch_28  \\\n",
       "count          50000.000          50000.000          50000.000   \n",
       "mean               0.033              0.032              0.031   \n",
       "std                0.013              0.013              0.013   \n",
       "min                0.004              0.003              0.003   \n",
       "25%                0.023              0.023              0.022   \n",
       "50%                0.030              0.029              0.028   \n",
       "75%                0.039              0.038              0.037   \n",
       "max                0.138              0.138              0.135   \n",
       "\n",
       "       val_loss_epoch_29  val_loss_epoch_30  val_loss_epoch_31  \\\n",
       "count          50000.000          50000.000          50000.000   \n",
       "mean               0.030              0.029              0.029   \n",
       "std                0.012              0.012              0.012   \n",
       "min                0.003              0.003              0.002   \n",
       "25%                0.022              0.021              0.021   \n",
       "50%                0.028              0.027              0.027   \n",
       "75%                0.036              0.035              0.034   \n",
       "max                0.134              0.133              0.131   \n",
       "\n",
       "       val_loss_epoch_32  val_loss_epoch_33  val_loss_epoch_34  \\\n",
       "count          50000.000          50000.000          50000.000   \n",
       "mean               0.028              0.027              0.027   \n",
       "std                0.011              0.011              0.011   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.020              0.020              0.020   \n",
       "50%                0.026              0.025              0.025   \n",
       "75%                0.033              0.032              0.031   \n",
       "max                0.130              0.129              0.129   \n",
       "\n",
       "       val_loss_epoch_35  val_loss_epoch_36  val_loss_epoch_37  \\\n",
       "count          50000.000          50000.000          50000.000   \n",
       "mean               0.026              0.026              0.025   \n",
       "std                0.011              0.010              0.010   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.019              0.019              0.019   \n",
       "50%                0.024              0.024              0.023   \n",
       "75%                0.031              0.030              0.030   \n",
       "max                0.127              0.125              0.124   \n",
       "\n",
       "       val_loss_epoch_38  val_loss_epoch_39  val_loss_epoch_40  \\\n",
       "count          50000.000          49999.000          49999.000   \n",
       "mean               0.025              0.024              0.024   \n",
       "std                0.010              0.010              0.009   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.018              0.018              0.018   \n",
       "50%                0.023              0.023              0.022   \n",
       "75%                0.029              0.028              0.028   \n",
       "max                0.123              0.122              0.121   \n",
       "\n",
       "       val_loss_epoch_41  val_loss_epoch_42  val_loss_epoch_43  \\\n",
       "count          49997.000          49997.000          49996.000   \n",
       "mean               0.024              0.023              0.023   \n",
       "std                0.009              0.009              0.009   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.017              0.017              0.017   \n",
       "50%                0.022              0.022              0.021   \n",
       "75%                0.027              0.027              0.027   \n",
       "max                0.120              0.120              0.118   \n",
       "\n",
       "       val_loss_epoch_44  val_loss_epoch_45  val_loss_epoch_46  \\\n",
       "count          49996.000          49995.000          49994.000   \n",
       "mean               0.022              0.022              0.022   \n",
       "std                0.009              0.009              0.008   \n",
       "min                0.003              0.002              0.002   \n",
       "25%                0.017              0.017              0.016   \n",
       "50%                0.021              0.021              0.020   \n",
       "75%                0.026              0.026              0.025   \n",
       "max                0.120              0.117              0.115   \n",
       "\n",
       "       val_loss_epoch_47  val_loss_epoch_48  val_loss_epoch_49  \\\n",
       "count          49992.000          49992.000          49989.000   \n",
       "mean               0.021              0.021              0.021   \n",
       "std                0.008              0.008              0.008   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.016              0.016              0.016   \n",
       "50%                0.020              0.020              0.020   \n",
       "75%                0.025              0.025              0.024   \n",
       "max                0.113              0.113              0.110   \n",
       "\n",
       "       val_loss_epoch_50  val_loss_epoch_51  val_loss_epoch_52  \\\n",
       "count          49984.000          49982.000          49980.000   \n",
       "mean               0.021              0.020              0.020   \n",
       "std                0.008              0.008              0.008   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.016              0.015              0.015   \n",
       "50%                0.019              0.019              0.019   \n",
       "75%                0.024              0.024              0.024   \n",
       "max                0.112              0.109              0.108   \n",
       "\n",
       "       val_loss_epoch_53  val_loss_epoch_54  val_loss_epoch_55  \\\n",
       "count          49974.000          49970.000          49965.000   \n",
       "mean               0.020              0.020              0.020   \n",
       "std                0.008              0.007              0.007   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.015              0.015              0.015   \n",
       "50%                0.019              0.019              0.018   \n",
       "75%                0.023              0.023              0.023   \n",
       "max                0.110              0.108              0.107   \n",
       "\n",
       "       val_loss_epoch_56  val_loss_epoch_57  val_loss_epoch_58  \\\n",
       "count          49960.000          49957.000          49949.000   \n",
       "mean               0.019              0.019              0.019   \n",
       "std                0.007              0.007              0.007   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.015              0.014              0.014   \n",
       "50%                0.018              0.018              0.018   \n",
       "75%                0.023              0.022              0.022   \n",
       "max                0.107              0.107              0.107   \n",
       "\n",
       "       val_loss_epoch_59  val_loss_epoch_60  val_loss_epoch_61  \\\n",
       "count          49945.000          49935.000          49923.000   \n",
       "mean               0.019              0.019              0.018   \n",
       "std                0.007              0.007              0.007   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.014              0.014              0.014   \n",
       "50%                0.018              0.018              0.017   \n",
       "75%                0.022              0.022              0.022   \n",
       "max                0.109              0.107              0.107   \n",
       "\n",
       "       val_loss_epoch_62  val_loss_epoch_63  val_loss_epoch_64  \\\n",
       "count          49905.000          49890.000          49876.000   \n",
       "mean               0.018              0.018              0.018   \n",
       "std                0.007              0.007              0.007   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.014              0.014              0.014   \n",
       "50%                0.017              0.017              0.017   \n",
       "75%                0.021              0.021              0.021   \n",
       "max                0.106              0.108              0.106   \n",
       "\n",
       "       val_loss_epoch_65  val_loss_epoch_66  val_loss_epoch_67  \\\n",
       "count          49856.000          49835.000          49810.000   \n",
       "mean               0.018              0.018              0.018   \n",
       "std                0.006              0.006              0.006   \n",
       "min                0.002              0.003              0.002   \n",
       "25%                0.014              0.013              0.013   \n",
       "50%                0.017              0.017              0.017   \n",
       "75%                0.021              0.021              0.021   \n",
       "max                0.106              0.105              0.106   \n",
       "\n",
       "       val_loss_epoch_68  val_loss_epoch_69  val_loss_epoch_70  \\\n",
       "count          49785.000          49762.000          49727.000   \n",
       "mean               0.017              0.017              0.017   \n",
       "std                0.006              0.006              0.006   \n",
       "min                0.002              0.003              0.002   \n",
       "25%                0.013              0.013              0.013   \n",
       "50%                0.017              0.016              0.016   \n",
       "75%                0.020              0.020              0.020   \n",
       "max                0.104              0.104              0.103   \n",
       "\n",
       "       val_loss_epoch_71  val_loss_epoch_72  val_loss_epoch_73  \\\n",
       "count          49689.000          49646.000          49613.000   \n",
       "mean               0.017              0.017              0.017   \n",
       "std                0.006              0.006              0.006   \n",
       "min                0.003              0.002              0.002   \n",
       "25%                0.013              0.013              0.013   \n",
       "50%                0.016              0.016              0.016   \n",
       "75%                0.020              0.020              0.020   \n",
       "max                0.104              0.101              0.101   \n",
       "\n",
       "       val_loss_epoch_74  val_loss_epoch_75  val_loss_epoch_76  \\\n",
       "count          49576.000          49535.000          49483.000   \n",
       "mean               0.017              0.017              0.017   \n",
       "std                0.006              0.006              0.006   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.013              0.013              0.013   \n",
       "50%                0.016              0.016              0.016   \n",
       "75%                0.020              0.020              0.019   \n",
       "max                0.100              0.101              0.099   \n",
       "\n",
       "       val_loss_epoch_77  val_loss_epoch_78  val_loss_epoch_79  \\\n",
       "count          49428.000          49357.000          49282.000   \n",
       "mean               0.016              0.016              0.016   \n",
       "std                0.006              0.006              0.006   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.012              0.012              0.012   \n",
       "50%                0.016              0.016              0.015   \n",
       "75%                0.019              0.019              0.019   \n",
       "max                0.098              0.096              0.096   \n",
       "\n",
       "       val_loss_epoch_80  val_loss_epoch_81  val_loss_epoch_82  \\\n",
       "count          49198.000          49107.000          49000.000   \n",
       "mean               0.016              0.016              0.016   \n",
       "std                0.006              0.006              0.006   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.012              0.012              0.012   \n",
       "50%                0.015              0.015              0.015   \n",
       "75%                0.019              0.019              0.019   \n",
       "max                0.094              0.095              0.089   \n",
       "\n",
       "       val_loss_epoch_83  val_loss_epoch_84  val_loss_epoch_85  \\\n",
       "count          48880.000          48770.000          48637.000   \n",
       "mean               0.016              0.016              0.016   \n",
       "std                0.006              0.006              0.006   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.012              0.012              0.012   \n",
       "50%                0.015              0.015              0.015   \n",
       "75%                0.019              0.019              0.018   \n",
       "max                0.088              0.085              0.083   \n",
       "\n",
       "       val_loss_epoch_86  val_loss_epoch_87  val_loss_epoch_88  \\\n",
       "count          48489.000          48358.000          48202.000   \n",
       "mean               0.016              0.016              0.015   \n",
       "std                0.005              0.005              0.005   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.012              0.012              0.012   \n",
       "50%                0.015              0.015              0.015   \n",
       "75%                0.018              0.018              0.018   \n",
       "max                0.080              0.077              0.077   \n",
       "\n",
       "       val_loss_epoch_89  val_loss_epoch_90  val_loss_epoch_91  \\\n",
       "count          48024.000          47845.000          47646.000   \n",
       "mean               0.015              0.015              0.015   \n",
       "std                0.005              0.005              0.005   \n",
       "min                0.002              0.003              0.002   \n",
       "25%                0.012              0.012              0.012   \n",
       "50%                0.015              0.015              0.015   \n",
       "75%                0.018              0.018              0.018   \n",
       "max                0.076              0.075              0.074   \n",
       "\n",
       "       val_loss_epoch_92  val_loss_epoch_93  val_loss_epoch_94  \\\n",
       "count          47447.000          47224.000          46989.000   \n",
       "mean               0.015              0.015              0.015   \n",
       "std                0.005              0.005              0.005   \n",
       "min                0.002              0.002              0.002   \n",
       "25%                0.012              0.012              0.012   \n",
       "50%                0.014              0.014              0.014   \n",
       "75%                0.018              0.018              0.018   \n",
       "max                0.078              0.074              0.073   \n",
       "\n",
       "       val_loss_epoch_95  val_loss_epoch_96  val_loss_epoch_97  \\\n",
       "count          46764.000          46530.000          46244.000   \n",
       "mean               0.015              0.015              0.015   \n",
       "std                0.005              0.005              0.005   \n",
       "min                0.003              0.002              0.002   \n",
       "25%                0.011              0.011              0.011   \n",
       "50%                0.014              0.014              0.014   \n",
       "75%                0.018              0.018              0.018   \n",
       "max                0.074              0.073              0.072   \n",
       "\n",
       "       val_loss_epoch_98  val_loss_epoch_99  val_loss_epoch_100  \\\n",
       "count          45959.000          45683.000           45352.000   \n",
       "mean               0.015              0.015               0.015   \n",
       "std                0.005              0.005               0.005   \n",
       "min                0.002              0.002               0.002   \n",
       "25%                0.011              0.011               0.011   \n",
       "50%                0.014              0.014               0.014   \n",
       "75%                0.018              0.017               0.017   \n",
       "max                0.073              0.072               0.072   \n",
       "\n",
       "       val_loss_epoch_101  val_loss_epoch_102  val_loss_epoch_103  \\\n",
       "count           45032.000           44725.000           44416.000   \n",
       "mean                0.015               0.015               0.015   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.072               0.073               0.072   \n",
       "\n",
       "       val_loss_epoch_104  val_loss_epoch_105  val_loss_epoch_106  \\\n",
       "count           44045.000           43666.000           43276.000   \n",
       "mean                0.015               0.015               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.071               0.071               0.070   \n",
       "\n",
       "       val_loss_epoch_107  val_loss_epoch_108  val_loss_epoch_109  \\\n",
       "count           42871.000           42516.000           42120.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.071               0.069               0.069   \n",
       "\n",
       "       val_loss_epoch_110  val_loss_epoch_111  val_loss_epoch_112  \\\n",
       "count           41681.000           41237.000           40781.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.003               0.002   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.069               0.068               0.067   \n",
       "\n",
       "       val_loss_epoch_113  val_loss_epoch_114  val_loss_epoch_115  \\\n",
       "count           40315.000           39829.000           39368.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.002               0.003   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.068               0.065               0.065   \n",
       "\n",
       "       val_loss_epoch_116  val_loss_epoch_117  val_loss_epoch_118  \\\n",
       "count           38884.000           38358.000           37875.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.002               0.003               0.002   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.017               0.017               0.016   \n",
       "max                 0.063               0.062               0.061   \n",
       "\n",
       "       val_loss_epoch_119  val_loss_epoch_120  val_loss_epoch_121  \\\n",
       "count           37348.000           36860.000           36343.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.003               0.002   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.059               0.058               0.057   \n",
       "\n",
       "       val_loss_epoch_122  val_loss_epoch_123  val_loss_epoch_124  \\\n",
       "count           35791.000           35260.000           34687.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.057               0.057               0.057   \n",
       "\n",
       "       val_loss_epoch_125  val_loss_epoch_126  val_loss_epoch_127  \\\n",
       "count           34157.000           33582.000           33063.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.057               0.060               0.058   \n",
       "\n",
       "       val_loss_epoch_128  val_loss_epoch_129  val_loss_epoch_130  \\\n",
       "count           32504.000           31957.000           31392.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.055               0.054               0.054   \n",
       "\n",
       "       val_loss_epoch_131  val_loss_epoch_132  val_loss_epoch_133  \\\n",
       "count           30845.000           30268.000           29729.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.053               0.053               0.052   \n",
       "\n",
       "       val_loss_epoch_134  val_loss_epoch_135  val_loss_epoch_136  \\\n",
       "count           29168.000           28631.000           27983.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.002               0.003               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.052               0.052               0.052   \n",
       "\n",
       "       val_loss_epoch_137  val_loss_epoch_138  val_loss_epoch_139  \\\n",
       "count           27429.000           26867.000           26363.000   \n",
       "mean                0.014               0.014               0.013   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.052               0.054               0.052   \n",
       "\n",
       "       val_loss_epoch_140  val_loss_epoch_141  val_loss_epoch_142  \\\n",
       "count           25806.000           25243.000           24678.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.052               0.052               0.051   \n",
       "\n",
       "       val_loss_epoch_143  val_loss_epoch_144  val_loss_epoch_145  \\\n",
       "count           24168.000           23634.000           23071.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.003               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.051               0.051               0.051   \n",
       "\n",
       "       val_loss_epoch_146  val_loss_epoch_147  val_loss_epoch_148  \\\n",
       "count           22521.000           21987.000           21456.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.002               0.003               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.051               0.051               0.051   \n",
       "\n",
       "       val_loss_epoch_149  val_loss_epoch_150  val_loss_epoch_151  \\\n",
       "count           20973.000           20467.000           19984.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.002               0.003               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.051               0.050               0.049   \n",
       "\n",
       "       val_loss_epoch_152  val_loss_epoch_153  val_loss_epoch_154  \\\n",
       "count           19485.000           19010.000           18544.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.005               0.004               0.004   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.050               0.050               0.049   \n",
       "\n",
       "       val_loss_epoch_155  val_loss_epoch_156  val_loss_epoch_157  \\\n",
       "count           18054.000           17599.000           17138.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.050               0.049               0.049   \n",
       "\n",
       "       val_loss_epoch_158  val_loss_epoch_159  val_loss_epoch_160  \\\n",
       "count           16695.000           16231.000           15795.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.049               0.050               0.048   \n",
       "\n",
       "       val_loss_epoch_161  val_loss_epoch_162  val_loss_epoch_163  \\\n",
       "count           15394.000           14973.000           14563.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.048               0.048               0.048   \n",
       "\n",
       "       val_loss_epoch_164  val_loss_epoch_165  val_loss_epoch_166  \\\n",
       "count           14150.000           13751.000           13347.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.047               0.047               0.047   \n",
       "\n",
       "       val_loss_epoch_167  val_loss_epoch_168  val_loss_epoch_169  \\\n",
       "count           12961.000           12579.000           12195.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.003               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.047               0.048               0.046   \n",
       "\n",
       "       val_loss_epoch_170  val_loss_epoch_171  val_loss_epoch_172  \\\n",
       "count           11826.000           11507.000           11169.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.047               0.046               0.047   \n",
       "\n",
       "       val_loss_epoch_173  val_loss_epoch_174  val_loss_epoch_175  \\\n",
       "count           10845.000           10467.000           10136.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.045               0.047               0.046   \n",
       "\n",
       "       val_loss_epoch_176  val_loss_epoch_177  val_loss_epoch_178  \\\n",
       "count            9816.000            9524.000            9211.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.045               0.045               0.045   \n",
       "\n",
       "       val_loss_epoch_179  val_loss_epoch_180  val_loss_epoch_181  \\\n",
       "count            8910.000            8632.000            8389.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.002               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.045               0.044               0.045   \n",
       "\n",
       "       val_loss_epoch_182  val_loss_epoch_183  val_loss_epoch_184  \\\n",
       "count            8105.000            7861.000            7574.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.044               0.044               0.044   \n",
       "\n",
       "       val_loss_epoch_185  val_loss_epoch_186  val_loss_epoch_187  \\\n",
       "count            7322.000            7087.000            6849.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.043               0.043               0.043   \n",
       "\n",
       "       val_loss_epoch_188  val_loss_epoch_189  val_loss_epoch_190  \\\n",
       "count            6618.000            6415.000            6201.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.042               0.043               0.042   \n",
       "\n",
       "       val_loss_epoch_191  val_loss_epoch_192  val_loss_epoch_193  \\\n",
       "count            5968.000            5776.000            5573.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.046               0.042               0.043   \n",
       "\n",
       "       val_loss_epoch_194  val_loss_epoch_195  val_loss_epoch_196  \\\n",
       "count            5374.000            5191.000            5013.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.044               0.041               0.041   \n",
       "\n",
       "       val_loss_epoch_197  val_loss_epoch_198  val_loss_epoch_199  \\\n",
       "count            4861.000            4688.000            4506.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.002               0.003               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.043               0.042               0.040   \n",
       "\n",
       "       val_loss_epoch_200  val_loss_epoch_201  val_loss_epoch_202  \\\n",
       "count            4349.000            4214.000            4077.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.002   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.041               0.040               0.043   \n",
       "\n",
       "       val_loss_epoch_203  val_loss_epoch_204  val_loss_epoch_205  \\\n",
       "count            3932.000            3783.000            3642.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.004   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.041               0.040               0.043   \n",
       "\n",
       "       val_loss_epoch_206  val_loss_epoch_207  val_loss_epoch_208  \\\n",
       "count            3509.000            3363.000            3234.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.041               0.041               0.045   \n",
       "\n",
       "       val_loss_epoch_209  val_loss_epoch_210  val_loss_epoch_211  \\\n",
       "count            3116.000            3004.000            2885.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.003               0.004   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.042               0.041               0.042   \n",
       "\n",
       "       val_loss_epoch_212  val_loss_epoch_213  val_loss_epoch_214  \\\n",
       "count            2773.000            2690.000            2584.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.004               0.004   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.038               0.038               0.039   \n",
       "\n",
       "       val_loss_epoch_215  val_loss_epoch_216  val_loss_epoch_217  \\\n",
       "count            2484.000            2386.000            2291.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.038               0.038               0.038   \n",
       "\n",
       "       val_loss_epoch_218  val_loss_epoch_219  val_loss_epoch_220  \\\n",
       "count            2205.000            2119.000            2034.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.004               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.016               0.016               0.015   \n",
       "max                 0.038               0.041               0.039   \n",
       "\n",
       "       val_loss_epoch_221  val_loss_epoch_222  val_loss_epoch_223  \\\n",
       "count            1967.000            1896.000            1824.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.012   \n",
       "75%                 0.015               0.015               0.015   \n",
       "max                 0.037               0.037               0.037   \n",
       "\n",
       "       val_loss_epoch_224  val_loss_epoch_225  val_loss_epoch_226  \\\n",
       "count            1753.000            1688.000            1610.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.012               0.012               0.013   \n",
       "75%                 0.015               0.016               0.015   \n",
       "max                 0.037               0.038               0.040   \n",
       "\n",
       "       val_loss_epoch_227  val_loss_epoch_228  val_loss_epoch_229  \\\n",
       "count            1544.000            1481.000            1429.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.015               0.015   \n",
       "max                 0.036               0.039               0.037   \n",
       "\n",
       "       val_loss_epoch_230  val_loss_epoch_231  val_loss_epoch_232  \\\n",
       "count            1376.000            1310.000            1262.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.037               0.037               0.036   \n",
       "\n",
       "       val_loss_epoch_233  val_loss_epoch_234  val_loss_epoch_235  \\\n",
       "count            1214.000            1160.000            1114.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.036               0.039               0.036   \n",
       "\n",
       "       val_loss_epoch_236  val_loss_epoch_237  val_loss_epoch_238  \\\n",
       "count            1058.000            1019.000             986.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.015               0.016   \n",
       "max                 0.036               0.035               0.035   \n",
       "\n",
       "       val_loss_epoch_239  val_loss_epoch_240  val_loss_epoch_241  \\\n",
       "count             953.000             921.000             886.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.003               0.003   \n",
       "25%                 0.010               0.010               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.034               0.035               0.034   \n",
       "\n",
       "       val_loss_epoch_242  val_loss_epoch_243  val_loss_epoch_244  \\\n",
       "count             855.000             822.000             787.000   \n",
       "mean                0.013               0.013               0.013   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.003               0.003   \n",
       "25%                 0.010               0.011               0.010   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.035               0.036               0.034   \n",
       "\n",
       "       val_loss_epoch_245  val_loss_epoch_246  val_loss_epoch_247  \\\n",
       "count             745.000             715.000             682.000   \n",
       "mean                0.013               0.013               0.014   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.003               0.004               0.005   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.034               0.035               0.034   \n",
       "\n",
       "       val_loss_epoch_248  val_loss_epoch_249  val_loss_epoch_250  \\\n",
       "count             646.000             618.000             599.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.004               0.004   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.034               0.034               0.033   \n",
       "\n",
       "       val_loss_epoch_251  val_loss_epoch_252  val_loss_epoch_253  \\\n",
       "count             567.000             538.000             519.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.004               0.005   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.033               0.033               0.033   \n",
       "\n",
       "       val_loss_epoch_254  val_loss_epoch_255  val_loss_epoch_256  \\\n",
       "count             497.000             479.000             462.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.004               0.004   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.033               0.033               0.034   \n",
       "\n",
       "       val_loss_epoch_257  val_loss_epoch_258  val_loss_epoch_259  \\\n",
       "count             438.000             417.000             396.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.004               0.004               0.004   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.033               0.034               0.033   \n",
       "\n",
       "       val_loss_epoch_260  val_loss_epoch_261  val_loss_epoch_262  \\\n",
       "count             379.000             364.000             341.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.004               0.004               0.005   \n",
       "min                 0.004               0.004               0.006   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.033               0.032               0.033   \n",
       "\n",
       "       val_loss_epoch_263  val_loss_epoch_264  val_loss_epoch_265  \\\n",
       "count             327.000             315.000             296.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.004               0.005               0.004   \n",
       "min                 0.006               0.006               0.006   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.013   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.033               0.036               0.032   \n",
       "\n",
       "       val_loss_epoch_266  val_loss_epoch_267  val_loss_epoch_268  \\\n",
       "count             284.000             270.000             257.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.004               0.005   \n",
       "min                 0.006               0.006               0.006   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.034               0.032               0.032   \n",
       "\n",
       "       val_loss_epoch_269  val_loss_epoch_270  val_loss_epoch_271  \\\n",
       "count             240.000             232.000             222.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.006               0.006   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.016               0.016               0.017   \n",
       "max                 0.032               0.032               0.032   \n",
       "\n",
       "       val_loss_epoch_272  val_loss_epoch_273  val_loss_epoch_274  \\\n",
       "count             211.000             202.000             192.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.006               0.006   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.035               0.032               0.032   \n",
       "\n",
       "       val_loss_epoch_275  val_loss_epoch_276  val_loss_epoch_277  \\\n",
       "count             186.000             175.000             168.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.006               0.006   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.014               0.014   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.032               0.032               0.031   \n",
       "\n",
       "       val_loss_epoch_278  val_loss_epoch_279  val_loss_epoch_280  \\\n",
       "count             156.000             151.000             146.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.006               0.006   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.031               0.033               0.032   \n",
       "\n",
       "       val_loss_epoch_281  val_loss_epoch_282  val_loss_epoch_283  \\\n",
       "count             139.000             133.000             123.000   \n",
       "mean                0.015               0.015               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.006               0.006   \n",
       "25%                 0.012               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.017               0.016   \n",
       "max                 0.031               0.032               0.031   \n",
       "\n",
       "       val_loss_epoch_284  val_loss_epoch_285  val_loss_epoch_286  \\\n",
       "count             119.000             118.000             114.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.006               0.006   \n",
       "25%                 0.012               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.031               0.033               0.031   \n",
       "\n",
       "       val_loss_epoch_287  val_loss_epoch_288  val_loss_epoch_289  \\\n",
       "count             108.000             104.000             102.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.005               0.005   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.032               0.031               0.030   \n",
       "\n",
       "       val_loss_epoch_290  val_loss_epoch_291  val_loss_epoch_292  \\\n",
       "count              99.000              94.000              92.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.006               0.006   \n",
       "25%                 0.012               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.033               0.030               0.031   \n",
       "\n",
       "       val_loss_epoch_293  val_loss_epoch_294  val_loss_epoch_295  \\\n",
       "count              89.000              87.000              85.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.005               0.005   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.017               0.016   \n",
       "max                 0.031               0.031               0.030   \n",
       "\n",
       "       val_loss_epoch_296  val_loss_epoch_297  val_loss_epoch_298  \\\n",
       "count              83.000              79.000              77.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.006               0.006               0.007   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.016               0.015   \n",
       "max                 0.030               0.031               0.030   \n",
       "\n",
       "       val_loss_epoch_299  val_loss_epoch_300  val_loss_epoch_301  \\\n",
       "count              75.000              73.000              72.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.007               0.007               0.007   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.017               0.016   \n",
       "max                 0.030               0.031               0.032   \n",
       "\n",
       "       val_loss_epoch_302  val_loss_epoch_303  val_loss_epoch_304  \\\n",
       "count              71.000              67.000              64.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.007               0.006               0.007   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.013   \n",
       "75%                 0.016               0.017               0.015   \n",
       "max                 0.030               0.030               0.031   \n",
       "\n",
       "       val_loss_epoch_305  val_loss_epoch_306  val_loss_epoch_307  \\\n",
       "count              62.000              59.000              56.000   \n",
       "mean                0.014               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.007               0.007               0.007   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.013               0.013               0.013   \n",
       "75%                 0.016               0.016               0.017   \n",
       "max                 0.031               0.032               0.031   \n",
       "\n",
       "       val_loss_epoch_308  val_loss_epoch_309  val_loss_epoch_310  \\\n",
       "count              53.000              53.000              50.000   \n",
       "mean                0.014               0.014               0.015   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.007               0.006               0.007   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.030               0.030               0.031   \n",
       "\n",
       "       val_loss_epoch_311  val_loss_epoch_312  val_loss_epoch_313  \\\n",
       "count              49.000              47.000              46.000   \n",
       "mean                0.015               0.014               0.014   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.007               0.007               0.007   \n",
       "25%                 0.011               0.011               0.011   \n",
       "50%                 0.014               0.014               0.013   \n",
       "75%                 0.017               0.017               0.016   \n",
       "max                 0.030               0.030               0.028   \n",
       "\n",
       "       val_loss_epoch_314  val_loss_epoch_315  val_loss_epoch_316  \\\n",
       "count              39.000              37.000              35.000   \n",
       "mean                0.014               0.015               0.015   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.007               0.007               0.009   \n",
       "25%                 0.011               0.012               0.012   \n",
       "50%                 0.014               0.013               0.014   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.026               0.027               0.027   \n",
       "\n",
       "       val_loss_epoch_317  val_loss_epoch_318  val_loss_epoch_319  \\\n",
       "count              35.000              35.000              33.000   \n",
       "mean                0.015               0.015               0.015   \n",
       "std                 0.004               0.005               0.005   \n",
       "min                 0.009               0.009               0.009   \n",
       "25%                 0.011               0.012               0.011   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.018               0.017   \n",
       "max                 0.027               0.030               0.027   \n",
       "\n",
       "       val_loss_epoch_320  val_loss_epoch_321  val_loss_epoch_322  \\\n",
       "count              32.000              29.000              27.000   \n",
       "mean                0.015               0.014               0.015   \n",
       "std                 0.004               0.005               0.005   \n",
       "min                 0.009               0.009               0.009   \n",
       "25%                 0.012               0.011               0.011   \n",
       "50%                 0.013               0.014               0.014   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.027               0.028               0.028   \n",
       "\n",
       "       val_loss_epoch_323  val_loss_epoch_324  val_loss_epoch_325  \\\n",
       "count              25.000              22.000              20.000   \n",
       "mean                0.015               0.015               0.015   \n",
       "std                 0.004               0.005               0.005   \n",
       "min                 0.009               0.009               0.010   \n",
       "25%                 0.012               0.012               0.012   \n",
       "50%                 0.014               0.013               0.014   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.026               0.027               0.028   \n",
       "\n",
       "       val_loss_epoch_326  val_loss_epoch_327  val_loss_epoch_328  \\\n",
       "count              19.000              19.000              18.000   \n",
       "mean                0.015               0.015               0.016   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.009               0.009               0.009   \n",
       "25%                 0.012               0.013               0.013   \n",
       "50%                 0.014               0.014               0.015   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.028               0.027               0.028   \n",
       "\n",
       "       val_loss_epoch_329  val_loss_epoch_330  val_loss_epoch_331  \\\n",
       "count              17.000              16.000              16.000   \n",
       "mean                0.015               0.016               0.016   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.009               0.009               0.009   \n",
       "25%                 0.013               0.013               0.012   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.017               0.018               0.017   \n",
       "max                 0.026               0.027               0.026   \n",
       "\n",
       "       val_loss_epoch_332  val_loss_epoch_333  val_loss_epoch_334  \\\n",
       "count              15.000              15.000              15.000   \n",
       "mean                0.016               0.015               0.016   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.010               0.009               0.009   \n",
       "25%                 0.012               0.013               0.013   \n",
       "50%                 0.015               0.014               0.016   \n",
       "75%                 0.018               0.017               0.017   \n",
       "max                 0.026               0.026               0.026   \n",
       "\n",
       "       val_loss_epoch_335  val_loss_epoch_336  val_loss_epoch_337  \\\n",
       "count              14.000              14.000              13.000   \n",
       "mean                0.016               0.016               0.016   \n",
       "std                 0.005               0.005               0.006   \n",
       "min                 0.009               0.009               0.009   \n",
       "25%                 0.012               0.012               0.013   \n",
       "50%                 0.014               0.014               0.015   \n",
       "75%                 0.018               0.018               0.018   \n",
       "max                 0.026               0.026               0.028   \n",
       "\n",
       "       val_loss_epoch_338  val_loss_epoch_339  val_loss_epoch_340  \\\n",
       "count              11.000              11.000              11.000   \n",
       "mean                0.016               0.017               0.016   \n",
       "std                 0.005               0.005               0.005   \n",
       "min                 0.011               0.011               0.012   \n",
       "25%                 0.013               0.013               0.013   \n",
       "50%                 0.015               0.015               0.015   \n",
       "75%                 0.017               0.017               0.017   \n",
       "max                 0.026               0.028               0.026   \n",
       "\n",
       "       val_loss_epoch_341  val_loss_epoch_342  val_loss_epoch_343  \\\n",
       "count              10.000              10.000              10.000   \n",
       "mean                0.015               0.015               0.015   \n",
       "std                 0.005               0.004               0.004   \n",
       "min                 0.011               0.012               0.011   \n",
       "25%                 0.013               0.013               0.013   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.027               0.025               0.025   \n",
       "\n",
       "       val_loss_epoch_344  val_loss_epoch_345  val_loss_epoch_346  \\\n",
       "count              10.000              10.000              10.000   \n",
       "mean                0.015               0.015               0.016   \n",
       "std                 0.004               0.004               0.005   \n",
       "min                 0.012               0.012               0.011   \n",
       "25%                 0.013               0.013               0.013   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.016               0.017               0.017   \n",
       "max                 0.025               0.025               0.028   \n",
       "\n",
       "       val_loss_epoch_347  val_loss_epoch_348  val_loss_epoch_349  \\\n",
       "count              10.000              10.000              10.000   \n",
       "mean                0.015               0.015               0.015   \n",
       "std                 0.004               0.004               0.004   \n",
       "min                 0.012               0.012               0.011   \n",
       "25%                 0.013               0.013               0.013   \n",
       "50%                 0.015               0.014               0.014   \n",
       "75%                 0.016               0.016               0.016   \n",
       "max                 0.025               0.025               0.025   \n",
       "\n",
       "       val_loss_epoch_350  val_loss_epoch_351  val_loss_epoch_352  \\\n",
       "count               9.000               8.000               8.000   \n",
       "mean                0.015               0.015               0.015   \n",
       "std                 0.004               0.005               0.005   \n",
       "min                 0.011               0.011               0.012   \n",
       "25%                 0.013               0.012               0.013   \n",
       "50%                 0.014               0.014               0.014   \n",
       "75%                 0.016               0.016               0.015   \n",
       "max                 0.025               0.025               0.026   \n",
       "\n",
       "       val_loss_epoch_353  val_loss_epoch_354  val_loss_epoch_355  \\\n",
       "count               8.000               6.000               6.000   \n",
       "mean                0.015               0.014               0.013   \n",
       "std                 0.005               0.002               0.002   \n",
       "min                 0.011               0.011               0.011   \n",
       "25%                 0.012               0.013               0.012   \n",
       "50%                 0.014               0.013               0.013   \n",
       "75%                 0.016               0.015               0.015   \n",
       "max                 0.025               0.017               0.017   \n",
       "\n",
       "       val_loss_epoch_356  val_loss_epoch_357  val_loss_epoch_358  \\\n",
       "count               6.000               6.000               6.000   \n",
       "mean                0.014               0.014               0.013   \n",
       "std                 0.002               0.002               0.002   \n",
       "min                 0.012               0.011               0.011   \n",
       "25%                 0.013               0.013               0.012   \n",
       "50%                 0.014               0.013               0.013   \n",
       "75%                 0.016               0.014               0.015   \n",
       "max                 0.018               0.017               0.017   \n",
       "\n",
       "       val_loss_epoch_359  val_loss_epoch_360  val_loss_epoch_361  \\\n",
       "count               5.000               4.000               3.000   \n",
       "mean                0.014               0.014               0.013   \n",
       "std                 0.003               0.003               0.003   \n",
       "min                 0.012               0.011               0.011   \n",
       "25%                 0.012               0.012               0.012   \n",
       "50%                 0.013               0.014               0.013   \n",
       "75%                 0.014               0.016               0.014   \n",
       "max                 0.018               0.019               0.016   \n",
       "\n",
       "       val_loss_epoch_362  val_loss_epoch_363  val_loss_epoch_364  \\\n",
       "count               1.000               1.000               1.000   \n",
       "mean                0.017               0.016               0.017   \n",
       "std                   NaN                 NaN                 NaN   \n",
       "min                 0.017               0.016               0.017   \n",
       "25%                 0.017               0.016               0.017   \n",
       "50%                 0.017               0.016               0.017   \n",
       "75%                 0.017               0.016               0.017   \n",
       "max                 0.017               0.016               0.017   \n",
       "\n",
       "       val_loss_epoch_365  val_loss_epoch_366  val_loss_epoch_367  \\\n",
       "count               1.000               1.000               1.000   \n",
       "mean                0.016               0.017               0.017   \n",
       "std                   NaN                 NaN                 NaN   \n",
       "min                 0.016               0.017               0.017   \n",
       "25%                 0.016               0.017               0.017   \n",
       "50%                 0.016               0.017               0.017   \n",
       "75%                 0.016               0.017               0.017   \n",
       "max                 0.016               0.017               0.017   \n",
       "\n",
       "       val_loss_epoch_368  val_loss_epoch_369  val_loss_epoch_370  \\\n",
       "count               1.000               1.000               1.000   \n",
       "mean                0.017               0.017               0.016   \n",
       "std                   NaN                 NaN                 NaN   \n",
       "min                 0.017               0.017               0.016   \n",
       "25%                 0.017               0.017               0.016   \n",
       "50%                 0.017               0.017               0.016   \n",
       "75%                 0.017               0.017               0.016   \n",
       "max                 0.017               0.017               0.016   \n",
       "\n",
       "       val_loss_epoch_371  \n",
       "count               1.000  \n",
       "mean                0.016  \n",
       "std                   NaN  \n",
       "min                 0.016  \n",
       "25%                 0.016  \n",
       "50%                 0.016  \n",
       "75%                 0.016  \n",
       "max                 0.016  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>r2_keras_loss_epoch_1</th>\n",
       "      <th>r2_keras_loss_epoch_2</th>\n",
       "      <th>r2_keras_loss_epoch_3</th>\n",
       "      <th>r2_keras_loss_epoch_4</th>\n",
       "      <th>r2_keras_loss_epoch_5</th>\n",
       "      <th>r2_keras_loss_epoch_6</th>\n",
       "      <th>r2_keras_loss_epoch_7</th>\n",
       "      <th>r2_keras_loss_epoch_8</th>\n",
       "      <th>r2_keras_loss_epoch_9</th>\n",
       "      <th>r2_keras_loss_epoch_10</th>\n",
       "      <th>r2_keras_loss_epoch_11</th>\n",
       "      <th>r2_keras_loss_epoch_12</th>\n",
       "      <th>r2_keras_loss_epoch_13</th>\n",
       "      <th>r2_keras_loss_epoch_14</th>\n",
       "      <th>r2_keras_loss_epoch_15</th>\n",
       "      <th>r2_keras_loss_epoch_16</th>\n",
       "      <th>r2_keras_loss_epoch_17</th>\n",
       "      <th>r2_keras_loss_epoch_18</th>\n",
       "      <th>r2_keras_loss_epoch_19</th>\n",
       "      <th>r2_keras_loss_epoch_20</th>\n",
       "      <th>r2_keras_loss_epoch_21</th>\n",
       "      <th>r2_keras_loss_epoch_22</th>\n",
       "      <th>r2_keras_loss_epoch_23</th>\n",
       "      <th>r2_keras_loss_epoch_24</th>\n",
       "      <th>r2_keras_loss_epoch_25</th>\n",
       "      <th>r2_keras_loss_epoch_26</th>\n",
       "      <th>r2_keras_loss_epoch_27</th>\n",
       "      <th>r2_keras_loss_epoch_28</th>\n",
       "      <th>r2_keras_loss_epoch_29</th>\n",
       "      <th>r2_keras_loss_epoch_30</th>\n",
       "      <th>r2_keras_loss_epoch_31</th>\n",
       "      <th>r2_keras_loss_epoch_32</th>\n",
       "      <th>r2_keras_loss_epoch_33</th>\n",
       "      <th>r2_keras_loss_epoch_34</th>\n",
       "      <th>r2_keras_loss_epoch_35</th>\n",
       "      <th>r2_keras_loss_epoch_36</th>\n",
       "      <th>r2_keras_loss_epoch_37</th>\n",
       "      <th>r2_keras_loss_epoch_38</th>\n",
       "      <th>r2_keras_loss_epoch_39</th>\n",
       "      <th>r2_keras_loss_epoch_40</th>\n",
       "      <th>r2_keras_loss_epoch_41</th>\n",
       "      <th>r2_keras_loss_epoch_42</th>\n",
       "      <th>r2_keras_loss_epoch_43</th>\n",
       "      <th>r2_keras_loss_epoch_44</th>\n",
       "      <th>r2_keras_loss_epoch_45</th>\n",
       "      <th>r2_keras_loss_epoch_46</th>\n",
       "      <th>r2_keras_loss_epoch_47</th>\n",
       "      <th>r2_keras_loss_epoch_48</th>\n",
       "      <th>r2_keras_loss_epoch_49</th>\n",
       "      <th>r2_keras_loss_epoch_50</th>\n",
       "      <th>r2_keras_loss_epoch_51</th>\n",
       "      <th>r2_keras_loss_epoch_52</th>\n",
       "      <th>r2_keras_loss_epoch_53</th>\n",
       "      <th>r2_keras_loss_epoch_54</th>\n",
       "      <th>r2_keras_loss_epoch_55</th>\n",
       "      <th>r2_keras_loss_epoch_56</th>\n",
       "      <th>r2_keras_loss_epoch_57</th>\n",
       "      <th>r2_keras_loss_epoch_58</th>\n",
       "      <th>r2_keras_loss_epoch_59</th>\n",
       "      <th>r2_keras_loss_epoch_60</th>\n",
       "      <th>r2_keras_loss_epoch_61</th>\n",
       "      <th>r2_keras_loss_epoch_62</th>\n",
       "      <th>r2_keras_loss_epoch_63</th>\n",
       "      <th>r2_keras_loss_epoch_64</th>\n",
       "      <th>r2_keras_loss_epoch_65</th>\n",
       "      <th>r2_keras_loss_epoch_66</th>\n",
       "      <th>r2_keras_loss_epoch_67</th>\n",
       "      <th>r2_keras_loss_epoch_68</th>\n",
       "      <th>r2_keras_loss_epoch_69</th>\n",
       "      <th>r2_keras_loss_epoch_70</th>\n",
       "      <th>r2_keras_loss_epoch_71</th>\n",
       "      <th>r2_keras_loss_epoch_72</th>\n",
       "      <th>r2_keras_loss_epoch_73</th>\n",
       "      <th>r2_keras_loss_epoch_74</th>\n",
       "      <th>r2_keras_loss_epoch_75</th>\n",
       "      <th>r2_keras_loss_epoch_76</th>\n",
       "      <th>r2_keras_loss_epoch_77</th>\n",
       "      <th>r2_keras_loss_epoch_78</th>\n",
       "      <th>r2_keras_loss_epoch_79</th>\n",
       "      <th>r2_keras_loss_epoch_80</th>\n",
       "      <th>r2_keras_loss_epoch_81</th>\n",
       "      <th>r2_keras_loss_epoch_82</th>\n",
       "      <th>r2_keras_loss_epoch_83</th>\n",
       "      <th>r2_keras_loss_epoch_84</th>\n",
       "      <th>r2_keras_loss_epoch_85</th>\n",
       "      <th>r2_keras_loss_epoch_86</th>\n",
       "      <th>r2_keras_loss_epoch_87</th>\n",
       "      <th>r2_keras_loss_epoch_88</th>\n",
       "      <th>r2_keras_loss_epoch_89</th>\n",
       "      <th>r2_keras_loss_epoch_90</th>\n",
       "      <th>r2_keras_loss_epoch_91</th>\n",
       "      <th>r2_keras_loss_epoch_92</th>\n",
       "      <th>r2_keras_loss_epoch_93</th>\n",
       "      <th>r2_keras_loss_epoch_94</th>\n",
       "      <th>r2_keras_loss_epoch_95</th>\n",
       "      <th>r2_keras_loss_epoch_96</th>\n",
       "      <th>r2_keras_loss_epoch_97</th>\n",
       "      <th>r2_keras_loss_epoch_98</th>\n",
       "      <th>r2_keras_loss_epoch_99</th>\n",
       "      <th>r2_keras_loss_epoch_100</th>\n",
       "      <th>r2_keras_loss_epoch_101</th>\n",
       "      <th>r2_keras_loss_epoch_102</th>\n",
       "      <th>r2_keras_loss_epoch_103</th>\n",
       "      <th>r2_keras_loss_epoch_104</th>\n",
       "      <th>r2_keras_loss_epoch_105</th>\n",
       "      <th>r2_keras_loss_epoch_106</th>\n",
       "      <th>r2_keras_loss_epoch_107</th>\n",
       "      <th>r2_keras_loss_epoch_108</th>\n",
       "      <th>r2_keras_loss_epoch_109</th>\n",
       "      <th>r2_keras_loss_epoch_110</th>\n",
       "      <th>r2_keras_loss_epoch_111</th>\n",
       "      <th>r2_keras_loss_epoch_112</th>\n",
       "      <th>r2_keras_loss_epoch_113</th>\n",
       "      <th>r2_keras_loss_epoch_114</th>\n",
       "      <th>r2_keras_loss_epoch_115</th>\n",
       "      <th>r2_keras_loss_epoch_116</th>\n",
       "      <th>r2_keras_loss_epoch_117</th>\n",
       "      <th>r2_keras_loss_epoch_118</th>\n",
       "      <th>r2_keras_loss_epoch_119</th>\n",
       "      <th>r2_keras_loss_epoch_120</th>\n",
       "      <th>r2_keras_loss_epoch_121</th>\n",
       "      <th>r2_keras_loss_epoch_122</th>\n",
       "      <th>r2_keras_loss_epoch_123</th>\n",
       "      <th>r2_keras_loss_epoch_124</th>\n",
       "      <th>r2_keras_loss_epoch_125</th>\n",
       "      <th>r2_keras_loss_epoch_126</th>\n",
       "      <th>r2_keras_loss_epoch_127</th>\n",
       "      <th>r2_keras_loss_epoch_128</th>\n",
       "      <th>r2_keras_loss_epoch_129</th>\n",
       "      <th>r2_keras_loss_epoch_130</th>\n",
       "      <th>r2_keras_loss_epoch_131</th>\n",
       "      <th>r2_keras_loss_epoch_132</th>\n",
       "      <th>r2_keras_loss_epoch_133</th>\n",
       "      <th>r2_keras_loss_epoch_134</th>\n",
       "      <th>r2_keras_loss_epoch_135</th>\n",
       "      <th>r2_keras_loss_epoch_136</th>\n",
       "      <th>r2_keras_loss_epoch_137</th>\n",
       "      <th>r2_keras_loss_epoch_138</th>\n",
       "      <th>r2_keras_loss_epoch_139</th>\n",
       "      <th>r2_keras_loss_epoch_140</th>\n",
       "      <th>r2_keras_loss_epoch_141</th>\n",
       "      <th>r2_keras_loss_epoch_142</th>\n",
       "      <th>r2_keras_loss_epoch_143</th>\n",
       "      <th>r2_keras_loss_epoch_144</th>\n",
       "      <th>r2_keras_loss_epoch_145</th>\n",
       "      <th>r2_keras_loss_epoch_146</th>\n",
       "      <th>r2_keras_loss_epoch_147</th>\n",
       "      <th>r2_keras_loss_epoch_148</th>\n",
       "      <th>r2_keras_loss_epoch_149</th>\n",
       "      <th>r2_keras_loss_epoch_150</th>\n",
       "      <th>r2_keras_loss_epoch_151</th>\n",
       "      <th>r2_keras_loss_epoch_152</th>\n",
       "      <th>r2_keras_loss_epoch_153</th>\n",
       "      <th>r2_keras_loss_epoch_154</th>\n",
       "      <th>r2_keras_loss_epoch_155</th>\n",
       "      <th>r2_keras_loss_epoch_156</th>\n",
       "      <th>r2_keras_loss_epoch_157</th>\n",
       "      <th>r2_keras_loss_epoch_158</th>\n",
       "      <th>r2_keras_loss_epoch_159</th>\n",
       "      <th>r2_keras_loss_epoch_160</th>\n",
       "      <th>r2_keras_loss_epoch_161</th>\n",
       "      <th>r2_keras_loss_epoch_162</th>\n",
       "      <th>r2_keras_loss_epoch_163</th>\n",
       "      <th>r2_keras_loss_epoch_164</th>\n",
       "      <th>r2_keras_loss_epoch_165</th>\n",
       "      <th>r2_keras_loss_epoch_166</th>\n",
       "      <th>r2_keras_loss_epoch_167</th>\n",
       "      <th>r2_keras_loss_epoch_168</th>\n",
       "      <th>r2_keras_loss_epoch_169</th>\n",
       "      <th>r2_keras_loss_epoch_170</th>\n",
       "      <th>r2_keras_loss_epoch_171</th>\n",
       "      <th>r2_keras_loss_epoch_172</th>\n",
       "      <th>r2_keras_loss_epoch_173</th>\n",
       "      <th>r2_keras_loss_epoch_174</th>\n",
       "      <th>r2_keras_loss_epoch_175</th>\n",
       "      <th>r2_keras_loss_epoch_176</th>\n",
       "      <th>r2_keras_loss_epoch_177</th>\n",
       "      <th>r2_keras_loss_epoch_178</th>\n",
       "      <th>r2_keras_loss_epoch_179</th>\n",
       "      <th>r2_keras_loss_epoch_180</th>\n",
       "      <th>r2_keras_loss_epoch_181</th>\n",
       "      <th>r2_keras_loss_epoch_182</th>\n",
       "      <th>r2_keras_loss_epoch_183</th>\n",
       "      <th>r2_keras_loss_epoch_184</th>\n",
       "      <th>r2_keras_loss_epoch_185</th>\n",
       "      <th>r2_keras_loss_epoch_186</th>\n",
       "      <th>r2_keras_loss_epoch_187</th>\n",
       "      <th>r2_keras_loss_epoch_188</th>\n",
       "      <th>r2_keras_loss_epoch_189</th>\n",
       "      <th>r2_keras_loss_epoch_190</th>\n",
       "      <th>r2_keras_loss_epoch_191</th>\n",
       "      <th>r2_keras_loss_epoch_192</th>\n",
       "      <th>r2_keras_loss_epoch_193</th>\n",
       "      <th>r2_keras_loss_epoch_194</th>\n",
       "      <th>r2_keras_loss_epoch_195</th>\n",
       "      <th>r2_keras_loss_epoch_196</th>\n",
       "      <th>r2_keras_loss_epoch_197</th>\n",
       "      <th>r2_keras_loss_epoch_198</th>\n",
       "      <th>r2_keras_loss_epoch_199</th>\n",
       "      <th>r2_keras_loss_epoch_200</th>\n",
       "      <th>r2_keras_loss_epoch_201</th>\n",
       "      <th>r2_keras_loss_epoch_202</th>\n",
       "      <th>r2_keras_loss_epoch_203</th>\n",
       "      <th>r2_keras_loss_epoch_204</th>\n",
       "      <th>r2_keras_loss_epoch_205</th>\n",
       "      <th>r2_keras_loss_epoch_206</th>\n",
       "      <th>r2_keras_loss_epoch_207</th>\n",
       "      <th>r2_keras_loss_epoch_208</th>\n",
       "      <th>r2_keras_loss_epoch_209</th>\n",
       "      <th>r2_keras_loss_epoch_210</th>\n",
       "      <th>r2_keras_loss_epoch_211</th>\n",
       "      <th>r2_keras_loss_epoch_212</th>\n",
       "      <th>r2_keras_loss_epoch_213</th>\n",
       "      <th>r2_keras_loss_epoch_214</th>\n",
       "      <th>r2_keras_loss_epoch_215</th>\n",
       "      <th>r2_keras_loss_epoch_216</th>\n",
       "      <th>r2_keras_loss_epoch_217</th>\n",
       "      <th>r2_keras_loss_epoch_218</th>\n",
       "      <th>r2_keras_loss_epoch_219</th>\n",
       "      <th>r2_keras_loss_epoch_220</th>\n",
       "      <th>r2_keras_loss_epoch_221</th>\n",
       "      <th>r2_keras_loss_epoch_222</th>\n",
       "      <th>r2_keras_loss_epoch_223</th>\n",
       "      <th>r2_keras_loss_epoch_224</th>\n",
       "      <th>r2_keras_loss_epoch_225</th>\n",
       "      <th>r2_keras_loss_epoch_226</th>\n",
       "      <th>r2_keras_loss_epoch_227</th>\n",
       "      <th>r2_keras_loss_epoch_228</th>\n",
       "      <th>r2_keras_loss_epoch_229</th>\n",
       "      <th>r2_keras_loss_epoch_230</th>\n",
       "      <th>r2_keras_loss_epoch_231</th>\n",
       "      <th>r2_keras_loss_epoch_232</th>\n",
       "      <th>r2_keras_loss_epoch_233</th>\n",
       "      <th>r2_keras_loss_epoch_234</th>\n",
       "      <th>r2_keras_loss_epoch_235</th>\n",
       "      <th>r2_keras_loss_epoch_236</th>\n",
       "      <th>r2_keras_loss_epoch_237</th>\n",
       "      <th>r2_keras_loss_epoch_238</th>\n",
       "      <th>r2_keras_loss_epoch_239</th>\n",
       "      <th>r2_keras_loss_epoch_240</th>\n",
       "      <th>r2_keras_loss_epoch_241</th>\n",
       "      <th>r2_keras_loss_epoch_242</th>\n",
       "      <th>r2_keras_loss_epoch_243</th>\n",
       "      <th>r2_keras_loss_epoch_244</th>\n",
       "      <th>r2_keras_loss_epoch_245</th>\n",
       "      <th>r2_keras_loss_epoch_246</th>\n",
       "      <th>r2_keras_loss_epoch_247</th>\n",
       "      <th>r2_keras_loss_epoch_248</th>\n",
       "      <th>r2_keras_loss_epoch_249</th>\n",
       "      <th>r2_keras_loss_epoch_250</th>\n",
       "      <th>r2_keras_loss_epoch_251</th>\n",
       "      <th>r2_keras_loss_epoch_252</th>\n",
       "      <th>r2_keras_loss_epoch_253</th>\n",
       "      <th>r2_keras_loss_epoch_254</th>\n",
       "      <th>r2_keras_loss_epoch_255</th>\n",
       "      <th>r2_keras_loss_epoch_256</th>\n",
       "      <th>r2_keras_loss_epoch_257</th>\n",
       "      <th>r2_keras_loss_epoch_258</th>\n",
       "      <th>r2_keras_loss_epoch_259</th>\n",
       "      <th>r2_keras_loss_epoch_260</th>\n",
       "      <th>r2_keras_loss_epoch_261</th>\n",
       "      <th>r2_keras_loss_epoch_262</th>\n",
       "      <th>r2_keras_loss_epoch_263</th>\n",
       "      <th>r2_keras_loss_epoch_264</th>\n",
       "      <th>r2_keras_loss_epoch_265</th>\n",
       "      <th>r2_keras_loss_epoch_266</th>\n",
       "      <th>r2_keras_loss_epoch_267</th>\n",
       "      <th>r2_keras_loss_epoch_268</th>\n",
       "      <th>r2_keras_loss_epoch_269</th>\n",
       "      <th>r2_keras_loss_epoch_270</th>\n",
       "      <th>r2_keras_loss_epoch_271</th>\n",
       "      <th>r2_keras_loss_epoch_272</th>\n",
       "      <th>r2_keras_loss_epoch_273</th>\n",
       "      <th>r2_keras_loss_epoch_274</th>\n",
       "      <th>r2_keras_loss_epoch_275</th>\n",
       "      <th>r2_keras_loss_epoch_276</th>\n",
       "      <th>r2_keras_loss_epoch_277</th>\n",
       "      <th>r2_keras_loss_epoch_278</th>\n",
       "      <th>r2_keras_loss_epoch_279</th>\n",
       "      <th>r2_keras_loss_epoch_280</th>\n",
       "      <th>r2_keras_loss_epoch_281</th>\n",
       "      <th>r2_keras_loss_epoch_282</th>\n",
       "      <th>r2_keras_loss_epoch_283</th>\n",
       "      <th>r2_keras_loss_epoch_284</th>\n",
       "      <th>r2_keras_loss_epoch_285</th>\n",
       "      <th>r2_keras_loss_epoch_286</th>\n",
       "      <th>r2_keras_loss_epoch_287</th>\n",
       "      <th>r2_keras_loss_epoch_288</th>\n",
       "      <th>r2_keras_loss_epoch_289</th>\n",
       "      <th>r2_keras_loss_epoch_290</th>\n",
       "      <th>r2_keras_loss_epoch_291</th>\n",
       "      <th>r2_keras_loss_epoch_292</th>\n",
       "      <th>r2_keras_loss_epoch_293</th>\n",
       "      <th>r2_keras_loss_epoch_294</th>\n",
       "      <th>r2_keras_loss_epoch_295</th>\n",
       "      <th>r2_keras_loss_epoch_296</th>\n",
       "      <th>r2_keras_loss_epoch_297</th>\n",
       "      <th>r2_keras_loss_epoch_298</th>\n",
       "      <th>r2_keras_loss_epoch_299</th>\n",
       "      <th>r2_keras_loss_epoch_300</th>\n",
       "      <th>r2_keras_loss_epoch_301</th>\n",
       "      <th>r2_keras_loss_epoch_302</th>\n",
       "      <th>r2_keras_loss_epoch_303</th>\n",
       "      <th>r2_keras_loss_epoch_304</th>\n",
       "      <th>r2_keras_loss_epoch_305</th>\n",
       "      <th>r2_keras_loss_epoch_306</th>\n",
       "      <th>r2_keras_loss_epoch_307</th>\n",
       "      <th>r2_keras_loss_epoch_308</th>\n",
       "      <th>r2_keras_loss_epoch_309</th>\n",
       "      <th>r2_keras_loss_epoch_310</th>\n",
       "      <th>r2_keras_loss_epoch_311</th>\n",
       "      <th>r2_keras_loss_epoch_312</th>\n",
       "      <th>r2_keras_loss_epoch_313</th>\n",
       "      <th>r2_keras_loss_epoch_314</th>\n",
       "      <th>r2_keras_loss_epoch_315</th>\n",
       "      <th>r2_keras_loss_epoch_316</th>\n",
       "      <th>r2_keras_loss_epoch_317</th>\n",
       "      <th>r2_keras_loss_epoch_318</th>\n",
       "      <th>r2_keras_loss_epoch_319</th>\n",
       "      <th>r2_keras_loss_epoch_320</th>\n",
       "      <th>r2_keras_loss_epoch_321</th>\n",
       "      <th>r2_keras_loss_epoch_322</th>\n",
       "      <th>r2_keras_loss_epoch_323</th>\n",
       "      <th>r2_keras_loss_epoch_324</th>\n",
       "      <th>r2_keras_loss_epoch_325</th>\n",
       "      <th>r2_keras_loss_epoch_326</th>\n",
       "      <th>r2_keras_loss_epoch_327</th>\n",
       "      <th>r2_keras_loss_epoch_328</th>\n",
       "      <th>r2_keras_loss_epoch_329</th>\n",
       "      <th>r2_keras_loss_epoch_330</th>\n",
       "      <th>r2_keras_loss_epoch_331</th>\n",
       "      <th>r2_keras_loss_epoch_332</th>\n",
       "      <th>r2_keras_loss_epoch_333</th>\n",
       "      <th>r2_keras_loss_epoch_334</th>\n",
       "      <th>r2_keras_loss_epoch_335</th>\n",
       "      <th>r2_keras_loss_epoch_336</th>\n",
       "      <th>r2_keras_loss_epoch_337</th>\n",
       "      <th>r2_keras_loss_epoch_338</th>\n",
       "      <th>r2_keras_loss_epoch_339</th>\n",
       "      <th>r2_keras_loss_epoch_340</th>\n",
       "      <th>r2_keras_loss_epoch_341</th>\n",
       "      <th>r2_keras_loss_epoch_342</th>\n",
       "      <th>r2_keras_loss_epoch_343</th>\n",
       "      <th>r2_keras_loss_epoch_344</th>\n",
       "      <th>r2_keras_loss_epoch_345</th>\n",
       "      <th>r2_keras_loss_epoch_346</th>\n",
       "      <th>r2_keras_loss_epoch_347</th>\n",
       "      <th>r2_keras_loss_epoch_348</th>\n",
       "      <th>r2_keras_loss_epoch_349</th>\n",
       "      <th>r2_keras_loss_epoch_350</th>\n",
       "      <th>r2_keras_loss_epoch_351</th>\n",
       "      <th>r2_keras_loss_epoch_352</th>\n",
       "      <th>r2_keras_loss_epoch_353</th>\n",
       "      <th>r2_keras_loss_epoch_354</th>\n",
       "      <th>r2_keras_loss_epoch_355</th>\n",
       "      <th>r2_keras_loss_epoch_356</th>\n",
       "      <th>r2_keras_loss_epoch_357</th>\n",
       "      <th>r2_keras_loss_epoch_358</th>\n",
       "      <th>r2_keras_loss_epoch_359</th>\n",
       "      <th>r2_keras_loss_epoch_360</th>\n",
       "      <th>r2_keras_loss_epoch_361</th>\n",
       "      <th>r2_keras_loss_epoch_362</th>\n",
       "      <th>r2_keras_loss_epoch_363</th>\n",
       "      <th>r2_keras_loss_epoch_364</th>\n",
       "      <th>r2_keras_loss_epoch_365</th>\n",
       "      <th>r2_keras_loss_epoch_366</th>\n",
       "      <th>r2_keras_loss_epoch_367</th>\n",
       "      <th>r2_keras_loss_epoch_368</th>\n",
       "      <th>r2_keras_loss_epoch_369</th>\n",
       "      <th>r2_keras_loss_epoch_370</th>\n",
       "      <th>r2_keras_loss_epoch_371</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>49999.000</td>\n",
       "      <td>49999.000</td>\n",
       "      <td>49997.000</td>\n",
       "      <td>49997.000</td>\n",
       "      <td>49996.000</td>\n",
       "      <td>49996.000</td>\n",
       "      <td>49995.000</td>\n",
       "      <td>49994.000</td>\n",
       "      <td>49992.000</td>\n",
       "      <td>49992.000</td>\n",
       "      <td>49989.000</td>\n",
       "      <td>49984.000</td>\n",
       "      <td>49982.000</td>\n",
       "      <td>49980.000</td>\n",
       "      <td>49974.000</td>\n",
       "      <td>49970.000</td>\n",
       "      <td>49965.000</td>\n",
       "      <td>49960.000</td>\n",
       "      <td>49957.000</td>\n",
       "      <td>49949.000</td>\n",
       "      <td>49945.000</td>\n",
       "      <td>49935.000</td>\n",
       "      <td>49923.000</td>\n",
       "      <td>49905.000</td>\n",
       "      <td>49890.000</td>\n",
       "      <td>49876.000</td>\n",
       "      <td>49856.000</td>\n",
       "      <td>49835.000</td>\n",
       "      <td>49810.000</td>\n",
       "      <td>49785.000</td>\n",
       "      <td>49762.000</td>\n",
       "      <td>49727.000</td>\n",
       "      <td>49689.000</td>\n",
       "      <td>49646.000</td>\n",
       "      <td>49613.000</td>\n",
       "      <td>49576.000</td>\n",
       "      <td>49535.000</td>\n",
       "      <td>49483.000</td>\n",
       "      <td>49428.000</td>\n",
       "      <td>49357.000</td>\n",
       "      <td>49282.000</td>\n",
       "      <td>49198.000</td>\n",
       "      <td>49107.000</td>\n",
       "      <td>49000.000</td>\n",
       "      <td>48880.000</td>\n",
       "      <td>48770.000</td>\n",
       "      <td>48637.000</td>\n",
       "      <td>48489.000</td>\n",
       "      <td>48358.000</td>\n",
       "      <td>48202.000</td>\n",
       "      <td>48024.000</td>\n",
       "      <td>47845.000</td>\n",
       "      <td>47646.000</td>\n",
       "      <td>47447.000</td>\n",
       "      <td>47224.000</td>\n",
       "      <td>46989.000</td>\n",
       "      <td>46764.000</td>\n",
       "      <td>46530.000</td>\n",
       "      <td>46244.000</td>\n",
       "      <td>45959.000</td>\n",
       "      <td>45683.000</td>\n",
       "      <td>45352.000</td>\n",
       "      <td>45032.000</td>\n",
       "      <td>44725.000</td>\n",
       "      <td>44416.000</td>\n",
       "      <td>44045.000</td>\n",
       "      <td>43666.000</td>\n",
       "      <td>43276.000</td>\n",
       "      <td>42871.000</td>\n",
       "      <td>42516.000</td>\n",
       "      <td>42120.000</td>\n",
       "      <td>41681.000</td>\n",
       "      <td>41237.000</td>\n",
       "      <td>40781.000</td>\n",
       "      <td>40315.000</td>\n",
       "      <td>39829.000</td>\n",
       "      <td>39368.000</td>\n",
       "      <td>38884.000</td>\n",
       "      <td>38358.000</td>\n",
       "      <td>37875.000</td>\n",
       "      <td>37348.000</td>\n",
       "      <td>36860.000</td>\n",
       "      <td>36343.000</td>\n",
       "      <td>35791.000</td>\n",
       "      <td>35260.000</td>\n",
       "      <td>34687.000</td>\n",
       "      <td>34157.000</td>\n",
       "      <td>33582.000</td>\n",
       "      <td>33063.000</td>\n",
       "      <td>32504.000</td>\n",
       "      <td>31957.000</td>\n",
       "      <td>31392.000</td>\n",
       "      <td>30845.000</td>\n",
       "      <td>30268.000</td>\n",
       "      <td>29729.000</td>\n",
       "      <td>29168.000</td>\n",
       "      <td>28631.000</td>\n",
       "      <td>27983.000</td>\n",
       "      <td>27429.000</td>\n",
       "      <td>26867.000</td>\n",
       "      <td>26363.000</td>\n",
       "      <td>25806.000</td>\n",
       "      <td>25243.000</td>\n",
       "      <td>24678.000</td>\n",
       "      <td>24168.000</td>\n",
       "      <td>23634.000</td>\n",
       "      <td>23071.000</td>\n",
       "      <td>22521.000</td>\n",
       "      <td>21987.000</td>\n",
       "      <td>21456.000</td>\n",
       "      <td>20973.000</td>\n",
       "      <td>20467.000</td>\n",
       "      <td>19984.000</td>\n",
       "      <td>19485.000</td>\n",
       "      <td>19010.000</td>\n",
       "      <td>18544.000</td>\n",
       "      <td>18054.000</td>\n",
       "      <td>17599.000</td>\n",
       "      <td>17138.000</td>\n",
       "      <td>16695.000</td>\n",
       "      <td>16231.000</td>\n",
       "      <td>15795.000</td>\n",
       "      <td>15394.000</td>\n",
       "      <td>14973.000</td>\n",
       "      <td>14563.000</td>\n",
       "      <td>14150.000</td>\n",
       "      <td>13751.000</td>\n",
       "      <td>13347.000</td>\n",
       "      <td>12961.000</td>\n",
       "      <td>12579.000</td>\n",
       "      <td>12195.000</td>\n",
       "      <td>11826.000</td>\n",
       "      <td>11507.000</td>\n",
       "      <td>11169.000</td>\n",
       "      <td>10845.000</td>\n",
       "      <td>10467.000</td>\n",
       "      <td>10136.000</td>\n",
       "      <td>9816.000</td>\n",
       "      <td>9524.000</td>\n",
       "      <td>9211.000</td>\n",
       "      <td>8910.000</td>\n",
       "      <td>8632.000</td>\n",
       "      <td>8389.000</td>\n",
       "      <td>8105.000</td>\n",
       "      <td>7861.000</td>\n",
       "      <td>7574.000</td>\n",
       "      <td>7322.000</td>\n",
       "      <td>7087.000</td>\n",
       "      <td>6849.000</td>\n",
       "      <td>6618.000</td>\n",
       "      <td>6415.000</td>\n",
       "      <td>6201.000</td>\n",
       "      <td>5968.000</td>\n",
       "      <td>5776.000</td>\n",
       "      <td>5573.000</td>\n",
       "      <td>5374.000</td>\n",
       "      <td>5191.000</td>\n",
       "      <td>5013.000</td>\n",
       "      <td>4861.000</td>\n",
       "      <td>4688.000</td>\n",
       "      <td>4506.000</td>\n",
       "      <td>4349.000</td>\n",
       "      <td>4214.000</td>\n",
       "      <td>4077.000</td>\n",
       "      <td>3932.000</td>\n",
       "      <td>3783.000</td>\n",
       "      <td>3642.000</td>\n",
       "      <td>3509.000</td>\n",
       "      <td>3363.000</td>\n",
       "      <td>3234.000</td>\n",
       "      <td>3116.000</td>\n",
       "      <td>3004.000</td>\n",
       "      <td>2885.000</td>\n",
       "      <td>2773.000</td>\n",
       "      <td>2690.000</td>\n",
       "      <td>2584.000</td>\n",
       "      <td>2484.000</td>\n",
       "      <td>2386.000</td>\n",
       "      <td>2291.000</td>\n",
       "      <td>2205.000</td>\n",
       "      <td>2119.000</td>\n",
       "      <td>2034.000</td>\n",
       "      <td>1967.000</td>\n",
       "      <td>1896.000</td>\n",
       "      <td>1824.000</td>\n",
       "      <td>1753.000</td>\n",
       "      <td>1688.000</td>\n",
       "      <td>1610.000</td>\n",
       "      <td>1544.000</td>\n",
       "      <td>1481.000</td>\n",
       "      <td>1429.000</td>\n",
       "      <td>1376.000</td>\n",
       "      <td>1310.000</td>\n",
       "      <td>1262.000</td>\n",
       "      <td>1214.000</td>\n",
       "      <td>1160.000</td>\n",
       "      <td>1114.000</td>\n",
       "      <td>1058.000</td>\n",
       "      <td>1019.000</td>\n",
       "      <td>986.000</td>\n",
       "      <td>953.000</td>\n",
       "      <td>921.000</td>\n",
       "      <td>886.000</td>\n",
       "      <td>855.000</td>\n",
       "      <td>822.000</td>\n",
       "      <td>787.000</td>\n",
       "      <td>745.000</td>\n",
       "      <td>715.000</td>\n",
       "      <td>682.000</td>\n",
       "      <td>646.000</td>\n",
       "      <td>618.000</td>\n",
       "      <td>599.000</td>\n",
       "      <td>567.000</td>\n",
       "      <td>538.000</td>\n",
       "      <td>519.000</td>\n",
       "      <td>497.000</td>\n",
       "      <td>479.000</td>\n",
       "      <td>462.000</td>\n",
       "      <td>438.000</td>\n",
       "      <td>417.000</td>\n",
       "      <td>396.000</td>\n",
       "      <td>379.000</td>\n",
       "      <td>364.000</td>\n",
       "      <td>341.000</td>\n",
       "      <td>327.000</td>\n",
       "      <td>315.000</td>\n",
       "      <td>296.000</td>\n",
       "      <td>284.000</td>\n",
       "      <td>270.000</td>\n",
       "      <td>257.000</td>\n",
       "      <td>240.000</td>\n",
       "      <td>232.000</td>\n",
       "      <td>222.000</td>\n",
       "      <td>211.000</td>\n",
       "      <td>202.000</td>\n",
       "      <td>192.000</td>\n",
       "      <td>186.000</td>\n",
       "      <td>175.000</td>\n",
       "      <td>168.000</td>\n",
       "      <td>156.000</td>\n",
       "      <td>151.000</td>\n",
       "      <td>146.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>133.000</td>\n",
       "      <td>123.000</td>\n",
       "      <td>119.000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>114.000</td>\n",
       "      <td>108.000</td>\n",
       "      <td>104.000</td>\n",
       "      <td>102.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>89.000</td>\n",
       "      <td>87.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>79.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>71.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24999.500</td>\n",
       "      <td>1.628</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.597</td>\n",
       "      <td>-0.739</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>-0.859</td>\n",
       "      <td>-0.877</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.901</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.944</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14433.901</td>\n",
       "      <td>7.617</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.844</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12499.750</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.767</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>-0.882</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>-0.934</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24999.500</td>\n",
       "      <td>0.793</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>-0.901</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.929</td>\n",
       "      <td>-0.934</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37499.250</td>\n",
       "      <td>1.973</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.802</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>-0.906</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>-0.927</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49999.000</td>\n",
       "      <td>1323.710</td>\n",
       "      <td>159.804</td>\n",
       "      <td>78.173</td>\n",
       "      <td>58.875</td>\n",
       "      <td>43.242</td>\n",
       "      <td>29.571</td>\n",
       "      <td>18.773</td>\n",
       "      <td>8.997</td>\n",
       "      <td>2.922</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>-0.496</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-0.726</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>-0.795</td>\n",
       "      <td>-0.786</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-0.806</td>\n",
       "      <td>-0.806</td>\n",
       "      <td>-0.812</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>-0.826</td>\n",
       "      <td>-0.825</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>-0.826</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>-0.851</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>-0.857</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-0.855</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>-0.862</td>\n",
       "      <td>-0.862</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>-0.873</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-0.879</td>\n",
       "      <td>-0.879</td>\n",
       "      <td>-0.880</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.903</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>-0.903</td>\n",
       "      <td>-0.906</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>-0.907</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>-0.911</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-0.911</td>\n",
       "      <td>-0.911</td>\n",
       "      <td>-0.911</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.922</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>-0.927</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>-0.927</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.929</td>\n",
       "      <td>-0.929</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.932</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.948</td>\n",
       "      <td>-0.948</td>\n",
       "      <td>-0.948</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  r2_keras_loss_epoch_1  r2_keras_loss_epoch_2  \\\n",
       "count 50000.000              50000.000              50000.000   \n",
       "mean  24999.500                  1.628                 -0.210   \n",
       "std   14433.901                  7.617                  1.045   \n",
       "min       0.000                 -0.844                 -0.958   \n",
       "25%   12499.750                  0.085                 -0.561   \n",
       "50%   24999.500                  0.793                 -0.360   \n",
       "75%   37499.250                  1.973                 -0.051   \n",
       "max   49999.000               1323.710                159.804   \n",
       "\n",
       "       r2_keras_loss_epoch_3  r2_keras_loss_epoch_4  r2_keras_loss_epoch_5  \\\n",
       "count              50000.000              50000.000              50000.000   \n",
       "mean                  -0.597                 -0.739                 -0.800   \n",
       "std                    0.535                  0.389                  0.283   \n",
       "min                   -0.982                 -0.990                 -0.994   \n",
       "25%                   -0.767                 -0.847                 -0.882   \n",
       "50%                   -0.665                 -0.782                 -0.831   \n",
       "75%                   -0.523                 -0.700                 -0.766   \n",
       "max                   78.173                 58.875                 43.242   \n",
       "\n",
       "       r2_keras_loss_epoch_6  r2_keras_loss_epoch_7  r2_keras_loss_epoch_8  \\\n",
       "count              50000.000              50000.000              50000.000   \n",
       "mean                  -0.835                 -0.859                 -0.877   \n",
       "std                    0.199                  0.138                  0.092   \n",
       "min                   -0.996                 -0.997                 -0.998   \n",
       "25%                   -0.902                 -0.916                 -0.926   \n",
       "50%                   -0.858                 -0.876                 -0.890   \n",
       "75%                   -0.802                 -0.827                 -0.846   \n",
       "max                   29.571                 18.773                  8.997   \n",
       "\n",
       "       r2_keras_loss_epoch_9  r2_keras_loss_epoch_10  r2_keras_loss_epoch_11  \\\n",
       "count              50000.000               50000.000               50000.000   \n",
       "mean                  -0.891                  -0.901                  -0.909   \n",
       "std                    0.068                   0.057                   0.052   \n",
       "min                   -0.998                  -0.998                  -0.998   \n",
       "25%                   -0.934                  -0.940                  -0.945   \n",
       "50%                   -0.901                  -0.910                  -0.918   \n",
       "75%                   -0.861                  -0.874                  -0.884   \n",
       "max                    2.922                   0.206                  -0.232   \n",
       "\n",
       "       r2_keras_loss_epoch_12  r2_keras_loss_epoch_13  r2_keras_loss_epoch_14  \\\n",
       "count               50000.000               50000.000               50000.000   \n",
       "mean                   -0.917                  -0.923                  -0.928   \n",
       "std                     0.047                   0.044                   0.041   \n",
       "min                    -0.999                  -0.999                  -0.999   \n",
       "25%                    -0.950                  -0.954                  -0.957   \n",
       "50%                    -0.924                  -0.929                  -0.934   \n",
       "75%                    -0.892                  -0.900                  -0.906   \n",
       "max                    -0.344                  -0.367                  -0.402   \n",
       "\n",
       "       r2_keras_loss_epoch_15  r2_keras_loss_epoch_16  r2_keras_loss_epoch_17  \\\n",
       "count               50000.000               50000.000               50000.000   \n",
       "mean                   -0.933                  -0.937                  -0.941   \n",
       "std                     0.039                   0.037                   0.035   \n",
       "min                    -0.999                  -0.999                  -0.999   \n",
       "25%                    -0.960                  -0.963                  -0.966   \n",
       "50%                    -0.939                  -0.943                  -0.947   \n",
       "75%                    -0.912                  -0.918                  -0.923   \n",
       "max                    -0.431                  -0.440                  -0.455   \n",
       "\n",
       "       r2_keras_loss_epoch_18  r2_keras_loss_epoch_19  r2_keras_loss_epoch_20  \\\n",
       "count               50000.000               50000.000               50000.000   \n",
       "mean                   -0.944                  -0.947                  -0.950   \n",
       "std                     0.033                   0.032                   0.030   \n",
       "min                    -0.999                  -0.999                  -0.999   \n",
       "25%                    -0.968                  -0.970                  -0.972   \n",
       "50%                    -0.950                  -0.953                  -0.956   \n",
       "75%                    -0.927                  -0.931                  -0.935   \n",
       "max                    -0.454                  -0.465                  -0.460   \n",
       "\n",
       "       r2_keras_loss_epoch_21  r2_keras_loss_epoch_22  r2_keras_loss_epoch_23  \\\n",
       "count               50000.000               50000.000               50000.000   \n",
       "mean                   -0.953                  -0.955                  -0.958   \n",
       "std                     0.029                   0.028                   0.027   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.974                  -0.976                  -0.977   \n",
       "50%                    -0.958                  -0.961                  -0.963   \n",
       "75%                    -0.938                  -0.942                  -0.945   \n",
       "max                    -0.465                  -0.466                  -0.471   \n",
       "\n",
       "       r2_keras_loss_epoch_24  r2_keras_loss_epoch_25  r2_keras_loss_epoch_26  \\\n",
       "count               50000.000               50000.000               50000.000   \n",
       "mean                   -0.960                  -0.962                  -0.964   \n",
       "std                     0.026                   0.025                   0.024   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.979                  -0.980                  -0.981   \n",
       "50%                    -0.965                  -0.967                  -0.969   \n",
       "75%                    -0.947                  -0.950                  -0.952   \n",
       "max                    -0.477                  -0.487                  -0.480   \n",
       "\n",
       "       r2_keras_loss_epoch_27  r2_keras_loss_epoch_28  r2_keras_loss_epoch_29  \\\n",
       "count               50000.000               50000.000               50000.000   \n",
       "mean                   -0.966                  -0.967                  -0.969   \n",
       "std                     0.023                   0.022                   0.022   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.982                  -0.983                  -0.984   \n",
       "50%                    -0.971                  -0.972                  -0.974   \n",
       "75%                    -0.955                  -0.957                  -0.959   \n",
       "max                    -0.468                  -0.473                  -0.489   \n",
       "\n",
       "       r2_keras_loss_epoch_30  r2_keras_loss_epoch_31  r2_keras_loss_epoch_32  \\\n",
       "count               50000.000               50000.000               50000.000   \n",
       "mean                   -0.970                  -0.971                  -0.973   \n",
       "std                     0.021                   0.020                   0.020   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.985                  -0.986                  -0.986   \n",
       "50%                    -0.975                  -0.976                  -0.977   \n",
       "75%                    -0.961                  -0.962                  -0.964   \n",
       "max                    -0.477                  -0.486                  -0.490   \n",
       "\n",
       "       r2_keras_loss_epoch_33  r2_keras_loss_epoch_34  r2_keras_loss_epoch_35  \\\n",
       "count               50000.000               50000.000               50000.000   \n",
       "mean                   -0.974                  -0.975                  -0.976   \n",
       "std                     0.019                   0.019                   0.018   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.987                  -0.988                  -0.988   \n",
       "50%                    -0.978                  -0.979                  -0.980   \n",
       "75%                    -0.966                  -0.967                  -0.968   \n",
       "max                    -0.483                  -0.477                  -0.496   \n",
       "\n",
       "       r2_keras_loss_epoch_36  r2_keras_loss_epoch_37  r2_keras_loss_epoch_38  \\\n",
       "count               50000.000               50000.000               50000.000   \n",
       "mean                   -0.977                  -0.978                  -0.978   \n",
       "std                     0.018                   0.017                   0.017   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.989                  -0.989                  -0.990   \n",
       "50%                    -0.981                  -0.982                  -0.983   \n",
       "75%                    -0.970                  -0.971                  -0.972   \n",
       "max                    -0.478                  -0.487                  -0.477   \n",
       "\n",
       "       r2_keras_loss_epoch_39  r2_keras_loss_epoch_40  r2_keras_loss_epoch_41  \\\n",
       "count               49999.000               49999.000               49997.000   \n",
       "mean                   -0.979                  -0.980                  -0.980   \n",
       "std                     0.016                   0.016                   0.015   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.990                  -0.990                  -0.991   \n",
       "50%                    -0.983                  -0.984                  -0.984   \n",
       "75%                    -0.973                  -0.974                  -0.975   \n",
       "max                    -0.493                  -0.486                  -0.492   \n",
       "\n",
       "       r2_keras_loss_epoch_42  r2_keras_loss_epoch_43  r2_keras_loss_epoch_44  \\\n",
       "count               49997.000               49996.000               49996.000   \n",
       "mean                   -0.981                  -0.982                  -0.982   \n",
       "std                     0.015                   0.014                   0.014   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.991                  -0.991                  -0.992   \n",
       "50%                    -0.985                  -0.985                  -0.986   \n",
       "75%                    -0.976                  -0.976                  -0.977   \n",
       "max                    -0.488                  -0.490                  -0.498   \n",
       "\n",
       "       r2_keras_loss_epoch_45  r2_keras_loss_epoch_46  r2_keras_loss_epoch_47  \\\n",
       "count               49995.000               49994.000               49992.000   \n",
       "mean                   -0.983                  -0.983                  -0.984   \n",
       "std                     0.014                   0.013                   0.013   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.992                  -0.992                  -0.992   \n",
       "50%                    -0.986                  -0.987                  -0.987   \n",
       "75%                    -0.978                  -0.979                  -0.979   \n",
       "max                    -0.500                  -0.494                  -0.492   \n",
       "\n",
       "       r2_keras_loss_epoch_48  r2_keras_loss_epoch_49  r2_keras_loss_epoch_50  \\\n",
       "count               49992.000               49989.000               49984.000   \n",
       "mean                   -0.984                  -0.985                  -0.985   \n",
       "std                     0.013                   0.013                   0.012   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.993                  -0.993                  -0.993   \n",
       "50%                    -0.988                  -0.988                  -0.988   \n",
       "75%                    -0.980                  -0.980                  -0.981   \n",
       "max                    -0.475                  -0.498                  -0.684   \n",
       "\n",
       "       r2_keras_loss_epoch_51  r2_keras_loss_epoch_52  r2_keras_loss_epoch_53  \\\n",
       "count               49982.000               49980.000               49974.000   \n",
       "mean                   -0.985                  -0.986                  -0.986   \n",
       "std                     0.012                   0.012                   0.011   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.993                  -0.993                  -0.993   \n",
       "50%                    -0.989                  -0.989                  -0.989   \n",
       "75%                    -0.981                  -0.982                  -0.982   \n",
       "max                    -0.687                  -0.689                  -0.706   \n",
       "\n",
       "       r2_keras_loss_epoch_54  r2_keras_loss_epoch_55  r2_keras_loss_epoch_56  \\\n",
       "count               49970.000               49965.000               49960.000   \n",
       "mean                   -0.986                  -0.987                  -0.987   \n",
       "std                     0.011                   0.011                   0.011   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.994                  -0.994                  -0.994   \n",
       "50%                    -0.989                  -0.990                  -0.990   \n",
       "75%                    -0.983                  -0.983                  -0.983   \n",
       "max                    -0.714                  -0.720                  -0.725   \n",
       "\n",
       "       r2_keras_loss_epoch_57  r2_keras_loss_epoch_58  r2_keras_loss_epoch_59  \\\n",
       "count               49957.000               49949.000               49945.000   \n",
       "mean                   -0.987                  -0.988                  -0.988   \n",
       "std                     0.010                   0.010                   0.010   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.994                  -0.994                  -0.994   \n",
       "50%                    -0.990                  -0.990                  -0.990   \n",
       "75%                    -0.984                  -0.984                  -0.984   \n",
       "max                    -0.726                  -0.744                  -0.749   \n",
       "\n",
       "       r2_keras_loss_epoch_60  r2_keras_loss_epoch_61  r2_keras_loss_epoch_62  \\\n",
       "count               49935.000               49923.000               49905.000   \n",
       "mean                   -0.988                  -0.988                  -0.988   \n",
       "std                     0.010                   0.010                   0.009   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.994                  -0.994                  -0.995   \n",
       "50%                    -0.991                  -0.991                  -0.991   \n",
       "75%                    -0.985                  -0.985                  -0.985   \n",
       "max                    -0.765                  -0.773                  -0.778   \n",
       "\n",
       "       r2_keras_loss_epoch_63  r2_keras_loss_epoch_64  r2_keras_loss_epoch_65  \\\n",
       "count               49890.000               49876.000               49856.000   \n",
       "mean                   -0.989                  -0.989                  -0.989   \n",
       "std                     0.009                   0.009                   0.009   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.995                  -0.995                  -0.995   \n",
       "50%                    -0.991                  -0.991                  -0.991   \n",
       "75%                    -0.986                  -0.986                  -0.986   \n",
       "max                    -0.782                  -0.795                  -0.786   \n",
       "\n",
       "       r2_keras_loss_epoch_66  r2_keras_loss_epoch_67  r2_keras_loss_epoch_68  \\\n",
       "count               49835.000               49810.000               49785.000   \n",
       "mean                   -0.989                  -0.989                  -0.990   \n",
       "std                     0.009                   0.009                   0.009   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.995                  -0.995                  -0.995   \n",
       "50%                    -0.992                  -0.992                  -0.992   \n",
       "75%                    -0.986                  -0.987                  -0.987   \n",
       "max                    -0.798                  -0.806                  -0.806   \n",
       "\n",
       "       r2_keras_loss_epoch_69  r2_keras_loss_epoch_70  r2_keras_loss_epoch_71  \\\n",
       "count               49762.000               49727.000               49689.000   \n",
       "mean                   -0.990                  -0.990                  -0.990   \n",
       "std                     0.008                   0.008                   0.008   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.995                  -0.995                  -0.995   \n",
       "50%                    -0.992                  -0.992                  -0.992   \n",
       "75%                    -0.987                  -0.987                  -0.987   \n",
       "max                    -0.812                  -0.809                  -0.826   \n",
       "\n",
       "       r2_keras_loss_epoch_72  r2_keras_loss_epoch_73  r2_keras_loss_epoch_74  \\\n",
       "count               49646.000               49613.000               49576.000   \n",
       "mean                   -0.990                  -0.990                  -0.990   \n",
       "std                     0.008                   0.008                   0.008   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.995                  -0.995                  -0.996   \n",
       "50%                    -0.992                  -0.992                  -0.993   \n",
       "75%                    -0.988                  -0.988                  -0.988   \n",
       "max                    -0.825                  -0.834                  -0.826   \n",
       "\n",
       "       r2_keras_loss_epoch_75  r2_keras_loss_epoch_76  r2_keras_loss_epoch_77  \\\n",
       "count               49535.000               49483.000               49428.000   \n",
       "mean                   -0.991                  -0.991                  -0.991   \n",
       "std                     0.008                   0.008                   0.007   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.996                  -0.996                  -0.996   \n",
       "50%                    -0.993                  -0.993                  -0.993   \n",
       "75%                    -0.988                  -0.988                  -0.988   \n",
       "max                    -0.838                  -0.841                  -0.845   \n",
       "\n",
       "       r2_keras_loss_epoch_78  r2_keras_loss_epoch_79  r2_keras_loss_epoch_80  \\\n",
       "count               49357.000               49282.000               49198.000   \n",
       "mean                   -0.991                  -0.991                  -0.991   \n",
       "std                     0.007                   0.007                   0.007   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.996                  -0.996                  -0.996   \n",
       "50%                    -0.993                  -0.993                  -0.993   \n",
       "75%                    -0.989                  -0.989                  -0.989   \n",
       "max                    -0.850                  -0.850                  -0.849   \n",
       "\n",
       "       r2_keras_loss_epoch_81  r2_keras_loss_epoch_82  r2_keras_loss_epoch_83  \\\n",
       "count               49107.000               49000.000               48880.000   \n",
       "mean                   -0.991                  -0.991                  -0.992   \n",
       "std                     0.007                   0.007                   0.007   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.996                  -0.996                  -0.996   \n",
       "50%                    -0.993                  -0.993                  -0.993   \n",
       "75%                    -0.989                  -0.989                  -0.989   \n",
       "max                    -0.851                  -0.856                  -0.854   \n",
       "\n",
       "       r2_keras_loss_epoch_84  r2_keras_loss_epoch_85  r2_keras_loss_epoch_86  \\\n",
       "count               48770.000               48637.000               48489.000   \n",
       "mean                   -0.992                  -0.992                  -0.992   \n",
       "std                     0.007                   0.007                   0.007   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.996                  -0.996                  -0.996   \n",
       "50%                    -0.993                  -0.993                  -0.994   \n",
       "75%                    -0.989                  -0.989                  -0.990   \n",
       "max                    -0.856                  -0.856                  -0.856   \n",
       "\n",
       "       r2_keras_loss_epoch_87  r2_keras_loss_epoch_88  r2_keras_loss_epoch_89  \\\n",
       "count               48358.000               48202.000               48024.000   \n",
       "mean                   -0.992                  -0.992                  -0.992   \n",
       "std                     0.007                   0.007                   0.006   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.996                  -0.996                  -0.996   \n",
       "50%                    -0.994                  -0.994                  -0.994   \n",
       "75%                    -0.990                  -0.990                  -0.990   \n",
       "max                    -0.857                  -0.858                  -0.855   \n",
       "\n",
       "       r2_keras_loss_epoch_90  r2_keras_loss_epoch_91  r2_keras_loss_epoch_92  \\\n",
       "count               47845.000               47646.000               47447.000   \n",
       "mean                   -0.992                  -0.992                  -0.992   \n",
       "std                     0.006                   0.006                   0.006   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.996                  -0.996                  -0.996   \n",
       "50%                    -0.994                  -0.994                  -0.994   \n",
       "75%                    -0.990                  -0.990                  -0.990   \n",
       "max                    -0.861                  -0.860                  -0.860   \n",
       "\n",
       "       r2_keras_loss_epoch_93  r2_keras_loss_epoch_94  r2_keras_loss_epoch_95  \\\n",
       "count               47224.000               46989.000               46764.000   \n",
       "mean                   -0.992                  -0.992                  -0.992   \n",
       "std                     0.006                   0.006                   0.006   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.996                  -0.996                  -0.996   \n",
       "50%                    -0.994                  -0.994                  -0.994   \n",
       "75%                    -0.990                  -0.990                  -0.990   \n",
       "max                    -0.862                  -0.862                  -0.865   \n",
       "\n",
       "       r2_keras_loss_epoch_96  r2_keras_loss_epoch_97  r2_keras_loss_epoch_98  \\\n",
       "count               46530.000               46244.000               45959.000   \n",
       "mean                   -0.993                  -0.993                  -0.993   \n",
       "std                     0.006                   0.006                   0.006   \n",
       "min                    -1.000                  -1.000                  -1.000   \n",
       "25%                    -0.996                  -0.997                  -0.997   \n",
       "50%                    -0.994                  -0.994                  -0.994   \n",
       "75%                    -0.990                  -0.991                  -0.991   \n",
       "max                    -0.867                  -0.866                  -0.868   \n",
       "\n",
       "       r2_keras_loss_epoch_99  r2_keras_loss_epoch_100  \\\n",
       "count               45683.000                45352.000   \n",
       "mean                   -0.993                   -0.993   \n",
       "std                     0.006                    0.006   \n",
       "min                    -1.000                   -1.000   \n",
       "25%                    -0.997                   -0.997   \n",
       "50%                    -0.994                   -0.994   \n",
       "75%                    -0.991                   -0.991   \n",
       "max                    -0.866                   -0.871   \n",
       "\n",
       "       r2_keras_loss_epoch_101  r2_keras_loss_epoch_102  \\\n",
       "count                45032.000                44725.000   \n",
       "mean                    -0.993                   -0.993   \n",
       "std                      0.006                    0.006   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.994                   -0.994   \n",
       "75%                     -0.991                   -0.991   \n",
       "max                     -0.872                   -0.873   \n",
       "\n",
       "       r2_keras_loss_epoch_103  r2_keras_loss_epoch_104  \\\n",
       "count                44416.000                44045.000   \n",
       "mean                    -0.993                   -0.993   \n",
       "std                      0.006                    0.006   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.994                   -0.995   \n",
       "75%                     -0.991                   -0.991   \n",
       "max                     -0.874                   -0.876   \n",
       "\n",
       "       r2_keras_loss_epoch_105  r2_keras_loss_epoch_106  \\\n",
       "count                43666.000                43276.000   \n",
       "mean                    -0.993                   -0.993   \n",
       "std                      0.006                    0.006   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.991                   -0.991   \n",
       "max                     -0.876                   -0.879   \n",
       "\n",
       "       r2_keras_loss_epoch_107  r2_keras_loss_epoch_108  \\\n",
       "count                42871.000                42516.000   \n",
       "mean                    -0.993                   -0.993   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.991                   -0.991   \n",
       "max                     -0.879                   -0.880   \n",
       "\n",
       "       r2_keras_loss_epoch_109  r2_keras_loss_epoch_110  \\\n",
       "count                42120.000                41681.000   \n",
       "mean                    -0.993                   -0.993   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.991                   -0.991   \n",
       "max                     -0.883                   -0.884   \n",
       "\n",
       "       r2_keras_loss_epoch_111  r2_keras_loss_epoch_112  \\\n",
       "count                41237.000                40781.000   \n",
       "mean                    -0.993                   -0.993   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.992   \n",
       "max                     -0.884                   -0.888   \n",
       "\n",
       "       r2_keras_loss_epoch_113  r2_keras_loss_epoch_114  \\\n",
       "count                40315.000                39829.000   \n",
       "mean                    -0.993                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.992   \n",
       "max                     -0.888                   -0.888   \n",
       "\n",
       "       r2_keras_loss_epoch_115  r2_keras_loss_epoch_116  \\\n",
       "count                39368.000                38884.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.992   \n",
       "max                     -0.892                   -0.892   \n",
       "\n",
       "       r2_keras_loss_epoch_117  r2_keras_loss_epoch_118  \\\n",
       "count                38358.000                37875.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.992   \n",
       "max                     -0.892                   -0.893   \n",
       "\n",
       "       r2_keras_loss_epoch_119  r2_keras_loss_epoch_120  \\\n",
       "count                37348.000                36860.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.992   \n",
       "max                     -0.897                   -0.899   \n",
       "\n",
       "       r2_keras_loss_epoch_121  r2_keras_loss_epoch_122  \\\n",
       "count                36343.000                35791.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.992   \n",
       "max                     -0.899                   -0.899   \n",
       "\n",
       "       r2_keras_loss_epoch_123  r2_keras_loss_epoch_124  \\\n",
       "count                35260.000                34687.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.992   \n",
       "max                     -0.902                   -0.903   \n",
       "\n",
       "       r2_keras_loss_epoch_125  r2_keras_loss_epoch_126  \\\n",
       "count                34157.000                33582.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.992   \n",
       "max                     -0.904                   -0.904   \n",
       "\n",
       "       r2_keras_loss_epoch_127  r2_keras_loss_epoch_128  \\\n",
       "count                33063.000                32504.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.992   \n",
       "max                     -0.905                   -0.905   \n",
       "\n",
       "       r2_keras_loss_epoch_129  r2_keras_loss_epoch_130  \\\n",
       "count                31957.000                31392.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.992                   -0.993   \n",
       "max                     -0.903                   -0.906   \n",
       "\n",
       "       r2_keras_loss_epoch_131  r2_keras_loss_epoch_132  \\\n",
       "count                30845.000                30268.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.909                   -0.907   \n",
       "\n",
       "       r2_keras_loss_epoch_133  r2_keras_loss_epoch_134  \\\n",
       "count                29729.000                29168.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.995   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.908                   -0.905   \n",
       "\n",
       "       r2_keras_loss_epoch_135  r2_keras_loss_epoch_136  \\\n",
       "count                28631.000                27983.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.005   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.995                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.911                   -0.910   \n",
       "\n",
       "       r2_keras_loss_epoch_137  r2_keras_loss_epoch_138  \\\n",
       "count                27429.000                26867.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.005                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.911                   -0.911   \n",
       "\n",
       "       r2_keras_loss_epoch_139  r2_keras_loss_epoch_140  \\\n",
       "count                26363.000                25806.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.911                   -0.913   \n",
       "\n",
       "       r2_keras_loss_epoch_141  r2_keras_loss_epoch_142  \\\n",
       "count                25243.000                24678.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.910                   -0.909   \n",
       "\n",
       "       r2_keras_loss_epoch_143  r2_keras_loss_epoch_144  \\\n",
       "count                24168.000                23634.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.909                   -0.915   \n",
       "\n",
       "       r2_keras_loss_epoch_145  r2_keras_loss_epoch_146  \\\n",
       "count                23071.000                22521.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.917                   -0.908   \n",
       "\n",
       "       r2_keras_loss_epoch_147  r2_keras_loss_epoch_148  \\\n",
       "count                21987.000                21456.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.912                   -0.918   \n",
       "\n",
       "       r2_keras_loss_epoch_149  r2_keras_loss_epoch_150  \\\n",
       "count                20973.000                20467.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.921                   -0.916   \n",
       "\n",
       "       r2_keras_loss_epoch_151  r2_keras_loss_epoch_152  \\\n",
       "count                19984.000                19485.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.920                   -0.921   \n",
       "\n",
       "       r2_keras_loss_epoch_153  r2_keras_loss_epoch_154  \\\n",
       "count                19010.000                18544.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.921                   -0.923   \n",
       "\n",
       "       r2_keras_loss_epoch_155  r2_keras_loss_epoch_156  \\\n",
       "count                18054.000                17599.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.921                   -0.922   \n",
       "\n",
       "       r2_keras_loss_epoch_157  r2_keras_loss_epoch_158  \\\n",
       "count                17138.000                16695.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.923                   -0.925   \n",
       "\n",
       "       r2_keras_loss_epoch_159  r2_keras_loss_epoch_160  \\\n",
       "count                16231.000                15795.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.993                   -0.993   \n",
       "max                     -0.923                   -0.924   \n",
       "\n",
       "       r2_keras_loss_epoch_161  r2_keras_loss_epoch_162  \\\n",
       "count                15394.000                14973.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.925                   -0.927   \n",
       "\n",
       "       r2_keras_loss_epoch_163  r2_keras_loss_epoch_164  \\\n",
       "count                14563.000                14150.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.925                   -0.926   \n",
       "\n",
       "       r2_keras_loss_epoch_165  r2_keras_loss_epoch_166  \\\n",
       "count                13751.000                13347.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.927                   -0.928   \n",
       "\n",
       "       r2_keras_loss_epoch_167  r2_keras_loss_epoch_168  \\\n",
       "count                12961.000                12579.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.929                   -0.929   \n",
       "\n",
       "       r2_keras_loss_epoch_169  r2_keras_loss_epoch_170  \\\n",
       "count                12195.000                11826.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.928                   -0.930   \n",
       "\n",
       "       r2_keras_loss_epoch_171  r2_keras_loss_epoch_172  \\\n",
       "count                11507.000                11169.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.930                   -0.932   \n",
       "\n",
       "       r2_keras_loss_epoch_173  r2_keras_loss_epoch_174  \\\n",
       "count                10845.000                10467.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.931                   -0.931   \n",
       "\n",
       "       r2_keras_loss_epoch_175  r2_keras_loss_epoch_176  \\\n",
       "count                10136.000                 9816.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.933                   -0.933   \n",
       "\n",
       "       r2_keras_loss_epoch_177  r2_keras_loss_epoch_178  \\\n",
       "count                 9524.000                 9211.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.933                   -0.935   \n",
       "\n",
       "       r2_keras_loss_epoch_179  r2_keras_loss_epoch_180  \\\n",
       "count                 8910.000                 8632.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.936                   -0.935   \n",
       "\n",
       "       r2_keras_loss_epoch_181  r2_keras_loss_epoch_182  \\\n",
       "count                 8389.000                 8105.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.937                   -0.938   \n",
       "\n",
       "       r2_keras_loss_epoch_183  r2_keras_loss_epoch_184  \\\n",
       "count                 7861.000                 7574.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.938                   -0.939   \n",
       "\n",
       "       r2_keras_loss_epoch_185  r2_keras_loss_epoch_186  \\\n",
       "count                 7322.000                 7087.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.939                   -0.941   \n",
       "\n",
       "       r2_keras_loss_epoch_187  r2_keras_loss_epoch_188  \\\n",
       "count                 6849.000                 6618.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.940                   -0.941   \n",
       "\n",
       "       r2_keras_loss_epoch_189  r2_keras_loss_epoch_190  \\\n",
       "count                 6415.000                 6201.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.942                   -0.942   \n",
       "\n",
       "       r2_keras_loss_epoch_191  r2_keras_loss_epoch_192  \\\n",
       "count                 5968.000                 5776.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.943                   -0.941   \n",
       "\n",
       "       r2_keras_loss_epoch_193  r2_keras_loss_epoch_194  \\\n",
       "count                 5573.000                 5374.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.943                   -0.945   \n",
       "\n",
       "       r2_keras_loss_epoch_195  r2_keras_loss_epoch_196  \\\n",
       "count                 5191.000                 5013.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.945                   -0.946   \n",
       "\n",
       "       r2_keras_loss_epoch_197  r2_keras_loss_epoch_198  \\\n",
       "count                 4861.000                 4688.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.945                   -0.946   \n",
       "\n",
       "       r2_keras_loss_epoch_199  r2_keras_loss_epoch_200  \\\n",
       "count                 4506.000                 4349.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.947                   -0.948   \n",
       "\n",
       "       r2_keras_loss_epoch_201  r2_keras_loss_epoch_202  \\\n",
       "count                 4214.000                 4077.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.948                   -0.948   \n",
       "\n",
       "       r2_keras_loss_epoch_203  r2_keras_loss_epoch_204  \\\n",
       "count                 3932.000                 3783.000   \n",
       "mean                    -0.995                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.950                   -0.950   \n",
       "\n",
       "       r2_keras_loss_epoch_205  r2_keras_loss_epoch_206  \\\n",
       "count                 3642.000                 3509.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.950                   -0.949   \n",
       "\n",
       "       r2_keras_loss_epoch_207  r2_keras_loss_epoch_208  \\\n",
       "count                 3363.000                 3234.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.952                   -0.952   \n",
       "\n",
       "       r2_keras_loss_epoch_209  r2_keras_loss_epoch_210  \\\n",
       "count                 3116.000                 3004.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.950                   -0.951   \n",
       "\n",
       "       r2_keras_loss_epoch_211  r2_keras_loss_epoch_212  \\\n",
       "count                 2885.000                 2773.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.952                   -0.952   \n",
       "\n",
       "       r2_keras_loss_epoch_213  r2_keras_loss_epoch_214  \\\n",
       "count                 2690.000                 2584.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.954                   -0.953   \n",
       "\n",
       "       r2_keras_loss_epoch_215  r2_keras_loss_epoch_216  \\\n",
       "count                 2484.000                 2386.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.997   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.953                   -0.954   \n",
       "\n",
       "       r2_keras_loss_epoch_217  r2_keras_loss_epoch_218  \\\n",
       "count                 2291.000                 2205.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.994                   -0.995   \n",
       "max                     -0.954                   -0.954   \n",
       "\n",
       "       r2_keras_loss_epoch_219  r2_keras_loss_epoch_220  \\\n",
       "count                 2119.000                 2034.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.956                   -0.955   \n",
       "\n",
       "       r2_keras_loss_epoch_221  r2_keras_loss_epoch_222  \\\n",
       "count                 1967.000                 1896.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.956                   -0.957   \n",
       "\n",
       "       r2_keras_loss_epoch_223  r2_keras_loss_epoch_224  \\\n",
       "count                 1824.000                 1753.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.957                   -0.956   \n",
       "\n",
       "       r2_keras_loss_epoch_225  r2_keras_loss_epoch_226  \\\n",
       "count                 1688.000                 1610.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.956                   -0.957   \n",
       "\n",
       "       r2_keras_loss_epoch_227  r2_keras_loss_epoch_228  \\\n",
       "count                 1544.000                 1481.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.957                   -0.958   \n",
       "\n",
       "       r2_keras_loss_epoch_229  r2_keras_loss_epoch_230  \\\n",
       "count                 1429.000                 1376.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.957                   -0.959   \n",
       "\n",
       "       r2_keras_loss_epoch_231  r2_keras_loss_epoch_232  \\\n",
       "count                 1310.000                 1262.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.959                   -0.958   \n",
       "\n",
       "       r2_keras_loss_epoch_233  r2_keras_loss_epoch_234  \\\n",
       "count                 1214.000                 1160.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.959                   -0.959   \n",
       "\n",
       "       r2_keras_loss_epoch_235  r2_keras_loss_epoch_236  \\\n",
       "count                 1114.000                 1058.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.959                   -0.960   \n",
       "\n",
       "       r2_keras_loss_epoch_237  r2_keras_loss_epoch_238  \\\n",
       "count                 1019.000                  986.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.959                   -0.960   \n",
       "\n",
       "       r2_keras_loss_epoch_239  r2_keras_loss_epoch_240  \\\n",
       "count                  953.000                  921.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.961                   -0.960   \n",
       "\n",
       "       r2_keras_loss_epoch_241  r2_keras_loss_epoch_242  \\\n",
       "count                  886.000                  855.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.959                   -0.961   \n",
       "\n",
       "       r2_keras_loss_epoch_243  r2_keras_loss_epoch_244  \\\n",
       "count                  822.000                  787.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.961                   -0.960   \n",
       "\n",
       "       r2_keras_loss_epoch_245  r2_keras_loss_epoch_246  \\\n",
       "count                  745.000                  715.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.961                   -0.961   \n",
       "\n",
       "       r2_keras_loss_epoch_247  r2_keras_loss_epoch_248  \\\n",
       "count                  682.000                  646.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.961                   -0.961   \n",
       "\n",
       "       r2_keras_loss_epoch_249  r2_keras_loss_epoch_250  \\\n",
       "count                  618.000                  599.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.962                   -0.962   \n",
       "\n",
       "       r2_keras_loss_epoch_251  r2_keras_loss_epoch_252  \\\n",
       "count                  567.000                  538.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.962                   -0.962   \n",
       "\n",
       "       r2_keras_loss_epoch_253  r2_keras_loss_epoch_254  \\\n",
       "count                  519.000                  497.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.963                   -0.963   \n",
       "\n",
       "       r2_keras_loss_epoch_255  r2_keras_loss_epoch_256  \\\n",
       "count                  479.000                  462.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.962                   -0.963   \n",
       "\n",
       "       r2_keras_loss_epoch_257  r2_keras_loss_epoch_258  \\\n",
       "count                  438.000                  417.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.963                   -0.962   \n",
       "\n",
       "       r2_keras_loss_epoch_259  r2_keras_loss_epoch_260  \\\n",
       "count                  396.000                  379.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.963                   -0.963   \n",
       "\n",
       "       r2_keras_loss_epoch_261  r2_keras_loss_epoch_262  \\\n",
       "count                  364.000                  341.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.964                   -0.964   \n",
       "\n",
       "       r2_keras_loss_epoch_263  r2_keras_loss_epoch_264  \\\n",
       "count                  327.000                  315.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.964                   -0.963   \n",
       "\n",
       "       r2_keras_loss_epoch_265  r2_keras_loss_epoch_266  \\\n",
       "count                  296.000                  284.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.964                   -0.965   \n",
       "\n",
       "       r2_keras_loss_epoch_267  r2_keras_loss_epoch_268  \\\n",
       "count                  270.000                  257.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.965                   -0.965   \n",
       "\n",
       "       r2_keras_loss_epoch_269  r2_keras_loss_epoch_270  \\\n",
       "count                  240.000                  232.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.965                   -0.965   \n",
       "\n",
       "       r2_keras_loss_epoch_271  r2_keras_loss_epoch_272  \\\n",
       "count                  222.000                  211.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.965                   -0.965   \n",
       "\n",
       "       r2_keras_loss_epoch_273  r2_keras_loss_epoch_274  \\\n",
       "count                  202.000                  192.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -1.000                   -1.000   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.966                   -0.966   \n",
       "\n",
       "       r2_keras_loss_epoch_275  r2_keras_loss_epoch_276  \\\n",
       "count                  186.000                  175.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.966                   -0.966   \n",
       "\n",
       "       r2_keras_loss_epoch_277  r2_keras_loss_epoch_278  \\\n",
       "count                  168.000                  156.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.966                   -0.965   \n",
       "\n",
       "       r2_keras_loss_epoch_279  r2_keras_loss_epoch_280  \\\n",
       "count                  151.000                  146.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.966                   -0.966   \n",
       "\n",
       "       r2_keras_loss_epoch_281  r2_keras_loss_epoch_282  \\\n",
       "count                  139.000                  133.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.003                    0.003   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.966                   -0.967   \n",
       "\n",
       "       r2_keras_loss_epoch_283  r2_keras_loss_epoch_284  \\\n",
       "count                  123.000                  119.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.966                   -0.966   \n",
       "\n",
       "       r2_keras_loss_epoch_285  r2_keras_loss_epoch_286  \\\n",
       "count                  118.000                  114.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.968                   -0.967   \n",
       "\n",
       "       r2_keras_loss_epoch_287  r2_keras_loss_epoch_288  \\\n",
       "count                  108.000                  104.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.967                   -0.966   \n",
       "\n",
       "       r2_keras_loss_epoch_289  r2_keras_loss_epoch_290  \\\n",
       "count                  102.000                   99.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.968                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_291  r2_keras_loss_epoch_292  \\\n",
       "count                   94.000                   92.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.967                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_293  r2_keras_loss_epoch_294  \\\n",
       "count                   89.000                   87.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.967                   -0.965   \n",
       "\n",
       "       r2_keras_loss_epoch_295  r2_keras_loss_epoch_296  \\\n",
       "count                   85.000                   83.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.967                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_297  r2_keras_loss_epoch_298  \\\n",
       "count                   79.000                   77.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.969                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_299  r2_keras_loss_epoch_300  \\\n",
       "count                   75.000                   73.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.968                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_301  r2_keras_loss_epoch_302  \\\n",
       "count                   72.000                   71.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.967                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_303  r2_keras_loss_epoch_304  \\\n",
       "count                   67.000                   64.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.969                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_305  r2_keras_loss_epoch_306  \\\n",
       "count                   62.000                   59.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.968                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_307  r2_keras_loss_epoch_308  \\\n",
       "count                   56.000                   53.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.969                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_309  r2_keras_loss_epoch_310  \\\n",
       "count                   53.000                   50.000   \n",
       "mean                    -0.996                   -0.995   \n",
       "std                      0.004                    0.004   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.996   \n",
       "75%                     -0.995                   -0.994   \n",
       "max                     -0.968                   -0.970   \n",
       "\n",
       "       r2_keras_loss_epoch_311  r2_keras_loss_epoch_312  \\\n",
       "count                   49.000                   47.000   \n",
       "mean                    -0.995                   -0.995   \n",
       "std                      0.004                    0.005   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.996                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.970                   -0.968   \n",
       "\n",
       "       r2_keras_loss_epoch_313  r2_keras_loss_epoch_314  \\\n",
       "count                   46.000                   39.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.987                   -0.991   \n",
       "\n",
       "       r2_keras_loss_epoch_315  r2_keras_loss_epoch_316  \\\n",
       "count                   37.000                   35.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.998   \n",
       "25%                     -0.997                   -0.997   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.991                   -0.992   \n",
       "\n",
       "       r2_keras_loss_epoch_317  r2_keras_loss_epoch_318  \\\n",
       "count                   35.000                   35.000   \n",
       "mean                    -0.996                   -0.996   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.997                   -0.998   \n",
       "50%                     -0.996                   -0.996   \n",
       "75%                     -0.995                   -0.995   \n",
       "max                     -0.992                   -0.992   \n",
       "\n",
       "       r2_keras_loss_epoch_319  r2_keras_loss_epoch_320  \\\n",
       "count                   33.000                   32.000   \n",
       "mean                    -0.996                   -0.997   \n",
       "std                      0.002                    0.001   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.995                   -0.996   \n",
       "max                     -0.992                   -0.992   \n",
       "\n",
       "       r2_keras_loss_epoch_321  r2_keras_loss_epoch_322  \\\n",
       "count                   29.000                   27.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.998   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.996                   -0.996   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_323  r2_keras_loss_epoch_324  \\\n",
       "count                   25.000                   22.000   \n",
       "mean                    -0.996                   -0.997   \n",
       "std                      0.001                    0.002   \n",
       "min                     -0.998                   -0.998   \n",
       "25%                     -0.997                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.996                   -0.996   \n",
       "max                     -0.993                   -0.992   \n",
       "\n",
       "       r2_keras_loss_epoch_325  r2_keras_loss_epoch_326  \\\n",
       "count                   20.000                   19.000   \n",
       "mean                    -0.996                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.998                   -0.998   \n",
       "25%                     -0.997                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.996                   -0.996   \n",
       "max                     -0.993                   -0.992   \n",
       "\n",
       "       r2_keras_loss_epoch_327  r2_keras_loss_epoch_328  \\\n",
       "count                   19.000                   18.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.998                   -0.998   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.996                   -0.997   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_329  r2_keras_loss_epoch_330  \\\n",
       "count                   17.000                   16.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.001                    0.002   \n",
       "min                     -0.998                   -0.998   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_331  r2_keras_loss_epoch_332  \\\n",
       "count                   16.000                   15.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.001                    0.002   \n",
       "min                     -0.998                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_333  r2_keras_loss_epoch_334  \\\n",
       "count                   15.000                   15.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_335  r2_keras_loss_epoch_336  \\\n",
       "count                   14.000                   14.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.998                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.993                   -0.992   \n",
       "\n",
       "       r2_keras_loss_epoch_337  r2_keras_loss_epoch_338  \\\n",
       "count                   13.000                   11.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.997                   -0.996   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_339  r2_keras_loss_epoch_340  \\\n",
       "count                   11.000                   11.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.996                   -0.996   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_341  r2_keras_loss_epoch_342  \\\n",
       "count                   10.000                   10.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.994                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_343  r2_keras_loss_epoch_344  \\\n",
       "count                   10.000                   10.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_345  r2_keras_loss_epoch_346  \\\n",
       "count                   10.000                   10.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_347  r2_keras_loss_epoch_348  \\\n",
       "count                   10.000                   10.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.998   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.993                   -0.994   \n",
       "\n",
       "       r2_keras_loss_epoch_349  r2_keras_loss_epoch_350  \\\n",
       "count                   10.000                    9.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.997                   -0.997   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.993                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_351  r2_keras_loss_epoch_352  \\\n",
       "count                    8.000                    8.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.998                   -0.998   \n",
       "75%                     -0.996                   -0.997   \n",
       "max                     -0.993                   -0.994   \n",
       "\n",
       "       r2_keras_loss_epoch_353  r2_keras_loss_epoch_354  \\\n",
       "count                    8.000                    6.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.998                   -0.998   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.994                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_355  r2_keras_loss_epoch_356  \\\n",
       "count                    6.000                    6.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.998                   -0.998   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.994                   -0.993   \n",
       "\n",
       "       r2_keras_loss_epoch_357  r2_keras_loss_epoch_358  \\\n",
       "count                    6.000                    6.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.999   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.998                   -0.998   \n",
       "75%                     -0.997                   -0.997   \n",
       "max                     -0.994                   -0.994   \n",
       "\n",
       "       r2_keras_loss_epoch_359  r2_keras_loss_epoch_360  \\\n",
       "count                    5.000                    4.000   \n",
       "mean                    -0.997                   -0.997   \n",
       "std                      0.002                    0.002   \n",
       "min                     -0.999                   -0.998   \n",
       "25%                     -0.998                   -0.998   \n",
       "50%                     -0.998                   -0.998   \n",
       "75%                     -0.997                   -0.996   \n",
       "max                     -0.994                   -0.994   \n",
       "\n",
       "       r2_keras_loss_epoch_361  r2_keras_loss_epoch_362  \\\n",
       "count                    3.000                    1.000   \n",
       "mean                    -0.996                   -0.994   \n",
       "std                      0.002                      NaN   \n",
       "min                     -0.998                   -0.994   \n",
       "25%                     -0.998                   -0.994   \n",
       "50%                     -0.997                   -0.994   \n",
       "75%                     -0.995                   -0.994   \n",
       "max                     -0.994                   -0.994   \n",
       "\n",
       "       r2_keras_loss_epoch_363  r2_keras_loss_epoch_364  \\\n",
       "count                    1.000                    1.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                        NaN                      NaN   \n",
       "min                     -0.994                   -0.994   \n",
       "25%                     -0.994                   -0.994   \n",
       "50%                     -0.994                   -0.994   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.994                   -0.994   \n",
       "\n",
       "       r2_keras_loss_epoch_365  r2_keras_loss_epoch_366  \\\n",
       "count                    1.000                    1.000   \n",
       "mean                    -0.993                   -0.994   \n",
       "std                        NaN                      NaN   \n",
       "min                     -0.993                   -0.994   \n",
       "25%                     -0.993                   -0.994   \n",
       "50%                     -0.993                   -0.994   \n",
       "75%                     -0.993                   -0.994   \n",
       "max                     -0.993                   -0.994   \n",
       "\n",
       "       r2_keras_loss_epoch_367  r2_keras_loss_epoch_368  \\\n",
       "count                    1.000                    1.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                        NaN                      NaN   \n",
       "min                     -0.994                   -0.994   \n",
       "25%                     -0.994                   -0.994   \n",
       "50%                     -0.994                   -0.994   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.994                   -0.994   \n",
       "\n",
       "       r2_keras_loss_epoch_369  r2_keras_loss_epoch_370  \\\n",
       "count                    1.000                    1.000   \n",
       "mean                    -0.994                   -0.994   \n",
       "std                        NaN                      NaN   \n",
       "min                     -0.994                   -0.994   \n",
       "25%                     -0.994                   -0.994   \n",
       "50%                     -0.994                   -0.994   \n",
       "75%                     -0.994                   -0.994   \n",
       "max                     -0.994                   -0.994   \n",
       "\n",
       "       r2_keras_loss_epoch_371  \n",
       "count                    1.000  \n",
       "mean                    -0.994  \n",
       "std                        NaN  \n",
       "min                     -0.994  \n",
       "25%                     -0.994  \n",
       "50%                     -0.994  \n",
       "75%                     -0.994  \n",
       "max                     -0.994  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>val_r2_keras_loss_epoch_1</th>\n",
       "      <th>val_r2_keras_loss_epoch_2</th>\n",
       "      <th>val_r2_keras_loss_epoch_3</th>\n",
       "      <th>val_r2_keras_loss_epoch_4</th>\n",
       "      <th>val_r2_keras_loss_epoch_5</th>\n",
       "      <th>val_r2_keras_loss_epoch_6</th>\n",
       "      <th>val_r2_keras_loss_epoch_7</th>\n",
       "      <th>val_r2_keras_loss_epoch_8</th>\n",
       "      <th>val_r2_keras_loss_epoch_9</th>\n",
       "      <th>val_r2_keras_loss_epoch_10</th>\n",
       "      <th>val_r2_keras_loss_epoch_11</th>\n",
       "      <th>val_r2_keras_loss_epoch_12</th>\n",
       "      <th>val_r2_keras_loss_epoch_13</th>\n",
       "      <th>val_r2_keras_loss_epoch_14</th>\n",
       "      <th>val_r2_keras_loss_epoch_15</th>\n",
       "      <th>val_r2_keras_loss_epoch_16</th>\n",
       "      <th>val_r2_keras_loss_epoch_17</th>\n",
       "      <th>val_r2_keras_loss_epoch_18</th>\n",
       "      <th>val_r2_keras_loss_epoch_19</th>\n",
       "      <th>val_r2_keras_loss_epoch_20</th>\n",
       "      <th>val_r2_keras_loss_epoch_21</th>\n",
       "      <th>val_r2_keras_loss_epoch_22</th>\n",
       "      <th>val_r2_keras_loss_epoch_23</th>\n",
       "      <th>val_r2_keras_loss_epoch_24</th>\n",
       "      <th>val_r2_keras_loss_epoch_25</th>\n",
       "      <th>val_r2_keras_loss_epoch_26</th>\n",
       "      <th>val_r2_keras_loss_epoch_27</th>\n",
       "      <th>val_r2_keras_loss_epoch_28</th>\n",
       "      <th>val_r2_keras_loss_epoch_29</th>\n",
       "      <th>val_r2_keras_loss_epoch_30</th>\n",
       "      <th>val_r2_keras_loss_epoch_31</th>\n",
       "      <th>val_r2_keras_loss_epoch_32</th>\n",
       "      <th>val_r2_keras_loss_epoch_33</th>\n",
       "      <th>val_r2_keras_loss_epoch_34</th>\n",
       "      <th>val_r2_keras_loss_epoch_35</th>\n",
       "      <th>val_r2_keras_loss_epoch_36</th>\n",
       "      <th>val_r2_keras_loss_epoch_37</th>\n",
       "      <th>val_r2_keras_loss_epoch_38</th>\n",
       "      <th>val_r2_keras_loss_epoch_39</th>\n",
       "      <th>val_r2_keras_loss_epoch_40</th>\n",
       "      <th>val_r2_keras_loss_epoch_41</th>\n",
       "      <th>val_r2_keras_loss_epoch_42</th>\n",
       "      <th>val_r2_keras_loss_epoch_43</th>\n",
       "      <th>val_r2_keras_loss_epoch_44</th>\n",
       "      <th>val_r2_keras_loss_epoch_45</th>\n",
       "      <th>val_r2_keras_loss_epoch_46</th>\n",
       "      <th>val_r2_keras_loss_epoch_47</th>\n",
       "      <th>val_r2_keras_loss_epoch_48</th>\n",
       "      <th>val_r2_keras_loss_epoch_49</th>\n",
       "      <th>val_r2_keras_loss_epoch_50</th>\n",
       "      <th>val_r2_keras_loss_epoch_51</th>\n",
       "      <th>val_r2_keras_loss_epoch_52</th>\n",
       "      <th>val_r2_keras_loss_epoch_53</th>\n",
       "      <th>val_r2_keras_loss_epoch_54</th>\n",
       "      <th>val_r2_keras_loss_epoch_55</th>\n",
       "      <th>val_r2_keras_loss_epoch_56</th>\n",
       "      <th>val_r2_keras_loss_epoch_57</th>\n",
       "      <th>val_r2_keras_loss_epoch_58</th>\n",
       "      <th>val_r2_keras_loss_epoch_59</th>\n",
       "      <th>val_r2_keras_loss_epoch_60</th>\n",
       "      <th>val_r2_keras_loss_epoch_61</th>\n",
       "      <th>val_r2_keras_loss_epoch_62</th>\n",
       "      <th>val_r2_keras_loss_epoch_63</th>\n",
       "      <th>val_r2_keras_loss_epoch_64</th>\n",
       "      <th>val_r2_keras_loss_epoch_65</th>\n",
       "      <th>val_r2_keras_loss_epoch_66</th>\n",
       "      <th>val_r2_keras_loss_epoch_67</th>\n",
       "      <th>val_r2_keras_loss_epoch_68</th>\n",
       "      <th>val_r2_keras_loss_epoch_69</th>\n",
       "      <th>val_r2_keras_loss_epoch_70</th>\n",
       "      <th>val_r2_keras_loss_epoch_71</th>\n",
       "      <th>val_r2_keras_loss_epoch_72</th>\n",
       "      <th>val_r2_keras_loss_epoch_73</th>\n",
       "      <th>val_r2_keras_loss_epoch_74</th>\n",
       "      <th>val_r2_keras_loss_epoch_75</th>\n",
       "      <th>val_r2_keras_loss_epoch_76</th>\n",
       "      <th>val_r2_keras_loss_epoch_77</th>\n",
       "      <th>val_r2_keras_loss_epoch_78</th>\n",
       "      <th>val_r2_keras_loss_epoch_79</th>\n",
       "      <th>val_r2_keras_loss_epoch_80</th>\n",
       "      <th>val_r2_keras_loss_epoch_81</th>\n",
       "      <th>val_r2_keras_loss_epoch_82</th>\n",
       "      <th>val_r2_keras_loss_epoch_83</th>\n",
       "      <th>val_r2_keras_loss_epoch_84</th>\n",
       "      <th>val_r2_keras_loss_epoch_85</th>\n",
       "      <th>val_r2_keras_loss_epoch_86</th>\n",
       "      <th>val_r2_keras_loss_epoch_87</th>\n",
       "      <th>val_r2_keras_loss_epoch_88</th>\n",
       "      <th>val_r2_keras_loss_epoch_89</th>\n",
       "      <th>val_r2_keras_loss_epoch_90</th>\n",
       "      <th>val_r2_keras_loss_epoch_91</th>\n",
       "      <th>val_r2_keras_loss_epoch_92</th>\n",
       "      <th>val_r2_keras_loss_epoch_93</th>\n",
       "      <th>val_r2_keras_loss_epoch_94</th>\n",
       "      <th>val_r2_keras_loss_epoch_95</th>\n",
       "      <th>val_r2_keras_loss_epoch_96</th>\n",
       "      <th>val_r2_keras_loss_epoch_97</th>\n",
       "      <th>val_r2_keras_loss_epoch_98</th>\n",
       "      <th>val_r2_keras_loss_epoch_99</th>\n",
       "      <th>val_r2_keras_loss_epoch_100</th>\n",
       "      <th>val_r2_keras_loss_epoch_101</th>\n",
       "      <th>val_r2_keras_loss_epoch_102</th>\n",
       "      <th>val_r2_keras_loss_epoch_103</th>\n",
       "      <th>val_r2_keras_loss_epoch_104</th>\n",
       "      <th>val_r2_keras_loss_epoch_105</th>\n",
       "      <th>val_r2_keras_loss_epoch_106</th>\n",
       "      <th>val_r2_keras_loss_epoch_107</th>\n",
       "      <th>val_r2_keras_loss_epoch_108</th>\n",
       "      <th>val_r2_keras_loss_epoch_109</th>\n",
       "      <th>val_r2_keras_loss_epoch_110</th>\n",
       "      <th>val_r2_keras_loss_epoch_111</th>\n",
       "      <th>val_r2_keras_loss_epoch_112</th>\n",
       "      <th>val_r2_keras_loss_epoch_113</th>\n",
       "      <th>val_r2_keras_loss_epoch_114</th>\n",
       "      <th>val_r2_keras_loss_epoch_115</th>\n",
       "      <th>val_r2_keras_loss_epoch_116</th>\n",
       "      <th>val_r2_keras_loss_epoch_117</th>\n",
       "      <th>val_r2_keras_loss_epoch_118</th>\n",
       "      <th>val_r2_keras_loss_epoch_119</th>\n",
       "      <th>val_r2_keras_loss_epoch_120</th>\n",
       "      <th>val_r2_keras_loss_epoch_121</th>\n",
       "      <th>val_r2_keras_loss_epoch_122</th>\n",
       "      <th>val_r2_keras_loss_epoch_123</th>\n",
       "      <th>val_r2_keras_loss_epoch_124</th>\n",
       "      <th>val_r2_keras_loss_epoch_125</th>\n",
       "      <th>val_r2_keras_loss_epoch_126</th>\n",
       "      <th>val_r2_keras_loss_epoch_127</th>\n",
       "      <th>val_r2_keras_loss_epoch_128</th>\n",
       "      <th>val_r2_keras_loss_epoch_129</th>\n",
       "      <th>val_r2_keras_loss_epoch_130</th>\n",
       "      <th>val_r2_keras_loss_epoch_131</th>\n",
       "      <th>val_r2_keras_loss_epoch_132</th>\n",
       "      <th>val_r2_keras_loss_epoch_133</th>\n",
       "      <th>val_r2_keras_loss_epoch_134</th>\n",
       "      <th>val_r2_keras_loss_epoch_135</th>\n",
       "      <th>val_r2_keras_loss_epoch_136</th>\n",
       "      <th>val_r2_keras_loss_epoch_137</th>\n",
       "      <th>val_r2_keras_loss_epoch_138</th>\n",
       "      <th>val_r2_keras_loss_epoch_139</th>\n",
       "      <th>val_r2_keras_loss_epoch_140</th>\n",
       "      <th>val_r2_keras_loss_epoch_141</th>\n",
       "      <th>val_r2_keras_loss_epoch_142</th>\n",
       "      <th>val_r2_keras_loss_epoch_143</th>\n",
       "      <th>val_r2_keras_loss_epoch_144</th>\n",
       "      <th>val_r2_keras_loss_epoch_145</th>\n",
       "      <th>val_r2_keras_loss_epoch_146</th>\n",
       "      <th>val_r2_keras_loss_epoch_147</th>\n",
       "      <th>val_r2_keras_loss_epoch_148</th>\n",
       "      <th>val_r2_keras_loss_epoch_149</th>\n",
       "      <th>val_r2_keras_loss_epoch_150</th>\n",
       "      <th>val_r2_keras_loss_epoch_151</th>\n",
       "      <th>val_r2_keras_loss_epoch_152</th>\n",
       "      <th>val_r2_keras_loss_epoch_153</th>\n",
       "      <th>val_r2_keras_loss_epoch_154</th>\n",
       "      <th>val_r2_keras_loss_epoch_155</th>\n",
       "      <th>val_r2_keras_loss_epoch_156</th>\n",
       "      <th>val_r2_keras_loss_epoch_157</th>\n",
       "      <th>val_r2_keras_loss_epoch_158</th>\n",
       "      <th>val_r2_keras_loss_epoch_159</th>\n",
       "      <th>val_r2_keras_loss_epoch_160</th>\n",
       "      <th>val_r2_keras_loss_epoch_161</th>\n",
       "      <th>val_r2_keras_loss_epoch_162</th>\n",
       "      <th>val_r2_keras_loss_epoch_163</th>\n",
       "      <th>val_r2_keras_loss_epoch_164</th>\n",
       "      <th>val_r2_keras_loss_epoch_165</th>\n",
       "      <th>val_r2_keras_loss_epoch_166</th>\n",
       "      <th>val_r2_keras_loss_epoch_167</th>\n",
       "      <th>val_r2_keras_loss_epoch_168</th>\n",
       "      <th>val_r2_keras_loss_epoch_169</th>\n",
       "      <th>val_r2_keras_loss_epoch_170</th>\n",
       "      <th>val_r2_keras_loss_epoch_171</th>\n",
       "      <th>val_r2_keras_loss_epoch_172</th>\n",
       "      <th>val_r2_keras_loss_epoch_173</th>\n",
       "      <th>val_r2_keras_loss_epoch_174</th>\n",
       "      <th>val_r2_keras_loss_epoch_175</th>\n",
       "      <th>val_r2_keras_loss_epoch_176</th>\n",
       "      <th>val_r2_keras_loss_epoch_177</th>\n",
       "      <th>val_r2_keras_loss_epoch_178</th>\n",
       "      <th>val_r2_keras_loss_epoch_179</th>\n",
       "      <th>val_r2_keras_loss_epoch_180</th>\n",
       "      <th>val_r2_keras_loss_epoch_181</th>\n",
       "      <th>val_r2_keras_loss_epoch_182</th>\n",
       "      <th>val_r2_keras_loss_epoch_183</th>\n",
       "      <th>val_r2_keras_loss_epoch_184</th>\n",
       "      <th>val_r2_keras_loss_epoch_185</th>\n",
       "      <th>val_r2_keras_loss_epoch_186</th>\n",
       "      <th>val_r2_keras_loss_epoch_187</th>\n",
       "      <th>val_r2_keras_loss_epoch_188</th>\n",
       "      <th>val_r2_keras_loss_epoch_189</th>\n",
       "      <th>val_r2_keras_loss_epoch_190</th>\n",
       "      <th>val_r2_keras_loss_epoch_191</th>\n",
       "      <th>val_r2_keras_loss_epoch_192</th>\n",
       "      <th>val_r2_keras_loss_epoch_193</th>\n",
       "      <th>val_r2_keras_loss_epoch_194</th>\n",
       "      <th>val_r2_keras_loss_epoch_195</th>\n",
       "      <th>val_r2_keras_loss_epoch_196</th>\n",
       "      <th>val_r2_keras_loss_epoch_197</th>\n",
       "      <th>val_r2_keras_loss_epoch_198</th>\n",
       "      <th>val_r2_keras_loss_epoch_199</th>\n",
       "      <th>val_r2_keras_loss_epoch_200</th>\n",
       "      <th>val_r2_keras_loss_epoch_201</th>\n",
       "      <th>val_r2_keras_loss_epoch_202</th>\n",
       "      <th>val_r2_keras_loss_epoch_203</th>\n",
       "      <th>val_r2_keras_loss_epoch_204</th>\n",
       "      <th>val_r2_keras_loss_epoch_205</th>\n",
       "      <th>val_r2_keras_loss_epoch_206</th>\n",
       "      <th>val_r2_keras_loss_epoch_207</th>\n",
       "      <th>val_r2_keras_loss_epoch_208</th>\n",
       "      <th>val_r2_keras_loss_epoch_209</th>\n",
       "      <th>val_r2_keras_loss_epoch_210</th>\n",
       "      <th>val_r2_keras_loss_epoch_211</th>\n",
       "      <th>val_r2_keras_loss_epoch_212</th>\n",
       "      <th>val_r2_keras_loss_epoch_213</th>\n",
       "      <th>val_r2_keras_loss_epoch_214</th>\n",
       "      <th>val_r2_keras_loss_epoch_215</th>\n",
       "      <th>val_r2_keras_loss_epoch_216</th>\n",
       "      <th>val_r2_keras_loss_epoch_217</th>\n",
       "      <th>val_r2_keras_loss_epoch_218</th>\n",
       "      <th>val_r2_keras_loss_epoch_219</th>\n",
       "      <th>val_r2_keras_loss_epoch_220</th>\n",
       "      <th>val_r2_keras_loss_epoch_221</th>\n",
       "      <th>val_r2_keras_loss_epoch_222</th>\n",
       "      <th>val_r2_keras_loss_epoch_223</th>\n",
       "      <th>val_r2_keras_loss_epoch_224</th>\n",
       "      <th>val_r2_keras_loss_epoch_225</th>\n",
       "      <th>val_r2_keras_loss_epoch_226</th>\n",
       "      <th>val_r2_keras_loss_epoch_227</th>\n",
       "      <th>val_r2_keras_loss_epoch_228</th>\n",
       "      <th>val_r2_keras_loss_epoch_229</th>\n",
       "      <th>val_r2_keras_loss_epoch_230</th>\n",
       "      <th>val_r2_keras_loss_epoch_231</th>\n",
       "      <th>val_r2_keras_loss_epoch_232</th>\n",
       "      <th>val_r2_keras_loss_epoch_233</th>\n",
       "      <th>val_r2_keras_loss_epoch_234</th>\n",
       "      <th>val_r2_keras_loss_epoch_235</th>\n",
       "      <th>val_r2_keras_loss_epoch_236</th>\n",
       "      <th>val_r2_keras_loss_epoch_237</th>\n",
       "      <th>val_r2_keras_loss_epoch_238</th>\n",
       "      <th>val_r2_keras_loss_epoch_239</th>\n",
       "      <th>val_r2_keras_loss_epoch_240</th>\n",
       "      <th>val_r2_keras_loss_epoch_241</th>\n",
       "      <th>val_r2_keras_loss_epoch_242</th>\n",
       "      <th>val_r2_keras_loss_epoch_243</th>\n",
       "      <th>val_r2_keras_loss_epoch_244</th>\n",
       "      <th>val_r2_keras_loss_epoch_245</th>\n",
       "      <th>val_r2_keras_loss_epoch_246</th>\n",
       "      <th>val_r2_keras_loss_epoch_247</th>\n",
       "      <th>val_r2_keras_loss_epoch_248</th>\n",
       "      <th>val_r2_keras_loss_epoch_249</th>\n",
       "      <th>val_r2_keras_loss_epoch_250</th>\n",
       "      <th>val_r2_keras_loss_epoch_251</th>\n",
       "      <th>val_r2_keras_loss_epoch_252</th>\n",
       "      <th>val_r2_keras_loss_epoch_253</th>\n",
       "      <th>val_r2_keras_loss_epoch_254</th>\n",
       "      <th>val_r2_keras_loss_epoch_255</th>\n",
       "      <th>val_r2_keras_loss_epoch_256</th>\n",
       "      <th>val_r2_keras_loss_epoch_257</th>\n",
       "      <th>val_r2_keras_loss_epoch_258</th>\n",
       "      <th>val_r2_keras_loss_epoch_259</th>\n",
       "      <th>val_r2_keras_loss_epoch_260</th>\n",
       "      <th>val_r2_keras_loss_epoch_261</th>\n",
       "      <th>val_r2_keras_loss_epoch_262</th>\n",
       "      <th>val_r2_keras_loss_epoch_263</th>\n",
       "      <th>val_r2_keras_loss_epoch_264</th>\n",
       "      <th>val_r2_keras_loss_epoch_265</th>\n",
       "      <th>val_r2_keras_loss_epoch_266</th>\n",
       "      <th>val_r2_keras_loss_epoch_267</th>\n",
       "      <th>val_r2_keras_loss_epoch_268</th>\n",
       "      <th>val_r2_keras_loss_epoch_269</th>\n",
       "      <th>val_r2_keras_loss_epoch_270</th>\n",
       "      <th>val_r2_keras_loss_epoch_271</th>\n",
       "      <th>val_r2_keras_loss_epoch_272</th>\n",
       "      <th>val_r2_keras_loss_epoch_273</th>\n",
       "      <th>val_r2_keras_loss_epoch_274</th>\n",
       "      <th>val_r2_keras_loss_epoch_275</th>\n",
       "      <th>val_r2_keras_loss_epoch_276</th>\n",
       "      <th>val_r2_keras_loss_epoch_277</th>\n",
       "      <th>val_r2_keras_loss_epoch_278</th>\n",
       "      <th>val_r2_keras_loss_epoch_279</th>\n",
       "      <th>val_r2_keras_loss_epoch_280</th>\n",
       "      <th>val_r2_keras_loss_epoch_281</th>\n",
       "      <th>val_r2_keras_loss_epoch_282</th>\n",
       "      <th>val_r2_keras_loss_epoch_283</th>\n",
       "      <th>val_r2_keras_loss_epoch_284</th>\n",
       "      <th>val_r2_keras_loss_epoch_285</th>\n",
       "      <th>val_r2_keras_loss_epoch_286</th>\n",
       "      <th>val_r2_keras_loss_epoch_287</th>\n",
       "      <th>val_r2_keras_loss_epoch_288</th>\n",
       "      <th>val_r2_keras_loss_epoch_289</th>\n",
       "      <th>val_r2_keras_loss_epoch_290</th>\n",
       "      <th>val_r2_keras_loss_epoch_291</th>\n",
       "      <th>val_r2_keras_loss_epoch_292</th>\n",
       "      <th>val_r2_keras_loss_epoch_293</th>\n",
       "      <th>val_r2_keras_loss_epoch_294</th>\n",
       "      <th>val_r2_keras_loss_epoch_295</th>\n",
       "      <th>val_r2_keras_loss_epoch_296</th>\n",
       "      <th>val_r2_keras_loss_epoch_297</th>\n",
       "      <th>val_r2_keras_loss_epoch_298</th>\n",
       "      <th>val_r2_keras_loss_epoch_299</th>\n",
       "      <th>val_r2_keras_loss_epoch_300</th>\n",
       "      <th>val_r2_keras_loss_epoch_301</th>\n",
       "      <th>val_r2_keras_loss_epoch_302</th>\n",
       "      <th>val_r2_keras_loss_epoch_303</th>\n",
       "      <th>val_r2_keras_loss_epoch_304</th>\n",
       "      <th>val_r2_keras_loss_epoch_305</th>\n",
       "      <th>val_r2_keras_loss_epoch_306</th>\n",
       "      <th>val_r2_keras_loss_epoch_307</th>\n",
       "      <th>val_r2_keras_loss_epoch_308</th>\n",
       "      <th>val_r2_keras_loss_epoch_309</th>\n",
       "      <th>val_r2_keras_loss_epoch_310</th>\n",
       "      <th>val_r2_keras_loss_epoch_311</th>\n",
       "      <th>val_r2_keras_loss_epoch_312</th>\n",
       "      <th>val_r2_keras_loss_epoch_313</th>\n",
       "      <th>val_r2_keras_loss_epoch_314</th>\n",
       "      <th>val_r2_keras_loss_epoch_315</th>\n",
       "      <th>val_r2_keras_loss_epoch_316</th>\n",
       "      <th>val_r2_keras_loss_epoch_317</th>\n",
       "      <th>val_r2_keras_loss_epoch_318</th>\n",
       "      <th>val_r2_keras_loss_epoch_319</th>\n",
       "      <th>val_r2_keras_loss_epoch_320</th>\n",
       "      <th>val_r2_keras_loss_epoch_321</th>\n",
       "      <th>val_r2_keras_loss_epoch_322</th>\n",
       "      <th>val_r2_keras_loss_epoch_323</th>\n",
       "      <th>val_r2_keras_loss_epoch_324</th>\n",
       "      <th>val_r2_keras_loss_epoch_325</th>\n",
       "      <th>val_r2_keras_loss_epoch_326</th>\n",
       "      <th>val_r2_keras_loss_epoch_327</th>\n",
       "      <th>val_r2_keras_loss_epoch_328</th>\n",
       "      <th>val_r2_keras_loss_epoch_329</th>\n",
       "      <th>val_r2_keras_loss_epoch_330</th>\n",
       "      <th>val_r2_keras_loss_epoch_331</th>\n",
       "      <th>val_r2_keras_loss_epoch_332</th>\n",
       "      <th>val_r2_keras_loss_epoch_333</th>\n",
       "      <th>val_r2_keras_loss_epoch_334</th>\n",
       "      <th>val_r2_keras_loss_epoch_335</th>\n",
       "      <th>val_r2_keras_loss_epoch_336</th>\n",
       "      <th>val_r2_keras_loss_epoch_337</th>\n",
       "      <th>val_r2_keras_loss_epoch_338</th>\n",
       "      <th>val_r2_keras_loss_epoch_339</th>\n",
       "      <th>val_r2_keras_loss_epoch_340</th>\n",
       "      <th>val_r2_keras_loss_epoch_341</th>\n",
       "      <th>val_r2_keras_loss_epoch_342</th>\n",
       "      <th>val_r2_keras_loss_epoch_343</th>\n",
       "      <th>val_r2_keras_loss_epoch_344</th>\n",
       "      <th>val_r2_keras_loss_epoch_345</th>\n",
       "      <th>val_r2_keras_loss_epoch_346</th>\n",
       "      <th>val_r2_keras_loss_epoch_347</th>\n",
       "      <th>val_r2_keras_loss_epoch_348</th>\n",
       "      <th>val_r2_keras_loss_epoch_349</th>\n",
       "      <th>val_r2_keras_loss_epoch_350</th>\n",
       "      <th>val_r2_keras_loss_epoch_351</th>\n",
       "      <th>val_r2_keras_loss_epoch_352</th>\n",
       "      <th>val_r2_keras_loss_epoch_353</th>\n",
       "      <th>val_r2_keras_loss_epoch_354</th>\n",
       "      <th>val_r2_keras_loss_epoch_355</th>\n",
       "      <th>val_r2_keras_loss_epoch_356</th>\n",
       "      <th>val_r2_keras_loss_epoch_357</th>\n",
       "      <th>val_r2_keras_loss_epoch_358</th>\n",
       "      <th>val_r2_keras_loss_epoch_359</th>\n",
       "      <th>val_r2_keras_loss_epoch_360</th>\n",
       "      <th>val_r2_keras_loss_epoch_361</th>\n",
       "      <th>val_r2_keras_loss_epoch_362</th>\n",
       "      <th>val_r2_keras_loss_epoch_363</th>\n",
       "      <th>val_r2_keras_loss_epoch_364</th>\n",
       "      <th>val_r2_keras_loss_epoch_365</th>\n",
       "      <th>val_r2_keras_loss_epoch_366</th>\n",
       "      <th>val_r2_keras_loss_epoch_367</th>\n",
       "      <th>val_r2_keras_loss_epoch_368</th>\n",
       "      <th>val_r2_keras_loss_epoch_369</th>\n",
       "      <th>val_r2_keras_loss_epoch_370</th>\n",
       "      <th>val_r2_keras_loss_epoch_371</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>49999.000</td>\n",
       "      <td>49999.000</td>\n",
       "      <td>49997.000</td>\n",
       "      <td>49997.000</td>\n",
       "      <td>49996.000</td>\n",
       "      <td>49996.000</td>\n",
       "      <td>49995.000</td>\n",
       "      <td>49994.000</td>\n",
       "      <td>49992.000</td>\n",
       "      <td>49992.000</td>\n",
       "      <td>49989.000</td>\n",
       "      <td>49984.000</td>\n",
       "      <td>49982.000</td>\n",
       "      <td>49980.000</td>\n",
       "      <td>49974.000</td>\n",
       "      <td>49970.000</td>\n",
       "      <td>49965.000</td>\n",
       "      <td>49960.000</td>\n",
       "      <td>49957.000</td>\n",
       "      <td>49949.000</td>\n",
       "      <td>49945.000</td>\n",
       "      <td>49935.000</td>\n",
       "      <td>49923.000</td>\n",
       "      <td>49905.000</td>\n",
       "      <td>49890.000</td>\n",
       "      <td>49876.000</td>\n",
       "      <td>49856.000</td>\n",
       "      <td>49835.000</td>\n",
       "      <td>49810.000</td>\n",
       "      <td>49785.000</td>\n",
       "      <td>49762.000</td>\n",
       "      <td>49727.000</td>\n",
       "      <td>49689.000</td>\n",
       "      <td>49646.000</td>\n",
       "      <td>49613.000</td>\n",
       "      <td>49576.000</td>\n",
       "      <td>49535.000</td>\n",
       "      <td>49483.000</td>\n",
       "      <td>49428.000</td>\n",
       "      <td>49357.000</td>\n",
       "      <td>49282.000</td>\n",
       "      <td>49198.000</td>\n",
       "      <td>49107.000</td>\n",
       "      <td>49000.000</td>\n",
       "      <td>48880.000</td>\n",
       "      <td>48770.000</td>\n",
       "      <td>48637.000</td>\n",
       "      <td>48489.000</td>\n",
       "      <td>48358.000</td>\n",
       "      <td>48202.000</td>\n",
       "      <td>48024.000</td>\n",
       "      <td>47845.000</td>\n",
       "      <td>47646.000</td>\n",
       "      <td>47447.000</td>\n",
       "      <td>47224.000</td>\n",
       "      <td>46989.000</td>\n",
       "      <td>46764.000</td>\n",
       "      <td>46530.000</td>\n",
       "      <td>46244.000</td>\n",
       "      <td>45959.000</td>\n",
       "      <td>45683.000</td>\n",
       "      <td>45352.000</td>\n",
       "      <td>45032.000</td>\n",
       "      <td>44725.000</td>\n",
       "      <td>44416.000</td>\n",
       "      <td>44045.000</td>\n",
       "      <td>43666.000</td>\n",
       "      <td>43276.000</td>\n",
       "      <td>42871.000</td>\n",
       "      <td>42516.000</td>\n",
       "      <td>42120.000</td>\n",
       "      <td>41681.000</td>\n",
       "      <td>41237.000</td>\n",
       "      <td>40781.000</td>\n",
       "      <td>40315.000</td>\n",
       "      <td>39829.000</td>\n",
       "      <td>39368.000</td>\n",
       "      <td>38884.000</td>\n",
       "      <td>38358.000</td>\n",
       "      <td>37875.000</td>\n",
       "      <td>37348.000</td>\n",
       "      <td>36860.000</td>\n",
       "      <td>36343.000</td>\n",
       "      <td>35791.000</td>\n",
       "      <td>35260.000</td>\n",
       "      <td>34687.000</td>\n",
       "      <td>34157.000</td>\n",
       "      <td>33582.000</td>\n",
       "      <td>33063.000</td>\n",
       "      <td>32504.000</td>\n",
       "      <td>31957.000</td>\n",
       "      <td>31392.000</td>\n",
       "      <td>30845.000</td>\n",
       "      <td>30268.000</td>\n",
       "      <td>29729.000</td>\n",
       "      <td>29168.000</td>\n",
       "      <td>28631.000</td>\n",
       "      <td>27983.000</td>\n",
       "      <td>27429.000</td>\n",
       "      <td>26867.000</td>\n",
       "      <td>26363.000</td>\n",
       "      <td>25806.000</td>\n",
       "      <td>25243.000</td>\n",
       "      <td>24678.000</td>\n",
       "      <td>24168.000</td>\n",
       "      <td>23634.000</td>\n",
       "      <td>23071.000</td>\n",
       "      <td>22521.000</td>\n",
       "      <td>21987.000</td>\n",
       "      <td>21456.000</td>\n",
       "      <td>20973.000</td>\n",
       "      <td>20467.000</td>\n",
       "      <td>19984.000</td>\n",
       "      <td>19485.000</td>\n",
       "      <td>19010.000</td>\n",
       "      <td>18544.000</td>\n",
       "      <td>18054.000</td>\n",
       "      <td>17599.000</td>\n",
       "      <td>17138.000</td>\n",
       "      <td>16695.000</td>\n",
       "      <td>16231.000</td>\n",
       "      <td>15795.000</td>\n",
       "      <td>15394.000</td>\n",
       "      <td>14973.000</td>\n",
       "      <td>14563.000</td>\n",
       "      <td>14150.000</td>\n",
       "      <td>13751.000</td>\n",
       "      <td>13347.000</td>\n",
       "      <td>12961.000</td>\n",
       "      <td>12579.000</td>\n",
       "      <td>12195.000</td>\n",
       "      <td>11826.000</td>\n",
       "      <td>11507.000</td>\n",
       "      <td>11169.000</td>\n",
       "      <td>10845.000</td>\n",
       "      <td>10467.000</td>\n",
       "      <td>10136.000</td>\n",
       "      <td>9816.000</td>\n",
       "      <td>9524.000</td>\n",
       "      <td>9211.000</td>\n",
       "      <td>8910.000</td>\n",
       "      <td>8632.000</td>\n",
       "      <td>8389.000</td>\n",
       "      <td>8105.000</td>\n",
       "      <td>7861.000</td>\n",
       "      <td>7574.000</td>\n",
       "      <td>7322.000</td>\n",
       "      <td>7087.000</td>\n",
       "      <td>6849.000</td>\n",
       "      <td>6618.000</td>\n",
       "      <td>6415.000</td>\n",
       "      <td>6201.000</td>\n",
       "      <td>5968.000</td>\n",
       "      <td>5776.000</td>\n",
       "      <td>5573.000</td>\n",
       "      <td>5374.000</td>\n",
       "      <td>5191.000</td>\n",
       "      <td>5013.000</td>\n",
       "      <td>4861.000</td>\n",
       "      <td>4688.000</td>\n",
       "      <td>4506.000</td>\n",
       "      <td>4349.000</td>\n",
       "      <td>4214.000</td>\n",
       "      <td>4077.000</td>\n",
       "      <td>3932.000</td>\n",
       "      <td>3783.000</td>\n",
       "      <td>3642.000</td>\n",
       "      <td>3509.000</td>\n",
       "      <td>3363.000</td>\n",
       "      <td>3234.000</td>\n",
       "      <td>3116.000</td>\n",
       "      <td>3004.000</td>\n",
       "      <td>2885.000</td>\n",
       "      <td>2773.000</td>\n",
       "      <td>2690.000</td>\n",
       "      <td>2584.000</td>\n",
       "      <td>2484.000</td>\n",
       "      <td>2386.000</td>\n",
       "      <td>2291.000</td>\n",
       "      <td>2205.000</td>\n",
       "      <td>2119.000</td>\n",
       "      <td>2034.000</td>\n",
       "      <td>1967.000</td>\n",
       "      <td>1896.000</td>\n",
       "      <td>1824.000</td>\n",
       "      <td>1753.000</td>\n",
       "      <td>1688.000</td>\n",
       "      <td>1610.000</td>\n",
       "      <td>1544.000</td>\n",
       "      <td>1481.000</td>\n",
       "      <td>1429.000</td>\n",
       "      <td>1376.000</td>\n",
       "      <td>1310.000</td>\n",
       "      <td>1262.000</td>\n",
       "      <td>1214.000</td>\n",
       "      <td>1160.000</td>\n",
       "      <td>1114.000</td>\n",
       "      <td>1058.000</td>\n",
       "      <td>1019.000</td>\n",
       "      <td>986.000</td>\n",
       "      <td>953.000</td>\n",
       "      <td>921.000</td>\n",
       "      <td>886.000</td>\n",
       "      <td>855.000</td>\n",
       "      <td>822.000</td>\n",
       "      <td>787.000</td>\n",
       "      <td>745.000</td>\n",
       "      <td>715.000</td>\n",
       "      <td>682.000</td>\n",
       "      <td>646.000</td>\n",
       "      <td>618.000</td>\n",
       "      <td>599.000</td>\n",
       "      <td>567.000</td>\n",
       "      <td>538.000</td>\n",
       "      <td>519.000</td>\n",
       "      <td>497.000</td>\n",
       "      <td>479.000</td>\n",
       "      <td>462.000</td>\n",
       "      <td>438.000</td>\n",
       "      <td>417.000</td>\n",
       "      <td>396.000</td>\n",
       "      <td>379.000</td>\n",
       "      <td>364.000</td>\n",
       "      <td>341.000</td>\n",
       "      <td>327.000</td>\n",
       "      <td>315.000</td>\n",
       "      <td>296.000</td>\n",
       "      <td>284.000</td>\n",
       "      <td>270.000</td>\n",
       "      <td>257.000</td>\n",
       "      <td>240.000</td>\n",
       "      <td>232.000</td>\n",
       "      <td>222.000</td>\n",
       "      <td>211.000</td>\n",
       "      <td>202.000</td>\n",
       "      <td>192.000</td>\n",
       "      <td>186.000</td>\n",
       "      <td>175.000</td>\n",
       "      <td>168.000</td>\n",
       "      <td>156.000</td>\n",
       "      <td>151.000</td>\n",
       "      <td>146.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>133.000</td>\n",
       "      <td>123.000</td>\n",
       "      <td>119.000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>114.000</td>\n",
       "      <td>108.000</td>\n",
       "      <td>104.000</td>\n",
       "      <td>102.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>89.000</td>\n",
       "      <td>87.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>79.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>71.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24999.500</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>-0.819</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.929</td>\n",
       "      <td>-0.934</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.948</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14433.901</td>\n",
       "      <td>2.446</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12499.750</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>-0.869</td>\n",
       "      <td>-0.894</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24999.500</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.742</td>\n",
       "      <td>-0.811</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.944</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37499.250</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-0.643</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>-0.785</td>\n",
       "      <td>-0.814</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>-0.878</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>-0.914</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.932</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49999.000</td>\n",
       "      <td>432.881</td>\n",
       "      <td>89.901</td>\n",
       "      <td>68.551</td>\n",
       "      <td>51.245</td>\n",
       "      <td>36.820</td>\n",
       "      <td>24.552</td>\n",
       "      <td>14.200</td>\n",
       "      <td>6.032</td>\n",
       "      <td>1.074</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>-0.517</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-0.548</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>-0.541</td>\n",
       "      <td>-0.509</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.512</td>\n",
       "      <td>-0.549</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.633</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>-0.664</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.731</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>-0.718</td>\n",
       "      <td>-0.742</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>-0.806</td>\n",
       "      <td>-0.806</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-0.814</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>-0.829</td>\n",
       "      <td>-0.811</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>-0.805</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.844</td>\n",
       "      <td>-0.844</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>-0.851</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-0.855</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>-0.862</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>-0.864</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>-0.859</td>\n",
       "      <td>-0.869</td>\n",
       "      <td>-0.859</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>-0.878</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>-0.879</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>-0.881</td>\n",
       "      <td>-0.886</td>\n",
       "      <td>-0.842</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.889</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.880</td>\n",
       "      <td>-0.881</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.896</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>-0.922</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.922</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>-0.927</td>\n",
       "      <td>-0.927</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>-0.927</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.929</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.934</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.934</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.948</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  val_r2_keras_loss_epoch_1  val_r2_keras_loss_epoch_2  \\\n",
       "count 50000.000                  50000.000                  50000.000   \n",
       "mean  24999.500                      0.162                     -0.470   \n",
       "std   14433.901                      2.446                      0.639   \n",
       "min       0.000                     -0.937                     -0.976   \n",
       "25%   12499.750                     -0.388                     -0.700   \n",
       "50%   24999.500                     -0.099                     -0.562   \n",
       "75%   37499.250                      0.327                     -0.353   \n",
       "max   49999.000                    432.881                     89.901   \n",
       "\n",
       "       val_r2_keras_loss_epoch_3  val_r2_keras_loss_epoch_4  \\\n",
       "count                  50000.000                  50000.000   \n",
       "mean                      -0.690                     -0.775   \n",
       "std                        0.457                      0.335   \n",
       "min                       -0.987                     -0.993   \n",
       "25%                       -0.820                     -0.869   \n",
       "50%                       -0.742                     -0.811   \n",
       "75%                       -0.643                     -0.740   \n",
       "max                       68.551                     51.245   \n",
       "\n",
       "       val_r2_keras_loss_epoch_5  val_r2_keras_loss_epoch_6  \\\n",
       "count                  50000.000                  50000.000   \n",
       "mean                      -0.819                     -0.848   \n",
       "std                        0.240                      0.168   \n",
       "min                       -0.996                     -0.997   \n",
       "25%                       -0.894                     -0.909   \n",
       "50%                       -0.846                     -0.867   \n",
       "75%                       -0.785                     -0.814   \n",
       "max                       36.820                     24.552   \n",
       "\n",
       "       val_r2_keras_loss_epoch_7  val_r2_keras_loss_epoch_8  \\\n",
       "count                  50000.000                  50000.000   \n",
       "mean                      -0.868                     -0.883   \n",
       "std                        0.114                      0.079   \n",
       "min                       -0.998                     -0.998   \n",
       "25%                       -0.921                     -0.930   \n",
       "50%                       -0.883                     -0.895   \n",
       "75%                       -0.836                     -0.853   \n",
       "max                       14.200                      6.032   \n",
       "\n",
       "       val_r2_keras_loss_epoch_9  val_r2_keras_loss_epoch_10  \\\n",
       "count                  50000.000                   50000.000   \n",
       "mean                      -0.895                      -0.904   \n",
       "std                        0.062                       0.055   \n",
       "min                       -0.998                      -0.998   \n",
       "25%                       -0.937                      -0.942   \n",
       "50%                       -0.905                      -0.913   \n",
       "75%                       -0.867                      -0.878   \n",
       "max                        1.074                      -0.135   \n",
       "\n",
       "       val_r2_keras_loss_epoch_11  val_r2_keras_loss_epoch_12  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.912                      -0.919   \n",
       "std                         0.050                       0.047   \n",
       "min                        -0.999                      -0.999   \n",
       "25%                        -0.947                      -0.951   \n",
       "50%                        -0.920                      -0.926   \n",
       "75%                        -0.887                      -0.895   \n",
       "max                        -0.275                      -0.326   \n",
       "\n",
       "       val_r2_keras_loss_epoch_13  val_r2_keras_loss_epoch_14  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.924                      -0.929   \n",
       "std                         0.044                       0.041   \n",
       "min                        -0.999                      -0.999   \n",
       "25%                        -0.955                      -0.958   \n",
       "50%                        -0.931                      -0.936   \n",
       "75%                        -0.902                      -0.908   \n",
       "max                        -0.371                      -0.398   \n",
       "\n",
       "       val_r2_keras_loss_epoch_15  val_r2_keras_loss_epoch_16  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.934                      -0.938   \n",
       "std                         0.039                       0.037   \n",
       "min                        -0.999                      -0.999   \n",
       "25%                        -0.961                      -0.964   \n",
       "50%                        -0.940                      -0.944   \n",
       "75%                        -0.914                      -0.919   \n",
       "max                        -0.428                      -0.463   \n",
       "\n",
       "       val_r2_keras_loss_epoch_17  val_r2_keras_loss_epoch_18  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.941                      -0.945   \n",
       "std                         0.035                       0.033   \n",
       "min                        -0.999                      -0.999   \n",
       "25%                        -0.966                      -0.969   \n",
       "50%                        -0.947                      -0.951   \n",
       "75%                        -0.923                      -0.928   \n",
       "max                        -0.465                      -0.466   \n",
       "\n",
       "       val_r2_keras_loss_epoch_19  val_r2_keras_loss_epoch_20  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.948                      -0.951   \n",
       "std                         0.032                       0.030   \n",
       "min                        -0.999                      -0.999   \n",
       "25%                        -0.971                      -0.972   \n",
       "50%                        -0.954                      -0.956   \n",
       "75%                        -0.932                      -0.935   \n",
       "max                        -0.491                      -0.416   \n",
       "\n",
       "       val_r2_keras_loss_epoch_21  val_r2_keras_loss_epoch_22  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.953                      -0.956   \n",
       "std                         0.029                       0.028   \n",
       "min                        -0.999                      -1.000   \n",
       "25%                        -0.974                      -0.976   \n",
       "50%                        -0.959                      -0.961   \n",
       "75%                        -0.939                      -0.942   \n",
       "max                        -0.502                      -0.516   \n",
       "\n",
       "       val_r2_keras_loss_epoch_23  val_r2_keras_loss_epoch_24  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.958                      -0.960   \n",
       "std                         0.027                       0.026   \n",
       "min                        -0.999                      -1.000   \n",
       "25%                        -0.977                      -0.979   \n",
       "50%                        -0.963                      -0.965   \n",
       "75%                        -0.945                      -0.947   \n",
       "max                        -0.470                      -0.492   \n",
       "\n",
       "       val_r2_keras_loss_epoch_25  val_r2_keras_loss_epoch_26  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.962                      -0.964   \n",
       "std                         0.025                       0.024   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.980                      -0.981   \n",
       "50%                        -0.967                      -0.969   \n",
       "75%                        -0.950                      -0.952   \n",
       "max                        -0.487                      -0.515   \n",
       "\n",
       "       val_r2_keras_loss_epoch_27  val_r2_keras_loss_epoch_28  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.965                      -0.967   \n",
       "std                         0.024                       0.023   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.982                      -0.983   \n",
       "50%                        -0.971                      -0.972   \n",
       "75%                        -0.954                      -0.957   \n",
       "max                        -0.544                      -0.490   \n",
       "\n",
       "       val_r2_keras_loss_epoch_29  val_r2_keras_loss_epoch_30  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.968                      -0.970   \n",
       "std                         0.022                       0.021   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.984                      -0.985   \n",
       "50%                        -0.974                      -0.975   \n",
       "75%                        -0.959                      -0.960   \n",
       "max                        -0.450                      -0.453   \n",
       "\n",
       "       val_r2_keras_loss_epoch_31  val_r2_keras_loss_epoch_32  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.971                      -0.972   \n",
       "std                         0.021                       0.020   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.986                      -0.986   \n",
       "50%                        -0.976                      -0.977   \n",
       "75%                        -0.962                      -0.964   \n",
       "max                        -0.517                      -0.488   \n",
       "\n",
       "       val_r2_keras_loss_epoch_33  val_r2_keras_loss_epoch_34  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.973                      -0.974   \n",
       "std                         0.020                       0.019   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.987                      -0.987   \n",
       "50%                        -0.978                      -0.979   \n",
       "75%                        -0.965                      -0.967   \n",
       "max                        -0.400                      -0.555   \n",
       "\n",
       "       val_r2_keras_loss_epoch_35  val_r2_keras_loss_epoch_36  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.975                      -0.976   \n",
       "std                         0.018                       0.018   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.988                      -0.989   \n",
       "50%                        -0.980                      -0.981   \n",
       "75%                        -0.968                      -0.969   \n",
       "max                        -0.518                      -0.548   \n",
       "\n",
       "       val_r2_keras_loss_epoch_37  val_r2_keras_loss_epoch_38  \\\n",
       "count                   50000.000                   50000.000   \n",
       "mean                       -0.977                      -0.978   \n",
       "std                         0.017                       0.017   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.989                      -0.989   \n",
       "50%                        -0.982                      -0.982   \n",
       "75%                        -0.970                      -0.971   \n",
       "max                        -0.456                      -0.541   \n",
       "\n",
       "       val_r2_keras_loss_epoch_39  val_r2_keras_loss_epoch_40  \\\n",
       "count                   49999.000                   49999.000   \n",
       "mean                       -0.979                      -0.979   \n",
       "std                         0.016                       0.016   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.990                      -0.990   \n",
       "50%                        -0.983                      -0.984   \n",
       "75%                        -0.972                      -0.973   \n",
       "max                        -0.509                      -0.525   \n",
       "\n",
       "       val_r2_keras_loss_epoch_41  val_r2_keras_loss_epoch_42  \\\n",
       "count                   49997.000                   49997.000   \n",
       "mean                       -0.980                      -0.981   \n",
       "std                         0.016                       0.015   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.990                      -0.991   \n",
       "50%                        -0.984                      -0.985   \n",
       "75%                        -0.974                      -0.975   \n",
       "max                        -0.543                      -0.538   \n",
       "\n",
       "       val_r2_keras_loss_epoch_43  val_r2_keras_loss_epoch_44  \\\n",
       "count                   49996.000                   49996.000   \n",
       "mean                       -0.981                      -0.982   \n",
       "std                         0.015                       0.015   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.991                      -0.991   \n",
       "50%                        -0.985                      -0.986   \n",
       "75%                        -0.976                      -0.977   \n",
       "max                        -0.512                      -0.549   \n",
       "\n",
       "       val_r2_keras_loss_epoch_45  val_r2_keras_loss_epoch_46  \\\n",
       "count                   49995.000                   49994.000   \n",
       "mean                       -0.982                      -0.983   \n",
       "std                         0.014                       0.014   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.992                      -0.992   \n",
       "50%                        -0.986                      -0.986   \n",
       "75%                        -0.977                      -0.978   \n",
       "max                        -0.505                      -0.538   \n",
       "\n",
       "       val_r2_keras_loss_epoch_47  val_r2_keras_loss_epoch_48  \\\n",
       "count                   49992.000                   49992.000   \n",
       "mean                       -0.983                      -0.984   \n",
       "std                         0.014                       0.013   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.992                      -0.992   \n",
       "50%                        -0.987                      -0.987   \n",
       "75%                        -0.979                      -0.979   \n",
       "max                        -0.493                      -0.453   \n",
       "\n",
       "       val_r2_keras_loss_epoch_49  val_r2_keras_loss_epoch_50  \\\n",
       "count                   49989.000                   49984.000   \n",
       "mean                       -0.984                      -0.985   \n",
       "std                         0.013                       0.012   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.993                      -0.993   \n",
       "50%                        -0.987                      -0.988   \n",
       "75%                        -0.980                      -0.980   \n",
       "max                        -0.523                      -0.633   \n",
       "\n",
       "       val_r2_keras_loss_epoch_51  val_r2_keras_loss_epoch_52  \\\n",
       "count                   49982.000                   49980.000   \n",
       "mean                       -0.985                      -0.985   \n",
       "std                         0.012                       0.012   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.993                      -0.993   \n",
       "50%                        -0.988                      -0.988   \n",
       "75%                        -0.981                      -0.981   \n",
       "max                        -0.637                      -0.661   \n",
       "\n",
       "       val_r2_keras_loss_epoch_53  val_r2_keras_loss_epoch_54  \\\n",
       "count                   49974.000                   49970.000   \n",
       "mean                       -0.986                      -0.986   \n",
       "std                         0.012                       0.012   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.993                      -0.993   \n",
       "50%                        -0.989                      -0.989   \n",
       "75%                        -0.982                      -0.982   \n",
       "max                        -0.667                      -0.664   \n",
       "\n",
       "       val_r2_keras_loss_epoch_55  val_r2_keras_loss_epoch_56  \\\n",
       "count                   49965.000                   49960.000   \n",
       "mean                       -0.986                      -0.986   \n",
       "std                         0.011                       0.011   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.993                      -0.994   \n",
       "50%                        -0.989                      -0.989   \n",
       "75%                        -0.982                      -0.983   \n",
       "max                        -0.686                      -0.697   \n",
       "\n",
       "       val_r2_keras_loss_epoch_57  val_r2_keras_loss_epoch_58  \\\n",
       "count                   49957.000                   49949.000   \n",
       "mean                       -0.987                      -0.987   \n",
       "std                         0.011                       0.011   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.994                      -0.994   \n",
       "50%                        -0.990                      -0.990   \n",
       "75%                        -0.983                      -0.984   \n",
       "max                        -0.703                      -0.713   \n",
       "\n",
       "       val_r2_keras_loss_epoch_59  val_r2_keras_loss_epoch_60  \\\n",
       "count                   49945.000                   49935.000   \n",
       "mean                       -0.987                      -0.988   \n",
       "std                         0.010                       0.010   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.994                      -0.994   \n",
       "50%                        -0.990                      -0.990   \n",
       "75%                        -0.984                      -0.984   \n",
       "max                        -0.731                      -0.733   \n",
       "\n",
       "       val_r2_keras_loss_epoch_61  val_r2_keras_loss_epoch_62  \\\n",
       "count                   49923.000                   49905.000   \n",
       "mean                       -0.988                      -0.988   \n",
       "std                         0.010                       0.010   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.994                      -0.994   \n",
       "50%                        -0.990                      -0.991   \n",
       "75%                        -0.984                      -0.985   \n",
       "max                        -0.733                      -0.762   \n",
       "\n",
       "       val_r2_keras_loss_epoch_63  val_r2_keras_loss_epoch_64  \\\n",
       "count                   49890.000                   49876.000   \n",
       "mean                       -0.988                      -0.988   \n",
       "std                         0.010                       0.010   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.994                      -0.995   \n",
       "50%                        -0.991                      -0.991   \n",
       "75%                        -0.985                      -0.985   \n",
       "max                        -0.718                      -0.742   \n",
       "\n",
       "       val_r2_keras_loss_epoch_65  val_r2_keras_loss_epoch_66  \\\n",
       "count                   49856.000                   49835.000   \n",
       "mean                       -0.989                      -0.989   \n",
       "std                         0.009                       0.009   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.995                      -0.995   \n",
       "50%                        -0.991                      -0.991   \n",
       "75%                        -0.985                      -0.986   \n",
       "max                        -0.762                      -0.781   \n",
       "\n",
       "       val_r2_keras_loss_epoch_67  val_r2_keras_loss_epoch_68  \\\n",
       "count                   49810.000                   49785.000   \n",
       "mean                       -0.989                      -0.989   \n",
       "std                         0.009                       0.009   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.995                      -0.995   \n",
       "50%                        -0.991                      -0.991   \n",
       "75%                        -0.986                      -0.986   \n",
       "max                        -0.782                      -0.774   \n",
       "\n",
       "       val_r2_keras_loss_epoch_69  val_r2_keras_loss_epoch_70  \\\n",
       "count                   49762.000                   49727.000   \n",
       "mean                       -0.989                      -0.989   \n",
       "std                         0.009                       0.009   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.995                      -0.995   \n",
       "50%                        -0.992                      -0.992   \n",
       "75%                        -0.986                      -0.987   \n",
       "max                        -0.801                      -0.806   \n",
       "\n",
       "       val_r2_keras_loss_epoch_71  val_r2_keras_loss_epoch_72  \\\n",
       "count                   49689.000                   49646.000   \n",
       "mean                       -0.990                      -0.990   \n",
       "std                         0.009                       0.008   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.995                      -0.995   \n",
       "50%                        -0.992                      -0.992   \n",
       "75%                        -0.987                      -0.987   \n",
       "max                        -0.806                      -0.798   \n",
       "\n",
       "       val_r2_keras_loss_epoch_73  val_r2_keras_loss_epoch_74  \\\n",
       "count                   49613.000                   49576.000   \n",
       "mean                       -0.990                      -0.990   \n",
       "std                         0.008                       0.008   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.995                      -0.995   \n",
       "50%                        -0.992                      -0.992   \n",
       "75%                        -0.987                      -0.987   \n",
       "max                        -0.814                      -0.771   \n",
       "\n",
       "       val_r2_keras_loss_epoch_75  val_r2_keras_loss_epoch_76  \\\n",
       "count                   49535.000                   49483.000   \n",
       "mean                       -0.990                      -0.990   \n",
       "std                         0.008                       0.008   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.995                      -0.995   \n",
       "50%                        -0.992                      -0.992   \n",
       "75%                        -0.987                      -0.988   \n",
       "max                        -0.829                      -0.811   \n",
       "\n",
       "       val_r2_keras_loss_epoch_77  val_r2_keras_loss_epoch_78  \\\n",
       "count                   49428.000                   49357.000   \n",
       "mean                       -0.990                      -0.990   \n",
       "std                         0.008                       0.008   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.995                      -0.995   \n",
       "50%                        -0.992                      -0.993   \n",
       "75%                        -0.988                      -0.988   \n",
       "max                        -0.817                      -0.824   \n",
       "\n",
       "       val_r2_keras_loss_epoch_79  val_r2_keras_loss_epoch_80  \\\n",
       "count                   49282.000                   49198.000   \n",
       "mean                       -0.991                      -0.991   \n",
       "std                         0.008                       0.008   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.993                      -0.993   \n",
       "75%                        -0.988                      -0.988   \n",
       "max                        -0.805                      -0.830   \n",
       "\n",
       "       val_r2_keras_loss_epoch_81  val_r2_keras_loss_epoch_82  \\\n",
       "count                   49107.000                   49000.000   \n",
       "mean                       -0.991                      -0.991   \n",
       "std                         0.008                       0.007   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.993                      -0.993   \n",
       "75%                        -0.988                      -0.988   \n",
       "max                        -0.839                      -0.836   \n",
       "\n",
       "       val_r2_keras_loss_epoch_83  val_r2_keras_loss_epoch_84  \\\n",
       "count                   48880.000                   48770.000   \n",
       "mean                       -0.991                      -0.991   \n",
       "std                         0.007                       0.007   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.993                      -0.993   \n",
       "75%                        -0.989                      -0.989   \n",
       "max                        -0.837                      -0.838   \n",
       "\n",
       "       val_r2_keras_loss_epoch_85  val_r2_keras_loss_epoch_86  \\\n",
       "count                   48637.000                   48489.000   \n",
       "mean                       -0.991                      -0.991   \n",
       "std                         0.007                       0.007   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.993                      -0.993   \n",
       "75%                        -0.989                      -0.989   \n",
       "max                        -0.838                      -0.835   \n",
       "\n",
       "       val_r2_keras_loss_epoch_87  val_r2_keras_loss_epoch_88  \\\n",
       "count                   48358.000                   48202.000   \n",
       "mean                       -0.991                      -0.991   \n",
       "std                         0.007                       0.007   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.993                      -0.993   \n",
       "75%                        -0.989                      -0.989   \n",
       "max                        -0.843                      -0.844   \n",
       "\n",
       "       val_r2_keras_loss_epoch_89  val_r2_keras_loss_epoch_90  \\\n",
       "count                   48024.000                   47845.000   \n",
       "mean                       -0.992                      -0.992   \n",
       "std                         0.007                       0.007   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.993                      -0.993   \n",
       "75%                        -0.989                      -0.989   \n",
       "max                        -0.844                      -0.845   \n",
       "\n",
       "       val_r2_keras_loss_epoch_91  val_r2_keras_loss_epoch_92  \\\n",
       "count                   47646.000                   47447.000   \n",
       "mean                       -0.992                      -0.992   \n",
       "std                         0.007                       0.007   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.993                      -0.994   \n",
       "75%                        -0.989                      -0.990   \n",
       "max                        -0.847                      -0.851   \n",
       "\n",
       "       val_r2_keras_loss_epoch_93  val_r2_keras_loss_epoch_94  \\\n",
       "count                   47224.000                   46989.000   \n",
       "mean                       -0.992                      -0.992   \n",
       "std                         0.007                       0.007   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.994                      -0.994   \n",
       "75%                        -0.990                      -0.990   \n",
       "max                        -0.850                      -0.849   \n",
       "\n",
       "       val_r2_keras_loss_epoch_95  val_r2_keras_loss_epoch_96  \\\n",
       "count                   46764.000                   46530.000   \n",
       "mean                       -0.992                      -0.992   \n",
       "std                         0.006                       0.006   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.994                      -0.994   \n",
       "75%                        -0.990                      -0.990   \n",
       "max                        -0.848                      -0.856   \n",
       "\n",
       "       val_r2_keras_loss_epoch_97  val_r2_keras_loss_epoch_98  \\\n",
       "count                   46244.000                   45959.000   \n",
       "mean                       -0.992                      -0.992   \n",
       "std                         0.006                       0.006   \n",
       "min                        -1.000                      -1.000   \n",
       "25%                        -0.996                      -0.996   \n",
       "50%                        -0.994                      -0.994   \n",
       "75%                        -0.990                      -0.990   \n",
       "max                        -0.845                      -0.858   \n",
       "\n",
       "       val_r2_keras_loss_epoch_99  val_r2_keras_loss_epoch_100  \\\n",
       "count                   45683.000                    45352.000   \n",
       "mean                       -0.992                       -0.992   \n",
       "std                         0.006                        0.006   \n",
       "min                        -1.000                       -1.000   \n",
       "25%                        -0.996                       -0.996   \n",
       "50%                        -0.994                       -0.994   \n",
       "75%                        -0.990                       -0.990   \n",
       "max                        -0.855                       -0.846   \n",
       "\n",
       "       val_r2_keras_loss_epoch_101  val_r2_keras_loss_epoch_102  \\\n",
       "count                    45032.000                    44725.000   \n",
       "mean                        -0.992                       -0.992   \n",
       "std                          0.006                        0.006   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.996                       -0.996   \n",
       "50%                         -0.994                       -0.994   \n",
       "75%                         -0.990                       -0.990   \n",
       "max                         -0.862                       -0.863   \n",
       "\n",
       "       val_r2_keras_loss_epoch_103  val_r2_keras_loss_epoch_104  \\\n",
       "count                    44416.000                    44045.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.006                        0.006   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.996                       -0.996   \n",
       "50%                         -0.994                       -0.994   \n",
       "75%                         -0.990                       -0.990   \n",
       "max                         -0.864                       -0.868   \n",
       "\n",
       "       val_r2_keras_loss_epoch_105  val_r2_keras_loss_epoch_106  \\\n",
       "count                    43666.000                    43276.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.006                        0.006   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.994                       -0.994   \n",
       "75%                         -0.991                       -0.991   \n",
       "max                         -0.859                       -0.869   \n",
       "\n",
       "       val_r2_keras_loss_epoch_107  val_r2_keras_loss_epoch_108  \\\n",
       "count                    42871.000                    42516.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.006                        0.006   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.994                       -0.994   \n",
       "75%                         -0.991                       -0.991   \n",
       "max                         -0.859                       -0.875   \n",
       "\n",
       "       val_r2_keras_loss_epoch_109  val_r2_keras_loss_epoch_110  \\\n",
       "count                    42120.000                    41681.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.006                        0.006   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.994                       -0.994   \n",
       "75%                         -0.991                       -0.991   \n",
       "max                         -0.871                       -0.861   \n",
       "\n",
       "       val_r2_keras_loss_epoch_111  val_r2_keras_loss_epoch_112  \\\n",
       "count                    41237.000                    40781.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.006                        0.006   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.994                       -0.994   \n",
       "75%                         -0.991                       -0.991   \n",
       "max                         -0.871                       -0.878   \n",
       "\n",
       "       val_r2_keras_loss_epoch_113  val_r2_keras_loss_epoch_114  \\\n",
       "count                    40315.000                    39829.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.006                        0.006   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.991                       -0.991   \n",
       "max                         -0.885                       -0.884   \n",
       "\n",
       "       val_r2_keras_loss_epoch_115  val_r2_keras_loss_epoch_116  \\\n",
       "count                    39368.000                    38884.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.006                        0.006   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.991                       -0.991   \n",
       "max                         -0.879                       -0.875   \n",
       "\n",
       "       val_r2_keras_loss_epoch_117  val_r2_keras_loss_epoch_118  \\\n",
       "count                    38358.000                    37875.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.991                       -0.991   \n",
       "max                         -0.881                       -0.886   \n",
       "\n",
       "       val_r2_keras_loss_epoch_119  val_r2_keras_loss_epoch_120  \\\n",
       "count                    37348.000                    36860.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.991                       -0.991   \n",
       "max                         -0.842                       -0.887   \n",
       "\n",
       "       val_r2_keras_loss_epoch_121  val_r2_keras_loss_epoch_122  \\\n",
       "count                    36343.000                    35791.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.991                       -0.992   \n",
       "max                         -0.889                       -0.837   \n",
       "\n",
       "       val_r2_keras_loss_epoch_123  val_r2_keras_loss_epoch_124  \\\n",
       "count                    35260.000                    34687.000   \n",
       "mean                        -0.993                       -0.993   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.892                       -0.885   \n",
       "\n",
       "       val_r2_keras_loss_epoch_125  val_r2_keras_loss_epoch_126  \\\n",
       "count                    34157.000                    33582.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.893                       -0.874   \n",
       "\n",
       "       val_r2_keras_loss_epoch_127  val_r2_keras_loss_epoch_128  \\\n",
       "count                    33063.000                    32504.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.893                       -0.888   \n",
       "\n",
       "       val_r2_keras_loss_epoch_129  val_r2_keras_loss_epoch_130  \\\n",
       "count                    31957.000                    31392.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.897                       -0.893   \n",
       "\n",
       "       val_r2_keras_loss_epoch_131  val_r2_keras_loss_epoch_132  \\\n",
       "count                    30845.000                    30268.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.885                       -0.880   \n",
       "\n",
       "       val_r2_keras_loss_epoch_133  val_r2_keras_loss_epoch_134  \\\n",
       "count                    29729.000                    29168.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.881                       -0.895   \n",
       "\n",
       "       val_r2_keras_loss_epoch_135  val_r2_keras_loss_epoch_136  \\\n",
       "count                    28631.000                    27983.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.895                       -0.893   \n",
       "\n",
       "       val_r2_keras_loss_epoch_137  val_r2_keras_loss_epoch_138  \\\n",
       "count                    27429.000                    26867.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.893                       -0.896   \n",
       "\n",
       "       val_r2_keras_loss_epoch_139  val_r2_keras_loss_epoch_140  \\\n",
       "count                    26363.000                    25806.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.883                       -0.899   \n",
       "\n",
       "       val_r2_keras_loss_epoch_141  val_r2_keras_loss_epoch_142  \\\n",
       "count                    25243.000                    24678.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.897                       -0.868   \n",
       "\n",
       "       val_r2_keras_loss_epoch_143  val_r2_keras_loss_epoch_144  \\\n",
       "count                    24168.000                    23634.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.992                       -0.992   \n",
       "max                         -0.899                       -0.898   \n",
       "\n",
       "       val_r2_keras_loss_epoch_145  val_r2_keras_loss_epoch_146  \\\n",
       "count                    23071.000                    22521.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.885                       -0.874   \n",
       "\n",
       "       val_r2_keras_loss_epoch_147  val_r2_keras_loss_epoch_148  \\\n",
       "count                    21987.000                    21456.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.887                       -0.917   \n",
       "\n",
       "       val_r2_keras_loss_epoch_149  val_r2_keras_loss_epoch_150  \\\n",
       "count                    20973.000                    20467.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.005                        0.005   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.995   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.915                       -0.913   \n",
       "\n",
       "       val_r2_keras_loss_epoch_151  val_r2_keras_loss_epoch_152  \\\n",
       "count                    19984.000                    19485.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.995                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.918                       -0.919   \n",
       "\n",
       "       val_r2_keras_loss_epoch_153  val_r2_keras_loss_epoch_154  \\\n",
       "count                    19010.000                    18544.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.919                       -0.915   \n",
       "\n",
       "       val_r2_keras_loss_epoch_155  val_r2_keras_loss_epoch_156  \\\n",
       "count                    18054.000                    17599.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.921                       -0.920   \n",
       "\n",
       "       val_r2_keras_loss_epoch_157  val_r2_keras_loss_epoch_158  \\\n",
       "count                    17138.000                    16695.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.922                       -0.923   \n",
       "\n",
       "       val_r2_keras_loss_epoch_159  val_r2_keras_loss_epoch_160  \\\n",
       "count                    16231.000                    15795.000   \n",
       "mean                        -0.994                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.924                       -0.922   \n",
       "\n",
       "       val_r2_keras_loss_epoch_161  val_r2_keras_loss_epoch_162  \\\n",
       "count                    15394.000                    14973.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.924                       -0.920   \n",
       "\n",
       "       val_r2_keras_loss_epoch_163  val_r2_keras_loss_epoch_164  \\\n",
       "count                    14563.000                    14150.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.926                       -0.925   \n",
       "\n",
       "       val_r2_keras_loss_epoch_165  val_r2_keras_loss_epoch_166  \\\n",
       "count                    13751.000                    13347.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.927                       -0.927   \n",
       "\n",
       "       val_r2_keras_loss_epoch_167  val_r2_keras_loss_epoch_168  \\\n",
       "count                    12961.000                    12579.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.926                       -0.918   \n",
       "\n",
       "       val_r2_keras_loss_epoch_169  val_r2_keras_loss_epoch_170  \\\n",
       "count                    12195.000                    11826.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.927                       -0.930   \n",
       "\n",
       "       val_r2_keras_loss_epoch_171  val_r2_keras_loss_epoch_172  \\\n",
       "count                    11507.000                    11169.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.931                       -0.924   \n",
       "\n",
       "       val_r2_keras_loss_epoch_173  val_r2_keras_loss_epoch_174  \\\n",
       "count                    10845.000                    10467.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.933                       -0.924   \n",
       "\n",
       "       val_r2_keras_loss_epoch_175  val_r2_keras_loss_epoch_176  \\\n",
       "count                    10136.000                     9816.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.933                       -0.931   \n",
       "\n",
       "       val_r2_keras_loss_epoch_177  val_r2_keras_loss_epoch_178  \\\n",
       "count                     9524.000                     9211.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.993   \n",
       "max                         -0.929                       -0.931   \n",
       "\n",
       "       val_r2_keras_loss_epoch_179  val_r2_keras_loss_epoch_180  \\\n",
       "count                     8910.000                     8632.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.997                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.993                       -0.994   \n",
       "max                         -0.934                       -0.935   \n",
       "\n",
       "       val_r2_keras_loss_epoch_181  val_r2_keras_loss_epoch_182  \\\n",
       "count                     8389.000                     8105.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.938                       -0.935   \n",
       "\n",
       "       val_r2_keras_loss_epoch_183  val_r2_keras_loss_epoch_184  \\\n",
       "count                     7861.000                     7574.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.938                       -0.939   \n",
       "\n",
       "       val_r2_keras_loss_epoch_185  val_r2_keras_loss_epoch_186  \\\n",
       "count                     7322.000                     7087.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.937                       -0.937   \n",
       "\n",
       "       val_r2_keras_loss_epoch_187  val_r2_keras_loss_epoch_188  \\\n",
       "count                     6849.000                     6618.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.934                       -0.940   \n",
       "\n",
       "       val_r2_keras_loss_epoch_189  val_r2_keras_loss_epoch_190  \\\n",
       "count                     6415.000                     6201.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.941                       -0.943   \n",
       "\n",
       "       val_r2_keras_loss_epoch_191  val_r2_keras_loss_epoch_192  \\\n",
       "count                     5968.000                     5776.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.941                       -0.945   \n",
       "\n",
       "       val_r2_keras_loss_epoch_193  val_r2_keras_loss_epoch_194  \\\n",
       "count                     5573.000                     5374.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.943                       -0.946   \n",
       "\n",
       "       val_r2_keras_loss_epoch_195  val_r2_keras_loss_epoch_196  \\\n",
       "count                     5191.000                     5013.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.945                       -0.945   \n",
       "\n",
       "       val_r2_keras_loss_epoch_197  val_r2_keras_loss_epoch_198  \\\n",
       "count                     4861.000                     4688.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.937                       -0.948   \n",
       "\n",
       "       val_r2_keras_loss_epoch_199  val_r2_keras_loss_epoch_200  \\\n",
       "count                     4506.000                     4349.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.949                       -0.943   \n",
       "\n",
       "       val_r2_keras_loss_epoch_201  val_r2_keras_loss_epoch_202  \\\n",
       "count                     4214.000                     4077.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.950                       -0.946   \n",
       "\n",
       "       val_r2_keras_loss_epoch_203  val_r2_keras_loss_epoch_204  \\\n",
       "count                     3932.000                     3783.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.950                       -0.951   \n",
       "\n",
       "       val_r2_keras_loss_epoch_205  val_r2_keras_loss_epoch_206  \\\n",
       "count                     3642.000                     3509.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.949                       -0.951   \n",
       "\n",
       "       val_r2_keras_loss_epoch_207  val_r2_keras_loss_epoch_208  \\\n",
       "count                     3363.000                     3234.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.952                       -0.953   \n",
       "\n",
       "       val_r2_keras_loss_epoch_209  val_r2_keras_loss_epoch_210  \\\n",
       "count                     3116.000                     3004.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.941                       -0.954   \n",
       "\n",
       "       val_r2_keras_loss_epoch_211  val_r2_keras_loss_epoch_212  \\\n",
       "count                     2885.000                     2773.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.940                       -0.951   \n",
       "\n",
       "       val_r2_keras_loss_epoch_213  val_r2_keras_loss_epoch_214  \\\n",
       "count                     2690.000                     2584.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.956                       -0.955   \n",
       "\n",
       "       val_r2_keras_loss_epoch_215  val_r2_keras_loss_epoch_216  \\\n",
       "count                     2484.000                     2386.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.952                       -0.955   \n",
       "\n",
       "       val_r2_keras_loss_epoch_217  val_r2_keras_loss_epoch_218  \\\n",
       "count                     2291.000                     2205.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.955                       -0.956   \n",
       "\n",
       "       val_r2_keras_loss_epoch_219  val_r2_keras_loss_epoch_220  \\\n",
       "count                     2119.000                     2034.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.952                       -0.958   \n",
       "\n",
       "       val_r2_keras_loss_epoch_221  val_r2_keras_loss_epoch_222  \\\n",
       "count                     1967.000                     1896.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.958                       -0.959   \n",
       "\n",
       "       val_r2_keras_loss_epoch_223  val_r2_keras_loss_epoch_224  \\\n",
       "count                     1824.000                     1753.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.959                       -0.959   \n",
       "\n",
       "       val_r2_keras_loss_epoch_225  val_r2_keras_loss_epoch_226  \\\n",
       "count                     1688.000                     1610.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.958                       -0.955   \n",
       "\n",
       "       val_r2_keras_loss_epoch_227  val_r2_keras_loss_epoch_228  \\\n",
       "count                     1544.000                     1481.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.959                       -0.955   \n",
       "\n",
       "       val_r2_keras_loss_epoch_229  val_r2_keras_loss_epoch_230  \\\n",
       "count                     1429.000                     1376.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.959                       -0.960   \n",
       "\n",
       "       val_r2_keras_loss_epoch_231  val_r2_keras_loss_epoch_232  \\\n",
       "count                     1310.000                     1262.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.960                       -0.958   \n",
       "\n",
       "       val_r2_keras_loss_epoch_233  val_r2_keras_loss_epoch_234  \\\n",
       "count                     1214.000                     1160.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.960                       -0.961   \n",
       "\n",
       "       val_r2_keras_loss_epoch_235  val_r2_keras_loss_epoch_236  \\\n",
       "count                     1114.000                     1058.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.961                       -0.958   \n",
       "\n",
       "       val_r2_keras_loss_epoch_237  val_r2_keras_loss_epoch_238  \\\n",
       "count                     1019.000                      986.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.960                       -0.961   \n",
       "\n",
       "       val_r2_keras_loss_epoch_239  val_r2_keras_loss_epoch_240  \\\n",
       "count                      953.000                      921.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.961                       -0.962   \n",
       "\n",
       "       val_r2_keras_loss_epoch_241  val_r2_keras_loss_epoch_242  \\\n",
       "count                      886.000                      855.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.962                       -0.962   \n",
       "\n",
       "       val_r2_keras_loss_epoch_243  val_r2_keras_loss_epoch_244  \\\n",
       "count                      822.000                      787.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.961                       -0.963   \n",
       "\n",
       "       val_r2_keras_loss_epoch_245  val_r2_keras_loss_epoch_246  \\\n",
       "count                      745.000                      715.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -1.000                       -1.000   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.962                       -0.960   \n",
       "\n",
       "       val_r2_keras_loss_epoch_247  val_r2_keras_loss_epoch_248  \\\n",
       "count                      682.000                      646.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.963                       -0.964   \n",
       "\n",
       "       val_r2_keras_loss_epoch_249  val_r2_keras_loss_epoch_250  \\\n",
       "count                      618.000                      599.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.964                       -0.964   \n",
       "\n",
       "       val_r2_keras_loss_epoch_251  val_r2_keras_loss_epoch_252  \\\n",
       "count                      567.000                      538.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.963                       -0.963   \n",
       "\n",
       "       val_r2_keras_loss_epoch_253  val_r2_keras_loss_epoch_254  \\\n",
       "count                      519.000                      497.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.963                       -0.964   \n",
       "\n",
       "       val_r2_keras_loss_epoch_255  val_r2_keras_loss_epoch_256  \\\n",
       "count                      479.000                      462.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.964                       -0.965   \n",
       "\n",
       "       val_r2_keras_loss_epoch_257  val_r2_keras_loss_epoch_258  \\\n",
       "count                      438.000                      417.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.963                       -0.966   \n",
       "\n",
       "       val_r2_keras_loss_epoch_259  val_r2_keras_loss_epoch_260  \\\n",
       "count                      396.000                      379.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.966                       -0.964   \n",
       "\n",
       "       val_r2_keras_loss_epoch_261  val_r2_keras_loss_epoch_262  \\\n",
       "count                      364.000                      341.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.966                       -0.967   \n",
       "\n",
       "       val_r2_keras_loss_epoch_263  val_r2_keras_loss_epoch_264  \\\n",
       "count                      327.000                      315.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.995   \n",
       "max                         -0.967                       -0.963   \n",
       "\n",
       "       val_r2_keras_loss_epoch_265  val_r2_keras_loss_epoch_266  \\\n",
       "count                      296.000                      284.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.966                       -0.967   \n",
       "\n",
       "       val_r2_keras_loss_epoch_267  val_r2_keras_loss_epoch_268  \\\n",
       "count                      270.000                      257.000   \n",
       "mean                        -0.995                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.967                       -0.967   \n",
       "\n",
       "       val_r2_keras_loss_epoch_269  val_r2_keras_loss_epoch_270  \\\n",
       "count                      240.000                      232.000   \n",
       "mean                        -0.996                       -0.995   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.967                       -0.966   \n",
       "\n",
       "       val_r2_keras_loss_epoch_271  val_r2_keras_loss_epoch_272  \\\n",
       "count                      222.000                      211.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.995   \n",
       "max                         -0.966                       -0.965   \n",
       "\n",
       "       val_r2_keras_loss_epoch_273  val_r2_keras_loss_epoch_274  \\\n",
       "count                      202.000                      192.000   \n",
       "mean                        -0.995                       -0.996   \n",
       "std                          0.003                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.967                       -0.967   \n",
       "\n",
       "       val_r2_keras_loss_epoch_275  val_r2_keras_loss_epoch_276  \\\n",
       "count                      186.000                      175.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.004                        0.003   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.995                       -0.995   \n",
       "max                         -0.965                       -0.968   \n",
       "\n",
       "       val_r2_keras_loss_epoch_277  val_r2_keras_loss_epoch_278  \\\n",
       "count                      168.000                      156.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.995                       -0.995   \n",
       "max                         -0.968                       -0.968   \n",
       "\n",
       "       val_r2_keras_loss_epoch_279  val_r2_keras_loss_epoch_280  \\\n",
       "count                      151.000                      146.000   \n",
       "mean                        -0.996                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.995                       -0.994   \n",
       "max                         -0.967                       -0.966   \n",
       "\n",
       "       val_r2_keras_loss_epoch_281  val_r2_keras_loss_epoch_282  \\\n",
       "count                      139.000                      133.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.995   \n",
       "max                         -0.968                       -0.969   \n",
       "\n",
       "       val_r2_keras_loss_epoch_283  val_r2_keras_loss_epoch_284  \\\n",
       "count                      123.000                      119.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.968                       -0.968   \n",
       "\n",
       "       val_r2_keras_loss_epoch_285  val_r2_keras_loss_epoch_286  \\\n",
       "count                      118.000                      114.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.995                       -0.994   \n",
       "max                         -0.964                       -0.968   \n",
       "\n",
       "       val_r2_keras_loss_epoch_287  val_r2_keras_loss_epoch_288  \\\n",
       "count                      108.000                      104.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.968                       -0.968   \n",
       "\n",
       "       val_r2_keras_loss_epoch_289  val_r2_keras_loss_epoch_290  \\\n",
       "count                      102.000                       99.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.970                       -0.970   \n",
       "\n",
       "       val_r2_keras_loss_epoch_291  val_r2_keras_loss_epoch_292  \\\n",
       "count                       94.000                       92.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.969                       -0.969   \n",
       "\n",
       "       val_r2_keras_loss_epoch_293  val_r2_keras_loss_epoch_294  \\\n",
       "count                       89.000                       87.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.998   \n",
       "50%                         -0.996                       -0.997   \n",
       "75%                         -0.995                       -0.994   \n",
       "max                         -0.967                       -0.970   \n",
       "\n",
       "       val_r2_keras_loss_epoch_295  val_r2_keras_loss_epoch_296  \\\n",
       "count                       85.000                       83.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.994                       -0.995   \n",
       "max                         -0.970                       -0.970   \n",
       "\n",
       "       val_r2_keras_loss_epoch_297  val_r2_keras_loss_epoch_298  \\\n",
       "count                       79.000                       77.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.997   \n",
       "50%                         -0.997                       -0.996   \n",
       "75%                         -0.995                       -0.995   \n",
       "max                         -0.969                       -0.969   \n",
       "\n",
       "       val_r2_keras_loss_epoch_299  val_r2_keras_loss_epoch_300  \\\n",
       "count                       75.000                       73.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.969                       -0.970   \n",
       "\n",
       "       val_r2_keras_loss_epoch_301  val_r2_keras_loss_epoch_302  \\\n",
       "count                       72.000                       71.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.995                       -0.994   \n",
       "max                         -0.966                       -0.971   \n",
       "\n",
       "       val_r2_keras_loss_epoch_303  val_r2_keras_loss_epoch_304  \\\n",
       "count                       67.000                       64.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.995                       -0.995   \n",
       "max                         -0.970                       -0.967   \n",
       "\n",
       "       val_r2_keras_loss_epoch_305  val_r2_keras_loss_epoch_306  \\\n",
       "count                       62.000                       59.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.005   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.997                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.995   \n",
       "max                         -0.971                       -0.966   \n",
       "\n",
       "       val_r2_keras_loss_epoch_307  val_r2_keras_loss_epoch_308  \\\n",
       "count                       56.000                       53.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.995                       -0.995   \n",
       "max                         -0.968                       -0.970   \n",
       "\n",
       "       val_r2_keras_loss_epoch_309  val_r2_keras_loss_epoch_310  \\\n",
       "count                       53.000                       50.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.005   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.971                       -0.969   \n",
       "\n",
       "       val_r2_keras_loss_epoch_311  val_r2_keras_loss_epoch_312  \\\n",
       "count                       49.000                       47.000   \n",
       "mean                        -0.995                       -0.995   \n",
       "std                          0.004                        0.004   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.971                       -0.971   \n",
       "\n",
       "       val_r2_keras_loss_epoch_313  val_r2_keras_loss_epoch_314  \\\n",
       "count                       46.000                       39.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.003                        0.002   \n",
       "min                         -0.999                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.994                       -0.995   \n",
       "max                         -0.986                       -0.991   \n",
       "\n",
       "       val_r2_keras_loss_epoch_315  val_r2_keras_loss_epoch_316  \\\n",
       "count                       37.000                       35.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.999                       -0.998   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.995                       -0.995   \n",
       "max                         -0.991                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_317  val_r2_keras_loss_epoch_318  \\\n",
       "count                       35.000                       35.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.996                       -0.996   \n",
       "75%                         -0.995                       -0.994   \n",
       "max                         -0.992                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_319  val_r2_keras_loss_epoch_320  \\\n",
       "count                       33.000                       32.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.995                       -0.995   \n",
       "max                         -0.992                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_321  val_r2_keras_loss_epoch_322  \\\n",
       "count                       29.000                       27.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.996                       -0.995   \n",
       "max                         -0.992                       -0.991   \n",
       "\n",
       "       val_r2_keras_loss_epoch_323  val_r2_keras_loss_epoch_324  \\\n",
       "count                       25.000                       22.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.996                       -0.996   \n",
       "max                         -0.992                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_325  val_r2_keras_loss_epoch_326  \\\n",
       "count                       20.000                       19.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.995                       -0.995   \n",
       "max                         -0.991                       -0.991   \n",
       "\n",
       "       val_r2_keras_loss_epoch_327  val_r2_keras_loss_epoch_328  \\\n",
       "count                       19.000                       18.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.997                       -0.997   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.995                       -0.996   \n",
       "max                         -0.992                       -0.990   \n",
       "\n",
       "       val_r2_keras_loss_epoch_329  val_r2_keras_loss_epoch_330  \\\n",
       "count                       17.000                       16.000   \n",
       "mean                        -0.997                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.997                       -0.998   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.996                       -0.996   \n",
       "max                         -0.992                       -0.991   \n",
       "\n",
       "       val_r2_keras_loss_epoch_331  val_r2_keras_loss_epoch_332  \\\n",
       "count                       16.000                       15.000   \n",
       "mean                        -0.997                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.997                       -0.998   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.996                       -0.996   \n",
       "max                         -0.992                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_333  val_r2_keras_loss_epoch_334  \\\n",
       "count                       15.000                       15.000   \n",
       "mean                        -0.997                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.996                       -0.995   \n",
       "max                         -0.992                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_335  val_r2_keras_loss_epoch_336  \\\n",
       "count                       14.000                       14.000   \n",
       "mean                        -0.997                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.996                       -0.996   \n",
       "max                         -0.992                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_337  val_r2_keras_loss_epoch_338  \\\n",
       "count                       13.000                       11.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.998                       -0.997   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.995                       -0.996   \n",
       "max                         -0.991                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_339  val_r2_keras_loss_epoch_340  \\\n",
       "count                       11.000                       11.000   \n",
       "mean                        -0.996                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.996                       -0.996   \n",
       "max                         -0.992                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_341  val_r2_keras_loss_epoch_342  \\\n",
       "count                       10.000                       10.000   \n",
       "mean                        -0.996                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.997                       -0.997   \n",
       "max                         -0.991                       -0.993   \n",
       "\n",
       "       val_r2_keras_loss_epoch_343  val_r2_keras_loss_epoch_344  \\\n",
       "count                       10.000                       10.000   \n",
       "mean                        -0.997                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.998                       -0.998   \n",
       "75%                         -0.997                       -0.997   \n",
       "max                         -0.993                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_345  val_r2_keras_loss_epoch_346  \\\n",
       "count                       10.000                       10.000   \n",
       "mean                        -0.997                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.997                       -0.997   \n",
       "max                         -0.992                       -0.991   \n",
       "\n",
       "       val_r2_keras_loss_epoch_347  val_r2_keras_loss_epoch_348  \\\n",
       "count                       10.000                       10.000   \n",
       "mean                        -0.997                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.999   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.997                       -0.997   \n",
       "max                         -0.992                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_349  val_r2_keras_loss_epoch_350  \\\n",
       "count                       10.000                        9.000   \n",
       "mean                        -0.997                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.998                       -0.997   \n",
       "75%                         -0.997                       -0.997   \n",
       "max                         -0.993                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_351  val_r2_keras_loss_epoch_352  \\\n",
       "count                        8.000                        8.000   \n",
       "mean                        -0.997                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.999                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.998                       -0.998   \n",
       "75%                         -0.996                       -0.996   \n",
       "max                         -0.993                       -0.992   \n",
       "\n",
       "       val_r2_keras_loss_epoch_353  val_r2_keras_loss_epoch_354  \\\n",
       "count                        8.000                        6.000   \n",
       "mean                        -0.997                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.999                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.998                       -0.998   \n",
       "75%                         -0.996                       -0.997   \n",
       "max                         -0.992                       -0.994   \n",
       "\n",
       "       val_r2_keras_loss_epoch_355  val_r2_keras_loss_epoch_356  \\\n",
       "count                        6.000                        6.000   \n",
       "mean                        -0.997                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.999                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.998                       -0.997   \n",
       "75%                         -0.997                       -0.997   \n",
       "max                         -0.994                       -0.994   \n",
       "\n",
       "       val_r2_keras_loss_epoch_357  val_r2_keras_loss_epoch_358  \\\n",
       "count                        6.000                        6.000   \n",
       "mean                        -0.997                       -0.997   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.998                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.998                       -0.997   \n",
       "75%                         -0.997                       -0.997   \n",
       "max                         -0.994                       -0.994   \n",
       "\n",
       "       val_r2_keras_loss_epoch_359  val_r2_keras_loss_epoch_360  \\\n",
       "count                        5.000                        4.000   \n",
       "mean                        -0.997                       -0.996   \n",
       "std                          0.002                        0.002   \n",
       "min                         -0.999                       -0.998   \n",
       "25%                         -0.998                       -0.998   \n",
       "50%                         -0.997                       -0.997   \n",
       "75%                         -0.997                       -0.996   \n",
       "max                         -0.994                       -0.993   \n",
       "\n",
       "       val_r2_keras_loss_epoch_361  val_r2_keras_loss_epoch_362  \\\n",
       "count                        3.000                        1.000   \n",
       "mean                        -0.997                       -0.994   \n",
       "std                          0.002                          NaN   \n",
       "min                         -0.998                       -0.994   \n",
       "25%                         -0.998                       -0.994   \n",
       "50%                         -0.997                       -0.994   \n",
       "75%                         -0.996                       -0.994   \n",
       "max                         -0.994                       -0.994   \n",
       "\n",
       "       val_r2_keras_loss_epoch_363  val_r2_keras_loss_epoch_364  \\\n",
       "count                        1.000                        1.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                            NaN                          NaN   \n",
       "min                         -0.994                       -0.994   \n",
       "25%                         -0.994                       -0.994   \n",
       "50%                         -0.994                       -0.994   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.994                       -0.994   \n",
       "\n",
       "       val_r2_keras_loss_epoch_365  val_r2_keras_loss_epoch_366  \\\n",
       "count                        1.000                        1.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                            NaN                          NaN   \n",
       "min                         -0.994                       -0.994   \n",
       "25%                         -0.994                       -0.994   \n",
       "50%                         -0.994                       -0.994   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.994                       -0.994   \n",
       "\n",
       "       val_r2_keras_loss_epoch_367  val_r2_keras_loss_epoch_368  \\\n",
       "count                        1.000                        1.000   \n",
       "mean                        -0.994                       -0.995   \n",
       "std                            NaN                          NaN   \n",
       "min                         -0.994                       -0.995   \n",
       "25%                         -0.994                       -0.995   \n",
       "50%                         -0.994                       -0.995   \n",
       "75%                         -0.994                       -0.995   \n",
       "max                         -0.994                       -0.995   \n",
       "\n",
       "       val_r2_keras_loss_epoch_369  val_r2_keras_loss_epoch_370  \\\n",
       "count                        1.000                        1.000   \n",
       "mean                        -0.994                       -0.994   \n",
       "std                            NaN                          NaN   \n",
       "min                         -0.994                       -0.994   \n",
       "25%                         -0.994                       -0.994   \n",
       "50%                         -0.994                       -0.994   \n",
       "75%                         -0.994                       -0.994   \n",
       "max                         -0.994                       -0.994   \n",
       "\n",
       "       val_r2_keras_loss_epoch_371  \n",
       "count                        1.000  \n",
       "mean                        -0.995  \n",
       "std                            NaN  \n",
       "min                         -0.995  \n",
       "25%                         -0.995  \n",
       "50%                         -0.995  \n",
       "75%                         -0.995  \n",
       "max                         -0.995  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for metric\n",
    "path = './data/results/weights_' + path_identifier_lambda_net_data + '/' + list(history.keys())[1] + '_epoch_' + str(epochs_lambda).zfill(3) + '.png'\n",
    "\n",
    "adjustment_threshold_metric = 10#100\n",
    "    \n",
    "metric_df_adjusted = metric_df.copy(deep=True).iloc[:,1:]\n",
    "if adjustment_threshold_metric > 0:\n",
    "    metric_df_adjusted[metric_df_adjusted.columns] = np.where(metric_df_adjusted[metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, metric_df_adjusted[metric_df_adjusted.columns])\n",
    "    \n",
    "val_metric_df_adjusted = val_metric_df.copy(deep=True).iloc[:,1:]\n",
    "if adjustment_threshold_metric > 0:\n",
    "    val_metric_df_adjusted[val_metric_df_adjusted.columns] = np.where(val_metric_df_adjusted[val_metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, val_metric_df_adjusted[val_metric_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model ' + list(history.keys())[1])\n",
    "plt.ylabel(list(history.keys())[1])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-17T09:44:26.883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "path = './data/results/weights_' + path_identifier_lambda_net_data + '/' + list(history.keys())[0] + '_epoch_' + str(epochs_lambda).zfill(3) + '.png'\n",
    "\n",
    "adjustment_threshold_loss = 0#10000\n",
    "    \n",
    "loss_df_adjusted = loss_df.copy(deep=True).iloc[:,1:]\n",
    "\n",
    "if adjustment_threshold_loss > 0:\n",
    "    loss_df_adjusted[loss_df_adjusted.columns] = np.where(loss_df_adjusted[loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, loss_df_adjusted[loss_df_adjusted.columns])\n",
    "    \n",
    "val_loss_df_adjusted = val_loss_df.copy(deep=True).iloc[:,1:]\n",
    "if adjustment_threshold_loss > 0:\n",
    "    val_loss_df_adjusted[val_loss_df_adjusted.columns] = np.where(val_loss_df_adjusted[val_loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, val_loss_df_adjusted[val_loss_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model ' + list(history.keys())[0])\n",
    "plt.ylabel(list(history.keys())[0])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
