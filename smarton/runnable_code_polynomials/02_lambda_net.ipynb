{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Î»-Nets for I-Net training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:28:50.777816Z",
     "start_time": "2020-12-01T19:28:50.770303Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def nCr(n,r):\n",
    "    f = math.factorial\n",
    "    return f(n) // f(r) // f(n-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:28:50.791566Z",
     "start_time": "2020-12-01T19:28:50.780240Z"
    }
   },
   "outputs": [],
   "source": [
    "d = 3\n",
    "n = 4\n",
    "sparsity = nCr(n+d, d)\n",
    "\n",
    "\n",
    "x_max = 1#10 #this number excluded\n",
    "x_min = -1#-10\n",
    "x_step = 0.01#0.1\n",
    "a_max = 10 #this number excluded\n",
    "a_min = -10\n",
    "a_step = 0.1\n",
    "\n",
    "lambda_dataset_size = 1000 #specify the number of data points to train the lambda net on for loading (must be same as in previous notebook)\n",
    "\n",
    "number_formulas_load = 10000 #manually specify number of formulas for loading file (must be the same as used in the previous notebook)\n",
    "number_of_lambda_nets = number_formulas_load #use this parameter to select how many lambda nets should be generated (must be smaller or equal to number_formulas_load)\n",
    "\n",
    "\n",
    "#lambda net specifications \n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "lambda_network_layers = [5*sparsity]\n",
    "dropout = 0.0\n",
    "optimizer='SGD'\n",
    "\n",
    "each_epochs_save = 10  #specifies the number of epochs to checkpoint lambda network weights, if None no checkpointing\n",
    "\n",
    "same_training_all_lambda_nets = False\n",
    "fixed_seed_lambda_training = False\n",
    "initialize_network_zero = True\n",
    "\n",
    "\n",
    "n_jobs = -3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:28:50.807747Z",
     "start_time": "2020-12-01T19:28:50.793506Z"
    }
   },
   "outputs": [],
   "source": [
    "##############DO NOT CHANGE###################\n",
    "variables = 'abcdefghijklmnopqrstuvwxyz'[:n]\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "if each_epochs_save != None:\n",
    "    epochs_save_range = range(1, epochs//each_epochs_save+1) if each_epochs_save == 1 else range(epochs//each_epochs_save+1)\n",
    "else:\n",
    "    epochs_save_range = None\n",
    "    \n",
    "layers_str = ''.join([str(neurons) + '-' for neurons in lambda_network_layers])\n",
    "\n",
    "advanced_metric_dataset_size = 10#200\n",
    "\n",
    "if same_training_all_lambda_nets:\n",
    "    training_string = '_same'\n",
    "else:\n",
    "    training_string = '_diverse'\n",
    "\n",
    "generate_subset = True if number_of_lambda_nets < number_formulas_load else False\n",
    "\n",
    "    \n",
    "if generate_subset:\n",
    "    data_size = number_of_lambda_nets\n",
    "else:\n",
    "    data_size = number_formulas_load\n",
    "\n",
    "if fixed_seed_lambda_training:\n",
    "    seed_shuffle_string = '_SeedMethod'\n",
    "elif not fixed_seed_lambda_training:\n",
    "    seed_shuffle_string = '_NoSeedMethod'\n",
    "    \n",
    "if initialize_network_zero:\n",
    "    seed_shuffle_string = seed_shuffle_string + '_zero_initialize'\n",
    "\n",
    "    \n",
    "use_gpu = False\n",
    "if use_gpu:\n",
    "    gpu_numbers = '0'\n",
    "else:\n",
    "    gpu_numbers = ''\n",
    "    \n",
    "structure = '_' + layers_str + str(epochs) + 'e' + str(batch_size) + 'b_' + optimizer \n",
    "    \n",
    "filename = seed_shuffle_string + '_' + str(RANDOM_SEED) + structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:29:58.985191Z",
     "start_time": "2020-12-01T19:28:50.809933Z"
    }
   },
   "outputs": [],
   "source": [
    "import ttg\n",
    "from itertools import product       # forms cartesian products\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from more_itertools import random_product \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import math\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "from IPython.display import Image\n",
    "\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import random \n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "#keras.backend.set_epsilon(10e-3)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:29:59.020953Z",
     "start_time": "2020-12-01T19:29:58.988513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:29:59.048053Z",
     "start_time": "2020-12-01T19:29:59.024689Z"
    }
   },
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s2, s3), (s4, s5), ...\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "def chunks(lst, chunksize):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), chunksize):\n",
    "        yield lst[i:i + chunksize]\n",
    "\n",
    "#test for exact equality\n",
    "def arreq_in_list(myarr, list_arrays):\n",
    "    return next((True for elem in list_arrays if np.array_equal(elem, myarr)), False)\n",
    "\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "\n",
    "ALPHABET = \\\n",
    "  \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "def encode (n):\n",
    "    try:\n",
    "        return ALPHABET [n]\n",
    "    except IndexError:\n",
    "        raise Exception (\"cannot encode: %s\" % n)\n",
    "        \n",
    "def dec_to_base (dec = 0, base = 16):\n",
    "    if dec < base:\n",
    "        return encode (dec)\n",
    "    else:\n",
    "        return dec_to_base (dec // base, base) + encode (dec % base)\n",
    "    \n",
    "    \n",
    "def mergeDict(dict1, dict2):\n",
    "    #Merge dictionaries and keep values of common keys in list\n",
    "    newDict = {**dict1, **dict2}\n",
    "    for key, value in newDict.items():\n",
    "        if key in dict1 and key in dict2:\n",
    "            if isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend(value)\n",
    "            elif isinstance(dict1[key], list) and not isinstance(value, list):\n",
    "                newDict[key] = dict1[key]\n",
    "                newDict[key].extend([value])\n",
    "            elif not isinstance(dict1[key], list) and isinstance(value, list):\n",
    "                newDict[key] = [dict1[key]]\n",
    "                newDict[key].extend(value)\n",
    "            else:\n",
    "                newDict[key] = [dict1[key], value]\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss/Error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:29:59.056834Z",
     "start_time": "2020-12-01T19:29:59.051076Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def calcualate_function_value_with_X_data_entry(coefficient_list, X_data_entry):\n",
    "    \n",
    "    global list_of_monomial_identifiers\n",
    "     \n",
    "    result = 0    \n",
    "    for coefficient_value, coefficient_multipliers in zip(coefficient_list, list_of_monomial_identifiers):\n",
    "        partial_results = [X_data_value**int(coefficient_multiplier) for coefficient_multiplier, X_data_value in zip(coefficient_multipliers, X_data_entry)]\n",
    "        \n",
    "        result += coefficient_value * reduce(lambda x, y: x*y, partial_results)\n",
    "        \n",
    "    return result, np.append(X_data_entry, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:29:59.094410Z",
     "start_time": "2020-12-01T19:29:59.059053Z"
    },
    "code_folding": [
     0,
     20,
     43,
     66,
     88,
     91,
     103
    ]
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "        \n",
    "    if tf.is_tensor(y_true):\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    else:\n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    if tf.is_tensor(y_pred):\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "    else:\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "            \n",
    "            \n",
    "    return tf.math.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "def accuracy_multilabel(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    if 'float' in str(y_true[0].dtype):        \n",
    "        if tf.is_tensor(y_true):\n",
    "            y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "        else:\n",
    "            y_true = y_true.astype('float32')\n",
    "        if tf.is_tensor(y_pred):\n",
    "            y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        else:\n",
    "            y_pred = y_pred.astype('float32')\n",
    "            \n",
    "        n_digits = int(-np.log10(a_step))\n",
    "        \n",
    "        y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "        y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(tf.reduce_all(K.equal(y_true, y_pred), axis=1), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def accuracy_single(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    if 'float' in str(y_true[0].dtype):        \n",
    "        if tf.is_tensor(y_true):\n",
    "            y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "        else:\n",
    "            y_true = y_true.astype('float32')\n",
    "        if tf.is_tensor(y_pred):\n",
    "            y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        else:\n",
    "            y_pred = y_pred.astype('float32')\n",
    "            \n",
    "        n_digits = int(-np.log10(a_step))\n",
    "        \n",
    "        y_true = tf.math.round(y_true * 10**n_digits) / (10**n_digits) \n",
    "        y_pred = tf.math.round(y_pred * 10**n_digits) / (10**n_digits) \n",
    "        \n",
    "    return K.mean(tf.dtypes.cast(tf.dtypes.cast(K.equal(y_true, y_pred), tf.int32), tf.float32))#tf.reduce_all(K.equal(K.equal(y_true, y_pred), True), axis=1)#K.all(K.equal(y_true, y_pred)) #K.equal(y_true, y_pred)                        \n",
    "\n",
    "def mean_absolute_percentage_error_keras(y_true, y_pred, epsilon=10e-3): \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values    \n",
    "        \n",
    "    if tf.is_tensor(y_true):\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    else:\n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "        y_true = tf.dtypes.cast(y_true, tf.float32) \n",
    "    if tf.is_tensor(y_pred):\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "    else:\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n",
    "        \n",
    "    epsilon = tf.convert_to_tensor(epsilon)\n",
    "    epsilon = tf.dtypes.cast(epsilon, tf.float32)\n",
    "        \n",
    "    return tf.reduce_mean(tf.abs(tf.divide(tf.subtract(y_pred, y_true),(y_true + epsilon))))\n",
    "\n",
    "def huber_loss_delta_set(y_true, y_pred):\n",
    "    return keras.losses.huber_loss(y_true, y_pred, delta=0.3)\n",
    "\n",
    "def relative_absolute_average_error(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "       \n",
    "    #error value calculation    \n",
    "    result = np.sum(np.abs(y_true-y_pred))/(y_true.shape[0]*np.std(y_true)) #correct STD?\n",
    "    \n",
    "    return result\n",
    "\n",
    "def relative_maximum_average_error(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred = y_pred.values\n",
    "    \n",
    "    #error value calculation    \n",
    "    result = np.max(y_true-y_pred)/np.std(y_true) #correct STD?\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of Monomial Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:29:59.186648Z",
     "start_time": "2020-12-01T19:29:59.096413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8446bddcff41a78858d13a083e800a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 256\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0013', '0020', '0021', '0022', '0023', '0030', '0031', '0032', '0033', '0100', '0101', '0102', '0103', '0110', '0111', '0112', '0113', '0120', '0121', '0122', '0123', '0130', '0131', '0132', '0133', '0200', '0201', '0202', '0203', '0210', '0211', '0212', '0213', '0220', '0221', '0222', '0223', '0230', '0231', '0232', '0233', '0300', '0301', '0302', '0303', '0310', '0311', '0312', '0313', '0320', '0321', '0322', '0323', '0330', '0331', '0332', '0333', '1000', '1001', '1002', '1003', '1010', '1011', '1012', '1013', '1020', '1021', '1022', '1023', '1030', '1031', '1032', '1033', '1100', '1101', '1102', '1103', '1110', '1111', '1112', '1113', '1120', '1121', '1122', '1123', '1130', '1131', '1132', '1133', '1200', '1201', '1202', '1203', '1210', '1211', '1212', '1213', '1220', '1221', '1222', '1223', '1230', '1231', '1232', '1233', '1300', '1301', '1302', '1303', '1310', '1311', '1312', '1313', '1320', '1321', '1322', '1323', '1330', '1331', '1332', '1333', '2000', '2001', '2002', '2003', '2010', '2011', '2012', '2013', '2020', '2021', '2022', '2023', '2030', '2031', '2032', '2033', '2100', '2101', '2102', '2103', '2110', '2111', '2112', '2113', '2120', '2121', '2122', '2123', '2130', '2131', '2132', '2133', '2200', '2201', '2202', '2203', '2210', '2211', '2212', '2213', '2220', '2221', '2222', '2223', '2230', '2231', '2232', '2233', '2300', '2301', '2302', '2303', '2310', '2311', '2312', '2313', '2320', '2321', '2322', '2323', '2330', '2331', '2332', '2333', '3000', '3001', '3002', '3003', '3010', '3011', '3012', '3013', '3020', '3021', '3022', '3023', '3030', '3031', '3032', '3033', '3100', '3101', '3102', '3103', '3110', '3111', '3112', '3113', '3120', '3121', '3122', '3123', '3130', '3131', '3132', '3133', '3200', '3201', '3202', '3203', '3210', '3211', '3212', '3213', '3220', '3221', '3222', '3223', '3230', '3231', '3232', '3233', '3300', '3301', '3302', '3303', '3310', '3311', '3312', '3313', '3320', '3321', '3322', '3323', '3330', '3331', '3332', '3333']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcce19fd1f9469985d0418ae12ad091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List length: 35\n",
      "Number of monomials in a polynomial with 4 variables and degree 3: 35\n",
      "Sparsity: 35\n",
      "['0000', '0001', '0002', '0003', '0010', '0011', '0012', '0020', '0021', '0030', '0100', '0101', '0102', '0110', '0111', '0120', '0200', '0201', '0210', '0300', '1000', '1001', '1002', '1010', '1011', '1020', '1100', '1101', '1110', '1200', '2000', '2001', '2010', '2100', '3000']\n"
     ]
    }
   ],
   "source": [
    "list_of_monomial_identifiers_extended = []\n",
    "for i in tqdm(range((d+1)**n)):    \n",
    "    monomial_identifier = dec_to_base(i, base = (d+1)).zfill(n) \n",
    "    list_of_monomial_identifiers_extended.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers_extended)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers_extended)\n",
    "\n",
    "list_of_monomial_identifiers = []\n",
    "for monomial_identifier in tqdm(list_of_monomial_identifiers_extended):\n",
    "    monomial_identifier_values = list(map(int, list(monomial_identifier)))\n",
    "    if sum(monomial_identifier_values) <= d:\n",
    "        list_of_monomial_identifiers.append(monomial_identifier)\n",
    "\n",
    "print('List length: ' + str(len(list_of_monomial_identifiers)))\n",
    "print('Number of monomials in a polynomial with ' + str(n) + ' variables and degree ' + str(d) + ': ' + str(nCr(n+d, d)))\n",
    "print('Sparsity: ' + str(sparsity))\n",
    "print(list_of_monomial_identifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.371923Z",
     "start_time": "2020-12-01T19:29:59.188594Z"
    }
   },
   "outputs": [],
   "source": [
    "path_polynomials = './data/saved_polynomial_lists/polynomials_sample' + str(number_formulas_load) + '_variables_' + str(n) +  '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step) + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '.csv'\n",
    "polynomials_list_df = pd.read_csv(path_polynomials)\n",
    "\n",
    "path_X_data = './data/saved_polynomial_lists/X_sample' + str(number_formulas_load) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) +  training_string + '.pkl'\n",
    "with open(path_X_data, 'rb') as f:\n",
    "    X_data_list = pickle.load(f)\n",
    "    \n",
    "path_y_data = './data/saved_polynomial_lists/y_sample' + str(number_formulas_load) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) +  training_string + '.pkl'\n",
    "with open(path_y_data, 'rb') as f:\n",
    "    y_data_list = pickle.load(f)\n",
    "    \n",
    "if generate_subset:\n",
    "    polynomials_list_df = polynomials_list_df.sample(n=number_of_lambda_nets, random_state=RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    X_data_list = random.sample(X_data_list, number_of_lambda_nets)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    y_data_list = random.sample(y_data_list, number_of_lambda_nets)\n",
    "    random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.485685Z",
     "start_time": "2020-12-01T19:30:13.375392Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#clear files\n",
    "if each_epochs_save != None:\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        \n",
    "        for i in epochs_save_range:\n",
    "            index = i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "            path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size)  + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(index).zfill(3)  + filename + '.txt'\n",
    "\n",
    "            with open(path, 'wt') as text_file:\n",
    "                text_file.truncate()   \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "else:\n",
    "    \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "\n",
    "        path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "        with open(path, 'wt') as text_file:\n",
    "            text_file.truncate()   \n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir('./data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.525626Z",
     "start_time": "2020-12-01T19:30:13.489323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.820</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>-0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.480</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.830</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3\n",
       "0 -0.420  0.820 -0.680 -0.640\n",
       "1 -0.980 -0.820  0.060 -0.300\n",
       "2 -0.480  0.000 -0.370  0.600\n",
       "3 -0.250  0.630 -0.480 -0.960\n",
       "4 -0.830  0.230 -0.170 -0.460"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.539311Z",
     "start_time": "2020-12-01T19:30:13.528403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.800</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.770</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3\n",
       "0  0.610  0.220 -0.980  0.170\n",
       "1 -0.230 -0.050 -0.900  0.600\n",
       "2  0.800 -0.540  0.550  0.440\n",
       "3  0.030 -0.600 -0.320 -0.430\n",
       "4  0.950  0.770 -0.250  0.530"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[1][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.546580Z",
     "start_time": "2020-12-01T19:30:13.541100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000    6.300\n",
       "0001   -7.200\n",
       "0002   -9.400\n",
       "0003    8.900\n",
       "0010   -3.000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[0][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.555464Z",
     "start_time": "2020-12-01T19:30:13.550311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000   -9.900\n",
       "0001    9.400\n",
       "0002   -6.000\n",
       "0003    7.800\n",
       "0010    0.800\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_list[1][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T17:06:36.919643Z",
     "start_time": "2020-09-16T17:06:36.912904Z"
    }
   },
   "source": [
    "## Lambda Network Training + Weigh/Bias saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.602268Z",
     "start_time": "2020-12-01T19:30:13.558502Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate_lambda_net(identifier, \n",
    "                        X_data_real_lambda, \n",
    "                        y_data_real_lambda, \n",
    "                        y_data_pred_lambda, \n",
    "                        y_data_pred_lambda_poly_lstsq, \n",
    "                        y_data_real_lambda_poly_lstsq):\n",
    "    \n",
    "    mae_real_VS_predLambda = np.round(mean_absolute_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    mae_real_VS_predPolyLstsq = np.round(mean_absolute_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    mae_predLambda_VS_predPolyLstsq = np.round(mean_absolute_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    mae_real_VS_realPolyLstsq = np.round(mean_absolute_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)    \n",
    "\n",
    "    rmse_real_VS_predLambda = np.round(root_mean_squared_error(y_data_real_lambda, y_data_pred_lambda), 4)    \n",
    "    rmse_real_VS_predPolyLstsq = np.round(root_mean_squared_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)    \n",
    "    rmse_predLambda_VS_predPolyLstsq = np.round(root_mean_squared_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)    \n",
    "    rmse_real_VS_realPolyLstsq = np.round(root_mean_squared_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)    \n",
    "\n",
    "    mape_real_VS_predLambda = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_pred_lambda), 4)    \n",
    "    mape_real_VS_predPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)    \n",
    "    mape_predLambda_VS_predPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)    \n",
    "    mape_real_VS_realPolyLstsq = np.round(mean_absolute_percentage_error_keras(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)            \n",
    "\n",
    "    r2_real_VS_predLambda = np.round(r2_score(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    r2_real_VS_predPolyLstsq = np.round(r2_score(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    r2_predLambda_VS_predPolyLstsq = np.round(r2_score(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    r2_real_VS_realPolyLstsq = np.round(r2_score(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    raae_real_VS_predLambda = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    raae_real_VS_predPolyLstsq = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    raae_predLambda_VS_predPolyLstsq = np.round(relative_absolute_average_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    raae_real_VS_realPolyLstsq = np.round(relative_absolute_average_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    rmae_real_VS_predLambda = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_pred_lambda), 4)\n",
    "    rmae_real_VS_predPolyLstsq = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_pred_lambda_poly_lstsq), 4)\n",
    "    rmae_predLambda_VS_predPolyLstsq = np.round(relative_maximum_average_error(y_data_pred_lambda_poly_lstsq, y_data_pred_lambda), 4)\n",
    "    rmae_real_VS_realPolyLstsq = np.round(relative_maximum_average_error(y_data_real_lambda, y_data_real_lambda_poly_lstsq), 4)\n",
    "\n",
    "    fd_real_VS_predLambda = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size]))), 4)\n",
    "    fd_real_VS_predPolyLstsq = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size]))), 4)\n",
    "    fd_predLambda_VS_predPolyLstsq = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size]))), 4)\n",
    "    fd_real_VS_realPolyLstsq = np.round(frechet_dist(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda_poly_lstsq[:advanced_metric_dataset_size]))), 4)\n",
    "\n",
    "    dtw_real_VS_predLambda, dtw_complete_real_VS_predLambda = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size])))\n",
    "    dtw_real_VS_predLambda = np.round(dtw_real_VS_predLambda, 4)\n",
    "    dtw_real_VS_predPolyLstsq, dtw_complete_real_VS_predPolyLstsq = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size])))\n",
    "    dtw_real_VS_predPolyLstsq = np.round(dtw_real_VS_predPolyLstsq, 4)\n",
    "    dtw_predLambda_VS_predPolyLstsq, dtw_complete_predLambda_VS_predPolyLstsq = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda_poly_lstsq[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_pred_lambda[:advanced_metric_dataset_size])))\n",
    "    dtw_predLambda_VS_predPolyLstsq = np.round(dtw_predLambda_VS_predPolyLstsq, 4)    \n",
    "    dtw_real_VS_realPolyLstsq, dtw_complete_real_VS_realPolyLstsq = dtw(np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda[:advanced_metric_dataset_size])), np.column_stack((X_data_real_lambda[:advanced_metric_dataset_size], y_data_real_lambda_poly_lstsq[:advanced_metric_dataset_size])))\n",
    "    dtw_real_VS_realPolyLstsq = np.round(dtw_real_VS_realPolyLstsq, 4) \n",
    "        \n",
    "    std_data_real_lambda = np.round(np.std(y_data_real_lambda), 4) \n",
    "    std_data_pred_lambda = np.round(np.std(y_data_pred_lambda), 4) \n",
    "    std_data_pred_lambda_poly_lstsq = np.round(np.std(y_data_pred_lambda_poly_lstsq), 4) \n",
    "    std_data_real_lambda_poly_lstsq = np.round(np.std(y_data_real_lambda_poly_lstsq), 4) \n",
    "\n",
    "    mean_data_real_lambda = np.round(np.mean(y_data_real_lambda), 4) \n",
    "    mean_data_pred_lambda = np.round(np.mean(y_data_pred_lambda), 4) \n",
    "    mean_data_pred_lambda_poly_lstsq = np.round(np.mean(y_data_pred_lambda_poly_lstsq), 4) \n",
    "    mean_data_real_lambda_poly_lstsq = np.round(np.mean(y_data_real_lambda_poly_lstsq), 4) \n",
    "\n",
    "    return [{\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': mae_real_VS_predLambda,\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': mae_real_VS_predPolyLstsq,\n",
    "             'MAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': mae_predLambda_VS_predPolyLstsq,\n",
    "             'MAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': mae_real_VS_realPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': rmse_real_VS_predLambda,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': rmse_real_VS_predPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': rmse_predLambda_VS_predPolyLstsq,\n",
    "             'RMSE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': rmse_real_VS_realPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': mape_real_VS_predLambda,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': mape_real_VS_predPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': mape_predLambda_VS_predPolyLstsq,\n",
    "             'MAPE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': mape_real_VS_realPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': r2_real_VS_predLambda,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': r2_real_VS_predPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': r2_predLambda_VS_predPolyLstsq,\n",
    "             'R2 FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': r2_real_VS_realPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': raae_real_VS_predLambda,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': raae_real_VS_predPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': raae_predLambda_VS_predPolyLstsq,\n",
    "             'RAAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': raae_real_VS_realPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': rmae_real_VS_predLambda,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': rmae_real_VS_predPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': rmae_predLambda_VS_predPolyLstsq,\n",
    "             'RMAE FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': rmae_real_VS_realPolyLstsq,\n",
    "             'FD FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': fd_real_VS_predLambda,   \n",
    "             'FD FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': fd_real_VS_predPolyLstsq,   \n",
    "             'FD FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': fd_predLambda_VS_predPolyLstsq,   \n",
    "             'FD FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': fd_real_VS_realPolyLstsq,   \n",
    "             'DTW FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA': dtw_real_VS_predLambda, \n",
    "             'DTW FV ' + identifier + ' REAL LAMBDA VS PRED LAMBDA POLY LSTSQ': dtw_real_VS_predPolyLstsq, \n",
    "             'DTW FV ' + identifier + ' PRED LAMBDA VS PRED LAMBDA POLY LSTSQ': dtw_predLambda_VS_predPolyLstsq, \n",
    "             'DTW FV ' + identifier + ' REAL LAMBDA VS REAL LAMBDA POLY LSTSQ': dtw_real_VS_realPolyLstsq, \n",
    "            },\n",
    "            {\n",
    "             'STD FV ' + identifier + ' REAL LAMBDA': std_data_real_lambda,\n",
    "             'STD FV ' + identifier + ' PRED LAMBDA': std_data_pred_lambda, \n",
    "             'STD FV ' + identifier + ' PRED LAMBDA POLY LSTSQ': std_data_pred_lambda_poly_lstsq, \n",
    "             'STD FV ' + identifier + ' REAL LAMBDA POLY LSTSQ': std_data_real_lambda_poly_lstsq, \n",
    "            },\n",
    "            {\n",
    "             'MEAN FV ' + identifier + ' REAL LAMBDA': mean_data_real_lambda,\n",
    "             'MEAN FV ' + identifier + ' PRED LAMBDA': mean_data_pred_lambda, \n",
    "             'MEAN FV ' + identifier + ' PRED LAMBDA POLY LSTSQ': mean_data_pred_lambda_poly_lstsq, \n",
    "             'MEAN FV ' + identifier + ' REAL LAMBDA POLY LSTSQ': mean_data_real_lambda_poly_lstsq, \n",
    "            }]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.612387Z",
     "start_time": "2020-12-01T19:30:13.604286Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_function_values_from_polynomial(X_data, polynomial):\n",
    "    function_value_list = []\n",
    "    for entry in X_data:\n",
    "        function_value, _ = calcualate_function_value_with_X_data_entry(polynomial, entry)\n",
    "        function_value_list.append(function_value)\n",
    "    function_value_array = np.array(function_value_list).reshape(len(function_value_list), 1)     \n",
    "\n",
    "    return function_value_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.626442Z",
     "start_time": "2020-12-01T19:30:13.614680Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_term_matric_for_lstsq(X_data, polynomial_indices):\n",
    "    term_list_all = []\n",
    "    y = 0\n",
    "    for term in list(polynomial_indices):\n",
    "        term_list = [int(value_mult) for value_mult in term]\n",
    "        term_list_all.append(term_list)\n",
    "    terms_matrix = []\n",
    "    for unknowns in X_data:\n",
    "        terms = []\n",
    "        for term_multipliers in term_list_all:\n",
    "            term_value = prod([unknown**multiplier for unknown, multiplier in zip(unknowns, term_multipliers)])\n",
    "            terms.append(term_value)\n",
    "        terms_matrix.append(np.array(terms))\n",
    "    terms_matrix = np.array(terms_matrix)\n",
    "    \n",
    "    return terms_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T19:30:13.697647Z",
     "start_time": "2020-12-01T19:30:13.628955Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "def train_nn(X_data_lambda, y_data_real_lambda, polynomial, callbacks=None, return_history=False, each_epochs_save=None, printing=False, return_model=False):\n",
    "    \n",
    "    if fixed_seed_lambda_training:\n",
    "        random.seed(RANDOM_SEED)\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        if int(tf.__version__[0]) >= 2:\n",
    "            tf.random.set_seed(RANDOM_SEED)\n",
    "        else:\n",
    "            tf.set_random_seed(RANDOM_SEED) \n",
    "        \n",
    "    if isinstance(X_data_lambda, pd.DataFrame):\n",
    "        X_data_lambda = X_data_lambda.values\n",
    "    if isinstance(y_data_real_lambda, pd.DataFrame):\n",
    "        y_data_real_lambda = y_data_real_lambda.values\n",
    "                \n",
    "    X_train_lambda_with_valid, X_test_lambda, y_train_real_lambda_with_valid, y_test_real_lambda = train_test_split(X_data_lambda, y_data_real_lambda, test_size=0.25, random_state=RANDOM_SEED)           \n",
    "    X_train_lambda, X_valid_lambda, y_train_real_lambda, y_valid_real_lambda = train_test_split(X_train_lambda_with_valid, y_train_real_lambda_with_valid, test_size=0.25, random_state=RANDOM_SEED)           \n",
    "     \n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    if initialize_network_zero:\n",
    "        model.add(Dense(lambda_network_layers[0], activation='relu', input_dim=X_data_lambda.shape[1], kernel_initializer='zeros', bias_initializer='zeros')) #1024\n",
    "    else:\n",
    "        model.add(Dense(lambda_network_layers[0], activation='relu', input_dim=X_data_lambda.shape[1])) #1024\n",
    "        \n",
    "    if dropout > 0:\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    for neurons in lambda_network_layers[1:]:\n",
    "        if initialize_network_zero:\n",
    "            model.add(Dense(neurons, activation='relu', kernel_initializer='zeros', bias_initializer='zeros'))\n",
    "        else:\n",
    "            model.add(Dense(neurons, activation='relu'))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(dropout))   \n",
    "    \n",
    "    if initialize_network_zero:\n",
    "        model.add(Dense(1, kernel_initializer='zeros', bias_initializer='zeros'))\n",
    "    else:\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=[mean_absolute_percentage_error_keras, root_mean_squared_error]\n",
    "                 )\n",
    "    \n",
    "    \n",
    "    weights = []\n",
    "    polynomial_lstsq_pred_list = []\n",
    "    polynomial_lstsq_true_list = []\n",
    "\n",
    "     \n",
    "    if each_epochs_save == None:   \n",
    "        model_history = model.fit(X_train_lambda, \n",
    "                      y_train_real_lambda, \n",
    "                      epochs=epochs, \n",
    "                      batch_size=batch_size, \n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=(X_valid_lambda, y_valid_real_lambda),\n",
    "                      verbose=0,\n",
    "                      workers=0)\n",
    "        weights.append(model.get_weights())\n",
    "        \n",
    "        history = model_history.history\n",
    "        \n",
    "        y_train_pred_lambda = model.predict(X_train_lambda) \n",
    "        y_valid_pred_lambda = model.predict(X_valid_lambda)                \n",
    "        y_test_pred_lambda = model.predict(X_test_lambda)\n",
    "    \n",
    "        terms_matrix = generate_term_matric_for_lstsq(X_train_lambda, list(polynomial.index))\n",
    "                \n",
    "        polynomial_lstsq_pred, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_pred_lambda.ravel(), rcond=-1)#[::-1]\n",
    "        polynomial_lstsq_true, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_real_lambda.ravel(), rcond=-1)#[::-1] \n",
    "        polynomial_lstsq_pred_list.append(polynomial_lstsq_pred)\n",
    "        polynomial_lstsq_true_list.append(polynomial_lstsq_true)\n",
    "        \n",
    "        y_train_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_pred)\n",
    "        y_train_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_true)\n",
    "        y_valid_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_pred)\n",
    "        y_valid_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_true)    \n",
    "        y_test_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_pred)\n",
    "        y_test_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_true)  \n",
    "        \n",
    "        pred_list = (y_train_real_lambda, \n",
    "                     y_train_pred_lambda, \n",
    "                     y_train_pred_lambda_poly_lstsq,\n",
    "                     #y_train_real_lambda_poly_lstsq,\n",
    "                     X_train_lambda, \n",
    "                     y_valid_real_lambda,\n",
    "                     y_valid_pred_lambda, \n",
    "                     y_valid_pred_lambda_poly_lstsq,\n",
    "                     #y_valid_real_lambda_poly_lstsq,\n",
    "                     X_valid_lambda, \n",
    "                     y_test_real_lambda, \n",
    "                     y_test_pred_lambda, \n",
    "                     y_test_pred_lambda_poly_lstsq, \n",
    "                     #y_test_real_lambda_poly_lstsq,\n",
    "                     X_test_lambda)\n",
    "\n",
    "        scores_train, std_train, mean_train = evaluate_lambda_net('TRAIN', X_train_lambda, y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, y_train_real_lambda_poly_lstsq)\n",
    "        scores_valid, std_valid, mean_valid = evaluate_lambda_net('VALID', X_valid_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, y_valid_real_lambda_poly_lstsq)\n",
    "        scores_test, std_test, mean_test = evaluate_lambda_net('TEST', X_test_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, y_test_real_lambda_poly_lstsq)\n",
    "\n",
    "        scores_std = {}\n",
    "        for aDict in (std_train, std_valid, std_test):\n",
    "            scores_std.update(aDict)      \n",
    "        scores_mean = {}\n",
    "        for aDict in (mean_train, mean_valid, mean_test):\n",
    "            scores_mean.update(aDict)\n",
    "        \n",
    "        scores_list =  [scores_train,\n",
    "                             scores_valid,\n",
    "                             scores_test,\n",
    "                             scores_std,\n",
    "                             scores_mean]            \n",
    "                            \n",
    "    else:\n",
    "        scores_list = []\n",
    "        pred_list = []\n",
    "        for i in epochs_save_range:\n",
    "            train_epochs_step = each_epochs_save if i > 1 else max(each_epochs_save-1, 1) if i==1 else 1\n",
    "            \n",
    "            model_history = model.fit(X_train_lambda, \n",
    "                      y_train_real_lambda, \n",
    "                      epochs=train_epochs_step, \n",
    "                      batch_size=batch_size, \n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=(X_valid_lambda, y_valid_real_lambda),\n",
    "                      verbose=0,\n",
    "                      workers=1,\n",
    "                      use_multiprocessing=False)\n",
    "            \n",
    "            #history adjustment for continuing training\n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                history = model_history.history\n",
    "            else:\n",
    "                history = mergeDict(history, model_history.history)\n",
    "                #for key_1 in history.keys():\n",
    "                #    for key_2 in model_history.history.keys():\n",
    "                #        if key_1 == key_2:\n",
    "                #            history[key_1] += model_history.history[key_2]  \n",
    "\n",
    "            weights.append(model.get_weights())\n",
    "            \n",
    "            y_train_pred_lambda = model.predict(X_train_lambda)                \n",
    "            y_valid_pred_lambda = model.predict(X_valid_lambda)                \n",
    "            y_test_pred_lambda = model.predict(X_test_lambda)        \n",
    "\n",
    "            terms_matrix = generate_term_matric_for_lstsq(X_train_lambda, list(polynomial.index))\n",
    "                        \n",
    "            polynomial_lstsq_pred, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_pred_lambda.ravel(), rcond=-1)#[::-1] \n",
    "            #does not change over time\n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                polynomial_lstsq_true, _, _, _ = np.linalg.lstsq(terms_matrix, y_train_real_lambda.ravel(), rcond=-1)#[::-1] \n",
    "            polynomial_lstsq_pred_list.append(polynomial_lstsq_pred)\n",
    "            polynomial_lstsq_true_list.append(polynomial_lstsq_true)            \n",
    "\n",
    "            \n",
    "            y_train_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_pred)\n",
    "            y_valid_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_pred)\n",
    "            y_test_pred_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_pred)           \n",
    "            if i == 0 and each_epochs_save != 1 or i == 1 and each_epochs_save == 1:\n",
    "                y_train_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_train_lambda, polynomial_lstsq_true)\n",
    "                y_valid_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_valid_lambda, polynomial_lstsq_true)  \n",
    "                y_test_real_lambda_poly_lstsq = calculate_function_values_from_polynomial(X_test_lambda, polynomial_lstsq_true)                    \n",
    "                \n",
    "            pred_list.append((y_train_real_lambda, \n",
    "                              y_train_pred_lambda, \n",
    "                              y_train_pred_lambda_poly_lstsq,\n",
    "                              #y_train_real_lambda_poly_lstsq,\n",
    "                              X_train_lambda, \n",
    "                              y_valid_real_lambda,\n",
    "                              y_valid_pred_lambda, \n",
    "                              y_valid_pred_lambda_poly_lstsq,\n",
    "                              #y_valid_real_lambda_poly_lstsq,\n",
    "                              X_valid_lambda, \n",
    "                              y_test_real_lambda, \n",
    "                              y_test_pred_lambda, \n",
    "                              y_test_pred_lambda_poly_lstsq, \n",
    "                              #y_test_real_lambda_poly_lstsq,\n",
    "                              X_test_lambda))\n",
    "    \n",
    "            scores_train, std_train, mean_train = evaluate_lambda_net('TRAIN', X_train_lambda, y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, y_train_real_lambda_poly_lstsq)\n",
    "            scores_valid, std_valid, mean_valid = evaluate_lambda_net('VALID', X_valid_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, y_valid_real_lambda_poly_lstsq)\n",
    "            scores_test, std_test, mean_test = evaluate_lambda_net('TEST', X_test_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, y_test_real_lambda_poly_lstsq)\n",
    "\n",
    "            scores_std = {}\n",
    "            for aDict in (std_train, std_valid, std_test):\n",
    "                scores_std.update(aDict)\n",
    "            scores_mean = {}\n",
    "            for aDict in (mean_train, mean_valid, mean_test):\n",
    "                scores_mean.update(aDict)\n",
    "\n",
    "            scores_list_single_epoch =  [scores_train,\n",
    "                                              scores_valid,\n",
    "                                              scores_test,\n",
    "                                              scores_std,\n",
    "                                              scores_mean]        \n",
    "                  \n",
    "            scores_list.append(scores_list_single_epoch)\n",
    "       \n",
    "\n",
    "        \n",
    "    if printing:        \n",
    "        for i, (weights_for_epoch, polynomial_lstsq_pred_for_epoch, polynomial_lstsq_true_for_epoch) in enumerate(zip(weights, polynomial_lstsq_pred_list, polynomial_lstsq_true_list)):        \n",
    "            if each_epochs_save == None:\n",
    "                path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "            else:\n",
    "                index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "                path = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(index).zfill(3)  + filename + '.txt'\n",
    "            with open(path, 'a') as text_file: \n",
    "                for i, value in enumerate(polynomial.values):\n",
    "                    if i == 0:\n",
    "                        text_file.write(str(value))  \n",
    "                    else:\n",
    "                        text_file.write(', ' + str(value))   \n",
    "                for value in polynomial_lstsq_pred_for_epoch:\n",
    "                    text_file.write(', ' + str(value))\n",
    "                for value in polynomial_lstsq_true_for_epoch:\n",
    "                    text_file.write(', ' + str(value))\n",
    "                for layer_weights, biases in pairwise(weights_for_epoch):    #clf.get_weights()\n",
    "                    for neuron in layer_weights:\n",
    "                        for weight in neuron:\n",
    "                            text_file.write(', ' + str(weight))\n",
    "                    for bias in biases:\n",
    "                        text_file.write(', ' + str(bias))\n",
    "                text_file.write('\\n')\n",
    "\n",
    "            text_file.close() \n",
    "\n",
    "            \n",
    "    if return_model:\n",
    "        return (polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list, history, model\n",
    "    elif return_history:\n",
    "        return (polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list, history, #polynomial_lstsq_pred_list, polynomial_lstsq_true_list#, weights, history\n",
    "    else:\n",
    "        return (polynomial, polynomial_lstsq_pred_list, polynomial_lstsq_true_list), scores_list, pred_list#, weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T00:09:00.060009Z",
     "start_time": "2020-12-01T19:30:13.699736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    8.020, max:    9.482, cur:    8.020)\n",
      "\tvalidation       \t (min:    8.013, max:    9.897, cur:    8.013)\n",
      "mean_absolute_percentage_error_keras\n",
      "\ttraining         \t (min:    1.004, max:    3.251, cur:    3.119)\n",
      "\tvalidation       \t (min:    0.981, max:    1.517, cur:    1.517)\n",
      "root_mean_squared_error\n",
      "\ttraining         \t (min:   11.024, max:   12.605, cur:   11.222)\n",
      "\tvalidation       \t (min:   10.656, max:   12.652, cur:   10.656)\n"
     ]
    }
   ],
   "source": [
    "clf_list = []\n",
    "chunksize = 1000 if data_size > 10000 else max(data_size//10, min(50, data_size))\n",
    "X_data_list_splits = list(chunks(X_data_list, chunksize))\n",
    "y_data_list_splits = list(chunks(y_data_list, chunksize))\n",
    "\n",
    "for X_data_list_split, y_data_list_split in tqdm(zip(X_data_list_splits, y_data_list_splits), total=max(len(X_data_list_splits), len(y_data_list_splits))):\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    clf_sublist = parallel(delayed(train_nn)(X_data[1].values, y_data[1].values, X_data[0], return_history=True, each_epochs_save=each_epochs_save, printing=True) for X_data, y_data in zip(X_data_list_split, y_data_list_split))  \n",
    "    clf_list.extend(clf_sublist)\n",
    "    del parallel\n",
    "rand_index = np.random.randint(data_size)\n",
    "random_network = train_nn(X_data_list[rand_index][1], y_data_list[rand_index][1], X_data_list[rand_index][0], callbacks=[PlotLossesKerasTF()], return_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Lambda-Model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T00:09:10.757508Z",
     "start_time": "2020-12-02T00:09:00.062058Z"
    }
   },
   "outputs": [],
   "source": [
    "if each_epochs_save == None:\n",
    "    scores_list_train = [clf[1][0] for clf in clf_list]\n",
    "    scores_list_valid = [clf[1][1] for clf in clf_list]\n",
    "    scores_list_test = [clf[1][2] for clf in clf_list]\n",
    "    scores_list_stds = [clf[1][3] for clf in clf_list]\n",
    "    scores_list_means = [clf[1][4] for clf in clf_list]\n",
    "\n",
    "    scores_list_train_mean = pd.DataFrame(scores_list_train, columns=scores_list_train[0].keys()).mean()\n",
    "    df_mean_scores_train = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED', 'TRAIN POLY', 'TRAIN POLY PRED', 'TRAIN LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "\n",
    "    scores_list_valid_mean = pd.DataFrame(scores_list_valid, columns=scores_list_valid[0].keys()).mean()\n",
    "    df_mean_scores_valid = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED', 'VALID POLY', 'VALID POLY PRED', 'VALID LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "\n",
    "    scores_list_test_mean = pd.DataFrame(scores_list_test, columns=scores_list_test[0].keys()).mean()\n",
    "    df_mean_scores_test = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED', 'TEST POLY', 'TEST POLY PRED', 'TEST LSTSQ'], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "\n",
    "    stds_mean = pd.DataFrame(scores_list_stds, columns=scores_list_stds[0].keys()).mean()\n",
    "    df_stds = pd.DataFrame(stds_mean, columns=['0'], index=stds_mean.index)\n",
    "    \n",
    "    means_mean = pd.DataFrame(scores_list_means, columns=scores_list_means[0].keys()).mean()\n",
    "    df_means = pd.DataFrame(means_mean, columns=['0'], index=means_mean.index)\n",
    "    \n",
    "    path_scores_train = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_train_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_valid = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_valid_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_test = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_test_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_stds = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/stds_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_means = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/means_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "   \n",
    "    df_mean_scores_train.to_csv(path_scores_train, sep=',')\n",
    "    df_mean_scores_valid.to_csv(path_scores_valid, sep=',')\n",
    "    df_mean_scores_test.to_csv(path_scores_test, sep=',')\n",
    "    df_stds.to_csv(path_stds, sep=',')\n",
    "    df_means.to_csv(path_means, sep=',')\n",
    "else:\n",
    "    scores_list = [clf[1] for clf in clf_list]\n",
    "    \n",
    "    scores_list_by_epochs = [[] for i in epochs_save_range]\n",
    "    for scores_list in scores_list:   \n",
    "        for index, scores in enumerate(scores_list):\n",
    "            scores_list_by_epochs[index].append(scores)\n",
    "            \n",
    "        \n",
    "    for i, scores_list_single_epoch in enumerate(scores_list_by_epochs):\n",
    "        index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "           \n",
    "        scores_list_train = [scores_list[0] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_valid = [scores_list[1] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_test = [scores_list[2] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_stds = [scores_list[3] for scores_list in scores_list_single_epoch]\n",
    "        scores_list_means = [scores_list[4] for scores_list in scores_list_single_epoch]\n",
    "        \n",
    "        scores_list_train_mean = pd.DataFrame(scores_list_train, columns=scores_list_train[0].keys()).mean()  \n",
    "        scores_list_valid_mean = pd.DataFrame(scores_list_valid, columns=scores_list_valid[0].keys()).mean()  \n",
    "        scores_list_test_mean = pd.DataFrame(scores_list_test, columns=scores_list_test[0].keys()).mean()\n",
    "        stds_mean = pd.DataFrame(scores_list_stds, columns=scores_list_stds[0].keys()).mean()\n",
    "        means_mean = pd.DataFrame(scores_list_means, columns=scores_list_means[0].keys()).mean()\n",
    "\n",
    "        if index == 1:\n",
    "            df_mean_scores_train = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED E' + str(index), 'TRAIN POLY E' + str(index), 'TRAIN POLY PRED E' + str(index), 'TRAIN LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_valid = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index), 'VALID POLY PRED E' + str(index), 'VALID LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_test = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index), 'TEST POLY PRED E' + str(index), 'TEST LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_stds = pd.DataFrame(stds_mean, columns=['E' + str(index)], index=stds_mean.index)   \n",
    "            df_means = pd.DataFrame(means_mean, columns=['E' + str(index)], index=means_mean.index)   \n",
    "        else:\n",
    "            df_mean_scores_train_new = pd.DataFrame(np.column_stack((scores_list_train_mean.values[0::4], scores_list_train_mean.values[1::4], scores_list_train_mean.values[2::4], scores_list_train_mean.values[3::4])), columns=['TRAIN PRED E' + str(index), 'TRAIN POLY E' + str(index), 'TRAIN POLY PRED E' + str(index), 'TRAIN LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_train = pd.concat([df_mean_scores_train, df_mean_scores_train_new],axis=1)  \n",
    "            \n",
    "            df_mean_scores_valid_new = pd.DataFrame(np.column_stack((scores_list_valid_mean.values[0::4], scores_list_valid_mean.values[1::4], scores_list_valid_mean.values[2::4], scores_list_valid_mean.values[3::4])), columns=['VALID PRED E' + str(index), 'VALID POLY E' + str(index), 'VALID POLY PRED E' + str(index), 'VALID LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_valid = pd.concat([df_mean_scores_valid, df_mean_scores_valid_new],axis=1)  \n",
    "\n",
    "            df_mean_scores_test_new = pd.DataFrame(np.column_stack((scores_list_test_mean.values[0::4], scores_list_test_mean.values[1::4], scores_list_test_mean.values[2::4], scores_list_test_mean.values[3::4])), columns=['TEST PRED E' + str(index), 'TEST POLY E' + str(index), 'TEST POLY PRED E' + str(index), 'TEST LSTSQ E' + str(index)], index=['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV', 'FD FV', 'DTW FV'])\n",
    "            df_mean_scores_test = pd.concat([df_mean_scores_test, df_mean_scores_test_new],axis=1)  \n",
    "\n",
    "            df_stds_new = pd.DataFrame(stds_mean, columns=['E' + str(index)], index=stds_mean.index)\n",
    "            df_stds = pd.concat([df_stds, df_stds_new],axis=1)  \n",
    "            \n",
    "            df_means_new = pd.DataFrame(means_mean, columns=['E' + str(index)], index=means_mean.index)\n",
    "            df_means = pd.concat([df_means, df_means_new],axis=1)     \n",
    "\n",
    "    path_scores_train = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_train_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_valid = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_valid_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_scores_test = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/scores_test_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_stds = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/stds_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_means = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/means_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "    df_mean_scores_train.to_csv(path_scores_train, sep=',')\n",
    "    df_mean_scores_valid.to_csv(path_scores_valid, sep=',')\n",
    "    df_mean_scores_test.to_csv(path_scores_test, sep=',')\n",
    "    df_stds.to_csv(path_stds, sep=',')\n",
    "    df_means.to_csv(path_means, sep=',')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T00:09:10.783788Z",
     "start_time": "2020-12-02T00:09:10.759929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN PRED E1</th>\n",
       "      <th>TRAIN POLY E1</th>\n",
       "      <th>TRAIN POLY PRED E1</th>\n",
       "      <th>TRAIN LSTSQ E1</th>\n",
       "      <th>TRAIN PRED E10</th>\n",
       "      <th>TRAIN POLY E10</th>\n",
       "      <th>TRAIN POLY PRED E10</th>\n",
       "      <th>TRAIN LSTSQ E10</th>\n",
       "      <th>TRAIN PRED E20</th>\n",
       "      <th>TRAIN POLY E20</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAIN POLY PRED E180</th>\n",
       "      <th>TRAIN LSTSQ E180</th>\n",
       "      <th>TRAIN PRED E190</th>\n",
       "      <th>TRAIN POLY E190</th>\n",
       "      <th>TRAIN POLY PRED E190</th>\n",
       "      <th>TRAIN LSTSQ E190</th>\n",
       "      <th>TRAIN PRED E200</th>\n",
       "      <th>TRAIN POLY E200</th>\n",
       "      <th>TRAIN POLY PRED E200</th>\n",
       "      <th>TRAIN LSTSQ E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>10.221</td>\n",
       "      <td>10.221</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.038</td>\n",
       "      <td>10.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.854</td>\n",
       "      <td>9.854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.598</td>\n",
       "      <td>8.598</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.582</td>\n",
       "      <td>8.582</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>13.019</td>\n",
       "      <td>13.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.841</td>\n",
       "      <td>12.841</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.661</td>\n",
       "      <td>12.661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.375</td>\n",
       "      <td>11.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.356</td>\n",
       "      <td>11.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>1.036</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.413</td>\n",
       "      <td>1.413</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.833</td>\n",
       "      <td>1.833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.151</td>\n",
       "      <td>6.151</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.279</td>\n",
       "      <td>6.279</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-13.044</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>-12.819</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.028</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-13.107</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-12.983</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.924</td>\n",
       "      <td>3.225</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.906</td>\n",
       "      <td>3.189</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.889</td>\n",
       "      <td>...</td>\n",
       "      <td>3.208</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.768</td>\n",
       "      <td>3.206</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>3.475</td>\n",
       "      <td>3.475</td>\n",
       "      <td>3.768</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.476</td>\n",
       "      <td>3.476</td>\n",
       "      <td>3.773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.476</td>\n",
       "      <td>3.476</td>\n",
       "      <td>...</td>\n",
       "      <td>3.751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.480</td>\n",
       "      <td>3.480</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.480</td>\n",
       "      <td>3.480</td>\n",
       "      <td>3.792</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD FV</th>\n",
       "      <td>25.212</td>\n",
       "      <td>25.212</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.967</td>\n",
       "      <td>24.967</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.716</td>\n",
       "      <td>24.716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.795</td>\n",
       "      <td>22.795</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.762</td>\n",
       "      <td>22.762</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW FV</th>\n",
       "      <td>102.397</td>\n",
       "      <td>102.397</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.571</td>\n",
       "      <td>100.571</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.719</td>\n",
       "      <td>98.719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>86.170</td>\n",
       "      <td>86.170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>86.011</td>\n",
       "      <td>86.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRAIN PRED E1  TRAIN POLY E1  TRAIN POLY PRED E1  TRAIN LSTSQ E1  \\\n",
       "MAE FV          10.221         10.221               0.000           0.000   \n",
       "RMSE FV         13.019         13.019               0.000           0.000   \n",
       "MAPE FV          1.036          1.036               0.000           0.000   \n",
       "R2 FV           -0.420         -0.420             -13.044           1.000   \n",
       "RAAE FV          0.924          0.924               3.225           0.000   \n",
       "RMAE FV          3.475          3.475               3.768           0.000   \n",
       "FD FV           25.212         25.212               0.000           0.000   \n",
       "DTW FV         102.397        102.397               0.000           0.000   \n",
       "\n",
       "         TRAIN PRED E10  TRAIN POLY E10  TRAIN POLY PRED E10  TRAIN LSTSQ E10  \\\n",
       "MAE FV           10.038          10.038                0.000            0.000   \n",
       "RMSE FV          12.841          12.841                0.000            0.000   \n",
       "MAPE FV           1.413           1.413                0.000            0.000   \n",
       "R2 FV            -0.373          -0.373              -12.819            1.000   \n",
       "RAAE FV           0.906           0.906                3.189            0.000   \n",
       "RMAE FV           3.476           3.476                3.773            0.000   \n",
       "FD FV            24.967          24.967                0.000            0.000   \n",
       "DTW FV          100.571         100.571                0.000            0.000   \n",
       "\n",
       "         TRAIN PRED E20  TRAIN POLY E20  ...  TRAIN POLY PRED E180  \\\n",
       "MAE FV            9.854           9.854  ...                 0.000   \n",
       "RMSE FV          12.661          12.661  ...                 0.000   \n",
       "MAPE FV           1.833           1.833  ...                 0.000   \n",
       "R2 FV            -0.327          -0.327  ...               -13.028   \n",
       "RAAE FV           0.889           0.889  ...                 3.208   \n",
       "RMAE FV           3.476           3.476  ...                 3.751   \n",
       "FD FV            24.716          24.716  ...                 0.000   \n",
       "DTW FV           98.719          98.719  ...                 0.000   \n",
       "\n",
       "         TRAIN LSTSQ E180  TRAIN PRED E190  TRAIN POLY E190  \\\n",
       "MAE FV              0.000            8.598            8.598   \n",
       "RMSE FV             0.000           11.375           11.375   \n",
       "MAPE FV             0.000            6.151            6.151   \n",
       "R2 FV               1.000           -0.037           -0.037   \n",
       "RAAE FV             0.000            0.769            0.769   \n",
       "RMAE FV             0.000            3.480            3.480   \n",
       "FD FV               0.000           22.795           22.795   \n",
       "DTW FV              0.000           86.170           86.170   \n",
       "\n",
       "         TRAIN POLY PRED E190  TRAIN LSTSQ E190  TRAIN PRED E200  \\\n",
       "MAE FV                  0.000             0.000            8.582   \n",
       "RMSE FV                 0.000             0.000           11.356   \n",
       "MAPE FV                 0.000             0.000            6.279   \n",
       "R2 FV                 -13.107             1.000           -0.034   \n",
       "RAAE FV                   inf             0.000            0.768   \n",
       "RMAE FV                   inf             0.000            3.480   \n",
       "FD FV                   0.000             0.000           22.762   \n",
       "DTW FV                  0.000             0.000           86.011   \n",
       "\n",
       "         TRAIN POLY E200  TRAIN POLY PRED E200  TRAIN LSTSQ E200  \n",
       "MAE FV             8.582                 0.000             0.000  \n",
       "RMSE FV           11.356                 0.000             0.000  \n",
       "MAPE FV            6.279                 0.000             0.000  \n",
       "R2 FV             -0.034               -12.983             1.000  \n",
       "RAAE FV            0.768                 3.206             0.000  \n",
       "RMAE FV            3.480                 3.792             0.000  \n",
       "FD FV             22.762                 0.000             0.000  \n",
       "DTW FV            86.011                 0.000             0.000  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T00:09:10.805937Z",
     "start_time": "2020-12-02T00:09:10.785243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALID PRED E1</th>\n",
       "      <th>VALID POLY E1</th>\n",
       "      <th>VALID POLY PRED E1</th>\n",
       "      <th>VALID LSTSQ E1</th>\n",
       "      <th>VALID PRED E10</th>\n",
       "      <th>VALID POLY E10</th>\n",
       "      <th>VALID POLY PRED E10</th>\n",
       "      <th>VALID LSTSQ E10</th>\n",
       "      <th>VALID PRED E20</th>\n",
       "      <th>VALID POLY E20</th>\n",
       "      <th>...</th>\n",
       "      <th>VALID POLY PRED E180</th>\n",
       "      <th>VALID LSTSQ E180</th>\n",
       "      <th>VALID PRED E190</th>\n",
       "      <th>VALID POLY E190</th>\n",
       "      <th>VALID POLY PRED E190</th>\n",
       "      <th>VALID LSTSQ E190</th>\n",
       "      <th>VALID PRED E200</th>\n",
       "      <th>VALID POLY E200</th>\n",
       "      <th>VALID POLY PRED E200</th>\n",
       "      <th>VALID LSTSQ E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>10.204</td>\n",
       "      <td>10.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.023</td>\n",
       "      <td>10.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.840</td>\n",
       "      <td>9.840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.599</td>\n",
       "      <td>8.599</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.583</td>\n",
       "      <td>8.583</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>12.980</td>\n",
       "      <td>12.980</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.803</td>\n",
       "      <td>12.803</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.623</td>\n",
       "      <td>12.623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.348</td>\n",
       "      <td>11.348</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.330</td>\n",
       "      <td>11.330</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>1.019</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.256</td>\n",
       "      <td>1.256</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.522</td>\n",
       "      <td>1.522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.254</td>\n",
       "      <td>4.254</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.330</td>\n",
       "      <td>4.330</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-12.776</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>-12.528</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.592</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-12.794</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-12.555</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.928</td>\n",
       "      <td>3.186</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.910</td>\n",
       "      <td>3.148</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.892</td>\n",
       "      <td>...</td>\n",
       "      <td>3.161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.773</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.772</td>\n",
       "      <td>3.161</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>3.034</td>\n",
       "      <td>3.034</td>\n",
       "      <td>3.201</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.035</td>\n",
       "      <td>3.035</td>\n",
       "      <td>3.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.035</td>\n",
       "      <td>3.035</td>\n",
       "      <td>...</td>\n",
       "      <td>3.159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.039</td>\n",
       "      <td>3.039</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.039</td>\n",
       "      <td>3.039</td>\n",
       "      <td>3.214</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD FV</th>\n",
       "      <td>24.851</td>\n",
       "      <td>24.851</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.606</td>\n",
       "      <td>24.606</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.354</td>\n",
       "      <td>24.354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.418</td>\n",
       "      <td>22.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.386</td>\n",
       "      <td>22.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW FV</th>\n",
       "      <td>101.702</td>\n",
       "      <td>101.702</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.883</td>\n",
       "      <td>99.883</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.038</td>\n",
       "      <td>98.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.528</td>\n",
       "      <td>85.528</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.366</td>\n",
       "      <td>85.366</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VALID PRED E1  VALID POLY E1  VALID POLY PRED E1  VALID LSTSQ E1  \\\n",
       "MAE FV          10.204         10.204               0.000           0.000   \n",
       "RMSE FV         12.980         12.980               0.000           0.000   \n",
       "MAPE FV          1.019          1.019               0.000           0.000   \n",
       "R2 FV           -0.428         -0.428             -12.776           1.000   \n",
       "RAAE FV          0.928          0.928               3.186           0.000   \n",
       "RMAE FV          3.034          3.034               3.201           0.000   \n",
       "FD FV           24.851         24.851               0.000           0.000   \n",
       "DTW FV         101.702        101.702               0.000           0.000   \n",
       "\n",
       "         VALID PRED E10  VALID POLY E10  VALID POLY PRED E10  VALID LSTSQ E10  \\\n",
       "MAE FV           10.023          10.023                0.000            0.000   \n",
       "RMSE FV          12.803          12.803                0.000            0.000   \n",
       "MAPE FV           1.256           1.256                0.000            0.000   \n",
       "R2 FV            -0.381          -0.381              -12.528            1.000   \n",
       "RAAE FV           0.910           0.910                3.148            0.000   \n",
       "RMAE FV           3.035           3.035                3.200            0.000   \n",
       "FD FV            24.606          24.606                0.000            0.000   \n",
       "DTW FV           99.883          99.883                0.000            0.000   \n",
       "\n",
       "         VALID PRED E20  VALID POLY E20  ...  VALID POLY PRED E180  \\\n",
       "MAE FV            9.840           9.840  ...                 0.000   \n",
       "RMSE FV          12.623          12.623  ...                 0.000   \n",
       "MAPE FV           1.522           1.522  ...                 0.000   \n",
       "R2 FV            -0.335          -0.335  ...               -12.592   \n",
       "RAAE FV           0.892           0.892  ...                 3.161   \n",
       "RMAE FV           3.035           3.035  ...                 3.159   \n",
       "FD FV            24.354          24.354  ...                 0.000   \n",
       "DTW FV           98.038          98.038  ...                 0.000   \n",
       "\n",
       "         VALID LSTSQ E180  VALID PRED E190  VALID POLY E190  \\\n",
       "MAE FV              0.000            8.599            8.599   \n",
       "RMSE FV             0.000           11.348           11.348   \n",
       "MAPE FV             0.000            4.254            4.254   \n",
       "R2 FV               1.000           -0.043           -0.043   \n",
       "RAAE FV             0.000            0.773            0.773   \n",
       "RMAE FV             0.000            3.039            3.039   \n",
       "FD FV               0.000           22.418           22.418   \n",
       "DTW FV              0.000           85.528           85.528   \n",
       "\n",
       "         VALID POLY PRED E190  VALID LSTSQ E190  VALID PRED E200  \\\n",
       "MAE FV                  0.000             0.000            8.583   \n",
       "RMSE FV                 0.000             0.000           11.330   \n",
       "MAPE FV                 0.000             0.000            4.330   \n",
       "R2 FV                 -12.794             1.000           -0.039   \n",
       "RAAE FV                   inf             0.000            0.772   \n",
       "RMAE FV                   inf             0.000            3.039   \n",
       "FD FV                   0.000             0.000           22.386   \n",
       "DTW FV                  0.000             0.000           85.366   \n",
       "\n",
       "         VALID POLY E200  VALID POLY PRED E200  VALID LSTSQ E200  \n",
       "MAE FV             8.583                 0.000             0.000  \n",
       "RMSE FV           11.330                 0.000             0.000  \n",
       "MAPE FV            4.330                 0.000             0.000  \n",
       "R2 FV             -0.039               -12.555             1.000  \n",
       "RAAE FV            0.772                 3.161             0.000  \n",
       "RMAE FV            3.039                 3.214             0.000  \n",
       "FD FV             22.386                 0.000             0.000  \n",
       "DTW FV            85.366                 0.000             0.000  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T00:09:10.828196Z",
     "start_time": "2020-12-02T00:09:10.807455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST PRED E1</th>\n",
       "      <th>TEST POLY E1</th>\n",
       "      <th>TEST POLY PRED E1</th>\n",
       "      <th>TEST LSTSQ E1</th>\n",
       "      <th>TEST PRED E10</th>\n",
       "      <th>TEST POLY E10</th>\n",
       "      <th>TEST POLY PRED E10</th>\n",
       "      <th>TEST LSTSQ E10</th>\n",
       "      <th>TEST PRED E20</th>\n",
       "      <th>TEST POLY E20</th>\n",
       "      <th>...</th>\n",
       "      <th>TEST POLY PRED E180</th>\n",
       "      <th>TEST LSTSQ E180</th>\n",
       "      <th>TEST PRED E190</th>\n",
       "      <th>TEST POLY E190</th>\n",
       "      <th>TEST POLY PRED E190</th>\n",
       "      <th>TEST LSTSQ E190</th>\n",
       "      <th>TEST PRED E200</th>\n",
       "      <th>TEST POLY E200</th>\n",
       "      <th>TEST POLY PRED E200</th>\n",
       "      <th>TEST LSTSQ E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE FV</th>\n",
       "      <td>10.216</td>\n",
       "      <td>10.216</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.035</td>\n",
       "      <td>10.035</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.851</td>\n",
       "      <td>9.851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.603</td>\n",
       "      <td>8.603</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.587</td>\n",
       "      <td>8.587</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE FV</th>\n",
       "      <td>12.994</td>\n",
       "      <td>12.994</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.817</td>\n",
       "      <td>12.817</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.636</td>\n",
       "      <td>12.636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.355</td>\n",
       "      <td>11.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.337</td>\n",
       "      <td>11.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE FV</th>\n",
       "      <td>1.054</td>\n",
       "      <td>1.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.553</td>\n",
       "      <td>1.553</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.111</td>\n",
       "      <td>2.111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.368</td>\n",
       "      <td>8.368</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.573</td>\n",
       "      <td>8.573</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 FV</th>\n",
       "      <td>-0.429</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>-12.681</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-12.522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.615</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-12.802</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-12.544</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAAE FV</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.928</td>\n",
       "      <td>3.175</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.911</td>\n",
       "      <td>3.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.893</td>\n",
       "      <td>...</td>\n",
       "      <td>3.161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.773</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.771</td>\n",
       "      <td>3.156</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMAE FV</th>\n",
       "      <td>3.154</td>\n",
       "      <td>3.154</td>\n",
       "      <td>3.347</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.154</td>\n",
       "      <td>3.154</td>\n",
       "      <td>3.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.155</td>\n",
       "      <td>3.155</td>\n",
       "      <td>...</td>\n",
       "      <td>3.327</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.159</td>\n",
       "      <td>3.159</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.159</td>\n",
       "      <td>3.159</td>\n",
       "      <td>3.361</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD FV</th>\n",
       "      <td>25.030</td>\n",
       "      <td>25.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.785</td>\n",
       "      <td>24.785</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.531</td>\n",
       "      <td>24.531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.580</td>\n",
       "      <td>22.580</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.547</td>\n",
       "      <td>22.547</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW FV</th>\n",
       "      <td>102.319</td>\n",
       "      <td>102.319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.492</td>\n",
       "      <td>100.492</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.637</td>\n",
       "      <td>98.637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>86.003</td>\n",
       "      <td>86.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.840</td>\n",
       "      <td>85.840</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TEST PRED E1  TEST POLY E1  TEST POLY PRED E1  TEST LSTSQ E1  \\\n",
       "MAE FV         10.216        10.216              0.000          0.000   \n",
       "RMSE FV        12.994        12.994              0.000          0.000   \n",
       "MAPE FV         1.054         1.054              0.000          0.000   \n",
       "R2 FV          -0.429        -0.429            -12.681          1.000   \n",
       "RAAE FV         0.928         0.928              3.175          0.000   \n",
       "RMAE FV         3.154         3.154              3.347          0.000   \n",
       "FD FV          25.030        25.030              0.000          0.000   \n",
       "DTW FV        102.319       102.319              0.000          0.000   \n",
       "\n",
       "         TEST PRED E10  TEST POLY E10  TEST POLY PRED E10  TEST LSTSQ E10  \\\n",
       "MAE FV          10.035         10.035               0.000           0.000   \n",
       "RMSE FV         12.817         12.817               0.000           0.000   \n",
       "MAPE FV          1.553          1.553               0.000           0.000   \n",
       "R2 FV           -0.382         -0.382             -12.522           1.000   \n",
       "RAAE FV          0.911          0.911               3.144           0.000   \n",
       "RMAE FV          3.154          3.154               3.350           0.000   \n",
       "FD FV           24.785         24.785               0.000           0.000   \n",
       "DTW FV         100.492        100.492               0.000           0.000   \n",
       "\n",
       "         TEST PRED E20  TEST POLY E20  ...  TEST POLY PRED E180  \\\n",
       "MAE FV           9.851          9.851  ...                0.000   \n",
       "RMSE FV         12.636         12.636  ...                0.000   \n",
       "MAPE FV          2.111          2.111  ...                0.000   \n",
       "R2 FV           -0.335         -0.335  ...              -12.615   \n",
       "RAAE FV          0.893          0.893  ...                3.161   \n",
       "RMAE FV          3.155          3.155  ...                3.327   \n",
       "FD FV           24.531         24.531  ...                0.000   \n",
       "DTW FV          98.637         98.637  ...                0.000   \n",
       "\n",
       "         TEST LSTSQ E180  TEST PRED E190  TEST POLY E190  TEST POLY PRED E190  \\\n",
       "MAE FV             0.000           8.603           8.603                0.000   \n",
       "RMSE FV            0.000          11.355          11.355                0.000   \n",
       "MAPE FV            0.000           8.368           8.368                0.000   \n",
       "R2 FV              1.000          -0.042          -0.042              -12.802   \n",
       "RAAE FV            0.000           0.773           0.773                  inf   \n",
       "RMAE FV            0.000           3.159           3.159                  inf   \n",
       "FD FV              0.000          22.580          22.580                0.000   \n",
       "DTW FV             0.000          86.003          86.003                0.000   \n",
       "\n",
       "         TEST LSTSQ E190  TEST PRED E200  TEST POLY E200  TEST POLY PRED E200  \\\n",
       "MAE FV             0.000           8.587           8.587                0.000   \n",
       "RMSE FV            0.000          11.337          11.337                0.000   \n",
       "MAPE FV            0.000           8.573           8.573                0.000   \n",
       "R2 FV              1.000          -0.039          -0.039              -12.544   \n",
       "RAAE FV            0.000           0.771           0.771                3.156   \n",
       "RMAE FV            0.000           3.159           3.159                3.361   \n",
       "FD FV              0.000          22.547          22.547                0.000   \n",
       "DTW FV             0.000          85.840          85.840                0.000   \n",
       "\n",
       "         TEST LSTSQ E200  \n",
       "MAE FV             0.000  \n",
       "RMSE FV            0.000  \n",
       "MAPE FV            0.000  \n",
       "R2 FV              1.000  \n",
       "RAAE FV            0.000  \n",
       "RMAE FV            0.000  \n",
       "FD FV              0.000  \n",
       "DTW FV             0.000  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T00:09:10.858322Z",
     "start_time": "2020-12-02T00:09:10.829746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E1</th>\n",
       "      <th>E10</th>\n",
       "      <th>E20</th>\n",
       "      <th>E30</th>\n",
       "      <th>E40</th>\n",
       "      <th>E50</th>\n",
       "      <th>E60</th>\n",
       "      <th>E70</th>\n",
       "      <th>E80</th>\n",
       "      <th>E90</th>\n",
       "      <th>...</th>\n",
       "      <th>E110</th>\n",
       "      <th>E120</th>\n",
       "      <th>E130</th>\n",
       "      <th>E140</th>\n",
       "      <th>E150</th>\n",
       "      <th>E160</th>\n",
       "      <th>E170</th>\n",
       "      <th>E180</th>\n",
       "      <th>E190</th>\n",
       "      <th>E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN REAL LAMBDA</th>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>...</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN PRED LAMBDA</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TRAIN REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>...</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "      <td>11.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID REAL LAMBDA</th>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>...</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID PRED LAMBDA</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV VALID REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>...</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "      <td>11.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST REAL LAMBDA</th>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>...</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST PRED LAMBDA</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD FV TEST REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>...</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "      <td>11.124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        E1    E10    E20    E30    E40    E50  \\\n",
       "STD FV TRAIN REAL LAMBDA            11.169 11.169 11.169 11.169 11.169 11.169   \n",
       "STD FV TRAIN PRED LAMBDA             0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.169 11.169 11.169 11.169 11.169 11.169   \n",
       "STD FV VALID REAL LAMBDA            11.114 11.114 11.114 11.114 11.114 11.114   \n",
       "STD FV VALID PRED LAMBDA             0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.114 11.114 11.114 11.114 11.114 11.114   \n",
       "STD FV TEST REAL LAMBDA             11.124 11.124 11.124 11.124 11.124 11.124   \n",
       "STD FV TEST PRED LAMBDA              0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  11.124 11.124 11.124 11.124 11.124 11.124   \n",
       "\n",
       "                                       E60    E70    E80    E90  ...   E110  \\\n",
       "STD FV TRAIN REAL LAMBDA            11.169 11.169 11.169 11.169  ... 11.169   \n",
       "STD FV TRAIN PRED LAMBDA             0.000  0.000  0.000  0.000  ...  0.000   \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  0.000  0.000  0.000  0.000  ...  0.000   \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.169 11.169 11.169 11.169  ... 11.169   \n",
       "STD FV VALID REAL LAMBDA            11.114 11.114 11.114 11.114  ... 11.114   \n",
       "STD FV VALID PRED LAMBDA             0.000  0.000  0.000  0.000  ...  0.000   \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  0.000  0.000  0.000  0.000  ...  0.000   \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.114 11.114 11.114 11.114  ... 11.114   \n",
       "STD FV TEST REAL LAMBDA             11.124 11.124 11.124 11.124  ... 11.124   \n",
       "STD FV TEST PRED LAMBDA              0.000  0.000  0.000  0.000  ...  0.000   \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   0.000  0.000  0.000  0.000  ...  0.000   \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  11.124 11.124 11.124 11.124  ... 11.124   \n",
       "\n",
       "                                      E120   E130   E140   E150   E160   E170  \\\n",
       "STD FV TRAIN REAL LAMBDA            11.169 11.169 11.169 11.169 11.169 11.169   \n",
       "STD FV TRAIN PRED LAMBDA             0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.169 11.169 11.169 11.169 11.169 11.169   \n",
       "STD FV VALID REAL LAMBDA            11.114 11.114 11.114 11.114 11.114 11.114   \n",
       "STD FV VALID PRED LAMBDA             0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.114 11.114 11.114 11.114 11.114 11.114   \n",
       "STD FV TEST REAL LAMBDA             11.124 11.124 11.124 11.124 11.124 11.124   \n",
       "STD FV TEST PRED LAMBDA              0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  11.124 11.124 11.124 11.124 11.124 11.124   \n",
       "\n",
       "                                      E180   E190   E200  \n",
       "STD FV TRAIN REAL LAMBDA            11.169 11.169 11.169  \n",
       "STD FV TRAIN PRED LAMBDA             0.000  0.000  0.000  \n",
       "STD FV TRAIN PRED LAMBDA POLY LSTSQ  0.000  0.000  0.000  \n",
       "STD FV TRAIN REAL LAMBDA POLY LSTSQ 11.169 11.169 11.169  \n",
       "STD FV VALID REAL LAMBDA            11.114 11.114 11.114  \n",
       "STD FV VALID PRED LAMBDA             0.000  0.000  0.000  \n",
       "STD FV VALID PRED LAMBDA POLY LSTSQ  0.000  0.000  0.000  \n",
       "STD FV VALID REAL LAMBDA POLY LSTSQ 11.114 11.114 11.114  \n",
       "STD FV TEST REAL LAMBDA             11.124 11.124 11.124  \n",
       "STD FV TEST PRED LAMBDA              0.000  0.000  0.000  \n",
       "STD FV TEST PRED LAMBDA POLY LSTSQ   0.000  0.000  0.000  \n",
       "STD FV TEST REAL LAMBDA POLY LSTSQ  11.124 11.124 11.124  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T00:09:10.882577Z",
     "start_time": "2020-12-02T00:09:10.859818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E1</th>\n",
       "      <th>E10</th>\n",
       "      <th>E20</th>\n",
       "      <th>E30</th>\n",
       "      <th>E40</th>\n",
       "      <th>E50</th>\n",
       "      <th>E60</th>\n",
       "      <th>E70</th>\n",
       "      <th>E80</th>\n",
       "      <th>E90</th>\n",
       "      <th>...</th>\n",
       "      <th>E110</th>\n",
       "      <th>E120</th>\n",
       "      <th>E130</th>\n",
       "      <th>E140</th>\n",
       "      <th>E150</th>\n",
       "      <th>E160</th>\n",
       "      <th>E170</th>\n",
       "      <th>E180</th>\n",
       "      <th>E190</th>\n",
       "      <th>E200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN REAL LAMBDA</th>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN PRED LAMBDA</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TRAIN REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID REAL LAMBDA</th>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID PRED LAMBDA</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV VALID REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST REAL LAMBDA</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST PRED LAMBDA</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST PRED LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN FV TEST REAL LAMBDA POLY LSTSQ</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         E1    E10    E20    E30    E40  \\\n",
       "MEAN FV TRAIN REAL LAMBDA            -0.078 -0.078 -0.078 -0.078 -0.078   \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.000 -0.004 -0.007 -0.011 -0.014   \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.000 -0.004 -0.007 -0.011 -0.014   \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.078 -0.078 -0.078 -0.078 -0.078   \n",
       "MEAN FV VALID REAL LAMBDA            -0.083 -0.083 -0.083 -0.083 -0.083   \n",
       "MEAN FV VALID PRED LAMBDA            -0.000 -0.004 -0.007 -0.011 -0.014   \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.000 -0.004 -0.007 -0.011 -0.014   \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.083 -0.083 -0.083 -0.083 -0.083   \n",
       "MEAN FV TEST REAL LAMBDA             -0.080 -0.080 -0.080 -0.080 -0.080   \n",
       "MEAN FV TEST PRED LAMBDA             -0.000 -0.004 -0.007 -0.011 -0.014   \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  -0.000 -0.004 -0.007 -0.011 -0.014   \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.080 -0.080 -0.080 -0.080 -0.080   \n",
       "\n",
       "                                        E50    E60    E70    E80    E90  ...  \\\n",
       "MEAN FV TRAIN REAL LAMBDA            -0.078 -0.078 -0.078 -0.078 -0.078  ...   \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.017 -0.021 -0.024 -0.027 -0.029  ...   \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.017 -0.021 -0.024 -0.027 -0.029  ...   \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.078 -0.078 -0.078 -0.078 -0.078  ...   \n",
       "MEAN FV VALID REAL LAMBDA            -0.083 -0.083 -0.083 -0.083 -0.083  ...   \n",
       "MEAN FV VALID PRED LAMBDA            -0.017 -0.021 -0.024 -0.027 -0.029  ...   \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.017 -0.021 -0.024 -0.027 -0.029  ...   \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.083 -0.083 -0.083 -0.083 -0.083  ...   \n",
       "MEAN FV TEST REAL LAMBDA             -0.080 -0.080 -0.080 -0.080 -0.080  ...   \n",
       "MEAN FV TEST PRED LAMBDA             -0.017 -0.021 -0.024 -0.027 -0.029  ...   \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  -0.017 -0.021 -0.024 -0.027 -0.029  ...   \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.080 -0.080 -0.080 -0.080 -0.080  ...   \n",
       "\n",
       "                                       E110   E120   E130   E140   E150  \\\n",
       "MEAN FV TRAIN REAL LAMBDA            -0.078 -0.078 -0.078 -0.078 -0.078   \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.035 -0.037 -0.039 -0.041 -0.043   \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.035 -0.037 -0.039 -0.041 -0.043   \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.078 -0.078 -0.078 -0.078 -0.078   \n",
       "MEAN FV VALID REAL LAMBDA            -0.083 -0.083 -0.083 -0.083 -0.083   \n",
       "MEAN FV VALID PRED LAMBDA            -0.035 -0.037 -0.039 -0.041 -0.043   \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.035 -0.037 -0.039 -0.041 -0.043   \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.083 -0.083 -0.083 -0.083 -0.083   \n",
       "MEAN FV TEST REAL LAMBDA             -0.080 -0.080 -0.080 -0.080 -0.080   \n",
       "MEAN FV TEST PRED LAMBDA             -0.035 -0.037 -0.039 -0.041 -0.043   \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  -0.035 -0.037 -0.039 -0.041 -0.043   \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.080 -0.080 -0.080 -0.080 -0.080   \n",
       "\n",
       "                                       E160   E170   E180   E190   E200  \n",
       "MEAN FV TRAIN REAL LAMBDA            -0.078 -0.078 -0.078 -0.078 -0.078  \n",
       "MEAN FV TRAIN PRED LAMBDA            -0.045 -0.047 -0.048 -0.050 -0.051  \n",
       "MEAN FV TRAIN PRED LAMBDA POLY LSTSQ -0.045 -0.047 -0.048 -0.050 -0.051  \n",
       "MEAN FV TRAIN REAL LAMBDA POLY LSTSQ -0.078 -0.078 -0.078 -0.078 -0.078  \n",
       "MEAN FV VALID REAL LAMBDA            -0.083 -0.083 -0.083 -0.083 -0.083  \n",
       "MEAN FV VALID PRED LAMBDA            -0.045 -0.047 -0.048 -0.050 -0.051  \n",
       "MEAN FV VALID PRED LAMBDA POLY LSTSQ -0.045 -0.047 -0.048 -0.050 -0.051  \n",
       "MEAN FV VALID REAL LAMBDA POLY LSTSQ -0.083 -0.083 -0.083 -0.083 -0.083  \n",
       "MEAN FV TEST REAL LAMBDA             -0.080 -0.080 -0.080 -0.080 -0.080  \n",
       "MEAN FV TEST PRED LAMBDA             -0.045 -0.047 -0.048 -0.050 -0.051  \n",
       "MEAN FV TEST PRED LAMBDA POLY LSTSQ  -0.045 -0.047 -0.048 -0.050 -0.051  \n",
       "MEAN FV TEST REAL LAMBDA POLY LSTSQ  -0.080 -0.080 -0.080 -0.080 -0.080  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Lambda-Net Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:35.602271Z",
     "start_time": "2020-12-02T00:09:10.884339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b2df2a5fb14300b291aefd948edefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0d254dccb74d6e999451020c24d97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if each_epochs_save == None:\n",
    "    \n",
    "    variable_names = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    variable_names_list = [variable + '_' for variable in variable_names[:n]]\n",
    "    variable_names_list.append('FV_')\n",
    "    \n",
    "    polynomial_real_list = [clf[0][0] for clf in clf_list] \n",
    "    polynomial_lstsq_pred_lambda_list = [clf[0][1] for clf in clf_list] \n",
    "    polynomial_lstsq_real_lambda_list = [clf[0][2] for clf in clf_list] \n",
    "    \n",
    "    polynomial_real_df = pd.DataFrame(polynomial_real_list)\n",
    "\n",
    "    y_train_real_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][0])))\n",
    "    y_train_pred_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][1])))\n",
    "    y_train_pred_lambda_poly_lstsq_list = np.zeros((len(clf_list), len(clf_list[0][2][2])))\n",
    "    X_train_lambda_list = np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][3].shape)]][0])\n",
    "    y_valid_real_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][4])))\n",
    "    y_valid_pred_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][5])))\n",
    "    y_valid_pred_lambda_poly_lstsq_list = np.zeros((len(clf_list), len(clf_list[0][2][6])))\n",
    "    X_valid_lambda_list = np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][7].shape)]][0])\n",
    "    y_test_real_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][8])))\n",
    "    y_test_pred_lambda_list = np.zeros((len(clf_list), len(clf_list[0][2][9])))\n",
    "    y_test_pred_lambda_poly_lstsq_list = np.zeros((len(clf_list), len(clf_list[0][2][10])))\n",
    "    X_test_lambda_list = np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][11].shape)]][0])\n",
    "\n",
    "    for index, (y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, X_train_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, X_valid_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, X_test_lambda) in enumerate([clf[2] for clf in clf_list]):\n",
    "        y_train_real_lambda_list[index] = y_train_real_lambda.ravel()\n",
    "        y_train_pred_lambda_list[index] = y_train_pred_lambda.ravel()\n",
    "        y_train_pred_lambda_poly_lstsq_list[index] = y_train_pred_lambda_poly_lstsq.ravel()\n",
    "        X_train_lambda_list[index] = X_train_lambda#.ravel()\n",
    "\n",
    "        y_valid_real_lambda_list[index] = y_valid_real_lambda.ravel()\n",
    "        y_valid_pred_lambda_list[index] = y_valid_pred_lambda.ravel()\n",
    "        y_valid_pred_lambda_poly_lstsq_list[index] = y_valid_pred_lambda_poly_lstsq.ravel()\n",
    "        X_valid_lambda_list[index] = X_valid_lambda#.ravel()\n",
    "\n",
    "        y_test_real_lambda_list[index] = y_test_real_lambda.ravel()\n",
    "        y_test_pred_lambda_list[index] = y_test_pred_lambda.ravel()\n",
    "        y_test_pred_lambda_poly_lstsq_list[index] = y_test_pred_lambda_poly_lstsq.ravel()\n",
    "        X_test_lambda_list[index] = X_test_lambda#.ravel()\n",
    "    \n",
    "    #add x_data before each pred\n",
    "    y_train_real_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_real_lambda.reshape(len(y_train_real_lambda),1)], axis=1).ravel() for X_train_lambda, y_train_real_lambda in zip(X_train_lambda_list, y_train_real_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_list[0].shape[0])]).ravel())\n",
    "    y_valid_real_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_real_lambda.reshape(len(y_valid_real_lambda),1)], axis=1).ravel() for X_valid_lambda, y_valid_real_lambda in zip(X_valid_lambda_list, y_valid_real_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_list[0].shape[0])]).ravel())\n",
    "    y_test_real_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_real_lambda.reshape(len(y_test_real_lambda),1)], axis=1).ravel() for X_test_lambda, y_test_real_lambda in zip(X_test_lambda_list, y_test_real_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_list[0].shape[0])]).ravel())\n",
    "    y_train_pred_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda.reshape(len(y_train_pred_lambda),1)], axis=1).ravel() for X_train_lambda, y_train_pred_lambda in zip(X_train_lambda_list, y_train_pred_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_list[0].shape[0])]).ravel())\n",
    "    y_valid_pred_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda.reshape(len(y_valid_pred_lambda),1)], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda in zip(X_valid_lambda_list, y_valid_pred_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_list[0].shape[0])]).ravel())\n",
    "    y_test_pred_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda.reshape(len(y_test_pred_lambda),1)], axis=1).ravel() for X_test_lambda, y_test_pred_lambda in zip(X_test_lambda_list, y_test_pred_lambda_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_list[0].shape[0])]).ravel())\n",
    "    y_train_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda_poly_lstsq.reshape(len(y_train_pred_lambda_poly_lstsq),1)], axis=1).ravel() for X_train_lambda, y_train_pred_lambda_poly_lstsq in zip(X_train_lambda_list, y_train_pred_lambda_poly_lstsq_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_list[0].shape[0])]).ravel())\n",
    "    y_valid_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda_poly_lstsq.reshape(len(y_valid_pred_lambda_poly_lstsq),1)], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda_poly_lstsq in zip(X_valid_lambda_list, y_valid_pred_lambda_poly_lstsq_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_list[0].shape[0])]).ravel())\n",
    "    y_test_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda_poly_lstsq.reshape(len(y_test_pred_lambda_poly_lstsq),1)], axis=1).ravel() for X_test_lambda, y_test_pred_lambda_poly_lstsq in zip(X_test_lambda_list, y_test_pred_lambda_poly_lstsq_list)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_list[0].shape[0])]).ravel())    \n",
    "    \n",
    "    y_train_real_lambda_df = pd.concat([polynomial_real_df, y_train_real_lambda_df], axis=1)\n",
    "    y_valid_real_lambda_df = pd.concat([polynomial_real_df, y_valid_real_lambda_df], axis=1)\n",
    "    y_test_real_lambda_df = pd.concat([polynomial_real_df, y_test_real_lambda_df], axis=1)\n",
    "    y_train_pred_lambda_df = pd.concat([polynomial_real_df, y_train_pred_lambda_df], axis=1)\n",
    "    y_valid_pred_lambda_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_df], axis=1)\n",
    "    y_test_pred_lambda_df = pd.concat([polynomial_real_df, y_test_pred_lambda_df], axis=1)\n",
    "    y_train_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_train_pred_lambda_poly_lstsq_df], axis=1)\n",
    "    y_valid_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_poly_lstsq_df], axis=1)\n",
    "    y_test_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_test_pred_lambda_poly_lstsq_df], axis=1)\n",
    "       \n",
    "    path_y_train_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_real_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_valid_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_real_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_test_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_real_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_train_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_valid_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_test_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_train_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_poly_lstsq_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_valid_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_poly_lstsq_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "    path_y_test_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_poly_lstsq_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "   \n",
    "    y_train_real_lambda_df.to_csv(path_y_train_real_lambda, sep=',', index=False)\n",
    "    y_valid_real_lambda_df.to_csv(path_y_valid_real_lambda, sep=',', index=False)\n",
    "    y_test_real_lambda_df.to_csv(path_y_test_real_lambda, sep=',', index=False)\n",
    "    y_train_pred_lambda_df.to_csv(path_y_train_pred_lambda, sep=',', index=False)\n",
    "    y_valid_pred_lambda_df.to_csv(path_y_valid_pred_lambda, sep=',', index=False)\n",
    "    y_test_pred_lambda_df.to_csv(path_y_test_pred_lambda, sep=',', index=False)\n",
    "    y_train_pred_lambda_poly_lstsq_df.to_csv(path_y_train_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "    y_valid_pred_lambda_poly_lstsq_df.to_csv(path_y_valid_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "    y_test_pred_lambda_poly_lstsq_df.to_csv(path_y_test_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    variable_names = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    variable_names_list = [variable + '_' for variable in variable_names[:n]]\n",
    "    variable_names_list.append('FV_')\n",
    "    \n",
    "    polynomial_real_list = [clf[0][0] for clf in clf_list]\n",
    "    polynomial_lstsq_pred_lambda_list = [clf[0][1] for clf in clf_list]\n",
    "    polynomial_lstsq_real_lambda_list = [clf[0][2] for clf in clf_list]\n",
    "    \n",
    "    polynomial_real_df = pd.DataFrame(polynomial_real_list)\n",
    "    \n",
    "    y_train_real_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][0]), 1)) for i in epochs_save_range]\n",
    "    y_train_pred_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][1]), 1)) for i in epochs_save_range]\n",
    "    y_train_pred_lambda_poly_lstsq_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][2]), 1)) for i in epochs_save_range]\n",
    "    X_train_lambda_list = [np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][0][3].shape)]][0]) for i in epochs_save_range]\n",
    "    y_valid_real_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][4]), 1)) for i in epochs_save_range]\n",
    "    y_valid_pred_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][5]), 1)) for i in epochs_save_range]\n",
    "    y_valid_pred_lambda_poly_lstsq_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][6]), 1)) for i in epochs_save_range]\n",
    "    X_valid_lambda_list = [np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][0][7].shape)]][0]) for i in epochs_save_range]\n",
    "    y_test_real_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][8]), 1)) for i in epochs_save_range]\n",
    "    y_test_pred_lambda_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][9]), 1)) for i in epochs_save_range]\n",
    "    y_test_pred_lambda_poly_lstsq_list = [np.zeros((len(clf_list), len(clf_list[0][2][0][10]), 1)) for i in epochs_save_range]\n",
    "    X_test_lambda_list = [np.zeros([(a, *rest) for a, rest in [(len(clf_list), clf_list[0][2][0][11].shape)]][0]) for i in epochs_save_range]\n",
    "    \n",
    "    for i, y_data_list_per_epoch in tqdm(enumerate([clf[2] for clf in clf_list]), total=len(clf_list)):\n",
    "        \n",
    "        for index, (y_train_real_lambda, y_train_pred_lambda, y_train_pred_lambda_poly_lstsq, X_train_lambda, y_valid_real_lambda, y_valid_pred_lambda, y_valid_pred_lambda_poly_lstsq, X_valid_lambda, y_test_real_lambda, y_test_pred_lambda, y_test_pred_lambda_poly_lstsq, X_test_lambda) in enumerate(y_data_list_per_epoch):\n",
    "            y_train_real_lambda_list[index][i] = y_train_real_lambda#.ravel()\n",
    "            y_train_pred_lambda_list[index][i] = y_train_pred_lambda#.ravel()\n",
    "            y_train_pred_lambda_poly_lstsq_list[index][i] = y_train_pred_lambda_poly_lstsq#.ravel()\n",
    "            X_train_lambda_list[index][i] = X_train_lambda#.ravel()\n",
    "            \n",
    "            y_valid_real_lambda_list[index][i] = y_valid_real_lambda#.ravel()\n",
    "            y_valid_pred_lambda_list[index][i] = y_valid_pred_lambda#.ravel()\n",
    "            y_valid_pred_lambda_poly_lstsq_list[index][i] = y_valid_pred_lambda_poly_lstsq#.ravel()\n",
    "            X_valid_lambda_list[index][i] = X_valid_lambda#.ravel()\n",
    "            \n",
    "            y_test_real_lambda_list[index][i] = y_test_real_lambda#.ravel()\n",
    "            y_test_pred_lambda_list[index][i] = y_test_pred_lambda#.ravel()\n",
    "            y_test_pred_lambda_poly_lstsq_list[index][i] = y_test_pred_lambda_poly_lstsq#.ravel()\n",
    "            X_test_lambda_list[index][i] = X_test_lambda#.ravel()\n",
    "    \n",
    "    for i, (y_train_real_lambda_by_epoch, y_train_pred_lambda_by_epoch, y_train_pred_lambda_poly_lstsq_by_epoch, X_train_lambda_by_epoch, y_valid_real_lambda_by_epoch, y_valid_pred_lambda_by_epoch, y_valid_pred_lambda_poly_lstsq_by_epoch, X_valid_lambda_by_epoch, y_test_real_lambda_by_epoch, y_test_pred_lambda_by_epoch, y_test_pred_lambda_poly_lstsq_by_epoch, X_test_lambda_by_epoch) in tqdm(enumerate(zip(y_train_real_lambda_list, y_train_pred_lambda_list, y_train_pred_lambda_poly_lstsq_list, X_train_lambda_list, y_valid_real_lambda_list, y_valid_pred_lambda_list, y_valid_pred_lambda_poly_lstsq_list, X_valid_lambda_list, y_test_real_lambda_list, y_test_pred_lambda_list, y_test_pred_lambda_poly_lstsq_list, X_test_lambda_list)), total=len(y_train_pred_lambda_list)):\n",
    "        index = (i+1)*each_epochs_save if each_epochs_save==1 else i*each_epochs_save if i > 1 else each_epochs_save if i==1 else 1\n",
    "        \n",
    "        y_train_real_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_real_lambda], axis=1).ravel() for X_train_lambda, y_train_real_lambda in zip(X_train_lambda_by_epoch, y_train_real_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_valid_real_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_real_lambda], axis=1).ravel() for X_valid_lambda, y_valid_real_lambda in zip(X_valid_lambda_by_epoch, y_valid_real_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_test_real_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_real_lambda], axis=1).ravel() for X_test_lambda, y_test_real_lambda in zip(X_test_lambda_by_epoch, y_test_real_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_train_pred_lambda_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda], axis=1).ravel() for X_train_lambda, y_train_pred_lambda in zip(X_train_lambda_by_epoch, y_train_pred_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_valid_pred_lambda_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda in zip(X_valid_lambda_by_epoch, y_valid_pred_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_test_pred_lambda_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda], axis=1).ravel() for X_test_lambda, y_test_pred_lambda in zip(X_test_lambda_by_epoch, y_test_pred_lambda_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_train_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_train_lambda, y_train_pred_lambda_poly_lstsq], axis=1).ravel() for X_train_lambda, y_train_pred_lambda_poly_lstsq in zip(X_train_lambda_by_epoch, y_train_pred_lambda_poly_lstsq_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_train_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_valid_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_valid_lambda, y_valid_pred_lambda_poly_lstsq], axis=1).ravel() for X_valid_lambda, y_valid_pred_lambda_poly_lstsq in zip(X_valid_lambda_by_epoch, y_valid_pred_lambda_poly_lstsq_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_valid_lambda_by_epoch[0].shape[0])]).ravel())\n",
    "        y_test_pred_lambda_poly_lstsq_df = pd.DataFrame([np.concatenate([X_test_lambda, y_test_pred_lambda_poly_lstsq], axis=1).ravel() for X_test_lambda, y_test_pred_lambda_poly_lstsq in zip(X_test_lambda_by_epoch, y_test_pred_lambda_poly_lstsq_by_epoch)], columns=np.array([[variable_name + str(i+1) for variable_name in variable_names_list] for i in range(X_test_lambda_by_epoch[0].shape[0])]).ravel())    \n",
    "\n",
    "        y_train_real_lambda_df = pd.concat([polynomial_real_df, y_train_real_lambda_df], axis=1)\n",
    "        y_valid_real_lambda_df = pd.concat([polynomial_real_df, y_valid_real_lambda_df], axis=1)\n",
    "        y_test_real_lambda_df = pd.concat([polynomial_real_df, y_test_real_lambda_df], axis=1)\n",
    "        y_train_pred_lambda_df = pd.concat([polynomial_real_df, y_train_pred_lambda_df], axis=1)\n",
    "        y_valid_pred_lambda_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_df], axis=1)\n",
    "        y_test_pred_lambda_df = pd.concat([polynomial_real_df, y_test_pred_lambda_df], axis=1)\n",
    "        y_train_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_train_pred_lambda_poly_lstsq_df], axis=1)\n",
    "        y_valid_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_valid_pred_lambda_poly_lstsq_df], axis=1)\n",
    "        y_test_pred_lambda_poly_lstsq_df = pd.concat([polynomial_real_df, y_test_pred_lambda_poly_lstsq_df], axis=1)\n",
    "\n",
    "        path_y_train_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_real_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_valid_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_real_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_test_real_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_real_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_train_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_valid_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_test_pred_lambda = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_train_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_train_pred_lambda_poly_lstsq_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_valid_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_valid_pred_lambda_poly_lstsq_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "        path_y_test_pred_lambda_poly_lstsq = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/y_test_pred_lambda_poly_lstsq_' + 'epoch_' + str(index).zfill(3) + '_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "        y_train_real_lambda_df.to_csv(path_y_train_real_lambda, sep=',', index=False)\n",
    "        y_valid_real_lambda_df.to_csv(path_y_valid_real_lambda, sep=',', index=False)\n",
    "        y_test_real_lambda_df.to_csv(path_y_test_real_lambda, sep=',', index=False)         \n",
    "        y_train_pred_lambda_df.to_csv(path_y_train_pred_lambda, sep=',', index=False)\n",
    "        y_valid_pred_lambda_df.to_csv(path_y_valid_pred_lambda, sep=',', index=False)\n",
    "        y_test_pred_lambda_df.to_csv(path_y_test_pred_lambda, sep=',', index=False)    \n",
    "        y_train_pred_lambda_poly_lstsq_df.to_csv(path_y_train_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "        y_valid_pred_lambda_poly_lstsq_df.to_csv(path_y_valid_pred_lambda_poly_lstsq, sep=',', index=False)\n",
    "        y_test_pred_lambda_poly_lstsq_df.to_csv(path_y_test_pred_lambda_poly_lstsq, sep=',', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:35.629658Z",
     "start_time": "2020-12-02T01:37:35.604871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0012</th>\n",
       "      <th>0020</th>\n",
       "      <th>0021</th>\n",
       "      <th>0030</th>\n",
       "      <th>...</th>\n",
       "      <th>a_249</th>\n",
       "      <th>b_249</th>\n",
       "      <th>c_249</th>\n",
       "      <th>d_249</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>a_250</th>\n",
       "      <th>b_250</th>\n",
       "      <th>c_250</th>\n",
       "      <th>d_250</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>-9.400</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-7.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.960</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>0.530</td>\n",
       "      <td>19.032</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>23.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.900</td>\n",
       "      <td>9.400</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>7.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-6.100</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>9.500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.730</td>\n",
       "      <td>1.935</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-13.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>9.700</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.100</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-34.270</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-7.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.800</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.710</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>9.774</td>\n",
       "      <td>0.910</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>7.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.340</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>1.342</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>3.687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0000   0001   0002   0003   0010   0011   0012   0020   0021   0030  ...  \\\n",
       "0  6.300 -7.200 -9.400  8.900 -3.000 -3.800 -4.300 -6.500  8.800 -7.400  ...   \n",
       "1 -9.900  9.400 -6.000  7.800  0.800 -1.300 -2.900 -6.100 -4.500  9.500  ...   \n",
       "2 -8.900  6.900 -4.200  9.700 -2.600 -8.000 -4.100 -7.500 -0.300 -2.900  ...   \n",
       "3  4.200 -4.400  7.500 -1.700  9.600  9.800 -8.600 -4.200 -9.200 -2.000  ...   \n",
       "4  0.200 -0.800 -4.400 -6.500  3.000  2.600 -7.700  9.300 -8.800 -7.200  ...   \n",
       "\n",
       "   a_249  b_249  c_249  d_249  FV_249  a_250  b_250  c_250  d_250  FV_250  \n",
       "0  0.380  0.960 -0.820  0.530  19.032  0.480  0.970 -1.000  0.350  23.972  \n",
       "1 -0.890 -0.980 -0.440  0.730   1.935 -0.040  0.630 -0.100  0.170 -13.036  \n",
       "2 -0.930 -0.730 -0.910 -0.980 -34.270  0.330 -0.210  0.120 -0.100  -7.948  \n",
       "3  0.220  0.680  0.710 -0.460   9.774  0.910 -0.130  0.050 -0.910   7.523  \n",
       "4  0.280  0.340 -0.520 -0.690   1.342 -0.280 -0.520  0.070 -0.370   3.687  \n",
       "\n",
       "[5 rows x 1285 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_real_lambda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:35.703897Z",
     "start_time": "2020-12-02T01:37:35.631354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0012</th>\n",
       "      <th>0020</th>\n",
       "      <th>0021</th>\n",
       "      <th>0030</th>\n",
       "      <th>...</th>\n",
       "      <th>a_249</th>\n",
       "      <th>b_249</th>\n",
       "      <th>c_249</th>\n",
       "      <th>d_249</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>a_250</th>\n",
       "      <th>b_250</th>\n",
       "      <th>c_250</th>\n",
       "      <th>d_250</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>-9.400</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-7.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.960</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.900</td>\n",
       "      <td>9.400</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>7.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-6.100</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>9.500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-9.596</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-9.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>9.700</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.100</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-8.839</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-8.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.800</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.710</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>5.124</td>\n",
       "      <td>0.910</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>5.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.340</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>1.549</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>1.549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0000   0001   0002   0003   0010   0011   0012   0020   0021   0030  ...  \\\n",
       "0  6.300 -7.200 -9.400  8.900 -3.000 -3.800 -4.300 -6.500  8.800 -7.400  ...   \n",
       "1 -9.900  9.400 -6.000  7.800  0.800 -1.300 -2.900 -6.100 -4.500  9.500  ...   \n",
       "2 -8.900  6.900 -4.200  9.700 -2.600 -8.000 -4.100 -7.500 -0.300 -2.900  ...   \n",
       "3  4.200 -4.400  7.500 -1.700  9.600  9.800 -8.600 -4.200 -9.200 -2.000  ...   \n",
       "4  0.200 -0.800 -4.400 -6.500  3.000  2.600 -7.700  9.300 -8.800 -7.200  ...   \n",
       "\n",
       "   a_249  b_249  c_249  d_249  FV_249  a_250  b_250  c_250  d_250  FV_250  \n",
       "0  0.380  0.960 -0.820  0.530   0.087  0.480  0.970 -1.000  0.350   0.087  \n",
       "1 -0.890 -0.980 -0.440  0.730  -9.596 -0.040  0.630 -0.100  0.170  -9.596  \n",
       "2 -0.930 -0.730 -0.910 -0.980  -8.839  0.330 -0.210  0.120 -0.100  -8.839  \n",
       "3  0.220  0.680  0.710 -0.460   5.124  0.910 -0.130  0.050 -0.910   5.124  \n",
       "4  0.280  0.340 -0.520 -0.690   1.549 -0.280 -0.520  0.070 -0.370   1.549  \n",
       "\n",
       "[5 rows x 1285 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_lambda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:35.726782Z",
     "start_time": "2020-12-02T01:37:35.705641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0012</th>\n",
       "      <th>0020</th>\n",
       "      <th>0021</th>\n",
       "      <th>0030</th>\n",
       "      <th>...</th>\n",
       "      <th>a_249</th>\n",
       "      <th>b_249</th>\n",
       "      <th>c_249</th>\n",
       "      <th>d_249</th>\n",
       "      <th>FV_249</th>\n",
       "      <th>a_250</th>\n",
       "      <th>b_250</th>\n",
       "      <th>c_250</th>\n",
       "      <th>d_250</th>\n",
       "      <th>FV_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>-9.400</td>\n",
       "      <td>8.900</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>8.800</td>\n",
       "      <td>-7.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.960</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.900</td>\n",
       "      <td>9.400</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>7.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-6.100</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>9.500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-9.596</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-9.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>9.700</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.100</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-8.839</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-8.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>9.600</td>\n",
       "      <td>9.800</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-9.200</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.710</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>5.124</td>\n",
       "      <td>0.910</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>5.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-4.400</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-7.700</td>\n",
       "      <td>9.300</td>\n",
       "      <td>-8.800</td>\n",
       "      <td>-7.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.340</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>1.549</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>1.549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0000   0001   0002   0003   0010   0011   0012   0020   0021   0030  ...  \\\n",
       "0  6.300 -7.200 -9.400  8.900 -3.000 -3.800 -4.300 -6.500  8.800 -7.400  ...   \n",
       "1 -9.900  9.400 -6.000  7.800  0.800 -1.300 -2.900 -6.100 -4.500  9.500  ...   \n",
       "2 -8.900  6.900 -4.200  9.700 -2.600 -8.000 -4.100 -7.500 -0.300 -2.900  ...   \n",
       "3  4.200 -4.400  7.500 -1.700  9.600  9.800 -8.600 -4.200 -9.200 -2.000  ...   \n",
       "4  0.200 -0.800 -4.400 -6.500  3.000  2.600 -7.700  9.300 -8.800 -7.200  ...   \n",
       "\n",
       "   a_249  b_249  c_249  d_249  FV_249  a_250  b_250  c_250  d_250  FV_250  \n",
       "0  0.380  0.960 -0.820  0.530   0.087  0.480  0.970 -1.000  0.350   0.087  \n",
       "1 -0.890 -0.980 -0.440  0.730  -9.596 -0.040  0.630 -0.100  0.170  -9.596  \n",
       "2 -0.930 -0.730 -0.910 -0.980  -8.839  0.330 -0.210  0.120 -0.100  -8.839  \n",
       "3  0.220  0.680  0.710 -0.460   5.124  0.910 -0.130  0.050 -0.910   5.124  \n",
       "4  0.280  0.340 -0.520 -0.690   1.549 -0.280 -0.520  0.070 -0.370   1.549  \n",
       "\n",
       "[5 rows x 1285 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_lambda_poly_lstsq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:39.045725Z",
     "start_time": "2020-12-02T01:37:35.728710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4101770b3a461fa38e5872603ace49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list_total = []\n",
    "metric_list_total = []\n",
    "\n",
    "val_loss_list_total = []\n",
    "val_metric_list_total = []\n",
    "\n",
    "for _, entry in tqdm(enumerate(clf_list)):\n",
    "    entry = entry[3]\n",
    "    loss_list = []\n",
    "    metric_list = []\n",
    "    val_loss_list = []\n",
    "    val_metric_list = []\n",
    "    for i in range(epochs):  \n",
    "        loss_list.append(entry['loss'][i])\n",
    "        metric_list.append(entry['mean_absolute_percentage_error_keras'][i])\n",
    "        val_loss_list.append(entry['val_loss'][i])\n",
    "        val_metric_list.append(entry['val_mean_absolute_percentage_error_keras'][i])\n",
    "    loss_list_total.append(loss_list)\n",
    "    metric_list_total.append(metric_list)\n",
    "    val_loss_list_total.append(val_loss_list)\n",
    "    val_metric_list_total.append(val_metric_list)\n",
    "\n",
    "loss_df = pd.DataFrame(data=loss_list_total, columns=['loss_epoch_' + str(i+1) for i in range(epochs)])\n",
    "metric_df = pd.DataFrame(data=metric_list_total, columns=['metric_epoch_' + str(i+1) for i in range(epochs)]) \n",
    "val_loss_df = pd.DataFrame(data=val_loss_list_total, columns=['val_loss_epoch_' + str(i+1) for i in range(epochs)])\n",
    "val_metric_df = pd.DataFrame(data=val_metric_list_total, columns=['val_metric_epoch_' + str(i+1) for i in range(epochs)]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:53.916367Z",
     "start_time": "2020-12-02T01:37:39.047645Z"
    }
   },
   "outputs": [],
   "source": [
    "path_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_val_loss = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_loss_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "path_val_metric = './data/weights/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/history_val_metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.txt'\n",
    "\n",
    "loss_df.to_csv(path_loss, index=None, sep=',')\n",
    "metric_df.to_csv(path_metric, index=None, sep=',')\n",
    "val_loss_df.to_csv(path_val_loss, index=None, sep=',')\n",
    "val_metric_df.to_csv(path_val_metric, index=None, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:54.660728Z",
     "start_time": "2020-12-02T01:37:53.920866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_epoch_1</th>\n",
       "      <th>loss_epoch_2</th>\n",
       "      <th>loss_epoch_3</th>\n",
       "      <th>loss_epoch_4</th>\n",
       "      <th>loss_epoch_5</th>\n",
       "      <th>loss_epoch_6</th>\n",
       "      <th>loss_epoch_7</th>\n",
       "      <th>loss_epoch_8</th>\n",
       "      <th>loss_epoch_9</th>\n",
       "      <th>loss_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_epoch_191</th>\n",
       "      <th>loss_epoch_192</th>\n",
       "      <th>loss_epoch_193</th>\n",
       "      <th>loss_epoch_194</th>\n",
       "      <th>loss_epoch_195</th>\n",
       "      <th>loss_epoch_196</th>\n",
       "      <th>loss_epoch_197</th>\n",
       "      <th>loss_epoch_198</th>\n",
       "      <th>loss_epoch_199</th>\n",
       "      <th>loss_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.233</td>\n",
       "      <td>10.212</td>\n",
       "      <td>10.191</td>\n",
       "      <td>10.170</td>\n",
       "      <td>10.149</td>\n",
       "      <td>10.129</td>\n",
       "      <td>10.109</td>\n",
       "      <td>10.089</td>\n",
       "      <td>10.069</td>\n",
       "      <td>10.050</td>\n",
       "      <td>...</td>\n",
       "      <td>8.598</td>\n",
       "      <td>8.596</td>\n",
       "      <td>8.594</td>\n",
       "      <td>8.593</td>\n",
       "      <td>8.591</td>\n",
       "      <td>8.589</td>\n",
       "      <td>8.588</td>\n",
       "      <td>8.586</td>\n",
       "      <td>8.584</td>\n",
       "      <td>8.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.348</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.324</td>\n",
       "      <td>2.313</td>\n",
       "      <td>2.301</td>\n",
       "      <td>2.290</td>\n",
       "      <td>2.278</td>\n",
       "      <td>2.267</td>\n",
       "      <td>2.256</td>\n",
       "      <td>2.245</td>\n",
       "      <td>...</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.689</td>\n",
       "      <td>1.689</td>\n",
       "      <td>1.688</td>\n",
       "      <td>1.688</td>\n",
       "      <td>1.688</td>\n",
       "      <td>1.687</td>\n",
       "      <td>1.687</td>\n",
       "      <td>1.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.700</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.700</td>\n",
       "      <td>4.700</td>\n",
       "      <td>...</td>\n",
       "      <td>4.204</td>\n",
       "      <td>4.204</td>\n",
       "      <td>4.204</td>\n",
       "      <td>4.204</td>\n",
       "      <td>4.204</td>\n",
       "      <td>4.203</td>\n",
       "      <td>4.203</td>\n",
       "      <td>4.203</td>\n",
       "      <td>4.203</td>\n",
       "      <td>4.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.504</td>\n",
       "      <td>8.494</td>\n",
       "      <td>8.478</td>\n",
       "      <td>8.465</td>\n",
       "      <td>8.455</td>\n",
       "      <td>8.442</td>\n",
       "      <td>8.426</td>\n",
       "      <td>8.419</td>\n",
       "      <td>8.408</td>\n",
       "      <td>8.399</td>\n",
       "      <td>...</td>\n",
       "      <td>7.338</td>\n",
       "      <td>7.336</td>\n",
       "      <td>7.333</td>\n",
       "      <td>7.331</td>\n",
       "      <td>7.329</td>\n",
       "      <td>7.327</td>\n",
       "      <td>7.326</td>\n",
       "      <td>7.325</td>\n",
       "      <td>7.324</td>\n",
       "      <td>7.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.972</td>\n",
       "      <td>9.953</td>\n",
       "      <td>9.939</td>\n",
       "      <td>9.921</td>\n",
       "      <td>9.905</td>\n",
       "      <td>9.886</td>\n",
       "      <td>9.868</td>\n",
       "      <td>9.855</td>\n",
       "      <td>9.838</td>\n",
       "      <td>9.821</td>\n",
       "      <td>...</td>\n",
       "      <td>8.439</td>\n",
       "      <td>8.436</td>\n",
       "      <td>8.434</td>\n",
       "      <td>8.432</td>\n",
       "      <td>8.431</td>\n",
       "      <td>8.429</td>\n",
       "      <td>8.428</td>\n",
       "      <td>8.427</td>\n",
       "      <td>8.427</td>\n",
       "      <td>8.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.643</td>\n",
       "      <td>11.614</td>\n",
       "      <td>11.590</td>\n",
       "      <td>11.567</td>\n",
       "      <td>11.540</td>\n",
       "      <td>11.516</td>\n",
       "      <td>11.489</td>\n",
       "      <td>11.459</td>\n",
       "      <td>11.440</td>\n",
       "      <td>11.420</td>\n",
       "      <td>...</td>\n",
       "      <td>9.719</td>\n",
       "      <td>9.715</td>\n",
       "      <td>9.713</td>\n",
       "      <td>9.710</td>\n",
       "      <td>9.709</td>\n",
       "      <td>9.709</td>\n",
       "      <td>9.707</td>\n",
       "      <td>9.706</td>\n",
       "      <td>9.706</td>\n",
       "      <td>9.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.656</td>\n",
       "      <td>20.574</td>\n",
       "      <td>20.492</td>\n",
       "      <td>20.410</td>\n",
       "      <td>20.328</td>\n",
       "      <td>20.247</td>\n",
       "      <td>20.166</td>\n",
       "      <td>20.085</td>\n",
       "      <td>20.004</td>\n",
       "      <td>19.923</td>\n",
       "      <td>...</td>\n",
       "      <td>15.547</td>\n",
       "      <td>15.546</td>\n",
       "      <td>15.544</td>\n",
       "      <td>15.543</td>\n",
       "      <td>15.541</td>\n",
       "      <td>15.540</td>\n",
       "      <td>15.539</td>\n",
       "      <td>15.538</td>\n",
       "      <td>15.537</td>\n",
       "      <td>15.535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss_epoch_1  loss_epoch_2  loss_epoch_3  loss_epoch_4  loss_epoch_5  \\\n",
       "count     10000.000     10000.000     10000.000     10000.000     10000.000   \n",
       "mean         10.233        10.212        10.191        10.170        10.149   \n",
       "std           2.348         2.336         2.324         2.313         2.301   \n",
       "min           4.700         4.700         4.700         4.700         4.700   \n",
       "25%           8.504         8.494         8.478         8.465         8.455   \n",
       "50%           9.972         9.953         9.939         9.921         9.905   \n",
       "75%          11.643        11.614        11.590        11.567        11.540   \n",
       "max          20.656        20.574        20.492        20.410        20.328   \n",
       "\n",
       "       loss_epoch_6  loss_epoch_7  loss_epoch_8  loss_epoch_9  loss_epoch_10  \\\n",
       "count     10000.000     10000.000     10000.000     10000.000      10000.000   \n",
       "mean         10.129        10.109        10.089        10.069         10.050   \n",
       "std           2.290         2.278         2.267         2.256          2.245   \n",
       "min           4.700         4.700         4.700         4.700          4.700   \n",
       "25%           8.442         8.426         8.419         8.408          8.399   \n",
       "50%           9.886         9.868         9.855         9.838          9.821   \n",
       "75%          11.516        11.489        11.459        11.440         11.420   \n",
       "max          20.247        20.166        20.085        20.004         19.923   \n",
       "\n",
       "       ...  loss_epoch_191  loss_epoch_192  loss_epoch_193  loss_epoch_194  \\\n",
       "count  ...       10000.000       10000.000       10000.000       10000.000   \n",
       "mean   ...           8.598           8.596           8.594           8.593   \n",
       "std    ...           1.690           1.690           1.689           1.689   \n",
       "min    ...           4.204           4.204           4.204           4.204   \n",
       "25%    ...           7.338           7.336           7.333           7.331   \n",
       "50%    ...           8.439           8.436           8.434           8.432   \n",
       "75%    ...           9.719           9.715           9.713           9.710   \n",
       "max    ...          15.547          15.546          15.544          15.543   \n",
       "\n",
       "       loss_epoch_195  loss_epoch_196  loss_epoch_197  loss_epoch_198  \\\n",
       "count       10000.000       10000.000       10000.000       10000.000   \n",
       "mean            8.591           8.589           8.588           8.586   \n",
       "std             1.688           1.688           1.688           1.687   \n",
       "min             4.204           4.203           4.203           4.203   \n",
       "25%             7.329           7.327           7.326           7.325   \n",
       "50%             8.431           8.429           8.428           8.427   \n",
       "75%             9.709           9.709           9.707           9.706   \n",
       "max            15.541          15.540          15.539          15.538   \n",
       "\n",
       "       loss_epoch_199  loss_epoch_200  \n",
       "count       10000.000       10000.000  \n",
       "mean            8.584           8.583  \n",
       "std             1.687           1.686  \n",
       "min             4.203           4.202  \n",
       "25%             7.324           7.323  \n",
       "50%             8.427           8.425  \n",
       "75%             9.706           9.704  \n",
       "max            15.537          15.535  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:55.360978Z",
     "start_time": "2020-12-02T01:37:54.662745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss_epoch_1</th>\n",
       "      <th>val_loss_epoch_2</th>\n",
       "      <th>val_loss_epoch_3</th>\n",
       "      <th>val_loss_epoch_4</th>\n",
       "      <th>val_loss_epoch_5</th>\n",
       "      <th>val_loss_epoch_6</th>\n",
       "      <th>val_loss_epoch_7</th>\n",
       "      <th>val_loss_epoch_8</th>\n",
       "      <th>val_loss_epoch_9</th>\n",
       "      <th>val_loss_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>val_loss_epoch_191</th>\n",
       "      <th>val_loss_epoch_192</th>\n",
       "      <th>val_loss_epoch_193</th>\n",
       "      <th>val_loss_epoch_194</th>\n",
       "      <th>val_loss_epoch_195</th>\n",
       "      <th>val_loss_epoch_196</th>\n",
       "      <th>val_loss_epoch_197</th>\n",
       "      <th>val_loss_epoch_198</th>\n",
       "      <th>val_loss_epoch_199</th>\n",
       "      <th>val_loss_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.204</td>\n",
       "      <td>10.183</td>\n",
       "      <td>10.163</td>\n",
       "      <td>10.142</td>\n",
       "      <td>10.122</td>\n",
       "      <td>10.102</td>\n",
       "      <td>10.082</td>\n",
       "      <td>10.062</td>\n",
       "      <td>10.043</td>\n",
       "      <td>10.023</td>\n",
       "      <td>...</td>\n",
       "      <td>8.598</td>\n",
       "      <td>8.596</td>\n",
       "      <td>8.594</td>\n",
       "      <td>8.593</td>\n",
       "      <td>8.591</td>\n",
       "      <td>8.589</td>\n",
       "      <td>8.588</td>\n",
       "      <td>8.586</td>\n",
       "      <td>8.585</td>\n",
       "      <td>8.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.383</td>\n",
       "      <td>2.371</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.348</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.303</td>\n",
       "      <td>2.293</td>\n",
       "      <td>2.282</td>\n",
       "      <td>...</td>\n",
       "      <td>1.737</td>\n",
       "      <td>1.736</td>\n",
       "      <td>1.736</td>\n",
       "      <td>1.735</td>\n",
       "      <td>1.735</td>\n",
       "      <td>1.734</td>\n",
       "      <td>1.734</td>\n",
       "      <td>1.734</td>\n",
       "      <td>1.733</td>\n",
       "      <td>1.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.614</td>\n",
       "      <td>4.613</td>\n",
       "      <td>4.612</td>\n",
       "      <td>4.611</td>\n",
       "      <td>4.611</td>\n",
       "      <td>4.610</td>\n",
       "      <td>4.609</td>\n",
       "      <td>4.608</td>\n",
       "      <td>4.607</td>\n",
       "      <td>4.606</td>\n",
       "      <td>...</td>\n",
       "      <td>4.198</td>\n",
       "      <td>4.198</td>\n",
       "      <td>4.197</td>\n",
       "      <td>4.197</td>\n",
       "      <td>4.196</td>\n",
       "      <td>4.196</td>\n",
       "      <td>4.195</td>\n",
       "      <td>4.195</td>\n",
       "      <td>4.194</td>\n",
       "      <td>4.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.464</td>\n",
       "      <td>8.455</td>\n",
       "      <td>8.441</td>\n",
       "      <td>8.429</td>\n",
       "      <td>8.413</td>\n",
       "      <td>8.401</td>\n",
       "      <td>8.392</td>\n",
       "      <td>8.382</td>\n",
       "      <td>8.371</td>\n",
       "      <td>8.358</td>\n",
       "      <td>...</td>\n",
       "      <td>7.309</td>\n",
       "      <td>7.308</td>\n",
       "      <td>7.306</td>\n",
       "      <td>7.305</td>\n",
       "      <td>7.304</td>\n",
       "      <td>7.301</td>\n",
       "      <td>7.299</td>\n",
       "      <td>7.297</td>\n",
       "      <td>7.294</td>\n",
       "      <td>7.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.928</td>\n",
       "      <td>9.913</td>\n",
       "      <td>9.894</td>\n",
       "      <td>9.874</td>\n",
       "      <td>9.858</td>\n",
       "      <td>9.836</td>\n",
       "      <td>9.821</td>\n",
       "      <td>9.805</td>\n",
       "      <td>9.789</td>\n",
       "      <td>9.775</td>\n",
       "      <td>...</td>\n",
       "      <td>8.442</td>\n",
       "      <td>8.438</td>\n",
       "      <td>8.436</td>\n",
       "      <td>8.434</td>\n",
       "      <td>8.431</td>\n",
       "      <td>8.430</td>\n",
       "      <td>8.429</td>\n",
       "      <td>8.428</td>\n",
       "      <td>8.427</td>\n",
       "      <td>8.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.628</td>\n",
       "      <td>11.601</td>\n",
       "      <td>11.578</td>\n",
       "      <td>11.555</td>\n",
       "      <td>11.533</td>\n",
       "      <td>11.510</td>\n",
       "      <td>11.482</td>\n",
       "      <td>11.457</td>\n",
       "      <td>11.435</td>\n",
       "      <td>11.416</td>\n",
       "      <td>...</td>\n",
       "      <td>9.749</td>\n",
       "      <td>9.748</td>\n",
       "      <td>9.743</td>\n",
       "      <td>9.739</td>\n",
       "      <td>9.736</td>\n",
       "      <td>9.734</td>\n",
       "      <td>9.731</td>\n",
       "      <td>9.727</td>\n",
       "      <td>9.724</td>\n",
       "      <td>9.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.642</td>\n",
       "      <td>20.577</td>\n",
       "      <td>20.511</td>\n",
       "      <td>20.446</td>\n",
       "      <td>20.382</td>\n",
       "      <td>20.317</td>\n",
       "      <td>20.252</td>\n",
       "      <td>20.188</td>\n",
       "      <td>20.125</td>\n",
       "      <td>20.062</td>\n",
       "      <td>...</td>\n",
       "      <td>15.587</td>\n",
       "      <td>15.575</td>\n",
       "      <td>15.563</td>\n",
       "      <td>15.560</td>\n",
       "      <td>15.559</td>\n",
       "      <td>15.559</td>\n",
       "      <td>15.558</td>\n",
       "      <td>15.557</td>\n",
       "      <td>15.557</td>\n",
       "      <td>15.556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val_loss_epoch_1  val_loss_epoch_2  val_loss_epoch_3  val_loss_epoch_4  \\\n",
       "count         10000.000         10000.000         10000.000         10000.000   \n",
       "mean             10.204            10.183            10.163            10.142   \n",
       "std               2.383             2.371             2.359             2.348   \n",
       "min               4.614             4.613             4.612             4.611   \n",
       "25%               8.464             8.455             8.441             8.429   \n",
       "50%               9.928             9.913             9.894             9.874   \n",
       "75%              11.628            11.601            11.578            11.555   \n",
       "max              20.642            20.577            20.511            20.446   \n",
       "\n",
       "       val_loss_epoch_5  val_loss_epoch_6  val_loss_epoch_7  val_loss_epoch_8  \\\n",
       "count         10000.000         10000.000         10000.000         10000.000   \n",
       "mean             10.122            10.102            10.082            10.062   \n",
       "std               2.336             2.325             2.314             2.303   \n",
       "min               4.611             4.610             4.609             4.608   \n",
       "25%               8.413             8.401             8.392             8.382   \n",
       "50%               9.858             9.836             9.821             9.805   \n",
       "75%              11.533            11.510            11.482            11.457   \n",
       "max              20.382            20.317            20.252            20.188   \n",
       "\n",
       "       val_loss_epoch_9  val_loss_epoch_10  ...  val_loss_epoch_191  \\\n",
       "count         10000.000          10000.000  ...           10000.000   \n",
       "mean             10.043             10.023  ...               8.598   \n",
       "std               2.293              2.282  ...               1.737   \n",
       "min               4.607              4.606  ...               4.198   \n",
       "25%               8.371              8.358  ...               7.309   \n",
       "50%               9.789              9.775  ...               8.442   \n",
       "75%              11.435             11.416  ...               9.749   \n",
       "max              20.125             20.062  ...              15.587   \n",
       "\n",
       "       val_loss_epoch_192  val_loss_epoch_193  val_loss_epoch_194  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                8.596               8.594               8.593   \n",
       "std                 1.736               1.736               1.735   \n",
       "min                 4.198               4.197               4.197   \n",
       "25%                 7.308               7.306               7.305   \n",
       "50%                 8.438               8.436               8.434   \n",
       "75%                 9.748               9.743               9.739   \n",
       "max                15.575              15.563              15.560   \n",
       "\n",
       "       val_loss_epoch_195  val_loss_epoch_196  val_loss_epoch_197  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                8.591               8.589               8.588   \n",
       "std                 1.735               1.734               1.734   \n",
       "min                 4.196               4.196               4.195   \n",
       "25%                 7.304               7.301               7.299   \n",
       "50%                 8.431               8.430               8.429   \n",
       "75%                 9.736               9.734               9.731   \n",
       "max                15.559              15.559              15.558   \n",
       "\n",
       "       val_loss_epoch_198  val_loss_epoch_199  val_loss_epoch_200  \n",
       "count           10000.000           10000.000           10000.000  \n",
       "mean                8.586               8.585               8.583  \n",
       "std                 1.734               1.733               1.733  \n",
       "min                 4.195               4.194               4.194  \n",
       "25%                 7.297               7.294               7.292  \n",
       "50%                 8.428               8.427               8.427  \n",
       "75%                 9.727               9.724               9.722  \n",
       "max                15.557              15.557              15.556  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:55.968076Z",
     "start_time": "2020-12-02T01:37:55.362706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_epoch_1</th>\n",
       "      <th>metric_epoch_2</th>\n",
       "      <th>metric_epoch_3</th>\n",
       "      <th>metric_epoch_4</th>\n",
       "      <th>metric_epoch_5</th>\n",
       "      <th>metric_epoch_6</th>\n",
       "      <th>metric_epoch_7</th>\n",
       "      <th>metric_epoch_8</th>\n",
       "      <th>metric_epoch_9</th>\n",
       "      <th>metric_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>metric_epoch_191</th>\n",
       "      <th>metric_epoch_192</th>\n",
       "      <th>metric_epoch_193</th>\n",
       "      <th>metric_epoch_194</th>\n",
       "      <th>metric_epoch_195</th>\n",
       "      <th>metric_epoch_196</th>\n",
       "      <th>metric_epoch_197</th>\n",
       "      <th>metric_epoch_198</th>\n",
       "      <th>metric_epoch_199</th>\n",
       "      <th>metric_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.021</td>\n",
       "      <td>1.048</td>\n",
       "      <td>1.102</td>\n",
       "      <td>1.145</td>\n",
       "      <td>1.165</td>\n",
       "      <td>1.213</td>\n",
       "      <td>1.259</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.345</td>\n",
       "      <td>1.383</td>\n",
       "      <td>...</td>\n",
       "      <td>6.077</td>\n",
       "      <td>6.112</td>\n",
       "      <td>6.167</td>\n",
       "      <td>6.131</td>\n",
       "      <td>6.271</td>\n",
       "      <td>6.143</td>\n",
       "      <td>6.166</td>\n",
       "      <td>6.812</td>\n",
       "      <td>6.204</td>\n",
       "      <td>6.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.005</td>\n",
       "      <td>2.150</td>\n",
       "      <td>5.155</td>\n",
       "      <td>7.361</td>\n",
       "      <td>7.695</td>\n",
       "      <td>10.236</td>\n",
       "      <td>12.624</td>\n",
       "      <td>14.536</td>\n",
       "      <td>16.783</td>\n",
       "      <td>18.026</td>\n",
       "      <td>...</td>\n",
       "      <td>216.837</td>\n",
       "      <td>217.403</td>\n",
       "      <td>218.343</td>\n",
       "      <td>218.445</td>\n",
       "      <td>221.780</td>\n",
       "      <td>219.502</td>\n",
       "      <td>219.837</td>\n",
       "      <td>280.047</td>\n",
       "      <td>220.961</td>\n",
       "      <td>221.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.006</td>\n",
       "      <td>...</td>\n",
       "      <td>1.566</td>\n",
       "      <td>1.568</td>\n",
       "      <td>1.570</td>\n",
       "      <td>1.573</td>\n",
       "      <td>1.572</td>\n",
       "      <td>1.578</td>\n",
       "      <td>1.577</td>\n",
       "      <td>1.581</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.006</td>\n",
       "      <td>1.009</td>\n",
       "      <td>1.014</td>\n",
       "      <td>1.018</td>\n",
       "      <td>1.023</td>\n",
       "      <td>1.028</td>\n",
       "      <td>1.033</td>\n",
       "      <td>...</td>\n",
       "      <td>2.067</td>\n",
       "      <td>2.069</td>\n",
       "      <td>2.070</td>\n",
       "      <td>2.075</td>\n",
       "      <td>2.080</td>\n",
       "      <td>2.079</td>\n",
       "      <td>2.084</td>\n",
       "      <td>2.084</td>\n",
       "      <td>2.091</td>\n",
       "      <td>2.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.002</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.017</td>\n",
       "      <td>1.027</td>\n",
       "      <td>1.038</td>\n",
       "      <td>1.048</td>\n",
       "      <td>1.060</td>\n",
       "      <td>1.071</td>\n",
       "      <td>1.084</td>\n",
       "      <td>1.096</td>\n",
       "      <td>...</td>\n",
       "      <td>2.879</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.892</td>\n",
       "      <td>2.896</td>\n",
       "      <td>2.904</td>\n",
       "      <td>2.902</td>\n",
       "      <td>2.914</td>\n",
       "      <td>2.913</td>\n",
       "      <td>2.922</td>\n",
       "      <td>2.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>91.033</td>\n",
       "      <td>201.869</td>\n",
       "      <td>486.742</td>\n",
       "      <td>701.471</td>\n",
       "      <td>739.950</td>\n",
       "      <td>994.654</td>\n",
       "      <td>1226.537</td>\n",
       "      <td>1410.575</td>\n",
       "      <td>1635.684</td>\n",
       "      <td>1751.056</td>\n",
       "      <td>...</td>\n",
       "      <td>21146.715</td>\n",
       "      <td>21199.523</td>\n",
       "      <td>21252.541</td>\n",
       "      <td>21302.158</td>\n",
       "      <td>21340.082</td>\n",
       "      <td>21405.949</td>\n",
       "      <td>21436.148</td>\n",
       "      <td>27547.275</td>\n",
       "      <td>21539.758</td>\n",
       "      <td>21610.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       metric_epoch_1  metric_epoch_2  metric_epoch_3  metric_epoch_4  \\\n",
       "count       10000.000       10000.000       10000.000       10000.000   \n",
       "mean            1.021           1.048           1.102           1.145   \n",
       "std             1.005           2.150           5.155           7.361   \n",
       "min             0.990           0.975           0.962           0.952   \n",
       "25%             0.998           0.998           0.998           0.999   \n",
       "50%             1.000           1.001           1.003           1.006   \n",
       "75%             1.002           1.008           1.017           1.027   \n",
       "max            91.033         201.869         486.742         701.471   \n",
       "\n",
       "       metric_epoch_5  metric_epoch_6  metric_epoch_7  metric_epoch_8  \\\n",
       "count       10000.000       10000.000       10000.000       10000.000   \n",
       "mean            1.165           1.213           1.259           1.301   \n",
       "std             7.695          10.236          12.624          14.536   \n",
       "min             0.941           0.932           0.924           0.917   \n",
       "25%             1.000           1.000           1.001           1.003   \n",
       "50%             1.009           1.014           1.018           1.023   \n",
       "75%             1.038           1.048           1.060           1.071   \n",
       "max           739.950         994.654        1226.537        1410.575   \n",
       "\n",
       "       metric_epoch_9  metric_epoch_10  ...  metric_epoch_191  \\\n",
       "count       10000.000        10000.000  ...         10000.000   \n",
       "mean            1.345            1.383  ...             6.077   \n",
       "std            16.783           18.026  ...           216.837   \n",
       "min             0.906            0.896  ...             0.379   \n",
       "25%             1.005            1.006  ...             1.566   \n",
       "50%             1.028            1.033  ...             2.067   \n",
       "75%             1.084            1.096  ...             2.879   \n",
       "max          1635.684         1751.056  ...         21146.715   \n",
       "\n",
       "       metric_epoch_192  metric_epoch_193  metric_epoch_194  metric_epoch_195  \\\n",
       "count         10000.000         10000.000         10000.000         10000.000   \n",
       "mean              6.112             6.167             6.131             6.271   \n",
       "std             217.403           218.343           218.445           221.780   \n",
       "min               0.379             0.380             0.383             0.379   \n",
       "25%               1.568             1.570             1.573             1.572   \n",
       "50%               2.069             2.070             2.075             2.080   \n",
       "75%               2.885             2.892             2.896             2.904   \n",
       "max           21199.523         21252.541         21302.158         21340.082   \n",
       "\n",
       "       metric_epoch_196  metric_epoch_197  metric_epoch_198  metric_epoch_199  \\\n",
       "count         10000.000         10000.000         10000.000         10000.000   \n",
       "mean              6.143             6.166             6.812             6.204   \n",
       "std             219.502           219.837           280.047           220.961   \n",
       "min               0.380             0.379             0.381             0.380   \n",
       "25%               1.578             1.577             1.581             1.582   \n",
       "50%               2.079             2.084             2.084             2.091   \n",
       "75%               2.902             2.914             2.913             2.922   \n",
       "max           21405.949         21436.148         27547.275         21539.758   \n",
       "\n",
       "       metric_epoch_200  \n",
       "count         10000.000  \n",
       "mean              6.202  \n",
       "std             221.605  \n",
       "min               0.380  \n",
       "25%               1.583  \n",
       "50%               2.093  \n",
       "75%               2.924  \n",
       "max           21610.023  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:56.578531Z",
     "start_time": "2020-12-02T01:37:55.969769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_metric_epoch_1</th>\n",
       "      <th>val_metric_epoch_2</th>\n",
       "      <th>val_metric_epoch_3</th>\n",
       "      <th>val_metric_epoch_4</th>\n",
       "      <th>val_metric_epoch_5</th>\n",
       "      <th>val_metric_epoch_6</th>\n",
       "      <th>val_metric_epoch_7</th>\n",
       "      <th>val_metric_epoch_8</th>\n",
       "      <th>val_metric_epoch_9</th>\n",
       "      <th>val_metric_epoch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>val_metric_epoch_191</th>\n",
       "      <th>val_metric_epoch_192</th>\n",
       "      <th>val_metric_epoch_193</th>\n",
       "      <th>val_metric_epoch_194</th>\n",
       "      <th>val_metric_epoch_195</th>\n",
       "      <th>val_metric_epoch_196</th>\n",
       "      <th>val_metric_epoch_197</th>\n",
       "      <th>val_metric_epoch_198</th>\n",
       "      <th>val_metric_epoch_199</th>\n",
       "      <th>val_metric_epoch_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.019</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.094</td>\n",
       "      <td>1.120</td>\n",
       "      <td>1.147</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.227</td>\n",
       "      <td>1.254</td>\n",
       "      <td>...</td>\n",
       "      <td>4.243</td>\n",
       "      <td>4.250</td>\n",
       "      <td>4.258</td>\n",
       "      <td>4.266</td>\n",
       "      <td>4.273</td>\n",
       "      <td>4.281</td>\n",
       "      <td>4.288</td>\n",
       "      <td>4.296</td>\n",
       "      <td>4.303</td>\n",
       "      <td>4.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.894</td>\n",
       "      <td>1.982</td>\n",
       "      <td>3.066</td>\n",
       "      <td>4.146</td>\n",
       "      <td>5.219</td>\n",
       "      <td>6.284</td>\n",
       "      <td>7.331</td>\n",
       "      <td>8.371</td>\n",
       "      <td>9.403</td>\n",
       "      <td>10.432</td>\n",
       "      <td>...</td>\n",
       "      <td>99.763</td>\n",
       "      <td>99.918</td>\n",
       "      <td>100.072</td>\n",
       "      <td>100.227</td>\n",
       "      <td>100.389</td>\n",
       "      <td>100.545</td>\n",
       "      <td>100.697</td>\n",
       "      <td>100.860</td>\n",
       "      <td>101.014</td>\n",
       "      <td>101.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.996</td>\n",
       "      <td>...</td>\n",
       "      <td>1.347</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.349</td>\n",
       "      <td>1.351</td>\n",
       "      <td>1.353</td>\n",
       "      <td>1.354</td>\n",
       "      <td>1.355</td>\n",
       "      <td>1.356</td>\n",
       "      <td>1.358</td>\n",
       "      <td>1.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.017</td>\n",
       "      <td>...</td>\n",
       "      <td>1.780</td>\n",
       "      <td>1.783</td>\n",
       "      <td>1.786</td>\n",
       "      <td>1.789</td>\n",
       "      <td>1.791</td>\n",
       "      <td>1.794</td>\n",
       "      <td>1.797</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.802</td>\n",
       "      <td>1.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.002</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.014</td>\n",
       "      <td>1.021</td>\n",
       "      <td>1.030</td>\n",
       "      <td>1.038</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.056</td>\n",
       "      <td>1.066</td>\n",
       "      <td>1.076</td>\n",
       "      <td>...</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.587</td>\n",
       "      <td>2.593</td>\n",
       "      <td>2.597</td>\n",
       "      <td>2.602</td>\n",
       "      <td>2.606</td>\n",
       "      <td>2.611</td>\n",
       "      <td>2.616</td>\n",
       "      <td>2.620</td>\n",
       "      <td>2.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.596</td>\n",
       "      <td>197.446</td>\n",
       "      <td>304.603</td>\n",
       "      <td>411.385</td>\n",
       "      <td>517.368</td>\n",
       "      <td>622.551</td>\n",
       "      <td>725.958</td>\n",
       "      <td>828.565</td>\n",
       "      <td>930.444</td>\n",
       "      <td>1032.123</td>\n",
       "      <td>...</td>\n",
       "      <td>9819.684</td>\n",
       "      <td>9834.444</td>\n",
       "      <td>9849.028</td>\n",
       "      <td>9863.788</td>\n",
       "      <td>9879.249</td>\n",
       "      <td>9894.185</td>\n",
       "      <td>9908.770</td>\n",
       "      <td>9924.405</td>\n",
       "      <td>9939.166</td>\n",
       "      <td>9954.103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val_metric_epoch_1  val_metric_epoch_2  val_metric_epoch_3  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                1.019               1.043               1.068   \n",
       "std                 0.894               1.982               3.066   \n",
       "min                 0.974               0.961               0.951   \n",
       "25%                 0.996               0.994               0.993   \n",
       "50%                 0.999               1.000               1.000   \n",
       "75%                 1.002               1.008               1.014   \n",
       "max                89.596             197.446             304.603   \n",
       "\n",
       "       val_metric_epoch_4  val_metric_epoch_5  val_metric_epoch_6  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                1.094               1.120               1.147   \n",
       "std                 4.146               5.219               6.284   \n",
       "min                 0.939               0.928               0.919   \n",
       "25%                 0.993               0.993               0.993   \n",
       "50%                 1.001               1.003               1.005   \n",
       "75%                 1.021               1.030               1.038   \n",
       "max               411.385             517.368             622.551   \n",
       "\n",
       "       val_metric_epoch_7  val_metric_epoch_8  val_metric_epoch_9  \\\n",
       "count           10000.000           10000.000           10000.000   \n",
       "mean                1.173               1.200               1.227   \n",
       "std                 7.331               8.371               9.403   \n",
       "min                 0.910               0.899               0.889   \n",
       "25%                 0.994               0.995               0.995   \n",
       "50%                 1.008               1.010               1.013   \n",
       "75%                 1.047               1.056               1.066   \n",
       "max               725.958             828.565             930.444   \n",
       "\n",
       "       val_metric_epoch_10  ...  val_metric_epoch_191  val_metric_epoch_192  \\\n",
       "count            10000.000  ...             10000.000             10000.000   \n",
       "mean                 1.254  ...                 4.243                 4.250   \n",
       "std                 10.432  ...                99.763                99.918   \n",
       "min                  0.880  ...                 0.353                 0.353   \n",
       "25%                  0.996  ...                 1.347                 1.348   \n",
       "50%                  1.017  ...                 1.780                 1.783   \n",
       "75%                  1.076  ...                 2.582                 2.587   \n",
       "max               1032.123  ...              9819.684              9834.444   \n",
       "\n",
       "       val_metric_epoch_193  val_metric_epoch_194  val_metric_epoch_195  \\\n",
       "count             10000.000             10000.000             10000.000   \n",
       "mean                  4.258                 4.266                 4.273   \n",
       "std                 100.072               100.227               100.389   \n",
       "min                   0.354                 0.354                 0.354   \n",
       "25%                   1.349                 1.351                 1.353   \n",
       "50%                   1.786                 1.789                 1.791   \n",
       "75%                   2.593                 2.597                 2.602   \n",
       "max                9849.028              9863.788              9879.249   \n",
       "\n",
       "       val_metric_epoch_196  val_metric_epoch_197  val_metric_epoch_198  \\\n",
       "count             10000.000             10000.000             10000.000   \n",
       "mean                  4.281                 4.288                 4.296   \n",
       "std                 100.545               100.697               100.860   \n",
       "min                   0.354                 0.354                 0.354   \n",
       "25%                   1.354                 1.355                 1.356   \n",
       "50%                   1.794                 1.797                 1.799   \n",
       "75%                   2.606                 2.611                 2.616   \n",
       "max                9894.185              9908.770              9924.405   \n",
       "\n",
       "       val_metric_epoch_199  val_metric_epoch_200  \n",
       "count             10000.000             10000.000  \n",
       "mean                  4.303                 4.310  \n",
       "std                 101.014               101.170  \n",
       "min                   0.355                 0.355  \n",
       "25%                   1.358                 1.359  \n",
       "50%                   1.802                 1.804  \n",
       "75%                   2.620                 2.623  \n",
       "max                9939.166              9954.103  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:58.107797Z",
     "start_time": "2020-12-02T01:37:56.580194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for metric\n",
    "path = './data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/metric_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.png'\n",
    "\n",
    "adjustment_threshold_metric = 0#100\n",
    "    \n",
    "metric_df_adjusted = metric_df.copy(deep=True)\n",
    "if adjustment_threshold_metric > 0:\n",
    "    metric_df_adjusted[metric_df_adjusted.columns] = np.where(metric_df_adjusted[metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, metric_df_adjusted[metric_df_adjusted.columns])\n",
    "    \n",
    "val_metric_df_adjusted = val_metric_df.copy(deep=True)\n",
    "if adjustment_threshold_metric > 0:\n",
    "    val_metric_df_adjusted[val_metric_df_adjusted.columns] = np.where(val_metric_df_adjusted[val_metric_df_adjusted.columns] > adjustment_threshold_metric, adjustment_threshold_metric, val_metric_df_adjusted[val_metric_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_metric_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model metric')\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:37:59.534506Z",
     "start_time": "2020-12-02T01:37:58.109569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "path = './data/results/weights_' + str(data_size) + '_train_' + str(lambda_dataset_size) + '_variables_' + str(n) + '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_astep_' + str(a_step)  + '_amin_' + str(a_min) + '_amax_' + str(a_max) + '_xstep_' + str(x_step) + '_xmin_' + str(x_min) + '_xmax_' + str(x_max) + training_string + filename + '/loss_' + str(data_size) +  '_degree_' + str(d) + '_sparsity_' + str(sparsity) + '_amax_' + str(a_max) + '_xmax_' + str(x_max) + training_string + '_epoch_' + str(epochs).zfill(3)  + filename + '.png'\n",
    "\n",
    "adjustment_threshold_loss = 0#10000\n",
    "    \n",
    "loss_df_adjusted = loss_df.copy(deep=True)\n",
    "\n",
    "if adjustment_threshold_loss > 0:\n",
    "    loss_df_adjusted[loss_df_adjusted.columns] = np.where(loss_df_adjusted[loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, loss_df_adjusted[loss_df_adjusted.columns])\n",
    "    \n",
    "val_loss_df_adjusted = val_loss_df.copy(deep=True)\n",
    "if adjustment_threshold_loss > 0:\n",
    "    val_loss_df_adjusted[val_loss_df_adjusted.columns] = np.where(val_loss_df_adjusted[val_loss_df_adjusted.columns] > adjustment_threshold_loss, adjustment_threshold_loss, val_loss_df_adjusted[val_loss_df_adjusted.columns])\n",
    "\n",
    "    \n",
    "plt.plot(loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.plot(val_loss_df_adjusted.describe().loc['mean'].values)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig(path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
