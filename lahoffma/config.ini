[Integer]

# max degree of polynomials
d = 3
# number of variables in polynomials
n = 4

# number of data points to calculate the function (polynomial) values for, determines the lambda-nets' dataset size
lambda_dataset_size = 100 
# number of functions (polynomials) generated , specifies the interpretation-net's dataset size
interpretation_dataset_size = 5000

# number of cpu cores to use for parallelization
n_jobs = 10

# size of batch to train lambda-net
batch_size = 64
# number of epochs to train lambda-net
epochs = 200
# specifies the number of epochs to checkpoint lambda network weights, if None no checkpointing
each_epochs_save = 5  

[Float]

# relative amount of coefficients to set to 0, interpreted as percent
sparsity = 0.0 

# Possible values for coefficients
# max coefficient
a_max = 10
# min coefficient
a_min = -10
# discretization of coefficient range, controls the number of possible coefficient values
a_step = 0.1

# Possible values for input variables
# max variable value
x_max = 1
# min variable value
x_min = -1
# discretization of variable range, controls the number of possible variable input values
x_step = 0.01

# dropout limit to train lambda-net
dropout = 0.0

[Boolean]

# whether each polynomial and thus lambda-net is trained on the same input datapoints (x) or not
# MUST BE TRUE --> DO NOT CHANGE
same_training_all_polynomials = True

[String]

# optimizer used to train lambda-net
optimizer='SGD'

[Other]

