{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Specification of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:06:27.611974Z",
     "iopub.status.busy": "2022-06-07T15:06:27.611728Z",
     "iopub.status.idle": "2022-06-07T15:06:27.641326Z",
     "shell.execute_reply": "2022-06-07T15:06:27.640400Z",
     "shell.execute_reply.started": "2022-06-07T15:06:27.611893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnpassen: \\n\\nnumber_of_variables --> anzahl variablen\\n\\nlambda_dataset_size --> datensatz größe für training von lambda-nets\\nnumber_of_generated_datasets and  number_of_trained_lambda_nets and interpretation_dataset_size --> anzahl der lambda-nets\\n\\nlambda net --> alles wie in notebook 2\\n\\ni net -->\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Anpassen: \n",
    "\n",
    "number_of_variables --> anzahl variablen\n",
    "\n",
    "lambda_dataset_size --> datensatz größe für training von lambda-nets\n",
    "number_of_generated_datasets and  number_of_trained_lambda_nets and interpretation_dataset_size --> anzahl der lambda-nets\n",
    "\n",
    "lambda net --> alles wie in notebook 2\n",
    "\n",
    "i net -->\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:06:27.642928Z",
     "iopub.status.busy": "2022-06-07T15:06:27.642735Z",
     "iopub.status.idle": "2022-06-07T15:06:27.948575Z",
     "shell.execute_reply": "2022-06-07T15:06:27.946618Z",
     "shell.execute_reply.started": "2022-06-07T15:06:27.642904Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 3,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'vanilla', #'SDT', 'vanilla'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 10, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [],\n",
    "        \n",
    "        'use_distribution_list': True,\n",
    "        'random_parameters_distribution': True, ##MAKEPATH DIFFERENT FILES\n",
    "        'max_distributions_per_class': 1, # None; 0; int >= 1  \n",
    "        'exclude_linearly_seperable': False,\n",
    "        'data_generation_filtering': False,\n",
    "        'fixed_class_probability': False,\n",
    "        'balanced_data': False,\n",
    "        'weighted_data_generation': False,\n",
    "        'shift_distrib': False,\n",
    "        \n",
    "        'dt_type_train': 'vanilla', # (None, 'vanilla', 'SDT')\n",
    "        'maximum_depth_train': 3, #None or int\n",
    "        'decision_sparsity_train': 1, #None or int\n",
    "        \n",
    "        'function_generation_type': 'make_classification',# 'make_classification_distribution', 'make_classification_distribution_trained', 'distribution', 'distribution_trained', 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'distrib_by_feature': True,\n",
    "        'distribution_list': ['uniform', 'normal', 'gamma', 'beta', 'poisson'],#['uniform', 'gamma', 'poisson', 'exponential', 'weibull'],#['uniform', 'normal', 'gamma', 'exponential', 'beta', 'binomial', 'poisson'], \n",
    "        'distribution_list_eval': ['uniform', 'normal', 'gamma', 'beta', 'poisson'],#['uniform', 'gamma', 'poisson', 'exponential', 'weibull'],#['uniform', 'normal', 'gamma', 'beta', 'poisson'],\n",
    "        \n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        'number_of_generated_datasets': 100,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "        \n",
    "        'data_noise': 0, #None or float\n",
    "        \n",
    "        'distrib_param_max': 5,\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-3,\n",
    "        'restore_best_weights': True,\n",
    "        'patience_lambda': 50,\n",
    "        \n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'use_batchnorm_lambda': False,\n",
    "        \n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 100,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        #'dense_layers': [1024, 1024, 256, 2048, 2048],\n",
    "        'dense_layers': [1792, 512, 512],\n",
    "        #'dense_layers': [1792, 512, 512],\n",
    "        \n",
    "        #'dropout': [0, 0, 0, 0, 0.3],#[0.3, 0.3, 0.3, 0.3, 0.3],\n",
    "        'dropout': [0, 0, 0.5],\n",
    "        #'dropout': [0, 0, 0.5],\n",
    "\n",
    "        #'hidden_activation': 'relu',\n",
    "        'hidden_activation': 'sigmoid',\n",
    "        #'hidden_activation': 'swish',\n",
    "\n",
    "        #'optimizer': 'rmsprop', \n",
    "        'optimizer': 'adam', \n",
    "        #'optimizer': 'adam', \n",
    "        \n",
    "        #'learning_rate': 0.001,\n",
    "        'learning_rate': 0.001,\n",
    "        #'learning_rate': 0.001, \n",
    "        \n",
    "        'separate_weight_bias': False,\n",
    "        \n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,        \n",
    "        'additional_hidden': False,\n",
    "        \n",
    "        'loss': 'binary_crossentropy', #mse; binary_crossentropy; 'binary_accuracy'\n",
    "        'metrics': ['binary_accuracy'], #soft_ or _penalized\n",
    "        \n",
    "        'epochs': 500, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 100,\n",
    "                \n",
    "        'test_size': 5, #Float for fraction, Int for number 0\n",
    "        'evaluate_distribution': True,\n",
    "        'force_evaluate_real_world': False,\n",
    "        \n",
    "        'function_representation_type': 5, # 1=standard representation; 2=sparse representation with classification for variables; 3=softmax to select classes (n top probabilities)\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2,3) #3=autoencoder dimensionality reduction\n",
    "        \n",
    "        'resampling_strategy': None,#'ADASYN', #'SMOTE', None\n",
    "        'resampling_threshold': 0.25,#0.2,\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 60,\n",
    "        'nas_optimizer': 'greedy' #'hyperband',#\"bayesian\",'greedy', 'random'\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "        \n",
    "        'number_of_random_evaluations_per_distribution': 10,\n",
    "        'random_evaluation_dataset_size_per_distribution': 10_000, \n",
    "        'optimize_sampling': True,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'random_evaluation_dataset_distribution': 'uniform', \n",
    "        \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        #'sklearn_dt_benchmark': False,\n",
    "        #'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': False,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 15,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 42,   \n",
    "        'verbosity': 0\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:06:27.952119Z",
     "iopub.status.busy": "2022-06-07T15:06:27.950004Z",
     "iopub.status.idle": "2022-06-07T15:06:28.085150Z",
     "shell.execute_reply": "2022-06-07T15:06:28.080561Z",
     "shell.execute_reply.started": "2022-06-07T15:06:27.952068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-07T15:06:28.086461Z",
     "iopub.status.busy": "2022-06-07T15:06:28.086255Z",
     "iopub.status.idle": "2022-06-07T15:06:37.866926Z",
     "shell.execute_reply": "2022-06-07T15:06:37.866296Z",
     "shell.execute_reply.started": "2022-06-07T15:06:28.086431Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:06:37.868186Z",
     "iopub.status.busy": "2022-06-07T15:06:37.867936Z",
     "iopub.status.idle": "2022-06-07T15:06:37.872735Z",
     "shell.execute_reply": "2022-06-07T15:06:37.872220Z",
     "shell.execute_reply.started": "2022-06-07T15:06:37.868160Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:06:37.873578Z",
     "iopub.status.busy": "2022-06-07T15:06:37.873434Z",
     "iopub.status.idle": "2022-06-07T15:06:37.938252Z",
     "shell.execute_reply": "2022-06-07T15:06:37.937695Z",
     "shell.execute_reply.started": "2022-06-07T15:06:37.873559Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:06:37.939644Z",
     "iopub.status.busy": "2022-06-07T15:06:37.939471Z",
     "iopub.status.idle": "2022-06-07T15:06:37.985251Z",
     "shell.execute_reply": "2022-06-07T15:06:37.984545Z",
     "shell.execute_reply.started": "2022-06-07T15:06:37.939622Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:06:37.986454Z",
     "iopub.status.busy": "2022-06-07T15:06:37.986214Z",
     "iopub.status.idle": "2022-06-07T15:36:45.789037Z",
     "shell.execute_reply": "2022-06-07T15:36:45.788530Z",
     "shell.execute_reply.started": "2022-06-07T15:06:37.986432Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f70d398c7d488194149fdc0bcdcac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(config)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth)  if function_representation_type >= 3 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes if function_representation_type >= 3 and dt_type == 'SDT'\n",
    "  else None\n",
    "                                                            )\n",
    "\n",
    "\n",
    "if distrib_by_feature:\n",
    "    config['evaluation']['random_evaluation_dataset_distribution'] = config['data']['distribution_list_eval']\n",
    "    config['data']['distribution_list'] = [config['data']['distribution_list']]\n",
    "    config['data']['distribution_list_eval'] = [config['data']['distribution_list_eval']]\n",
    "  \n",
    "    \n",
    "\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:36:45.789948Z",
     "iopub.status.busy": "2022-06-07T15:36:45.789822Z",
     "iopub.status.idle": "2022-06-07T15:36:45.793817Z",
     "shell.execute_reply": "2022-06-07T15:36:45.793227Z",
     "shell.execute_reply.started": "2022-06-07T15:36:45.789932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets100_var10_class2_make_classification_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_noBalance_noBalance/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1792-512-512_drop0-0-0.5e500b256_adam_funcRep5_reshapeNone\n",
      "lNetSize5000_numLNets100_var10_class2_make_classification_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_noBalance_noBalance/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-07T15:36:45.794658Z",
     "iopub.status.busy": "2022-06-07T15:36:45.794521Z",
     "iopub.status.idle": "2022-06-07T15:36:46.085115Z",
     "shell.execute_reply": "2022-06-07T15:36:46.084249Z",
     "shell.execute_reply.started": "2022-06-07T15:36:45.794640Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:36:46.086432Z",
     "iopub.status.busy": "2022-06-07T15:36:46.086191Z",
     "iopub.status.idle": "2022-06-07T15:36:46.130152Z",
     "shell.execute_reply": "2022-06-07T15:36:46.129757Z",
     "shell.execute_reply.started": "2022-06-07T15:36:46.086401Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-06-07T15:36:46.132076Z",
     "iopub.status.busy": "2022-06-07T15:36:46.131952Z",
     "iopub.status.idle": "2022-06-07T15:36:46.263492Z",
     "shell.execute_reply": "2022-06-07T15:36:46.263150Z",
     "shell.execute_reply.started": "2022-06-07T15:36:46.132060Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['data']['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    \n",
    "    \n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'\n",
    "    \n",
    "    if True:\n",
    "        path_X_data = './data/saved_function_lists/X_data_' + path_dict['path_identifier_function_data'] + '.pkl'\n",
    "        with open(path_X_data, 'rb') as f:\n",
    "            X_data_list = pickle.load(f)\n",
    "\n",
    "        path_y_data = './data/saved_function_lists/y_data_' + path_dict['path_identifier_function_data'] + '.pkl'\n",
    "        with open(path_y_data, 'rb') as f:\n",
    "            y_data_list = pickle.load(f)        \n",
    "            \n",
    "    path_distribution_parameters = directory + '/' + 'distribution_parameters' + '.txt'\n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    \n",
    "    try:\n",
    "        distribution_parameters = pd.read_csv(path_distribution_parameters, sep=\",\", header=None)\n",
    "        distribution_parameters = distribution_parameters.sort_values(by=0)\n",
    "    except:\n",
    "        distribution_parameters = pd.DataFrame([None] * network_parameters.shape[0])\n",
    "    \n",
    "    #if no_noise == False:\n",
    "    #    network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    #    distribution_parameters = distribution_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              distribution_parameters_row,\n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              X_test_network[1].values,\n",
    "                                              y_test_network[1].values,\n",
    "                                              config) for X_test_network, y_test_network, network_parameters_row, distribution_parameters_row in zip(X_data_list[:config['i_net']['interpretation_dataset_size']], \n",
    "                                                                                                                                                     y_data_list[:config['i_net']['interpretation_dataset_size']], \n",
    "                                                                                                                                                     network_parameters.values[:config['i_net']['interpretation_dataset_size']], \n",
    "                                                                                                                                                     distribution_parameters.values[:config['i_net']['interpretation_dataset_size']]))        \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-07T15:36:46.264187Z",
     "iopub.status.busy": "2022-06-07T15:36:46.264013Z",
     "iopub.status.idle": "2022-06-07T15:37:39.868874Z",
     "shell.execute_reply": "2022-06-07T15:37:39.868114Z",
     "shell.execute_reply.started": "2022-06-07T15:36:46.264170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=15)]: Done 100 out of 100 | elapsed:   53.0s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "\n",
    "    lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "    lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "    if test_size > 0 and not evaluate_distribution:\n",
    "        lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "    else:\n",
    "        lambda_net_dataset_test = None\n",
    "        lambda_net_dataset_valid = lambda_net_dataset_eval\n",
    "        \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    if test_size > 0 and not evaluate_distribution:\n",
    "        lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    \n",
    "    else:\n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset, test_split=0.1)    \n",
    "        lambda_net_dataset_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "### Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:37:39.870120Z",
     "iopub.status.busy": "2022-06-07T15:37:39.869948Z",
     "iopub.status.idle": "2022-06-07T15:37:39.873995Z",
     "shell.execute_reply": "2022-06-07T15:37:39.873497Z",
     "shell.execute_reply.started": "2022-06-07T15:37:39.870097Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 1561)\n",
      "(10, 1561)\n"
     ]
    }
   ],
   "source": [
    "print(lambda_net_dataset_train.shape)\n",
    "print(lambda_net_dataset_valid.shape)\n",
    "if test_size > 0 and not evaluate_distribution:\n",
    "    print(lambda_net_dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-07T15:37:39.874806Z",
     "iopub.status.busy": "2022-06-07T15:37:39.874664Z",
     "iopub.status.idle": "2022-06-07T15:37:40.034315Z",
     "shell.execute_reply": "2022-06-07T15:37:40.033979Z",
     "shell.execute_reply.started": "2022-06-07T15:37:39.874787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>split0</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>split6</th>\n",
       "      <th>lp0</th>\n",
       "      <th>lp1</th>\n",
       "      <th>lp2</th>\n",
       "      <th>lp3</th>\n",
       "      <th>lp4</th>\n",
       "      <th>lp5</th>\n",
       "      <th>lp6</th>\n",
       "      <th>lp7</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>wb_52</th>\n",
       "      <th>wb_53</th>\n",
       "      <th>wb_54</th>\n",
       "      <th>wb_55</th>\n",
       "      <th>wb_56</th>\n",
       "      <th>wb_57</th>\n",
       "      <th>wb_58</th>\n",
       "      <th>wb_59</th>\n",
       "      <th>wb_60</th>\n",
       "      <th>wb_61</th>\n",
       "      <th>wb_62</th>\n",
       "      <th>wb_63</th>\n",
       "      <th>wb_64</th>\n",
       "      <th>wb_65</th>\n",
       "      <th>wb_66</th>\n",
       "      <th>wb_67</th>\n",
       "      <th>wb_68</th>\n",
       "      <th>wb_69</th>\n",
       "      <th>wb_70</th>\n",
       "      <th>wb_71</th>\n",
       "      <th>wb_72</th>\n",
       "      <th>wb_73</th>\n",
       "      <th>wb_74</th>\n",
       "      <th>wb_75</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1437</th>\n",
       "      <th>wb_1438</th>\n",
       "      <th>wb_1439</th>\n",
       "      <th>wb_1440</th>\n",
       "      <th>wb_1441</th>\n",
       "      <th>wb_1442</th>\n",
       "      <th>wb_1443</th>\n",
       "      <th>wb_1444</th>\n",
       "      <th>wb_1445</th>\n",
       "      <th>wb_1446</th>\n",
       "      <th>wb_1447</th>\n",
       "      <th>wb_1448</th>\n",
       "      <th>wb_1449</th>\n",
       "      <th>wb_1450</th>\n",
       "      <th>wb_1451</th>\n",
       "      <th>wb_1452</th>\n",
       "      <th>wb_1453</th>\n",
       "      <th>wb_1454</th>\n",
       "      <th>wb_1455</th>\n",
       "      <th>wb_1456</th>\n",
       "      <th>wb_1457</th>\n",
       "      <th>wb_1458</th>\n",
       "      <th>wb_1459</th>\n",
       "      <th>wb_1460</th>\n",
       "      <th>wb_1461</th>\n",
       "      <th>wb_1462</th>\n",
       "      <th>wb_1463</th>\n",
       "      <th>wb_1464</th>\n",
       "      <th>wb_1465</th>\n",
       "      <th>wb_1466</th>\n",
       "      <th>wb_1467</th>\n",
       "      <th>wb_1468</th>\n",
       "      <th>wb_1469</th>\n",
       "      <th>wb_1470</th>\n",
       "      <th>wb_1471</th>\n",
       "      <th>wb_1472</th>\n",
       "      <th>wb_1473</th>\n",
       "      <th>wb_1474</th>\n",
       "      <th>wb_1475</th>\n",
       "      <th>wb_1476</th>\n",
       "      <th>wb_1477</th>\n",
       "      <th>wb_1478</th>\n",
       "      <th>wb_1479</th>\n",
       "      <th>wb_1480</th>\n",
       "      <th>wb_1481</th>\n",
       "      <th>wb_1482</th>\n",
       "      <th>wb_1483</th>\n",
       "      <th>wb_1484</th>\n",
       "      <th>wb_1485</th>\n",
       "      <th>wb_1486</th>\n",
       "      <th>wb_1487</th>\n",
       "      <th>wb_1488</th>\n",
       "      <th>wb_1489</th>\n",
       "      <th>wb_1490</th>\n",
       "      <th>wb_1491</th>\n",
       "      <th>wb_1492</th>\n",
       "      <th>wb_1493</th>\n",
       "      <th>wb_1494</th>\n",
       "      <th>wb_1495</th>\n",
       "      <th>wb_1496</th>\n",
       "      <th>wb_1497</th>\n",
       "      <th>wb_1498</th>\n",
       "      <th>wb_1499</th>\n",
       "      <th>wb_1500</th>\n",
       "      <th>wb_1501</th>\n",
       "      <th>wb_1502</th>\n",
       "      <th>wb_1503</th>\n",
       "      <th>wb_1504</th>\n",
       "      <th>wb_1505</th>\n",
       "      <th>wb_1506</th>\n",
       "      <th>wb_1507</th>\n",
       "      <th>wb_1508</th>\n",
       "      <th>wb_1509</th>\n",
       "      <th>wb_1510</th>\n",
       "      <th>wb_1511</th>\n",
       "      <th>wb_1512</th>\n",
       "      <th>wb_1513</th>\n",
       "      <th>wb_1514</th>\n",
       "      <th>wb_1515</th>\n",
       "      <th>wb_1516</th>\n",
       "      <th>wb_1517</th>\n",
       "      <th>wb_1518</th>\n",
       "      <th>wb_1519</th>\n",
       "      <th>wb_1520</th>\n",
       "      <th>wb_1521</th>\n",
       "      <th>wb_1522</th>\n",
       "      <th>wb_1523</th>\n",
       "      <th>wb_1524</th>\n",
       "      <th>wb_1525</th>\n",
       "      <th>wb_1526</th>\n",
       "      <th>wb_1527</th>\n",
       "      <th>wb_1528</th>\n",
       "      <th>wb_1529</th>\n",
       "      <th>wb_1530</th>\n",
       "      <th>wb_1531</th>\n",
       "      <th>wb_1532</th>\n",
       "      <th>wb_1533</th>\n",
       "      <th>wb_1534</th>\n",
       "      <th>wb_1535</th>\n",
       "      <th>wb_1536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.474</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.530</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.629</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359</td>\n",
       "      <td>-1.192</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>3.316</td>\n",
       "      <td>0.346</td>\n",
       "      <td>-1.649</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.360</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-1.761</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.237</td>\n",
       "      <td>1.659</td>\n",
       "      <td>2.844</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-1.478</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>2.652</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-1.993</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-1.672</td>\n",
       "      <td>-1.247</td>\n",
       "      <td>-1.535</td>\n",
       "      <td>2.529</td>\n",
       "      <td>-1.413</td>\n",
       "      <td>-1.087</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>2.661</td>\n",
       "      <td>-1.248</td>\n",
       "      <td>0.794</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>1.182</td>\n",
       "      <td>-1.420</td>\n",
       "      <td>-1.505</td>\n",
       "      <td>1.689</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-1.783</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-1.557</td>\n",
       "      <td>-1.226</td>\n",
       "      <td>-1.096</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-1.420</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.292</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-1.277</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>2.441</td>\n",
       "      <td>-1.304</td>\n",
       "      <td>-1.817</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.485</td>\n",
       "      <td>2.702</td>\n",
       "      <td>2.389</td>\n",
       "      <td>0.182</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.488</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-1.192</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.045</td>\n",
       "      <td>1.972</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-1.627</td>\n",
       "      <td>-1.921</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>2.637</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.767</td>\n",
       "      <td>1.368</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.727</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>1.627</td>\n",
       "      <td>-5.102</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>1.183</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-3.638</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-2.678</td>\n",
       "      <td>0.552</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>1.215</td>\n",
       "      <td>-2.516</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-2.775</td>\n",
       "      <td>2.915</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-1.283</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-2.325</td>\n",
       "      <td>-4.131</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>5.576</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-2.344</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-1.888</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1.789</td>\n",
       "      <td>3.516</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-2.574</td>\n",
       "      <td>5.133</td>\n",
       "      <td>-2.119</td>\n",
       "      <td>-4.241</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-4.740</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>4.229</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-3.275</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>4.095</td>\n",
       "      <td>1.432</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>-2.533</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>3.194</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>6.026</td>\n",
       "      <td>3.244</td>\n",
       "      <td>4.304</td>\n",
       "      <td>0.175</td>\n",
       "      <td>2.786</td>\n",
       "      <td>3.910</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-3.452</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-1.258</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.613</td>\n",
       "      <td>3.455</td>\n",
       "      <td>3.631</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.494</td>\n",
       "      <td>7.303</td>\n",
       "      <td>1.316</td>\n",
       "      <td>-2.111</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3.864</td>\n",
       "      <td>-3.219</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-1.183</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-3.976</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.947</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.555</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.301</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.634</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.293</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.766</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.539</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-3.024</td>\n",
       "      <td>6.750</td>\n",
       "      <td>-3.208</td>\n",
       "      <td>-1.832</td>\n",
       "      <td>1.968</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-1.989</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-2.829</td>\n",
       "      <td>5.899</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>-1.547</td>\n",
       "      <td>1.427</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-5.864</td>\n",
       "      <td>5.784</td>\n",
       "      <td>-6.939</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-2.573</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-2.546</td>\n",
       "      <td>-4.585</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>1.533</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-1.882</td>\n",
       "      <td>-1.650</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-4.837</td>\n",
       "      <td>2.508</td>\n",
       "      <td>-3.675</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>2.089</td>\n",
       "      <td>-2.367</td>\n",
       "      <td>-10.064</td>\n",
       "      <td>2.785</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-4.414</td>\n",
       "      <td>-2.265</td>\n",
       "      <td>2.904</td>\n",
       "      <td>4.913</td>\n",
       "      <td>-1.848</td>\n",
       "      <td>-2.712</td>\n",
       "      <td>-1.592</td>\n",
       "      <td>1.744</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-1.203</td>\n",
       "      <td>-1.473</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>2.045</td>\n",
       "      <td>2.976</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-2.236</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-4.682</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-1.727</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-1.923</td>\n",
       "      <td>7.260</td>\n",
       "      <td>4.257</td>\n",
       "      <td>-2.107</td>\n",
       "      <td>1.302</td>\n",
       "      <td>-3.682</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-3.677</td>\n",
       "      <td>2.262</td>\n",
       "      <td>-3.100</td>\n",
       "      <td>4.828</td>\n",
       "      <td>4.895</td>\n",
       "      <td>0.096</td>\n",
       "      <td>2.564</td>\n",
       "      <td>-2.026</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-3.840</td>\n",
       "      <td>-3.040</td>\n",
       "      <td>-2.131</td>\n",
       "      <td>-4.138</td>\n",
       "      <td>9.062</td>\n",
       "      <td>1.900</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.778</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-1.150</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-1.251</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.633</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.489</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.843</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>1.007</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.517</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-10.087</td>\n",
       "      <td>2.976</td>\n",
       "      <td>-4.615</td>\n",
       "      <td>4.607</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-14.264</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>5.043</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-6.308</td>\n",
       "      <td>0.073</td>\n",
       "      <td>1.784</td>\n",
       "      <td>0.245</td>\n",
       "      <td>3.411</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-7.420</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>2.367</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-6.090</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-4.381</td>\n",
       "      <td>3.531</td>\n",
       "      <td>6.400</td>\n",
       "      <td>6.723</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-6.005</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>13.286</td>\n",
       "      <td>2.477</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.655</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>4.221</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-2.003</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-2.038</td>\n",
       "      <td>3.955</td>\n",
       "      <td>-11.800</td>\n",
       "      <td>0.554</td>\n",
       "      <td>4.855</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>3.040</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.002</td>\n",
       "      <td>4.571</td>\n",
       "      <td>-1.717</td>\n",
       "      <td>-5.966</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.673</td>\n",
       "      <td>-4.997</td>\n",
       "      <td>-5.996</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>4.378</td>\n",
       "      <td>2.246</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.192</td>\n",
       "      <td>8.100</td>\n",
       "      <td>4.229</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.046</td>\n",
       "      <td>4.278</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>4.258</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-2.072</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3.667</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-10.816</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-3.567</td>\n",
       "      <td>-1.887</td>\n",
       "      <td>-1.113</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.698</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>1.065</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-1.232</td>\n",
       "      <td>0.661</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.799</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.878</td>\n",
       "      <td>-0.564</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.325</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.698</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.477</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.790</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.902</td>\n",
       "      <td>2.195</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-2.266</td>\n",
       "      <td>-2.172</td>\n",
       "      <td>3.152</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-4.283</td>\n",
       "      <td>-3.778</td>\n",
       "      <td>-3.360</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-2.308</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-4.556</td>\n",
       "      <td>-4.745</td>\n",
       "      <td>3.620</td>\n",
       "      <td>0.254</td>\n",
       "      <td>3.387</td>\n",
       "      <td>-1.983</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>5.220</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-3.147</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-2.770</td>\n",
       "      <td>5.726</td>\n",
       "      <td>-3.675</td>\n",
       "      <td>2.973</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-2.705</td>\n",
       "      <td>-3.502</td>\n",
       "      <td>-3.801</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>4.803</td>\n",
       "      <td>-5.914</td>\n",
       "      <td>4.983</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-3.254</td>\n",
       "      <td>6.750</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-3.165</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>6.458</td>\n",
       "      <td>0.164</td>\n",
       "      <td>7.139</td>\n",
       "      <td>1.304</td>\n",
       "      <td>-1.802</td>\n",
       "      <td>8.186</td>\n",
       "      <td>4.791</td>\n",
       "      <td>-2.991</td>\n",
       "      <td>7.280</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-7.764</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-1.514</td>\n",
       "      <td>-3.538</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>2.799</td>\n",
       "      <td>4.748</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.183</td>\n",
       "      <td>2.975</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-4.795</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.904</td>\n",
       "      <td>5.365</td>\n",
       "      <td>-2.721</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>1.061</td>\n",
       "      <td>4.134</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.516</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-1.527</td>\n",
       "      <td>-1.223</td>\n",
       "      <td>-7.370</td>\n",
       "      <td>-3.689</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  seed  feat0  feat1  feat2  feat3  feat4  feat5  feat6  split0  \\\n",
       "83 83.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "53 53.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "70 70.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "45 45.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "44 44.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000   0.000   \n",
       "\n",
       "    split1  split2  split3  split4  split5  split6   lp0   lp1   lp2   lp3  \\\n",
       "83   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "53   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "70   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "45   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "44   0.000   0.000   0.000   0.000   0.000   0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "     lp4   lp5   lp6   lp7   wb_0   wb_1   wb_2   wb_3   wb_4  wb_5  wb_6  \\\n",
       "83 0.000 0.000 0.000 0.000 -0.035  0.138  0.441  0.298  0.224 0.367 0.048   \n",
       "53 0.000 0.000 0.000 0.000 -0.035 -0.097  0.522  0.049  0.767 1.368 0.048   \n",
       "70 0.000 0.000 0.000 0.000 -0.035 -0.097 -0.181  0.033  0.866 0.080 0.048   \n",
       "45 0.000 0.000 0.000 0.000 -0.035 -0.097  0.778 -0.266  0.180 0.187 0.048   \n",
       "44 0.000 0.000 0.000 0.000 -0.035 -0.097  0.624  0.440 -0.698 0.617 0.048   \n",
       "\n",
       "     wb_7   wb_8   wb_9  wb_10  wb_11  wb_12  wb_13  wb_14  wb_15  wb_16  \\\n",
       "83 -0.059 -0.153 -0.050 -0.100  0.026  0.160 -0.119 -0.054  0.058 -0.044   \n",
       "53 -0.059  0.258 -0.408 -0.725 -0.050 -0.114  0.174  0.601  0.075 -0.076   \n",
       "70 -0.059  0.555 -0.572 -0.259 -0.039 -0.102 -0.410  0.301 -0.086 -0.634   \n",
       "45 -0.059  0.010 -0.135 -0.184  0.105 -0.020 -0.144 -0.054  0.028  0.418   \n",
       "44 -0.059  0.119 -0.124 -0.185  0.130 -0.946 -0.188 -0.062  0.077  0.141   \n",
       "\n",
       "    wb_17  wb_18  wb_19  wb_20  wb_21  wb_22  wb_23  wb_24  wb_25  wb_26  \\\n",
       "83 -0.184 -0.007  0.317  0.155 -0.067 -0.195  0.147 -0.278  0.494  0.332   \n",
       "53 -0.267  0.056 -0.020  0.269 -0.160 -0.189  0.155 -0.142  0.165  0.210   \n",
       "70 -0.289 -0.121  0.166  0.161  0.293 -0.189  0.155 -0.480  0.020  0.371   \n",
       "45 -0.306 -0.139 -0.003  0.334 -0.147 -0.189  0.155 -0.101  0.428 -0.138   \n",
       "44 -0.069 -0.607  1.065  0.225  0.109 -0.189  0.155  0.093  0.782  0.118   \n",
       "\n",
       "    wb_27  wb_28  wb_29  wb_30  wb_31  wb_32  wb_33  wb_34  wb_35  wb_36  \\\n",
       "83 -0.042 -0.108 -0.004  0.661  0.012  0.330 -0.017  0.237 -0.216  0.421   \n",
       "53  0.036 -0.108 -0.177 -0.066 -0.700  0.009  0.076  0.109 -0.646 -0.018   \n",
       "70 -0.351 -0.257 -0.035  0.090 -0.283 -0.120  0.165  0.025 -0.518 -0.001   \n",
       "45  0.145 -0.108 -1.150  0.394 -1.251  0.136 -0.212  0.333  0.058 -0.633   \n",
       "44  0.039 -0.108 -1.232  0.661 -0.163  0.293  0.311  0.799 -0.029  0.366   \n",
       "\n",
       "    wb_37  wb_38  wb_39  wb_40  wb_41  wb_42  wb_43  wb_44  wb_45  wb_46  \\\n",
       "83  0.138 -0.223  0.202  0.590 -0.072 -0.117  0.474 -0.210 -0.117 -0.008   \n",
       "53  0.124 -0.051  0.290  0.727 -0.072 -0.117  0.267  0.456 -0.072  0.286   \n",
       "70  0.392 -0.251  0.272  0.766 -1.095 -0.117  0.315  0.136 -0.097 -0.074   \n",
       "45  0.131 -0.287 -0.314 -0.055 -0.362 -0.117  0.489 -0.312 -0.384  0.144   \n",
       "44  0.878 -0.564  0.287  0.510  0.074 -0.117  0.245 -0.875  0.201  0.376   \n",
       "\n",
       "    wb_47  wb_48  wb_49  wb_50  wb_51  wb_52  wb_53  wb_54  wb_55  wb_56  \\\n",
       "83  0.176 -0.142  0.530 -0.079 -0.016  0.310  0.190 -0.208  0.552  0.003   \n",
       "53  0.093 -0.292  0.030  0.057 -0.197  0.927  0.098 -0.208  0.385 -0.050   \n",
       "70  0.023 -0.143 -0.241 -0.134  0.376  0.036  0.176 -0.208 -0.044 -0.081   \n",
       "45  0.083 -0.136  0.843 -0.291  0.010  0.609  0.341 -0.208  0.831  0.112   \n",
       "44  0.909  0.325 -0.173 -0.090  0.017 -0.102  0.297 -0.208 -0.362  0.049   \n",
       "\n",
       "    wb_57  wb_58  wb_59  wb_60  wb_61  wb_62  wb_63  wb_64  wb_65  wb_66  \\\n",
       "83  0.262 -0.183  0.630  0.006  0.361  0.074 -0.219  0.038 -0.174 -0.068   \n",
       "53  0.018 -0.409  0.375  0.165  0.990  0.004 -0.303 -0.057 -0.174 -0.196   \n",
       "70 -0.358 -0.372  0.333  0.045 -0.430 -0.261 -0.209 -0.185 -0.174  0.066   \n",
       "45 -0.238 -0.325  1.007  0.726  0.044  0.215 -0.286  0.334 -0.174 -0.154   \n",
       "44 -0.698 -0.920  0.310  0.765  0.263 -0.395 -0.039 -0.075 -0.174 -0.064   \n",
       "\n",
       "    wb_67  wb_68  wb_69  wb_70  wb_71  wb_72  wb_73  wb_74  wb_75  ...  \\\n",
       "83 -0.629  0.380  0.049 -0.179  0.195 -0.225  0.661  0.590  0.032  ...   \n",
       "53 -0.383 -0.047  1.199 -0.174  0.419  0.881  0.049  0.566  0.154  ...   \n",
       "70 -0.181 -0.160  0.141 -0.174 -0.252  0.062  0.253  0.533  0.125  ...   \n",
       "45 -0.543  0.646  0.083 -0.174  0.296 -0.014 -0.043  0.087 -0.203  ...   \n",
       "44 -0.291  0.614  0.477 -0.174 -0.345  0.479  0.023  0.790 -0.464  ...   \n",
       "\n",
       "    wb_1437  wb_1438  wb_1439  wb_1440  wb_1441  wb_1442  wb_1443  wb_1444  \\\n",
       "83   -1.359   -1.192   -0.578   -0.848   -0.187    3.316    0.346   -1.649   \n",
       "53   -0.177    1.627   -5.102   -0.129   -0.322   -0.038    1.183   -0.102   \n",
       "70   -3.539    0.035   -3.024    6.750   -3.208   -1.832    1.968   -0.115   \n",
       "45   -9.517    0.287  -10.087    2.976   -4.615    4.607   -0.312  -14.264   \n",
       "44   -7.902    2.195   -0.033   -2.266   -2.172    3.152    0.190   -4.283   \n",
       "\n",
       "    wb_1445  wb_1446  wb_1447  wb_1448  wb_1449  wb_1450  wb_1451  wb_1452  \\\n",
       "83   -0.091   -0.082   -0.133   -1.360    0.341   -0.200   -1.761   -0.123   \n",
       "53   -0.079   -0.257   -0.069   -3.638    0.034   -0.200   -0.189   -2.678   \n",
       "70   -0.485   -1.989   -0.550   -2.829    5.899   -0.200   -0.389   -1.547   \n",
       "45   -0.084   -0.185    5.043    0.015   -0.850   -0.200   -6.308    0.073   \n",
       "44   -3.778   -3.360    0.406   -2.308    0.194   -0.200   -4.556   -4.745   \n",
       "\n",
       "    wb_1453  wb_1454  wb_1455  wb_1456  wb_1457  wb_1458  wb_1459  wb_1460  \\\n",
       "83    0.237    1.659    2.844   -0.029   -1.478   -0.119   -0.153    2.652   \n",
       "53    0.552   -0.330    1.215   -2.516   -0.367   -0.220   -2.775    2.915   \n",
       "70    1.427    0.049    0.075   -0.027   -5.864    5.784   -6.939    0.200   \n",
       "45    1.784    0.245    3.411   -0.034   -7.420    0.037   -0.162    2.367   \n",
       "44    3.620    0.254    3.387   -1.983   -0.114    0.427   -0.171    5.220   \n",
       "\n",
       "    wb_1461  wb_1462  wb_1463  wb_1464  wb_1465  wb_1466  wb_1467  wb_1468  \\\n",
       "83    0.111    0.044   -1.993    0.309   -1.672   -1.247   -1.535    2.529   \n",
       "53    0.065    0.044   -1.283    0.018   -0.279   -2.325   -4.131   -0.079   \n",
       "70    0.418    0.044   -2.573    0.397   -2.546   -4.585   -0.338   -0.029   \n",
       "45    0.232    0.044   -6.090   -0.071   -0.201   -0.014   -4.381    3.531   \n",
       "44    0.276    0.044   -3.147    0.070   -2.770    5.726   -3.675    2.973   \n",
       "\n",
       "    wb_1469  wb_1470  wb_1471  wb_1472  wb_1473  wb_1474  wb_1475  wb_1476  \\\n",
       "83   -1.413   -1.087   -0.102   -0.396   -0.111   -0.188    2.661   -1.248   \n",
       "53    5.576   -0.186   -2.344   -0.980   -0.111   -1.888    0.472    1.789   \n",
       "70    1.533   -0.990   -1.882   -1.650   -0.111   -4.837    2.508   -3.675   \n",
       "45    6.400    6.723   -0.009   -6.005   -0.111   -0.001   13.286    2.477   \n",
       "44   -0.483   -2.705   -3.502   -3.801   -0.111   -0.197    4.803   -5.914   \n",
       "\n",
       "    wb_1477  wb_1478  wb_1479  wb_1480  wb_1481  wb_1482  wb_1483  wb_1484  \\\n",
       "83    0.794   -0.191   -0.150    1.182   -1.420   -1.505    1.689    0.071   \n",
       "53    3.516   -0.195   -2.574    5.133   -2.119   -4.241   -0.190    0.326   \n",
       "70    0.138   -0.195   -0.865    2.089   -2.367  -10.064    2.785    0.062   \n",
       "45    0.048   -0.195    0.449    0.655   -0.014   -0.203    4.221    0.018   \n",
       "44    4.983   -0.195   -3.254    6.750   -0.008   -3.165   -2.114   -0.014   \n",
       "\n",
       "    wb_1485  wb_1486  wb_1487  wb_1488  wb_1489  wb_1490  wb_1491  wb_1492  \\\n",
       "83   -1.783   -1.092    0.996    0.358   -1.557   -1.226   -1.096    0.103   \n",
       "53   -4.740   -0.256    4.229    0.544   -0.088   -3.275   -0.199    0.166   \n",
       "70   -4.414   -2.265    2.904    4.913   -1.848   -2.712   -1.592    1.744   \n",
       "45   -0.129   -2.003    0.024   -2.038    3.955  -11.800    0.554    4.855   \n",
       "44   -0.126   -0.046    6.458    0.164    7.139    1.304   -1.802    8.186   \n",
       "\n",
       "    wb_1493  wb_1494  wb_1495  wb_1496  wb_1497  wb_1498  wb_1499  wb_1500  \\\n",
       "83    0.054   -0.084   -1.420   -0.020    0.485    0.292   -0.975   -1.277   \n",
       "53    0.050   -0.113   -0.442   -0.027    4.095    1.432   -0.392   -2.533   \n",
       "70    0.048   -1.203   -1.473   -0.027    2.045    2.976   -0.159   -2.236   \n",
       "45    0.048   -0.102    3.040   -0.027    0.002    4.571   -1.717   -5.966   \n",
       "44    4.791   -2.991    7.280   -0.027   -0.015    0.013    0.269   -7.764   \n",
       "\n",
       "    wb_1501  wb_1502  wb_1503  wb_1504  wb_1505  wb_1506  wb_1507  wb_1508  \\\n",
       "83   -0.243    2.441   -1.304   -1.817   -0.092    0.485    2.702    2.389   \n",
       "53   -0.150    3.194   -0.913   -0.262   -0.092    6.026    3.244    4.304   \n",
       "70   -0.168    0.099   -4.682   -0.070   -0.092    0.081   -0.067   -1.727   \n",
       "45    0.018    0.673   -4.997   -5.996   -0.092    4.378    2.246    0.137   \n",
       "44   -0.032    0.514   -1.514   -3.538   -0.092    2.799    4.748    0.137   \n",
       "\n",
       "    wb_1509  wb_1510  wb_1511  wb_1512  wb_1513  wb_1514  wb_1515  wb_1516  \\\n",
       "83    0.182    2.375    1.488    0.118   -0.159    0.400    0.520    0.125   \n",
       "53    0.175    2.786    3.910    0.052   -3.452    0.132   -1.258    0.125   \n",
       "70    0.182   -1.923    7.260    4.257   -2.107    1.302   -3.682    0.125   \n",
       "45    0.182    0.192    8.100    4.229   -0.145    0.046    4.278    0.125   \n",
       "44    0.176    0.183    2.975    0.130   -4.795    0.325    0.408    0.125   \n",
       "\n",
       "    wb_1517  wb_1518  wb_1519  wb_1520  wb_1521  wb_1522  wb_1523  wb_1524  \\\n",
       "83   -1.192    0.098   -0.717   -0.122    0.457    0.096    0.297   -0.064   \n",
       "53    0.613    3.455    3.631   -0.188    0.494    7.303    1.316   -2.111   \n",
       "70   -3.677    2.262   -3.100    4.828    4.895    0.096    2.564   -2.026   \n",
       "45   -0.089    4.258   -0.003   -0.113   -0.005    0.095   -2.072   -0.828   \n",
       "44    0.904    5.365   -2.721   -0.113    1.061    4.134    0.134   -0.067   \n",
       "\n",
       "    wb_1525  wb_1526  wb_1527  wb_1528  wb_1529  wb_1530  wb_1531  wb_1532  \\\n",
       "83    0.045    1.972   -0.054    0.028   -1.627   -1.921   -0.167   -0.377   \n",
       "53    0.045    3.864   -3.219    0.035   -1.183   -0.135   -3.976   -0.114   \n",
       "70    0.045    0.033   -0.192    0.035   -3.840   -3.040   -2.131   -4.138   \n",
       "45    0.045    3.667   -0.055    0.035  -10.816   -0.109   -3.567   -1.887   \n",
       "44    0.045    0.516   -0.046    0.035   -1.527   -1.223   -7.370   -3.689   \n",
       "\n",
       "    wb_1533  wb_1534  wb_1535  wb_1536  \n",
       "83    2.637    0.136   -0.033    0.156  \n",
       "53    0.364    0.947   -0.033    0.017  \n",
       "70    9.062    1.900   -0.033   -0.157  \n",
       "45   -1.113   -0.377   -0.033   -0.158  \n",
       "44    0.295    0.130   -0.033    0.111  \n",
       "\n",
       "[5 rows x 1561 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:37:40.034923Z",
     "iopub.status.busy": "2022-06-07T15:37:40.034816Z",
     "iopub.status.idle": "2022-06-07T15:37:40.037207Z",
     "shell.execute_reply": "2022-06-07T15:37:40.036716Z",
     "shell.execute_reply.started": "2022-06-07T15:37:40.034907Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset_train.samples_class_0_list_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:37:40.037790Z",
     "iopub.status.busy": "2022-06-07T15:37:40.037695Z",
     "iopub.status.idle": "2022-06-07T15:37:40.084292Z",
     "shell.execute_reply": "2022-06-07T15:37:40.083945Z",
     "shell.execute_reply.started": "2022-06-07T15:37:40.037778Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset_train.distribution_dict_row_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:37:40.084902Z",
     "iopub.status.busy": "2022-06-07T15:37:40.084802Z",
     "iopub.status.idle": "2022-06-07T15:37:40.228217Z",
     "shell.execute_reply": "2022-06-07T15:37:40.227857Z",
     "shell.execute_reply.started": "2022-06-07T15:37:40.084890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambda_net_dataset_train.distribution_dict_list_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:37:40.228798Z",
     "iopub.status.busy": "2022-06-07T15:37:40.228693Z",
     "iopub.status.idle": "2022-06-07T15:37:40.355311Z",
     "shell.execute_reply": "2022-06-07T15:37:40.354824Z",
     "shell.execute_reply.started": "2022-06-07T15:37:40.228785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-06-07T15:37:40.356107Z",
     "iopub.status.busy": "2022-06-07T15:37:40.355916Z",
     "iopub.status.idle": "2022-06-07T15:38:03.635955Z",
     "shell.execute_reply": "2022-06-07T15:38:03.635518Z",
     "shell.execute_reply.started": "2022-06-07T15:37:40.356089Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "network_parameters_structure [(10, 128), (128,), (128, 1), (1,)]\n",
      "Epoch 1/500\n",
      "1/1 - 8s - loss: 0.8303 - binary_accuracy_inet_decision_function_fv_metric: 0.5111 - val_loss: 0.7719 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5052 - lr: 0.0010 - 8s/epoch - 8s/step\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 0.8002 - binary_accuracy_inet_decision_function_fv_metric: 0.4996 - val_loss: 0.8785 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4560 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 0.7990 - binary_accuracy_inet_decision_function_fv_metric: 0.5001 - val_loss: 0.7069 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4696 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 0.7846 - binary_accuracy_inet_decision_function_fv_metric: 0.5067 - val_loss: 0.7147 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4972 - lr: 0.0010 - 78ms/epoch - 78ms/step\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 0.7672 - binary_accuracy_inet_decision_function_fv_metric: 0.5009 - val_loss: 0.6993 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4922 - lr: 0.0010 - 74ms/epoch - 74ms/step\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 0.7698 - binary_accuracy_inet_decision_function_fv_metric: 0.4955 - val_loss: 0.6954 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4944 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 0.7488 - binary_accuracy_inet_decision_function_fv_metric: 0.5043 - val_loss: 0.6988 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4966 - lr: 0.0010 - 86ms/epoch - 86ms/step\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 0.7578 - binary_accuracy_inet_decision_function_fv_metric: 0.4986 - val_loss: 0.6914 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5494 - lr: 0.0010 - 87ms/epoch - 87ms/step\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 0.7619 - binary_accuracy_inet_decision_function_fv_metric: 0.4893 - val_loss: 0.6903 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5522 - lr: 0.0010 - 80ms/epoch - 80ms/step\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 0.7492 - binary_accuracy_inet_decision_function_fv_metric: 0.4887 - val_loss: 0.6892 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5492 - lr: 0.0010 - 75ms/epoch - 75ms/step\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 0.7330 - binary_accuracy_inet_decision_function_fv_metric: 0.5034 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4874 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 0.7388 - binary_accuracy_inet_decision_function_fv_metric: 0.4892 - val_loss: 0.6968 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4832 - lr: 0.0010 - 99ms/epoch - 99ms/step\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 0.7355 - binary_accuracy_inet_decision_function_fv_metric: 0.4962 - val_loss: 0.7003 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5016 - lr: 0.0010 - 92ms/epoch - 92ms/step\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 0.7384 - binary_accuracy_inet_decision_function_fv_metric: 0.5008 - val_loss: 0.6977 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5064 - lr: 0.0010 - 79ms/epoch - 79ms/step\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 0.7495 - binary_accuracy_inet_decision_function_fv_metric: 0.4954 - val_loss: 0.6946 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5474 - lr: 0.0010 - 86ms/epoch - 86ms/step\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 0.7417 - binary_accuracy_inet_decision_function_fv_metric: 0.4901 - val_loss: 0.7138 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5064 - lr: 0.0010 - 87ms/epoch - 87ms/step\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 0.7324 - binary_accuracy_inet_decision_function_fv_metric: 0.5063 - val_loss: 0.7168 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5102 - lr: 0.0010 - 83ms/epoch - 83ms/step\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 0.7318 - binary_accuracy_inet_decision_function_fv_metric: 0.5043 - val_loss: 0.7152 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5092 - lr: 0.0010 - 93ms/epoch - 93ms/step\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 0.7204 - binary_accuracy_inet_decision_function_fv_metric: 0.5090 - val_loss: 0.7102 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5086 - lr: 0.0010 - 91ms/epoch - 91ms/step\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 0.7303 - binary_accuracy_inet_decision_function_fv_metric: 0.4924 - val_loss: 0.7037 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5108 - lr: 0.0010 - 93ms/epoch - 93ms/step\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 0.7213 - binary_accuracy_inet_decision_function_fv_metric: 0.5047 - val_loss: 0.6984 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4958 - lr: 0.0010 - 89ms/epoch - 89ms/step\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 0.7204 - binary_accuracy_inet_decision_function_fv_metric: 0.5094 - val_loss: 0.6955 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4636 - lr: 0.0010 - 86ms/epoch - 86ms/step\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 0.7220 - binary_accuracy_inet_decision_function_fv_metric: 0.5037 - val_loss: 0.6950 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4942 - lr: 0.0010 - 90ms/epoch - 90ms/step\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 0.7175 - binary_accuracy_inet_decision_function_fv_metric: 0.5106 - val_loss: 0.6946 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4956 - lr: 0.0010 - 90ms/epoch - 90ms/step\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 0.7146 - binary_accuracy_inet_decision_function_fv_metric: 0.4996 - val_loss: 0.6941 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4872 - lr: 0.0010 - 101ms/epoch - 101ms/step\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 0.7238 - binary_accuracy_inet_decision_function_fv_metric: 0.5047 - val_loss: 0.7034 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4578 - lr: 0.0010 - 93ms/epoch - 93ms/step\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 0.7218 - binary_accuracy_inet_decision_function_fv_metric: 0.4957 - val_loss: 0.7008 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4706 - lr: 0.0010 - 93ms/epoch - 93ms/step\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 0.7177 - binary_accuracy_inet_decision_function_fv_metric: 0.4960 - val_loss: 0.6985 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5054 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 0.7139 - binary_accuracy_inet_decision_function_fv_metric: 0.5022 - val_loss: 0.6965 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5056 - lr: 0.0010 - 90ms/epoch - 90ms/step\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 0.7157 - binary_accuracy_inet_decision_function_fv_metric: 0.5012 - val_loss: 0.6946 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5060 - lr: 0.0010 - 82ms/epoch - 82ms/step\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 0.7101 - binary_accuracy_inet_decision_function_fv_metric: 0.5036 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4996 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 0.7083 - binary_accuracy_inet_decision_function_fv_metric: 0.5017 - val_loss: 0.6957 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4732 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 0.7064 - binary_accuracy_inet_decision_function_fv_metric: 0.5057 - val_loss: 0.6958 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4704 - lr: 0.0010 - 82ms/epoch - 82ms/step\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 0.7098 - binary_accuracy_inet_decision_function_fv_metric: 0.5029 - val_loss: 0.6962 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4682 - lr: 0.0010 - 80ms/epoch - 80ms/step\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 0.7148 - binary_accuracy_inet_decision_function_fv_metric: 0.4881 - val_loss: 0.6951 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4954 - lr: 0.0010 - 85ms/epoch - 85ms/step\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 0.7037 - binary_accuracy_inet_decision_function_fv_metric: 0.5019 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5086 - lr: 0.0010 - 86ms/epoch - 86ms/step\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 0.7098 - binary_accuracy_inet_decision_function_fv_metric: 0.4978 - val_loss: 0.6924 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5200 - lr: 0.0010 - 89ms/epoch - 89ms/step\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 0.7081 - binary_accuracy_inet_decision_function_fv_metric: 0.5004 - val_loss: 0.6917 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5202 - lr: 0.0010 - 91ms/epoch - 91ms/step\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 0.7034 - binary_accuracy_inet_decision_function_fv_metric: 0.5058 - val_loss: 0.6916 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5288 - lr: 0.0010 - 76ms/epoch - 76ms/step\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 0.7065 - binary_accuracy_inet_decision_function_fv_metric: 0.4994 - val_loss: 0.6920 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5286 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 0.7024 - binary_accuracy_inet_decision_function_fv_metric: 0.5087 - val_loss: 0.6928 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5284 - lr: 0.0010 - 82ms/epoch - 82ms/step\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 0.7040 - binary_accuracy_inet_decision_function_fv_metric: 0.5095 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5040 - lr: 0.0010 - 76ms/epoch - 76ms/step\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 0.6990 - binary_accuracy_inet_decision_function_fv_metric: 0.5140 - val_loss: 0.6941 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5046 - lr: 0.0010 - 90ms/epoch - 90ms/step\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 0.7021 - binary_accuracy_inet_decision_function_fv_metric: 0.5099 - val_loss: 0.6944 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5058 - lr: 0.0010 - 96ms/epoch - 96ms/step\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 0.7036 - binary_accuracy_inet_decision_function_fv_metric: 0.5038 - val_loss: 0.6948 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5026 - lr: 0.0010 - 101ms/epoch - 101ms/step\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 0.7003 - binary_accuracy_inet_decision_function_fv_metric: 0.5036 - val_loss: 0.6959 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4892 - lr: 0.0010 - 88ms/epoch - 88ms/step\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 0.6999 - binary_accuracy_inet_decision_function_fv_metric: 0.5192 - val_loss: 0.6968 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4866 - lr: 0.0010 - 88ms/epoch - 88ms/step\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 0.7007 - binary_accuracy_inet_decision_function_fv_metric: 0.5055 - val_loss: 0.6965 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4862 - lr: 0.0010 - 83ms/epoch - 83ms/step\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 0.7002 - binary_accuracy_inet_decision_function_fv_metric: 0.5129 - val_loss: 0.6960 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4870 - lr: 0.0010 - 94ms/epoch - 94ms/step\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 0.7018 - binary_accuracy_inet_decision_function_fv_metric: 0.4902 - val_loss: 0.6954 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4812 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 0.6997 - binary_accuracy_inet_decision_function_fv_metric: 0.4948 - val_loss: 0.6945 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4802 - lr: 0.0010 - 79ms/epoch - 79ms/step\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 0.7022 - binary_accuracy_inet_decision_function_fv_metric: 0.4944 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4846 - lr: 0.0010 - 82ms/epoch - 82ms/step\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 0.6994 - binary_accuracy_inet_decision_function_fv_metric: 0.5025 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4886 - lr: 0.0010 - 77ms/epoch - 77ms/step\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 0.6996 - binary_accuracy_inet_decision_function_fv_metric: 0.4966 - val_loss: 0.6930 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4890 - lr: 0.0010 - 74ms/epoch - 74ms/step\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 0.6969 - binary_accuracy_inet_decision_function_fv_metric: 0.5098 - val_loss: 0.6928 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4942 - lr: 0.0010 - 81ms/epoch - 81ms/step\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 0.6967 - binary_accuracy_inet_decision_function_fv_metric: 0.5104 - val_loss: 0.6926 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5090 - lr: 0.0010 - 80ms/epoch - 80ms/step\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 0.6980 - binary_accuracy_inet_decision_function_fv_metric: 0.4985 - val_loss: 0.6925 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5076 - lr: 0.0010 - 83ms/epoch - 83ms/step\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 0.6971 - binary_accuracy_inet_decision_function_fv_metric: 0.5130 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5080 - lr: 0.0010 - 82ms/epoch - 82ms/step\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 0.6967 - binary_accuracy_inet_decision_function_fv_metric: 0.4978 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5102 - lr: 0.0010 - 91ms/epoch - 91ms/step\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 0.6994 - binary_accuracy_inet_decision_function_fv_metric: 0.4999 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5108 - lr: 0.0010 - 80ms/epoch - 80ms/step\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 0.6996 - binary_accuracy_inet_decision_function_fv_metric: 0.4823 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5106 - lr: 1.0000e-04 - 81ms/epoch - 81ms/step\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 0.6962 - binary_accuracy_inet_decision_function_fv_metric: 0.5042 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5106 - lr: 1.0000e-04 - 82ms/epoch - 82ms/step\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 0.6973 - binary_accuracy_inet_decision_function_fv_metric: 0.4999 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5106 - lr: 1.0000e-04 - 86ms/epoch - 86ms/step\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 0.6979 - binary_accuracy_inet_decision_function_fv_metric: 0.4982 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5110 - lr: 1.0000e-04 - 95ms/epoch - 95ms/step\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 0.6961 - binary_accuracy_inet_decision_function_fv_metric: 0.4928 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5110 - lr: 1.0000e-04 - 93ms/epoch - 93ms/step\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 0.6981 - binary_accuracy_inet_decision_function_fv_metric: 0.4975 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5110 - lr: 1.0000e-04 - 86ms/epoch - 86ms/step\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 0.6982 - binary_accuracy_inet_decision_function_fv_metric: 0.4948 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5110 - lr: 1.0000e-04 - 81ms/epoch - 81ms/step\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 0.6993 - binary_accuracy_inet_decision_function_fv_metric: 0.4976 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5108 - lr: 1.0000e-04 - 85ms/epoch - 85ms/step\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 0.6961 - binary_accuracy_inet_decision_function_fv_metric: 0.5140 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5108 - lr: 1.0000e-04 - 89ms/epoch - 89ms/step\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 0.6997 - binary_accuracy_inet_decision_function_fv_metric: 0.4934 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5110 - lr: 1.0000e-04 - 82ms/epoch - 82ms/step\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 0.6965 - binary_accuracy_inet_decision_function_fv_metric: 0.5025 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5282 - lr: 1.0000e-04 - 77ms/epoch - 77ms/step\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 0.6949 - binary_accuracy_inet_decision_function_fv_metric: 0.5124 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4902 - lr: 1.0000e-04 - 80ms/epoch - 80ms/step\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 0.6959 - binary_accuracy_inet_decision_function_fv_metric: 0.5085 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4902 - lr: 1.0000e-04 - 86ms/epoch - 86ms/step\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 0.6957 - binary_accuracy_inet_decision_function_fv_metric: 0.5048 - val_loss: 0.6936 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4904 - lr: 1.0000e-04 - 87ms/epoch - 87ms/step\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 0.6986 - binary_accuracy_inet_decision_function_fv_metric: 0.4962 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4906 - lr: 1.0000e-04 - 92ms/epoch - 92ms/step\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 0.6972 - binary_accuracy_inet_decision_function_fv_metric: 0.5062 - val_loss: 0.6942 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4902 - lr: 1.0000e-04 - 88ms/epoch - 88ms/step\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 0.6970 - binary_accuracy_inet_decision_function_fv_metric: 0.4960 - val_loss: 0.6942 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4902 - lr: 1.0000e-04 - 95ms/epoch - 95ms/step\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 0.6951 - binary_accuracy_inet_decision_function_fv_metric: 0.5043 - val_loss: 0.6942 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4858 - lr: 1.0000e-04 - 93ms/epoch - 93ms/step\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 0.6943 - binary_accuracy_inet_decision_function_fv_metric: 0.5091 - val_loss: 0.6942 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4858 - lr: 1.0000e-04 - 91ms/epoch - 91ms/step\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 0.6961 - binary_accuracy_inet_decision_function_fv_metric: 0.5024 - val_loss: 0.6942 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4858 - lr: 1.0000e-04 - 81ms/epoch - 81ms/step\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 0.6973 - binary_accuracy_inet_decision_function_fv_metric: 0.5060 - val_loss: 0.6944 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4858 - lr: 1.0000e-04 - 91ms/epoch - 91ms/step\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 0.6997 - binary_accuracy_inet_decision_function_fv_metric: 0.4879 - val_loss: 0.6944 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4854 - lr: 1.0000e-04 - 82ms/epoch - 82ms/step\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 0.6940 - binary_accuracy_inet_decision_function_fv_metric: 0.5105 - val_loss: 0.6945 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4858 - lr: 1.0000e-04 - 75ms/epoch - 75ms/step\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 0.6939 - binary_accuracy_inet_decision_function_fv_metric: 0.5182 - val_loss: 0.6945 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4876 - lr: 1.0000e-04 - 77ms/epoch - 77ms/step\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 0.6966 - binary_accuracy_inet_decision_function_fv_metric: 0.4982 - val_loss: 0.6946 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4858 - lr: 1.0000e-04 - 84ms/epoch - 84ms/step\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 0.6960 - binary_accuracy_inet_decision_function_fv_metric: 0.5023 - val_loss: 0.6946 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4876 - lr: 1.0000e-04 - 84ms/epoch - 84ms/step\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 0.6977 - binary_accuracy_inet_decision_function_fv_metric: 0.5032 - val_loss: 0.6946 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4892 - lr: 1.0000e-04 - 90ms/epoch - 90ms/step\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 0.6972 - binary_accuracy_inet_decision_function_fv_metric: 0.5032 - val_loss: 0.6947 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4898 - lr: 1.0000e-04 - 98ms/epoch - 98ms/step\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 0.6976 - binary_accuracy_inet_decision_function_fv_metric: 0.4959 - val_loss: 0.6946 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4906 - lr: 1.0000e-04 - 77ms/epoch - 77ms/step\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 0.6959 - binary_accuracy_inet_decision_function_fv_metric: 0.5002 - val_loss: 0.6946 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4908 - lr: 1.0000e-04 - 77ms/epoch - 77ms/step\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 0.6982 - binary_accuracy_inet_decision_function_fv_metric: 0.4956 - val_loss: 0.6945 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4908 - lr: 1.0000e-04 - 79ms/epoch - 79ms/step\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 0.6952 - binary_accuracy_inet_decision_function_fv_metric: 0.5103 - val_loss: 0.6944 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4908 - lr: 1.0000e-04 - 79ms/epoch - 79ms/step\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 0.6943 - binary_accuracy_inet_decision_function_fv_metric: 0.5115 - val_loss: 0.6942 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4958 - lr: 1.0000e-04 - 84ms/epoch - 84ms/step\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 0.6971 - binary_accuracy_inet_decision_function_fv_metric: 0.5050 - val_loss: 0.6941 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5236 - lr: 1.0000e-04 - 87ms/epoch - 87ms/step\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 0.6976 - binary_accuracy_inet_decision_function_fv_metric: 0.5011 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5122 - lr: 1.0000e-04 - 89ms/epoch - 89ms/step\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 0.6988 - binary_accuracy_inet_decision_function_fv_metric: 0.4772 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5126 - lr: 1.0000e-04 - 98ms/epoch - 98ms/step\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 0.6956 - binary_accuracy_inet_decision_function_fv_metric: 0.5064 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5126 - lr: 1.0000e-04 - 90ms/epoch - 90ms/step\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 0.6954 - binary_accuracy_inet_decision_function_fv_metric: 0.5045 - val_loss: 0.6935 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5104 - lr: 1.0000e-04 - 101ms/epoch - 101ms/step\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 0.6965 - binary_accuracy_inet_decision_function_fv_metric: 0.4980 - val_loss: 0.6934 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5138 - lr: 1.0000e-04 - 93ms/epoch - 93ms/step\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 0.6977 - binary_accuracy_inet_decision_function_fv_metric: 0.4903 - val_loss: 0.6933 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5082 - lr: 1.0000e-04 - 79ms/epoch - 79ms/step\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 0.6977 - binary_accuracy_inet_decision_function_fv_metric: 0.5022 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5084 - lr: 1.0000e-04 - 80ms/epoch - 80ms/step\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 0.6947 - binary_accuracy_inet_decision_function_fv_metric: 0.5173 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5132 - lr: 1.0000e-04 - 84ms/epoch - 84ms/step\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 0.6957 - binary_accuracy_inet_decision_function_fv_metric: 0.4955 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5132 - lr: 1.0000e-04 - 85ms/epoch - 85ms/step\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 0.6960 - binary_accuracy_inet_decision_function_fv_metric: 0.5075 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5132 - lr: 1.0000e-04 - 93ms/epoch - 93ms/step\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 0.6952 - binary_accuracy_inet_decision_function_fv_metric: 0.4996 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5132 - lr: 1.0000e-04 - 96ms/epoch - 96ms/step\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 0.6964 - binary_accuracy_inet_decision_function_fv_metric: 0.5008 - val_loss: 0.6931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5132 - lr: 1.0000e-04 - 98ms/epoch - 98ms/step\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 0.6967 - binary_accuracy_inet_decision_function_fv_metric: 0.5034 - val_loss: 0.6932 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5072 - lr: 1.0000e-04 - 99ms/epoch - 99ms/step\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 0.6962 - binary_accuracy_inet_decision_function_fv_metric: 0.4974 - val_loss: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5242 - lr: 1.0000e-04 - 87ms/epoch - 87ms/step\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 0.6963 - binary_accuracy_inet_decision_function_fv_metric: 0.4956 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5304 - lr: 1.0000e-04 - 86ms/epoch - 86ms/step\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 0.6948 - binary_accuracy_inet_decision_function_fv_metric: 0.5111 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5260 - lr: 1.0000e-04 - 91ms/epoch - 91ms/step\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 0.6985 - binary_accuracy_inet_decision_function_fv_metric: 0.4948 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5260 - lr: 1.0000e-05 - 95ms/epoch - 95ms/step\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 0.6969 - binary_accuracy_inet_decision_function_fv_metric: 0.5026 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5262 - lr: 1.0000e-05 - 93ms/epoch - 93ms/step\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 0.6965 - binary_accuracy_inet_decision_function_fv_metric: 0.4956 - val_loss: 0.6938 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5264 - lr: 1.0000e-05 - 96ms/epoch - 96ms/step\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 0.6938 - binary_accuracy_inet_decision_function_fv_metric: 0.5172 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5264 - lr: 1.0000e-05 - 92ms/epoch - 92ms/step\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 0.6947 - binary_accuracy_inet_decision_function_fv_metric: 0.5106 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5264 - lr: 1.0000e-05 - 97ms/epoch - 97ms/step\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 0.6980 - binary_accuracy_inet_decision_function_fv_metric: 0.4874 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5262 - lr: 1.0000e-05 - 86ms/epoch - 86ms/step\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 0.6973 - binary_accuracy_inet_decision_function_fv_metric: 0.5026 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5262 - lr: 1.0000e-05 - 84ms/epoch - 84ms/step\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 0.6954 - binary_accuracy_inet_decision_function_fv_metric: 0.5124 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5264 - lr: 1.0000e-05 - 101ms/epoch - 101ms/step\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 0.6951 - binary_accuracy_inet_decision_function_fv_metric: 0.5082 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5264 - lr: 1.0000e-05 - 88ms/epoch - 88ms/step\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 0.6976 - binary_accuracy_inet_decision_function_fv_metric: 0.4946 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5264 - lr: 1.0000e-05 - 92ms/epoch - 92ms/step\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 0.6951 - binary_accuracy_inet_decision_function_fv_metric: 0.5140 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5262 - lr: 1.0000e-05 - 85ms/epoch - 85ms/step\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 0.6969 - binary_accuracy_inet_decision_function_fv_metric: 0.4989 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5200 - lr: 1.0000e-05 - 88ms/epoch - 88ms/step\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 0.6951 - binary_accuracy_inet_decision_function_fv_metric: 0.5045 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5200 - lr: 1.0000e-05 - 90ms/epoch - 90ms/step\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 0.6974 - binary_accuracy_inet_decision_function_fv_metric: 0.4994 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5200 - lr: 1.0000e-05 - 89ms/epoch - 89ms/step\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 0.6954 - binary_accuracy_inet_decision_function_fv_metric: 0.4956 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5138 - lr: 1.0000e-05 - 87ms/epoch - 87ms/step\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 0.6960 - binary_accuracy_inet_decision_function_fv_metric: 0.5021 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5136 - lr: 1.0000e-05 - 86ms/epoch - 86ms/step\n",
      "Epoch 127/500\n",
      "1/1 - 0s - loss: 0.6962 - binary_accuracy_inet_decision_function_fv_metric: 0.5000 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5146 - lr: 1.0000e-05 - 94ms/epoch - 94ms/step\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 0.6952 - binary_accuracy_inet_decision_function_fv_metric: 0.5135 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5168 - lr: 1.0000e-05 - 82ms/epoch - 82ms/step\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 0.6958 - binary_accuracy_inet_decision_function_fv_metric: 0.4994 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5170 - lr: 1.0000e-05 - 84ms/epoch - 84ms/step\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 0.6957 - binary_accuracy_inet_decision_function_fv_metric: 0.5039 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5136 - lr: 1.0000e-05 - 90ms/epoch - 90ms/step\n",
      "Epoch 131/500\n",
      "1/1 - 0s - loss: 0.6953 - binary_accuracy_inet_decision_function_fv_metric: 0.5064 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5136 - lr: 1.0000e-05 - 84ms/epoch - 84ms/step\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 0.6954 - binary_accuracy_inet_decision_function_fv_metric: 0.5050 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5118 - lr: 1.0000e-05 - 86ms/epoch - 86ms/step\n",
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 0.6949 - binary_accuracy_inet_decision_function_fv_metric: 0.5152 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5118 - lr: 1.0000e-05 - 82ms/epoch - 82ms/step\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 0.6966 - binary_accuracy_inet_decision_function_fv_metric: 0.5014 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5118 - lr: 1.0000e-05 - 84ms/epoch - 84ms/step\n",
      "Epoch 135/500\n",
      "1/1 - 0s - loss: 0.6944 - binary_accuracy_inet_decision_function_fv_metric: 0.5144 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5182 - lr: 1.0000e-05 - 86ms/epoch - 86ms/step\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 0.6937 - binary_accuracy_inet_decision_function_fv_metric: 0.5124 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5182 - lr: 1.0000e-05 - 90ms/epoch - 90ms/step\n",
      "Epoch 137/500\n",
      "1/1 - 0s - loss: 0.6931 - binary_accuracy_inet_decision_function_fv_metric: 0.5168 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5182 - lr: 1.0000e-05 - 98ms/epoch - 98ms/step\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 0.6966 - binary_accuracy_inet_decision_function_fv_metric: 0.5006 - val_loss: 0.6939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5192 - lr: 1.0000e-05 - 98ms/epoch - 98ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as activation_2_layer_call_fn, activation_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0:00:22\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model,\n",
    " encoder_model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=plot_losses\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate I-Net Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:03.636984Z",
     "iopub.status.busy": "2022-06-07T15:38:03.636723Z",
     "iopub.status.idle": "2022-06-07T15:38:03.765523Z",
     "shell.execute_reply": "2022-06-07T15:38:03.764917Z",
     "shell.execute_reply.started": "2022-06-07T15:38:03.636959Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "        \n",
    "    writepath_nas = './results_nas.csv'\n",
    "\n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "\n",
    "    if not os.path.exists(writepath_nas):\n",
    "        with open(writepath_nas, 'w+') as text_file:       \n",
    "            for key in flat_config.keys():\n",
    "                text_file.write(key)\n",
    "                text_file.write(';')         \n",
    "\n",
    "            for hp in history[0].hyperparameters.values.keys():\n",
    "                text_file.write(hp + ';')    \n",
    "               \n",
    "            text_file.write('score')\n",
    "            \n",
    "            text_file.write('\\n')\n",
    "\n",
    "    with open(writepath_nas, 'a+') as text_file:  \n",
    "        for value in flat_config.values():\n",
    "            text_file.write(str(value))\n",
    "            text_file.write(';')\n",
    "\n",
    "        for hp, value in history[0].hyperparameters.values.items():\n",
    "            text_file.write(str(value) + ';')        \n",
    "\n",
    "        \n",
    "        text_file.write(str(history[0].score))\n",
    "            \n",
    "        text_file.write('\\n')            \n",
    "\n",
    "        text_file.close()      \n",
    "        \n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make_classification evaluation Paul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:26:31.611364Z",
     "iopub.status.busy": "2022-06-07T16:26:31.611193Z",
     "iopub.status.idle": "2022-06-07T16:26:32.380384Z",
     "shell.execute_reply": "2022-06-07T16:26:32.379983Z",
     "shell.execute_reply.started": "2022-06-07T16:26:31.611343Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_LR = {\n",
    "    'data': {\n",
    "        'n_datasets': 10,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:37:30.597757Z",
     "iopub.status.busy": "2022-06-07T16:37:30.597568Z",
     "iopub.status.idle": "2022-06-07T16:37:32.301828Z",
     "shell.execute_reply": "2022-06-07T16:37:32.301314Z",
     "shell.execute_reply.started": "2022-06-07T16:37:30.597739Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, mean_squared_error\n",
    "\n",
    "def precision(tp, fp, tn, fn):\n",
    "    return tp / (tp + fp)\n",
    "def recall(tp, fp, tn, fn):\n",
    "    return tp / (tp + fn)\n",
    "def f1(tp, fp, tn, fn):\n",
    "    pre = precision(tp, fp, tn, fn)\n",
    "    rec = recall(tp, fp, tn, fn)\n",
    "    return 2 * (pre * rec) / (pre + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:41:59.410995Z",
     "iopub.status.busy": "2022-06-07T16:41:59.410818Z",
     "iopub.status.idle": "2022-06-07T16:41:59.998179Z",
     "shell.execute_reply": "2022-06-07T16:41:59.997576Z",
     "shell.execute_reply.started": "2022-06-07T16:41:59.410978Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluateSingleSample(i, loss_function, metrics, config):\n",
    "    \n",
    "    informative = np.random.randint(config['data']['number_of_variables']//2, high=config['data']['number_of_variables']+1) #config['data']['number_of_variables']\n",
    "    redundant = np.random.randint(0, high=config['data']['number_of_variables']-informative+1) #0\n",
    "    repeated = config['data']['number_of_variables']-informative-redundant # 0\n",
    "\n",
    "    n_clusters_per_class =  max(2, np.random.randint(0, high=informative//2+1)) #2\n",
    "\n",
    "    X_data, y_data = make_classification(n_samples=config['data']['lambda_dataset_size'], \n",
    "                                                       n_features=config['data']['number_of_variables'], #The total number of features. These comprise n_informative informative features, n_redundant redundant features, n_repeated duplicated features and n_features-n_informative-n_redundant-n_repeated useless features drawn at random.\n",
    "                                                       n_informative=informative,#config['data']['number_of_variables'], #The number of informative features. Each class is composed of a number of gaussian clusters each located around the vertices of a hypercube in a subspace of dimension n_informative.\n",
    "                                                       n_redundant=redundant, #The number of redundant features. These features are generated as random linear combinations of the informative features.\n",
    "                                                       n_repeated=repeated, #The number of duplicated features, drawn randomly from the informative and the redundant features.\n",
    "                                                       n_classes=config['data']['num_classes'], \n",
    "                                                       n_clusters_per_class=n_clusters_per_class, \n",
    "                                                       #flip_y=0.0, #The fraction of samples whose class is assigned randomly. \n",
    "                                                       #class_sep=1.0, #The factor multiplying the hypercube size. Larger values spread out the clusters/classes and make the classification task easier.\n",
    "                                                       #hypercube=False, #If True, the clusters are put on the vertices of a hypercube. If False, the clusters are put on the vertices of a random polytope.\n",
    "                                                       #shift=0.0, #Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep].\n",
    "                                                       #scale=1.0, #Multiply features by the specified value. \n",
    "                                                       shuffle=True, \n",
    "                                                       random_state=100_000+i) \n",
    "    \n",
    "    ## normalisierung\n",
    "    for i, column in enumerate(X_data.T):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(column.reshape(-1, 1))\n",
    "        X_data[:,i] = scaler.transform(column.reshape(-1, 1)).ravel()    \n",
    "    \n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = split_train_test_valid(X_data, y_data, valid_frac=0.25, test_frac=0.1, seed=42)\n",
    "    \n",
    "    \n",
    "    lambda_net = generate_base_model(config)\n",
    "    \n",
    "    x_lambda_weights = shaped_network_parameters_to_array(lambda_net.get_weights(), config)\n",
    "    \n",
    "    \n",
    "    #### so meinte ich das quasi wie du ein logistic regression model basierend auf den lambda-net predictions bekommst ###\n",
    "    #model_valid = LogisticRegression()\n",
    "    #model_valid.fit(X_data, network_parameters_to_network(x_lambda_weights, config).predict(X_train))      \n",
    "    #y_coef_truth = model_valid.coef_\n",
    "\n",
    "        \n",
    "    inet_model = load_inet(loss_function, metrics, config)\n",
    "    \n",
    "    y_dt_pred = inet_model.predict(x_lambda_weights.reshape(1, -1))\n",
    "    y_dt_pred = y_dt_pred[0]\n",
    "    \n",
    "    ## hier für den vergleich dann das model auch auf den network parameters trainieren ###\n",
    "    #model_groundTruth = get_LR(X_train, network_parameters_to_network(x_lambda_weights, config).predict(X_train)\n",
    "    \n",
    "    #model_pred = LogisticRegression()\n",
    "    #model_pred.coef_ = y_coef_pred\n",
    "    #model_pred.intercept_ = 0\n",
    "    #model_pred.classes_ = model_groundTruth.classes_\n",
    "    \n",
    "    \n",
    "    model_pred_inet = parameterDT(y_dt_pred, config)\n",
    "    \n",
    "    y_train_lambda_net = network_parameters_to_network(x_lambda_weights, config).predict(X_train)\n",
    "    model_standard = DecisionTreeClassifier(max_depth=config['function_family']['maximum_depth']) \n",
    "    model_standard.fit(X_train, np.round(y_train_lambda_net))\n",
    "    \n",
    "    y_lambda_net = np.round(network_parameters_to_network(x_lambda_weights, config).predict(X_test)).flatten()\n",
    "    \n",
    "    score_standard_model = model_standard.score(X_test, y_lambda_net)\n",
    "\n",
    "    y_pred_standard_model = np.round(model_standard.predict(X_test))\n",
    "    y_pred_inet_model  = np.round(model_pred_inet.predict(X_test))\n",
    "    \n",
    "    score_inet_model = accuracy_score(y_lambda_net, y_pred_inet_model)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_lambda_net, y_pred_inet_model, labels=[1,0]).ravel()\n",
    "    \n",
    "    pre = precision(tp, fp, tn, fn)\n",
    "    rec = recall(tp, fp, tn, fn)\n",
    "    fone = f1(tp, fp, tn, fn)\n",
    "    \n",
    "    #results.append([i, score_groundTruthModel, score_predModel, mse, tp, fn, fp, tn, pre, rec, fone])\n",
    "    \n",
    "    return i+1, score_standard_model, score_inet_model, tp, fn, fp, tn, pre, rec, fone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:42:41.925906Z",
     "iopub.status.busy": "2022-06-07T16:42:41.925717Z",
     "iopub.status.idle": "2022-06-07T16:42:53.468736Z",
     "shell.execute_reply": "2022-06-07T16:42:53.467941Z",
     "shell.execute_reply.started": "2022-06-07T16:42:41.925885Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   3 out of  10 | elapsed:   11.2s remaining:   26.2s\n",
      "[Parallel(n_jobs=15)]: Done   5 out of  10 | elapsed:   11.3s remaining:   11.3s\n",
      "[Parallel(n_jobs=15)]: Done   7 out of  10 | elapsed:   11.4s remaining:    4.9s\n",
      "[Parallel(n_jobs=15)]: Done  10 out of  10 | elapsed:   11.5s finished\n"
     ]
    }
   ],
   "source": [
    "parallel = Parallel(n_jobs=config['computation']['n_jobs'], verbose=10, backend='loky') #loky\n",
    "\n",
    "result_list = parallel(delayed(evaluateSingleSample)(i, loss_function, metrics, config) for i in range(config_LR['data']['n_datasets']))\n",
    "\n",
    "results = pd.DataFrame(data=result_list,\n",
    "                       columns=[\"index_0=aggregated\", \n",
    "                                \"scoreOnClassfication_BaseModel\", \n",
    "                                \"scoreOnClassfication_PredictedModel\" , \n",
    "                                #\"mse\",  \n",
    "                                \"tp\", \n",
    "                                \"fn\", \n",
    "                                \"fp\", \n",
    "                                \"tn\", \n",
    "                                \"precision\", \n",
    "                                \"recall\", \n",
    "                                \"f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:42:53.470518Z",
     "iopub.status.busy": "2022-06-07T16:42:53.470264Z",
     "iopub.status.idle": "2022-06-07T16:42:53.533184Z",
     "shell.execute_reply": "2022-06-07T16:42:53.532583Z",
     "shell.execute_reply.started": "2022-06-07T16:42:53.470490Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_0=aggregated</th>\n",
       "      <th>scoreOnClassfication_BaseModel</th>\n",
       "      <th>scoreOnClassfication_PredictedModel</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.466</td>\n",
       "      <td>233</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.660</td>\n",
       "      <td>329</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.620</td>\n",
       "      <td>307</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>300</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.670</td>\n",
       "      <td>334</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.570</td>\n",
       "      <td>280</td>\n",
       "      <td>211</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>209</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.600</td>\n",
       "      <td>298</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.558</td>\n",
       "      <td>267</td>\n",
       "      <td>217</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.602</td>\n",
       "      <td>292</td>\n",
       "      <td>190</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_0=aggregated  scoreOnClassfication_BaseModel  \\\n",
       "0                  10                           1.000   \n",
       "1                  10                           1.000   \n",
       "2                  10                           0.990   \n",
       "3                  10                           1.000   \n",
       "4                  10                           0.994   \n",
       "5                  10                           0.976   \n",
       "6                  10                           1.000   \n",
       "7                  10                           0.994   \n",
       "8                  10                           0.980   \n",
       "9                  10                           0.984   \n",
       "\n",
       "   scoreOnClassfication_PredictedModel   tp   fn  fp  tn  precision  recall  \\\n",
       "0                                0.466  233  267   0   0      1.000   0.466   \n",
       "1                                0.660  329  170   0   1      1.000   0.659   \n",
       "2                                0.620  307  189   1   3      0.997   0.619   \n",
       "3                                0.600  300  200   0   0      1.000   0.600   \n",
       "4                                0.670  334  163   2   1      0.994   0.672   \n",
       "5                                0.570  280  211   4   5      0.986   0.570   \n",
       "6                                0.418  209  291   0   0      1.000   0.418   \n",
       "7                                0.600  298  200   0   2      1.000   0.598   \n",
       "8                                0.558  267  217   4  12      0.985   0.552   \n",
       "9                                0.602  292  190   9   9      0.970   0.606   \n",
       "\n",
       "     f1  \n",
       "0 0.636  \n",
       "1 0.795  \n",
       "2 0.764  \n",
       "3 0.750  \n",
       "4 0.802  \n",
       "5 0.723  \n",
       "6 0.590  \n",
       "7 0.749  \n",
       "8 0.707  \n",
       "9 0.746  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ab hier ignorieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:03.766469Z",
     "iopub.status.busy": "2022-06-07T15:38:03.766294Z",
     "iopub.status.idle": "2022-06-07T15:38:03.774004Z",
     "shell.execute_reply": "2022-06-07T15:38:03.773563Z",
     "shell.execute_reply.started": "2022-06-07T15:38:03.766445Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    index = 0\n",
    "    lambda_net = lambda_net_dataset_train.lambda_net_list[index]\n",
    "    \n",
    "    lambda_net_model = network_parameters_to_network(lambda_net.network_parameters, config)\n",
    "    lambda_net_model_preds = lambda_net_model.predict(lambda_net.X_train_lambda)\n",
    "    dt_train_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_train_data.fit(lambda_net.X_train_lambda, np.round(lambda_net_model_preds))\n",
    "    \n",
    "    random_data = np.random.uniform(0, 1, lambda_net.X_train_lambda.shape)\n",
    "    lambda_net_model_preds_random = lambda_net_model.predict(random_data)\n",
    "    dt_random_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_random_data.fit(random_data, np.round(lambda_net_model_preds_random))\n",
    "    \n",
    "    plot_decision_area_evaluation(lambda_net.X_train_lambda, \n",
    "                                lambda_net.y_train_lambda.flatten(), \n",
    "                                lambda_net.X_test_lambda, \n",
    "                                lambda_net.y_test_lambda.flatten(),\n",
    "                                random_data,\n",
    "                                lambda_net_model_preds_random.flatten(),                                   \n",
    "                                lambda_net_model,\n",
    "                                dt_train_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                model.predict(np.array([lambda_net.network_parameters]))[0],\n",
    "                                np.array([str(i) for i in range(lambda_net.X_train_lambda.shape[1])]),\n",
    "                                config\n",
    "                               )\n",
    "\n",
    "    index = 0\n",
    "    lambda_net = lambda_net_dataset_valid.lambda_net_list[index]\n",
    "    \n",
    "    lambda_net_model = network_parameters_to_network(lambda_net.network_parameters, config)\n",
    "    lambda_net_model_preds = lambda_net_model.predict(lambda_net.X_train_lambda)\n",
    "    dt_train_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_train_data.fit(lambda_net.X_train_lambda, np.round(lambda_net_model_preds))\n",
    "    \n",
    "    random_data = np.random.uniform(0, 1, lambda_net.X_train_lambda.shape)\n",
    "    lambda_net_model_preds_random = lambda_net_model.predict(random_data)\n",
    "    dt_random_data = DecisionTreeClassifier(max_depth=3)\n",
    "    dt_random_data.fit(random_data, np.round(lambda_net_model_preds_random))\n",
    "    \n",
    "    plot_decision_area_evaluation(lambda_net.X_train_lambda, \n",
    "                                lambda_net.y_train_lambda.flatten(), \n",
    "                                lambda_net.X_test_lambda, \n",
    "                                lambda_net.y_test_lambda.flatten(),\n",
    "                                random_data,\n",
    "                                lambda_net_model_preds_random.flatten(), \n",
    "                                lambda_net_model,\n",
    "                                dt_train_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                dt_random_data,\n",
    "                                model.predict(np.array([lambda_net.network_parameters]))[0],\n",
    "                                np.array([str(i) for i in range(lambda_net.X_train_lambda.shape[1])]),\n",
    "                                config\n",
    "                               )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:03.775033Z",
     "iopub.status.busy": "2022-06-07T15:38:03.774669Z",
     "iopub.status.idle": "2022-06-07T15:38:05.896781Z",
     "shell.execute_reply": "2022-06-07T15:38:05.896090Z",
     "shell.execute_reply.started": "2022-06-07T15:38:03.775008Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "if test_size > 0 and not evaluate_distribution:\n",
    "    network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "else:\n",
    "    network_parameters = np.array([lambda_net_dataset_valid.network_parameters_array[index]])\n",
    "    \n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    encoder_model = load_encoder_model(config)\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data(network_parameters, config, encoder_model)    \n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:05.898224Z",
     "iopub.status.busy": "2022-06-07T15:38:05.898003Z",
     "iopub.status.idle": "2022-06-07T15:38:05.902287Z",
     "shell.execute_reply": "2022-06-07T15:38:05.901751Z",
     "shell.execute_reply.started": "2022-06-07T15:38:05.898195Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = None\n",
    "if not function_value_loss:\n",
    "    if test_size > 0 and not evaluate_distribution:\n",
    "        dt_parameters = y_test[index][:-2 ** config['function_family']['maximum_depth'] ]\n",
    "    else:\n",
    "        dt_parameters = y_valid[index][:-2 ** config['function_family']['maximum_depth'] ]\n",
    "\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:05.903600Z",
     "iopub.status.busy": "2022-06-07T15:38:05.903175Z",
     "iopub.status.idle": "2022-06-07T15:38:05.950541Z",
     "shell.execute_reply": "2022-06-07T15:38:05.949842Z",
     "shell.execute_reply.started": "2022-06-07T15:38:05.903570Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 1537)]       0           []                               \n",
      "                                                                                                  \n",
      " hidden1_1792 (Dense)           (None, 1792)         2756096     ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation1_sigmoid (Activatio  (None, 1792)        0           ['hidden1_1792[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " hidden2_512 (Dense)            (None, 512)          918016      ['activation1_sigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " activation2_sigmoid (Activatio  (None, 512)         0           ['hidden2_512[0][0]']            \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " hidden3_512 (Dense)            (None, 512)          262656      ['activation2_sigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " activation3_sigmoid (Activatio  (None, 512)         0           ['hidden3_512[0][0]']            \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " dropout3_0.5 (Dropout)         (None, 512)          0           ['activation3_sigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " output_coeff_70 (Dense)        (None, 70)           35910       ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_1 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_2 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_3 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_4 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_5 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_6 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_identifier_7 (Dense)    (None, 10)           5130        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_leaf_node_8 (Dense)     (None, 8)            4104        ['dropout3_0.5[0][0]']           \n",
      "                                                                                                  \n",
      " output_combined (Concatenate)  (None, 148)          0           ['output_coeff_70[0][0]',        \n",
      "                                                                  'output_identifier_1[0][0]',    \n",
      "                                                                  'output_identifier_2[0][0]',    \n",
      "                                                                  'output_identifier_3[0][0]',    \n",
      "                                                                  'output_identifier_4[0][0]',    \n",
      "                                                                  'output_identifier_5[0][0]',    \n",
      "                                                                  'output_identifier_6[0][0]',    \n",
      "                                                                  'output_identifier_7[0][0]',    \n",
      "                                                                  'output_leaf_node_8[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,012,692\n",
      "Trainable params: 4,012,692\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Normal: This is useful for looking at means and other linear combinations (e.g. regression coefficients) because of the CLT. Related to that is if something is known to arise due to additive effects of many different small causes then the normal may be a reasonable distribution: for example, many biological measures are the result of multiple genes and multiple environmental factors and therefor are often approximately normal.\n",
    "\n",
    "    Gamma: Right skewed and useful for things with a natural minimum at 0. Commonly used for elapsed times and some financial variables.\n",
    "\n",
    "    Exponential: special case of the Gamma. It is memoryless and scales easily.\n",
    "\n",
    "    Chi-squared (𝜒2): special case of the Gamma. Arises as sum of squared normal variables (so used for variances).\n",
    "\n",
    "    Beta: Defined between 0 and 1 (but could be transformed to be between other values), useful for proportions or other quantities that must be between 0 and 1.\n",
    "\n",
    "    Binomial: How many \"successes\" out of a given number of independent trials with same probability of \"success\".\n",
    "\n",
    "    Poisson: Common for counts. Nice properties that if the number of events in a period of time or area follows a Poisson, then the number in twice the time or area still follows the Poisson (with twice the mean): this works for adding Poissons or scaling with values other than 2.\n",
    "\n",
    "    Note that if events occur over time and the time between occurrences follows an exponential then the number that occur in a time period follows a Poisson.\n",
    "\n",
    "    Negative Binomial: Counts with minimum 0 (or other value depending on which version) and no upper bound. Conceptually it is the number of \"failures\" before k \"successes\". The negative binomial is also a mixture of Poisson variables whose means come from a gamma distribution.\n",
    "\n",
    "    Geometric: special case for negative binomial where it is the number of \"failures\" before the 1st \"success\". If you truncate (round down) an exponential variable to make it discrete, the result is geometric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train & Valid Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:05.952235Z",
     "iopub.status.busy": "2022-06-07T15:38:05.951727Z",
     "iopub.status.idle": "2022-06-07T15:38:07.897483Z",
     "shell.execute_reply": "2022-06-07T15:38:07.897115Z",
     "shell.execute_reply.started": "2022-06-07T15:38:05.952193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d11c737d954dc999dd8f8b59a8f437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25adb92b33974cf89672f439b59afbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mean_train_parameters = np.round(np.mean(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "std_train_parameters = np.round(np.std(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "\n",
    "(inet_evaluation_result_dict_train, \n",
    " inet_evaluation_result_dict_mean_train, \n",
    " dt_distilled_list_train,\n",
    " distances_dict) = evaluate_interpretation_net_synthetic_data(lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               lambda_net_dataset_train.X_test_lambda_array,\n",
    "                                                               model,\n",
    "                                                               config,\n",
    "                                                               identifier='train',\n",
    "                                                               mean_train_parameters=mean_train_parameters,\n",
    "                                                               std_train_parameters=std_train_parameters,\n",
    "                                                               network_parameters_train_array=lambda_net_dataset_train.network_parameters_array)\n",
    "\n",
    "\n",
    "(inet_evaluation_result_dict_valid, \n",
    " inet_evaluation_result_dict_mean_valid, \n",
    " dt_distilled_list_valid,\n",
    " distances_dict) = evaluate_interpretation_net_synthetic_data(lambda_net_dataset_valid.network_parameters_array, \n",
    "                                                               lambda_net_dataset_valid.X_test_lambda_array,\n",
    "                                                               model,\n",
    "                                                               config,\n",
    "                                                               identifier='valid',\n",
    "                                                               mean_train_parameters=mean_train_parameters,\n",
    "                                                               std_train_parameters=std_train_parameters,\n",
    "                                                               network_parameters_train_array=lambda_net_dataset_train.network_parameters_array,\n",
    "                                                               distances_dict=distances_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T10:48:37.785965Z",
     "iopub.status.busy": "2022-02-26T10:48:37.785727Z",
     "iopub.status.idle": "2022-02-26T10:48:38.372347Z",
     "shell.execute_reply": "2022-02-26T10:48:38.371431Z",
     "shell.execute_reply.started": "2022-02-26T10:48:37.785945Z"
    },
    "tags": []
   },
   "source": [
    "## Test Data Evaluation (+ Distribution Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:07.898153Z",
     "iopub.status.busy": "2022-06-07T15:38:07.898025Z",
     "iopub.status.idle": "2022-06-07T15:38:10.735771Z",
     "shell.execute_reply": "2022-06-07T15:38:10.735173Z",
     "shell.execute_reply.started": "2022-06-07T15:38:07.898135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#set_loky_pickler('pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:10.736746Z",
     "iopub.status.busy": "2022-06-07T15:38:10.736574Z",
     "iopub.status.idle": "2022-06-07T15:38:10.794533Z",
     "shell.execute_reply": "2022-06-07T15:38:10.794031Z",
     "shell.execute_reply.started": "2022-06-07T15:38:10.736722Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#config['computation']['n_jobs'] = 60\n",
    "#config['i_net']['test_size'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:10.795586Z",
     "iopub.status.busy": "2022-06-07T15:38:10.795451Z",
     "iopub.status.idle": "2022-06-07T15:38:21.644322Z",
     "shell.execute_reply": "2022-06-07T15:38:21.643910Z",
     "shell.execute_reply.started": "2022-06-07T15:38:10.795566Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 out of   5 | elapsed:    8.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed:   10.7s finished\n"
     ]
    }
   ],
   "source": [
    "if evaluate_distribution and test_size > 0:\n",
    "    \n",
    "    (distances_dict, \n",
    "     inet_evaluation_result_dict_test, \n",
    "     inet_evaluation_result_dict_complete_by_distribution_test,\n",
    "     inet_evaluation_result_dict_mean_test,\n",
    "     inet_evaluation_result_dict_mean_by_distribution_test,\n",
    "     inet_evaluation_results_test, \n",
    "     dt_inet_list_test, \n",
    "     dt_distilled_list_test, \n",
    "     data_dict_list_test, \n",
    "     normalizer_list_list_test,\n",
    "     test_network_list_distrib,\n",
    "     model_history_list,\n",
    "     distribution_parameter_list_list) = distribution_evaluation_interpretation_net_synthetic_data(loss_function, \n",
    "                                                                                            metrics,\n",
    "                                                                                            #model,\n",
    "                                                                                           config,\n",
    "                                                                                           distribution_list_evaluation = config['data']['distribution_list_eval'],#['uniform', 'normal', 'gamma', 'exponential', 'beta', 'binomial', 'poisson'],\n",
    "                                                                                           identifier='test',\n",
    "                                                                                           lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                                           mean_train_parameters=mean_train_parameters,\n",
    "                                                                                           std_train_parameters=std_train_parameters,\n",
    "                                                                                           distances_dict=distances_dict,\n",
    "                                                                                           max_distributions_per_class=max_distributions_per_class,#max_distributions_per_class,\n",
    "                                                                                           flip_percentage=noise_injected_level, #0.1,#\n",
    "                                                                                           data_noise=data_noise, #0.1,#\n",
    "                                                                                           random_parameters = random_parameters_distribution, #random_parameters_distribution\n",
    "                                                                                           verbose=0,\n",
    "                                                                                           backend='loky',#sequential\n",
    "                                                                                    )\n",
    "else:\n",
    "    (inet_evaluation_result_dict_test, \n",
    "     inet_evaluation_result_dict_mean_test, \n",
    "     dt_distilled_list_test,\n",
    "     distances_dict) = evaluate_interpretation_net_synthetic_data(lambda_net_dataset_test.network_parameters_array, \n",
    "                                                                   lambda_net_dataset_test.X_test_lambda_array,\n",
    "                                                                   model,\n",
    "                                                                   config,\n",
    "                                                                   identifier='test',\n",
    "                                                                   mean_train_parameters=mean_train_parameters,\n",
    "                                                                   std_train_parameters=std_train_parameters,\n",
    "                                                                   network_parameters_train_array=lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                   distances_dict=distances_dict)\n",
    "    \n",
    "    print_results_synthetic_evaluation(inet_evaluation_result_dict_mean_train, \n",
    "                                       inet_evaluation_result_dict_mean_valid, \n",
    "                                       inet_evaluation_result_dict_mean_test, \n",
    "                                       distances_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:21.645124Z",
     "iopub.status.busy": "2022-06-07T15:38:21.644987Z",
     "iopub.status.idle": "2022-06-07T15:38:22.340389Z",
     "shell.execute_reply": "2022-06-07T15:38:22.340025Z",
     "shell.execute_reply.started": "2022-06-07T15:38:21.645102Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-Net Performance by Network:  [0.68  0.556 0.506 0.66  0.004]\n",
      "Distilled Mean Performance by Network:  [0.624 0.542 0.99  0.512 0.984]\n",
      "Distilled Max Performance by Network:  [0.624 0.542 0.99  0.512 0.984]\n",
      "Median I-Net: 0.556\n",
      "Median DT Distilled: 0.624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc Distilled Train Data</th>\n",
       "      <th>Acc Distilled Data Random</th>\n",
       "      <th>Acc Distilled</th>\n",
       "      <th>Acc I-Net</th>\n",
       "      <th>Soft BC Distilled Train Data</th>\n",
       "      <th>Soft BC Distilled Data Random</th>\n",
       "      <th>Soft BC Distilled</th>\n",
       "      <th>Soft BC I-Net</th>\n",
       "      <th>BC Distilled Train Data</th>\n",
       "      <th>BC Distilled Data Random</th>\n",
       "      <th>BC Distilled</th>\n",
       "      <th>BC I-Net</th>\n",
       "      <th>F1 Score Distilled Train Data</th>\n",
       "      <th>F1 Score Distilled Data Random</th>\n",
       "      <th>F1 Score Distilled</th>\n",
       "      <th>F1 Score I-Net</th>\n",
       "      <th>ROC AUC Score Distilled Train Data</th>\n",
       "      <th>ROC AUC Score Distilled Data Random</th>\n",
       "      <th>ROC AUC Score Distilled</th>\n",
       "      <th>ROC AUC Score I-Net</th>\n",
       "      <th>Runtime Distilled Train Data</th>\n",
       "      <th>Runtime Distilled Data Random</th>\n",
       "      <th>Runtime Distilled</th>\n",
       "      <th>Runtime I-Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['uniform', 'normal', 'gamma', 'beta', 'poisson']</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Acc Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                     0.999   \n",
       "\n",
       "                                                   Acc Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                      0.915   \n",
       "\n",
       "                                                   Acc Distilled  Acc I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']          0.730      0.481   \n",
       "\n",
       "                                                   Soft BC Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                         0.322   \n",
       "\n",
       "                                                   Soft BC Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                          0.490   \n",
       "\n",
       "                                                   Soft BC Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']              0.593   \n",
       "\n",
       "                                                   Soft BC I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']          0.697   \n",
       "\n",
       "                                                   BC Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                    0.041   \n",
       "\n",
       "                                                   BC Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                     0.212   \n",
       "\n",
       "                                                   BC Distilled  BC I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']         0.961     0.702   \n",
       "\n",
       "                                                   F1 Score Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                          0.999   \n",
       "\n",
       "                                                   F1 Score Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                           0.906   \n",
       "\n",
       "                                                   F1 Score Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']               0.679   \n",
       "\n",
       "                                                   F1 Score I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']           0.430   \n",
       "\n",
       "                                                   ROC AUC Score Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                               0.999   \n",
       "\n",
       "                                                   ROC AUC Score Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                                0.824   \n",
       "\n",
       "                                                   ROC AUC Score Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                    0.813   \n",
       "\n",
       "                                                   ROC AUC Score I-Net  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                0.348   \n",
       "\n",
       "                                                   Runtime Distilled Train Data  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                         0.023   \n",
       "\n",
       "                                                   Runtime Distilled Data Random  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']                          0.023   \n",
       "\n",
       "                                                   Runtime Distilled  \\\n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']              0.023   \n",
       "\n",
       "                                                   Runtime I-Net  \n",
       "['uniform', 'normal', 'gamma', 'beta', 'poisson']          0.128  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Z-Score (Sample to Train Data)</th>\n",
       "      <th>Average Distance to Initialization</th>\n",
       "      <th>Average Mean Distance to Train Data</th>\n",
       "      <th>Average Distance to closest Train Data Sample</th>\n",
       "      <th>Average Biggest Distance for Single Neuron</th>\n",
       "      <th>Minimum Biggest Distance for Single Neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1024.850</td>\n",
       "      <td>517.562</td>\n",
       "      <td>673.313</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.684</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>2646.008</td>\n",
       "      <td>502.871</td>\n",
       "      <td>687.069</td>\n",
       "      <td>557.246</td>\n",
       "      <td>11.818</td>\n",
       "      <td>7.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>573.594</td>\n",
       "      <td>134.623</td>\n",
       "      <td>505.716</td>\n",
       "      <td>300.045</td>\n",
       "      <td>9.521</td>\n",
       "      <td>3.752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average Z-Score (Sample to Train Data)  \\\n",
       "train                                1024.850   \n",
       "valid                                2646.008   \n",
       "test                                  573.594   \n",
       "\n",
       "       Average Distance to Initialization  \\\n",
       "train                             517.562   \n",
       "valid                             502.871   \n",
       "test                              134.623   \n",
       "\n",
       "       Average Mean Distance to Train Data  \\\n",
       "train                              673.313   \n",
       "valid                              687.069   \n",
       "test                               505.716   \n",
       "\n",
       "       Average Distance to closest Train Data Sample  \\\n",
       "train                                          0.000   \n",
       "valid                                        557.246   \n",
       "test                                         300.045   \n",
       "\n",
       "       Average Biggest Distance for Single Neuron  \\\n",
       "train                                      11.684   \n",
       "valid                                      11.818   \n",
       "test                                        9.521   \n",
       "\n",
       "       Minimum Biggest Distance for Single Neuron  \n",
       "train                                       0.000  \n",
       "valid                                       7.322  \n",
       "test                                        3.752  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if evaluate_distribution and test_size > 0:\n",
    "    #print(distribution_parameter_list_list[0])\n",
    "    #print(lambda_net_dataset_valid.distribution_dict_list_list[0])\n",
    "\n",
    "    inet_performance_distrib_evaluation = np.array(inet_evaluation_result_dict_complete_by_distribution_test[list(inet_evaluation_result_dict_complete_by_distribution_test.keys())[0]]['inet_scores']['accuracy'])\n",
    "    print('I-Net Performance by Network: ', inet_performance_distrib_evaluation)\n",
    "\n",
    "    mean_random_performance_distrib_evaluation = np.mean(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)\n",
    "    print('Distilled Mean Performance by Network: ', mean_random_performance_distrib_evaluation)\n",
    "\n",
    "    max_random_performance_distrib_evaluation = np.max(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)\n",
    "    print('Distilled Max Performance by Network: ', max_random_performance_distrib_evaluation)\n",
    "\n",
    "    print('Median I-Net:', np.median(inet_evaluation_result_dict_complete_by_distribution_test[list(inet_evaluation_result_dict_complete_by_distribution_test.keys())[0]]['inet_scores']['accuracy']))\n",
    "    print('Median DT Distilled:', np.median(np.median(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)))#np.median(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['dt_scores']['accuracy']))\n",
    "\n",
    "    complete_distribution_evaluation_results = get_complete_distribution_evaluation_results_dataframe(inet_evaluation_result_dict_mean_by_distribution_test)\n",
    "    display(complete_distribution_evaluation_results.head(20))\n",
    "    \n",
    "    network_distances = get_print_network_distances_dataframe(distances_dict)\n",
    "    display(network_distances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:22.341144Z",
     "iopub.status.busy": "2022-06-07T15:38:22.340980Z",
     "iopub.status.idle": "2022-06-07T15:38:22.413445Z",
     "shell.execute_reply": "2022-06-07T15:38:22.412978Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.341126Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:38:22.414433Z",
     "iopub.status.busy": "2022-06-07T15:38:22.414149Z",
     "iopub.status.idle": "2022-06-07T15:38:22.888262Z",
     "shell.execute_reply": "2022-06-07T15:38:22.885998Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.414414Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'samples_class_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1245968/3215232234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdistribution_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_parameter_list_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature 1: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Samples'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples_class_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda_dataset_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdistribution_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples_class_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t Distribution 1: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdistrib_parameter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistrib_parameter_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'samples_class_0'"
     ]
    }
   ],
   "source": [
    "if evaluate_distribution:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    identifier_folder = config['function_family']['dt_type'] + '_' + str(config['function_family']['decision_sparsity']) + '_' + timestr\n",
    "    os.makedirs('./data/distrib_plots/' + identifier_folder + '/', exist_ok=True)\n",
    "    \n",
    "    for i in range(min(3, test_size)):\n",
    "        #index = 14\n",
    "        #index = np.argmax(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['dt_scores']['accuracy']))\n",
    "        top_number = i\n",
    "        #index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['dt_scores']['accuracy']))[::-1][top_number]\n",
    "\n",
    "        scores_distilled_median_random = np.median(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0)\n",
    "        scores_distilled_uniform = inet_evaluation_result_dict_complete_by_distribution_test[str(config['data']['distribution_list_eval'][0])]['dt_scores']['accuracy_uniform_data']\n",
    "        scores_distilled_normal = inet_evaluation_result_dict_complete_by_distribution_test[str(config['data']['distribution_list_eval'][0])]['dt_scores']['accuracy_normal_data']\n",
    "        \n",
    "        scores_distilled_array = np.mean([scores_distilled_median_random, scores_distilled_uniform, scores_distilled_normal], axis=0)\n",
    "        \n",
    "        index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test[list(inet_evaluation_result_dict_complete_by_distribution_test.keys())[0]]['inet_scores']['accuracy']) - scores_distilled_array)[::-1][top_number]\n",
    "        #index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.max(np.array([inet_evaluation_result_dict_complete_by_distribution_test[distrib]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0))[::-1][top_number]\n",
    "        #index = np.argsort(np.array(inet_evaluation_result_dict_complete_by_distribution_test['uniform']['inet_scores']['accuracy']) - np.mean(np.array([inet_evaluation_result_dict_complete_by_distribution_test[distrib]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']]), axis=0))[::-1][top_number]\n",
    "\n",
    "        distrib_for_index = np.argmax(np.array([inet_evaluation_result_dict_complete_by_distribution_test[str(distrib)]['dt_scores']['accuracy'] for distrib in config['data']['distribution_list_eval']])[:,index])\n",
    "\n",
    "        print('Index: ', index)\n",
    "        distribution_dict = distribution_parameter_list_list[index]\n",
    "\n",
    "        print('Feature 1: ', 'Samples', distribution_dict[0][list(distribution_dict[0].keys())[0]]['samples_class_0'], '/', config['data']['lambda_dataset_size']-distribution_dict[0][list(distribution_dict[0].keys())[0]]['samples_class_0'])\n",
    "        print('\\t Distribution 1: ' + list(distribution_dict[0].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[0][list(distribution_dict[0].keys())[0]]['class_0'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "        print('\\t Distribution 2: ' + list(distribution_dict[0].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[0][list(distribution_dict[0].keys())[0]]['class_1'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "\n",
    "        print('Feature 2: ', 'Samples', distribution_dict[1][list(distribution_dict[1].keys())[0]]['samples_class_0'], '/', config['data']['lambda_dataset_size']-distribution_dict[1][list(distribution_dict[1].keys())[0]]['samples_class_0'])\n",
    "        print('\\t Distribution 1: ' + list(distribution_dict[1].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[1][list(distribution_dict[1].keys())[0]]['class_0'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "        print('\\t Distribution 2: ' + list(distribution_dict[1].keys())[0])\n",
    "        for j, (distrib_parameter_name, distrib_parameter_value) in enumerate(distribution_dict[1][list(distribution_dict[1].keys())[0]]['class_1'].items()):\n",
    "            print('\\t\\t '  + distrib_parameter_name +  ': ' + str(np.round(distrib_parameter_value, 3)))\n",
    "\n",
    "        identifier_file = 'index' + str(index) + '_' + '_'.join([list(dist.keys())[0] + '_' +  '_'.join([key + '-' + str(np.round(value, 4)) for key, value in dist[list(dist.keys())[0]]['class_0'].items()]) + '_' + '_'.join([key + '-' + str(np.round(value, 4)) for key, value in dist[list(dist.keys())[0]]['class_1'].items()]) for dist in distribution_parameter_list_list[index]])\n",
    "        \n",
    "        plot_decision_area_evaluation_all_distrib(data_dict_list_test[index]['X_train'], \n",
    "                                            data_dict_list_test[index]['y_train'], \n",
    "                                            data_dict_list_test[index]['X_test'], \n",
    "                                            data_dict_list_test[index]['y_test'],\n",
    "                                            None,\n",
    "                                            None,\n",
    "                                            network_parameters_to_network(shaped_network_parameters_to_array(test_network_list_distrib[index], config), config),\n",
    "                                            dt_distilled_list_test[0][index][-3],\n",
    "                                            dt_distilled_list_test[0][index][-2],\n",
    "                                            dt_distilled_list_test[0][index][-1],\n",
    "                                            [dt_distilled_list_test[i][index][0] for i in range(len(config['data']['distribution_list_eval']))],     \n",
    "                                            dt_inet_list_test[0][index],\n",
    "                                            np.array([str(i) for i in range(data_dict_list_test[index]['X_train'].shape[1])]),\n",
    "                                            config['data']['distribution_list_eval'],\n",
    "                                            config,\n",
    "                                            identifier_folder = identifier_folder,\n",
    "                                            identifier_file = identifier_file\n",
    "                                           )    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.888793Z",
     "iopub.status.idle": "2022-06-07T15:38:22.888967Z",
     "shell.execute_reply": "2022-06-07T15:38:22.888881Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.888871Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    print('I-Net Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    dt_inet = parameterDT(dt_inet_list_test[distrib_for_index][index], config)\n",
    "    image = dt_inet.plot()\n",
    "    display(image)\n",
    "    \n",
    "    print('Random Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(dt_distilled_list_test[distrib_for_index][index][0], fontsize=10)  #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(dt_distilled_list_test[distrib_for_index][index][1], fontsize=10)  #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    plt.show()    \n",
    "    \n",
    "    print('Uniform Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(dt_distilled_list_test[distrib_for_index][index][2], fontsize=10)  #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    plt.show()    \n",
    "else:\n",
    "    print('I-Net Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    dt_parameters = dt_inet_list_test[distrib_for_index][index]\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "    display(image)\n",
    "    \n",
    "    print('Random Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = dt_distilled_list_test[distrib_for_index][index][0].plot_tree() #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    display(image)\n",
    "    \n",
    "    print('Train Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8)) \n",
    "    image = dt_distilled_list_test[distrib_for_index][index][1].plot_tree() #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL'] \n",
    "    display(image)\n",
    "    \n",
    "    print('Uniform Data Decision Tree')\n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = dt_distilled_list_test[distrib_for_index][index][2].plot_tree() #fist index=distrib; second index=index; third index=[config['evaluation']['random_evaluation_dataset_size_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL']\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.889663Z",
     "iopub.status.idle": "2022-06-07T15:38:22.889831Z",
     "shell.execute_reply": "2022-06-07T15:38:22.889750Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.889741Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_class_distrib_by_feature(model = model,\n",
    "                                  index = index,\n",
    "                                  test_network = network_parameters_to_network(lambda_net_dataset_valid.network_parameters_array[index], config, base_model=None),\n",
    "                                  distribution_training = config['data']['distribution_list_eval'][distrib_for_index],\n",
    "                                  distribution_dict = lambda_net_dataset_valid.distribution_dict_list_list[index],\n",
    "                                  X_test = lambda_net_dataset_valid.X_test_lambda_array[index],\n",
    "                                  config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.890441Z",
     "iopub.status.idle": "2022-06-07T15:38:22.890618Z",
     "shell.execute_reply": "2022-06-07T15:38:22.890538Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.890529Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_class_distrib_by_feature(model = model,\n",
    "                                  index = index,\n",
    "                                  test_network = network_parameters_to_network(shaped_network_parameters_to_array(test_network_list_distrib[index], config), config, base_model=None),\n",
    "                                  distribution_training = config['data']['distribution_list_eval'][distrib_for_index],\n",
    "                                  distribution_dict = lambda_net_dataset_valid.distribution_dict_list_list[index],\n",
    "                                  X_test =  data_dict_list_test[0]['X_test'],\n",
    "                                  config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Evaluation (Selected Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.891148Z",
     "iopub.status.idle": "2022-06-07T15:38:22.891381Z",
     "shell.execute_reply": "2022-06-07T15:38:22.891303Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.891293Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "if False:\n",
    "    evaluate_network_on_distribution_custom_parameters(distribution_name_feature_0 = 'normal',\n",
    "                                                       distribution_name_feature_1 = 'normal',\n",
    "                                                       distribution_parameters_0_param_1_feature_0 = 1.188840288782265,\n",
    "                                                       distribution_parameters_0_param_2_feature_0 = 0.8566173698593895,\n",
    "                                                       distribution_parameters_1_param_1_feature_0 = 0.8713650102755661,\n",
    "                                                       distribution_parameters_1_param_2_feature_0 = 1.8484540179178748,\n",
    "                                                       distribution_parameters_0_param_1_feature_1 = 1.7185974826882278,\n",
    "                                                       distribution_parameters_0_param_2_feature_1 = 0.5807878500034862,\n",
    "                                                       distribution_parameters_1_param_1_feature_1 = 0.44369536008631294,\n",
    "                                                       distribution_parameters_1_param_2_feature_1 = 1.17864258666672,\n",
    "                                                       inet = model,\n",
    "                                                       config = config,\n",
    "                                                       distribution_list_evaluation = config['data']['distribution_list_eval'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Real-World Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.891833Z",
     "iopub.status.idle": "2022-06-07T15:38:22.892063Z",
     "shell.execute_reply": "2022-06-07T15:38:22.891985Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.891976Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset_size_list = flatten_list([[config['evaluation']['random_evaluation_dataset_size_per_distribution']]*config['evaluation']['number_of_random_evaluations_per_distribution'], 'TRAINDATA', 'STANDARDUNIFORM', 'STANDARDNORMAL'])\n",
    "dataset_size_list = flatten_list([[config['evaluation']['random_evaluation_dataset_size_per_distribution']]*config['evaluation']['number_of_random_evaluations_per_distribution'], \n",
    "                                  'TRAINDATA', \n",
    "                                  ['STANDARDUNIFORM']*config['evaluation']['number_of_random_evaluations_per_distribution'], \n",
    "                                  ['STANDARDNORMAL']*config['evaluation']['number_of_random_evaluations_per_distribution']])\n",
    "\n",
    "\n",
    "dataset_size_list_print = []\n",
    "for size in dataset_size_list:\n",
    "    if type(size) is int:\n",
    "        size = size//1000\n",
    "        size = str(size) + 'k'\n",
    "        dataset_size_list_print.append(size)\n",
    "    else:\n",
    "        dataset_size_list_print.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.892527Z",
     "iopub.status.idle": "2022-06-07T15:38:22.892775Z",
     "shell.execute_reply": "2022-06-07T15:38:22.892690Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.892681Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#distances_dict = {}\n",
    "evaluation_result_dict = {}\n",
    "results_dict = {}\n",
    "dt_inet_dict = {}\n",
    "dt_distilled_list_dict = {}\n",
    "data_dict = {}\n",
    "normalizer_list_dict = {}\n",
    "test_network_list = {}\n",
    "\n",
    "identifier_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.893275Z",
     "iopub.status.idle": "2022-06-07T15:38:22.893515Z",
     "shell.execute_reply": "2022-06-07T15:38:22.893437Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.893427Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "\n",
    "#adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "#adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "#adult_data.head()\n",
    "\n",
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 #\"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 #\"Occupation\",  #6\n",
    "                 #\"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 \"capital_gain\"\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "nominal_features_adult = [\n",
    "                          'Race', \n",
    "                          'Workclass', \n",
    "                          #'Education',\n",
    "                          \"Marital Status\",\n",
    "                          #\"Occupation\", \n",
    "                          #\"Relationship\"\n",
    "                        ]\n",
    "ordinal_features_adult = ['Sex']\n",
    "\n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "#y_data_adult = pd.Series(OrdinalEncoder().fit_transform(adult_data['capital_gain'].values.reshape(-1, 1)).flatten(), name='capital_gain')\n",
    "y_data_adult = ((adult_data['capital_gain'] != ' <=50K') * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.893957Z",
     "iopub.status.idle": "2022-06-07T15:38:22.894147Z",
     "shell.execute_reply": "2022-06-07T15:38:22.894071Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.894062Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_train_network_adult = deepcopy(config)\n",
    "#config_train_network_adult['lambda_net']['batch_lambda'] = 32\n",
    "#config_train_network_adult['lambda_net']['learning_rate_lambda'] = 0.0003\n",
    "#config_train_network_adult['lambda_net']['dropout_lambda'] = 0.25\n",
    "#config_train_network_adult['lambda_net']['epochs_lambda'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.894621Z",
     "iopub.status.idle": "2022-06-07T15:38:22.894838Z",
     "shell.execute_reply": "2022-06-07T15:38:22.894761Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.894752Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Adult'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_adult, \n",
    "                                                                y_data_adult, \n",
    "                                                                nominal_features = nominal_features_adult, \n",
    "                                                                ordinal_features = ordinal_features_adult,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = config_train_network_adult)\n",
    "\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict['Adult'], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.895306Z",
     "iopub.status.idle": "2022-06-07T15:38:22.895474Z",
     "shell.execute_reply": "2022-06-07T15:38:22.895398Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.895390Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.896084Z",
     "iopub.status.idle": "2022-06-07T15:38:22.896308Z",
     "shell.execute_reply": "2022-06-07T15:38:22.896231Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.896223Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.896737Z",
     "iopub.status.idle": "2022-06-07T15:38:22.896967Z",
     "shell.execute_reply": "2022-06-07T15:38:22.896891Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.896882Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "\n",
    "features_select = [\n",
    "                    #'Cabin', \n",
    "                    #'Ticket', \n",
    "                    #'Name', \n",
    "                    #'PassengerId'    \n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "nominal_features_titanic = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features_titanic = ['Sex']\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.897434Z",
     "iopub.status.idle": "2022-06-07T15:38:22.897663Z",
     "shell.execute_reply": "2022-06-07T15:38:22.897571Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.897562Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Titanic'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_titanic, \n",
    "                                                                y_data_titanic, \n",
    "                                                                nominal_features = nominal_features_titanic, \n",
    "                                                                ordinal_features = ordinal_features_titanic,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.898111Z",
     "iopub.status.idle": "2022-06-07T15:38:22.898278Z",
     "shell.execute_reply": "2022-06-07T15:38:22.898203Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.898194Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.898838Z",
     "iopub.status.idle": "2022-06-07T15:38:22.899068Z",
     "shell.execute_reply": "2022-06-07T15:38:22.898991Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.898982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     \n",
    "    \n",
    "    y_train = data_dict[identifier]['y_train']\n",
    "    y_train_pred = pd.Series(np.round(test_network_list[identifier].predict(data_dict[identifier]['X_train'])).ravel(), \n",
    "                             name=\"Survived\")\n",
    "    X_data = pd.concat([data_dict[identifier]['X_train'], y_train_pred], axis=1)\n",
    "    display(X_data.head())\n",
    "    \n",
    "    X_data.groupby(\"Survived\").SibSp.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    #X_data[X_data.Parch > 0.8].groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    #plt.show()\n",
    "    X_data.groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    X_data.groupby(\"Survived\").Sex.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    uniform_data = generate_random_data_points_custom(config['data']['x_min'], \n",
    "                                   config['data']['x_max'],\n",
    "                                   config['evaluation']['random_evaluation_dataset_size_per_distribution'], \n",
    "                                   config['data']['number_of_variables'], \n",
    "                                   config['data']['categorical_indices'],\n",
    "                                   distrib='standarduniform',\n",
    "                                   random_parameters=config['data']['random_parameters_distribution'],\n",
    "                                   distrib_param_max=config['data']['distrib_param_max'],\n",
    "                                   seed=config['computation']['RANDOM_SEED'],\n",
    "                                   config=config)    \n",
    "    \n",
    "    y_uniform_data = np.round(test_network_list[identifier].predict(uniform_data))\n",
    "\n",
    "    uniform_data_with_labels_df = pd.DataFrame(data=np.hstack([uniform_data, y_uniform_data]), columns=X_data.columns)    \n",
    "    \n",
    "    uniform_data_with_labels_df.groupby(\"Survived\").SibSp.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    uniform_data_with_labels_df[uniform_data_with_labels_df.SibSp > 0.56].groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    uniform_data_with_labels_df[uniform_data_with_labels_df.SibSp < 0.56].groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()    \n",
    "    \n",
    "    uniform_data_with_labels_df.groupby(\"Survived\").Age.hist(alpha=0.6)\n",
    "    plt.show()\n",
    "    uniform_data_with_labels_df.groupby(\"Survived\").Sex.hist(alpha=0.6)\n",
    "    plt.show()        \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.899509Z",
     "iopub.status.idle": "2022-06-07T15:38:22.899730Z",
     "shell.execute_reply": "2022-06-07T15:38:22.899654Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.899646Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           'Weight', \n",
    "                           'Height', \n",
    "                           'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "nominal_features_absenteeism = []\n",
    "ordinal_features_absenteeism = []\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 4) * 1) #absenteeism_data['Absenteeism time in hours']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.900210Z",
     "iopub.status.idle": "2022-06-07T15:38:22.900437Z",
     "shell.execute_reply": "2022-06-07T15:38:22.900362Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.900353Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Absenteeism'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_absenteeism, \n",
    "                                                                y_data_absenteeism, \n",
    "                                                                nominal_features = nominal_features_absenteeism, \n",
    "                                                                ordinal_features = ordinal_features_absenteeism,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.900866Z",
     "iopub.status.idle": "2022-06-07T15:38:22.901360Z",
     "shell.execute_reply": "2022-06-07T15:38:22.901267Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.901253Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.901867Z",
     "iopub.status.idle": "2022-06-07T15:38:22.902016Z",
     "shell.execute_reply": "2022-06-07T15:38:22.901943Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.901935Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.902474Z",
     "iopub.status.idle": "2022-06-07T15:38:22.902691Z",
     "shell.execute_reply": "2022-06-07T15:38:22.902615Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.902607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('real_world_datasets/Loan/loan-train.csv', delimiter=',')\n",
    "\n",
    "loan_data['Gender'].fillna(loan_data['Gender'].mode()[0], inplace=True)\n",
    "loan_data['Dependents'].fillna(loan_data['Dependents'].mode()[0], inplace=True)\n",
    "loan_data['Married'].fillna(loan_data['Married'].mode()[0], inplace=True)\n",
    "loan_data['Self_Employed'].fillna(loan_data['Self_Employed'].mode()[0], inplace=True)\n",
    "loan_data['LoanAmount'].fillna(loan_data['LoanAmount'].mean(), inplace=True)\n",
    "loan_data['Loan_Amount_Term'].fillna(loan_data['Loan_Amount_Term'].mean(), inplace=True)\n",
    "loan_data['Credit_History'].fillna(loan_data['Credit_History'].mean(), inplace=True)\n",
    "\n",
    "features_select = [\n",
    "                    #'Loan_ID', \n",
    "                    'Gender', #\n",
    "                    'Married', \n",
    "                    'Dependents', \n",
    "                    'Education',\n",
    "                    'Self_Employed', \n",
    "                    'ApplicantIncome', \n",
    "                    'CoapplicantIncome', \n",
    "                    'LoanAmount',\n",
    "                    'Loan_Amount_Term', \n",
    "                    'Credit_History', \n",
    "                    'Property_Area', \n",
    "                    'Loan_Status'\n",
    "                    ]\n",
    "\n",
    "loan_data = loan_data[features_select]\n",
    "\n",
    "#loan_data['Dependents'][loan_data['Dependents'] == '3+'] = 4\n",
    "#loan_data['Dependents'] = loan_data['Dependents'].astype(int)\n",
    "\n",
    "#loan_data['Property_Area'][loan_data['Property_Area'] == 'Rural'] = 0\n",
    "#loan_data['Property_Area'][loan_data['Property_Area'] == 'Semiurban'] = 1\n",
    "#loan_data['Property_Area'][loan_data['Property_Area'] == 'Urban'] = 2\n",
    "#loan_data['Property_Area'] = loan_data['Property_Area'].astype(int)\n",
    "\n",
    "nominal_features_loan = [\n",
    "                        'Dependents',\n",
    "                        'Property_Area',    \n",
    "                        ]\n",
    "\n",
    "\n",
    "ordinal_features_loan = [\n",
    "                    'Education',\n",
    "                    'Gender', \n",
    "                    'Married', \n",
    "                    'Self_Employed',\n",
    "                   ]\n",
    "    \n",
    "X_data_loan = loan_data.drop(['Loan_Status'], axis = 1)\n",
    "y_data_loan = ((loan_data['Loan_Status'] == 'Y') * 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.903305Z",
     "iopub.status.idle": "2022-06-07T15:38:22.903461Z",
     "shell.execute_reply": "2022-06-07T15:38:22.903385Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.903377Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_train_network_loan_house = deepcopy(config)\n",
    "#config_train_network_loan_house['lambda_net']['batch_lambda'] = 64#16\n",
    "#config_train_network_loan_house['lambda_net']['learning_rate_lambda'] = 0.001\n",
    "#config_train_network_loan_house['lambda_net']['dropout_lambda'] = 0#.1\n",
    "#config_train_network_loan_house['lambda_net']['epochs_lambda'] = 500\n",
    "#config_train_network_loan_house['lambda_net']['optimizer_lambda'] = 'adam'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.903973Z",
     "iopub.status.idle": "2022-06-07T15:38:22.904135Z",
     "shell.execute_reply": "2022-06-07T15:38:22.904050Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.904042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Loan House'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_loan, \n",
    "                                                                y_data_loan, \n",
    "                                                                nominal_features = nominal_features_loan, \n",
    "                                                                ordinal_features = ordinal_features_loan,\n",
    "                                                                #config = config_train_network_loan_house,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.904647Z",
     "iopub.status.idle": "2022-06-07T15:38:22.905016Z",
     "shell.execute_reply": "2022-06-07T15:38:22.904936Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.904926Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.905614Z",
     "iopub.status.idle": "2022-06-07T15:38:22.905765Z",
     "shell.execute_reply": "2022-06-07T15:38:22.905691Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.905683Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.906439Z",
     "iopub.status.idle": "2022-06-07T15:38:22.906604Z",
     "shell.execute_reply": "2022-06-07T15:38:22.906525Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.906516Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loan_credit_data = pd.read_csv('real_world_datasets/Credit Loan/train_split.csv', delimiter=',')\n",
    "\n",
    "loan_credit_data['emp_title'].fillna(loan_credit_data['emp_title'].mode()[0], inplace=True)\n",
    "loan_credit_data['emp_length'].fillna(loan_credit_data['emp_length'].mode()[0], inplace=True)\n",
    "#loan_credit_data['desc'].fillna(loan_credit_data['desc'].mode()[0], inplace=True)\n",
    "loan_credit_data['title'].fillna(loan_credit_data['title'].mode()[0], inplace=True)\n",
    "#loan_credit_data['mths_since_last_delinq'].fillna(loan_credit_data['mths_since_last_delinq'].mode()[0], inplace=True)\n",
    "#loan_credit_data['mths_since_last_record'].fillna(loan_credit_data['mths_since_last_record'].mode()[0], inplace=True)\n",
    "loan_credit_data['revol_util'].fillna(loan_credit_data['revol_util'].mode()[0], inplace=True)\n",
    "loan_credit_data['collections_12_mths_ex_med'].fillna(loan_credit_data['collections_12_mths_ex_med'].mode()[0], inplace=True)\n",
    "#loan_credit_data['mths_since_last_major_derog'].fillna(loan_credit_data['mths_since_last_major_derog'].mode()[0], inplace=True)\n",
    "#loan_credit_data['verification_status_joint'].fillna(loan_credit_data['verification_status_joint'].mode()[0], inplace=True)\n",
    "loan_credit_data['tot_coll_amt'].fillna(loan_credit_data['tot_coll_amt'].mode()[0], inplace=True)\n",
    "loan_credit_data['tot_cur_bal'].fillna(loan_credit_data['tot_cur_bal'].mode()[0], inplace=True)\n",
    "loan_credit_data['total_rev_hi_lim'].fillna(loan_credit_data['total_rev_hi_lim'].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "##remove too many null\n",
    "#'mths_since_last_delinq','mths_since_last_record', 'mths_since_last_major_derog','pymnt_plan','desc', 'verification_status_joint'\n",
    "\n",
    "\n",
    "features_select = [\n",
    "                    #'member_id', \n",
    "                    'loan_amnt', \n",
    "                    'funded_amnt', \n",
    "                    'funded_amnt_inv', \n",
    "                    'term',\n",
    "                    #'batch_enrolled',\n",
    "                    'int_rate', \n",
    "                    'grade', \n",
    "                    #'sub_grade', \n",
    "                    #'emp_title',\n",
    "                    'emp_length',\n",
    "                    'home_ownership', \n",
    "                    'annual_inc', \n",
    "                    'verification_status',\n",
    "                    #'pymnt_plan', \n",
    "                    #'desc', \n",
    "                    'purpose', \n",
    "                    'title', \n",
    "                    #'zip_code', \n",
    "                    #'addr_state',\n",
    "                    'dti', \n",
    "                    'delinq_2yrs', \n",
    "                    'inq_last_6mths', \n",
    "                    #'mths_since_last_delinq',\n",
    "                    #'mths_since_last_record',\n",
    "                    'open_acc', \n",
    "                    'pub_rec', \n",
    "                    'revol_bal',\n",
    "                    'revol_util', \n",
    "                    'total_acc', \n",
    "                    'initial_list_status', \n",
    "                    'total_rec_int',\n",
    "                    'total_rec_late_fee', \n",
    "                    'recoveries', \n",
    "                    'collection_recovery_fee',\n",
    "                    'collections_12_mths_ex_med', \n",
    "                    #'mths_since_last_major_derog',\n",
    "                    'application_type', \n",
    "                    #'verification_status_joint', \n",
    "                    'last_week_pay',\n",
    "                    'acc_now_delinq', \n",
    "                    'tot_coll_amt', \n",
    "                    'tot_cur_bal', \n",
    "                    'total_rev_hi_lim',\n",
    "                    'loan_status'\n",
    "                    ]\n",
    "\n",
    "loan_credit_data = loan_credit_data[features_select]\n",
    "\n",
    "nominal_features_loan_credit = [\n",
    "\n",
    "                        ]\n",
    "ordinal_features_loan_credit = [\n",
    "                    #'member_id', \n",
    "                    'loan_amnt', \n",
    "                    'funded_amnt', \n",
    "                    'funded_amnt_inv', \n",
    "                    'term',\n",
    "                    #'batch_enrolled',\n",
    "                    'int_rate', \n",
    "                    'grade', \n",
    "                    #'sub_grade', \n",
    "                    #'emp_title',\n",
    "                    'emp_length',\n",
    "                    'home_ownership', \n",
    "                    'annual_inc', \n",
    "                    'verification_status',\n",
    "                    #'pymnt_plan', \n",
    "                    #'desc', \n",
    "                    'purpose', \n",
    "                    'title', \n",
    "                    #'zip_code', \n",
    "                    #'addr_state',\n",
    "                    'dti', \n",
    "                    'delinq_2yrs', \n",
    "                    'inq_last_6mths', \n",
    "                    #'mths_since_last_delinq',\n",
    "                    #'mths_since_last_record',\n",
    "                    'open_acc', \n",
    "                    'pub_rec', \n",
    "                    'revol_bal',\n",
    "                    'revol_util', \n",
    "                    'total_acc', \n",
    "                    'initial_list_status', \n",
    "                    'total_rec_int',\n",
    "                    'total_rec_late_fee', \n",
    "                    'recoveries', \n",
    "                    'collection_recovery_fee',\n",
    "                    'collections_12_mths_ex_med', \n",
    "                    #'mths_since_last_major_derog',\n",
    "                    'application_type', \n",
    "                    #'verification_status_joint', \n",
    "                    'last_week_pay',\n",
    "                    'acc_now_delinq', \n",
    "                    'tot_coll_amt', \n",
    "                    'tot_cur_bal', \n",
    "                    'total_rev_hi_lim',\n",
    "                   ]\n",
    "    \n",
    "X_data_loan_credit = loan_credit_data.drop(['loan_status'], axis = 1)\n",
    "y_data_loan_credit = pd.Series(OrdinalEncoder().fit_transform(loan_credit_data['loan_status'].values.reshape(-1, 1)).flatten(), name='loan_status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.907164Z",
     "iopub.status.idle": "2022-06-07T15:38:22.907400Z",
     "shell.execute_reply": "2022-06-07T15:38:22.907243Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.907235Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Loan Credit'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_loan_credit, \n",
    "                                                                y_data_loan_credit, \n",
    "                                                                nominal_features = nominal_features_loan_credit, \n",
    "                                                                ordinal_features = ordinal_features_loan_credit,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.907894Z",
     "iopub.status.idle": "2022-06-07T15:38:22.908046Z",
     "shell.execute_reply": "2022-06-07T15:38:22.907972Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.907964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.908601Z",
     "iopub.status.idle": "2022-06-07T15:38:22.908767Z",
     "shell.execute_reply": "2022-06-07T15:38:22.908680Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.908671Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.909288Z",
     "iopub.status.idle": "2022-06-07T15:38:22.909460Z",
     "shell.execute_reply": "2022-06-07T15:38:22.909369Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.909360Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "medical_insurance_data = pd.read_csv('real_world_datasets/Medical Insurance/insurance.csv', delimiter=',')\n",
    "\n",
    "features_select = [\n",
    "                    'age', \n",
    "                    'sex', \n",
    "                    'bmi', \n",
    "                    'children', \n",
    "                    'smoker',\n",
    "                    'region',\n",
    "                    'charges'\n",
    "                    ]\n",
    "\n",
    "medical_insurance_data = medical_insurance_data[features_select]\n",
    "\n",
    "nominal_features_medical_insurance = [\n",
    "                    'region',\n",
    "                        ]\n",
    "ordinal_features_medical_insurance = [\n",
    "                    'sex',\n",
    "                    'smoker'\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_medical_insurance = medical_insurance_data.drop(['charges'], axis = 1)\n",
    "y_data_medical_insurance = ((medical_insurance_data['charges'] > 10_000) * 1)\n",
    "\n",
    "X_data_medical_insurance.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.909971Z",
     "iopub.status.idle": "2022-06-07T15:38:22.910125Z",
     "shell.execute_reply": "2022-06-07T15:38:22.910051Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.910043Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Medical Insurance'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_medical_insurance, \n",
    "                                                                y_data_medical_insurance, \n",
    "                                                                nominal_features = nominal_features_medical_insurance, \n",
    "                                                                ordinal_features = ordinal_features_medical_insurance,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.910485Z",
     "iopub.status.idle": "2022-06-07T15:38:22.910632Z",
     "shell.execute_reply": "2022-06-07T15:38:22.910560Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.910552Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.911241Z",
     "iopub.status.idle": "2022-06-07T15:38:22.911391Z",
     "shell.execute_reply": "2022-06-07T15:38:22.911318Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.911309Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.911838Z",
     "iopub.status.idle": "2022-06-07T15:38:22.911989Z",
     "shell.execute_reply": "2022-06-07T15:38:22.911916Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.911908Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bank_data = pd.read_csv('real_world_datasets/Bank Marketing/bank-full.csv', delimiter=';') #bank\n",
    "\n",
    "features_select = [\n",
    "                    'age',\n",
    "                    'job', \n",
    "                    'marital', \n",
    "                    'education', \n",
    "                    'default',\n",
    "                    'housing',\n",
    "                    'loan',\n",
    "                    #'contact',\n",
    "                    #'day',\n",
    "                    #'month',\n",
    "                    'duration',\n",
    "                    'campaign',\n",
    "                    'pdays',\n",
    "                    'previous',\n",
    "                    'poutcome',\n",
    "                    'y',\n",
    "                    ]\n",
    "\n",
    "bank_data = bank_data[features_select]\n",
    "\n",
    "nominal_features_bank = [\n",
    "                        'job',\n",
    "                        'education',\n",
    "                        #'contact',\n",
    "                        #'day',\n",
    "                        #'month',\n",
    "                        'poutcome',\n",
    "                        ]\n",
    "ordinal_features_bank = [\n",
    "                    'marital',\n",
    "                    'default',\n",
    "                    'housing',\n",
    "                    'loan',\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_bank = bank_data.drop(['y'], axis = 1)\n",
    "y_data_bank = pd.Series(OrdinalEncoder().fit_transform(bank_data['y'].values.reshape(-1, 1)).flatten(), name='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.912427Z",
     "iopub.status.idle": "2022-06-07T15:38:22.912573Z",
     "shell.execute_reply": "2022-06-07T15:38:22.912500Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.912492Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Bank Marketing'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_bank, \n",
    "                                                                y_data_bank, \n",
    "                                                                nominal_features = nominal_features_bank, \n",
    "                                                                ordinal_features = ordinal_features_bank,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.913231Z",
     "iopub.status.idle": "2022-06-07T15:38:22.913468Z",
     "shell.execute_reply": "2022-06-07T15:38:22.913390Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.913381Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.914022Z",
     "iopub.status.idle": "2022-06-07T15:38:22.914175Z",
     "shell.execute_reply": "2022-06-07T15:38:22.914101Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.914093Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cervical cancer (Risk Factors) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.914704Z",
     "iopub.status.idle": "2022-06-07T15:38:22.914858Z",
     "shell.execute_reply": "2022-06-07T15:38:22.914784Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.914776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00383/risk_factors_cervical_cancer.csv', index_col=False)#, names=feature_names\n",
    "\n",
    "features_select = [\n",
    "                    'Age',\n",
    "                    'Number of sexual partners',\n",
    "                    'First sexual intercourse',\n",
    "                    'Num of pregnancies',\n",
    "                    'Smokes',\n",
    "                    'Smokes (years)',\n",
    "                    'Hormonal Contraceptives',\n",
    "                    'Hormonal Contraceptives (years)',\n",
    "                    'IUD',\n",
    "                    'IUD (years)',\n",
    "                    'STDs',\n",
    "                    'STDs (number)',\n",
    "                    'STDs: Number of diagnosis',\n",
    "                    'STDs: Time since first diagnosis',\n",
    "                    'STDs: Time since last diagnosis',\n",
    "                    'Biopsy'\n",
    "                    ]\n",
    "\n",
    "cc_data = cc_data[features_select]\n",
    "\n",
    "cc_data['Number of sexual partners'][cc_data['Number of sexual partners'] == '?'] = cc_data['Number of sexual partners'].mode()[0]\n",
    "cc_data['First sexual intercourse'][cc_data['First sexual intercourse'] == '?'] = cc_data['First sexual intercourse'].mode()[0]\n",
    "cc_data['Num of pregnancies'][cc_data['Num of pregnancies'] == '?'] = cc_data['Num of pregnancies'].mode()[0]\n",
    "cc_data['Smokes'][cc_data['Smokes'] == '?'] = cc_data['Smokes'].mode()[0]\n",
    "cc_data['Smokes (years)'][cc_data['Smokes (years)'] == '?'] = cc_data['Smokes (years)'].mode()[0]\n",
    "cc_data['Hormonal Contraceptives'][cc_data['Hormonal Contraceptives'] == '?'] = cc_data['Hormonal Contraceptives'].mode()[0]\n",
    "cc_data['Hormonal Contraceptives (years)'][cc_data['Hormonal Contraceptives (years)'] == '?'] = cc_data['Hormonal Contraceptives (years)'].mode()[0]\n",
    "cc_data['IUD'][cc_data['IUD'] == '?'] = cc_data['IUD'].mode()[0]\n",
    "cc_data['IUD (years)'][cc_data['IUD (years)'] == '?'] = cc_data['IUD (years)'].mode()[0]\n",
    "cc_data['STDs'][cc_data['STDs'] == '?'] = cc_data['STDs'].mode()[0]\n",
    "cc_data['STDs (number)'][cc_data['STDs (number)'] == '?'] = cc_data['STDs (number)'].mode()[0]\n",
    "cc_data['STDs: Time since first diagnosis'][cc_data['STDs: Time since first diagnosis'] == '?'] = cc_data['STDs: Time since first diagnosis'][cc_data['STDs: Time since first diagnosis'] != '?'].mode()[0]\n",
    "cc_data['STDs: Time since last diagnosis'][cc_data['STDs: Time since last diagnosis'] == '?'] = cc_data['STDs: Time since last diagnosis'][cc_data['STDs: Time since last diagnosis'] != '?'].mode()[0]\n",
    "\n",
    "nominal_features_cc = [\n",
    "                        ]\n",
    "ordinal_features_cc = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_cc = cc_data.drop(['Biopsy'], axis = 1)\n",
    "y_data_cc = pd.Series(OrdinalEncoder().fit_transform(cc_data['Biopsy'].values.reshape(-1, 1)).flatten(), name='Biopsy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.915342Z",
     "iopub.status.idle": "2022-06-07T15:38:22.915561Z",
     "shell.execute_reply": "2022-06-07T15:38:22.915474Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.915465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Cervical Cancer'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_cc, \n",
    "                                                                y_data_cc, \n",
    "                                                                nominal_features = nominal_features_cc, \n",
    "                                                                ordinal_features = ordinal_features_cc,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.915988Z",
     "iopub.status.idle": "2022-06-07T15:38:22.916136Z",
     "shell.execute_reply": "2022-06-07T15:38:22.916064Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.916056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.916780Z",
     "iopub.status.idle": "2022-06-07T15:38:22.916932Z",
     "shell.execute_reply": "2022-06-07T15:38:22.916857Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.916849Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brest Cancer Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.917361Z",
     "iopub.status.idle": "2022-06-07T15:38:22.917514Z",
     "shell.execute_reply": "2022-06-07T15:38:22.917440Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.917432Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'Sample code number',\n",
    "                'Clump Thickness',\n",
    "                'Uniformity of Cell Size',\n",
    "                'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion',\n",
    "                'Single Epithelial Cell Size',\n",
    "                'Bare Nuclei',\n",
    "                'Bland Chromatin',\n",
    "                'Normal Nucleoli',\n",
    "                'Mitoses',\n",
    "                'Class',\n",
    "                ]\n",
    "\n",
    "bcw_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', names=feature_names, index_col=False)\n",
    "\n",
    "bcw_data['Clump Thickness'][bcw_data['Clump Thickness'] == '?'] = bcw_data['Clump Thickness'].mode()[0]\n",
    "bcw_data['Uniformity of Cell Size'][bcw_data['Uniformity of Cell Size'] == '?'] = bcw_data['Uniformity of Cell Size'].mode()[0]\n",
    "bcw_data['Uniformity of Cell Shape'][bcw_data['Uniformity of Cell Shape'] == '?'] = bcw_data['Uniformity of Cell Shape'].mode()[0]\n",
    "bcw_data['Marginal Adhesion'][bcw_data['Marginal Adhesion'] == '?'] = bcw_data['Marginal Adhesion'].mode()[0]\n",
    "bcw_data['Single Epithelial Cell Size'][bcw_data['Single Epithelial Cell Size'] == '?'] = bcw_data['Single Epithelial Cell Size'].mode()[0]\n",
    "bcw_data['Bare Nuclei'][bcw_data['Bare Nuclei'] == '?'] = bcw_data['Bare Nuclei'].mode()[0]\n",
    "bcw_data['Bland Chromatin'][bcw_data['Bland Chromatin'] == '?'] = bcw_data['Bland Chromatin'].mode()[0]\n",
    "bcw_data['Normal Nucleoli'][bcw_data['Normal Nucleoli'] == '?'] = bcw_data['Normal Nucleoli'].mode()[0]\n",
    "bcw_data['Mitoses'][bcw_data['Mitoses'] == '?'] = bcw_data['Mitoses'].mode()[0]\n",
    "\n",
    "features_select = [\n",
    "                #'Sample code number',\n",
    "                'Clump Thickness',\n",
    "                'Uniformity of Cell Size',\n",
    "                'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion',\n",
    "                'Single Epithelial Cell Size',\n",
    "                'Bare Nuclei',\n",
    "                'Bland Chromatin',\n",
    "                'Normal Nucleoli',\n",
    "                'Mitoses',\n",
    "                'Class',\n",
    "                    ]\n",
    "\n",
    "bcw_data = bcw_data[features_select]\n",
    "\n",
    "nominal_features_bcw = [\n",
    "                        ]\n",
    "ordinal_features_bcw = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_bcw = bcw_data.drop(['Class'], axis = 1)\n",
    "y_data_bcw = pd.Series(OrdinalEncoder().fit_transform(bcw_data['Class'].values.reshape(-1, 1)).flatten(), name='Class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.918043Z",
     "iopub.status.idle": "2022-06-07T15:38:22.918244Z",
     "shell.execute_reply": "2022-06-07T15:38:22.918167Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.918158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Brest Cancer Wisconsin'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_bcw, \n",
    "                                                                y_data_bcw, \n",
    "                                                                nominal_features = nominal_features_bcw, \n",
    "                                                                ordinal_features = ordinal_features_bcw,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.918664Z",
     "iopub.status.idle": "2022-06-07T15:38:22.918815Z",
     "shell.execute_reply": "2022-06-07T15:38:22.918741Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.918733Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.919349Z",
     "iopub.status.idle": "2022-06-07T15:38:22.919572Z",
     "shell.execute_reply": "2022-06-07T15:38:22.919496Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.919487Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin Diagnostic Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.920021Z",
     "iopub.status.idle": "2022-06-07T15:38:22.920246Z",
     "shell.execute_reply": "2022-06-07T15:38:22.920170Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.920161Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'ID number',\n",
    "                'Diagnosis',\n",
    "                'radius',# (mean of distances from center to points on the perimeter)\n",
    "                'texture',# (standard deviation of gray-scale values)\n",
    "                'perimeter',\n",
    "                'area',\n",
    "                'smoothness',# (local variation in radius lengths)\n",
    "                'compactness',# (perimeter^2 / area - 1.0)\n",
    "                'concavity',# (severity of concave portions of the contour)\n",
    "                'concave points',# (number of concave portions of the contour)\n",
    "                'symmetry',\n",
    "                'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                ]\n",
    "#Wisconsin Diagnostic Breast Cancer\n",
    "wdbc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', names=feature_names, index_col=False)\n",
    "\n",
    "features_select = [\n",
    "                    #'ID number',\n",
    "                    'Diagnosis',\n",
    "                    'radius',# (mean of distances from center to points on the perimeter)\n",
    "                    'texture',# (standard deviation of gray-scale values)\n",
    "                    'perimeter',\n",
    "                    'area',\n",
    "                    'smoothness',# (local variation in radius lengths)\n",
    "                    'compactness',# (perimeter^2 / area - 1.0)\n",
    "                    'concavity',# (severity of concave portions of the contour)\n",
    "                    'concave points',# (number of concave portions of the contour)\n",
    "                    'symmetry',\n",
    "                    'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                    ]\n",
    "\n",
    "wdbc_data = wdbc_data[features_select]\n",
    "\n",
    "nominal_features_wdbc = [\n",
    "                        ]\n",
    "ordinal_features_wdbc = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_wdbc = wdbc_data.drop(['Diagnosis'], axis = 1)\n",
    "y_data_wdbc= pd.Series(OrdinalEncoder().fit_transform(wdbc_data['Diagnosis'].values.reshape(-1, 1)).flatten(), name='Diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.920620Z",
     "iopub.status.idle": "2022-06-07T15:38:22.920781Z",
     "shell.execute_reply": "2022-06-07T15:38:22.920696Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.920688Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Wisconsin Diagnostic Breast Cancer'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_wdbc, \n",
    "                                                                y_data_wdbc, \n",
    "                                                                nominal_features = nominal_features_wdbc, \n",
    "                                                                ordinal_features = ordinal_features_wdbc,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.921218Z",
     "iopub.status.idle": "2022-06-07T15:38:22.921480Z",
     "shell.execute_reply": "2022-06-07T15:38:22.921397Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.921384Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.921972Z",
     "iopub.status.idle": "2022-06-07T15:38:22.922120Z",
     "shell.execute_reply": "2022-06-07T15:38:22.922048Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.922040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin Prognostic Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.922504Z",
     "iopub.status.idle": "2022-06-07T15:38:22.922829Z",
     "shell.execute_reply": "2022-06-07T15:38:22.922751Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.922743Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'ID number',\n",
    "                'Diagnosis',\n",
    "                'radius',# (mean of distances from center to points on the perimeter)\n",
    "                'texture',# (standard deviation of gray-scale values)\n",
    "                'perimeter',\n",
    "                'area',\n",
    "                'smoothness',# (local variation in radius lengths)\n",
    "                'compactness',# (perimeter^2 / area - 1.0)\n",
    "                'concavity',# (severity of concave portions of the contour)\n",
    "                'concave points',# (number of concave portions of the contour)\n",
    "                'symmetry',\n",
    "                'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                ]\n",
    "#Wisconsin Prognostic Breast Cancer\n",
    "wpbc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wpbc.data', names=feature_names, index_col=False)\n",
    "\n",
    "features_select = [\n",
    "                    #'ID number',\n",
    "                    'Diagnosis',\n",
    "                    'radius',# (mean of distances from center to points on the perimeter)\n",
    "                    'texture',# (standard deviation of gray-scale values)\n",
    "                    'perimeter',\n",
    "                    'area',\n",
    "                    'smoothness',# (local variation in radius lengths)\n",
    "                    'compactness',# (perimeter^2 / area - 1.0)\n",
    "                    'concavity',# (severity of concave portions of the contour)\n",
    "                    'concave points',# (number of concave portions of the contour)\n",
    "                    'symmetry',\n",
    "                    'fractal dimension',# (\"coastline approximation\" - 1)\n",
    "                    ]\n",
    "\n",
    "wpbc_data = wpbc_data[features_select]\n",
    "\n",
    "nominal_features_wpbc = [\n",
    "                        ]\n",
    "ordinal_features_wpbc = [\n",
    "                   ]\n",
    " \n",
    "X_data_wpbc = wpbc_data.drop(['Diagnosis'], axis = 1)\n",
    "y_data_wpbc= pd.Series(OrdinalEncoder().fit_transform(wpbc_data['Diagnosis'].values.reshape(-1, 1)).flatten(), name='Diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.923259Z",
     "iopub.status.idle": "2022-06-07T15:38:22.923412Z",
     "shell.execute_reply": "2022-06-07T15:38:22.923338Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.923330Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Wisconsin Prognostic Breast Cancer'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_wpbc, \n",
    "                                                                y_data_wpbc, \n",
    "                                                                nominal_features = nominal_features_wpbc, \n",
    "                                                                ordinal_features = ordinal_features_wpbc,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.923948Z",
     "iopub.status.idle": "2022-06-07T15:38:22.924185Z",
     "shell.execute_reply": "2022-06-07T15:38:22.924109Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.924101Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.924628Z",
     "iopub.status.idle": "2022-06-07T15:38:22.924871Z",
     "shell.execute_reply": "2022-06-07T15:38:22.924793Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.924783Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.925335Z",
     "iopub.status.idle": "2022-06-07T15:38:22.925486Z",
     "shell.execute_reply": "2022-06-07T15:38:22.925413Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.925405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                'Sex',#\t\tnominal\t\t\tM, F, and I (infant)\n",
    "                'Length',#\tcontinuous\tmm\tLongest shell measurement\n",
    "                'Diameter',#\tcontinuous\tmm\tperpendicular to length\n",
    "                'Height',#\t\tcontinuous\tmm\twith meat in shell\n",
    "                'Whole weight',#\tcontinuous\tgrams\twhole abalone\n",
    "                'Shucked weight',#\tcontinuous\tgrams\tweight of meat\n",
    "                'Viscera weight',#\tcontinuous\tgrams\tgut weight (after bleeding)\n",
    "                'Shell weight',#\tcontinuous\tgrams\tafter being dried\n",
    "                'Rings',#\t\tinteger\t\t\t+1.5 gives the age in years\n",
    "                ]\n",
    "\n",
    "abalone_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data', names=feature_names, index_col=False)\n",
    "\n",
    "\n",
    "features_select = [\n",
    "                'Sex',#\t\tnominal\t\t\tM, F, and I (infant)\n",
    "                'Length',#\tcontinuous\tmm\tLongest shell measurement\n",
    "                'Diameter',#\tcontinuous\tmm\tperpendicular to length\n",
    "                'Height',#\t\tcontinuous\tmm\twith meat in shell\n",
    "                'Whole weight',#\tcontinuous\tgrams\twhole abalone\n",
    "                'Shucked weight',#\tcontinuous\tgrams\tweight of meat\n",
    "                'Viscera weight',#\tcontinuous\tgrams\tgut weight (after bleeding)\n",
    "                'Shell weight',#\tcontinuous\tgrams\tafter being dried\n",
    "                'Rings',#\t\tinteger\t\t\t+1.5 gives the age in years\n",
    "                    ]\n",
    "\n",
    "abalone_data = abalone_data[features_select]\n",
    "\n",
    "nominal_features_abalone = [\n",
    "                        'Sex',\n",
    "                        ]\n",
    "ordinal_features_abalone = [\n",
    "                   ]\n",
    "   \n",
    "X_data_abalone = abalone_data.drop(['Rings'], axis = 1)\n",
    "y_data_abalone = ((abalone_data['Rings'] > 10) * 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.925860Z",
     "iopub.status.idle": "2022-06-07T15:38:22.926005Z",
     "shell.execute_reply": "2022-06-07T15:38:22.925933Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.925925Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Abalone'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_abalone, \n",
    "                                                                y_data_abalone, \n",
    "                                                                nominal_features = nominal_features_abalone, \n",
    "                                                                ordinal_features = ordinal_features_abalone,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.926457Z",
     "iopub.status.idle": "2022-06-07T15:38:22.926599Z",
     "shell.execute_reply": "2022-06-07T15:38:22.926528Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.926520Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.927107Z",
     "iopub.status.idle": "2022-06-07T15:38:22.927335Z",
     "shell.execute_reply": "2022-06-07T15:38:22.927259Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.927250Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.927823Z",
     "iopub.status.idle": "2022-06-07T15:38:22.928054Z",
     "shell.execute_reply": "2022-06-07T15:38:22.927978Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.927969Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "   'buying',#       v-high, high, med, low\n",
    "   'maint',#        v-high, high, med, low\n",
    "   'doors',#        2, 3, 4, 5-more\n",
    "   'persons',#      2, 4, more\n",
    "   'lug_boot',#     small, med, big\n",
    "   'safety',#       low, med, high\n",
    "   'class',#        unacc, acc, good, v-good\n",
    "                ]\n",
    "\n",
    "car_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=feature_names, index_col=False)\n",
    "\n",
    "features_select = [\n",
    "                   'buying',#       v-high, high, med, low\n",
    "                   'maint',#        v-high, high, med, low\n",
    "                   'doors',#        2, 3, 4, 5-more\n",
    "                   'persons',#      2, 4, more\n",
    "                   'lug_boot',#     small, med, big\n",
    "                   'safety',#       low, med, high\n",
    "                   'class',#        unacc, acc, good, v-good\n",
    "                    ]\n",
    "\n",
    "car_data = car_data[features_select]\n",
    "\n",
    "nominal_features_car = [\n",
    "                       'buying',#       v-high, high, med, low\n",
    "                       'maint',#        v-high, high, med, low\n",
    "                       'doors',#        2, 3, 4, 5-more\n",
    "                       'persons',#      2, 4, more\n",
    "                       'lug_boot',#     small, med, big\n",
    "                       'safety',#       low, med, high\n",
    "                        ]\n",
    "\n",
    "ordinal_features_car = [\n",
    "                   ]\n",
    "\n",
    "\n",
    "    \n",
    "X_data_car = car_data.drop(['class'], axis = 1)\n",
    "y_data_car = ((car_data['class'] != 'unacc') * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.928409Z",
     "iopub.status.idle": "2022-06-07T15:38:22.928552Z",
     "shell.execute_reply": "2022-06-07T15:38:22.928481Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.928473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Car'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_car, \n",
    "                                                                y_data_car, \n",
    "                                                                nominal_features = nominal_features_car, \n",
    "                                                                ordinal_features = ordinal_features_car,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.929019Z",
     "iopub.status.idle": "2022-06-07T15:38:22.929233Z",
     "shell.execute_reply": "2022-06-07T15:38:22.929158Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.929149Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.929765Z",
     "iopub.status.idle": "2022-06-07T15:38:22.929931Z",
     "shell.execute_reply": "2022-06-07T15:38:22.929843Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.929835Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.930334Z",
     "iopub.status.idle": "2022-06-07T15:38:22.930557Z",
     "shell.execute_reply": "2022-06-07T15:38:22.930482Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.930473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "   'age',#      \n",
    "   'sex',#   \n",
    "   'cp',#      \n",
    "   'trestbps',#\n",
    "   'chol',#    \n",
    "   'fbs',#      \n",
    "   'restecg',# \n",
    "   'thalach',#      \n",
    "   'exang',#   \n",
    "   'oldpeak',#      \n",
    "   'slope',#\n",
    "   'ca',#    \n",
    "   'thal',#      \n",
    "   'num',#     \n",
    "                ]\n",
    "\n",
    "heart_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data', names=feature_names, index_col=False) #, delimiter=' '\n",
    "print(heart_data.shape)\n",
    "\n",
    "\n",
    "nominal_features_heart = [\n",
    "                        ]\n",
    "\n",
    "ordinal_features_heart = [\n",
    "                   ]\n",
    "\n",
    "\n",
    "heart_data['age'][heart_data['age'] == '?'] = heart_data['age'].mode()[0]\n",
    "heart_data['sex'][heart_data['sex'] == '?'] = heart_data['sex'].mode()[0]\n",
    "heart_data['cp'][heart_data['cp'] == '?'] = heart_data['cp'].mode()[0]\n",
    "heart_data['trestbps'][heart_data['trestbps'] == '?'] = heart_data['trestbps'].mode()[0]\n",
    "heart_data['chol'][heart_data['chol'] == '?'] = heart_data['chol'].mode()[0]\n",
    "heart_data['fbs'][heart_data['fbs'] == '?'] = heart_data['fbs'].mode()[0]\n",
    "heart_data['restecg'][heart_data['restecg'] == '?'] = heart_data['restecg'].mode()[0]\n",
    "heart_data['thalach'][heart_data['thalach'] == '?'] = heart_data['thalach'].mode()[0]\n",
    "heart_data['exang'][heart_data['exang'] == '?'] = heart_data['exang'].mode()[0]\n",
    "heart_data['oldpeak'][heart_data['oldpeak'] == '?'] = heart_data['oldpeak'].mode()[0]\n",
    "heart_data['slope'][heart_data['slope'] == '?'] = heart_data['slope'].mode()[0]\n",
    "heart_data['ca'][heart_data['ca'] == '?'] = heart_data['ca'].mode()[0]\n",
    "heart_data['thal'][heart_data['thal'] == '?'] = heart_data['thal'].mode()[0]\n",
    "    \n",
    "X_data_heart = heart_data.drop(['num'], axis = 1)\n",
    "y_data_heart = ((heart_data['num'] < 1) * 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.930908Z",
     "iopub.status.idle": "2022-06-07T15:38:22.931054Z",
     "shell.execute_reply": "2022-06-07T15:38:22.930981Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.930973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Heart Disease'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_heart, \n",
    "                                                                y_data_heart, \n",
    "                                                                nominal_features = nominal_features_heart, \n",
    "                                                                ordinal_features = ordinal_features_heart,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.931496Z",
     "iopub.status.idle": "2022-06-07T15:38:22.931691Z",
     "shell.execute_reply": "2022-06-07T15:38:22.931616Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.931607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.932263Z",
     "iopub.status.idle": "2022-06-07T15:38:22.932414Z",
     "shell.execute_reply": "2022-06-07T15:38:22.932341Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.932332Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.932946Z",
     "iopub.status.idle": "2022-06-07T15:38:22.933101Z",
     "shell.execute_reply": "2022-06-07T15:38:22.933026Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.933018Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "credit_card_data = pd.read_csv('./real_world_datasets/UCI_Credit_Card/UCI_Credit_Card.csv', index_col=False) #, delimiter=' '\n",
    "credit_card_data = credit_card_data.drop(['ID'], axis = 1)\n",
    "print(credit_card_data.shape)\n",
    "\n",
    "nominal_features_credit_card = [\n",
    "                        ]\n",
    "\n",
    "ordinal_features_credit_card = [\n",
    "                   ]\n",
    "    \n",
    "X_data_credit_card = credit_card_data.drop(['default.payment.next.month'], axis = 1)\n",
    "y_data_credit_card = ((credit_card_data['default.payment.next.month'] < 1) * 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.933508Z",
     "iopub.status.idle": "2022-06-07T15:38:22.933658Z",
     "shell.execute_reply": "2022-06-07T15:38:22.933585Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.933577Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Credit Card'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_credit_card, \n",
    "                                                                y_data_credit_card, \n",
    "                                                                nominal_features = nominal_features_credit_card, \n",
    "                                                                ordinal_features = ordinal_features_credit_card,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.934082Z",
     "iopub.status.idle": "2022-06-07T15:38:22.934255Z",
     "shell.execute_reply": "2022-06-07T15:38:22.934181Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.934173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.934777Z",
     "iopub.status.idle": "2022-06-07T15:38:22.934928Z",
     "shell.execute_reply": "2022-06-07T15:38:22.934855Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.934846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haberman's Survival Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.935417Z",
     "iopub.status.idle": "2022-06-07T15:38:22.935587Z",
     "shell.execute_reply": "2022-06-07T15:38:22.935495Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.935487Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "   'age',#      \n",
    "   'year',#   \n",
    "   'nodes_detected',#      \n",
    "   'survival',#     \n",
    "                ]\n",
    "\n",
    "haberman_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data', names=feature_names, index_col=False) #, delimiter=' '\n",
    "print(haberman_data.shape)\n",
    "\n",
    "\n",
    "nominal_features_haberman = [\n",
    "                        ]\n",
    "\n",
    "ordinal_features_haberman = [\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_haberman = haberman_data.drop(['survival'], axis = 1)\n",
    "y_data_haberman = ((haberman_data['survival'] < 2) * 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.936025Z",
     "iopub.status.idle": "2022-06-07T15:38:22.936236Z",
     "shell.execute_reply": "2022-06-07T15:38:22.936162Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.936154Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = 'Haberman'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_haberman, \n",
    "                                                                y_data_haberman, \n",
    "                                                                nominal_features = nominal_features_haberman, \n",
    "                                                                ordinal_features = ordinal_features_haberman,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.936711Z",
     "iopub.status.idle": "2022-06-07T15:38:22.936859Z",
     "shell.execute_reply": "2022-06-07T15:38:22.936787Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.936779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.937266Z",
     "iopub.status.idle": "2022-06-07T15:38:22.937453Z",
     "shell.execute_reply": "2022-06-07T15:38:22.937378Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.937370Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.937911Z",
     "iopub.status.idle": "2022-06-07T15:38:22.938059Z",
     "shell.execute_reply": "2022-06-07T15:38:22.937986Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.937978Z"
    }
   },
   "outputs": [],
   "source": [
    "heart_failure_data = pd.read_csv('real_world_datasets/Heart Failure/heart_failure_clinical_records_dataset.csv', delimiter=',')\n",
    "\n",
    "\n",
    "nominal_features_heart_failure = [\n",
    "                        ]\n",
    "ordinal_features_heart_failure = [\n",
    "\n",
    "                   ]\n",
    "\n",
    "    \n",
    "X_data_heart_failure = heart_failure_data.drop(['DEATH_EVENT'], axis = 1)\n",
    "y_data_heart_failure = ((heart_failure_data['DEATH_EVENT'] > 0) * 1)\n",
    "\n",
    "X_data_heart_failure.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.938582Z",
     "iopub.status.idle": "2022-06-07T15:38:22.938726Z",
     "shell.execute_reply": "2022-06-07T15:38:22.938654Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.938646Z"
    }
   },
   "outputs": [],
   "source": [
    "identifier = 'Heart Failure'\n",
    "identifier_list.append(identifier)\n",
    "\n",
    "(distances_dict[identifier], \n",
    " evaluation_result_dict[identifier], \n",
    " results_dict[identifier], \n",
    " dt_inet_dict[identifier], \n",
    " dt_distilled_list_dict[identifier], \n",
    " data_dict[identifier],\n",
    " normalizer_list_dict[identifier],\n",
    " test_network_list[identifier]) = evaluate_real_world_dataset(model,\n",
    "                                                                dataset_size_list,\n",
    "                                                                mean_train_parameters,\n",
    "                                                                std_train_parameters,\n",
    "                                                                lambda_net_dataset_train.network_parameters_array,\n",
    "                                                                X_data_heart_failure, \n",
    "                                                                y_data_heart_failure, \n",
    "                                                                nominal_features = nominal_features_heart_failure, \n",
    "                                                                ordinal_features = ordinal_features_heart_failure,\n",
    "                                                                config = config,\n",
    "                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                config_train_network = None)\n",
    "print_head = None\n",
    "if verbosity > 0:\n",
    "    print_results_different_data_sizes(results_dict[identifier], dataset_size_list_print)\n",
    "    print_network_distances(distances_dict)\n",
    "\n",
    "    dt_inet_plot = plot_decision_tree_from_parameters(dt_inet_dict[identifier], normalizer_list_dict[identifier], config)\n",
    "    dt_distilled_plot = plot_decision_tree_from_model(dt_distilled_list_dict[identifier][-2], config)\n",
    "\n",
    "    display(dt_inet_plot, dt_distilled_plot)\n",
    "\n",
    "    print_head = data_dict[identifier]['X_train'].head()\n",
    "print_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.939111Z",
     "iopub.status.idle": "2022-06-07T15:38:22.939259Z",
     "shell.execute_reply": "2022-06-07T15:38:22.939187Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.939179Z"
    }
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    plot_decision_area_evaluation_all_distrib(data_dict[identifier]['X_train'].values, \n",
    "                                data_dict[identifier]['y_train'].values, \n",
    "                                data_dict[identifier]['X_test'].values, \n",
    "                                data_dict[identifier]['y_test'].values,\n",
    "                                None,\n",
    "                                None,\n",
    "                                test_network_list[identifier],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('TRAINDATA')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDUNIFORM')],\n",
    "                                dt_distilled_list_dict[identifier][0][dataset_size_list.index('STANDARDNORMAL')],\n",
    "                                [dt_distilled_list_dict[identifier][0][dataset_size_list.index(config['evaluation']['random_evaluation_dataset_size_per_distribution'])]],\n",
    "                                dt_inet_dict[identifier],\n",
    "                                data_dict[identifier]['X_train'].columns,\n",
    "                                config['data']['distribution_list_eval'],\n",
    "                                config\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.939832Z",
     "iopub.status.idle": "2022-06-07T15:38:22.939981Z",
     "shell.execute_reply": "2022-06-07T15:38:22.939908Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.939900Z"
    }
   },
   "outputs": [],
   "source": [
    "if test_network_list[identifier] is not None:\n",
    "    for index, (var_name, feature_name) in enumerate(zip(['x'+str(i) for i in range(len(data_dict[identifier]['X_train'].columns))], list(data_dict[identifier]['X_train'].columns))):\n",
    "        scale_feature = normalizer_list_dict[identifier][index].scale_[0]\n",
    "        print(var_name, '=', feature_name, '(Scale: ' +  str(scale_feature) + ')')\n",
    "        \n",
    "    acc_list = [results_dict[identifier][i]['dt_scores']['accuracy_' + str(distribution_list_eval[0])] for i in range(max(loc for loc, val in enumerate(dataset_size_list) if val == dataset_size_list[0]))]\n",
    "    idx_min = np.argsort(acc_list)[0]#[len(acc_list)//2]\n",
    "    idx_uniform = dataset_size_list.index('STANDARDUNIFORM')\n",
    "    idx_train = dataset_size_list.index('TRAINDATA')\n",
    "    \n",
    "    print('\\n')\n",
    "    if config['function_family']['dt_type'] == 'vanilla':\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_train], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_inet = parameterDT(dt_inet_dict[identifier], config, normalizer_list=normalizer_list_dict[identifier])\n",
    "        image = dt_inet.plot()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_min], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plot_tree(dt_distilled_list_dict[identifier][0][idx_uniform], fontsize=10)  #fist index=distrib; second index=index; third index=10k vs Train\n",
    "        plt.show()      \n",
    "\n",
    " \n",
    "    else:\n",
    "        print('Accuracy Distilled Train', results_dict[identifier][idx_train]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train', results_dict[identifier][idx_train]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score Distilled Train (Train Data)', results_dict[identifier][idx_train]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_train].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy I-Net', results_dict[identifier][idx_min]['inet_scores']['accuracy'])\n",
    "        print('F1-Score  I-Net', results_dict[identifier][idx_min]['inet_scores']['f1_score'])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        dt_parameters = dt_inet_dict[identifier]\n",
    "        tree = generate_random_decision_tree(config)\n",
    "        tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "        image = tree.plot_tree()\n",
    "        display(image)\n",
    "\n",
    "        print('Accuracy Distilled Random', results_dict[identifier][idx_min]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random', results_dict[identifier][idx_min]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Random (Train Data)', results_dict[identifier][idx_min]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])        \n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_min].plot_tree()\n",
    "        display(image)\n",
    "        \n",
    "        print('Accuracy Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_' + str(distribution_list_eval[0])])\n",
    "        print('Accuracy Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['accuracy_data_random_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_' + str(distribution_list_eval[0])])\n",
    "        print('F1-Score  Distilled Uniform (Train Data)', results_dict[identifier][idx_uniform]['dt_scores']['f1_score_data_random_' + str(distribution_list_eval[0])])\n",
    "        plt.figure(figsize=(15,8))\n",
    "        image = dt_distilled_list_dict[identifier][0][idx_uniform].plot_tree()\n",
    "        display(image)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.940411Z",
     "iopub.status.idle": "2022-06-07T15:38:22.940633Z",
     "shell.execute_reply": "2022-06-07T15:38:22.940559Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.940550Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list_reduced = deepcopy(identifier_list)\n",
    "for identifier in identifier_list:\n",
    "    if test_network_list[identifier] is None:\n",
    "        identifier_list_reduced.remove(identifier)\n",
    "\n",
    "try:\n",
    "    #print_complete_performance_evaluation_results(results_dict, identifier_list, dataset_size_list, dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    complete_performance_evaluation_results = get_complete_performance_evaluation_results_dataframe(results_dict, \n",
    "                                                                                                    identifier_list_reduced, \n",
    "                                                                                                    dataset_size_list,\n",
    "                                                                                                    dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    display(complete_performance_evaluation_results.head(20))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    #print_complete_performance_evaluation_results(results_dict, identifier_list, dataset_size_list, dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    complete_performance_evaluation_results = get_complete_performance_evaluation_results_dataframe_all_distrib(results_dict, \n",
    "                                                                                                                identifier_list_reduced, \n",
    "                                                                                                                dataset_size_list,\n",
    "                                                                                                                distribution_list_evaluation = config['data']['distribution_list_eval'],\n",
    "                                                                                                                dataset_size=config['evaluation']['random_evaluation_dataset_size_per_distribution'])\n",
    "    display(complete_performance_evaluation_results.head(20))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#print_network_distances(distances_dict)\n",
    "network_distances = get_print_network_distances_dataframe(distances_dict)\n",
    "display(network_distances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.941112Z",
     "iopub.status.idle": "2022-06-07T15:38:22.941264Z",
     "shell.execute_reply": "2022-06-07T15:38:22.941191Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.941182Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if different_eval_data:\n",
    "    flat_config = flatten_dict(config_train)\n",
    "else:\n",
    "    flat_config = flatten_dict(config)    \n",
    "\n",
    "flat_dict_train = flatten_dict(inet_evaluation_result_dict_train)\n",
    "flat_dict_valid = flatten_dict(inet_evaluation_result_dict_valid)\n",
    "if not evaluate_distribution:\n",
    "    flat_dict_test = flatten_dict(inet_evaluation_result_dict_test)\n",
    "else:\n",
    "    flat_dict_test = flatten_dict(inet_evaluation_result_dict_complete_by_distribution_test)\n",
    "\n",
    "header_column = ''  \n",
    "\n",
    "for key in flat_config.keys():\n",
    "    header_column += key\n",
    "    header_column += ';'     \n",
    "\n",
    "number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "for key in flat_dict_train.keys():\n",
    "    #if 'function_values' not in key:\n",
    "    for i in range(number_of_evaluated_networks):\n",
    "        header_column += key + '_train_' + str(i) + ';'  \n",
    "\n",
    "number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "for key in flat_dict_valid.keys():\n",
    "    #if 'function_values' not in key:\n",
    "    for i in range(number_of_evaluated_networks):\n",
    "        header_column += key + '_valid_' + str(i) + ';'       \n",
    "\n",
    "number_of_evaluated_networks = np.array(flat_dict_test[list(flat_dict_test.keys())[0]]).shape[0]\n",
    "for key in flat_dict_test.keys():\n",
    "    #if 'function_values' not in key:\n",
    "    for i in range(number_of_evaluated_networks):\n",
    "        header_column += key + '_test_' + str(i) + ';'          \n",
    "\n",
    "header_column += '\\n'\n",
    "\n",
    "\n",
    "if os.path.exists(writepath_complete):        \n",
    "    with open(writepath_complete, 'r') as text_file: \n",
    "        lines = text_file.readlines()\n",
    "    \n",
    "    counter = 1\n",
    "    while lines[0] != header_column:  \n",
    "        writepath_complete = './results_complete-' + str(counter) + '.csv' \n",
    "        if os.path.exists(writepath_complete):\n",
    "            with open(writepath_complete, 'r') as text_file: \n",
    "                lines = text_file.readlines()\n",
    "        else:\n",
    "            break\n",
    "        counter += 1\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file: \n",
    "        text_file.write(header_column)\n",
    "\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file:  \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "            \n",
    "        \n",
    "    number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_train.items():\n",
    "        #if 'function_values' not in key:\n",
    "        for score in values:\n",
    "            text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_valid.items():\n",
    "        #if 'function_values' not in key:\n",
    "        for score in values:\n",
    "            text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_test[list(flat_dict_test.keys())[0]]).shape[0]\n",
    "    for key, values in flat_dict_test.items():\n",
    "        #if 'function_values' not in key:\n",
    "        for score in values:\n",
    "            text_file.write(str(score) + ';')   \n",
    "                    \n",
    "    text_file.write('\\n')            \n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.941827Z",
     "iopub.status.idle": "2022-06-07T15:38:22.941988Z",
     "shell.execute_reply": "2022-06-07T15:38:22.941903Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.941895Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inet_evaluation_result_dict_mean_train_flat = flatten_dict(inet_evaluation_result_dict_mean_train)\n",
    "inet_evaluation_result_dict_mean_valid_flat = flatten_dict(inet_evaluation_result_dict_mean_valid)\n",
    "if not evaluate_distribution:\n",
    "    inet_evaluation_result_dict_mean_test_flat = flatten_dict(inet_evaluation_result_dict_mean_test)\n",
    "else:\n",
    "    inet_evaluation_result_dict_mean_test_flat = flatten_dict(inet_evaluation_result_dict_mean_by_distribution_test)\n",
    "\n",
    "#identifier_list_synthetic = ['train', 'valid', 'test']\n",
    "identifier_list_combined = list(flatten_list([identifier_list, ['train', 'valid', 'test']]))\n",
    "\n",
    "header_column = ''\n",
    "\n",
    "for key in flat_config.keys():\n",
    "    header_column += key + ';'\n",
    "\n",
    "for key in inet_evaluation_result_dict_mean_train_flat.keys():\n",
    "    header_column += 'train_' + key + ';'\n",
    "for key in inet_evaluation_result_dict_mean_valid_flat.keys():\n",
    "    header_column += 'valid_' + key + ';'          \n",
    "for key in inet_evaluation_result_dict_mean_test_flat.keys():\n",
    "    header_column += 'test_' + key + ';'                \n",
    "\n",
    "for dataset_size in dataset_size_list:\n",
    "    for identifier in identifier_list:\n",
    "        results_dict_flat = flatten_dict(results_dict[identifier][-2])\n",
    "        #del results_dict_flat['function_values_y_test_inet_dt']\n",
    "        #del results_dict_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "        for key in results_dict_flat.keys():\n",
    "            header_column += key + '_' + identifier + '_' + str(dataset_size) + ';'                                   \n",
    "\n",
    "for key in distances_dict['train'].keys():\n",
    "    for identifier in identifier_list_combined:\n",
    "        header_column += key + '_' + identifier + ';' \n",
    "\n",
    "header_column += '\\n'\n",
    " \n",
    "if os.path.exists(writepath_summary):        \n",
    "    with open(writepath_summary, 'r') as text_file: \n",
    "        lines = text_file.readlines()\n",
    "\n",
    "    counter = 1\n",
    "    while lines[0] != header_column:  \n",
    "        writepath_summary = './results_summary-' + str(counter) + '.csv' \n",
    "        if os.path.exists(writepath_summary):\n",
    "            with open(writepath_summary, 'r') as text_file: \n",
    "                lines = text_file.readlines()\n",
    "        else:\n",
    "            break\n",
    "        counter += 1\n",
    "\n",
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "        text_file.write(header_column)\n",
    "\n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "        \n",
    "    for value in inet_evaluation_result_dict_mean_train_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "    for value in inet_evaluation_result_dict_mean_valid_flat.values():\n",
    "        text_file.write(str(value) + ';')            \n",
    "    for value in inet_evaluation_result_dict_mean_test_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "\n",
    "    for i in range(len(dataset_size_list)):\n",
    "        for identifier in identifier_list:\n",
    "            evaluation_result_dict_flat = flatten_dict(evaluation_result_dict[identifier])\n",
    "            #del evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "            #del evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "            \n",
    "            for key, values in evaluation_result_dict_flat.items():\n",
    "                text_file.write(str(values[i]) + ';')    #values[i]        \n",
    "     \n",
    "    for key in distances_dict['train'].keys():\n",
    "        for identifier in identifier_list_combined:\n",
    "            text_file.write(str(distances_dict[identifier][key]) + ';')      \n",
    "    \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-07T15:38:22.942481Z",
     "iopub.status.idle": "2022-06-07T15:38:22.942632Z",
     "shell.execute_reply": "2022-06-07T15:38:22.942558Z",
     "shell.execute_reply.started": "2022-06-07T15:38:22.942550Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
