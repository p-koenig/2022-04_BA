{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef01b1f1-b53f-4863-ab46-e68e73eccd08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T17:48:28.940799Z",
     "iopub.status.busy": "2022-03-28T17:48:28.940562Z",
     "iopub.status.idle": "2022-03-28T17:48:28.943349Z",
     "shell.execute_reply": "2022-03-28T17:48:28.943026Z",
     "shell.execute_reply.started": "2022-03-28T17:48:28.940736Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-channel",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import researchpy as rp\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "\n",
    "import itertools\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import traceback\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "pd.set_option('max_columns', 50)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de19331-758b-4554-a779-36edb940d315",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b8038-c7df-4505-ae82-056b9bd19c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    \n",
    "    def flatten(l):\n",
    "        for el in l:\n",
    "            if isinstance(el, Iterable) and not isinstance(el, (str, bytes)):\n",
    "                yield from flatten(el)\n",
    "            else:\n",
    "                yield el\n",
    "                \n",
    "    flat_l = flatten(l)\n",
    "    \n",
    "    return list(flat_l)\n",
    "\n",
    "\n",
    "def get_relevant_columns_by_config(config, dataframe):\n",
    "    try:\n",
    "        if config['i_net_nas'] == False:\n",
    "            config.pop('i_net_nas_trials')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for key, value in config.items():\n",
    "        try:\n",
    "            if isinstance(value, list):\n",
    "                if isinstance(value[0], str):\n",
    "                    dataframe_string_query = key + ' == \"' + str(value[0]) + '\"'\n",
    "                    for dataframe_string in value[1:]:\n",
    "                        dataframe_string_query += ' | ' + key + ' == \"' + str(dataframe_string) + '\"'\n",
    "\n",
    "                    dataframe = dataframe.query(dataframe_string_query)\n",
    "                else:\n",
    "                    dataframe = dataframe[dataframe[key].isin(value)]\n",
    "                    \n",
    "            else:\n",
    "                dataframe = dataframe[dataframe[key] == value]\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "        \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def plot_results(data_reduced, col, x, y, hue, plot_type=sns.barplot, aspect=1.5, col_wrap=2):\n",
    "    \n",
    "    #sns.set(rc={'figure.figsize':(20,10)})\n",
    "    \n",
    "    g = sns.FacetGrid(data_reduced, \n",
    "                      col=col,\n",
    "                      ##hue='scores_type', \n",
    "                      #height=5, \n",
    "                      col_wrap=col_wrap,\n",
    "                      aspect=aspect,\n",
    "                      ##legend_out=False,\n",
    "                     )    \n",
    "    indexes = np.unique(data_reduced[hue], return_index=True)[1]\n",
    "    hue_order = [data_reduced[hue].values[index] for index in sorted(indexes)]\n",
    "        \n",
    "    g.map(plot_type, \n",
    "          x, \n",
    "          y, \n",
    "          hue,\n",
    "          hue_order=hue_order,#np.unique(data_reduced[hue]),\n",
    "          ##figsize=(20,10),\n",
    "          palette=sns.color_palette(),#'colorblind'\n",
    "          #order=data_reduced[order_columnname],\n",
    "          ##order=np.unique(results_summary_reduced_accuracy_plot[\"scores_type\"]),\n",
    "         )\n",
    "    g.add_legend(fontsize=12,\n",
    "               ncol=3,\n",
    "               bbox_to_anchor=(0.5, -0.025),\n",
    "               borderaxespad=0)    \n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d75633-dbcf-43e6-a72b-45a898caf649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbf500ce-c6c7-45bf-8162-044c58a6ec5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T08:42:54.251311Z",
     "iopub.status.busy": "2022-03-28T08:42:54.251184Z",
     "iopub.status.idle": "2022-03-28T08:42:54.276701Z",
     "shell.execute_reply": "2022-03-28T08:42:54.275734Z",
     "shell.execute_reply.started": "2022-03-28T08:42:54.251294Z"
    },
    "tags": []
   },
   "source": [
    "# Prepare Results Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cd0b06-984c-4e6f-9d65-d445f4689eea",
   "metadata": {},
   "source": [
    "## Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73da04-8710-49f8-91b9-92fa72840804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results_complete = pd.read_csv('./results_complete.csv', delimiter=';')\n",
    "#results_complete = results_complete[results_complete['i_net_nas'] == True]\n",
    "#results_complete_columns = list(results_complete.columns)\n",
    "\n",
    "#results_summary = pd.read_csv('./results_summary-TEST.csv', delimiter=';')\n",
    "results_summary = pd.read_csv('./results_summary.csv', delimiter=';')\n",
    "#results_summary = results_summary[results_summary['i_net_nas'] == True]\n",
    "results_summary_columns = list(results_summary.columns)\n",
    "results_summary['function_family_decision_sparsity'][results_summary['data_number_of_variables'] == results_summary['function_family_decision_sparsity']] = -1\n",
    "\n",
    "\n",
    "results_summary.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcf474-8621-4180-8c70-7de64570f204",
   "metadata": {},
   "source": [
    "### Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2463e27-6257-40d3-b30f-ca8c237d59a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colmuns_identifier = [\n",
    "                  'function_family_maximum_depth',\n",
    "                  'function_family_decision_sparsity', \n",
    "                  'function_family_dt_type',\n",
    "    \n",
    "                  'data_dt_type_train',\n",
    "                  'data_maximum_depth_train',\n",
    "                  'data_number_of_variables',\n",
    "                  'data_noise_injected_level',\n",
    "                  'data_function_generation_type',\n",
    "                  'data_categorical_indices',\n",
    "                    \n",
    "                  'data_exclude_linearly_seperable', \n",
    "                  'data_data_generation_filtering', \n",
    "                  'data_fixed_class_probability', \n",
    "                  'data_weighted_data_generation', \n",
    "                  'data_shift_distrib',\n",
    "      \n",
    "                  'lambda_net_lambda_network_layers',\n",
    "                  'lambda_net_optimizer_lambda',\n",
    "    \n",
    "                  'i_net_dense_layers',\n",
    "                  'i_net_dropout',\n",
    "                  'i_net_learning_rate',\n",
    "                  'i_net_loss',\n",
    "                  'i_net_interpretation_dataset_size',\n",
    "                  'i_net_function_representation_type',\n",
    "                  'i_net_data_reshape_version',\n",
    "                  'i_net_nas',\n",
    "                  'i_net_nas_trials',\n",
    "    \n",
    "                  'evaluation_eval_data_description_eval_data_function_generation_type',\n",
    "                  'evaluation_eval_data_description_eval_data_noise_injected_level',\n",
    "    \n",
    "                  'evaluation_number_of_random_evaluations_per_distribution',\n",
    "                 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505e03a-a1ea-42bd-8ac6-6ea3b8be9628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_inet = []\n",
    "for column in results_summary_columns:\n",
    "    if 'inet_scores' in column:\n",
    "        columns_inet.append(column)\n",
    "results_summary_inet = results_summary[flatten_list([colmuns_identifier, columns_inet])]\n",
    "\n",
    "results_summary_inet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20b962-cba9-423e-bc2e-7c8c39648e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_inet = []\n",
    "for column in results_summary_columns:\n",
    "    if 'inet_scores' in column:\n",
    "        columns_inet.append(column)\n",
    "results_summary_inet = results_summary[flatten_list([colmuns_identifier, columns_inet])]\n",
    "\n",
    "columns_inet_rename = []\n",
    "for column in columns_inet:\n",
    "    column = column.replace('inet_scores_', '')\n",
    "    columns_inet_rename.append(column)\n",
    "\n",
    "results_summary_inet.columns = flatten_list([colmuns_identifier, columns_inet_rename])\n",
    "\n",
    "#results_summary_inet.insert(0, 'scores_type', 'inet_scores')\n",
    "results_summary_inet.insert(0, 'dt_type', [dt_type + str(decision_sparsity) for dt_type, decision_sparsity in zip(results_summary_inet['function_family_dt_type'].values, results_summary_inet['function_family_decision_sparsity'].values)])\n",
    "results_summary_inet.insert(0, 'technique', ['inet' for _ in range(results_summary_inet.shape[0])])\n",
    "\n",
    "    \n",
    "print(results_summary_inet.shape)\n",
    "results_summary_inet.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5671878-22c3-4a2f-9d46-a516fd0fc5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_dt_distilled = []\n",
    "for column in results_summary_columns:\n",
    "    if 'dt_scores' in column:\n",
    "        if 'data_random' not in column:\n",
    "            columns_dt_distilled.append(column)\n",
    "results_summary_dt_distilled = results_summary[flatten_list([colmuns_identifier, columns_dt_distilled])]\n",
    "\n",
    "columns_dt_distilled_rename = []\n",
    "for column in columns_dt_distilled:\n",
    "    column = column.replace('dt_scores_','')\n",
    "    columns_dt_distilled_rename.append(column)\n",
    "\n",
    "results_summary_dt_distilled.columns = flatten_list([colmuns_identifier, columns_dt_distilled_rename])\n",
    "    \n",
    "#results_summary_dt_distilled.insert(0, 'scores_type', 'dt_scores')\n",
    "results_summary_dt_distilled.insert(0, 'dt_type', [dt_type + str(decision_sparsity) for dt_type, decision_sparsity in zip(results_summary_dt_distilled['function_family_dt_type'].values, results_summary_dt_distilled['function_family_decision_sparsity'].values)])\n",
    "results_summary_dt_distilled.insert(0, 'technique', ['distilled' for _ in range(results_summary_dt_distilled.shape[0])])\n",
    "\n",
    "    \n",
    "print(results_summary_dt_distilled.shape)\n",
    "results_summary_dt_distilled.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bffa79-c228-4d50-9371-ad1635d7bae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_summary_inet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd8f3cf-219a-48d9-a5ba-68b981ac2f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_summary_dt_distilled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348a43e-1352-4078-9ebd-715deed82ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_summary_reduced = pd.concat([\n",
    "                                     results_summary_inet, \n",
    "                                     results_summary_dt_distilled, \n",
    "                                    ]).reset_index(drop=True)\n",
    "results_summary_reduced_columns = results_summary_reduced.columns\n",
    "results_summary_reduced.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b72bdd-789f-40fb-9035-7c50f0042b57",
   "metadata": {},
   "source": [
    "## Considered Results Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53083155-c762-4dc0-9a9a-4117f4736a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'i_net_dense_layers': ['[1792, 512, 512]'], #['[1024, 1024, 256, 2048, 2048]'], #\n",
    "    'i_net_dropout': ['[0, 0, 0.5]'], #['[0, 0, 0, 0, 0.3]'], #\n",
    "    \n",
    "    'i_net_loss': 'binary_crossentropy', # 'binary_crossentropy', 'soft_binary_crossentropy'\n",
    "    \n",
    "    'data_exclude_linearly_seperable': True,\n",
    "    'data_data_generation_filtering':  False, \n",
    "    'data_fixed_class_probability':  True, \n",
    "    'data_weighted_data_generation':  True, \n",
    "    'data_shift_distrib':  False, \n",
    "    \n",
    "    #'data_noise_injected_level': 0, \n",
    "    #'data_data_noise': 0,\n",
    "\n",
    "    'i_net_nas': False, # 'True', 'False'\n",
    "    'i_net_nas_trials': 20, #20, 100\n",
    "\n",
    "    #'data_number_of_variables': [unique_value], # [10]\n",
    "    'function_family_maximum_depth': [3, 4, 5], # [3, 4, 5]\n",
    "    \n",
    "    'evaluation_number_of_random_evaluations_per_distribution': [10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9e633-c44f-4460-8e94-b406a8094c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_names_list = ['valid_accuracy', 'valid_binary_crossentropy', 'valid_f1_score']\n",
    "valid_scores_columns = [name for name in results_summary_reduced_columns if 'valid' in name and any([score in name for score in score_names_list])]\n",
    "valid_identifier_columns = ['dt_type', 'data_number_of_variables', 'technique']\n",
    "valid_columns = flatten_list([valid_identifier_columns, valid_scores_columns])\n",
    "\n",
    "valid_scores_df = get_relevant_columns_by_config(config, results_summary_reduced)\n",
    "valid_scores_df = valid_scores_df[valid_columns]\n",
    "valid_scores_df = valid_scores_df.sort_values(['dt_type', 'data_number_of_variables', 'technique'], ascending=[True, True, True])\n",
    "valid_scores_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a9b73-2468-435d-becc-b9ed2e5410eb",
   "metadata": {},
   "source": [
    "## Real-World Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07680f0-a93a-483a-a6a3-1062ea6f8f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distribution_list = ['uniform', 'gamma', 'beta', 'poisson', 'normal']\n",
    "\n",
    "if True:\n",
    "    real_world_datasets = {\n",
    "                            'Adult': 28,#65,\n",
    "                            'Titanic': 9,\n",
    "                            'Absenteeism': 15,\n",
    "                            'Loan House': 16,#17,\n",
    "                            'Loan Credit': 32,\n",
    "                            'Medical Insurance': 9,#6,\n",
    "                            'Bank Marketing': 29,#17,\n",
    "                            'Cervical Cancer': 15,\n",
    "                            'Brest Cancer Wisconsin': 9,\n",
    "                            'Wisconsin Diagnostic Breast Cancer': 10,\n",
    "                            'Wisconsin Prognostic Breast Cancer': 10,\n",
    "                            'Abalone': 10,\n",
    "                            #'Car': 21,\n",
    "                           }\n",
    "    real_world_datasets = dict(sorted(real_world_datasets.items(), key=lambda item: item[1]))\n",
    "elif False:\n",
    "    real_world_datasets = {\n",
    "                        'Adult': 28,#65,\n",
    "                        'Titanic': 9,\n",
    "                            'Absenteeism': 15,\n",
    "                            'Loan House': 16,#17,\n",
    "                            #'Loan Credit': 32,\n",
    "                        'Medical Insurance': 9,#6,\n",
    "                            'Bank Marketing': 29,#17,\n",
    "                        'Cervical Cancer': 15,\n",
    "                            'Brest Cancer Wisconsin': 9,\n",
    "                            'Wisconsin Diagnostic Breast Cancer': 10,\n",
    "                            #'Wisconsin Prognostic Breast Cancer': 10,\n",
    "                            #'Abalone': 10,\n",
    "                            ##'Car': 21,\n",
    "                           }\n",
    "    real_world_datasets = dict(sorted(real_world_datasets.items(), key=lambda item: item[1]))\n",
    "else:\n",
    "    real_world_datasets = {\n",
    "                        'Adult': 32,#28,\n",
    "                        'Titanic': 10,#9,\n",
    "                            'Absenteeism': 15,\n",
    "                            'Loan House': 15,#16,\n",
    "                                'Loan Credit': 32,\n",
    "                        'Medical Insurance': 10,#9,\n",
    "                            'Bank Marketing': 32,#29,\n",
    "                        'Cervical Cancer': 15,\n",
    "                            'Brest Cancer Wisconsin': 10,#9,\n",
    "                            'Wisconsin Diagnostic Breast Cancer': 10,\n",
    "                            'Wisconsin Prognostic Breast Cancer': 10,\n",
    "                            'Abalone': 10,\n",
    "                            ##'Car': 21,\n",
    "                           }\n",
    "    real_world_datasets = dict(sorted(real_world_datasets.items(), key=lambda item: item[1]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646bc5f-8f1f-4b23-a123-cf2bd5cb31ea",
   "metadata": {},
   "source": [
    "## Restructuring & Selecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce14f56-3b94-4f78-a4c1-85f5cebfbee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_world_dataset_names = list(real_world_datasets.keys())\n",
    "score_names_list = ['accuracy']#['accuracy', 'binary_crossentropy', 'f1_score']\n",
    "real_world_scores_columns = [name for name in results_summary_reduced_columns if any([score in name for score in score_names_list]) and 'soft' not in name and any([dataset_name in name for dataset_name in real_world_dataset_names])]\n",
    "real_world_identifier_columns = ['dt_type', 'data_number_of_variables', 'technique']\n",
    "real_world_columns = flatten_list([real_world_identifier_columns, real_world_scores_columns])\n",
    "\n",
    "real_world_scores_df = get_relevant_columns_by_config(config, results_summary_reduced)\n",
    "real_world_scores_df = real_world_scores_df[real_world_columns]\n",
    "real_world_scores_df = real_world_scores_df.sort_values(['dt_type', 'data_number_of_variables', 'technique'], ascending=[True, True, True])\n",
    "#real_world_scores_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df9737-382e-45a9-83f2-808db70cea96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = flatten_list(['dt_type', 'technique', 'enumerator', 'distrib', [[real_world_dataset_name + ' ' + score_name for real_world_dataset_name in real_world_datasets.keys()] for score_name in score_names_list]])\n",
    "#print(np.array(columns).shape)\n",
    "#columns = np.hstack([columns for i in range(5)])\n",
    "#print(np.array(columns).shape)\n",
    "\n",
    "\n",
    "number_of_random_evaluations_per_distribution= 0\n",
    "for column in real_world_columns:\n",
    "    column_split = column.split('.')\n",
    "    value = 0\n",
    "    try:\n",
    "        value = int(column_split[-1])\n",
    "    except:\n",
    "        pass\n",
    "    if value > number_of_random_evaluations_per_distribution:\n",
    "        number_of_random_evaluations_per_distribution = value\n",
    "    \n",
    "\n",
    "empty_data_distilled = np.array([np.vstack([\n",
    "             [flatten_list(['vanilla1', 'distilled', i, distrib, [np.nan for _ in range(len(columns)-4)]]) for i in range(number_of_random_evaluations_per_distribution+1)],\n",
    "             #[flatten_list(['SDT1',  'distilled', 0, distrib, [np.nan for _ in range(len(columns)-4)]]) for i in range(number_of_random_evaluations_per_distribution+1)]\n",
    "             [flatten_list(['SDT-1',  'distilled', i, distrib, [np.nan for _ in range(len(columns)-4)]]) for i in range(number_of_random_evaluations_per_distribution+1)]\n",
    "            ]) for distrib in distribution_list] )\n",
    "\n",
    "empty_data_distilled = empty_data_distilled.reshape(empty_data_distilled.shape[0]*empty_data_distilled.shape[1], -1)\n",
    "\n",
    "empty_data_inet = np.array([\n",
    "                    flatten_list(['vanilla1', 'inet', np.nan, 'inet', [np.nan for _ in range(len(columns)-4)]]),\n",
    "                    #flatten_list(['SDT1', 'inet', 'inet', [np.nan for _ in range(len(columns)-4)]]),\n",
    "                    flatten_list(['SDT-1', 'inet', np.nan, 'inet', [np.nan for _ in range(len(columns)-4)]]),\n",
    "                  ])\n",
    "\n",
    "empty_data = np.vstack([empty_data_inet, empty_data_distilled])\n",
    "empty_data[:,4:] = np.nan_to_num(x=empty_data[:,4:].astype(np.float64), nan=0)\n",
    "\n",
    "real_world_scores_df_distrib_adjusted = pd.DataFrame(data=empty_data, columns=columns)\n",
    "\n",
    "\n",
    "for real_world_dataset_name, real_world_dataset_variables in real_world_datasets.items():\n",
    "    #scores_by_variables = real_world_scores_df[real_world_scores_df['data_number_of_variables'] == real_world_dataset_variables]\n",
    "\n",
    "    if real_world_scores_df[real_world_scores_df['data_number_of_variables'] == real_world_dataset_variables].shape[0] > 1:\n",
    "        scores_by_variables = real_world_scores_df[real_world_scores_df['data_number_of_variables'] == real_world_dataset_variables]\n",
    "        for i, row in real_world_scores_df_distrib_adjusted.iterrows():\n",
    "            for score_name in score_names_list:\n",
    "                relevant_column = None\n",
    "                for column_name in real_world_scores_df.columns:\n",
    "                    if (row['distrib'] in column_name and \n",
    "                        real_world_dataset_name in column_name and \n",
    "                        score_name in column_name and \n",
    "                        '10000' in column_name and \n",
    "                        '100000' not in column_name and \n",
    "                        'std' not in column_name):\n",
    "                        try:\n",
    "                            row['enumerator'] = int(row['enumerator'])\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        if '.' + str(row['enumerator']) in column_name or ('.' not in column_name and row['enumerator'] == 0):\n",
    "                            if relevant_column is None:\n",
    "                                relevant_column = column_name\n",
    "                            else:\n",
    "                                print('DOUBLE', relevant_column, column_name)\n",
    "                                print(\"row['enumerator']\", row['enumerator'])\n",
    "                try:\n",
    "                    if row['technique'] == 'distilled':\n",
    "                        scores_by_variables_selected = scores_by_variables[scores_by_variables['dt_type'] == row['dt_type']]\n",
    "                        scores_by_variables_selected = scores_by_variables_selected[scores_by_variables_selected['technique'] == row['technique']]\n",
    "\n",
    "                        row[real_world_dataset_name + ' ' + score_name] = np.max(scores_by_variables_selected[relevant_column].values)\n",
    "                    else:\n",
    "                        scores_by_variables_selected = scores_by_variables[scores_by_variables['dt_type'] == row['dt_type']]\n",
    "                        scores_by_variables_selected = scores_by_variables_selected[scores_by_variables_selected['technique'] == row['technique']]\n",
    "                        relevant_column = score_name + '_' + real_world_dataset_name + '_10000'\n",
    "                        row[real_world_dataset_name + ' ' + score_name] = np.max(scores_by_variables_selected[relevant_column].values)                            \n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "                    #print(scores_by_variables_selected[relevant_column])\n",
    "                    #traceback.print_exc()\n",
    "\n",
    "real_world_scores_df_distrib_adjusted.iloc[:,4:] = real_world_scores_df_distrib_adjusted.iloc[:,4:].astype(float)\n",
    "real_world_scores_df_distrib_adjusted.head(100)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69418fb3-c8d5-45c4-beef-39a2622dad31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for row in real_world_scores_df_distrib_adjusted.query('technique == \"inet\"').values:\n",
    "    \n",
    "    row_inet_identifier = row[:4]\n",
    "    row_inet_mean = row[4:]\n",
    "    row_inet_std = np.zeros_like(row_inet_mean)\n",
    "    \n",
    "    row_inet_mean_std = np.dstack([row_inet_mean, row_inet_std]).flatten()\n",
    "\n",
    "    row_inet = np.hstack([row_inet_identifier, row_inet_mean_std])    \n",
    "    data.append(row_inet)\n",
    "    \n",
    "for dt_type in real_world_scores_df_distrib_adjusted['dt_type'].unique():\n",
    "    rows_selected = real_world_scores_df_distrib_adjusted.query('dt_type == \"' + dt_type + '\" & technique == \"distilled\"')\n",
    "    rows_selected_values = rows_selected.values[:,4:]\n",
    "\n",
    "    row_identifier = [dt_type, 'distilled', np.nan, 'distilled']\n",
    "\n",
    "    row_values_mean = np.mean(rows_selected_values.astype(np.float64), axis=0)\n",
    "    row_values_std = np.std(rows_selected_values.astype(np.float64), axis=0)\n",
    "\n",
    "    row_values_mean_std = np.dstack([row_values_mean, row_values_std]).flatten()\n",
    "    #print(rows_selected.values)\n",
    "    row_mean_std = np.hstack([row_identifier, row_values_mean_std])\n",
    "    data.append(row_mean_std)\n",
    "        \n",
    "for distrib in distribution_list:\n",
    "    for dt_type in real_world_scores_df_distrib_adjusted['dt_type'].unique():\n",
    "        rows_selected = real_world_scores_df_distrib_adjusted.query('dt_type == \"' + dt_type + '\" & distrib == \"' + distrib + '\"')\n",
    "        rows_selected_values = rows_selected.values[:,4:]\n",
    "        row_identifier = [dt_type, 'distilled', np.nan, distrib]\n",
    "        \n",
    "        row_values_mean = np.mean(rows_selected_values.astype(np.float64), axis=0)\n",
    "        row_values_std = np.std(rows_selected_values.astype(np.float64), axis=0)\n",
    "\n",
    "        row_values_mean_std = np.dstack([row_values_mean, row_values_std]).flatten()\n",
    "        \n",
    "        row_mean_std = np.hstack([row_identifier, row_values_mean_std])\n",
    "        data.append(row_mean_std)\n",
    "        \n",
    "columns = flatten_list([list(real_world_scores_df_distrib_adjusted.columns[:4]), [ [column + ' Mean', column + ' STD'] for column in real_world_scores_df_distrib_adjusted.columns[4:]]])\n",
    "        \n",
    "real_world_scores_df_distrib_adjusted_mean_std = pd.DataFrame(data=data, columns=columns)\n",
    "real_world_scores_df_distrib_adjusted_mean_std.iloc[:,4:] = np.round(real_world_scores_df_distrib_adjusted_mean_std.iloc[:,4:].values.astype(np.float64), 4)\n",
    "real_world_scores_df_distrib_adjusted_mean_std = real_world_scores_df_distrib_adjusted_mean_std.drop('enumerator', axis=1)\n",
    "#display(real_world_scores_df_distrib_adjusted_mean_std.head(100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cfe191-2488-4b2d-b5c9-0c67643ba787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_latex_table_top(f):\n",
    "    f.write('\\\\begin{table}[htb]' + '\\n')\n",
    "    f.write('\\\\centering' + '\\n')\n",
    "    f.write('\\\\resizebox{\\columnwidth}{!}{' + '\\n')\n",
    "    f.write('%\\\\begin{threeparttable}' + '\\n')\n",
    "\n",
    "    f.write('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' + '\\n')\n",
    "    \n",
    "    \n",
    "def write_latex_table_bottom(f, dt_type):\n",
    "    f.write('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' + '\\n')\n",
    "\n",
    "    f.write('%\\\\begin{tablenotes}' + '\\n')\n",
    "    f.write('%\\\\item[a] \\\\footnotesize' + '\\n')\n",
    "    f.write('%\\\\item[b] \\\\footnotesize' + '\\n')\n",
    "    f.write('%\\\\end{tablenotes}' + '\\n')\n",
    "    f.write('%\\\\end{threeparttable}' + '\\n')\n",
    "    f.write('}' + '\\n')\n",
    "    f.write('\\\\caption{\\\\textbf{Evaluation Results ' + dt_type +'.}}' + '\\n')\n",
    "    f.write('\\\\label{tab:eval-results}' + '\\n')\n",
    "    f.write('\\\\end{table}' + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0585e69-7d6d-41d5-9ac3-ee0d6284a55d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA = real_world_scores_df_distrib_adjusted_mean_std.query('dt_type == \"vanilla1\"')\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA = real_world_scores_df_distrib_adjusted_mean_std_VANILLA.drop('dt_type', axis=1)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA = real_world_scores_df_distrib_adjusted_mean_std_VANILLA.drop('technique', axis=1)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA.index = real_world_scores_df_distrib_adjusted_mean_std_VANILLA['distrib']\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA = real_world_scores_df_distrib_adjusted_mean_std_VANILLA.drop('distrib', axis=1)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA = real_world_scores_df_distrib_adjusted_mean_std_VANILLA.T\n",
    "\n",
    "data = []\n",
    "for i in range(real_world_scores_df_distrib_adjusted_mean_std_VANILLA.shape[0]//2):\n",
    "    row_mean = real_world_scores_df_distrib_adjusted_mean_std_VANILLA.iloc[i*2].values\n",
    "    row_std = real_world_scores_df_distrib_adjusted_mean_std_VANILLA.iloc[i*2+1].values\n",
    "    \n",
    "    row_values_mean_std = np.dstack([row_mean, row_std]).flatten()\n",
    "    data.append(row_values_mean_std)\n",
    "    \n",
    "columns = flatten_list([ [column + ' mean', column + ' std']  for column in real_world_scores_df_distrib_adjusted_mean_std_VANILLA.columns])\n",
    "\n",
    "index = real_world_scores_df_distrib_adjusted.columns[4:]\n",
    "index = [name.replace(' accuracy', '') for name in index]\n",
    "index = [index + ' (n='+  str(real_world_datasets[index]) + ')' for index in index]\n",
    "\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended = pd.DataFrame(data=data, columns=columns, index=index)\n",
    "\n",
    "summary_row = pd.Series(data=np.dstack([np.mean(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.iloc[:,::2].values, axis=0), np.std(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.iloc[:,::2].values, axis=0)]).flatten(), name='Summary', index=real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.columns)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended = real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.append(summary_row)\n",
    "\n",
    "display(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.head(100))\n",
    "\n",
    "\n",
    "######################\n",
    "\n",
    "columns = flatten_list([[column, column]  for column in real_world_scores_df_distrib_adjusted_mean_std_VANILLA.columns])\n",
    "\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex = deepcopy(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.columns = columns\n",
    "#real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.index = index\n",
    "\n",
    "\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex = real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex * 100\n",
    "\n",
    "#combiner = lambda s1, s2: '$' + np.round(s1, 2).astype(str) + ' \\pm ' + np.round(s2, 2).astype(str) + '$'\n",
    "#combiner = lambda s1, s2: '$' + np.round(s1, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: ' ' + x if float(x) < 100 else '  ' + x if float(x) < 10 else x)  + ' \\pm ' + np.round(s2, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: ' ' + x if float(x) < 10 else x) + '$' \n",
    "#combiner = lambda s1, s2: '$' + np.round(s1, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: '\\phantom{0}' + x if float(x) < 100 else '\\phantom{00}' + x if float(x) < 10 else x)  + ' \\pm ' + np.round(s2, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: '\\phantom{0}' + x if float(x) < 10 else x) + '$' \n",
    "combiner = lambda s1, s2: np.round(s1, 2).apply(lambda x: '{:.2f}'.format(x)).astype(str).apply(lambda x: '\\phantom{0}' + x if float(x) < 100 else '\\phantom{00}' + x if float(x) < 10 else x) + ' $\\pm$ ' + np.round(s2, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: '\\phantom{0}' + x if float(x) < 10 else x) \n",
    "\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex = real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.iloc[:,::2].combine(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.iloc[:,1::2], combiner)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex_with_distilled_mean = deepcopy(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex = real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.drop('distilled', axis=1)\n",
    "\n",
    "if number_of_random_evaluations_per_distribution == 0:\n",
    "    for i, row in real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.iterrows():\n",
    "        distrib_mean = {}\n",
    "        for distrib in distribution_list:\n",
    "            distrib_mean[distrib] = float(row[distrib].split(' ')[0].split('}')[-1])\n",
    "        #best_distrib = max(distrib_mean, key=distrib_mean.get)\n",
    "        max_value = max(distrib_mean.values())\n",
    "        best_distrib_key_list = [key for key, value in distrib_mean.items() if value == max_value]\n",
    "\n",
    "        mean_inet = float(row['inet'].split(' ')[0].split('}')[-1])\n",
    "        if mean_inet == max_value:\n",
    "            row['inet'] = '\\\\bftab' + row['inet']\n",
    "            for best_distrib in best_distrib_key_list:\n",
    "                row[best_distrib] = '\\\\bftab' + row[best_distrib]\n",
    "        elif mean_inet > max_value:\n",
    "            row['inet'] = '\\\\bftab' + row['inet']\n",
    "        else:\n",
    "            for best_distrib in best_distrib_key_list:\n",
    "                row[best_distrib] = '\\\\bftab' + row[best_distrib]\n",
    "\n",
    "    for i, row in real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex_with_distilled_mean.iterrows():    \n",
    "        mean_inet = float(row['inet'].split(' ')[0].split('}')[-1])\n",
    "        mean_distilled = float(row['distilled'].split(' ')[0].split('}')[-1])\n",
    "        if mean_inet == mean_distilled:\n",
    "            row['inet'] = '\\\\bftab' + row['inet']\n",
    "            row['distilled'] = '\\\\bftab' + row['distilled']\n",
    "        elif mean_inet > mean_distilled:\n",
    "            row['inet'] = '\\\\bftab' + row['inet']\n",
    "        else:\n",
    "            row['distilled'] = '\\\\bftab' + row['distilled']\n",
    "\n",
    "        distrib_mean = {}\n",
    "        for distrib in distribution_list:\n",
    "            distrib_mean[distrib] = float(row[distrib].split(' ')[0].split('}')[-1])\n",
    "        #best_distrib = max(distrib_mean, key=distrib_mean.get)\n",
    "        max_value = max(distrib_mean.values())\n",
    "        best_distrib_key_list = [key for key, value in distrib_mean.items() if value == max_value]\n",
    "\n",
    "        for best_distrib in best_distrib_key_list:\n",
    "            row[best_distrib] = '\\\\bftab' + row[best_distrib]  \n",
    "else:\n",
    "    threshold = 0.05\n",
    "    \n",
    "    inet_scores = real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.loc[:,'inet mean'].values\n",
    "    distilled_max_scores = np.max(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.iloc[:,::2].iloc[:,2:].values, axis=1)\n",
    "    best_distrib_index_by_dataset = np.argmax(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.iloc[:,::2].iloc[:,2:].values, axis=1)\n",
    "    best_distrib_index_by_dataset = best_distrib_index_by_dataset + 2\n",
    "    best_distrib_name_by_dataset_name = [[dataset_name ,real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.columns[::2][best_distrib_index].split(' ')[0]] for dataset_name, best_distrib_index in zip(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.index, best_distrib_index_by_dataset)][:-1]\n",
    "\n",
    "    ttest_by_dataset_VANILLA = []\n",
    "    for dataset_name, best_distrib_name in best_distrib_name_by_dataset_name:\n",
    "        #print(dataset_name, best_distrib_name)\n",
    "        considered_columns_distilled = real_world_scores_df_distrib_adjusted.query('technique == \"' + 'distilled' + '\"' + '&' + 'dt_type == \"' + 'vanilla1' + '\"' + '&' + 'distrib == \"' + best_distrib_name + '\"')\n",
    "        considered_results_distilled = considered_columns_distilled.loc[:, ' '.join(dataset_name.split(' ')[:-1]) + ' accuracy'].values\n",
    "\n",
    "        considered_column_inet = real_world_scores_df_distrib_adjusted.query('technique == \"' + 'inet' + '\"' + '&' + 'dt_type == \"' + 'vanilla1' + '\"')\n",
    "        considered_result_inet = considered_column_inet.loc[:, ' '.join(dataset_name.split(' ')[:-1]) + ' accuracy'].values[0]\n",
    "\n",
    "        ttest_statistics, ttest_p_value  = scipy.stats.ttest_1samp(considered_results_distilled, considered_result_inet)\n",
    "\n",
    "        identifier_best = 'inet' if considered_result_inet > np.mean(considered_results_distilled) else best_distrib_name\n",
    "\n",
    "        ttest_by_dataset_VANILLA.append([dataset_name, identifier_best, ttest_p_value])\n",
    "\n",
    "    for dataset_name, identifier_best, p_value  in ttest_by_dataset_VANILLA:\n",
    "        if p_value < threshold:\n",
    "            real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.loc[dataset_name, identifier_best] = '\\\\bftab' + real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.loc[dataset_name, identifier_best]\n",
    "\n",
    "            \n",
    "    ttest_by_dataset_VANILLA = []\n",
    "    for dataset_name in real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.index[:-1]:\n",
    "        considered_results_distilled = []\n",
    "        for distrib in distribution_list:\n",
    "            considered_columns_distilled_distrib = real_world_scores_df_distrib_adjusted.query('technique == \"' + 'distilled' + '\"' + '&' + 'dt_type == \"' + 'vanilla1' + '\"' + '&' + 'distrib == \"' + distrib + '\"')\n",
    "            considered_results_distilled_distrib = considered_columns_distilled_distrib.loc[:, ' '.join(dataset_name.split(' ')[:-1]) + ' accuracy'].values\n",
    "            considered_results_distilled.append(considered_results_distilled_distrib)\n",
    "        considered_results_distilled = np.hstack(considered_results_distilled)\n",
    "\n",
    "        considered_column_inet = real_world_scores_df_distrib_adjusted.query('technique == \"' + 'inet' + '\"' + '&' + 'dt_type == \"' + 'vanilla1' + '\"')\n",
    "        considered_result_inet = considered_column_inet.loc[:, ' '.join(dataset_name.split(' ')[:-1]) + ' accuracy'].values[0]    \n",
    "\n",
    "        ttest_statistics, ttest_p_value  = scipy.stats.ttest_1samp(considered_results_distilled, considered_result_inet)\n",
    "\n",
    "        identifier_best = 'inet' if considered_result_inet > np.mean(considered_results_distilled) else 'distilled'\n",
    "\n",
    "        ttest_by_dataset_VANILLA.append([dataset_name, identifier_best, ttest_p_value, ('mean distilled', np.mean(considered_results_distilled)), ('std distilled', np.std(considered_results_distilled))])    \n",
    "\n",
    "    for dataset_name, identifier_best, p_value, mean_distilled, std_distilled in ttest_by_dataset_VANILLA:\n",
    "        if p_value < threshold:\n",
    "            real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex_with_distilled_mean.loc[dataset_name, identifier_best] = '\\\\bftab' + real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex_with_distilled_mean.loc[dataset_name, identifier_best]\n",
    "            \n",
    "    for i, row in real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex_with_distilled_mean.iterrows():    \n",
    "        distrib_mean = {}\n",
    "        for distrib in distribution_list:\n",
    "            distrib_mean[distrib] = float(row[distrib].split(' ')[0].split('}')[-1])\n",
    "        #best_distrib = max(distrib_mean, key=distrib_mean.get)\n",
    "        max_value = max(distrib_mean.values())\n",
    "        best_distrib_key_list = [key for key, value in distrib_mean.items() if value == max_value]\n",
    "\n",
    "        for best_distrib in best_distrib_key_list:\n",
    "            row[best_distrib] = '\\\\bftab' + row[best_distrib] \n",
    "            \n",
    "            \n",
    "\n",
    "with open(\"./evaluation_results/latex_table_vanilla_with_distilled_mean.tex\", \"w\") as f:\n",
    "    write_latex_table_top(f)\n",
    "    f.write(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex_with_distilled_mean.to_latex(index=True, bold_rows=True, escape=False))\n",
    "    write_latex_table_bottom(f, 'vanilla')\n",
    "with open(\"./evaluation_results/latex_table_vanilla.tex\", \"w\") as f:\n",
    "    write_latex_table_top(f)\n",
    "    f.write(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.to_latex(index=True, bold_rows=True, escape=False))\n",
    "    write_latex_table_bottom(f, 'vanilla')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80233296-1321-4d96-80a4-097a912b55cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_world_scores_df_distrib_adjusted_mean_std_SDT = real_world_scores_df_distrib_adjusted_mean_std.query('dt_type == \"SDT-1\"')\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT = real_world_scores_df_distrib_adjusted_mean_std_SDT.drop('dt_type', axis=1)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT = real_world_scores_df_distrib_adjusted_mean_std_SDT.drop('technique', axis=1)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT.index = real_world_scores_df_distrib_adjusted_mean_std_SDT['distrib']\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT = real_world_scores_df_distrib_adjusted_mean_std_SDT.drop('distrib', axis=1)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT = real_world_scores_df_distrib_adjusted_mean_std_SDT.T\n",
    "\n",
    "data = []\n",
    "for i in range(real_world_scores_df_distrib_adjusted_mean_std_SDT.shape[0]//2):\n",
    "    row_mean = real_world_scores_df_distrib_adjusted_mean_std_SDT.iloc[i*2].values\n",
    "    row_std = real_world_scores_df_distrib_adjusted_mean_std_SDT.iloc[i*2+1].values\n",
    "    \n",
    "    row_values_mean_std = np.dstack([row_mean, row_std]).flatten()\n",
    "    data.append(row_values_mean_std)\n",
    "    \n",
    "columns = flatten_list([ [column + ' mean', column + ' std']  for column in real_world_scores_df_distrib_adjusted_mean_std_SDT.columns])\n",
    "\n",
    "index = real_world_scores_df_distrib_adjusted.columns[4:]\n",
    "index = [name.replace(' accuracy', '') for name in index]\n",
    "index = [index + ' (n='+  str(real_world_datasets[index]) + ')' for index in index]\n",
    "\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT_extended = pd.DataFrame(data=data, columns=columns, index=index)\n",
    "\n",
    "summary_row = pd.Series(data=np.dstack([np.mean(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.iloc[:,::2].values, axis=0), np.std(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.iloc[:,::2].values, axis=0)]).flatten(), name='Summary', index=real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.columns)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT_extended = real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.append(summary_row)\n",
    "\n",
    "display(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.head(100))\n",
    "\n",
    "\n",
    "######################\n",
    "\n",
    "columns = flatten_list([[column, column]  for column in real_world_scores_df_distrib_adjusted_mean_std_SDT.columns])\n",
    "\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex = deepcopy(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.columns = columns\n",
    "\n",
    "\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex = real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex * 100\n",
    "\n",
    "#combiner = lambda s1, s2: '$' + np.round(s1, 2).astype(str) + ' \\pm ' + np.round(s2, 2).astype(str) + '$'\n",
    "#combiner = lambda s1, s2: '$' + np.round(s1, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: ' ' + x if float(x) < 100 else '  ' + x if float(x) < 10 else x)  + ' \\pm ' + np.round(s2, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: ' ' + x if float(x) < 10 else x) + '$' \n",
    "#combiner = lambda s1, s2: '$' + np.round(s1, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: '\\phantom{0}' + x if float(x) < 100 else '\\phantom{00}' + x if float(x) < 10 else x)  + ' \\pm ' + np.round(s2, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: '\\phantom{0}' + x if float(x) < 10 else x) + '$' \n",
    "combiner = lambda s1, s2: np.round(s1, 2).apply(lambda x: '{:.2f}'.format(x)).astype(str).apply(lambda x: '\\phantom{0}' + x if float(x) < 100 else '\\phantom{00}' + x if float(x) < 10 else x) + ' $\\pm$ ' + np.round(s2, 2).apply(lambda x: '{:.2f}'.format(x)).apply(lambda x: '\\phantom{0}' + x if float(x) < 10 else x) \n",
    "\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex = real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.iloc[:,::2].combine(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.iloc[:,1::2], combiner)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex_with_distilled_mean = deepcopy(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex)\n",
    "real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex = real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.drop('distilled', axis=1)\n",
    "\n",
    "if number_of_random_evaluations_per_distribution == 0:\n",
    "    for i, row in real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.iterrows():\n",
    "        distrib_mean = {}\n",
    "        for distrib in distribution_list:\n",
    "            distrib_mean[distrib] = float(row[distrib].split(' ')[0].split('}')[-1])\n",
    "        #best_distrib = max(distrib_mean, key=distrib_mean.get)\n",
    "        max_value = max(distrib_mean.values())\n",
    "        best_distrib_key_list = [key for key, value in distrib_mean.items() if value == max_value]\n",
    "\n",
    "        mean_inet = float(row['inet'].split(' ')[0].split('}')[-1])\n",
    "        if mean_inet == max_value:\n",
    "            row['inet'] = '\\\\bftab' + row['inet']\n",
    "            for best_distrib in best_distrib_key_list:\n",
    "                row[best_distrib] = '\\\\bftab' + row[best_distrib]\n",
    "        elif mean_inet > max_value:\n",
    "            row['inet'] = '\\\\bftab' + row['inet']\n",
    "        else:\n",
    "            for best_distrib in best_distrib_key_list:\n",
    "                row[best_distrib] = '\\\\bftab' + row[best_distrib]\n",
    "\n",
    "    for i, row in real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex_with_distilled_mean.iterrows():    \n",
    "        mean_inet = float(row['inet'].split(' ')[0].split('}')[-1])\n",
    "        mean_distilled = float(row['distilled'].split(' ')[0].split('}')[-1])\n",
    "        if mean_inet == mean_distilled:\n",
    "            row['inet'] = '\\\\bftab' + row['inet']\n",
    "            row['distilled'] = '\\\\bftab' + row['distilled']\n",
    "        elif mean_inet > mean_distilled:\n",
    "            row['inet'] = '\\\\bftab' + row['inet']\n",
    "        else:\n",
    "            row['distilled'] = '\\\\bftab' + row['distilled']\n",
    "\n",
    "        distrib_mean = {}\n",
    "        for distrib in distribution_list:\n",
    "            distrib_mean[distrib] = float(row[distrib].split(' ')[0].split('}')[-1])\n",
    "        #best_distrib = max(distrib_mean, key=distrib_mean.get)\n",
    "        max_value = max(distrib_mean.values())\n",
    "        best_distrib_key_list = [key for key, value in distrib_mean.items() if value == max_value]\n",
    "\n",
    "        for best_distrib in best_distrib_key_list:\n",
    "            row[best_distrib] = '\\\\bftab' + row[best_distrib] \n",
    "else:\n",
    "    threshold = 0.05\n",
    "    \n",
    "    inet_scores = real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.loc[:,'inet mean'].values\n",
    "    distilled_max_scores = np.max(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.iloc[:,::2].iloc[:,2:].values, axis=1)\n",
    "    best_distrib_index_by_dataset = np.argmax(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.iloc[:,::2].iloc[:,2:].values, axis=1)\n",
    "    best_distrib_index_by_dataset = best_distrib_index_by_dataset + 2\n",
    "    best_distrib_name_by_dataset_name = [[dataset_name ,real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.columns[::2][best_distrib_index].split(' ')[0]] for dataset_name, best_distrib_index in zip(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.index, best_distrib_index_by_dataset)][:-1]\n",
    "\n",
    "    ttest_by_dataset_SDT = []\n",
    "    for dataset_name, best_distrib_name in best_distrib_name_by_dataset_name:\n",
    "        #print(dataset_name, best_distrib_name)\n",
    "        considered_columns_distilled = real_world_scores_df_distrib_adjusted.query('technique == \"' + 'distilled' + '\"' + '&' + 'dt_type == \"' + 'SDT-1' + '\"' + '&' + 'distrib == \"' + best_distrib_name + '\"')\n",
    "        considered_results_distilled = considered_columns_distilled.loc[:, ' '.join(dataset_name.split(' ')[:-1]) + ' accuracy'].values\n",
    "\n",
    "        considered_column_inet = real_world_scores_df_distrib_adjusted.query('technique == \"' + 'inet' + '\"' + '&' + 'dt_type == \"' + 'SDT-1' + '\"')\n",
    "        considered_result_inet = considered_column_inet.loc[:, ' '.join(dataset_name.split(' ')[:-1]) + ' accuracy'].values[0]\n",
    "\n",
    "        ttest_statistics, ttest_p_value  = scipy.stats.ttest_1samp(considered_results_distilled, considered_result_inet)\n",
    "\n",
    "        identifier_best = 'inet' if considered_result_inet > np.mean(considered_results_distilled) else best_distrib_name\n",
    "\n",
    "        ttest_by_dataset_SDT.append([dataset_name, identifier_best, ttest_p_value])\n",
    "\n",
    "    for dataset_name, identifier_best, p_value  in ttest_by_dataset_SDT:\n",
    "        if p_value < threshold:\n",
    "            real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.loc[dataset_name, identifier_best] = '\\\\bftab' + real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.loc[dataset_name, identifier_best]\n",
    "\n",
    "            \n",
    "    ttest_by_dataset_SDT = []\n",
    "    for dataset_name in real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.index[:-1]:\n",
    "        considered_results_distilled = []\n",
    "        for distrib in distribution_list:\n",
    "            considered_columns_distilled_distrib = real_world_scores_df_distrib_adjusted.query('technique == \"' + 'distilled' + '\"' + '&' + 'dt_type == \"' + 'SDT-1' + '\"' + '&' + 'distrib == \"' + distrib + '\"')\n",
    "            considered_results_distilled_distrib = considered_columns_distilled_distrib.loc[:, ' '.join(dataset_name.split(' ')[:-1]) + ' accuracy'].values\n",
    "            considered_results_distilled.append(considered_results_distilled_distrib)\n",
    "        considered_results_distilled = np.hstack(considered_results_distilled)\n",
    "\n",
    "        considered_column_inet = real_world_scores_df_distrib_adjusted.query('technique == \"' + 'inet' + '\"' + '&' + 'dt_type == \"' + 'SDT-1' + '\"')\n",
    "        considered_result_inet = considered_column_inet.loc[:, ' '.join(dataset_name.split(' ')[:-1]) + ' accuracy'].values[0]    \n",
    "\n",
    "        ttest_statistics, ttest_p_value  = scipy.stats.ttest_1samp(considered_results_distilled, considered_result_inet)\n",
    "\n",
    "        identifier_best = 'inet' if considered_result_inet > np.mean(considered_results_distilled) else 'distilled'\n",
    "\n",
    "        ttest_by_dataset_SDT.append([dataset_name, identifier_best, ttest_p_value, ('mean distilled', np.mean(considered_results_distilled)), ('std distilled', np.std(considered_results_distilled))])    \n",
    "\n",
    "    for dataset_name, identifier_best, p_value, mean_distilled, std_distilled in ttest_by_dataset_SDT:\n",
    "        if p_value < threshold:\n",
    "            real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex_with_distilled_mean.loc[dataset_name, identifier_best] = '\\\\bftab' + real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex_with_distilled_mean.loc[dataset_name, identifier_best]\n",
    "            \n",
    "    for i, row in real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex_with_distilled_mean.iterrows():    \n",
    "        distrib_mean = {}\n",
    "        for distrib in distribution_list:\n",
    "            distrib_mean[distrib] = float(row[distrib].split(' ')[0].split('}')[-1])\n",
    "        #best_distrib = max(distrib_mean, key=distrib_mean.get)\n",
    "        max_value = max(distrib_mean.values())\n",
    "        best_distrib_key_list = [key for key, value in distrib_mean.items() if value == max_value]\n",
    "\n",
    "        for best_distrib in best_distrib_key_list:\n",
    "            row[best_distrib] = '\\\\bftab' + row[best_distrib] \n",
    "\n",
    "with open(\"./evaluation_results/latex_table_sdt_with_distilled_mean.tex\", \"w\") as f:\n",
    "    write_latex_table_top(f)\n",
    "    f.write(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex_with_distilled_mean.to_latex(index=True, bold_rows=True, escape=False))\n",
    "    write_latex_table_bottom(f, 'SDT')\n",
    "    \n",
    "with open(\"./evaluation_results/latex_table_sdt.tex\", \"w\") as f:\n",
    "    write_latex_table_top(f)\n",
    "    f.write(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.to_latex(index=True, bold_rows=True, escape=False))\n",
    "    write_latex_table_bottom(f, 'SDT')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37e645-d563-48f9-8c05-1f6686299d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011ea49-42f9-467e-9ecb-d45d2e01cf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c4a552-3632-483f-beed-84dec0ccf709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./evaluation_results/latex_tables_complete.tex\", \"w\") as f:\n",
    "    f.write('\\\\newpage \\n')\n",
    "    write_latex_table_top(f)\n",
    "    f.write(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex_with_distilled_mean.to_latex(index=True, bold_rows=True, escape=False))\n",
    "    write_latex_table_bottom(f, 'vanilla')\n",
    "\n",
    "    write_latex_table_top(f)\n",
    "    f.write(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex_with_distilled_mean.to_latex(index=True, bold_rows=True, escape=False))\n",
    "    write_latex_table_bottom(f, 'SDT')    \n",
    "    f.write('\\\\newpage \\n')\n",
    "    \n",
    "    write_latex_table_top(f)\n",
    "    f.write(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.to_latex(index=True, bold_rows=True, escape=False))\n",
    "    write_latex_table_bottom(f, 'vanilla')\n",
    "    \n",
    "    write_latex_table_top(f)\n",
    "    f.write(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.to_latex(index=True, bold_rows=True, escape=False))\n",
    "    write_latex_table_bottom(f, 'SDT')\n",
    "    f.write('\\\\newpage \\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783c8a2-ca40-44e0-b60b-89c714e64725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_world_scores_df_distrib_adjusted_plotting = real_world_scores_df_distrib_adjusted.melt(id_vars=[\"dt_type\", \"technique\", \"enumerator\", \"distrib\"], \n",
    "                                                                            var_name=\"score_name\", \n",
    "                                                                            value_name=\"value\")\n",
    "\n",
    "real_world_scores_df_distrib_adjusted_plotting = real_world_scores_df_distrib_adjusted_plotting[real_world_scores_df_distrib_adjusted_plotting['value'].notna()]\n",
    "real_world_scores_df_distrib_adjusted_plotting['distrib'] = pd.Categorical(real_world_scores_df_distrib_adjusted_plotting['distrib'], flatten_list(['inet', distribution_list]))\n",
    "real_world_scores_df_distrib_adjusted_plotting.sort_values('distrib')\n",
    "\n",
    "#real_world_scores_df_distrib_adjusted_plotting.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8b9f6-66bf-4361-9063-72a50d79f352",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81db4dd-0e05-4979-b465-9e12b70e6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.head(100))\n",
    "\n",
    "#display(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex.head(100))\n",
    "#display(real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended_latex_with_distilled_mean.head(100))\n",
    "\n",
    "\n",
    "inet_scores = real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.loc[:,'inet mean']\n",
    "distilled_scores = real_world_scores_df_distrib_adjusted_mean_std_VANILLA_extended.loc[:,'distilled mean']\n",
    "\n",
    "ttest_equal_var = scipy.stats.ttest_ind(inet_scores, distilled_scores)\n",
    "print(ttest_equal_var)\n",
    "\n",
    "ttest = scipy.stats.ttest_ind(inet_scores, distilled_scores, equal_var=False)\n",
    "print(ttest)\n",
    "\n",
    "#ttest_summary, ttest_results = rp.ttest(inet_scores, distilled_scores)\n",
    "#display(ttest_results)\n",
    "#display(ttest_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419dc2e8-6bd1-4a46-bfac-7b46fb2d02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.head(100))\n",
    "\n",
    "#display(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex.head(100))\n",
    "#display(real_world_scores_df_distrib_adjusted_mean_std_SDT_extended_latex_with_distilled_mean.head(100))\n",
    "\n",
    "inet_scores = real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.loc[:,'inet mean']\n",
    "distilled_scores = real_world_scores_df_distrib_adjusted_mean_std_SDT_extended.loc[:,'distilled mean']\n",
    "\n",
    "ttest_equal_var = scipy.stats.ttest_ind(inet_scores, distilled_scores)\n",
    "print(ttest_equal_var)\n",
    "\n",
    "ttest = scipy.stats.ttest_ind(inet_scores, distilled_scores, equal_var=False)\n",
    "print(ttest)\n",
    "\n",
    "#ttest_summary, ttest_results = rp.ttest(inet_scores, distilled_scores)\n",
    "#display(ttest_results)\n",
    "#display(ttest_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cc4a3e-1f58-42d7-98ac-b342974ece0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331c074-cece-44b0-b9cd-f1695f69364f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plot_results(data_reduced=real_world_scores_df_distrib_adjusted_plotting, \n",
    "                    col = 'score_name', \n",
    "                    x = 'dt_type', \n",
    "                    y = 'value', \n",
    "                    hue = 'technique', \n",
    "                    plot_type = sns.barplot, \n",
    "                    aspect = 2.5, \n",
    "                    col_wrap = 3)\n",
    "\n",
    "plt.savefig('./evaluation_results/real_workd_complete_by_technique_barplot.pdf', bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf164e-3fef-430c-bdb8-5abd83fc7000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plot_results(data_reduced=real_world_scores_df_distrib_adjusted_plotting, \n",
    "                    col = 'score_name', \n",
    "                    x = 'dt_type', \n",
    "                    y = 'value', \n",
    "                    hue = 'technique', \n",
    "                    plot_type = sns.boxplot, \n",
    "                    aspect = 2.5, \n",
    "                    col_wrap = 3)\n",
    "\n",
    "plt.savefig('./evaluation_results/real_workd_complete_by_technique_boxplot.pdf', bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebedec2c-526c-4079-9b4e-6be33b8230db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c9afe-48e3-4531-94de-7cb1fbd523bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plot_results(data_reduced=real_world_scores_df_distrib_adjusted_plotting, \n",
    "                    col = 'score_name', \n",
    "                    x = 'dt_type', \n",
    "                    y = 'value', \n",
    "                    hue = 'distrib', \n",
    "                    plot_type = sns.barplot, \n",
    "                    aspect = 2.5, \n",
    "                    col_wrap = 3)\n",
    "\n",
    "plt.savefig('./evaluation_results/real_workd_complete_by_technique_by_distrib_barplot.pdf', bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe60079-11d6-48e4-b121-4ee796058e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plot_results(data_reduced=real_world_scores_df_distrib_adjusted_plotting, \n",
    "                    col = 'score_name', \n",
    "                    x = 'dt_type', \n",
    "                    y = 'value', \n",
    "                    hue = 'distrib', \n",
    "                    plot_type = sns.boxplot, \n",
    "                    aspect = 2.5, \n",
    "                    col_wrap = 3)\n",
    "\n",
    "plt.savefig('./evaluation_results/real_workd_complete_by_technique_by_distrib_boxplot.pdf', bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a58fe-d300-4cfa-9ab9-52abe2c1d221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a35f3-8924-4f2c-848e-c6448e4c9560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b3bd4-b991-439e-a0bb-59db63c8ef31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fda90f-c2e4-4659-984d-70ed3a9cfab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d54a68-ba6b-48b9-acad-0338364c74a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48d242-4f2c-4996-9d1b-f50304eeda87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0464e6e6-9501-46bd-bb78-17da9ea6578f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16625373-f613-4dba-9b59-76307655d0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
