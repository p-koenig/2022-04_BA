{'balanced_data': True, 'data_generation_filtering': False, 'data_reshape_version': None, 'dataset_size': 10000, 'distrib_by_feature': True, 'distrib_param_max': 5, 'distribution_list': ['uniform', 'normal', 'gamma', 'beta', 'poisson'], 'distribution_list_eval': ['uniform', 'normal', 'gamma', 'beta', 'poisson'], 'dt_setting': 1, 'exclude_linearly_seperable': True, 'fixed_class_probability': False, 'force_evaluate_real_world': False, 'function_generation_type': 'distribution', 'inet_setting': 5, 'lambda_network_layers': [128], 'max_distributions_per_class': 1, 'maximum_depth': 3, 'n_jobs': 8, 'noise_injected_level': 0, 'normalize_lambda_nets': False, 'number_of_random_evaluations_per_distribution': 2, 'number_of_variables': 23, 'optimize_sampling': False, 'patience_lambda': 50, 'random_evaluation_dataset_size': 500, 'resampling_strategy': None, 'resampling_threshold': 0.25, 'restore_best_weights': True, 'separate_weight_bias': False, 'shift_distrib': False, 'weighted_data_generation': False, 'dt_type': 'vanilla', 'decision_sparsity': 1, 'function_representation_type': 3, 'dt_type_train': 'vanilla', 'maximum_depth_train': 3, 'decision_sparsity_train': 1, 'dense_layers': [1024, 1024, 256, 2048, 2048], 'dropout': [0, 0, 0, 0, 0.3], 'hidden_activation': 'swish', 'optimizer': 'rmsprop', 'learning_rate': 0.001}
lNetSize5000_numLNets10000_var23_class2_distribution_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_exLinSepun-no-ga-be-po_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1024-1024-256-2048-2048_drop0-0-0-0-0.3e500b256_rmsprop_funcRep3_reshapeNone
lNetSize5000_numLNets10000_var23_class2_distribution_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_exLinSepun-no-ga-be-po_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42
Num GPUs Available:  0
Num XLA-GPUs Available:  0
(9000, 3225)
(1000, 3225)
----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------
network_parameters_structure [(23, 128), (128,), (128, 1), (1,)]
Epoch 1/500
36/36 - 51s - loss: 1.8253 - binary_accuracy_inet_decision_function_fv_metric: 0.5000 - val_loss: 0.7045 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5008 - 51s/epoch - 1s/step
Epoch 2/500
36/36 - 16s - loss: 0.7341 - binary_accuracy_inet_decision_function_fv_metric: 0.5032 - val_loss: 0.9492 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4925 - 16s/epoch - 445ms/step
Epoch 3/500
36/36 - 15s - loss: 0.7160 - binary_accuracy_inet_decision_function_fv_metric: 0.5070 - val_loss: 0.6970 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5080 - 15s/epoch - 422ms/step
Epoch 4/500
36/36 - 15s - loss: 0.7182 - binary_accuracy_inet_decision_function_fv_metric: 0.5085 - val_loss: 0.6930 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5223 - 15s/epoch - 423ms/step
Epoch 5/500
36/36 - 15s - loss: 0.6948 - binary_accuracy_inet_decision_function_fv_metric: 0.5084 - val_loss: 0.7052 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5040 - 15s/epoch - 411ms/step
Epoch 6/500
36/36 - 15s - loss: 0.7606 - binary_accuracy_inet_decision_function_fv_metric: 0.5099 - val_loss: 0.6958 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5141 - 15s/epoch - 426ms/step
Epoch 7/500
36/36 - 14s - loss: 0.6938 - binary_accuracy_inet_decision_function_fv_metric: 0.5143 - val_loss: 0.7073 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5091 - 14s/epoch - 397ms/step
Epoch 8/500
