{'balanced_data': True, 'data_generation_filtering': False, 'data_reshape_version': None, 'dataset_size': 10000, 'distrib_by_feature': True, 'distrib_param_max': 5, 'distribution_list': ['uniform', 'normal', 'gamma', 'beta', 'poisson'], 'distribution_list_eval': ['uniform', 'normal', 'gamma', 'beta', 'poisson'], 'dt_setting': 3, 'exclude_linearly_seperable': True, 'fixed_class_probability': False, 'force_evaluate_real_world': False, 'function_generation_type': 'distribution', 'inet_setting': 3, 'lambda_network_layers': [128], 'max_distributions_per_class': 1, 'maximum_depth': 3, 'n_jobs': 8, 'noise_injected_level': 0, 'normalize_lambda_nets': False, 'number_of_random_evaluations_per_distribution': 10, 'number_of_variables': 3, 'optimize_sampling': False, 'patience_lambda': 50, 'random_evaluation_dataset_size': 500, 'resampling_strategy': None, 'resampling_threshold': 0.2, 'restore_best_weights': True, 'separate_weight_bias': False, 'shift_distrib': False, 'weighted_data_generation': False, 'dt_type': 'SDT', 'decision_sparsity': -1, 'function_representation_type': 1, 'dt_type_train': 'vanilla', 'maximum_depth_train': 3, 'decision_sparsity_train': 1, 'dense_layers': [1792, 512, 512], 'dropout': [0, 0, 0.5], 'hidden_activation': 'swish', 'optimizer': 'adam', 'learning_rate': 0.001}
lNetSize5000_numLNets10000_var3_class2_distribution_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_exLinSepun-no-ga-be-po_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1792-512-512_drop0-0-0.5e500b256_adam_funcRep1_reshapeNone
lNetSize5000_numLNets10000_var3_class2_distribution_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_exLinSepun-no-ga-be-po_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42
Num GPUs Available:  0
Num XLA-GPUs Available:  0
(9000, 687)
(1000, 687)
----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------
network_parameters_structure [(3, 128), (128,), (128, 1), (1,)]
Epoch 1/500
36/36 - 13s - loss: 0.6769 - binary_accuracy_inet_decision_function_fv_metric: 0.5738 - val_loss: 0.6426 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6256 - 13s/epoch - 373ms/step
Epoch 2/500
36/36 - 5s - loss: 0.6055 - binary_accuracy_inet_decision_function_fv_metric: 0.6561 - val_loss: 0.5182 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7406 - 5s/epoch - 145ms/step
Epoch 3/500
36/36 - 6s - loss: 0.5349 - binary_accuracy_inet_decision_function_fv_metric: 0.7312 - val_loss: 0.4480 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7886 - 6s/epoch - 154ms/step
Epoch 4/500
36/36 - 5s - loss: 0.4643 - binary_accuracy_inet_decision_function_fv_metric: 0.7858 - val_loss: 0.3857 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8346 - 5s/epoch - 147ms/step
Epoch 5/500
36/36 - 5s - loss: 0.4133 - binary_accuracy_inet_decision_function_fv_metric: 0.8191 - val_loss: 0.3607 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8486 - 5s/epoch - 130ms/step
Epoch 6/500
