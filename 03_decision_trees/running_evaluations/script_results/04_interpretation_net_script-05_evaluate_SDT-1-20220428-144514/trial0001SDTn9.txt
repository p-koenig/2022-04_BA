{'balanced_data': True, 'data_generation_filtering': False, 'data_reshape_version': None, 'dataset_size': 10000, 'distrib_by_feature': True, 'distrib_param_max': 5, 'distribution_list': ['uniform', 'normal', 'gamma', 'beta', 'poisson'], 'distribution_list_eval': ['uniform', 'normal', 'gamma', 'beta', 'poisson'], 'dt_setting': 3, 'exclude_linearly_seperable': True, 'fixed_class_probability': False, 'force_evaluate_real_world': False, 'function_generation_type': 'distribution', 'inet_setting': 3, 'lambda_network_layers': [128], 'max_distributions_per_class': 1, 'maximum_depth': 3, 'n_jobs': 8, 'noise_injected_level': 0, 'normalize_lambda_nets': False, 'number_of_random_evaluations_per_distribution': 10, 'number_of_variables': 9, 'optimize_sampling': False, 'patience_lambda': 50, 'random_evaluation_dataset_size': 500, 'resampling_strategy': None, 'resampling_threshold': 0.2, 'restore_best_weights': True, 'separate_weight_bias': False, 'shift_distrib': False, 'weighted_data_generation': False, 'dt_type': 'SDT', 'decision_sparsity': -1, 'function_representation_type': 1, 'dt_type_train': 'vanilla', 'maximum_depth_train': 3, 'decision_sparsity_train': 1, 'dense_layers': [1792, 512, 512], 'dropout': [0, 0, 0.5], 'hidden_activation': 'swish', 'optimizer': 'adam', 'learning_rate': 0.001}
lNetSize5000_numLNets10000_var9_class2_distribution_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_exLinSepun-no-ga-be-po_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1792-512-512_drop0-0-0.5e500b256_adam_funcRep1_reshapeNone
lNetSize5000_numLNets10000_var9_class2_distribution_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb_exLinSepun-no-ga-be-po_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.001_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42
Num GPUs Available:  0
Num XLA-GPUs Available:  0
(9000, 1497)
(1000, 1497)
----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------
network_parameters_structure [(9, 128), (128,), (128, 1), (1,)]
Epoch 1/500
36/36 - 12s - loss: 0.6838 - binary_accuracy_inet_decision_function_fv_metric: 0.5496 - val_loss: 0.6115 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6885 - 12s/epoch - 337ms/step
Epoch 2/500
36/36 - 5s - loss: 0.5828 - binary_accuracy_inet_decision_function_fv_metric: 0.7025 - val_loss: 0.4544 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8086 - 5s/epoch - 146ms/step
Epoch 3/500
36/36 - 7s - loss: 0.4679 - binary_accuracy_inet_decision_function_fv_metric: 0.7925 - val_loss: 0.3926 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8364 - 7s/epoch - 181ms/step
Epoch 4/500
36/36 - 7s - loss: 0.4353 - binary_accuracy_inet_decision_function_fv_metric: 0.8145 - val_loss: 0.3666 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8512 - 7s/epoch - 181ms/step
Epoch 5/500
36/36 - 6s - loss: 0.4112 - binary_accuracy_inet_decision_function_fv_metric: 0.8273 - val_loss: 0.3929 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8458 - 6s/epoch - 155ms/step
Epoch 6/500
