{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:01.987351Z",
     "iopub.status.busy": "2022-01-03T14:42:01.986541Z",
     "iopub.status.idle": "2022-01-03T14:42:02.028427Z",
     "shell.execute_reply": "2022-01-03T14:42:02.027183Z",
     "shell.execute_reply.started": "2022-01-03T14:42:01.987186Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 4,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'SDT', #'SDT', 'vanilla'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 9, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [0,1,2,3],\n",
    "        \n",
    "        'dt_type_train': 'vanilla', # (None, 'vanilla', 'SDT')\n",
    "        'maximum_depth_train': 5, #None or int\n",
    "        'decision_sparsity_train': 1, #None or int\n",
    "        \n",
    "        'function_generation_type': 'make_classification_trained',# 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [1024, 1024, 256, 2048, 2048],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.0001,\n",
    "        'loss': 'binary_crossentropy', #mse; soft_mse; binary_crossentropy; soft_binary_crossentropy; 'binary_accuracy'\n",
    "        'metrics': ['soft_binary_crossentropy', 'binary_accuracy'],\n",
    "        \n",
    "        'epochs': 500, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 10000,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 3, # 1=standard representation; 2=sparse representation with classification for variables; 3=softmax to select classes (n top probabilities)\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "        'soft_labels': False,\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2,3) #3=autoencoder dimensionality reduction\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 100,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': False,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "            \n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 7,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:02.030128Z",
     "iopub.status.busy": "2022-01-03T14:42:02.029816Z",
     "iopub.status.idle": "2022-01-03T14:42:02.037675Z",
     "shell.execute_reply": "2022-01-03T14:42:02.036618Z",
     "shell.execute_reply.started": "2022-01-03T14:42:02.030087Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:02.040834Z",
     "iopub.status.busy": "2022-01-03T14:42:02.040472Z",
     "iopub.status.idle": "2022-01-03T14:42:06.798331Z",
     "shell.execute_reply": "2022-01-03T14:42:06.797551Z",
     "shell.execute_reply.started": "2022-01-03T14:42:02.040782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:06.799608Z",
     "iopub.status.busy": "2022-01-03T14:42:06.799388Z",
     "iopub.status.idle": "2022-01-03T14:42:06.806998Z",
     "shell.execute_reply": "2022-01-03T14:42:06.806348Z",
     "shell.execute_reply.started": "2022-01-03T14:42:06.799579Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:06.808309Z",
     "iopub.status.busy": "2022-01-03T14:42:06.808016Z",
     "iopub.status.idle": "2022-01-03T14:42:06.826261Z",
     "shell.execute_reply": "2022-01-03T14:42:06.825607Z",
     "shell.execute_reply.started": "2022-01-03T14:42:06.808281Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:06.827468Z",
     "iopub.status.busy": "2022-01-03T14:42:06.827256Z",
     "iopub.status.idle": "2022-01-03T14:42:06.840668Z",
     "shell.execute_reply": "2022-01-03T14:42:06.839842Z",
     "shell.execute_reply.started": "2022-01-03T14:42:06.827441Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:06.842166Z",
     "iopub.status.busy": "2022-01-03T14:42:06.841923Z",
     "iopub.status.idle": "2022-01-03T14:42:11.841609Z",
     "shell.execute_reply": "2022-01-03T14:42:11.840511Z",
     "shell.execute_reply.started": "2022-01-03T14:42:06.842135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth)  if function_representation_type == 3 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 3 and dt_type == 'SDT'\n",
    "  else None\n",
    "                                                            )\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:11.843638Z",
     "iopub.status.busy": "2022-01-03T14:42:11.843300Z",
     "iopub.status.idle": "2022-01-03T14:42:11.849091Z",
     "shell.execute_reply": "2022-01-03T14:42:11.848327Z",
     "shell.execute_reply.started": "2022-01-03T14:42:11.843600Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets10000_var9_class2_make_classification_trained_xMax1_xMin0_xDistuniform_cat0-1-2-3_depth5_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1024-1024-256-2048-2048_drop0.3-0.3-0.3-0.3-0.3e500b256_adam\n",
      "lNetSize5000_numLNets10000_var9_class2_make_classification_trained_xMax1_xMin0_xDistuniform_cat0-1-2-3_depth5_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:11.850511Z",
     "iopub.status.busy": "2022-01-03T14:42:11.850194Z",
     "iopub.status.idle": "2022-01-03T14:42:11.866606Z",
     "shell.execute_reply": "2022-01-03T14:42:11.865677Z",
     "shell.execute_reply.started": "2022-01-03T14:42:11.850479Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:11.872471Z",
     "iopub.status.busy": "2022-01-03T14:42:11.872022Z",
     "iopub.status.idle": "2022-01-03T14:42:11.885627Z",
     "shell.execute_reply": "2022-01-03T14:42:11.884527Z",
     "shell.execute_reply.started": "2022-01-03T14:42:11.872431Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "       \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              config) for network_parameters_row in network_parameters.values)          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    #def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "    #    lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "    \n",
    "    #def initialize_target_function_wrapper(config, lambda_net):\n",
    "    #    lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:11.887533Z",
     "iopub.status.busy": "2022-01-03T14:42:11.887079Z",
     "iopub.status.idle": "2022-01-03T14:42:28.086703Z",
     "shell.execute_reply": "2022-01-03T14:42:28.085682Z",
     "shell.execute_reply.started": "2022-01-03T14:42:11.887489Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=7)]: Done 1038 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=7)]: Done 9955 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=7)]: Done 10000 out of 10000 | elapsed:   10.5s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "    if False:\n",
    "        lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "    else:\n",
    "        lambda_net_dataset_train_with_valid = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        _, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)   \n",
    "        \n",
    "        \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:28.088776Z",
     "iopub.status.busy": "2022-01-03T14:42:28.088204Z",
     "iopub.status.idle": "2022-01-03T14:42:28.094168Z",
     "shell.execute_reply": "2022-01-03T14:42:28.093491Z",
     "shell.execute_reply.started": "2022-01-03T14:42:28.088741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8955, 1593)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:28.095745Z",
     "iopub.status.busy": "2022-01-03T14:42:28.095405Z",
     "iopub.status.idle": "2022-01-03T14:42:28.103428Z",
     "shell.execute_reply": "2022-01-03T14:42:28.102775Z",
     "shell.execute_reply.started": "2022-01-03T14:42:28.095713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 1593)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:28.105170Z",
     "iopub.status.busy": "2022-01-03T14:42:28.104615Z",
     "iopub.status.idle": "2022-01-03T14:42:28.110245Z",
     "shell.execute_reply": "2022-01-03T14:42:28.109538Z",
     "shell.execute_reply.started": "2022-01-03T14:42:28.105130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1593)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:28.112033Z",
     "iopub.status.busy": "2022-01-03T14:42:28.111518Z",
     "iopub.status.idle": "2022-01-03T14:42:35.341442Z",
     "shell.execute_reply": "2022-01-03T14:42:35.340680Z",
     "shell.execute_reply.started": "2022-01-03T14:42:28.111993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>f6v8</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f7v5</th>\n",
       "      <th>f7v6</th>\n",
       "      <th>f7v7</th>\n",
       "      <th>f7v8</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f8v5</th>\n",
       "      <th>f8v6</th>\n",
       "      <th>f8v7</th>\n",
       "      <th>f8v8</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f9v5</th>\n",
       "      <th>f9v6</th>\n",
       "      <th>f9v7</th>\n",
       "      <th>f9v8</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f10v5</th>\n",
       "      <th>f10v6</th>\n",
       "      <th>f10v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1309</th>\n",
       "      <th>wb_1310</th>\n",
       "      <th>wb_1311</th>\n",
       "      <th>wb_1312</th>\n",
       "      <th>wb_1313</th>\n",
       "      <th>wb_1314</th>\n",
       "      <th>wb_1315</th>\n",
       "      <th>wb_1316</th>\n",
       "      <th>wb_1317</th>\n",
       "      <th>wb_1318</th>\n",
       "      <th>wb_1319</th>\n",
       "      <th>wb_1320</th>\n",
       "      <th>wb_1321</th>\n",
       "      <th>wb_1322</th>\n",
       "      <th>wb_1323</th>\n",
       "      <th>wb_1324</th>\n",
       "      <th>wb_1325</th>\n",
       "      <th>wb_1326</th>\n",
       "      <th>wb_1327</th>\n",
       "      <th>wb_1328</th>\n",
       "      <th>wb_1329</th>\n",
       "      <th>wb_1330</th>\n",
       "      <th>wb_1331</th>\n",
       "      <th>wb_1332</th>\n",
       "      <th>wb_1333</th>\n",
       "      <th>wb_1334</th>\n",
       "      <th>wb_1335</th>\n",
       "      <th>wb_1336</th>\n",
       "      <th>wb_1337</th>\n",
       "      <th>wb_1338</th>\n",
       "      <th>wb_1339</th>\n",
       "      <th>wb_1340</th>\n",
       "      <th>wb_1341</th>\n",
       "      <th>wb_1342</th>\n",
       "      <th>wb_1343</th>\n",
       "      <th>wb_1344</th>\n",
       "      <th>wb_1345</th>\n",
       "      <th>wb_1346</th>\n",
       "      <th>wb_1347</th>\n",
       "      <th>wb_1348</th>\n",
       "      <th>wb_1349</th>\n",
       "      <th>wb_1350</th>\n",
       "      <th>wb_1351</th>\n",
       "      <th>wb_1352</th>\n",
       "      <th>wb_1353</th>\n",
       "      <th>wb_1354</th>\n",
       "      <th>wb_1355</th>\n",
       "      <th>wb_1356</th>\n",
       "      <th>wb_1357</th>\n",
       "      <th>wb_1358</th>\n",
       "      <th>wb_1359</th>\n",
       "      <th>wb_1360</th>\n",
       "      <th>wb_1361</th>\n",
       "      <th>wb_1362</th>\n",
       "      <th>wb_1363</th>\n",
       "      <th>wb_1364</th>\n",
       "      <th>wb_1365</th>\n",
       "      <th>wb_1366</th>\n",
       "      <th>wb_1367</th>\n",
       "      <th>wb_1368</th>\n",
       "      <th>wb_1369</th>\n",
       "      <th>wb_1370</th>\n",
       "      <th>wb_1371</th>\n",
       "      <th>wb_1372</th>\n",
       "      <th>wb_1373</th>\n",
       "      <th>wb_1374</th>\n",
       "      <th>wb_1375</th>\n",
       "      <th>wb_1376</th>\n",
       "      <th>wb_1377</th>\n",
       "      <th>wb_1378</th>\n",
       "      <th>wb_1379</th>\n",
       "      <th>wb_1380</th>\n",
       "      <th>wb_1381</th>\n",
       "      <th>wb_1382</th>\n",
       "      <th>wb_1383</th>\n",
       "      <th>wb_1384</th>\n",
       "      <th>wb_1385</th>\n",
       "      <th>wb_1386</th>\n",
       "      <th>wb_1387</th>\n",
       "      <th>wb_1388</th>\n",
       "      <th>wb_1389</th>\n",
       "      <th>wb_1390</th>\n",
       "      <th>wb_1391</th>\n",
       "      <th>wb_1392</th>\n",
       "      <th>wb_1393</th>\n",
       "      <th>wb_1394</th>\n",
       "      <th>wb_1395</th>\n",
       "      <th>wb_1396</th>\n",
       "      <th>wb_1397</th>\n",
       "      <th>wb_1398</th>\n",
       "      <th>wb_1399</th>\n",
       "      <th>wb_1400</th>\n",
       "      <th>wb_1401</th>\n",
       "      <th>wb_1402</th>\n",
       "      <th>wb_1403</th>\n",
       "      <th>wb_1404</th>\n",
       "      <th>wb_1405</th>\n",
       "      <th>wb_1406</th>\n",
       "      <th>wb_1407</th>\n",
       "      <th>wb_1408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>6671.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.369</td>\n",
       "      <td>-0.694</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.468</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.731</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.502</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.555</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.704</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.382</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.379</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>3274.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1.159</td>\n",
       "      <td>-2.786</td>\n",
       "      <td>1.094</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.756</td>\n",
       "      <td>-1.076</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.729</td>\n",
       "      <td>1.268</td>\n",
       "      <td>1.209</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-2.008</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>1.110</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.483</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-1.326</td>\n",
       "      <td>-1.201</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-3.270</td>\n",
       "      <td>0.994</td>\n",
       "      <td>-0.907</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.053</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>1.113</td>\n",
       "      <td>1.169</td>\n",
       "      <td>0.890</td>\n",
       "      <td>-1.160</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-1.562</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.967</td>\n",
       "      <td>1.419</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-2.860</td>\n",
       "      <td>-2.403</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.490</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-3.115</td>\n",
       "      <td>0.932</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.305</td>\n",
       "      <td>-0.629</td>\n",
       "      <td>-1.420</td>\n",
       "      <td>0.019</td>\n",
       "      <td>1.942</td>\n",
       "      <td>1.076</td>\n",
       "      <td>-2.008</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-2.218</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>-1.966</td>\n",
       "      <td>-2.941</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-1.047</td>\n",
       "      <td>-1.239</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.597</td>\n",
       "      <td>1.073</td>\n",
       "      <td>-1.138</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-1.152</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.965</td>\n",
       "      <td>2.703</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.327</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-1.051</td>\n",
       "      <td>-1.590</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>3095.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.288</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>1.986</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.679</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>1.507</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.303</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.339</td>\n",
       "      <td>-2.448</td>\n",
       "      <td>1.912</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-2.943</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-2.286</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-2.718</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>2.477</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.955</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-2.530</td>\n",
       "      <td>0.477</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>0.134</td>\n",
       "      <td>1.335</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-1.283</td>\n",
       "      <td>-1.216</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.100</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-2.129</td>\n",
       "      <td>-1.120</td>\n",
       "      <td>3.027</td>\n",
       "      <td>2.566</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-4.369</td>\n",
       "      <td>2.063</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-2.771</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>0.275</td>\n",
       "      <td>2.475</td>\n",
       "      <td>0.594</td>\n",
       "      <td>-0.547</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-2.528</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-3.747</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.276</td>\n",
       "      <td>1.428</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-2.702</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>2.101</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-3.282</td>\n",
       "      <td>-2.729</td>\n",
       "      <td>2.224</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.443</td>\n",
       "      <td>2.127</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>-2.950</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.473</td>\n",
       "      <td>-1.521</td>\n",
       "      <td>-0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>8379.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.327</td>\n",
       "      <td>2.072</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.451</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-1.650</td>\n",
       "      <td>0.035</td>\n",
       "      <td>1.122</td>\n",
       "      <td>1.021</td>\n",
       "      <td>1.116</td>\n",
       "      <td>0.682</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-1.823</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>1.263</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.116</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-4.135</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-3.832</td>\n",
       "      <td>-3.341</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.780</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>1.085</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>0.922</td>\n",
       "      <td>1.215</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-1.117</td>\n",
       "      <td>-4.531</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-4.519</td>\n",
       "      <td>2.847</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-1.186</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-3.261</td>\n",
       "      <td>-3.094</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.665</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-1.151</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-1.789</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-4.243</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.757</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.633</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.315</td>\n",
       "      <td>1.055</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.390</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>1.139</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>1.321</td>\n",
       "      <td>0.995</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>3043.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.238</td>\n",
       "      <td>2.101</td>\n",
       "      <td>0.766</td>\n",
       "      <td>-1.209</td>\n",
       "      <td>1.356</td>\n",
       "      <td>1.615</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.619</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.370</td>\n",
       "      <td>1.141</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-1.342</td>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>2.996</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>1.471</td>\n",
       "      <td>0.623</td>\n",
       "      <td>1.378</td>\n",
       "      <td>-1.681</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.634</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-1.335</td>\n",
       "      <td>0.626</td>\n",
       "      <td>1.640</td>\n",
       "      <td>-1.694</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>2.076</td>\n",
       "      <td>0.303</td>\n",
       "      <td>1.639</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.840</td>\n",
       "      <td>0.778</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>-1.789</td>\n",
       "      <td>-1.308</td>\n",
       "      <td>1.001</td>\n",
       "      <td>-1.011</td>\n",
       "      <td>-1.084</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-1.249</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>1.308</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-1.373</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-1.313</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-1.059</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-1.461</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.891</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.441</td>\n",
       "      <td>2.306</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-1.575</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-1.195</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "6671 6671.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 3274.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 3095.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 8379.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 3043.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f2v0  f2v1  f2v2  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f3v0  f3v1  f3v2  f3v3  f3v4  f3v5  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f3v6  f3v7  f3v8  f4v0  f4v1  f4v2  f4v3  f4v4  f4v5  f4v6  f4v7  f4v8  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f5v0  f5v1  f5v2  f5v3  f5v4  f5v5  f5v6  f5v7  f5v8  f6v0  f6v1  f6v2  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f6v3  f6v4  f6v5  f6v6  f6v7  f6v8  f7v0  f7v1  f7v2  f7v3  f7v4  f7v5  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f7v6  f7v7  f7v8  f8v0  f8v1  f8v2  f8v3  f8v4  f8v5  f8v6  f8v7  f8v8  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f9v0  f9v1  f9v2  f9v3  f9v4  f9v5  f9v6  f9v7  f9v8  f10v0  f10v1  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "\n",
       "      f10v2  f10v3  f10v4  f10v5  f10v6  f10v7  ...  wb_1309  wb_1310  \\\n",
       "6671  0.000  0.000  0.000  0.000  0.000  0.000  ...   -0.518   -0.085   \n",
       "3274  0.000  0.000  0.000  0.000  0.000  0.000  ...    0.397   -0.085   \n",
       "3095  0.000  0.000  0.000  0.000  0.000  0.000  ...    2.288   -0.085   \n",
       "8379  0.000  0.000  0.000  0.000  0.000  0.000  ...    1.051   -0.085   \n",
       "3043  0.000  0.000  0.000  0.000  0.000  0.000  ...    0.271   -0.085   \n",
       "\n",
       "      wb_1311  wb_1312  wb_1313  wb_1314  wb_1315  wb_1316  wb_1317  wb_1318  \\\n",
       "6671    0.151    0.430    0.369   -0.694    0.054    0.473    0.461    0.468   \n",
       "3274    0.769    0.423    1.159   -2.786    1.094    0.293    0.192    0.756   \n",
       "3095    1.986    0.158    0.219   -0.054    0.056    0.718    0.444    0.679   \n",
       "8379    0.327    2.072    0.143   -1.035    0.846    1.451    0.184    0.124   \n",
       "3043    0.238    2.101    0.766   -1.209    1.356    1.615    0.588    0.619   \n",
       "\n",
       "      wb_1319  wb_1320  wb_1321  wb_1322  wb_1323  wb_1324  wb_1325  wb_1326  \\\n",
       "6671   -0.388   -0.210    0.407    0.575    0.107    0.511    0.106    0.190   \n",
       "3274   -1.076    0.575    0.729    1.268    1.209    0.476    0.867    0.081   \n",
       "3095   -0.167    0.654    0.048    0.112    0.103    1.507    0.110    0.303   \n",
       "8379   -1.650    0.035    1.122    1.021    1.116    0.682    1.026    0.380   \n",
       "3043   -0.155    0.497    0.484    0.571    0.909    0.370    1.141    0.656   \n",
       "\n",
       "      wb_1327  wb_1328  wb_1329  wb_1330  wb_1331  wb_1332  wb_1333  wb_1334  \\\n",
       "6671   -0.731    0.550   -0.649    0.502   -0.133   -0.603   -0.113   -0.272   \n",
       "3274   -2.008    1.266   -0.177    1.110   -0.133   -1.483   -0.113   -0.475   \n",
       "3095   -0.170    0.339   -2.448    1.912   -0.133   -2.943   -0.113   -2.286   \n",
       "8379   -1.823    0.712   -0.180    1.263   -0.133   -1.116   -0.113   -4.135   \n",
       "3043   -1.342    0.590   -0.182    2.996   -0.133   -0.333   -0.113    1.471   \n",
       "\n",
       "      wb_1335  wb_1336  wb_1337  wb_1338  wb_1339  wb_1340  wb_1341  wb_1342  \\\n",
       "6671    0.402    0.364   -0.763   -0.558    0.367   -0.069    0.407   -0.410   \n",
       "3274    0.735    0.061   -1.326   -1.201    0.109   -3.270    0.994   -0.907   \n",
       "3095    0.602    0.296   -2.718   -0.458    2.477   -0.070    0.193   -0.266   \n",
       "8379    0.922    0.154   -3.832   -3.341    0.823   -0.059    0.780   -0.179   \n",
       "3043    0.623    1.378   -1.681   -0.156    0.634   -1.068    0.209   -1.335   \n",
       "\n",
       "      wb_1343  wb_1344  wb_1345  wb_1346  wb_1347  wb_1348  wb_1349  wb_1350  \\\n",
       "6671    0.523    0.478   -0.125    0.376    0.308   -0.376   -0.107   -0.091   \n",
       "3274    0.179    1.053   -0.122    0.823    0.368   -0.912   -0.107    1.113   \n",
       "3095    0.955   -0.474   -2.530    0.477   -0.361   -0.148   -0.107   -0.336   \n",
       "8379    1.044    0.633   -0.108    1.085    0.407   -0.146   -0.107   -0.156   \n",
       "3043    0.626    1.640   -1.694   -0.974   -0.753   -0.357   -0.107    2.076   \n",
       "\n",
       "      wb_1351  wb_1352  wb_1353  wb_1354  wb_1355  wb_1356  wb_1357  wb_1358  \\\n",
       "6671    0.457    0.455   -0.305   -0.307   -0.034    0.086    0.486    0.555   \n",
       "3274    1.169    0.890   -1.160   -0.223   -1.562    1.034    0.967    1.419   \n",
       "3095    0.134    1.335   -0.051   -0.085   -1.283   -1.216    0.005    2.100   \n",
       "8379    0.588    0.640   -0.193   -0.106   -0.363    0.922    1.215    1.048   \n",
       "3043    0.303    1.639   -0.899   -0.186   -0.261   -0.272    1.840    0.778   \n",
       "\n",
       "      wb_1359  wb_1360  wb_1361  wb_1362  wb_1363  wb_1364  wb_1365  wb_1366  \\\n",
       "6671   -0.145   -0.205   -0.384   -0.432    0.480    0.410   -0.375   -0.704   \n",
       "3274   -0.130    0.217   -2.860   -2.403    0.450    0.490   -0.678   -3.115   \n",
       "3095   -0.140   -0.290   -2.129   -1.120    3.027    2.566   -0.230   -4.369   \n",
       "8379   -0.132   -1.117   -4.531   -0.192    0.068    0.789   -0.212   -4.519   \n",
       "3043   -0.458   -0.297   -1.789   -1.308    1.001   -1.011   -1.084   -0.152   \n",
       "\n",
       "      wb_1367  wb_1368  wb_1369  wb_1370  wb_1371  wb_1372  wb_1373  wb_1374  \\\n",
       "6671    0.435   -0.192   -0.423    0.444   -0.464   -0.073    0.111    0.557   \n",
       "3274    0.932   -0.084    0.344    0.305   -0.629   -1.420    0.019    1.942   \n",
       "3095    2.063   -0.056    1.306    0.287   -2.771   -0.377    0.275    2.475   \n",
       "8379    2.847   -0.134   -1.186    0.101   -3.261   -3.094    0.137    0.553   \n",
       "3043   -0.481   -0.230    0.747    0.240   -1.249   -0.473   -0.149    1.308   \n",
       "\n",
       "      wb_1375  wb_1376  wb_1377  wb_1378  wb_1379  wb_1380  wb_1381  wb_1382  \\\n",
       "6671    0.382   -0.140    0.515    0.379   -0.372   -0.399   -0.741   -0.498   \n",
       "3274    1.076   -2.008    0.681    0.250   -2.218   -1.068   -1.966   -2.941   \n",
       "3095    0.594   -0.547    0.389    0.376   -2.528   -0.168   -0.858   -3.747   \n",
       "8379    0.665   -0.038    0.286    0.152   -1.151   -0.817   -0.187   -1.789   \n",
       "3043   -0.341   -1.373    0.213    0.024   -0.436   -1.313   -0.192   -1.059   \n",
       "\n",
       "      wb_1383  wb_1384  wb_1385  wb_1386  wb_1387  wb_1388  wb_1389  wb_1390  \\\n",
       "6671   -0.106    0.405    0.434    0.363    0.063   -0.505   -0.029    0.067   \n",
       "3274   -0.106    0.107    0.749    0.697    0.071   -1.047   -1.239    0.067   \n",
       "3095   -0.106    0.276    1.428    0.077    0.053   -2.702   -2.500    0.067   \n",
       "8379   -0.106    0.179    0.493    0.980    0.176   -4.243   -0.025    0.067   \n",
       "3043   -0.106    0.253    0.044    0.618    0.514   -1.461   -0.044    0.067   \n",
       "\n",
       "      wb_1391  wb_1392  wb_1393  wb_1394  wb_1395  wb_1396  wb_1397  wb_1398  \\\n",
       "6671   -0.358    0.344    0.102   -0.265   -0.198   -0.306    0.474    0.440   \n",
       "3274   -0.017    0.597    1.073   -1.138   -0.196   -1.152    0.698    0.965   \n",
       "3095   -0.277   -0.352    2.101   -0.199   -3.282   -2.729    2.224    0.067   \n",
       "8379   -0.757    0.608    0.307   -0.030   -0.192   -0.633    0.816    1.315   \n",
       "3043   -0.329   -0.225    0.891   -0.228   -0.189   -0.086    0.342    0.441   \n",
       "\n",
       "      wb_1399  wb_1400  wb_1401  wb_1402  wb_1403  wb_1404  wb_1405  wb_1406  \\\n",
       "6671    0.511    0.312    0.094   -0.211    0.434   -0.554    0.502    0.404   \n",
       "3274    2.703    0.011    1.327   -0.189   -1.051   -1.590    0.359   -0.641   \n",
       "3095    0.127    0.443    2.127   -0.175   -1.350   -2.950    0.257    0.473   \n",
       "8379    1.055    0.912    0.390   -0.094    1.139   -0.652    1.321    0.995   \n",
       "3043    2.306    0.384    0.296   -0.225   -1.575   -0.876    0.657    0.386   \n",
       "\n",
       "      wb_1407  wb_1408  \n",
       "6671   -0.369    0.006  \n",
       "3274   -0.254    0.000  \n",
       "3095   -1.521   -0.086  \n",
       "8379   -2.097    0.060  \n",
       "3043   -1.195    0.162  \n",
       "\n",
       "[5 rows x 1593 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:35.343137Z",
     "iopub.status.busy": "2022-01-03T14:42:35.342731Z",
     "iopub.status.idle": "2022-01-03T14:42:36.219226Z",
     "shell.execute_reply": "2022-01-03T14:42:36.218484Z",
     "shell.execute_reply.started": "2022-01-03T14:42:35.343105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>f6v8</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f7v5</th>\n",
       "      <th>f7v6</th>\n",
       "      <th>f7v7</th>\n",
       "      <th>f7v8</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f8v5</th>\n",
       "      <th>f8v6</th>\n",
       "      <th>f8v7</th>\n",
       "      <th>f8v8</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f9v5</th>\n",
       "      <th>f9v6</th>\n",
       "      <th>f9v7</th>\n",
       "      <th>f9v8</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f10v5</th>\n",
       "      <th>f10v6</th>\n",
       "      <th>f10v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1309</th>\n",
       "      <th>wb_1310</th>\n",
       "      <th>wb_1311</th>\n",
       "      <th>wb_1312</th>\n",
       "      <th>wb_1313</th>\n",
       "      <th>wb_1314</th>\n",
       "      <th>wb_1315</th>\n",
       "      <th>wb_1316</th>\n",
       "      <th>wb_1317</th>\n",
       "      <th>wb_1318</th>\n",
       "      <th>wb_1319</th>\n",
       "      <th>wb_1320</th>\n",
       "      <th>wb_1321</th>\n",
       "      <th>wb_1322</th>\n",
       "      <th>wb_1323</th>\n",
       "      <th>wb_1324</th>\n",
       "      <th>wb_1325</th>\n",
       "      <th>wb_1326</th>\n",
       "      <th>wb_1327</th>\n",
       "      <th>wb_1328</th>\n",
       "      <th>wb_1329</th>\n",
       "      <th>wb_1330</th>\n",
       "      <th>wb_1331</th>\n",
       "      <th>wb_1332</th>\n",
       "      <th>wb_1333</th>\n",
       "      <th>wb_1334</th>\n",
       "      <th>wb_1335</th>\n",
       "      <th>wb_1336</th>\n",
       "      <th>wb_1337</th>\n",
       "      <th>wb_1338</th>\n",
       "      <th>wb_1339</th>\n",
       "      <th>wb_1340</th>\n",
       "      <th>wb_1341</th>\n",
       "      <th>wb_1342</th>\n",
       "      <th>wb_1343</th>\n",
       "      <th>wb_1344</th>\n",
       "      <th>wb_1345</th>\n",
       "      <th>wb_1346</th>\n",
       "      <th>wb_1347</th>\n",
       "      <th>wb_1348</th>\n",
       "      <th>wb_1349</th>\n",
       "      <th>wb_1350</th>\n",
       "      <th>wb_1351</th>\n",
       "      <th>wb_1352</th>\n",
       "      <th>wb_1353</th>\n",
       "      <th>wb_1354</th>\n",
       "      <th>wb_1355</th>\n",
       "      <th>wb_1356</th>\n",
       "      <th>wb_1357</th>\n",
       "      <th>wb_1358</th>\n",
       "      <th>wb_1359</th>\n",
       "      <th>wb_1360</th>\n",
       "      <th>wb_1361</th>\n",
       "      <th>wb_1362</th>\n",
       "      <th>wb_1363</th>\n",
       "      <th>wb_1364</th>\n",
       "      <th>wb_1365</th>\n",
       "      <th>wb_1366</th>\n",
       "      <th>wb_1367</th>\n",
       "      <th>wb_1368</th>\n",
       "      <th>wb_1369</th>\n",
       "      <th>wb_1370</th>\n",
       "      <th>wb_1371</th>\n",
       "      <th>wb_1372</th>\n",
       "      <th>wb_1373</th>\n",
       "      <th>wb_1374</th>\n",
       "      <th>wb_1375</th>\n",
       "      <th>wb_1376</th>\n",
       "      <th>wb_1377</th>\n",
       "      <th>wb_1378</th>\n",
       "      <th>wb_1379</th>\n",
       "      <th>wb_1380</th>\n",
       "      <th>wb_1381</th>\n",
       "      <th>wb_1382</th>\n",
       "      <th>wb_1383</th>\n",
       "      <th>wb_1384</th>\n",
       "      <th>wb_1385</th>\n",
       "      <th>wb_1386</th>\n",
       "      <th>wb_1387</th>\n",
       "      <th>wb_1388</th>\n",
       "      <th>wb_1389</th>\n",
       "      <th>wb_1390</th>\n",
       "      <th>wb_1391</th>\n",
       "      <th>wb_1392</th>\n",
       "      <th>wb_1393</th>\n",
       "      <th>wb_1394</th>\n",
       "      <th>wb_1395</th>\n",
       "      <th>wb_1396</th>\n",
       "      <th>wb_1397</th>\n",
       "      <th>wb_1398</th>\n",
       "      <th>wb_1399</th>\n",
       "      <th>wb_1400</th>\n",
       "      <th>wb_1401</th>\n",
       "      <th>wb_1402</th>\n",
       "      <th>wb_1403</th>\n",
       "      <th>wb_1404</th>\n",
       "      <th>wb_1405</th>\n",
       "      <th>wb_1406</th>\n",
       "      <th>wb_1407</th>\n",
       "      <th>wb_1408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>3466.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.280</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.286</td>\n",
       "      <td>2.531</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.033</td>\n",
       "      <td>1.871</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-1.800</td>\n",
       "      <td>0.463</td>\n",
       "      <td>2.715</td>\n",
       "      <td>0.984</td>\n",
       "      <td>2.360</td>\n",
       "      <td>2.092</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1.780</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>1.730</td>\n",
       "      <td>-1.866</td>\n",
       "      <td>0.713</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-1.507</td>\n",
       "      <td>1.394</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-1.655</td>\n",
       "      <td>-0.685</td>\n",
       "      <td>1.578</td>\n",
       "      <td>-1.293</td>\n",
       "      <td>1.415</td>\n",
       "      <td>-0.731</td>\n",
       "      <td>1.954</td>\n",
       "      <td>0.342</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>1.583</td>\n",
       "      <td>-1.415</td>\n",
       "      <td>-0.509</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.372</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.536</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.889</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>0.663</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>-0.580</td>\n",
       "      <td>3.387</td>\n",
       "      <td>2.065</td>\n",
       "      <td>-1.785</td>\n",
       "      <td>-0.752</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>0.222</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>-5.078</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.186</td>\n",
       "      <td>2.244</td>\n",
       "      <td>-2.868</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-1.338</td>\n",
       "      <td>-3.784</td>\n",
       "      <td>-1.023</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.199</td>\n",
       "      <td>4.149</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.593</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-4.757</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-1.783</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-1.241</td>\n",
       "      <td>-1.067</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.071</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.604</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-1.906</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>2.323</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-2.595</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-3.309</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.710</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.815</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.945</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.780</td>\n",
       "      <td>-0.738</td>\n",
       "      <td>1.503</td>\n",
       "      <td>-0.728</td>\n",
       "      <td>0.489</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.768</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-2.179</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-1.692</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-3.616</td>\n",
       "      <td>-1.008</td>\n",
       "      <td>0.577</td>\n",
       "      <td>-0.785</td>\n",
       "      <td>-1.421</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.429</td>\n",
       "      <td>-1.122</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.620</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-1.121</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-1.642</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.374</td>\n",
       "      <td>1.171</td>\n",
       "      <td>-2.398</td>\n",
       "      <td>-1.949</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-2.182</td>\n",
       "      <td>1.412</td>\n",
       "      <td>-1.554</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>0.687</td>\n",
       "      <td>3.408</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.289</td>\n",
       "      <td>2.417</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-1.308</td>\n",
       "      <td>0.679</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>1.133</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4148.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-1.451</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.382</td>\n",
       "      <td>-0.669</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.606</td>\n",
       "      <td>1.372</td>\n",
       "      <td>1.342</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.117</td>\n",
       "      <td>1.769</td>\n",
       "      <td>-1.597</td>\n",
       "      <td>0.513</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>1.562</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.583</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.691</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>0.555</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.466</td>\n",
       "      <td>-2.620</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.477</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.525</td>\n",
       "      <td>-1.253</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.743</td>\n",
       "      <td>0.553</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-3.125</td>\n",
       "      <td>-0.573</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-2.154</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.257</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>-1.118</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.628</td>\n",
       "      <td>-1.794</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.307</td>\n",
       "      <td>1.183</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.455</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.497</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>-1.172</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>2815.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.838</td>\n",
       "      <td>-1.326</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-1.282</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.653</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.864</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.524</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>1.400</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>1.129</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.818</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.777</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.760</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.704</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>1.082</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.574</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.684</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-0.663</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>-1.800</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.798</td>\n",
       "      <td>1.174</td>\n",
       "      <td>-0.880</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.815</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.560</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>0.447</td>\n",
       "      <td>-0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185</th>\n",
       "      <td>5185.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.522</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.641</td>\n",
       "      <td>1.017</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.383</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>1.017</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.461</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.592</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.509</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.638</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.551</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-1.344</td>\n",
       "      <td>1.224</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.712</td>\n",
       "      <td>1.023</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.464</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>1.191</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.633</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.597</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.461</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.761</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "3466 3466.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689   689.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 4148.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 2815.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 5185.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f2v0  f2v1  f2v2  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f3v0  f3v1  f3v2  f3v3  f3v4  f3v5  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f3v6  f3v7  f3v8  f4v0  f4v1  f4v2  f4v3  f4v4  f4v5  f4v6  f4v7  f4v8  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f5v0  f5v1  f5v2  f5v3  f5v4  f5v5  f5v6  f5v7  f5v8  f6v0  f6v1  f6v2  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f6v3  f6v4  f6v5  f6v6  f6v7  f6v8  f7v0  f7v1  f7v2  f7v3  f7v4  f7v5  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f7v6  f7v7  f7v8  f8v0  f8v1  f8v2  f8v3  f8v4  f8v5  f8v6  f8v7  f8v8  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f9v0  f9v1  f9v2  f9v3  f9v4  f9v5  f9v6  f9v7  f9v8  f10v0  f10v1  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "\n",
       "      f10v2  f10v3  f10v4  f10v5  f10v6  f10v7  ...  wb_1309  wb_1310  \\\n",
       "3466  0.000  0.000  0.000  0.000  0.000  0.000  ...    2.280   -0.085   \n",
       "689   0.000  0.000  0.000  0.000  0.000  0.000  ...    0.740   -0.085   \n",
       "4148  0.000  0.000  0.000  0.000  0.000  0.000  ...    0.009   -0.085   \n",
       "2815  0.000  0.000  0.000  0.000  0.000  0.000  ...    0.673   -0.085   \n",
       "5185  0.000  0.000  0.000  0.000  0.000  0.000  ...    0.005   -0.085   \n",
       "\n",
       "      wb_1311  wb_1312  wb_1313  wb_1314  wb_1315  wb_1316  wb_1317  wb_1318  \\\n",
       "3466    0.286    2.531    0.240   -0.198    0.033    1.871    0.297    0.290   \n",
       "689     0.793    0.956    0.147   -2.595    0.534    0.305    0.235    0.154   \n",
       "4148    1.585    0.802    0.352   -1.451    0.471    0.613    0.279    0.382   \n",
       "2815    0.342    0.753    0.422   -0.100    1.022    0.793    0.679    0.838   \n",
       "5185    0.481    0.158    0.522   -0.648    0.055    0.535    0.641    1.017   \n",
       "\n",
       "      wb_1319  wb_1320  wb_1321  wb_1322  wb_1323  wb_1324  wb_1325  wb_1326  \\\n",
       "3466   -1.800    0.463    2.715    0.984    2.360    2.092    0.105    1.780   \n",
       "689    -3.309    0.212    0.556    0.336    0.718    0.814    0.689    0.234   \n",
       "4148   -0.669    0.674    0.606    1.372    1.342    0.570    0.117    1.769   \n",
       "2815   -1.326   -0.658    0.674    0.901    1.034    0.546    0.924    0.234   \n",
       "5185   -0.946    0.476    0.047    0.110    0.110    1.041    0.111    0.383   \n",
       "\n",
       "      wb_1327  wb_1328  wb_1329  wb_1330  wb_1331  wb_1332  wb_1333  wb_1334  \\\n",
       "3466   -0.925    1.730   -1.866    0.713   -0.133   -0.604   -0.113   -1.507   \n",
       "689    -0.170    0.710   -0.167    0.815   -0.133   -1.945   -0.113   -0.274   \n",
       "4148   -1.597    0.513   -0.168    1.562   -0.133   -1.583   -0.113   -0.915   \n",
       "2815   -1.282    0.966   -0.188    0.653   -0.133   -0.864   -0.113    0.459   \n",
       "5185   -0.933    0.808   -0.984    1.017   -0.133   -0.816   -0.113   -0.513   \n",
       "\n",
       "      wb_1335  wb_1336  wb_1337  wb_1338  wb_1339  wb_1340  wb_1341  wb_1342  \\\n",
       "3466    1.394    0.170   -1.655   -0.685    1.578   -1.293    1.415   -0.731   \n",
       "689     0.343    0.109   -0.780   -0.738    1.503   -0.728    0.489   -0.601   \n",
       "4148    0.398    0.091   -0.691   -0.912    0.105   -0.720    0.555   -0.482   \n",
       "2815    0.400    0.524   -0.630   -0.520    1.400   -0.074    0.478   -0.583   \n",
       "5185    0.722    0.461   -0.716   -0.160    0.111   -0.068    0.117   -0.930   \n",
       "\n",
       "      wb_1343  wb_1344  wb_1345  wb_1346  wb_1347  wb_1348  wb_1349  wb_1350  \\\n",
       "3466    1.954    0.342   -0.132    1.583   -1.415   -0.509   -0.107   -1.372   \n",
       "689     0.467    0.208   -0.116    0.617    0.276   -0.350   -0.107    0.077   \n",
       "4148    0.669    0.466   -2.620   -0.625    0.410   -0.422   -0.107   -0.404   \n",
       "2815    1.129   -0.516   -0.850    0.483    0.818   -0.741   -0.107   -0.777   \n",
       "5185    0.180    0.592   -0.126    0.609    0.509   -0.461   -0.107   -0.364   \n",
       "\n",
       "      wb_1351  wb_1352  wb_1353  wb_1354  wb_1355  wb_1356  wb_1357  wb_1358  \\\n",
       "3466    0.323    0.329   -0.536   -0.665   -0.073   -0.889   -0.487    0.663   \n",
       "689     0.340    0.271   -0.306   -0.768   -0.240   -0.375   -2.179    0.656   \n",
       "4148    0.567    0.477   -0.050   -0.432    0.130   -0.411    0.455    0.525   \n",
       "2815    0.895    0.760   -0.369   -0.526   -0.368   -0.607    0.905    0.704   \n",
       "5185    0.961    0.500   -0.061   -0.427   -0.024    0.945    0.000    0.638   \n",
       "\n",
       "      wb_1359  wb_1360  wb_1361  wb_1362  wb_1363  wb_1364  wb_1365  wb_1366  \\\n",
       "3466   -0.135   -0.444   -0.566   -0.580    3.387    2.065   -1.785   -0.752   \n",
       "689    -1.692   -0.112   -3.616   -1.008    0.577   -0.785   -1.421   -0.157   \n",
       "4148   -1.253   -0.220   -0.022   -0.743    0.553   -0.506   -0.505   -3.125   \n",
       "2815   -0.145   -0.666   -0.686   -0.384    0.763    0.970   -0.690   -0.150   \n",
       "5185   -0.136   -0.477   -0.733   -0.888    0.074    0.551   -0.024   -1.344   \n",
       "\n",
       "      wb_1367  wb_1368  wb_1369  wb_1370  wb_1371  wb_1372  wb_1373  wb_1374  \\\n",
       "3466    1.100    0.175   -0.616    0.222   -0.588   -5.078    0.117    0.186   \n",
       "689     0.117   -0.141    0.699    0.116   -0.475   -0.053    0.032    0.429   \n",
       "4148   -0.573   -0.058    0.462    0.343   -2.154   -0.054    0.188    0.027   \n",
       "2815    1.082   -0.322    0.782    0.471   -0.574   -0.565   -0.428    0.843   \n",
       "5185    1.224   -0.259   -0.387    0.458   -0.938   -0.050    0.293    0.712   \n",
       "\n",
       "      wb_1375  wb_1376  wb_1377  wb_1378  wb_1379  wb_1380  wb_1381  wb_1382  \\\n",
       "3466    2.244   -2.868    0.961    0.188   -1.070   -1.338   -3.784   -1.023   \n",
       "689    -1.122   -0.388    0.620   -0.077   -1.121   -0.321   -1.642   -0.614   \n",
       "4148   -0.007   -0.568    0.346    0.257   -0.525   -0.913   -1.118   -0.908   \n",
       "2815    0.684   -0.856    0.575    0.496   -0.663   -0.417   -1.800   -0.542   \n",
       "5185    1.023   -0.048    0.686    0.464   -0.251   -0.150   -0.189   -0.834   \n",
       "\n",
       "      wb_1383  wb_1384  wb_1385  wb_1386  wb_1387  wb_1388  wb_1389  wb_1390  \\\n",
       "3466   -0.106    0.199    4.149    0.083    1.593   -0.979   -4.757    0.067   \n",
       "689    -0.106    0.179    0.478    0.374    1.171   -2.398   -1.949    0.067   \n",
       "4148   -0.106    0.244    0.503    0.425    0.628   -1.794   -0.537    0.067   \n",
       "2815   -0.106    0.620    0.690    0.798    1.174   -0.880   -0.818    0.067   \n",
       "5185   -0.106    1.191    0.036    0.983    0.049   -0.633   -0.487    0.067   \n",
       "\n",
       "      wb_1391  wb_1392  wb_1393  wb_1394  wb_1395  wb_1396  wb_1397  wb_1398  \\\n",
       "3466   -1.783   -0.773    0.140   -0.237   -1.241   -1.067    1.036    0.071   \n",
       "689    -0.460   -2.182    1.412   -1.554   -0.178   -0.905    0.687    3.408   \n",
       "4148   -0.368    0.307    1.183   -0.341   -0.199   -0.609    0.572    0.814   \n",
       "2815   -0.689   -0.692    0.978   -0.706   -0.203   -0.815    0.036    0.796   \n",
       "5185   -0.597    0.624    0.321    0.461   -0.195   -0.485    0.076    0.077   \n",
       "\n",
       "      wb_1399  wb_1400  wb_1401  wb_1402  wb_1403  wb_1404  wb_1405  wb_1406  \\\n",
       "3466    3.079    0.168    0.604   -0.124   -1.906   -0.874    0.521   -0.068   \n",
       "689     0.892    0.289    2.417   -0.182   -0.312   -1.308    0.679   -0.267   \n",
       "4148    0.721    0.269    1.455   -0.251   -0.438   -0.080    0.497   -0.763   \n",
       "2815    0.734    0.685    0.560   -0.303   -0.301   -0.781    0.087   -0.335   \n",
       "5185    0.127    0.622    0.418    0.271   -0.461   -0.108    0.122   -0.506   \n",
       "\n",
       "      wb_1407  wb_1408  \n",
       "3466    2.323    0.026  \n",
       "689     1.133    0.155  \n",
       "4148   -1.172    0.128  \n",
       "2815    0.447   -0.040  \n",
       "5185   -0.761    0.020  \n",
       "\n",
       "[5 rows x 1593 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:36.220708Z",
     "iopub.status.busy": "2022-01-03T14:42:36.220431Z",
     "iopub.status.idle": "2022-01-03T14:42:36.441756Z",
     "shell.execute_reply": "2022-01-03T14:42:36.441107Z",
     "shell.execute_reply.started": "2022-01-03T14:42:36.220677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>f6v8</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f7v5</th>\n",
       "      <th>f7v6</th>\n",
       "      <th>f7v7</th>\n",
       "      <th>f7v8</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f8v5</th>\n",
       "      <th>f8v6</th>\n",
       "      <th>f8v7</th>\n",
       "      <th>f8v8</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f9v5</th>\n",
       "      <th>f9v6</th>\n",
       "      <th>f9v7</th>\n",
       "      <th>f9v8</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f10v5</th>\n",
       "      <th>f10v6</th>\n",
       "      <th>f10v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1309</th>\n",
       "      <th>wb_1310</th>\n",
       "      <th>wb_1311</th>\n",
       "      <th>wb_1312</th>\n",
       "      <th>wb_1313</th>\n",
       "      <th>wb_1314</th>\n",
       "      <th>wb_1315</th>\n",
       "      <th>wb_1316</th>\n",
       "      <th>wb_1317</th>\n",
       "      <th>wb_1318</th>\n",
       "      <th>wb_1319</th>\n",
       "      <th>wb_1320</th>\n",
       "      <th>wb_1321</th>\n",
       "      <th>wb_1322</th>\n",
       "      <th>wb_1323</th>\n",
       "      <th>wb_1324</th>\n",
       "      <th>wb_1325</th>\n",
       "      <th>wb_1326</th>\n",
       "      <th>wb_1327</th>\n",
       "      <th>wb_1328</th>\n",
       "      <th>wb_1329</th>\n",
       "      <th>wb_1330</th>\n",
       "      <th>wb_1331</th>\n",
       "      <th>wb_1332</th>\n",
       "      <th>wb_1333</th>\n",
       "      <th>wb_1334</th>\n",
       "      <th>wb_1335</th>\n",
       "      <th>wb_1336</th>\n",
       "      <th>wb_1337</th>\n",
       "      <th>wb_1338</th>\n",
       "      <th>wb_1339</th>\n",
       "      <th>wb_1340</th>\n",
       "      <th>wb_1341</th>\n",
       "      <th>wb_1342</th>\n",
       "      <th>wb_1343</th>\n",
       "      <th>wb_1344</th>\n",
       "      <th>wb_1345</th>\n",
       "      <th>wb_1346</th>\n",
       "      <th>wb_1347</th>\n",
       "      <th>wb_1348</th>\n",
       "      <th>wb_1349</th>\n",
       "      <th>wb_1350</th>\n",
       "      <th>wb_1351</th>\n",
       "      <th>wb_1352</th>\n",
       "      <th>wb_1353</th>\n",
       "      <th>wb_1354</th>\n",
       "      <th>wb_1355</th>\n",
       "      <th>wb_1356</th>\n",
       "      <th>wb_1357</th>\n",
       "      <th>wb_1358</th>\n",
       "      <th>wb_1359</th>\n",
       "      <th>wb_1360</th>\n",
       "      <th>wb_1361</th>\n",
       "      <th>wb_1362</th>\n",
       "      <th>wb_1363</th>\n",
       "      <th>wb_1364</th>\n",
       "      <th>wb_1365</th>\n",
       "      <th>wb_1366</th>\n",
       "      <th>wb_1367</th>\n",
       "      <th>wb_1368</th>\n",
       "      <th>wb_1369</th>\n",
       "      <th>wb_1370</th>\n",
       "      <th>wb_1371</th>\n",
       "      <th>wb_1372</th>\n",
       "      <th>wb_1373</th>\n",
       "      <th>wb_1374</th>\n",
       "      <th>wb_1375</th>\n",
       "      <th>wb_1376</th>\n",
       "      <th>wb_1377</th>\n",
       "      <th>wb_1378</th>\n",
       "      <th>wb_1379</th>\n",
       "      <th>wb_1380</th>\n",
       "      <th>wb_1381</th>\n",
       "      <th>wb_1382</th>\n",
       "      <th>wb_1383</th>\n",
       "      <th>wb_1384</th>\n",
       "      <th>wb_1385</th>\n",
       "      <th>wb_1386</th>\n",
       "      <th>wb_1387</th>\n",
       "      <th>wb_1388</th>\n",
       "      <th>wb_1389</th>\n",
       "      <th>wb_1390</th>\n",
       "      <th>wb_1391</th>\n",
       "      <th>wb_1392</th>\n",
       "      <th>wb_1393</th>\n",
       "      <th>wb_1394</th>\n",
       "      <th>wb_1395</th>\n",
       "      <th>wb_1396</th>\n",
       "      <th>wb_1397</th>\n",
       "      <th>wb_1398</th>\n",
       "      <th>wb_1399</th>\n",
       "      <th>wb_1400</th>\n",
       "      <th>wb_1401</th>\n",
       "      <th>wb_1402</th>\n",
       "      <th>wb_1403</th>\n",
       "      <th>wb_1404</th>\n",
       "      <th>wb_1405</th>\n",
       "      <th>wb_1406</th>\n",
       "      <th>wb_1407</th>\n",
       "      <th>wb_1408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7217.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.569</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.303</td>\n",
       "      <td>-3.381</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-1.405</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.405</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.461</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>0.501</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.968</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-3.863</td>\n",
       "      <td>-0.748</td>\n",
       "      <td>1.036</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1.645</td>\n",
       "      <td>-5.051</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-1.684</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.977</td>\n",
       "      <td>0.634</td>\n",
       "      <td>1.503</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-1.140</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.793</td>\n",
       "      <td>-4.914</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-3.350</td>\n",
       "      <td>-1.376</td>\n",
       "      <td>-2.166</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>-2.732</td>\n",
       "      <td>1.004</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.903</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>-2.192</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-1.397</td>\n",
       "      <td>-1.020</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-1.197</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.949</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-1.189</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-1.175</td>\n",
       "      <td>-0.664</td>\n",
       "      <td>0.707</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.257</td>\n",
       "      <td>1.084</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.691</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>8291.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.663</td>\n",
       "      <td>2.440</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>2.122</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-2.591</td>\n",
       "      <td>0.268</td>\n",
       "      <td>1.870</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-1.682</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-1.483</td>\n",
       "      <td>0.499</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-2.625</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-1.906</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-1.375</td>\n",
       "      <td>-1.380</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-2.529</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>1.754</td>\n",
       "      <td>1.598</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.788</td>\n",
       "      <td>-2.367</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-1.427</td>\n",
       "      <td>-1.136</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>-2.049</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>0.465</td>\n",
       "      <td>-2.809</td>\n",
       "      <td>-0.738</td>\n",
       "      <td>-1.576</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-2.179</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.479</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-3.082</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.454</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>1.652</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>-2.231</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-2.681</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>-1.934</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2.261</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-3.702</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-1.114</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>4607.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>3.425</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.905</td>\n",
       "      <td>-1.803</td>\n",
       "      <td>0.397</td>\n",
       "      <td>1.422</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.763</td>\n",
       "      <td>1.227</td>\n",
       "      <td>0.727</td>\n",
       "      <td>-3.377</td>\n",
       "      <td>1.563</td>\n",
       "      <td>-2.488</td>\n",
       "      <td>0.549</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.742</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>2.039</td>\n",
       "      <td>-1.848</td>\n",
       "      <td>0.738</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>1.105</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-1.913</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.409</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.693</td>\n",
       "      <td>2.693</td>\n",
       "      <td>1.244</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-1.761</td>\n",
       "      <td>1.331</td>\n",
       "      <td>-2.612</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.588</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>1.460</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>1.248</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-1.779</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>1.091</td>\n",
       "      <td>0.774</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>-3.075</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.541</td>\n",
       "      <td>1.726</td>\n",
       "      <td>1.218</td>\n",
       "      <td>-3.196</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-2.754</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.732</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-2.670</td>\n",
       "      <td>-2.221</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-3.580</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.825</td>\n",
       "      <td>1.699</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-1.811</td>\n",
       "      <td>1.194</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>5114.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.604</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.273</td>\n",
       "      <td>2.743</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-0.685</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1.810</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-2.118</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.145</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.138</td>\n",
       "      <td>1.871</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-1.030</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>2.271</td>\n",
       "      <td>2.921</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-1.407</td>\n",
       "      <td>1.444</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>1.174</td>\n",
       "      <td>0.212</td>\n",
       "      <td>-1.910</td>\n",
       "      <td>-1.290</td>\n",
       "      <td>-1.183</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-3.434</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-1.184</td>\n",
       "      <td>-0.870</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-2.358</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-2.556</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-1.336</td>\n",
       "      <td>-1.034</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>1.132</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>1.367</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.806</td>\n",
       "      <td>-1.693</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-1.224</td>\n",
       "      <td>-2.425</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-1.874</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>-2.202</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.259</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-1.323</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-1.104</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>2.870</td>\n",
       "      <td>1.995</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>2.754</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.563</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>0.668</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.920</td>\n",
       "      <td>-0.650</td>\n",
       "      <td>0.826</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.501</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.801</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.522</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>0.729</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "7217 7217.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 8291.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 4607.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 5114.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 1859.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f2v0  f2v1  f2v2  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f3v0  f3v1  f3v2  f3v3  f3v4  f3v5  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f3v6  f3v7  f3v8  f4v0  f4v1  f4v2  f4v3  f4v4  f4v5  f4v6  f4v7  f4v8  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f5v0  f5v1  f5v2  f5v3  f5v4  f5v5  f5v6  f5v7  f5v8  f6v0  f6v1  f6v2  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f6v3  f6v4  f6v5  f6v6  f6v7  f6v8  f7v0  f7v1  f7v2  f7v3  f7v4  f7v5  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f7v6  f7v7  f7v8  f8v0  f8v1  f8v2  f8v3  f8v4  f8v5  f8v6  f8v7  f8v8  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f9v0  f9v1  f9v2  f9v3  f9v4  f9v5  f9v6  f9v7  f9v8  f10v0  f10v1  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "\n",
       "      f10v2  f10v3  f10v4  f10v5  f10v6  f10v7  ...  wb_1309  wb_1310  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  ...    0.448   -0.085   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  ...    0.026   -0.085   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  ...    0.437   -0.085   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  ...    1.604   -0.085   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  ...    0.509   -0.085   \n",
       "\n",
       "      wb_1311  wb_1312  wb_1313  wb_1314  wb_1315  wb_1316  wb_1317  wb_1318  \\\n",
       "7217    0.569    1.018    0.303   -3.381    0.059   -1.405    0.245    0.208   \n",
       "8291    0.663    2.440    0.504   -0.442    2.122    0.307    0.334    0.022   \n",
       "4607    0.568    0.898    0.377   -1.165    3.425    0.452    0.743    0.905   \n",
       "5114    0.273    2.743    0.405   -0.685    0.248    1.810    0.422    0.302   \n",
       "1859    0.393    0.732    0.128   -0.637    0.056   -0.563    0.580    0.016   \n",
       "\n",
       "      wb_1319  wb_1320  wb_1321  wb_1322  wb_1323  wb_1324  wb_1325  wb_1326  \\\n",
       "7217   -0.279    0.064    0.764    0.405    1.273    0.655    0.097    0.461   \n",
       "8291   -2.591    0.268    1.870    0.128    0.127    0.142    0.121    0.504   \n",
       "4607   -1.803    0.397    1.422    0.638    0.595    0.763    1.227    0.727   \n",
       "5114   -2.118    0.290    0.475    1.145    0.324    0.138    1.871    0.316   \n",
       "1859   -0.593    0.301    0.626    0.123    0.122    0.475    0.115    0.344   \n",
       "\n",
       "      wb_1327  wb_1328  wb_1329  wb_1330  wb_1331  wb_1332  wb_1333  wb_1334  \\\n",
       "7217   -0.946    0.501   -0.187    1.968   -0.133   -0.740   -0.113   -0.995   \n",
       "8291   -1.682    0.086   -1.483    0.499   -0.133   -2.625   -0.113   -1.906   \n",
       "4607   -3.377    1.563   -2.488    0.549   -0.133   -1.742   -0.113   -0.246   \n",
       "5114   -1.030    0.376   -1.524    0.075   -0.133   -0.856   -0.113    2.271   \n",
       "1859   -0.804    0.080   -0.615    0.668   -0.133   -0.611   -0.113   -0.322   \n",
       "\n",
       "      wb_1335  wb_1336  wb_1337  wb_1338  wb_1339  wb_1340  wb_1341  wb_1342  \\\n",
       "7217    0.316    0.129   -3.863   -0.748    1.036   -0.998    0.452   -0.403   \n",
       "8291    0.625    0.238   -1.375   -1.380    0.113   -2.529    0.122   -0.400   \n",
       "4607    0.207   -0.433   -0.562   -0.510    2.039   -1.848    0.738   -0.282   \n",
       "5114    2.921    0.196   -0.827   -0.432    0.375   -1.407    1.444   -0.920   \n",
       "1859    0.672    0.250   -0.535   -0.375    0.920   -0.650    0.826   -0.340   \n",
       "\n",
       "      wb_1343  wb_1344  wb_1345  wb_1346  wb_1347  wb_1348  wb_1349  wb_1350  \\\n",
       "7217    0.455    1.645   -5.051    0.189    0.881   -1.684   -0.107   -1.977   \n",
       "8291    1.754    1.598   -0.133   -0.788   -2.367   -0.457   -0.107   -0.760   \n",
       "4607    1.105    1.056   -1.913    0.582    0.409   -0.147   -0.107   -0.693   \n",
       "5114    1.174    0.212   -1.910   -1.290   -1.183   -0.505   -0.107   -3.434   \n",
       "1859    0.793    0.329   -0.735   -0.637    0.367   -0.080   -0.107   -0.398   \n",
       "\n",
       "      wb_1351  wb_1352  wb_1353  wb_1354  wb_1355  wb_1356  wb_1357  wb_1358  \\\n",
       "7217    0.634    1.503   -0.473   -1.140   -0.947   -0.793   -4.914    0.345   \n",
       "8291    0.839    0.165   -1.427   -1.136   -0.872   -2.049   -0.917    0.465   \n",
       "4607    2.693    1.244   -0.349   -0.204   -0.311   -0.921   -1.761    1.331   \n",
       "5114    0.449    0.333   -1.158    0.215   -1.184   -0.870   -0.002    0.286   \n",
       "1859    0.499    0.332   -0.575   -0.340   -0.621   -0.516   -0.004    0.338   \n",
       "\n",
       "      wb_1359  wb_1360  wb_1361  wb_1362  wb_1363  wb_1364  wb_1365  wb_1366  \\\n",
       "7217   -3.350   -1.376   -2.166   -0.816    0.278   -1.300   -0.264   -2.732   \n",
       "8291   -2.809   -0.738   -1.576   -0.076    0.077    0.442   -2.179   -0.154   \n",
       "4607   -2.612    0.185   -0.235   -0.963    0.499    0.588   -0.711   -0.154   \n",
       "5114   -2.358   -0.828   -0.085   -2.556    0.072   -1.336   -1.034   -0.154   \n",
       "1859   -0.609   -0.339   -0.334   -0.053    0.077   -0.493   -0.476   -0.150   \n",
       "\n",
       "      wb_1367  wb_1368  wb_1369  wb_1370  wb_1371  wb_1372  wb_1373  wb_1374  \\\n",
       "7217    1.004   -0.251   -0.903    0.199   -0.635   -2.192    0.058    0.283   \n",
       "8291    0.479   -0.336   -0.414    0.108   -0.316   -3.082    0.158    0.454   \n",
       "4607    1.460   -0.221    1.248    0.017   -0.329   -1.779   -0.332    1.091   \n",
       "5114    1.132   -0.032    1.367    0.387   -0.806   -1.693    0.220    0.199   \n",
       "1859    0.425   -0.260   -0.290    0.155   -0.501   -0.052    0.194    0.414   \n",
       "\n",
       "      wb_1375  wb_1376  wb_1377  wb_1378  wb_1379  wb_1380  wb_1381  wb_1382  \\\n",
       "7217   -1.397   -1.020    0.249    0.157   -0.194   -0.322   -0.166   -1.197   \n",
       "8291    1.148   -0.043    1.652    0.258   -0.570   -2.231   -0.195   -0.085   \n",
       "4607    0.774   -0.345    1.250    0.211   -0.275   -0.344   -3.075   -0.469   \n",
       "5114   -1.224   -2.425    0.106   -1.874   -0.297   -0.918   -2.202   -0.442   \n",
       "1859    0.801   -0.488    0.139    0.111   -0.546   -0.439   -0.667   -0.257   \n",
       "\n",
       "      wb_1383  wb_1384  wb_1385  wb_1386  wb_1387  wb_1388  wb_1389  wb_1390  \\\n",
       "7217   -0.106    0.588    0.412    0.688    0.949   -0.168   -1.189    0.067   \n",
       "8291   -0.106    0.336    0.057    0.080    0.405   -2.681   -0.498    0.067   \n",
       "4607   -0.106    0.542    0.541    1.726    1.218   -3.196   -2.500    0.067   \n",
       "5114   -0.106    0.259    1.306    0.079    0.302   -0.902   -1.323    0.067   \n",
       "1859   -0.106    0.506    0.842    0.754    0.522   -0.562   -0.510    0.067   \n",
       "\n",
       "      wb_1391  wb_1392  wb_1393  wb_1394  wb_1395  wb_1396  wb_1397  wb_1398  \\\n",
       "7217   -1.175   -0.664    0.707   -0.171   -0.203   -0.049    0.257    1.084   \n",
       "8291   -0.838   -1.934    0.486    0.309   -0.203   -0.610    0.054    2.261   \n",
       "4607   -2.754    0.824    0.732   -0.184   -2.670   -2.221    0.053   -3.580   \n",
       "5114   -0.719   -0.049    0.304   -0.148   -1.104   -0.965    2.870    1.995   \n",
       "1859   -0.411   -0.711    0.729   -0.294   -0.203   -0.585    0.060    0.077   \n",
       "\n",
       "      wb_1399  wb_1400  wb_1401  wb_1402  wb_1403  wb_1404  wb_1405  wb_1406  \\\n",
       "7217    0.925    0.691    1.309   -0.122    0.208   -0.135    0.344    0.159   \n",
       "8291    0.134    0.225    0.394   -0.160   -0.652   -3.702    0.088   -1.114   \n",
       "4607    0.766    0.825    1.699   -0.179   -0.465   -1.811    1.194   -0.312   \n",
       "5114    0.129    0.296    0.345   -0.070   -0.720   -0.172    2.754   -0.157   \n",
       "1859    0.141    0.367    0.438   -0.222   -0.395   -0.760    0.101   -0.441   \n",
       "\n",
       "      wb_1407  wb_1408  \n",
       "7217   -0.498    0.188  \n",
       "8291    0.261    0.141  \n",
       "4607   -0.897    0.129  \n",
       "5114    0.192   -0.164  \n",
       "1859    0.337    0.044  \n",
       "\n",
       "[5 rows x 1593 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:36.443082Z",
     "iopub.status.busy": "2022-01-03T14:42:36.442818Z",
     "iopub.status.idle": "2022-01-03T14:42:36.446051Z",
     "shell.execute_reply": "2022-01-03T14:42:36.445372Z",
     "shell.execute_reply.started": "2022-01-03T14:42:36.443056Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir data/logging/ --port=8811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:36.447200Z",
     "iopub.status.busy": "2022-01-03T14:42:36.447000Z",
     "iopub.status.idle": "2022-01-03T14:42:36.453814Z",
     "shell.execute_reply": "2022-01-03T14:42:36.452967Z",
     "shell.execute_reply.started": "2022-01-03T14:42:36.447175Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:36.455410Z",
     "iopub.status.busy": "2022-01-03T14:42:36.454894Z",
     "iopub.status.idle": "2022-01-03T15:40:10.845836Z",
     "shell.execute_reply": "2022-01-03T15:40:10.845169Z",
     "shell.execute_reply.started": "2022-01-03T14:42:36.455381Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "Epoch 1/500\n",
      "35/35 - 29s - loss: 0.6927 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6922 - binary_accuracy_inet_decision_function_fv_metric: 0.5155 - val_loss: 0.6887 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6908 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5487\n",
      "Epoch 2/500\n",
      "35/35 - 13s - loss: 0.6874 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6887 - binary_accuracy_inet_decision_function_fv_metric: 0.5432 - val_loss: 0.6840 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6880 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5646\n",
      "Epoch 3/500\n",
      "35/35 - 13s - loss: 0.6820 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6849 - binary_accuracy_inet_decision_function_fv_metric: 0.5637 - val_loss: 0.6797 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6851 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5703\n",
      "Epoch 4/500\n",
      "35/35 - 14s - loss: 0.6773 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6817 - binary_accuracy_inet_decision_function_fv_metric: 0.5702 - val_loss: 0.6794 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6853 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5695\n",
      "Epoch 5/500\n",
      "35/35 - 15s - loss: 0.6703 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6772 - binary_accuracy_inet_decision_function_fv_metric: 0.5698 - val_loss: 0.6713 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6804 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5882\n",
      "Epoch 6/500\n",
      "35/35 - 14s - loss: 0.6665 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6741 - binary_accuracy_inet_decision_function_fv_metric: 0.5887 - val_loss: 0.6604 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6735 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5978\n",
      "Epoch 7/500\n",
      "35/35 - 14s - loss: 0.6594 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6697 - binary_accuracy_inet_decision_function_fv_metric: 0.5988 - val_loss: 0.6556 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6705 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6079\n",
      "Epoch 8/500\n",
      "35/35 - 14s - loss: 0.6469 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6612 - binary_accuracy_inet_decision_function_fv_metric: 0.6157 - val_loss: 0.6373 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6587 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6272\n",
      "Epoch 9/500\n",
      "35/35 - 14s - loss: 0.6362 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6544 - binary_accuracy_inet_decision_function_fv_metric: 0.6265 - val_loss: 0.6352 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6573 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6263\n",
      "Epoch 10/500\n",
      "35/35 - 14s - loss: 0.6330 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6525 - binary_accuracy_inet_decision_function_fv_metric: 0.6293 - val_loss: 0.6399 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6609 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6257\n",
      "Epoch 11/500\n",
      "35/35 - 14s - loss: 0.6343 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6530 - binary_accuracy_inet_decision_function_fv_metric: 0.6287 - val_loss: 0.6402 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6615 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6237\n",
      "Epoch 12/500\n",
      "35/35 - 14s - loss: 0.6330 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6524 - binary_accuracy_inet_decision_function_fv_metric: 0.6297 - val_loss: 0.6413 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6618 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6249\n",
      "Epoch 13/500\n",
      "35/35 - 14s - loss: 0.6306 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6511 - binary_accuracy_inet_decision_function_fv_metric: 0.6303 - val_loss: 0.6379 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6251\n",
      "Epoch 14/500\n",
      "35/35 - 14s - loss: 0.6323 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6522 - binary_accuracy_inet_decision_function_fv_metric: 0.6287 - val_loss: 0.6405 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6608 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6228\n",
      "Epoch 15/500\n",
      "35/35 - 14s - loss: 0.6363 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6546 - binary_accuracy_inet_decision_function_fv_metric: 0.6255 - val_loss: 0.6477 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6655 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6164\n",
      "Epoch 16/500\n",
      "35/35 - 14s - loss: 0.6396 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6567 - binary_accuracy_inet_decision_function_fv_metric: 0.6224 - val_loss: 0.6460 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6651 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6220\n",
      "Epoch 17/500\n",
      "35/35 - 14s - loss: 0.6365 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6549 - binary_accuracy_inet_decision_function_fv_metric: 0.6242 - val_loss: 0.6469 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6648 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6143\n",
      "Epoch 18/500\n",
      "35/35 - 14s - loss: 0.6364 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6549 - binary_accuracy_inet_decision_function_fv_metric: 0.6234 - val_loss: 0.6456 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6642 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6171\n",
      "Epoch 19/500\n",
      "35/35 - 14s - loss: 0.6382 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6562 - binary_accuracy_inet_decision_function_fv_metric: 0.6205 - val_loss: 0.6491 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6666 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6132\n",
      "Epoch 20/500\n",
      "35/35 - 14s - loss: 0.6403 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6574 - binary_accuracy_inet_decision_function_fv_metric: 0.6188 - val_loss: 0.6443 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6633 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6166\n",
      "Epoch 21/500\n",
      "35/35 - 14s - loss: 0.6409 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6578 - binary_accuracy_inet_decision_function_fv_metric: 0.6189 - val_loss: 0.6482 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6655 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6157\n",
      "Epoch 22/500\n",
      "35/35 - 14s - loss: 0.6399 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6570 - binary_accuracy_inet_decision_function_fv_metric: 0.6210 - val_loss: 0.6474 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6656 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6193\n",
      "Epoch 23/500\n",
      "35/35 - 14s - loss: 0.6386 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6561 - binary_accuracy_inet_decision_function_fv_metric: 0.6239 - val_loss: 0.6446 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6615 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6270\n",
      "Epoch 24/500\n",
      "35/35 - 14s - loss: 0.6322 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6519 - binary_accuracy_inet_decision_function_fv_metric: 0.6326 - val_loss: 0.6310 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6556 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6346\n",
      "Epoch 25/500\n",
      "35/35 - 14s - loss: 0.6255 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6476 - binary_accuracy_inet_decision_function_fv_metric: 0.6396 - val_loss: 0.6301 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6554 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6378\n",
      "Epoch 26/500\n",
      "35/35 - 14s - loss: 0.6293 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6500 - binary_accuracy_inet_decision_function_fv_metric: 0.6360 - val_loss: 0.6295 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6543 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6401\n",
      "Epoch 27/500\n",
      "35/35 - 14s - loss: 0.6302 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6504 - binary_accuracy_inet_decision_function_fv_metric: 0.6355 - val_loss: 0.6389 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6602 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6314\n",
      "Epoch 28/500\n",
      "35/35 - 14s - loss: 0.6307 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6508 - binary_accuracy_inet_decision_function_fv_metric: 0.6349 - val_loss: 0.6293 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6542 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6391\n",
      "Epoch 29/500\n",
      "35/35 - 14s - loss: 0.6285 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6496 - binary_accuracy_inet_decision_function_fv_metric: 0.6360 - val_loss: 0.6221 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6502 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6496\n",
      "Epoch 30/500\n",
      "35/35 - 14s - loss: 0.6255 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6475 - binary_accuracy_inet_decision_function_fv_metric: 0.6411 - val_loss: 0.6267 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6530 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6480\n",
      "Epoch 31/500\n",
      "35/35 - 14s - loss: 0.6226 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6457 - binary_accuracy_inet_decision_function_fv_metric: 0.6441 - val_loss: 0.6254 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6508 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6450\n",
      "Epoch 32/500\n",
      "35/35 - 14s - loss: 0.6246 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6469 - binary_accuracy_inet_decision_function_fv_metric: 0.6409 - val_loss: 0.6295 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6541 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6389\n",
      "Epoch 33/500\n",
      "35/35 - 14s - loss: 0.6284 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6493 - binary_accuracy_inet_decision_function_fv_metric: 0.6375 - val_loss: 0.6248 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6518 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6438\n",
      "Epoch 34/500\n",
      "35/35 - 14s - loss: 0.6291 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6495 - binary_accuracy_inet_decision_function_fv_metric: 0.6389 - val_loss: 0.6243 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6514 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6484\n",
      "Epoch 35/500\n",
      "35/35 - 15s - loss: 0.6244 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6467 - binary_accuracy_inet_decision_function_fv_metric: 0.6438 - val_loss: 0.6179 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6467 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6574\n",
      "Epoch 36/500\n",
      "35/35 - 14s - loss: 0.6193 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6434 - binary_accuracy_inet_decision_function_fv_metric: 0.6480 - val_loss: 0.6116 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6432 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6617\n",
      "Epoch 37/500\n",
      "35/35 - 14s - loss: 0.6168 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6418 - binary_accuracy_inet_decision_function_fv_metric: 0.6505 - val_loss: 0.6157 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6461 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6609\n",
      "Epoch 38/500\n",
      "35/35 - 14s - loss: 0.6142 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6402 - binary_accuracy_inet_decision_function_fv_metric: 0.6535 - val_loss: 0.6096 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6419 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6626\n",
      "Epoch 39/500\n",
      "35/35 - 14s - loss: 0.6089 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6368 - binary_accuracy_inet_decision_function_fv_metric: 0.6591 - val_loss: 0.6111 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6416 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6584\n",
      "Epoch 40/500\n",
      "35/35 - 14s - loss: 0.6087 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6367 - binary_accuracy_inet_decision_function_fv_metric: 0.6588 - val_loss: 0.6038 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6391 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6700\n",
      "Epoch 41/500\n",
      "35/35 - 14s - loss: 0.6082 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6364 - binary_accuracy_inet_decision_function_fv_metric: 0.6591 - val_loss: 0.6079 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6405 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6590\n",
      "Epoch 42/500\n",
      "35/35 - 14s - loss: 0.6061 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6349 - binary_accuracy_inet_decision_function_fv_metric: 0.6611 - val_loss: 0.6023 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6375 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6711\n",
      "Epoch 43/500\n",
      "35/35 - 14s - loss: 0.6023 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6326 - binary_accuracy_inet_decision_function_fv_metric: 0.6655 - val_loss: 0.6022 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6372 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6711\n",
      "Epoch 44/500\n",
      "35/35 - 14s - loss: 0.5996 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6308 - binary_accuracy_inet_decision_function_fv_metric: 0.6687 - val_loss: 0.5953 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6342 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6791\n",
      "Epoch 45/500\n",
      "35/35 - 14s - loss: 0.5974 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6296 - binary_accuracy_inet_decision_function_fv_metric: 0.6696 - val_loss: 0.5961 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6340 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6783\n",
      "Epoch 46/500\n",
      "35/35 - 14s - loss: 0.5985 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6302 - binary_accuracy_inet_decision_function_fv_metric: 0.6688 - val_loss: 0.5917 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6311 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6823\n",
      "Epoch 47/500\n",
      "35/35 - 14s - loss: 0.6016 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6320 - binary_accuracy_inet_decision_function_fv_metric: 0.6676 - val_loss: 0.5981 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6340 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6720\n",
      "Epoch 48/500\n",
      "35/35 - 14s - loss: 0.5995 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6308 - binary_accuracy_inet_decision_function_fv_metric: 0.6677 - val_loss: 0.5933 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6322 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6792\n",
      "Epoch 49/500\n",
      "35/35 - 14s - loss: 0.5927 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6263 - binary_accuracy_inet_decision_function_fv_metric: 0.6751 - val_loss: 0.5856 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6280 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6878\n",
      "Epoch 50/500\n",
      "35/35 - 14s - loss: 0.5894 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6244 - binary_accuracy_inet_decision_function_fv_metric: 0.6786 - val_loss: 0.5829 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6261 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6879\n",
      "Epoch 51/500\n",
      "35/35 - 14s - loss: 0.5869 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6229 - binary_accuracy_inet_decision_function_fv_metric: 0.6805 - val_loss: 0.5833 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6258 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6909\n",
      "Epoch 52/500\n",
      "35/35 - 14s - loss: 0.5861 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6224 - binary_accuracy_inet_decision_function_fv_metric: 0.6807 - val_loss: 0.5774 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6221 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6961\n",
      "Epoch 53/500\n",
      "35/35 - 14s - loss: 0.5863 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6224 - binary_accuracy_inet_decision_function_fv_metric: 0.6839 - val_loss: 0.5841 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6263 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6903\n",
      "Epoch 54/500\n",
      "35/35 - 14s - loss: 0.5841 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6212 - binary_accuracy_inet_decision_function_fv_metric: 0.6847 - val_loss: 0.5767 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6218 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6965\n",
      "Epoch 55/500\n",
      "35/35 - 14s - loss: 0.5825 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6199 - binary_accuracy_inet_decision_function_fv_metric: 0.6871 - val_loss: 0.5778 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6232 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6968\n",
      "Epoch 56/500\n",
      "35/35 - 14s - loss: 0.5831 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6206 - binary_accuracy_inet_decision_function_fv_metric: 0.6854 - val_loss: 0.5794 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6238 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6942\n",
      "Epoch 57/500\n",
      "35/35 - 14s - loss: 0.5853 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6216 - binary_accuracy_inet_decision_function_fv_metric: 0.6843 - val_loss: 0.5856 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6281 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6874\n",
      "Epoch 58/500\n",
      "35/35 - 14s - loss: 0.5871 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6229 - binary_accuracy_inet_decision_function_fv_metric: 0.6816 - val_loss: 0.5817 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6247 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6909\n",
      "Epoch 59/500\n",
      "35/35 - 14s - loss: 0.5805 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6188 - binary_accuracy_inet_decision_function_fv_metric: 0.6878 - val_loss: 0.5732 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6203 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7016\n",
      "Epoch 60/500\n",
      "35/35 - 14s - loss: 0.5803 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6183 - binary_accuracy_inet_decision_function_fv_metric: 0.6900 - val_loss: 0.5707 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6200 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7033\n",
      "Epoch 61/500\n",
      "35/35 - 14s - loss: 0.5810 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6188 - binary_accuracy_inet_decision_function_fv_metric: 0.6886 - val_loss: 0.5748 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6210 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6975\n",
      "Epoch 62/500\n",
      "35/35 - 14s - loss: 0.5804 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6185 - binary_accuracy_inet_decision_function_fv_metric: 0.6897 - val_loss: 0.5692 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6175 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7028\n",
      "Epoch 63/500\n",
      "35/35 - 14s - loss: 0.5797 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6180 - binary_accuracy_inet_decision_function_fv_metric: 0.6899 - val_loss: 0.5630 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6138 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7091\n",
      "Epoch 64/500\n",
      "35/35 - 14s - loss: 0.5757 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6156 - binary_accuracy_inet_decision_function_fv_metric: 0.6938 - val_loss: 0.5631 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6144 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7093\n",
      "Epoch 65/500\n",
      "35/35 - 14s - loss: 0.5752 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6154 - binary_accuracy_inet_decision_function_fv_metric: 0.6937 - val_loss: 0.5667 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6179 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7079\n",
      "Epoch 66/500\n",
      "35/35 - 14s - loss: 0.5719 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6132 - binary_accuracy_inet_decision_function_fv_metric: 0.6971 - val_loss: 0.5641 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6155 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7099\n",
      "Epoch 67/500\n",
      "35/35 - 14s - loss: 0.5739 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6147 - binary_accuracy_inet_decision_function_fv_metric: 0.6943 - val_loss: 0.5561 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6091 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7099\n",
      "Epoch 68/500\n",
      "35/35 - 14s - loss: 0.5724 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6136 - binary_accuracy_inet_decision_function_fv_metric: 0.6967 - val_loss: 0.5563 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6104 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7170\n",
      "Epoch 69/500\n",
      "35/35 - 14s - loss: 0.5695 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6116 - binary_accuracy_inet_decision_function_fv_metric: 0.6999 - val_loss: 0.5615 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6135 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7108\n",
      "Epoch 70/500\n",
      "35/35 - 14s - loss: 0.5660 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6096 - binary_accuracy_inet_decision_function_fv_metric: 0.7027 - val_loss: 0.5520 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6076 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7188\n",
      "Epoch 71/500\n",
      "35/35 - 14s - loss: 0.5620 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6071 - binary_accuracy_inet_decision_function_fv_metric: 0.7055 - val_loss: 0.5515 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6084 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7210\n",
      "Epoch 72/500\n",
      "35/35 - 14s - loss: 0.5620 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6071 - binary_accuracy_inet_decision_function_fv_metric: 0.7054 - val_loss: 0.5523 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6080 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7188\n",
      "Epoch 73/500\n",
      "35/35 - 14s - loss: 0.5596 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6055 - binary_accuracy_inet_decision_function_fv_metric: 0.7095 - val_loss: 0.5509 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6073 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7228\n",
      "Epoch 74/500\n",
      "35/35 - 14s - loss: 0.5610 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6063 - binary_accuracy_inet_decision_function_fv_metric: 0.7076 - val_loss: 0.5499 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6065 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7219\n",
      "Epoch 75/500\n",
      "35/35 - 14s - loss: 0.5586 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6050 - binary_accuracy_inet_decision_function_fv_metric: 0.7098 - val_loss: 0.5551 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6100 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7189\n",
      "Epoch 76/500\n",
      "35/35 - 14s - loss: 0.5596 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6058 - binary_accuracy_inet_decision_function_fv_metric: 0.7079 - val_loss: 0.5569 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6107 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7163\n",
      "Epoch 77/500\n",
      "35/35 - 14s - loss: 0.5584 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6047 - binary_accuracy_inet_decision_function_fv_metric: 0.7091 - val_loss: 0.5513 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6065 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7197\n",
      "Epoch 78/500\n",
      "35/35 - 14s - loss: 0.5564 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6035 - binary_accuracy_inet_decision_function_fv_metric: 0.7119 - val_loss: 0.5481 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6061 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7256\n",
      "Epoch 79/500\n",
      "35/35 - 14s - loss: 0.5551 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6028 - binary_accuracy_inet_decision_function_fv_metric: 0.7129 - val_loss: 0.5496 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6062 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7225\n",
      "Epoch 80/500\n",
      "35/35 - 14s - loss: 0.5573 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6042 - binary_accuracy_inet_decision_function_fv_metric: 0.7100 - val_loss: 0.5457 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6026 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7221\n",
      "Epoch 81/500\n",
      "35/35 - 14s - loss: 0.5518 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6007 - binary_accuracy_inet_decision_function_fv_metric: 0.7135 - val_loss: 0.5465 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6052 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7244\n",
      "Epoch 82/500\n",
      "35/35 - 14s - loss: 0.5525 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6014 - binary_accuracy_inet_decision_function_fv_metric: 0.7123 - val_loss: 0.5456 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6033 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7232\n",
      "Epoch 83/500\n",
      "35/35 - 14s - loss: 0.5506 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6002 - binary_accuracy_inet_decision_function_fv_metric: 0.7148 - val_loss: 0.5461 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6044 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7236\n",
      "Epoch 84/500\n",
      "35/35 - 14s - loss: 0.5542 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6026 - binary_accuracy_inet_decision_function_fv_metric: 0.7109 - val_loss: 0.5476 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6052 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7195\n",
      "Epoch 85/500\n",
      "35/35 - 14s - loss: 0.5552 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6030 - binary_accuracy_inet_decision_function_fv_metric: 0.7099 - val_loss: 0.5487 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6059 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7210\n",
      "Epoch 86/500\n",
      "35/35 - 14s - loss: 0.5552 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6029 - binary_accuracy_inet_decision_function_fv_metric: 0.7112 - val_loss: 0.5454 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6039 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7234\n",
      "Epoch 87/500\n",
      "35/35 - 14s - loss: 0.5498 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5996 - binary_accuracy_inet_decision_function_fv_metric: 0.7149 - val_loss: 0.5422 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6032 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7248\n",
      "Epoch 88/500\n",
      "35/35 - 14s - loss: 0.5496 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5998 - binary_accuracy_inet_decision_function_fv_metric: 0.7137 - val_loss: 0.5461 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6051 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7212\n",
      "Epoch 89/500\n",
      "35/35 - 14s - loss: 0.5532 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6020 - binary_accuracy_inet_decision_function_fv_metric: 0.7111 - val_loss: 0.5423 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6028 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7238\n",
      "Epoch 90/500\n",
      "35/35 - 14s - loss: 0.5539 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6024 - binary_accuracy_inet_decision_function_fv_metric: 0.7113 - val_loss: 0.5438 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6027 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7253\n",
      "Epoch 91/500\n",
      "35/35 - 14s - loss: 0.5547 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6029 - binary_accuracy_inet_decision_function_fv_metric: 0.7101 - val_loss: 0.5502 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6071 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7218\n",
      "Epoch 92/500\n",
      "35/35 - 14s - loss: 0.5561 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6036 - binary_accuracy_inet_decision_function_fv_metric: 0.7097 - val_loss: 0.5479 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6062 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7233\n",
      "Epoch 93/500\n",
      "35/35 - 14s - loss: 0.5571 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6043 - binary_accuracy_inet_decision_function_fv_metric: 0.7087 - val_loss: 0.5572 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6112 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7117\n",
      "Epoch 94/500\n",
      "35/35 - 14s - loss: 0.5596 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6058 - binary_accuracy_inet_decision_function_fv_metric: 0.7074 - val_loss: 0.5456 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6039 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7243\n",
      "Epoch 95/500\n",
      "35/35 - 14s - loss: 0.5527 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6014 - binary_accuracy_inet_decision_function_fv_metric: 0.7113 - val_loss: 0.5509 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6071 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7206\n",
      "Epoch 96/500\n",
      "35/35 - 14s - loss: 0.5530 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6017 - binary_accuracy_inet_decision_function_fv_metric: 0.7119 - val_loss: 0.5492 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6057 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7208\n",
      "Epoch 97/500\n",
      "35/35 - 14s - loss: 0.5544 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6025 - binary_accuracy_inet_decision_function_fv_metric: 0.7117 - val_loss: 0.5499 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6057 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7168\n",
      "Epoch 98/500\n",
      "35/35 - 14s - loss: 0.5553 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6029 - binary_accuracy_inet_decision_function_fv_metric: 0.7110 - val_loss: 0.5546 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6088 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7149\n",
      "Epoch 99/500\n",
      "35/35 - 14s - loss: 0.5548 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6028 - binary_accuracy_inet_decision_function_fv_metric: 0.7117 - val_loss: 0.5516 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6065 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7211\n",
      "Epoch 100/500\n",
      "35/35 - 14s - loss: 0.5512 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6005 - binary_accuracy_inet_decision_function_fv_metric: 0.7146 - val_loss: 0.5504 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6051 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7182\n",
      "Epoch 101/500\n",
      "35/35 - 14s - loss: 0.5510 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6006 - binary_accuracy_inet_decision_function_fv_metric: 0.7144 - val_loss: 0.5505 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6076 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7246\n",
      "Epoch 102/500\n",
      "35/35 - 14s - loss: 0.5487 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5990 - binary_accuracy_inet_decision_function_fv_metric: 0.7164 - val_loss: 0.5447 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6033 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7251\n",
      "Epoch 103/500\n",
      "35/35 - 14s - loss: 0.5469 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5982 - binary_accuracy_inet_decision_function_fv_metric: 0.7182 - val_loss: 0.5464 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6036 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7239\n",
      "Epoch 104/500\n",
      "35/35 - 14s - loss: 0.5469 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5979 - binary_accuracy_inet_decision_function_fv_metric: 0.7179 - val_loss: 0.5434 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6021 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7250\n",
      "Epoch 105/500\n",
      "35/35 - 14s - loss: 0.5481 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5987 - binary_accuracy_inet_decision_function_fv_metric: 0.7164 - val_loss: 0.5425 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6018 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7295\n",
      "Epoch 106/500\n",
      "35/35 - 14s - loss: 0.5508 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6002 - binary_accuracy_inet_decision_function_fv_metric: 0.7164 - val_loss: 0.5481 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6062 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7253\n",
      "Epoch 107/500\n",
      "35/35 - 14s - loss: 0.5509 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6003 - binary_accuracy_inet_decision_function_fv_metric: 0.7157 - val_loss: 0.5467 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6042 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7236\n",
      "Epoch 108/500\n",
      "35/35 - 14s - loss: 0.5466 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5977 - binary_accuracy_inet_decision_function_fv_metric: 0.7190 - val_loss: 0.5420 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6014 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7286\n",
      "Epoch 109/500\n",
      "35/35 - 14s - loss: 0.5456 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5971 - binary_accuracy_inet_decision_function_fv_metric: 0.7207 - val_loss: 0.5435 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6028 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7276\n",
      "Epoch 110/500\n",
      "35/35 - 14s - loss: 0.5446 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5965 - binary_accuracy_inet_decision_function_fv_metric: 0.7196 - val_loss: 0.5452 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6027 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7223\n",
      "Epoch 111/500\n",
      "35/35 - 14s - loss: 0.5456 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5973 - binary_accuracy_inet_decision_function_fv_metric: 0.7194 - val_loss: 0.5468 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6046 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7245\n",
      "Epoch 112/500\n",
      "35/35 - 14s - loss: 0.5483 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5989 - binary_accuracy_inet_decision_function_fv_metric: 0.7158 - val_loss: 0.5477 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6052 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7220\n",
      "Epoch 113/500\n",
      "35/35 - 14s - loss: 0.5487 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5994 - binary_accuracy_inet_decision_function_fv_metric: 0.7157 - val_loss: 0.5442 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6030 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7265\n",
      "Epoch 114/500\n",
      "35/35 - 14s - loss: 0.5453 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5971 - binary_accuracy_inet_decision_function_fv_metric: 0.7193 - val_loss: 0.5460 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6043 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7228\n",
      "Epoch 115/500\n",
      "35/35 - 14s - loss: 0.5455 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5973 - binary_accuracy_inet_decision_function_fv_metric: 0.7176 - val_loss: 0.5397 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5995 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7309\n",
      "Epoch 116/500\n",
      "35/35 - 14s - loss: 0.5439 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5963 - binary_accuracy_inet_decision_function_fv_metric: 0.7201 - val_loss: 0.5443 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6038 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7246\n",
      "Epoch 117/500\n",
      "35/35 - 14s - loss: 0.5453 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5969 - binary_accuracy_inet_decision_function_fv_metric: 0.7195 - val_loss: 0.5427 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6023 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7271\n",
      "Epoch 118/500\n",
      "35/35 - 14s - loss: 0.5472 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5983 - binary_accuracy_inet_decision_function_fv_metric: 0.7174 - val_loss: 0.5453 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6045 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7268\n",
      "Epoch 119/500\n",
      "35/35 - 14s - loss: 0.5468 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5981 - binary_accuracy_inet_decision_function_fv_metric: 0.7176 - val_loss: 0.5493 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6063 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7223\n",
      "Epoch 120/500\n",
      "35/35 - 14s - loss: 0.5494 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5996 - binary_accuracy_inet_decision_function_fv_metric: 0.7153 - val_loss: 0.5469 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6043 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7232\n",
      "Epoch 121/500\n",
      "35/35 - 14s - loss: 0.5494 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5996 - binary_accuracy_inet_decision_function_fv_metric: 0.7148 - val_loss: 0.5489 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6067 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7223\n",
      "Epoch 122/500\n",
      "35/35 - 14s - loss: 0.5464 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5978 - binary_accuracy_inet_decision_function_fv_metric: 0.7176 - val_loss: 0.5432 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6021 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7277\n",
      "Epoch 123/500\n",
      "35/35 - 14s - loss: 0.5467 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5979 - binary_accuracy_inet_decision_function_fv_metric: 0.7171 - val_loss: 0.5531 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6089 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7168\n",
      "Epoch 124/500\n",
      "35/35 - 14s - loss: 0.5471 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5981 - binary_accuracy_inet_decision_function_fv_metric: 0.7182 - val_loss: 0.5456 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6042 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7270\n",
      "Epoch 125/500\n",
      "35/35 - 14s - loss: 0.5426 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5953 - binary_accuracy_inet_decision_function_fv_metric: 0.7224 - val_loss: 0.5436 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6026 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7249\n",
      "Epoch 126/500\n",
      "35/35 - 14s - loss: 0.5426 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5957 - binary_accuracy_inet_decision_function_fv_metric: 0.7206 - val_loss: 0.5392 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5991 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7292\n",
      "Epoch 127/500\n",
      "35/35 - 14s - loss: 0.5428 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5956 - binary_accuracy_inet_decision_function_fv_metric: 0.7204 - val_loss: 0.5436 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6034 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7265\n",
      "Epoch 128/500\n",
      "35/35 - 14s - loss: 0.5441 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5964 - binary_accuracy_inet_decision_function_fv_metric: 0.7200 - val_loss: 0.5481 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6059 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7234\n",
      "Epoch 129/500\n",
      "35/35 - 14s - loss: 0.5430 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5959 - binary_accuracy_inet_decision_function_fv_metric: 0.7205 - val_loss: 0.5461 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6043 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7233\n",
      "Epoch 130/500\n",
      "35/35 - 14s - loss: 0.5449 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5969 - binary_accuracy_inet_decision_function_fv_metric: 0.7201 - val_loss: 0.5444 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6032 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7257\n",
      "Epoch 131/500\n",
      "35/35 - 14s - loss: 0.5438 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5963 - binary_accuracy_inet_decision_function_fv_metric: 0.7209 - val_loss: 0.5469 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6050 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7246\n",
      "Epoch 132/500\n",
      "35/35 - 14s - loss: 0.5405 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5943 - binary_accuracy_inet_decision_function_fv_metric: 0.7230 - val_loss: 0.5419 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6024 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7265\n",
      "Epoch 133/500\n",
      "35/35 - 14s - loss: 0.5423 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5953 - binary_accuracy_inet_decision_function_fv_metric: 0.7222 - val_loss: 0.5428 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6017 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7236\n",
      "Epoch 134/500\n",
      "35/35 - 14s - loss: 0.5447 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5968 - binary_accuracy_inet_decision_function_fv_metric: 0.7202 - val_loss: 0.5387 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5993 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7300\n",
      "Epoch 135/500\n",
      "35/35 - 14s - loss: 0.5436 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5959 - binary_accuracy_inet_decision_function_fv_metric: 0.7208 - val_loss: 0.5415 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6019 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7270\n",
      "Epoch 136/500\n",
      "35/35 - 14s - loss: 0.5438 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5962 - binary_accuracy_inet_decision_function_fv_metric: 0.7203 - val_loss: 0.5483 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6057 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7202\n",
      "Epoch 137/500\n",
      "35/35 - 14s - loss: 0.5456 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5975 - binary_accuracy_inet_decision_function_fv_metric: 0.7190 - val_loss: 0.5461 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6048 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7206\n",
      "Epoch 138/500\n",
      "35/35 - 14s - loss: 0.5461 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5976 - binary_accuracy_inet_decision_function_fv_metric: 0.7181 - val_loss: 0.5458 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6048 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7229\n",
      "Epoch 139/500\n",
      "35/35 - 14s - loss: 0.5467 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5980 - binary_accuracy_inet_decision_function_fv_metric: 0.7176 - val_loss: 0.5500 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6071 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7213\n",
      "Epoch 140/500\n",
      "35/35 - 14s - loss: 0.5487 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5994 - binary_accuracy_inet_decision_function_fv_metric: 0.7155 - val_loss: 0.5499 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6066 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7208\n",
      "Epoch 141/500\n",
      "35/35 - 14s - loss: 0.5449 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5970 - binary_accuracy_inet_decision_function_fv_metric: 0.7199 - val_loss: 0.5439 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6031 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7276\n",
      "Epoch 142/500\n",
      "35/35 - 14s - loss: 0.5419 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5949 - binary_accuracy_inet_decision_function_fv_metric: 0.7227 - val_loss: 0.5393 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6005 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7301\n",
      "Epoch 143/500\n",
      "35/35 - 14s - loss: 0.5398 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5937 - binary_accuracy_inet_decision_function_fv_metric: 0.7239 - val_loss: 0.5426 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6020 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7253\n",
      "Epoch 144/500\n",
      "35/35 - 14s - loss: 0.5424 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5952 - binary_accuracy_inet_decision_function_fv_metric: 0.7238 - val_loss: 0.5412 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6004 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7271\n",
      "Epoch 145/500\n",
      "35/35 - 14s - loss: 0.5429 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5954 - binary_accuracy_inet_decision_function_fv_metric: 0.7224 - val_loss: 0.5450 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6042 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7285\n",
      "Epoch 146/500\n",
      "35/35 - 14s - loss: 0.5468 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5979 - binary_accuracy_inet_decision_function_fv_metric: 0.7200 - val_loss: 0.5483 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6051 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7207\n",
      "Epoch 147/500\n",
      "35/35 - 14s - loss: 0.5453 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5971 - binary_accuracy_inet_decision_function_fv_metric: 0.7195 - val_loss: 0.5398 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6002 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7271\n",
      "Epoch 148/500\n",
      "35/35 - 14s - loss: 0.5410 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5941 - binary_accuracy_inet_decision_function_fv_metric: 0.7244 - val_loss: 0.5444 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6030 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7270\n",
      "Epoch 149/500\n",
      "35/35 - 14s - loss: 0.5426 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5954 - binary_accuracy_inet_decision_function_fv_metric: 0.7219 - val_loss: 0.5450 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6028 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7243\n",
      "Epoch 150/500\n",
      "35/35 - 14s - loss: 0.5446 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5969 - binary_accuracy_inet_decision_function_fv_metric: 0.7198 - val_loss: 0.5489 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6058 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7215\n",
      "Epoch 151/500\n",
      "35/35 - 14s - loss: 0.5471 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5984 - binary_accuracy_inet_decision_function_fv_metric: 0.7163 - val_loss: 0.5491 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6063 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7216\n",
      "Epoch 152/500\n",
      "35/35 - 14s - loss: 0.5473 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5982 - binary_accuracy_inet_decision_function_fv_metric: 0.7187 - val_loss: 0.5458 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6043 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7259\n",
      "Epoch 153/500\n",
      "35/35 - 15s - loss: 0.5455 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5970 - binary_accuracy_inet_decision_function_fv_metric: 0.7205 - val_loss: 0.5460 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6042 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7255\n",
      "Epoch 154/500\n",
      "35/35 - 14s - loss: 0.5433 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5957 - binary_accuracy_inet_decision_function_fv_metric: 0.7231 - val_loss: 0.5456 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6043 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7230\n",
      "Epoch 155/500\n",
      "35/35 - 14s - loss: 0.5478 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5987 - binary_accuracy_inet_decision_function_fv_metric: 0.7163 - val_loss: 0.5423 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6022 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7231\n",
      "Epoch 156/500\n",
      "35/35 - 14s - loss: 0.5459 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5977 - binary_accuracy_inet_decision_function_fv_metric: 0.7171 - val_loss: 0.5424 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6021 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7251\n",
      "Epoch 157/500\n",
      "35/35 - 14s - loss: 0.5466 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5981 - binary_accuracy_inet_decision_function_fv_metric: 0.7155 - val_loss: 0.5515 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6076 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7151\n",
      "Epoch 158/500\n",
      "35/35 - 14s - loss: 0.5481 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5989 - binary_accuracy_inet_decision_function_fv_metric: 0.7155 - val_loss: 0.5444 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6032 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7252\n",
      "Epoch 159/500\n",
      "35/35 - 14s - loss: 0.5459 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5974 - binary_accuracy_inet_decision_function_fv_metric: 0.7183 - val_loss: 0.5436 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6028 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7240\n",
      "Epoch 160/500\n",
      "35/35 - 14s - loss: 0.5416 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5946 - binary_accuracy_inet_decision_function_fv_metric: 0.7224 - val_loss: 0.5391 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6008 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7279\n",
      "Epoch 161/500\n",
      "35/35 - 14s - loss: 0.5388 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5930 - binary_accuracy_inet_decision_function_fv_metric: 0.7247 - val_loss: 0.5388 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6001 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7299\n",
      "Epoch 162/500\n",
      "35/35 - 14s - loss: 0.5412 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5945 - binary_accuracy_inet_decision_function_fv_metric: 0.7228 - val_loss: 0.5448 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6034 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7251\n",
      "Epoch 163/500\n",
      "35/35 - 14s - loss: 0.5408 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5942 - binary_accuracy_inet_decision_function_fv_metric: 0.7228 - val_loss: 0.5398 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6009 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7281\n",
      "Epoch 164/500\n",
      "35/35 - 14s - loss: 0.5418 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5950 - binary_accuracy_inet_decision_function_fv_metric: 0.7220 - val_loss: 0.5362 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5983 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7311\n",
      "Epoch 165/500\n",
      "35/35 - 14s - loss: 0.5389 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5931 - binary_accuracy_inet_decision_function_fv_metric: 0.7258 - val_loss: 0.5376 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5981 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7264\n",
      "Epoch 166/500\n",
      "35/35 - 14s - loss: 0.5406 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5940 - binary_accuracy_inet_decision_function_fv_metric: 0.7237 - val_loss: 0.5393 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5999 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7271\n",
      "Epoch 167/500\n",
      "35/35 - 14s - loss: 0.5434 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5960 - binary_accuracy_inet_decision_function_fv_metric: 0.7210 - val_loss: 0.5470 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6045 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7229\n",
      "Epoch 168/500\n",
      "35/35 - 14s - loss: 0.5482 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5986 - binary_accuracy_inet_decision_function_fv_metric: 0.7172 - val_loss: 0.5436 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6027 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7281\n",
      "Epoch 169/500\n",
      "35/35 - 14s - loss: 0.5417 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5951 - binary_accuracy_inet_decision_function_fv_metric: 0.7234 - val_loss: 0.5435 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6023 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7228\n",
      "Epoch 170/500\n",
      "35/35 - 14s - loss: 0.5447 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5965 - binary_accuracy_inet_decision_function_fv_metric: 0.7202 - val_loss: 0.5449 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6040 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7243\n",
      "Epoch 171/500\n",
      "35/35 - 14s - loss: 0.5472 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5983 - binary_accuracy_inet_decision_function_fv_metric: 0.7176 - val_loss: 0.5451 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6044 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7253\n",
      "Epoch 172/500\n",
      "35/35 - 14s - loss: 0.5486 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5990 - binary_accuracy_inet_decision_function_fv_metric: 0.7170 - val_loss: 0.5491 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6066 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7221\n",
      "Epoch 173/500\n",
      "35/35 - 14s - loss: 0.5481 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5986 - binary_accuracy_inet_decision_function_fv_metric: 0.7174 - val_loss: 0.5499 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6062 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7203\n",
      "Epoch 174/500\n",
      "35/35 - 14s - loss: 0.5449 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5967 - binary_accuracy_inet_decision_function_fv_metric: 0.7223 - val_loss: 0.5415 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6007 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7264\n",
      "Epoch 175/500\n",
      "35/35 - 14s - loss: 0.5418 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5948 - binary_accuracy_inet_decision_function_fv_metric: 0.7238 - val_loss: 0.5400 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6004 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7298\n",
      "Epoch 176/500\n",
      "35/35 - 13s - loss: 0.5418 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5948 - binary_accuracy_inet_decision_function_fv_metric: 0.7251 - val_loss: 0.5407 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6001 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7278\n",
      "Epoch 177/500\n",
      "35/35 - 10s - loss: 0.5423 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5950 - binary_accuracy_inet_decision_function_fv_metric: 0.7235 - val_loss: 0.5441 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6031 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7242\n",
      "Epoch 178/500\n",
      "35/35 - 10s - loss: 0.5430 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5957 - binary_accuracy_inet_decision_function_fv_metric: 0.7233 - val_loss: 0.5451 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6035 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7226\n",
      "Epoch 179/500\n",
      "35/35 - 11s - loss: 0.5417 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5945 - binary_accuracy_inet_decision_function_fv_metric: 0.7251 - val_loss: 0.5398 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6006 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7282\n",
      "Epoch 180/500\n",
      "35/35 - 12s - loss: 0.5400 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5936 - binary_accuracy_inet_decision_function_fv_metric: 0.7265 - val_loss: 0.5423 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6023 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7281\n",
      "Epoch 181/500\n",
      "35/35 - 13s - loss: 0.5414 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5946 - binary_accuracy_inet_decision_function_fv_metric: 0.7248 - val_loss: 0.5402 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6008 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7321\n",
      "Epoch 182/500\n",
      "35/35 - 13s - loss: 0.5422 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5951 - binary_accuracy_inet_decision_function_fv_metric: 0.7248 - val_loss: 0.5402 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6004 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7304\n",
      "Epoch 183/500\n",
      "35/35 - 13s - loss: 0.5432 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5958 - binary_accuracy_inet_decision_function_fv_metric: 0.7238 - val_loss: 0.5440 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6034 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7271\n",
      "Epoch 184/500\n",
      "35/35 - 13s - loss: 0.5422 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5951 - binary_accuracy_inet_decision_function_fv_metric: 0.7240 - val_loss: 0.5381 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5992 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7309\n",
      "Epoch 185/500\n",
      "35/35 - 13s - loss: 0.5412 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5945 - binary_accuracy_inet_decision_function_fv_metric: 0.7243 - val_loss: 0.5407 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6015 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7291\n",
      "Epoch 186/500\n",
      "35/35 - 13s - loss: 0.5378 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5924 - binary_accuracy_inet_decision_function_fv_metric: 0.7267 - val_loss: 0.5379 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6003 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7314\n",
      "Epoch 187/500\n",
      "35/35 - 13s - loss: 0.5413 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5947 - binary_accuracy_inet_decision_function_fv_metric: 0.7228 - val_loss: 0.5442 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6036 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7257\n",
      "Epoch 188/500\n",
      "35/35 - 13s - loss: 0.5416 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5951 - binary_accuracy_inet_decision_function_fv_metric: 0.7236 - val_loss: 0.5443 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6039 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7264\n",
      "Epoch 189/500\n",
      "35/35 - 13s - loss: 0.5424 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5953 - binary_accuracy_inet_decision_function_fv_metric: 0.7235 - val_loss: 0.5469 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6049 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7244\n",
      "Epoch 190/500\n",
      "35/35 - 13s - loss: 0.5443 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5965 - binary_accuracy_inet_decision_function_fv_metric: 0.7218 - val_loss: 0.5401 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6009 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7305\n",
      "Epoch 191/500\n",
      "35/35 - 13s - loss: 0.5397 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5934 - binary_accuracy_inet_decision_function_fv_metric: 0.7259 - val_loss: 0.5379 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5990 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7325\n",
      "Epoch 192/500\n",
      "35/35 - 13s - loss: 0.5386 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5929 - binary_accuracy_inet_decision_function_fv_metric: 0.7272 - val_loss: 0.5401 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6005 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7300\n",
      "Epoch 193/500\n",
      "35/35 - 13s - loss: 0.5401 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5938 - binary_accuracy_inet_decision_function_fv_metric: 0.7255 - val_loss: 0.5413 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6011 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7295\n",
      "Epoch 194/500\n",
      "35/35 - 13s - loss: 0.5425 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5956 - binary_accuracy_inet_decision_function_fv_metric: 0.7230 - val_loss: 0.5435 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6027 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7260\n",
      "Epoch 195/500\n",
      "35/35 - 13s - loss: 0.5452 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5968 - binary_accuracy_inet_decision_function_fv_metric: 0.7223 - val_loss: 0.5415 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6018 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7285\n",
      "Epoch 196/500\n",
      "35/35 - 13s - loss: 0.5420 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5947 - binary_accuracy_inet_decision_function_fv_metric: 0.7243 - val_loss: 0.5404 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6005 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7289\n",
      "Epoch 197/500\n",
      "35/35 - 13s - loss: 0.5397 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5935 - binary_accuracy_inet_decision_function_fv_metric: 0.7267 - val_loss: 0.5418 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6009 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7282\n",
      "Epoch 198/500\n",
      "35/35 - 13s - loss: 0.5394 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5932 - binary_accuracy_inet_decision_function_fv_metric: 0.7266 - val_loss: 0.5401 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6006 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7323\n",
      "Epoch 199/500\n",
      "35/35 - 13s - loss: 0.5398 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5936 - binary_accuracy_inet_decision_function_fv_metric: 0.7264 - val_loss: 0.5433 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6025 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7261\n",
      "Epoch 200/500\n",
      "35/35 - 13s - loss: 0.5397 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5936 - binary_accuracy_inet_decision_function_fv_metric: 0.7267 - val_loss: 0.5451 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6039 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7261\n",
      "Epoch 201/500\n",
      "35/35 - 13s - loss: 0.5372 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5920 - binary_accuracy_inet_decision_function_fv_metric: 0.7293 - val_loss: 0.5351 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5980 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7330\n",
      "Epoch 202/500\n",
      "35/35 - 13s - loss: 0.5387 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5930 - binary_accuracy_inet_decision_function_fv_metric: 0.7263 - val_loss: 0.5386 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5998 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7305\n",
      "Epoch 203/500\n",
      "35/35 - 13s - loss: 0.5417 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5948 - binary_accuracy_inet_decision_function_fv_metric: 0.7245 - val_loss: 0.5400 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6004 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7304\n",
      "Epoch 204/500\n",
      "35/35 - 13s - loss: 0.5396 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5936 - binary_accuracy_inet_decision_function_fv_metric: 0.7261 - val_loss: 0.5415 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6018 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7293\n",
      "Epoch 205/500\n",
      "35/35 - 13s - loss: 0.5401 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5938 - binary_accuracy_inet_decision_function_fv_metric: 0.7257 - val_loss: 0.5409 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6015 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7268\n",
      "Epoch 206/500\n",
      "35/35 - 13s - loss: 0.5407 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5940 - binary_accuracy_inet_decision_function_fv_metric: 0.7249 - val_loss: 0.5435 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6024 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7252\n",
      "Epoch 207/500\n",
      "35/35 - 13s - loss: 0.5479 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5984 - binary_accuracy_inet_decision_function_fv_metric: 0.7191 - val_loss: 0.5542 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6092 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7174\n",
      "Epoch 208/500\n",
      "35/35 - 14s - loss: 0.5474 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5982 - binary_accuracy_inet_decision_function_fv_metric: 0.7193 - val_loss: 0.5466 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6043 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7233\n",
      "Epoch 209/500\n",
      "35/35 - 14s - loss: 0.5420 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5950 - binary_accuracy_inet_decision_function_fv_metric: 0.7248 - val_loss: 0.5398 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5999 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7284\n",
      "Epoch 210/500\n",
      "35/35 - 13s - loss: 0.5440 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5959 - binary_accuracy_inet_decision_function_fv_metric: 0.7224 - val_loss: 0.5452 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6041 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7231\n",
      "Epoch 211/500\n",
      "35/35 - 13s - loss: 0.5393 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5932 - binary_accuracy_inet_decision_function_fv_metric: 0.7260 - val_loss: 0.5366 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5988 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7310\n",
      "Epoch 212/500\n",
      "35/35 - 13s - loss: 0.5440 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5960 - binary_accuracy_inet_decision_function_fv_metric: 0.7232 - val_loss: 0.5411 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6012 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7283\n",
      "Epoch 213/500\n",
      "35/35 - 13s - loss: 0.5443 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5962 - binary_accuracy_inet_decision_function_fv_metric: 0.7228 - val_loss: 0.5460 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6047 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7245\n",
      "Epoch 214/500\n",
      "35/35 - 13s - loss: 0.5453 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5968 - binary_accuracy_inet_decision_function_fv_metric: 0.7208 - val_loss: 0.5497 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6068 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7206\n",
      "Epoch 215/500\n",
      "35/35 - 13s - loss: 0.5466 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5976 - binary_accuracy_inet_decision_function_fv_metric: 0.7202 - val_loss: 0.5491 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6063 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7237\n",
      "Epoch 216/500\n",
      "35/35 - 13s - loss: 0.5469 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5978 - binary_accuracy_inet_decision_function_fv_metric: 0.7201 - val_loss: 0.5508 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6074 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7181\n",
      "Epoch 217/500\n",
      "35/35 - 13s - loss: 0.5445 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5963 - binary_accuracy_inet_decision_function_fv_metric: 0.7223 - val_loss: 0.5437 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6025 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7278\n",
      "Epoch 218/500\n",
      "35/35 - 13s - loss: 0.5426 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5952 - binary_accuracy_inet_decision_function_fv_metric: 0.7248 - val_loss: 0.5475 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6051 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7234\n",
      "Epoch 219/500\n",
      "35/35 - 13s - loss: 0.5451 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5965 - binary_accuracy_inet_decision_function_fv_metric: 0.7224 - val_loss: 0.5504 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6068 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7216\n",
      "Epoch 220/500\n",
      "35/35 - 13s - loss: 0.5445 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5964 - binary_accuracy_inet_decision_function_fv_metric: 0.7221 - val_loss: 0.5476 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6049 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7218\n",
      "Epoch 221/500\n",
      "35/35 - 13s - loss: 0.5439 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5962 - binary_accuracy_inet_decision_function_fv_metric: 0.7223 - val_loss: 0.5444 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6033 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7265\n",
      "Epoch 222/500\n",
      "35/35 - 13s - loss: 0.5428 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5952 - binary_accuracy_inet_decision_function_fv_metric: 0.7235 - val_loss: 0.5443 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6036 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7270\n",
      "Epoch 223/500\n",
      "35/35 - 12s - loss: 0.5405 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5939 - binary_accuracy_inet_decision_function_fv_metric: 0.7252 - val_loss: 0.5444 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6033 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7239\n",
      "Epoch 224/500\n",
      "35/35 - 13s - loss: 0.5427 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5953 - binary_accuracy_inet_decision_function_fv_metric: 0.7238 - val_loss: 0.5433 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6024 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7247\n",
      "Epoch 225/500\n",
      "35/35 - 13s - loss: 0.5452 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5972 - binary_accuracy_inet_decision_function_fv_metric: 0.7195 - val_loss: 0.5458 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6035 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7228\n",
      "Epoch 226/500\n",
      "35/35 - 13s - loss: 0.5434 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5957 - binary_accuracy_inet_decision_function_fv_metric: 0.7218 - val_loss: 0.5471 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6044 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7208\n",
      "Epoch 227/500\n",
      "35/35 - 13s - loss: 0.5420 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5950 - binary_accuracy_inet_decision_function_fv_metric: 0.7234 - val_loss: 0.5429 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6026 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7237\n",
      "Epoch 228/500\n",
      "35/35 - 13s - loss: 0.5428 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5956 - binary_accuracy_inet_decision_function_fv_metric: 0.7232 - val_loss: 0.5515 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6074 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7151\n",
      "Epoch 229/500\n",
      "35/35 - 13s - loss: 0.5445 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5963 - binary_accuracy_inet_decision_function_fv_metric: 0.7214 - val_loss: 0.5475 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6049 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7235\n",
      "Epoch 230/500\n",
      "35/35 - 13s - loss: 0.5413 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5947 - binary_accuracy_inet_decision_function_fv_metric: 0.7230 - val_loss: 0.5421 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6019 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7251\n",
      "Epoch 231/500\n",
      "35/35 - 13s - loss: 0.5381 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5926 - binary_accuracy_inet_decision_function_fv_metric: 0.7269 - val_loss: 0.5462 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6042 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7221\n",
      "Epoch 232/500\n",
      "35/35 - 13s - loss: 0.5420 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5949 - binary_accuracy_inet_decision_function_fv_metric: 0.7236 - val_loss: 0.5471 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6047 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7215\n",
      "Epoch 233/500\n",
      "35/35 - 13s - loss: 0.5390 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5927 - binary_accuracy_inet_decision_function_fv_metric: 0.7266 - val_loss: 0.5430 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6021 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7272\n",
      "Epoch 234/500\n",
      "35/35 - 13s - loss: 0.5397 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5938 - binary_accuracy_inet_decision_function_fv_metric: 0.7250 - val_loss: 0.5424 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6021 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7261\n",
      "Epoch 235/500\n",
      "35/35 - 13s - loss: 0.5396 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5934 - binary_accuracy_inet_decision_function_fv_metric: 0.7258 - val_loss: 0.5455 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6035 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7228\n",
      "Epoch 236/500\n",
      "35/35 - 13s - loss: 0.5364 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5915 - binary_accuracy_inet_decision_function_fv_metric: 0.7285 - val_loss: 0.5404 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6001 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7280\n",
      "Epoch 237/500\n",
      "35/35 - 13s - loss: 0.5399 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5938 - binary_accuracy_inet_decision_function_fv_metric: 0.7249 - val_loss: 0.5462 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6043 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7222\n",
      "Epoch 238/500\n",
      "35/35 - 13s - loss: 0.5410 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5944 - binary_accuracy_inet_decision_function_fv_metric: 0.7235 - val_loss: 0.5466 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6046 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7198\n",
      "Epoch 239/500\n",
      "35/35 - 13s - loss: 0.5399 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5940 - binary_accuracy_inet_decision_function_fv_metric: 0.7238 - val_loss: 0.5441 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6030 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7252\n",
      "Epoch 240/500\n",
      "35/35 - 13s - loss: 0.5382 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5928 - binary_accuracy_inet_decision_function_fv_metric: 0.7255 - val_loss: 0.5388 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6001 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7277\n",
      "Epoch 241/500\n",
      "35/35 - 13s - loss: 0.5410 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5943 - binary_accuracy_inet_decision_function_fv_metric: 0.7231 - val_loss: 0.5461 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6046 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7207\n",
      "Epoch 242/500\n",
      "35/35 - 13s - loss: 0.5400 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5939 - binary_accuracy_inet_decision_function_fv_metric: 0.7248 - val_loss: 0.5442 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6027 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7233\n",
      "Epoch 243/500\n",
      "35/35 - 13s - loss: 0.5400 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5939 - binary_accuracy_inet_decision_function_fv_metric: 0.7251 - val_loss: 0.5417 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6006 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7267\n",
      "Epoch 244/500\n",
      "35/35 - 13s - loss: 0.5395 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5935 - binary_accuracy_inet_decision_function_fv_metric: 0.7259 - val_loss: 0.5433 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6011 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7254\n",
      "Epoch 245/500\n",
      "35/35 - 13s - loss: 0.5399 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5938 - binary_accuracy_inet_decision_function_fv_metric: 0.7250 - val_loss: 0.5448 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6037 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7244\n",
      "Epoch 246/500\n",
      "35/35 - 13s - loss: 0.5405 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5942 - binary_accuracy_inet_decision_function_fv_metric: 0.7253 - val_loss: 0.5385 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5991 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7299\n",
      "Epoch 247/500\n",
      "35/35 - 13s - loss: 0.5394 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5933 - binary_accuracy_inet_decision_function_fv_metric: 0.7251 - val_loss: 0.5456 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6040 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7204\n",
      "Epoch 248/500\n",
      "35/35 - 13s - loss: 0.5390 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5931 - binary_accuracy_inet_decision_function_fv_metric: 0.7267 - val_loss: 0.5431 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6021 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7248\n",
      "Epoch 249/500\n",
      "35/35 - 13s - loss: 0.5406 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5942 - binary_accuracy_inet_decision_function_fv_metric: 0.7246 - val_loss: 0.5443 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6029 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7248\n",
      "Epoch 250/500\n",
      "35/35 - 13s - loss: 0.5386 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5929 - binary_accuracy_inet_decision_function_fv_metric: 0.7256 - val_loss: 0.5425 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6018 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7253\n",
      "Epoch 251/500\n",
      "35/35 - 13s - loss: 0.5366 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.5918 - binary_accuracy_inet_decision_function_fv_metric: 0.7287 - val_loss: 0.5454 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6029 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7254\n",
      "Training Time: 0:57:31\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model,\n",
    " encoder_model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=['tensorboard'] #plot_losses\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:40:10.847374Z",
     "iopub.status.busy": "2022-01-03T15:40:10.847172Z",
     "iopub.status.idle": "2022-01-03T15:40:11.138131Z",
     "shell.execute_reply": "2022-01-03T15:40:11.137512Z",
     "shell.execute_reply.started": "2022-01-03T15:40:10.847349Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "        \n",
    "    writepath_nas = './results_nas.csv'\n",
    "\n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "\n",
    "    if not os.path.exists(writepath_nas):\n",
    "        with open(writepath_nas, 'w+') as text_file:       \n",
    "            for key in flat_config.keys():\n",
    "                text_file.write(key)\n",
    "                text_file.write(';')         \n",
    "\n",
    "            for hp in history[0].hyperparameters.values.keys():\n",
    "                text_file.write(hp + ';')    \n",
    "               \n",
    "            text_file.write('score')\n",
    "            \n",
    "            text_file.write('\\n')\n",
    "            \n",
    "            \n",
    "\n",
    "    with open(writepath_nas, 'a+') as text_file:  \n",
    "        for value in flat_config.values():\n",
    "            text_file.write(str(value))\n",
    "            text_file.write(';')\n",
    "\n",
    "        for hp, value in history[0].hyperparameters.values.items():\n",
    "            text_file.write(str(value) + ';')        \n",
    "\n",
    "        \n",
    "        text_file.write(str(history[0].score))\n",
    "            \n",
    "        text_file.write('\\n')            \n",
    "\n",
    "        text_file.close()      \n",
    "        \n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:40:11.139676Z",
     "iopub.status.busy": "2022-01-03T15:40:11.139399Z",
     "iopub.status.idle": "2022-01-03T15:40:11.827288Z",
     "shell.execute_reply": "2022-01-03T15:40:11.826410Z",
     "shell.execute_reply.started": "2022-01-03T15:40:11.139645Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 3\n",
    "network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data(network_parameters, config, encoder_model)    \n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:40:11.828974Z",
     "iopub.status.busy": "2022-01-03T15:40:11.828690Z",
     "iopub.status.idle": "2022-01-03T15:40:11.856633Z",
     "shell.execute_reply": "2022-01-03T15:40:11.856000Z",
     "shell.execute_reply.started": "2022-01-03T15:40:11.828943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 1409)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_1024 (Dense)            (None, 1024)         1443840     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation1_relu (Activation)   (None, 1024)         0           hidden1_1024[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout1_0.3 (Dropout)          (None, 1024)         0           activation1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_1024 (Dense)            (None, 1024)         1049600     dropout1_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation2_relu (Activation)   (None, 1024)         0           hidden2_1024[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout2_0.3 (Dropout)          (None, 1024)         0           activation2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden3_256 (Dense)             (None, 256)          262400      dropout2_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation3_relu (Activation)   (None, 256)          0           hidden3_256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout3_0.3 (Dropout)          (None, 256)          0           activation3_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden4_2048 (Dense)            (None, 2048)         526336      dropout3_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation4_relu (Activation)   (None, 2048)         0           hidden4_2048[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout4_0.3 (Dropout)          (None, 2048)         0           activation4_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden5_2048 (Dense)            (None, 2048)         4196352     dropout4_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation5_relu (Activation)   (None, 2048)         0           hidden5_2048[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout5_0.3 (Dropout)          (None, 2048)         0           activation5_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_coeff_135 (Dense)        (None, 135)          276615      dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_1 (Dense)     (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_2 (Dense)     (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_3 (Dense)     (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_4 (Dense)     (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_5 (Dense)     (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_6 (Dense)     (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_7 (Dense)     (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_8 (Dense)     (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_9 (Dense)     (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_10 (Dense)    (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_11 (Dense)    (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_12 (Dense)    (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_13 (Dense)    (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_14 (Dense)    (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_15 (Dense)    (None, 9)            18441       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_bias_15 (Dense)          (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_nodes_32 (Dense)    (None, 32)           65568       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_combined (Concatenate)   (None, 317)          0           output_coeff_135[0][0]           \n",
      "                                                                 output_identifier_1[0][0]        \n",
      "                                                                 output_identifier_2[0][0]        \n",
      "                                                                 output_identifier_3[0][0]        \n",
      "                                                                 output_identifier_4[0][0]        \n",
      "                                                                 output_identifier_5[0][0]        \n",
      "                                                                 output_identifier_6[0][0]        \n",
      "                                                                 output_identifier_7[0][0]        \n",
      "                                                                 output_identifier_8[0][0]        \n",
      "                                                                 output_identifier_9[0][0]        \n",
      "                                                                 output_identifier_10[0][0]       \n",
      "                                                                 output_identifier_11[0][0]       \n",
      "                                                                 output_identifier_12[0][0]       \n",
      "                                                                 output_identifier_13[0][0]       \n",
      "                                                                 output_identifier_14[0][0]       \n",
      "                                                                 output_identifier_15[0][0]       \n",
      "                                                                 output_bias_15[0][0]             \n",
      "                                                                 output_leaf_nodes_32[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 8,128,061\n",
      "Trainable params: 8,128,061\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:40:11.857973Z",
     "iopub.status.busy": "2022-01-03T15:40:11.857703Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=7)]: Done  11 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed: 17.0min\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_train.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    \n",
    "    network_parameters = np.array(lambda_net_dataset_train.network_parameters_array[:number])\n",
    "    if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "    elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "        network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "    dt_inet_list = model.predict(network_parameters)   \n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    \n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=10, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_train.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_train.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_train = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict_train == None:\n",
    "            inet_evaluation_result_dict_train = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict_train = mergeDict(inet_evaluation_result_dict_train, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict_train['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean_train = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict_train.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean_train[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean_train[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean_train[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('TRAIN DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_train = np.round(np.mean(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "std_train = np.round(np.std(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "\n",
    "z_score_aggregate_list = []\n",
    "distance_to_initialization_aggregate_list = []\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "max_distance_to_neuron_average_list = []\n",
    "max_distance_to_neuron_min_list = []\n",
    "\n",
    "for network in tqdm(lambda_net_dataset_train.network_parameters_array[:100]):\n",
    "    (z_score_aggregate, \n",
    "     distance_to_initialization_aggregate, \n",
    "     distance_to_sample_average, \n",
    "     distance_to_sample_min, \n",
    "     max_distance_to_neuron_average,\n",
    "     max_distance_to_neuron_min) = calculate_network_distance(mean=mean_train, \n",
    "                                                               std=std_train, \n",
    "                                                               network_parameters=network, \n",
    "                                                               lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               config=config)    \n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)  \n",
    "    max_distance_to_neuron_average_list.append(max_distance_to_neuron_average)\n",
    "    max_distance_to_neuron_min_list.append(max_distance_to_neuron_min)\n",
    "    \n",
    "z_score_average_train = np.mean(z_score_aggregate_list)\n",
    "distance_to_initialization_average_train = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_average_train = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_train = np.mean(distance_to_sample_min_list)\n",
    "\n",
    "max_distance_to_neuron_average_average_train = np.mean(max_distance_to_neuron_average_list)\n",
    "max_distance_to_neuron_min_average_train = np.mean(max_distance_to_neuron_min_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_valid.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    \n",
    "    network_parameters = np.array(lambda_net_dataset_valid.network_parameters_array[:number])\n",
    "    if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "    elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "        network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "    dt_inet_list = model.predict(network_parameters)  \n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_valid.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_valid.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_valid = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict_valid == None:\n",
    "            inet_evaluation_result_dict_valid = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict_valid = mergeDict(inet_evaluation_result_dict_valid, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict_valid['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean_valid = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict_valid.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean_valid[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean_valid[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean_valid[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('VALID DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_score_aggregate_list = []\n",
    "distance_to_initialization_aggregate_list = []\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "max_distance_to_neuron_average_list = []\n",
    "max_distance_to_neuron_min_list = []\n",
    "\n",
    "for network in tqdm(lambda_net_dataset_valid.network_parameters_array[:100]):\n",
    "    (z_score_aggregate, \n",
    "     distance_to_initialization_aggregate, \n",
    "     distance_to_sample_average, \n",
    "     distance_to_sample_min, \n",
    "     max_distance_to_neuron_average,\n",
    "     max_distance_to_neuron_min) = calculate_network_distance(mean=mean_train, \n",
    "                                                               std=std_train, \n",
    "                                                               network_parameters=network, \n",
    "                                                               lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               config=config)    \n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)  \n",
    "    max_distance_to_neuron_average_list.append(max_distance_to_neuron_average)\n",
    "    max_distance_to_neuron_min_list.append(max_distance_to_neuron_min)\n",
    "    \n",
    "z_score_average_valid = np.mean(z_score_aggregate_list)\n",
    "distance_to_initialization_average_valid = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_average_valid = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_valid = np.mean(distance_to_sample_min_list)\n",
    "\n",
    "max_distance_to_neuron_average_average_valid = np.mean(max_distance_to_neuron_average_list)\n",
    "max_distance_to_neuron_min_average_valid = np.mean(max_distance_to_neuron_min_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = lambda_net_dataset_test.X_test_lambda_array.shape[0]#10\n",
    "\n",
    "    start_inet = time.time() \n",
    "    \n",
    "    network_parameters = np.array(lambda_net_dataset_test.network_parameters_array[:number])\n",
    "    if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "    elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "        network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "    dt_inet_list = model.predict(network_parameters)  \n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_test.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_test.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_test = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict_test == None:\n",
    "            inet_evaluation_result_dict_test = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict_test = mergeDict(inet_evaluation_result_dict_test, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict_test['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean_test = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict_test.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean_test[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean_test[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean_test[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('TEST DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_score_aggregate_list = []\n",
    "distance_to_initialization_aggregate_list = []\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "max_distance_to_neuron_average_list = []\n",
    "max_distance_to_neuron_min_list = []\n",
    "\n",
    "for network in tqdm(lambda_net_dataset_test.network_parameters_array[:100]):\n",
    "    (z_score_aggregate, \n",
    "     distance_to_initialization_aggregate, \n",
    "     distance_to_sample_average, \n",
    "     distance_to_sample_min, \n",
    "     max_distance_to_neuron_average,\n",
    "     max_distance_to_neuron_min) = calculate_network_distance(mean=mean_train, \n",
    "                                                               std=std_train, \n",
    "                                                               network_parameters=network, \n",
    "                                                               lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               config=config)    \n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)  \n",
    "    max_distance_to_neuron_average_list.append(max_distance_to_neuron_average)\n",
    "    max_distance_to_neuron_min_list.append(max_distance_to_neuron_min)\n",
    "    \n",
    "z_score_average_test = np.mean(z_score_aggregate_list)\n",
    "distance_to_initialization_average_test = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_average_test = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_test = np.mean(distance_to_sample_min_list)\n",
    "\n",
    "max_distance_to_neuron_average_average_test = np.mean(max_distance_to_neuron_average_list)\n",
    "max_distance_to_neuron_min_average_test = np.mean(max_distance_to_neuron_min_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Train', 'Train ', ' Train ', 'Valid', 'Valid ', ' Valid ', 'Test', 'Test ', ' Test ']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Metric', \n",
    "         'Dist. (Random)', 'Dist.', 'I-Net', \n",
    "         'Dist. (Random)', 'Dist.', 'I-Net', \n",
    "         'Dist. (Random)', 'Dist.', 'I-Net'],\n",
    "        ['Soft Binary Crossentropy (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime_median'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime_median'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL DATA EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADULT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "\n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "#adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "#adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 'capital_gain'\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "categorical_features = ['Race', 'Workclass', 'Education', \"Marital Status\", \"Occupation\", \"Relationship\"]#[1, 2, 7]\n",
    "ordinal_features = ['Sex', 'capital_gain']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(adult_data)\n",
    "\n",
    "adult_data = transformer.transform(adult_data)\n",
    "adult_data = pd.DataFrame(adult_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    adult_data[ordinal_feature] = OrdinalEncoder().fit_transform(adult_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "adult_data = adult_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "y_data_adult = adult_data['capital_gain']\n",
    "\n",
    "print(X_data_adult.shape)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_adult.shape[1] > number_of_variables:\n",
    "    #X_data_adult = X_data_adult.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_adult = ExtraTreesClassifier(n_estimators=100,\n",
    "                                      random_state=RANDOM_SEED)\n",
    "    clf_adult = clf_adult.fit(X_data_adult, y_data_adult)\n",
    "\n",
    "    selector_adult = SelectFromModel(clf_adult, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_adult.get_support()   \n",
    "    X_data_adult = X_data_adult.loc[:,feature_idx]\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_adult.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_adult[column_name] = np.zeros(X_data_adult.shape[0])\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_adult:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_adult[column_name].values.reshape(-1, 1))\n",
    "    X_data_adult[column_name] = scaler.transform(X_data_adult[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_adult_with_valid, X_test_adult, y_train_adult_with_valid, y_test_adult = train_test_split(X_data_adult, y_data_adult, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_adult, X_valid_adult, y_train_adult, y_valid_adult = train_test_split(X_train_adult_with_valid, y_train_adult_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_adult.shape, y_train_adult.shape)\n",
    "print(X_valid_adult.shape, y_valid_adult.shape)\n",
    "print(X_test_adult.shape, y_test_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_adult, y_train_adult = oversample.fit_resample(X_train_adult, y_train_adult)\n",
    "\n",
    "    true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "    false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_adult = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_adult.fit(X_train_adult,\n",
    "                                      y_train_adult, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_adult, y_valid_adult),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult_parameters = shaped_network_parameters_to_array(test_network_adult.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "network_parameters = np.array([test_network_adult_parameters])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "test_network_adult_dt_inet = model.predict(network_parameters)[0]    \n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_size_list = [1_000, 10_000, 100_000, 1_000_000, 'TRAIN_DATA']\n",
    "    \n",
    "results_adult_list = []\n",
    "dt_distilled_adult_list = []\n",
    "for dataset_size in dataset_size_list:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_adult.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_adult['inet_scores']['runtime'] = inet_runtime\n",
    "    results_adult_list.append(results_adult)\n",
    "    dt_distilled_adult_list.append(dt_distilled_adult)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_adult['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_adult['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy',  np.round(results_adult['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['binary_crossentropy'], 3), np.round(results_adult['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_adult['dt_scores']['accuracy_data_random'], 3), np.round(results_adult['dt_scores']['accuracy'], 3), np.round(results_adult['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_adult['dt_scores']['f1_score_data_random'], 3), np.round(results_adult['dt_scores']['f1_score'], 3), np.round(results_adult['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n",
    "        \n",
    "adult_evaluation_result_dict = None\n",
    "for some_dict in results_adult_list:\n",
    "    if adult_evaluation_result_dict == None:\n",
    "        adult_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        adult_evaluation_result_dict = mergeDict(adult_evaluation_result_dict, some_dict)\n",
    "\n",
    "#adult_evaluation_result_dict['dataset_size'] = dataset_size_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = flatten_list(['Metric', [['Dist. (Random) ' + str(size), 'Dist. ' + str(size)] for size in dataset_size_list], 'I-Net'])\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft Binary Crossentropy', \n",
    "                      [[np.round(result_dict['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['soft_binary_crossentropy'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['soft_binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Binary Crossentropy',  \n",
    "                      [[np.round(result_dict['dt_scores']['binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['binary_crossentropy'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Accuracy', \n",
    "                      [[np.round(result_dict['dt_scores']['accuracy_data_random'], 3), np.round(result_dict['dt_scores']['accuracy'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['accuracy'], 3)]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      [[np.round(result_dict['dt_scores']['f1_score_data_random'], 3), np.round(result_dict['dt_scores']['f1_score'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['f1_score'], 3)]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      [[np.round(result_dict['dt_scores']['runtime'], 3), np.round(result_dict['dt_scores']['runtime'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['runtime'], 3)])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(z_score_aggregate_adult, \n",
    " distance_to_initialization_aggregate_adult, \n",
    " distance_to_sample_average_adult, \n",
    " distance_to_sample_min_adult,\n",
    " max_distance_to_neuron_average_adult,\n",
    " max_distance_to_neuron_min_adult) = calculate_network_distance(mean=mean_train, \n",
    "                                                       std=std_train, \n",
    "                                                       network_parameters=test_network_adult_parameters, \n",
    "                                                       lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                       config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data', 'Adult Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3), np.round(z_score_aggregate_adult, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3), np.round(distance_to_initialization_aggregate_adult, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3), np.round(distance_to_sample_average_adult, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3), np.round(distance_to_sample_min_adult, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3), np.round(max_distance_to_neuron_average_adult, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3), np.round(max_distance_to_neuron_min_adult, 3)],           \n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_adult_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_adult_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_adult, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_adult.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = titanic_data.drop([\n",
    "                                    'Cabin', \n",
    "                                    'Ticket', \n",
    "                                    'Name', \n",
    "                                    'PassengerId'\n",
    "                                ], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "categorical_features = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features = ['Sex']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(titanic_data)\n",
    "\n",
    "titanic_data = transformer.transform(titanic_data)\n",
    "titanic_data = pd.DataFrame(titanic_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    titanic_data[ordinal_feature] = OrdinalEncoder().fit_transform(titanic_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "titanic_data = titanic_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n",
    "\n",
    "print(X_data_titanic.shape)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_titanic.shape[1] > number_of_variables:\n",
    "    #X_data_titanic = X_data_titanic.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_titanic = ExtraTreesClassifier(n_estimators=100,\n",
    "                                      random_state=RANDOM_SEED)\n",
    "    clf_titanic = clf_titanic.fit(X_data_titanic, y_data_titanic)\n",
    "\n",
    "    selector_titanic = SelectFromModel(clf_titanic, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_titanic.get_support()   \n",
    "    X_data_titanic = X_data_titanic.loc[:,feature_idx]    \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_titanic.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_titanic[column_name] = np.zeros(X_data_titanic.shape[0])\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_titanic:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_titanic[column_name].values.reshape(-1, 1))\n",
    "    X_data_titanic[column_name] = scaler.transform(X_data_titanic[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_titanic_with_valid, X_test_titanic, y_train_titanic_with_valid, y_test_titanic = train_test_split(X_data_titanic, y_data_titanic, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_titanic, X_valid_titanic, y_train_titanic, y_valid_titanic = train_test_split(X_train_titanic_with_valid, y_train_titanic_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_titanic.shape, y_train_titanic.shape)\n",
    "print(X_valid_titanic.shape, y_valid_titanic.shape)\n",
    "print(X_test_titanic.shape, y_test_titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_titanic, y_train_titanic = oversample.fit_resample(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "    false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_titanic = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_titanic.fit(X_train_titanic,\n",
    "                                          y_train_titanic, \n",
    "                                          epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                          batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                          callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                          validation_data=(X_valid_titanic, y_valid_titanic),\n",
    "                                          verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic_parameters = shaped_network_parameters_to_array(test_network_titanic.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "network_parameters = np.array([test_network_titanic_parameters])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "test_network_titanic_dt_inet = model.predict(network_parameters)[0]    \n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_titanic_list = []\n",
    "dt_distilled_titanic_list = []\n",
    "for dataset_size in dataset_size_list:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_titanic.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_titanic['inet_scores']['runtime'] = inet_runtime\n",
    "    results_titanic_list.append(results_titanic)\n",
    "    dt_distilled_titanic_list.append(dt_distilled_titanic)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_titanic['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_titanic['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_titanic['dt_scores']['accuracy_data_random'], 3), np.round(results_titanic['dt_scores']['accuracy'], 3), np.round(results_titanic['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_titanic['dt_scores']['f1_score_data_random'], 3), np.round(results_titanic['dt_scores']['f1_score'], 3), np.round(results_titanic['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "        \n",
    "titanic_evaluation_result_dict = None\n",
    "for some_dict in results_titanic_list:\n",
    "    if titanic_evaluation_result_dict == None:\n",
    "        titanic_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        titanic_evaluation_result_dict = mergeDict(titanic_evaluation_result_dict, some_dict)\n",
    "\n",
    "#titanic_evaluation_result_dict['dataset_size'] = dataset_size_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = flatten_list(['Metric', [['Dist. (Random) ' + str(size), 'Dist. ' + str(size)] for size in dataset_size_list], 'I-Net'])\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft Binary Crossentropy', \n",
    "                      [[np.round(result_dict['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['soft_binary_crossentropy'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Binary Crossentropy',  \n",
    "                      [[np.round(result_dict['dt_scores']['binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['binary_crossentropy'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Accuracy', \n",
    "                      [[np.round(result_dict['dt_scores']['accuracy_data_random'], 3), np.round(result_dict['dt_scores']['accuracy'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['accuracy'], 3)]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      [[np.round(result_dict['dt_scores']['f1_score_data_random'], 3), np.round(result_dict['dt_scores']['f1_score'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['f1_score'], 3)]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      [[np.round(result_dict['dt_scores']['runtime'], 3), np.round(result_dict['dt_scores']['runtime'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['runtime'], 3)])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(z_score_aggregate_titanic, \n",
    " distance_to_initialization_aggregate_titanic, \n",
    " distance_to_sample_average_titanic, \n",
    " distance_to_sample_min_titanic,\n",
    " max_distance_to_neuron_average_titanic,\n",
    " max_distance_to_neuron_min_titanic) = calculate_network_distance(mean=mean_train, \n",
    "                                                       std=std_train, \n",
    "                                                       network_parameters=test_network_titanic_parameters, \n",
    "                                                       lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                       config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data', 'Adult Data', 'Titanic Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3), np.round(z_score_aggregate_adult, 3), np.round(z_score_aggregate_titanic, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3), np.round(distance_to_initialization_aggregate_adult, 3), np.round(distance_to_initialization_aggregate_titanic, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3), np.round(distance_to_sample_average_adult, 3), np.round(distance_to_sample_average_titanic, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3), np.round(distance_to_sample_min_adult, 3), np.round(distance_to_sample_min_titanic, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3), np.round(max_distance_to_neuron_average_adult, 3), np.round(max_distance_to_neuron_average_titanic, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3), np.round(max_distance_to_neuron_min_adult, 3), np.round(max_distance_to_neuron_min_titanic, 3)],           \n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_titanic_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_titanic_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_titanic, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_titanic.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "absenteeism_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           'Weight', \n",
    "                           'Height', \n",
    "                           'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "categorical_features = []#[1, 2, 7]\n",
    "ordinal_features = []\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(absenteeism_data)\n",
    "\n",
    "absenteeism_data = transformer.transform(absenteeism_data)\n",
    "absenteeism_data = pd.DataFrame(absenteeism_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    absenteeism_data[ordinal_feature] = OrdinalEncoder().fit_transform(absenteeism_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "absenteeism_data = absenteeism_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 4) * 1) #absenteeism_data['Absenteeism time in hours']\n",
    "\n",
    "print(X_data_absenteeism.shape)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_absenteeism.shape[1] > number_of_variables:\n",
    "    #X_data_absenteeism = X_data_absenteeism.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_absenteeism = ExtraTreesClassifier(n_estimators=100,\n",
    "                                          random_state=RANDOM_SEED)\n",
    "    clf_absenteeism = clf_absenteeism.fit(X_data_absenteeism, y_data_absenteeism)\n",
    "\n",
    "    selector_absenteeism = SelectFromModel(clf_absenteeism, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_absenteeism.get_support()   \n",
    "    X_data_absenteeism = X_data_absenteeism.loc[:,feature_idx]        \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_absenteeism.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_absenteeism[column_name] = np.zeros(X_data_absenteeism.shape[0])\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_absenteeism:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_absenteeism[column_name].values.reshape(-1, 1))\n",
    "    X_data_absenteeism[column_name] = scaler.transform(X_data_absenteeism[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_absenteeism_with_valid, X_test_absenteeism, y_train_absenteeism_with_valid, y_test_absenteeism = train_test_split(X_data_absenteeism, y_data_absenteeism, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_absenteeism, X_valid_absenteeism, y_train_absenteeism, y_valid_absenteeism = train_test_split(X_train_absenteeism_with_valid, y_train_absenteeism_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_absenteeism.shape, y_train_absenteeism.shape)\n",
    "print(X_valid_absenteeism.shape, y_valid_absenteeism.shape)\n",
    "print(X_test_absenteeism.shape, y_test_absenteeism.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_absenteeism, y_train_absenteeism = oversample.fit_resample(X_train_absenteeism, y_train_absenteeism)\n",
    "\n",
    "    true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "    false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_absenteeism = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_absenteeism.fit(X_train_absenteeism,\n",
    "                                      y_train_absenteeism, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_absenteeism, y_valid_absenteeism),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism_parameters = shaped_network_parameters_to_array(test_network_absenteeism.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "network_parameters = np.array([test_network_absenteeism_parameters])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "test_network_absenteeism_dt_inet = model.predict(network_parameters)[0]  \n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_absenteeism_list = []\n",
    "dt_distilled_absenteeism_list = []\n",
    "for dataset_size in dataset_size_list:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_absenteeism.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_absenteeism['inet_scores']['runtime'] = inet_runtime\n",
    "    results_absenteeism_list.append(results_absenteeism)\n",
    "    dt_distilled_absenteeism_list.append(dt_distilled_absenteeism)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_absenteeism['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_absenteeism['dt_scores']['accuracy_data_random'], 3), np.round(results_absenteeism['dt_scores']['accuracy'], 3), np.round(results_absenteeism['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_absenteeism['dt_scores']['f1_score_data_random'], 3), np.round(results_absenteeism['dt_scores']['f1_score'], 3), np.round(results_absenteeism['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime', np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "\n",
    "    \n",
    "absenteeism_evaluation_result_dict = None\n",
    "for some_dict in results_absenteeism_list:\n",
    "    if absenteeism_evaluation_result_dict == None:\n",
    "        absenteeism_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        absenteeism_evaluation_result_dict = mergeDict(absenteeism_evaluation_result_dict, some_dict)\n",
    "\n",
    "#absenteeism_evaluation_result_dict['dataset_size'] = dataset_size_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = flatten_list(['Metric', [['Dist. (Random) ' + str(size), 'Dist. ' + str(size)] for size in dataset_size_list], 'I-Net'])\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft Binary Crossentropy', \n",
    "                      [[np.round(result_dict['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['soft_binary_crossentropy'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Binary Crossentropy',  \n",
    "                      [[np.round(result_dict['dt_scores']['binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['binary_crossentropy'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Accuracy', \n",
    "                      [[np.round(result_dict['dt_scores']['accuracy_data_random'], 3), np.round(result_dict['dt_scores']['accuracy'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['accuracy'], 3)]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      [[np.round(result_dict['dt_scores']['f1_score_data_random'], 3), np.round(result_dict['dt_scores']['f1_score'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['f1_score'], 3)]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      [[np.round(result_dict['dt_scores']['runtime'], 3), np.round(result_dict['dt_scores']['runtime'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['runtime'], 3)])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(z_score_aggregate_absenteeism, \n",
    " distance_to_initialization_aggregate_absenteeism, \n",
    " distance_to_sample_average_absenteeism, \n",
    " distance_to_sample_min_absenteeism,\n",
    " max_distance_to_neuron_average_absenteeism,\n",
    " max_distance_to_neuron_min_absenteeism) = calculate_network_distance(mean=mean_train, \n",
    "                                                       std=std_train, \n",
    "                                                       network_parameters=test_network_absenteeism_parameters, \n",
    "                                                       lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                       config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data', 'Adult Data', 'Titanic Data', 'Absenteeism Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3), np.round(z_score_aggregate_adult, 3), np.round(z_score_aggregate_titanic, 3), np.round(z_score_aggregate_absenteeism, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3), np.round(distance_to_initialization_aggregate_adult, 3), np.round(distance_to_initialization_aggregate_titanic, 3), np.round(distance_to_initialization_aggregate_absenteeism, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3), np.round(distance_to_sample_average_adult, 3), np.round(distance_to_sample_average_titanic, 3), np.round(distance_to_sample_average_absenteeism, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3), np.round(distance_to_sample_min_adult, 3), np.round(distance_to_sample_min_titanic, 3), np.round(distance_to_sample_min_absenteeism, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3), np.round(max_distance_to_neuron_average_adult, 3), np.round(max_distance_to_neuron_average_titanic, 3), np.round(max_distance_to_neuron_average_absenteeism, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3), np.round(max_distance_to_neuron_min_adult, 3), np.round(max_distance_to_neuron_min_titanic, 3), np.round(max_distance_to_neuron_min_absenteeism, 3)],        \n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_absenteeism_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_absenteeism_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_absenteeism, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_absenteeism.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_size = 10000\n",
    "\n",
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', \n",
    "                   #'Dist. (Random) Adult', \n",
    "                   'Dist. Adult', \n",
    "                   'I-Net Adult',\n",
    "                   #'Dist. (Random) Titanic', \n",
    "                   'Dist. Titanic', \n",
    "                   'I-Net Titanic',                   \n",
    "                   #'Dist. (Random) Absent.', \n",
    "                   'Dist. Absent.', \n",
    "                   'I-Net Absent.',\n",
    "                  ]\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft BC', \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['soft_binary_crossentropy'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['soft_binary_crossentropy'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['soft_binary_crossentropy'], 3),                      \n",
    "                      ]),\n",
    "        flatten_list(['BC',  \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['binary_crossentropy'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['binary_crossentropy'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['binary_crossentropy'], 3),                       \n",
    "                     ]),\n",
    "        flatten_list(['Acc', \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['accuracy'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['accuracy'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['accuracy'], 3),      \n",
    "                     ]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['f1_score'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['f1_score'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['f1_score'], 3),                            \n",
    "                     ]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['runtime'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['runtime'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['runtime'], 3),                            \n",
    "                     ])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if different_eval_data:\n",
    "    flat_config = flatten_dict(config_train)\n",
    "else:\n",
    "    flat_config = flatten_dict(config)    \n",
    "\n",
    "flat_dict_train = flatten_dict(inet_evaluation_result_dict_train)\n",
    "flat_dict_valid = flatten_dict(inet_evaluation_result_dict_valid)\n",
    "flat_dict_test = flatten_dict(inet_evaluation_result_dict_test)\n",
    "\n",
    "\n",
    "#TODO ADD FUNCTION VALUES FOR EACH DATASET SIZE (IN SEPARATE FILE?)\n",
    "#    - COLLECT ERRORS PER NETWORK / FIND FILE WHERE SAVED\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file:       \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key)\n",
    "            text_file.write(';')      \n",
    "        \n",
    "        number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "        for key in flat_dict_train.keys():\n",
    "            if 'function_values' not in key:\n",
    "                for i in range(number_of_evaluated_networks):\n",
    "                    text_file.write(key + '_train_' + str(i) + ';')    \n",
    "                    \n",
    "        number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "        for key in flat_dict_valid.keys():\n",
    "            if 'function_values' not in key:\n",
    "                for i in range(number_of_evaluated_networks):\n",
    "                    text_file.write(key + '_valid_' + str(i) + ';')       \n",
    "                    \n",
    "        number_of_evaluated_networks = np.array(flat_dict_test['inet_scores_binary_crossentropy']).shape[0]\n",
    "        for key in flat_dict_test.keys():\n",
    "            if 'function_values' not in key:\n",
    "                for i in range(number_of_evaluated_networks):\n",
    "                    text_file.write(key + '_test_' + str(i) + ';')        \n",
    "        \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file:  \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "            \n",
    "        \n",
    "    number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_train.items():\n",
    "        if 'function_values' not in key:\n",
    "            for score in values:\n",
    "                text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_valid.items():\n",
    "        if 'function_values' not in key:\n",
    "            for score in values:\n",
    "                text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_test['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_test.items():\n",
    "        if 'function_values' not in key:\n",
    "            for score in values:\n",
    "                text_file.write(str(score) + ';')   \n",
    "                    \n",
    "    text_file.write('\\n')            \n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inet_evaluation_result_dict_mean_train_flat = flatten_dict(inet_evaluation_result_dict_mean_train)\n",
    "inet_evaluation_result_dict_mean_valid_flat = flatten_dict(inet_evaluation_result_dict_mean_valid)\n",
    "inet_evaluation_result_dict_mean_test_flat = flatten_dict(inet_evaluation_result_dict_mean_test)\n",
    "    \n",
    "results_adult_flat = flatten_dict(results_adult)\n",
    "del results_adult_flat['function_values_y_test_inet_dt']\n",
    "del results_adult_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "results_titanic_flat = flatten_dict(results_titanic)\n",
    "del results_titanic_flat['function_values_y_test_inet_dt']\n",
    "del results_titanic_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "results_absenteeism_flat = flatten_dict(results_absenteeism)\n",
    "del results_absenteeism_flat['function_values_y_test_inet_dt']\n",
    "del results_absenteeism_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "adult_evaluation_result_dict_flat = flatten_dict(adult_evaluation_result_dict)\n",
    "del adult_evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "del adult_evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "#del adult_evaluation_result_dict_flat['dataset_size']\n",
    "\n",
    "titanic_evaluation_result_dict_flat = flatten_dict(titanic_evaluation_result_dict)\n",
    "del titanic_evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "del titanic_evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "#del titanic_evaluation_result_dict_flat['dataset_size']\n",
    "\n",
    "absenteeism_evaluation_result_dict_flat = flatten_dict(absenteeism_evaluation_result_dict)\n",
    "del absenteeism_evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "del absenteeism_evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "#del absenteeism_evaluation_result_dict_flat['dataset_size']\n",
    "\n",
    "\n",
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key + ';')\n",
    "         \n",
    "        for key in inet_evaluation_result_dict_mean_train_flat.keys():\n",
    "            text_file.write('train_' + key + ';')\n",
    "        for key in inet_evaluation_result_dict_mean_valid_flat.keys():\n",
    "            text_file.write('valid_' + key + ';')            \n",
    "        for key in inet_evaluation_result_dict_mean_test_flat.keys():\n",
    "            text_file.write('test_' + key + ';')\n",
    "        \n",
    "        for dataset_size in dataset_size_list:\n",
    "            for key in results_adult_flat.keys():\n",
    "                text_file.write(key + '_adult_' + str(dataset_size) + ';')\n",
    "        \n",
    "            for key in results_titanic_flat.keys():\n",
    "                text_file.write(key + '_titanic_' + str(dataset_size) + ';')\n",
    "                \n",
    "            for key in results_absenteeism_flat.keys():\n",
    "                text_file.write(key + '_absenteeism_' + str(dataset_size) + ';')    \n",
    "         \n",
    "        text_file.write('z-score_train' + ';')    \n",
    "        text_file.write('z-score_valid' + ';')    \n",
    "        text_file.write('z-score_test' + ';')    \n",
    "        text_file.write('z-score_adult' + ';')    \n",
    "        text_file.write('z-score_titanic' + ';')    \n",
    "        text_file.write('z-score_absenteeism' + ';')    \n",
    "\n",
    "        text_file.write('dist_to_init_train' + ';')    \n",
    "        text_file.write('dist_to_init_valid' + ';')    \n",
    "        text_file.write('dist_to_init_test' + ';')    \n",
    "        text_file.write('dist_to_init_adult' + ';')    \n",
    "        text_file.write('dist_to_init_titanic' + ';')    \n",
    "        text_file.write('dist_to_init_absenteeism' + ';')    \n",
    "        \n",
    "        text_file.write('avg_dist_to_train_train' + ';')    \n",
    "        text_file.write('avg_dist_to_train_valid' + ';')    \n",
    "        text_file.write('avg_dist_to_train_test' + ';')    \n",
    "        text_file.write('avg_dist_to_train_adult' + ';')    \n",
    "        text_file.write('avg_dist_to_train_titanic' + ';')    \n",
    "        text_file.write('avg_dist_to_train_absenteeism' + ';')    \n",
    "        \n",
    "        text_file.write('min_dist_to_train_sample_train' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_valid' + ';')    \n",
    "        text_file.write('min_dist_to_train_samplee_test' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_adult' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_titanic' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_absenteeism')    \n",
    "        \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "        \n",
    "    for value in inet_evaluation_result_dict_mean_train_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "    for value in inet_evaluation_result_dict_mean_valid_flat.values():\n",
    "        text_file.write(str(value) + ';')            \n",
    "    for value in inet_evaluation_result_dict_mean_test_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "\n",
    "    for i in range(len(dataset_size_list)):\n",
    "        for values in adult_evaluation_result_dict_flat.values():\n",
    "            text_file.write(str(values[i]) + ';')            \n",
    "\n",
    "        for values in titanic_evaluation_result_dict_flat.values():\n",
    "            text_file.write(str(values[i]) + ';')            \n",
    "\n",
    "        for values in absenteeism_evaluation_result_dict_flat.values():\n",
    "            text_file.write(str(values[i]) + ';')            \n",
    "    \n",
    "    text_file.write(str(z_score_average_train) + ';')    \n",
    "    text_file.write(str(z_score_average_valid) + ';')    \n",
    "    text_file.write(str(z_score_average_test) + ';')    \n",
    "    text_file.write(str(z_score_aggregate_adult) + ';')    \n",
    "    text_file.write(str(z_score_aggregate_titanic) + ';')    \n",
    "    text_file.write(str(z_score_aggregate_absenteeism) + ';')    \n",
    "\n",
    "    text_file.write(str(distance_to_initialization_average_train) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_average_valid) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_average_test) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_aggregate_adult) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_aggregate_titanic) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_aggregate_absenteeism) + ';')    \n",
    "\n",
    "    text_file.write(str(distance_to_sample_average_average_train) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_average_valid) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_average_test) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_adult) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_titanic) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_absenteeism) + ';')    \n",
    "\n",
    "    text_file.write(str(distance_to_sample_min_average_train) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_average_valid) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_average_test) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_adult) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_titanic) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_absenteeism))       \n",
    "    \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
