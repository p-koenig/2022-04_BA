{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:48.568693Z",
     "iopub.status.busy": "2021-12-17T08:39:48.568270Z",
     "iopub.status.idle": "2021-12-17T08:39:48.585614Z",
     "shell.execute_reply": "2021-12-17T08:39:48.584733Z",
     "shell.execute_reply.started": "2021-12-17T08:39:48.568617Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 3,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': -1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'SDT', #'SDT', 'SDT'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 30, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [],\n",
    "        \n",
    "        'dt_type_train': 'vanilla', # (None, 'vanilla', 'SDT')\n",
    "        'maximum_depth_train': None, #None or int\n",
    "        'decision_sparsity_train': 1, #None or int\n",
    "        \n",
    "        'function_generation_type': 'random_decision_tree_trained',# 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [2048, 128],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0, 0],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.001,\n",
    "        'loss': 'binary_crossentropy', #mse; soft_mse; binary_crossentropy; soft_binary_crossentropy; 'binary_accuracy'\n",
    "        'metrics': ['binary_crossentropy', 'binary_accuracy'],\n",
    "        \n",
    "        'epochs': 200, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 512,\n",
    "\n",
    "        'interpretation_dataset_size': 10000,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 1, # 1=standard representation; 2=sparse representation with classification for variables\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "        'soft_labels': False,\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 20,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': True,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "            \n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 10,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:48.587586Z",
     "iopub.status.busy": "2021-12-17T08:39:48.587246Z",
     "iopub.status.idle": "2021-12-17T08:39:48.604397Z",
     "shell.execute_reply": "2021-12-17T08:39:48.603561Z",
     "shell.execute_reply.started": "2021-12-17T08:39:48.587548Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:48.606584Z",
     "iopub.status.busy": "2021-12-17T08:39:48.605994Z",
     "iopub.status.idle": "2021-12-17T08:39:52.106119Z",
     "shell.execute_reply": "2021-12-17T08:39:52.105479Z",
     "shell.execute_reply.started": "2021-12-17T08:39:48.606533Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:52.108478Z",
     "iopub.status.busy": "2021-12-17T08:39:52.108181Z",
     "iopub.status.idle": "2021-12-17T08:39:52.114354Z",
     "shell.execute_reply": "2021-12-17T08:39:52.113833Z",
     "shell.execute_reply.started": "2021-12-17T08:39:52.108442Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:52.115955Z",
     "iopub.status.busy": "2021-12-17T08:39:52.115559Z",
     "iopub.status.idle": "2021-12-17T08:39:52.130214Z",
     "shell.execute_reply": "2021-12-17T08:39:52.129745Z",
     "shell.execute_reply.started": "2021-12-17T08:39:52.115923Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:52.131109Z",
     "iopub.status.busy": "2021-12-17T08:39:52.130913Z",
     "iopub.status.idle": "2021-12-17T08:39:52.136939Z",
     "shell.execute_reply": "2021-12-17T08:39:52.136486Z",
     "shell.execute_reply.started": "2021-12-17T08:39:52.131087Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:52.137895Z",
     "iopub.status.busy": "2021-12-17T08:39:52.137683Z",
     "iopub.status.idle": "2021-12-17T08:39:54.607349Z",
     "shell.execute_reply": "2021-12-17T08:39:54.606756Z",
     "shell.execute_reply.started": "2021-12-17T08:39:52.137873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth)  if function_representation_type == 3 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 3 and dt_type == 'SDT'\n",
    "  else None\n",
    "                                                            )\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:54.608367Z",
     "iopub.status.busy": "2021-12-17T08:39:54.608217Z",
     "iopub.status.idle": "2021-12-17T08:39:54.614125Z",
     "shell.execute_reply": "2021-12-17T08:39:54.612966Z",
     "shell.execute_reply.started": "2021-12-17T08:39:54.608347Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets10000_var30_class2_random_decision_tree_trained_xMax1_xMin0_xDistuniform_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense2048-128_drop0-0e200b512_adam\n",
      "lNetSize5000_numLNets10000_var30_class2_random_decision_tree_trained_xMax1_xMin0_xDistuniform_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:54.615693Z",
     "iopub.status.busy": "2021-12-17T08:39:54.615298Z",
     "iopub.status.idle": "2021-12-17T08:39:54.624181Z",
     "shell.execute_reply": "2021-12-17T08:39:54.623267Z",
     "shell.execute_reply.started": "2021-12-17T08:39:54.615662Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:54.628184Z",
     "iopub.status.busy": "2021-12-17T08:39:54.627826Z",
     "iopub.status.idle": "2021-12-17T08:39:54.637525Z",
     "shell.execute_reply": "2021-12-17T08:39:54.636832Z",
     "shell.execute_reply.started": "2021-12-17T08:39:54.628153Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "       \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              config) for network_parameters_row in network_parameters.values)          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    #def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "    #    lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "    \n",
    "    #def initialize_target_function_wrapper(config, lambda_net):\n",
    "    #    lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:39:54.638527Z",
     "iopub.status.busy": "2021-12-17T08:39:54.638364Z",
     "iopub.status.idle": "2021-12-17T08:40:25.248200Z",
     "shell.execute_reply": "2021-12-17T08:40:25.247326Z",
     "shell.execute_reply.started": "2021-12-17T08:39:54.638507Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=10)]: Done 322 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=10)]: Done 5066 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=10)]: Done 10000 out of 10000 | elapsed:   15.3s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "    if False:\n",
    "        lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "    else:\n",
    "        lambda_net_dataset_train_with_valid = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        _, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)   \n",
    "        \n",
    "        \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:40:25.249802Z",
     "iopub.status.busy": "2021-12-17T08:40:25.249494Z",
     "iopub.status.idle": "2021-12-17T08:40:25.256987Z",
     "shell.execute_reply": "2021-12-17T08:40:25.255567Z",
     "shell.execute_reply.started": "2021-12-17T08:40:25.249777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 4332)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:40:25.257917Z",
     "iopub.status.busy": "2021-12-17T08:40:25.257773Z",
     "iopub.status.idle": "2021-12-17T08:40:25.266588Z",
     "shell.execute_reply": "2021-12-17T08:40:25.265340Z",
     "shell.execute_reply.started": "2021-12-17T08:40:25.257898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4332)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:40:25.267569Z",
     "iopub.status.busy": "2021-12-17T08:40:25.267426Z",
     "iopub.status.idle": "2021-12-17T08:40:25.273116Z",
     "shell.execute_reply": "2021-12-17T08:40:25.272173Z",
     "shell.execute_reply.started": "2021-12-17T08:40:25.267550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4332)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:40:25.274337Z",
     "iopub.status.busy": "2021-12-17T08:40:25.273951Z",
     "iopub.status.idle": "2021-12-17T08:40:40.630878Z",
     "shell.execute_reply": "2021-12-17T08:40:40.629768Z",
     "shell.execute_reply.started": "2021-12-17T08:40:25.274316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f0v15</th>\n",
       "      <th>f0v16</th>\n",
       "      <th>f0v17</th>\n",
       "      <th>f0v18</th>\n",
       "      <th>f0v19</th>\n",
       "      <th>f0v20</th>\n",
       "      <th>f0v21</th>\n",
       "      <th>f0v22</th>\n",
       "      <th>f0v23</th>\n",
       "      <th>f0v24</th>\n",
       "      <th>f0v25</th>\n",
       "      <th>f0v26</th>\n",
       "      <th>f0v27</th>\n",
       "      <th>f0v28</th>\n",
       "      <th>f0v29</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f1v15</th>\n",
       "      <th>f1v16</th>\n",
       "      <th>f1v17</th>\n",
       "      <th>f1v18</th>\n",
       "      <th>f1v19</th>\n",
       "      <th>f1v20</th>\n",
       "      <th>f1v21</th>\n",
       "      <th>f1v22</th>\n",
       "      <th>f1v23</th>\n",
       "      <th>f1v24</th>\n",
       "      <th>f1v25</th>\n",
       "      <th>f1v26</th>\n",
       "      <th>f1v27</th>\n",
       "      <th>f1v28</th>\n",
       "      <th>f1v29</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f2v10</th>\n",
       "      <th>f2v11</th>\n",
       "      <th>f2v12</th>\n",
       "      <th>f2v13</th>\n",
       "      <th>f2v14</th>\n",
       "      <th>f2v15</th>\n",
       "      <th>f2v16</th>\n",
       "      <th>f2v17</th>\n",
       "      <th>f2v18</th>\n",
       "      <th>f2v19</th>\n",
       "      <th>f2v20</th>\n",
       "      <th>f2v21</th>\n",
       "      <th>f2v22</th>\n",
       "      <th>f2v23</th>\n",
       "      <th>f2v24</th>\n",
       "      <th>f2v25</th>\n",
       "      <th>f2v26</th>\n",
       "      <th>f2v27</th>\n",
       "      <th>f2v28</th>\n",
       "      <th>f2v29</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_3997</th>\n",
       "      <th>wb_3998</th>\n",
       "      <th>wb_3999</th>\n",
       "      <th>wb_4000</th>\n",
       "      <th>wb_4001</th>\n",
       "      <th>wb_4002</th>\n",
       "      <th>wb_4003</th>\n",
       "      <th>wb_4004</th>\n",
       "      <th>wb_4005</th>\n",
       "      <th>wb_4006</th>\n",
       "      <th>wb_4007</th>\n",
       "      <th>wb_4008</th>\n",
       "      <th>wb_4009</th>\n",
       "      <th>wb_4010</th>\n",
       "      <th>wb_4011</th>\n",
       "      <th>wb_4012</th>\n",
       "      <th>wb_4013</th>\n",
       "      <th>wb_4014</th>\n",
       "      <th>wb_4015</th>\n",
       "      <th>wb_4016</th>\n",
       "      <th>wb_4017</th>\n",
       "      <th>wb_4018</th>\n",
       "      <th>wb_4019</th>\n",
       "      <th>wb_4020</th>\n",
       "      <th>wb_4021</th>\n",
       "      <th>wb_4022</th>\n",
       "      <th>wb_4023</th>\n",
       "      <th>wb_4024</th>\n",
       "      <th>wb_4025</th>\n",
       "      <th>wb_4026</th>\n",
       "      <th>wb_4027</th>\n",
       "      <th>wb_4028</th>\n",
       "      <th>wb_4029</th>\n",
       "      <th>wb_4030</th>\n",
       "      <th>wb_4031</th>\n",
       "      <th>wb_4032</th>\n",
       "      <th>wb_4033</th>\n",
       "      <th>wb_4034</th>\n",
       "      <th>wb_4035</th>\n",
       "      <th>wb_4036</th>\n",
       "      <th>wb_4037</th>\n",
       "      <th>wb_4038</th>\n",
       "      <th>wb_4039</th>\n",
       "      <th>wb_4040</th>\n",
       "      <th>wb_4041</th>\n",
       "      <th>wb_4042</th>\n",
       "      <th>wb_4043</th>\n",
       "      <th>wb_4044</th>\n",
       "      <th>wb_4045</th>\n",
       "      <th>wb_4046</th>\n",
       "      <th>wb_4047</th>\n",
       "      <th>wb_4048</th>\n",
       "      <th>wb_4049</th>\n",
       "      <th>wb_4050</th>\n",
       "      <th>wb_4051</th>\n",
       "      <th>wb_4052</th>\n",
       "      <th>wb_4053</th>\n",
       "      <th>wb_4054</th>\n",
       "      <th>wb_4055</th>\n",
       "      <th>wb_4056</th>\n",
       "      <th>wb_4057</th>\n",
       "      <th>wb_4058</th>\n",
       "      <th>wb_4059</th>\n",
       "      <th>wb_4060</th>\n",
       "      <th>wb_4061</th>\n",
       "      <th>wb_4062</th>\n",
       "      <th>wb_4063</th>\n",
       "      <th>wb_4064</th>\n",
       "      <th>wb_4065</th>\n",
       "      <th>wb_4066</th>\n",
       "      <th>wb_4067</th>\n",
       "      <th>wb_4068</th>\n",
       "      <th>wb_4069</th>\n",
       "      <th>wb_4070</th>\n",
       "      <th>wb_4071</th>\n",
       "      <th>wb_4072</th>\n",
       "      <th>wb_4073</th>\n",
       "      <th>wb_4074</th>\n",
       "      <th>wb_4075</th>\n",
       "      <th>wb_4076</th>\n",
       "      <th>wb_4077</th>\n",
       "      <th>wb_4078</th>\n",
       "      <th>wb_4079</th>\n",
       "      <th>wb_4080</th>\n",
       "      <th>wb_4081</th>\n",
       "      <th>wb_4082</th>\n",
       "      <th>wb_4083</th>\n",
       "      <th>wb_4084</th>\n",
       "      <th>wb_4085</th>\n",
       "      <th>wb_4086</th>\n",
       "      <th>wb_4087</th>\n",
       "      <th>wb_4088</th>\n",
       "      <th>wb_4089</th>\n",
       "      <th>wb_4090</th>\n",
       "      <th>wb_4091</th>\n",
       "      <th>wb_4092</th>\n",
       "      <th>wb_4093</th>\n",
       "      <th>wb_4094</th>\n",
       "      <th>wb_4095</th>\n",
       "      <th>wb_4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>3289.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.714</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.453</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.086</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.860</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>1.078</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>0.869</td>\n",
       "      <td>-1.153</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.801</td>\n",
       "      <td>-0.911</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.443</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-1.058</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-1.060</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>1.326</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-1.009</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.573</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>-1.062</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.235</td>\n",
       "      <td>1.146</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>-0.810</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>7460.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.313</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-2.226</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-2.323</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-1.238</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.489</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-1.663</td>\n",
       "      <td>1.252</td>\n",
       "      <td>-1.363</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-1.425</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.268</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-1.412</td>\n",
       "      <td>1.797</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>0.453</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>0.522</td>\n",
       "      <td>1.536</td>\n",
       "      <td>-1.767</td>\n",
       "      <td>-1.312</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.285</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.301</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-1.379</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-1.376</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-1.444</td>\n",
       "      <td>-1.614</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-2.175</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>-1.857</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>-2.207</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.221</td>\n",
       "      <td>1.858</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>0.293</td>\n",
       "      <td>1.531</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>-1.432</td>\n",
       "      <td>-1.458</td>\n",
       "      <td>-1.449</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.268</td>\n",
       "      <td>1.262</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>-1.363</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>-1.779</td>\n",
       "      <td>0.401</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-1.878</td>\n",
       "      <td>-1.434</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>6043.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.621</td>\n",
       "      <td>1.480</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>1.526</td>\n",
       "      <td>-1.043</td>\n",
       "      <td>0.573</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.502</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.619</td>\n",
       "      <td>1.472</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.417</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>1.529</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>1.263</td>\n",
       "      <td>0.431</td>\n",
       "      <td>1.133</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-1.163</td>\n",
       "      <td>1.613</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.848</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.395</td>\n",
       "      <td>1.120</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>9699.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.476</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.369</td>\n",
       "      <td>-0.734</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>0.529</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-0.664</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.288</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.523</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-1.042</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-0.563</td>\n",
       "      <td>0.424</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.536</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>-0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.592</td>\n",
       "      <td>1.868</td>\n",
       "      <td>1.430</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.606</td>\n",
       "      <td>1.216</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.119</td>\n",
       "      <td>1.162</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>1.337</td>\n",
       "      <td>-1.626</td>\n",
       "      <td>1.613</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>1.540</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-1.493</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>1.192</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-1.053</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-1.323</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-1.420</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-1.329</td>\n",
       "      <td>-1.586</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1.460</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.383</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.811</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-1.443</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>-1.815</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "3289 3289.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460 7460.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043 6043.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699 9699.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5       5.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f0v15  f0v16  f0v17  f0v18  \\\n",
       "3289 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5    0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v19  f0v20  f0v21  f0v22  f0v23  f0v24  f0v25  f0v26  f0v27  f0v28  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v29  f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  \\\n",
       "3289  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5     0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v10  f1v11  f1v12  f1v13  f1v14  f1v15  f1v16  f1v17  f1v18  f1v19  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v20  f1v21  f1v22  f1v23  f1v24  f1v25  f1v26  f1v27  f1v28  f1v29  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f2v0  f2v1  f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f2v10  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "\n",
       "      f2v11  f2v12  f2v13  f2v14  f2v15  f2v16  f2v17  f2v18  f2v19  f2v20  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f2v21  f2v22  f2v23  f2v24  f2v25  f2v26  f2v27  f2v28  f2v29  f3v0  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "\n",
       "      f3v1  f3v2  f3v3  f3v4  f3v5  f3v6  f3v7  ...  wb_3997  wb_3998  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.897   -0.895   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.207   -0.176   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.472   -0.317   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.394   -0.067   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.296   -0.469   \n",
       "\n",
       "      wb_3999  wb_4000  wb_4001  wb_4002  wb_4003  wb_4004  wb_4005  wb_4006  \\\n",
       "3289    0.190    0.423    0.714   -0.513    0.286    0.007    0.169    0.110   \n",
       "7460    0.313    1.306    0.172   -2.226    0.068   -2.323    0.317    0.283   \n",
       "6043    0.348    0.688    0.362   -0.321    0.067    0.399    0.326    0.460   \n",
       "9699    0.426    0.172    0.260   -0.560    0.064    0.433    0.447    0.456   \n",
       "5       0.208    0.431    0.106   -0.592    1.868    1.430    0.370    0.181   \n",
       "\n",
       "      wb_4007  wb_4008  wb_4009  wb_4010  wb_4011  wb_4012  wb_4013  wb_4014  \\\n",
       "3289   -0.265    0.016    0.218    0.453    1.378    1.086    0.982    0.860   \n",
       "7460   -1.238    0.297    0.519    0.384    0.489    1.099    0.416    0.140   \n",
       "6043   -0.174    0.485    0.445    0.454    0.579    0.461    0.621    1.480   \n",
       "9699   -0.637    0.375    0.696    0.157    0.522    0.321    0.121    0.128   \n",
       "5      -0.182    0.269    1.606    1.216    0.128    0.461    0.119    1.162   \n",
       "\n",
       "      wb_4015  wb_4016  wb_4017  wb_4018  wb_4019  wb_4020  wb_4021  wb_4022  \\\n",
       "3289   -0.357    1.078   -0.667    0.869   -1.153   -0.174   -0.899   -0.478   \n",
       "7460   -0.183    0.442   -1.663    1.252   -1.363   -0.529   -0.104   -1.425   \n",
       "6043   -0.404    1.526   -1.043    0.573   -0.093   -0.176   -0.106   -0.200   \n",
       "9699   -0.467    0.476   -0.745    0.536   -0.521   -0.178   -0.105   -0.300   \n",
       "5      -0.472    1.337   -1.626    1.613   -0.419   -0.176   -0.104   -0.253   \n",
       "\n",
       "      wb_4023  wb_4024  wb_4025  wb_4026  wb_4027  wb_4028  wb_4029  wb_4030  \\\n",
       "3289    0.279    0.127   -0.108   -0.665    0.405   -0.765    0.801   -0.911   \n",
       "7460    0.282    0.268   -0.438   -1.412    1.797   -0.371    0.453   -0.401   \n",
       "6043    0.369    0.024   -0.094   -0.389    0.505   -0.065    0.502   -0.430   \n",
       "9699    0.451    0.369   -0.734   -0.138    0.406   -0.483    0.529   -0.125   \n",
       "5       0.475    0.224   -0.462   -0.474    0.099   -0.425    1.540   -0.359   \n",
       "\n",
       "      wb_4031  wb_4032  wb_4033  wb_4034  wb_4035  wb_4036  wb_4037  wb_4038  \\\n",
       "3289    0.324    0.443   -0.117    0.343    0.176   -1.058   -0.107   -0.214   \n",
       "7460    0.522    1.536   -1.767   -1.312    0.377   -0.499   -0.107   -1.285   \n",
       "6043    0.619    1.472   -0.115    0.428    0.417   -0.311   -0.107   -0.284   \n",
       "9699    0.536    0.397   -0.664    0.411    0.131   -0.526   -0.107   -0.230   \n",
       "5       0.392    0.974   -0.115   -0.499   -1.493   -0.684   -0.107   -0.323   \n",
       "\n",
       "      wb_4039  wb_4040  wb_4041  wb_4042  wb_4043  wb_4044  wb_4045  wb_4046  \\\n",
       "3289    0.341    0.179    0.008    0.403   -1.060   -0.568   -0.207    1.326   \n",
       "7460    0.499    0.301   -0.207   -0.257   -1.379   -0.282    0.397    0.158   \n",
       "6043    1.529    0.126   -0.298   -0.275   -0.277    1.263    0.431    1.133   \n",
       "9699    0.199    0.316   -0.213    0.288   -0.228   -0.426   -0.418    0.523   \n",
       "5       1.192    0.038   -0.104   -0.354   -0.437   -1.053   -0.396    0.170   \n",
       "\n",
       "      wb_4047  wb_4048  wb_4049  wb_4050  wb_4051  wb_4052  wb_4053  wb_4054  \\\n",
       "3289   -0.257   -0.504   -0.639   -0.919    0.084    0.153   -0.985   -0.658   \n",
       "7460   -1.376   -0.296   -1.444   -1.614    0.699   -0.183   -0.426   -2.175   \n",
       "6043   -0.290    0.258   -0.247   -0.438    0.485    0.289   -0.048   -0.297   \n",
       "9699   -0.526   -0.103   -0.412   -0.575    0.309   -0.382   -1.042   -0.099   \n",
       "5      -0.412   -0.241   -0.396   -0.459    0.400    0.273   -0.531   -1.323   \n",
       "\n",
       "      wb_4055  wb_4056  wb_4057  wb_4058  wb_4059  wb_4060  wb_4061  wb_4062  \\\n",
       "3289   -0.188   -0.126   -0.713    0.271   -0.300   -0.268    0.086    0.159   \n",
       "7460    0.180   -0.586   -1.857    0.193   -1.222   -2.207    0.197    0.221   \n",
       "6043    0.294   -0.276    0.460    0.192   -0.436   -0.358    0.064    0.036   \n",
       "9699    0.333   -0.363   -0.434    0.310   -0.248   -0.066    0.220    0.121   \n",
       "5       0.270   -0.378    0.296    0.160   -0.543   -0.441    0.220    0.225   \n",
       "\n",
       "      wb_4063  wb_4064  wb_4065  wb_4066  wb_4067  wb_4068  wb_4069  wb_4070  \\\n",
       "3289   -0.252   -1.009    0.145   -0.573   -0.913   -0.309   -0.170   -0.438   \n",
       "7460    1.858   -0.413    0.293    1.531   -0.398   -1.432   -1.458   -1.449   \n",
       "6043    0.373   -1.052    0.453    0.475   -0.085   -0.485   -0.315   -0.387   \n",
       "9699   -0.486   -0.563    0.424   -0.537   -0.358   -0.561   -0.523   -0.474   \n",
       "5       0.296   -1.420    0.839    0.350   -0.446   -1.329   -1.586   -0.115   \n",
       "\n",
       "      wb_4071  wb_4072  wb_4073  wb_4074  wb_4075  wb_4076  wb_4077  wb_4078  \\\n",
       "3289   -0.106    0.155    0.224    0.721    0.242   -0.599   -1.062    0.230   \n",
       "7460   -0.106    0.268    1.262    0.394    0.459   -1.361   -1.363    0.377   \n",
       "6043   -0.106    0.191    0.428    0.417    0.765   -0.387   -1.163    1.613   \n",
       "9699   -0.106    0.381    0.439    0.082    0.077   -0.207   -0.536    0.441   \n",
       "5      -0.106    0.146    1.460    0.363    0.383   -0.174   -0.811    0.386   \n",
       "\n",
       "      wb_4079  wb_4080  wb_4081  wb_4082  wb_4083  wb_4084  wb_4085  wb_4086  \\\n",
       "3289   -0.797   -0.196    0.295   -0.196   -0.749   -0.279    0.074    0.235   \n",
       "7460   -0.803   -1.779    0.401   -0.309   -1.878   -1.434    0.253    0.650   \n",
       "6043   -0.320    0.920    0.848   -0.262   -0.749   -0.924    0.245    0.395   \n",
       "9699   -0.441   -0.463    0.168   -0.408   -0.737   -0.403    0.261    0.420   \n",
       "5      -1.443    0.349    0.452   -0.395   -0.604   -1.815    0.239    0.328   \n",
       "\n",
       "      wb_4087  wb_4088  wb_4089  wb_4090  wb_4091  wb_4092  wb_4093  wb_4094  \\\n",
       "3289    1.146    0.150    0.285   -0.043   -0.144   -0.406    0.132   -0.385   \n",
       "7460    0.430    0.196    0.347   -0.152    0.249   -0.311    0.290   -0.315   \n",
       "6043    1.120    0.331    0.365   -0.226   -0.268   -0.138    0.324    0.319   \n",
       "9699    0.177    0.279    0.333   -0.020    0.359   -0.225    0.093   -0.544   \n",
       "5       0.389    0.145    0.160   -0.335   -0.309   -0.376    0.413   -0.244   \n",
       "\n",
       "      wb_4095  wb_4096  \n",
       "3289   -0.810   -0.066  \n",
       "7460   -1.524    0.158  \n",
       "6043    0.554    0.074  \n",
       "9699   -0.623   -0.171  \n",
       "5      -0.321   -0.170  \n",
       "\n",
       "[5 rows x 4332 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:40:40.632731Z",
     "iopub.status.busy": "2021-12-17T08:40:40.632406Z",
     "iopub.status.idle": "2021-12-17T08:40:43.452064Z",
     "shell.execute_reply": "2021-12-17T08:40:43.448616Z",
     "shell.execute_reply.started": "2021-12-17T08:40:40.632701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f0v15</th>\n",
       "      <th>f0v16</th>\n",
       "      <th>f0v17</th>\n",
       "      <th>f0v18</th>\n",
       "      <th>f0v19</th>\n",
       "      <th>f0v20</th>\n",
       "      <th>f0v21</th>\n",
       "      <th>f0v22</th>\n",
       "      <th>f0v23</th>\n",
       "      <th>f0v24</th>\n",
       "      <th>f0v25</th>\n",
       "      <th>f0v26</th>\n",
       "      <th>f0v27</th>\n",
       "      <th>f0v28</th>\n",
       "      <th>f0v29</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f1v15</th>\n",
       "      <th>f1v16</th>\n",
       "      <th>f1v17</th>\n",
       "      <th>f1v18</th>\n",
       "      <th>f1v19</th>\n",
       "      <th>f1v20</th>\n",
       "      <th>f1v21</th>\n",
       "      <th>f1v22</th>\n",
       "      <th>f1v23</th>\n",
       "      <th>f1v24</th>\n",
       "      <th>f1v25</th>\n",
       "      <th>f1v26</th>\n",
       "      <th>f1v27</th>\n",
       "      <th>f1v28</th>\n",
       "      <th>f1v29</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f2v10</th>\n",
       "      <th>f2v11</th>\n",
       "      <th>f2v12</th>\n",
       "      <th>f2v13</th>\n",
       "      <th>f2v14</th>\n",
       "      <th>f2v15</th>\n",
       "      <th>f2v16</th>\n",
       "      <th>f2v17</th>\n",
       "      <th>f2v18</th>\n",
       "      <th>f2v19</th>\n",
       "      <th>f2v20</th>\n",
       "      <th>f2v21</th>\n",
       "      <th>f2v22</th>\n",
       "      <th>f2v23</th>\n",
       "      <th>f2v24</th>\n",
       "      <th>f2v25</th>\n",
       "      <th>f2v26</th>\n",
       "      <th>f2v27</th>\n",
       "      <th>f2v28</th>\n",
       "      <th>f2v29</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_3997</th>\n",
       "      <th>wb_3998</th>\n",
       "      <th>wb_3999</th>\n",
       "      <th>wb_4000</th>\n",
       "      <th>wb_4001</th>\n",
       "      <th>wb_4002</th>\n",
       "      <th>wb_4003</th>\n",
       "      <th>wb_4004</th>\n",
       "      <th>wb_4005</th>\n",
       "      <th>wb_4006</th>\n",
       "      <th>wb_4007</th>\n",
       "      <th>wb_4008</th>\n",
       "      <th>wb_4009</th>\n",
       "      <th>wb_4010</th>\n",
       "      <th>wb_4011</th>\n",
       "      <th>wb_4012</th>\n",
       "      <th>wb_4013</th>\n",
       "      <th>wb_4014</th>\n",
       "      <th>wb_4015</th>\n",
       "      <th>wb_4016</th>\n",
       "      <th>wb_4017</th>\n",
       "      <th>wb_4018</th>\n",
       "      <th>wb_4019</th>\n",
       "      <th>wb_4020</th>\n",
       "      <th>wb_4021</th>\n",
       "      <th>wb_4022</th>\n",
       "      <th>wb_4023</th>\n",
       "      <th>wb_4024</th>\n",
       "      <th>wb_4025</th>\n",
       "      <th>wb_4026</th>\n",
       "      <th>wb_4027</th>\n",
       "      <th>wb_4028</th>\n",
       "      <th>wb_4029</th>\n",
       "      <th>wb_4030</th>\n",
       "      <th>wb_4031</th>\n",
       "      <th>wb_4032</th>\n",
       "      <th>wb_4033</th>\n",
       "      <th>wb_4034</th>\n",
       "      <th>wb_4035</th>\n",
       "      <th>wb_4036</th>\n",
       "      <th>wb_4037</th>\n",
       "      <th>wb_4038</th>\n",
       "      <th>wb_4039</th>\n",
       "      <th>wb_4040</th>\n",
       "      <th>wb_4041</th>\n",
       "      <th>wb_4042</th>\n",
       "      <th>wb_4043</th>\n",
       "      <th>wb_4044</th>\n",
       "      <th>wb_4045</th>\n",
       "      <th>wb_4046</th>\n",
       "      <th>wb_4047</th>\n",
       "      <th>wb_4048</th>\n",
       "      <th>wb_4049</th>\n",
       "      <th>wb_4050</th>\n",
       "      <th>wb_4051</th>\n",
       "      <th>wb_4052</th>\n",
       "      <th>wb_4053</th>\n",
       "      <th>wb_4054</th>\n",
       "      <th>wb_4055</th>\n",
       "      <th>wb_4056</th>\n",
       "      <th>wb_4057</th>\n",
       "      <th>wb_4058</th>\n",
       "      <th>wb_4059</th>\n",
       "      <th>wb_4060</th>\n",
       "      <th>wb_4061</th>\n",
       "      <th>wb_4062</th>\n",
       "      <th>wb_4063</th>\n",
       "      <th>wb_4064</th>\n",
       "      <th>wb_4065</th>\n",
       "      <th>wb_4066</th>\n",
       "      <th>wb_4067</th>\n",
       "      <th>wb_4068</th>\n",
       "      <th>wb_4069</th>\n",
       "      <th>wb_4070</th>\n",
       "      <th>wb_4071</th>\n",
       "      <th>wb_4072</th>\n",
       "      <th>wb_4073</th>\n",
       "      <th>wb_4074</th>\n",
       "      <th>wb_4075</th>\n",
       "      <th>wb_4076</th>\n",
       "      <th>wb_4077</th>\n",
       "      <th>wb_4078</th>\n",
       "      <th>wb_4079</th>\n",
       "      <th>wb_4080</th>\n",
       "      <th>wb_4081</th>\n",
       "      <th>wb_4082</th>\n",
       "      <th>wb_4083</th>\n",
       "      <th>wb_4084</th>\n",
       "      <th>wb_4085</th>\n",
       "      <th>wb_4086</th>\n",
       "      <th>wb_4087</th>\n",
       "      <th>wb_4088</th>\n",
       "      <th>wb_4089</th>\n",
       "      <th>wb_4090</th>\n",
       "      <th>wb_4091</th>\n",
       "      <th>wb_4092</th>\n",
       "      <th>wb_4093</th>\n",
       "      <th>wb_4094</th>\n",
       "      <th>wb_4095</th>\n",
       "      <th>wb_4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7217.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.823</td>\n",
       "      <td>1.202</td>\n",
       "      <td>1.414</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>0.255</td>\n",
       "      <td>1.189</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.306</td>\n",
       "      <td>1.468</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>1.176</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-1.661</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-1.673</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.667</td>\n",
       "      <td>-1.161</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>1.733</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>2.217</td>\n",
       "      <td>1.050</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.872</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-1.073</td>\n",
       "      <td>0.515</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-1.098</td>\n",
       "      <td>0.321</td>\n",
       "      <td>-1.233</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-1.105</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.344</td>\n",
       "      <td>1.550</td>\n",
       "      <td>1.541</td>\n",
       "      <td>-1.015</td>\n",
       "      <td>-1.763</td>\n",
       "      <td>1.387</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>1.559</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-1.219</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.070</td>\n",
       "      <td>2.006</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1.087</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>8291.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-1.543</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-1.049</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.467</td>\n",
       "      <td>1.782</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-1.564</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>-1.059</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-1.579</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-1.393</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.030</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>-1.102</td>\n",
       "      <td>-1.605</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>-1.479</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.319</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-1.106</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-1.452</td>\n",
       "      <td>-1.274</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-1.177</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>-0.705</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1.396</td>\n",
       "      <td>0.411</td>\n",
       "      <td>1.234</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>-1.139</td>\n",
       "      <td>1.443</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>1.832</td>\n",
       "      <td>-1.115</td>\n",
       "      <td>-1.784</td>\n",
       "      <td>-1.097</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.473</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>-0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>4607.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-1.854</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.291</td>\n",
       "      <td>1.589</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.296</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.872</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-1.981</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.461</td>\n",
       "      <td>1.179</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.791</td>\n",
       "      <td>1.055</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.178</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-1.211</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.463</td>\n",
       "      <td>0.738</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>1.746</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>1.277</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-1.708</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>0.770</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.584</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.608</td>\n",
       "      <td>1.775</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.913</td>\n",
       "      <td>1.221</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>1.205</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.836</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.709</td>\n",
       "      <td>1.067</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.244</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>5114.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-1.111</td>\n",
       "      <td>0.241</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.971</td>\n",
       "      <td>-0.855</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.621</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.812</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.502</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.267</td>\n",
       "      <td>1.402</td>\n",
       "      <td>1.744</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-1.015</td>\n",
       "      <td>-0.617</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-1.211</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-1.208</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>1.656</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.877</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-1.291</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>1.184</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-1.307</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.217</td>\n",
       "      <td>1.344</td>\n",
       "      <td>1.363</td>\n",
       "      <td>0.519</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-1.048</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.364</td>\n",
       "      <td>1.107</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-1.275</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.272</td>\n",
       "      <td>1.532</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257</td>\n",
       "      <td>-0.496</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.421</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.517</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>0.635</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>0.588</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.592</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>0.361</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.424</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>0.557</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "7217 7217.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 8291.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 4607.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 5114.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 1859.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f0v15  f0v16  f0v17  f0v18  \\\n",
       "7217 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v19  f0v20  f0v21  f0v22  f0v23  f0v24  f0v25  f0v26  f0v27  f0v28  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v29  f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  \\\n",
       "7217  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v10  f1v11  f1v12  f1v13  f1v14  f1v15  f1v16  f1v17  f1v18  f1v19  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v20  f1v21  f1v22  f1v23  f1v24  f1v25  f1v26  f1v27  f1v28  f1v29  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f2v0  f2v1  f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f2v10  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "\n",
       "      f2v11  f2v12  f2v13  f2v14  f2v15  f2v16  f2v17  f2v18  f2v19  f2v20  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f2v21  f2v22  f2v23  f2v24  f2v25  f2v26  f2v27  f2v28  f2v29  f3v0  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "\n",
       "      f3v1  f3v2  f3v3  f3v4  f3v5  f3v6  f3v7  ...  wb_3997  wb_3998  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.641   -0.823   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.309   -1.543   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.269   -0.358   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.350   -1.111   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.257   -0.496   \n",
       "\n",
       "      wb_3999  wb_4000  wb_4001  wb_4002  wb_4003  wb_4004  wb_4005  wb_4006  \\\n",
       "7217    1.202    1.414    0.272   -0.567    0.067   -0.783    0.255    1.189   \n",
       "8291    0.387    0.639    0.237   -0.069    0.068    0.238    0.399    0.236   \n",
       "4607    0.327    0.990    0.167   -1.854    0.534    0.014    0.291    1.589   \n",
       "5114    0.241    1.051    0.971   -0.855    0.067    1.621    0.252    0.812   \n",
       "1859    0.502    0.625    0.267   -0.519    0.066    0.521    0.274    0.421   \n",
       "\n",
       "      wb_4007  wb_4008  wb_4009  wb_4010  wb_4011  wb_4012  wb_4013  wb_4014  \\\n",
       "7217   -0.988    0.143    0.355    0.306    1.468    0.337    0.119    0.407   \n",
       "8291   -1.049   -0.904    0.357    0.467    1.782    0.435    0.105    0.406   \n",
       "4607   -0.454    0.852    1.296    0.839    0.480    0.506    0.360    0.442   \n",
       "5114   -1.095    0.180    0.067    1.502    1.089    0.267    1.402    1.744   \n",
       "1859   -0.577    0.438    0.503    0.477    0.563    0.131    0.123    0.517   \n",
       "\n",
       "      wb_4015  wb_4016  wb_4017  wb_4018  wb_4019  wb_4020  wb_4021  wb_4022  \\\n",
       "7217   -0.518    1.176   -0.591    0.440   -0.370   -0.176   -1.661   -0.198   \n",
       "8291   -0.983    0.100   -0.989    0.121   -1.564   -0.177   -0.494   -0.803   \n",
       "4607   -0.384    0.872   -0.197    0.126   -0.207   -1.981   -1.361   -0.244   \n",
       "5114   -0.798    1.705   -0.485    0.124   -1.015   -0.617   -0.103   -0.142   \n",
       "1859   -0.540    0.635   -0.620    0.588   -0.515   -0.183   -0.100   -0.401   \n",
       "\n",
       "      wb_4023  wb_4024  wb_4025  wb_4026  wb_4027  wb_4028  wb_4029  wb_4030  \\\n",
       "7217    0.455    0.176   -0.417   -0.359    0.375   -0.451    0.681   -0.340   \n",
       "8291    0.374    0.273   -1.021   -1.059    0.120   -1.579    0.442   -0.450   \n",
       "4607    0.461    1.179   -0.077   -0.219    0.313   -0.791    1.055   -0.089   \n",
       "5114    0.181    0.149   -0.526   -1.211    0.455   -0.364    0.138   -0.745   \n",
       "1859    0.301    0.159   -0.498   -0.511    0.335   -0.492    0.138   -0.508   \n",
       "\n",
       "      wb_4031  wb_4032  wb_4033  wb_4034  wb_4035  wb_4036  wb_4037  wb_4038  \\\n",
       "7217    0.362    0.275   -1.673    0.277    0.667   -1.161   -0.107   -0.318   \n",
       "8291    0.404   -1.515   -1.257    0.313   -1.393   -0.112   -0.107   -1.030   \n",
       "4607    0.317    1.178   -0.383    0.425   -1.211   -0.195   -0.101   -0.198   \n",
       "5114    0.325    0.823   -1.208   -0.566    1.656   -0.404   -0.107   -0.877   \n",
       "1859    0.171    0.592   -0.519    0.672    0.480   -0.367   -0.107   -0.241   \n",
       "\n",
       "      wb_4039  wb_4040  wb_4041  wb_4042  wb_4043  wb_4044  wb_4045  wb_4046  \\\n",
       "7217    0.364    0.343   -0.089    0.184   -0.292   -0.347   -0.652    1.733   \n",
       "8291    0.317    0.296   -0.451   -0.611   -1.102   -1.605    0.281    0.540   \n",
       "4607    1.463    0.738   -0.200    0.143   -0.316   -0.228   -0.266    1.746   \n",
       "5114    0.531    0.323   -0.079   -0.124   -0.847   -0.638   -0.179    0.168   \n",
       "1859    0.509    0.307   -0.026    0.385   -0.486   -0.295    0.473    0.171   \n",
       "\n",
       "      wb_4047  wb_4048  wb_4049  wb_4050  wb_4051  wb_4052  wb_4053  wb_4054  \\\n",
       "7217   -0.307   -0.225   -0.334   -1.295    2.217    1.050   -0.037   -0.410   \n",
       "8291   -0.472   -0.956   -0.701   -1.479    0.070    0.319   -0.974   -1.095   \n",
       "4607   -0.591   -0.223   -0.301   -0.457    1.277    0.966   -1.708   -0.392   \n",
       "5114   -1.291   -0.095   -0.301   -0.356    1.184    0.102   -0.719   -0.178   \n",
       "1859   -0.515   -0.429   -0.432   -0.487    0.081   -0.281   -0.480   -0.452   \n",
       "\n",
       "      wb_4055  wb_4056  wb_4057  wb_4058  wb_4059  wb_4060  wb_4061  wb_4062  \\\n",
       "7217    0.872   -0.473   -1.073    0.515   -0.394   -0.427   -0.447    0.160   \n",
       "8291    0.328   -1.106   -0.364    0.400   -0.432   -0.069    0.251    0.196   \n",
       "4607    0.770   -0.252    0.268    0.584   -0.164   -0.372    0.171    0.146   \n",
       "5114    0.148   -0.215   -0.776    0.294   -0.282   -0.348    0.013    0.142   \n",
       "1859    0.361   -0.347   -0.429    0.184   -0.518   -0.064    0.291    0.123   \n",
       "\n",
       "      wb_4063  wb_4064  wb_4065  wb_4066  wb_4067  wb_4068  wb_4069  wb_4070  \\\n",
       "7217   -0.332   -1.098    0.321   -1.233   -0.262   -0.422   -1.105   -0.185   \n",
       "8291   -1.452   -1.274    0.432   -1.177   -0.403   -0.535   -0.477   -0.705   \n",
       "4607    0.377   -0.374    0.608    1.775   -0.137   -0.980   -0.298   -0.360   \n",
       "5114   -1.307   -0.568    0.075    0.283   -0.164   -0.965   -0.968   -0.272   \n",
       "1859   -0.447   -0.077    0.468    0.424   -0.450   -0.176   -0.545   -0.308   \n",
       "\n",
       "      wb_4071  wb_4072  wb_4073  wb_4074  wb_4075  wb_4076  wb_4077  wb_4078  \\\n",
       "7217   -0.106    0.177    0.344    1.550    1.541   -1.015   -1.763    1.387   \n",
       "8291   -0.106    0.401    1.396    0.411    1.234   -0.765   -1.139    1.443   \n",
       "4607   -0.106    0.265    0.453    0.913    1.221   -0.187   -0.075    0.615   \n",
       "5114   -0.106    0.217    1.344    1.363    0.519   -1.524   -0.374    0.357   \n",
       "1859   -0.106    0.332    0.451    0.539    0.471   -0.543   -0.630    0.043   \n",
       "\n",
       "      wb_4079  wb_4080  wb_4081  wb_4082  wb_4083  wb_4084  wb_4085  wb_4086  \\\n",
       "7217   -0.196   -0.395    1.559   -0.400   -1.219   -0.492    0.287    0.070   \n",
       "8291   -0.039   -0.610    1.832   -1.115   -1.784   -1.097    0.252    0.430   \n",
       "4607   -0.406    1.205    0.408    0.836   -0.918   -1.032    0.533    0.487   \n",
       "5114   -0.440    0.307    0.462   -0.153   -0.465   -1.048    0.233    0.694   \n",
       "1859   -0.126   -0.446    0.557   -0.420   -0.292   -0.503    0.057    0.503   \n",
       "\n",
       "      wb_4087  wb_4088  wb_4089  wb_4090  wb_4091  wb_4092  wb_4093  wb_4094  \\\n",
       "7217    2.006    0.646    1.087   -0.141   -0.366   -0.170    0.918   -0.490   \n",
       "8291    0.313    0.413    0.473   -0.924   -0.845   -0.393    0.560    0.241   \n",
       "4607    0.965    0.709    1.067   -0.093   -0.223   -0.185    0.670    0.244   \n",
       "5114    0.364    1.107    0.291   -0.081   -1.275   -0.240    0.272    1.532   \n",
       "1859    0.582   -0.072    0.367   -0.110    0.471   -0.440    0.434   -0.413   \n",
       "\n",
       "      wb_4095  wb_4096  \n",
       "7217   -0.399   -0.153  \n",
       "8291   -0.779   -0.168  \n",
       "4607    1.031    0.088  \n",
       "5114   -0.474   -0.207  \n",
       "1859   -0.404    0.202  \n",
       "\n",
       "[5 rows x 4332 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:40:43.455680Z",
     "iopub.status.busy": "2021-12-17T08:40:43.455058Z",
     "iopub.status.idle": "2021-12-17T08:40:43.969691Z",
     "shell.execute_reply": "2021-12-17T08:40:43.968907Z",
     "shell.execute_reply.started": "2021-12-17T08:40:43.455624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f0v15</th>\n",
       "      <th>f0v16</th>\n",
       "      <th>f0v17</th>\n",
       "      <th>f0v18</th>\n",
       "      <th>f0v19</th>\n",
       "      <th>f0v20</th>\n",
       "      <th>f0v21</th>\n",
       "      <th>f0v22</th>\n",
       "      <th>f0v23</th>\n",
       "      <th>f0v24</th>\n",
       "      <th>f0v25</th>\n",
       "      <th>f0v26</th>\n",
       "      <th>f0v27</th>\n",
       "      <th>f0v28</th>\n",
       "      <th>f0v29</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f1v15</th>\n",
       "      <th>f1v16</th>\n",
       "      <th>f1v17</th>\n",
       "      <th>f1v18</th>\n",
       "      <th>f1v19</th>\n",
       "      <th>f1v20</th>\n",
       "      <th>f1v21</th>\n",
       "      <th>f1v22</th>\n",
       "      <th>f1v23</th>\n",
       "      <th>f1v24</th>\n",
       "      <th>f1v25</th>\n",
       "      <th>f1v26</th>\n",
       "      <th>f1v27</th>\n",
       "      <th>f1v28</th>\n",
       "      <th>f1v29</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f2v10</th>\n",
       "      <th>f2v11</th>\n",
       "      <th>f2v12</th>\n",
       "      <th>f2v13</th>\n",
       "      <th>f2v14</th>\n",
       "      <th>f2v15</th>\n",
       "      <th>f2v16</th>\n",
       "      <th>f2v17</th>\n",
       "      <th>f2v18</th>\n",
       "      <th>f2v19</th>\n",
       "      <th>f2v20</th>\n",
       "      <th>f2v21</th>\n",
       "      <th>f2v22</th>\n",
       "      <th>f2v23</th>\n",
       "      <th>f2v24</th>\n",
       "      <th>f2v25</th>\n",
       "      <th>f2v26</th>\n",
       "      <th>f2v27</th>\n",
       "      <th>f2v28</th>\n",
       "      <th>f2v29</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_3997</th>\n",
       "      <th>wb_3998</th>\n",
       "      <th>wb_3999</th>\n",
       "      <th>wb_4000</th>\n",
       "      <th>wb_4001</th>\n",
       "      <th>wb_4002</th>\n",
       "      <th>wb_4003</th>\n",
       "      <th>wb_4004</th>\n",
       "      <th>wb_4005</th>\n",
       "      <th>wb_4006</th>\n",
       "      <th>wb_4007</th>\n",
       "      <th>wb_4008</th>\n",
       "      <th>wb_4009</th>\n",
       "      <th>wb_4010</th>\n",
       "      <th>wb_4011</th>\n",
       "      <th>wb_4012</th>\n",
       "      <th>wb_4013</th>\n",
       "      <th>wb_4014</th>\n",
       "      <th>wb_4015</th>\n",
       "      <th>wb_4016</th>\n",
       "      <th>wb_4017</th>\n",
       "      <th>wb_4018</th>\n",
       "      <th>wb_4019</th>\n",
       "      <th>wb_4020</th>\n",
       "      <th>wb_4021</th>\n",
       "      <th>wb_4022</th>\n",
       "      <th>wb_4023</th>\n",
       "      <th>wb_4024</th>\n",
       "      <th>wb_4025</th>\n",
       "      <th>wb_4026</th>\n",
       "      <th>wb_4027</th>\n",
       "      <th>wb_4028</th>\n",
       "      <th>wb_4029</th>\n",
       "      <th>wb_4030</th>\n",
       "      <th>wb_4031</th>\n",
       "      <th>wb_4032</th>\n",
       "      <th>wb_4033</th>\n",
       "      <th>wb_4034</th>\n",
       "      <th>wb_4035</th>\n",
       "      <th>wb_4036</th>\n",
       "      <th>wb_4037</th>\n",
       "      <th>wb_4038</th>\n",
       "      <th>wb_4039</th>\n",
       "      <th>wb_4040</th>\n",
       "      <th>wb_4041</th>\n",
       "      <th>wb_4042</th>\n",
       "      <th>wb_4043</th>\n",
       "      <th>wb_4044</th>\n",
       "      <th>wb_4045</th>\n",
       "      <th>wb_4046</th>\n",
       "      <th>wb_4047</th>\n",
       "      <th>wb_4048</th>\n",
       "      <th>wb_4049</th>\n",
       "      <th>wb_4050</th>\n",
       "      <th>wb_4051</th>\n",
       "      <th>wb_4052</th>\n",
       "      <th>wb_4053</th>\n",
       "      <th>wb_4054</th>\n",
       "      <th>wb_4055</th>\n",
       "      <th>wb_4056</th>\n",
       "      <th>wb_4057</th>\n",
       "      <th>wb_4058</th>\n",
       "      <th>wb_4059</th>\n",
       "      <th>wb_4060</th>\n",
       "      <th>wb_4061</th>\n",
       "      <th>wb_4062</th>\n",
       "      <th>wb_4063</th>\n",
       "      <th>wb_4064</th>\n",
       "      <th>wb_4065</th>\n",
       "      <th>wb_4066</th>\n",
       "      <th>wb_4067</th>\n",
       "      <th>wb_4068</th>\n",
       "      <th>wb_4069</th>\n",
       "      <th>wb_4070</th>\n",
       "      <th>wb_4071</th>\n",
       "      <th>wb_4072</th>\n",
       "      <th>wb_4073</th>\n",
       "      <th>wb_4074</th>\n",
       "      <th>wb_4075</th>\n",
       "      <th>wb_4076</th>\n",
       "      <th>wb_4077</th>\n",
       "      <th>wb_4078</th>\n",
       "      <th>wb_4079</th>\n",
       "      <th>wb_4080</th>\n",
       "      <th>wb_4081</th>\n",
       "      <th>wb_4082</th>\n",
       "      <th>wb_4083</th>\n",
       "      <th>wb_4084</th>\n",
       "      <th>wb_4085</th>\n",
       "      <th>wb_4086</th>\n",
       "      <th>wb_4087</th>\n",
       "      <th>wb_4088</th>\n",
       "      <th>wb_4089</th>\n",
       "      <th>wb_4090</th>\n",
       "      <th>wb_4091</th>\n",
       "      <th>wb_4092</th>\n",
       "      <th>wb_4093</th>\n",
       "      <th>wb_4094</th>\n",
       "      <th>wb_4095</th>\n",
       "      <th>wb_4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710</td>\n",
       "      <td>-1.008</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.558</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.676</td>\n",
       "      <td>-1.301</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.454</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.815</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.669</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.333</td>\n",
       "      <td>2.164</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>-0.723</td>\n",
       "      <td>-1.728</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>-1.690</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>-0.548</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.436</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.630</td>\n",
       "      <td>2.623</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>-1.543</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>2.521</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-2.504</td>\n",
       "      <td>-1.527</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1.562</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-0.702</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.599</td>\n",
       "      <td>-2.511</td>\n",
       "      <td>2.283</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.783</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.316</td>\n",
       "      <td>2.669</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>1.810</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.133</td>\n",
       "      <td>3.201</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-3.144</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>2.630</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.732</td>\n",
       "      <td>-2.809</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-1.753</td>\n",
       "      <td>2.408</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2.054</td>\n",
       "      <td>-2.606</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.294</td>\n",
       "      <td>3.515</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-2.566</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-2.753</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-1.444</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>2.710</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>2.601</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-3.373</td>\n",
       "      <td>-3.603</td>\n",
       "      <td>-1.407</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.094</td>\n",
       "      <td>3.225</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-1.192</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-1.421</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.334</td>\n",
       "      <td>3.219</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-1.669</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-2.995</td>\n",
       "      <td>-0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.516</td>\n",
       "      <td>-1.512</td>\n",
       "      <td>1.290</td>\n",
       "      <td>2.585</td>\n",
       "      <td>1.281</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.059</td>\n",
       "      <td>4.009</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.533</td>\n",
       "      <td>1.741</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.133</td>\n",
       "      <td>3.576</td>\n",
       "      <td>-2.180</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-3.598</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-2.243</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>3.040</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>1.752</td>\n",
       "      <td>3.266</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.816</td>\n",
       "      <td>3.963</td>\n",
       "      <td>-2.147</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-2.674</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1.770</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-2.586</td>\n",
       "      <td>-2.326</td>\n",
       "      <td>2.180</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-3.498</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-1.337</td>\n",
       "      <td>4.513</td>\n",
       "      <td>1.806</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-1.545</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>1.483</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.253</td>\n",
       "      <td>3.337</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-2.190</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.878</td>\n",
       "      <td>2.984</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-2.133</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-2.690</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-1.963</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.088</td>\n",
       "      <td>2.191</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-3.174</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>2.317</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-2.190</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476</td>\n",
       "      <td>-4.002</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-3.108</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.083</td>\n",
       "      <td>2.626</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>3.453</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>3.357</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.627</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.516</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.647</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.531</td>\n",
       "      <td>2.842</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  f0v9  \\\n",
       "29 29.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38 38.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79 79.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19 19.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27 27.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f0v10  f0v11  f0v12  f0v13  f0v14  f0v15  f0v16  f0v17  f0v18  f0v19  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f0v20  f0v21  f0v22  f0v23  f0v24  f0v25  f0v26  f0v27  f0v28  f0v29  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  f1v10  f1v11  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "\n",
       "    f1v12  f1v13  f1v14  f1v15  f1v16  f1v17  f1v18  f1v19  f1v20  f1v21  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f1v22  f1v23  f1v24  f1v25  f1v26  f1v27  f1v28  f1v29  f2v0  f2v1  f2v2  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f2v10  f2v11  f2v12  f2v13  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f2v14  f2v15  f2v16  f2v17  f2v18  f2v19  f2v20  f2v21  f2v22  f2v23  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f2v24  f2v25  f2v26  f2v27  f2v28  f2v29  f3v0  f3v1  f3v2  f3v3  f3v4  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f3v5  f3v6  f3v7  ...  wb_3997  wb_3998  wb_3999  wb_4000  wb_4001  \\\n",
       "29 0.000 0.000 0.000  ...    0.710   -1.008    0.531    0.173    0.558   \n",
       "38 0.000 0.000 0.000  ...    0.140   -0.194    0.184    0.175    0.175   \n",
       "79 0.000 0.000 0.000  ...    2.599   -2.511    2.283    0.172    0.783   \n",
       "19 0.000 0.000 0.000  ...    1.516   -1.512    1.290    2.585    1.281   \n",
       "27 0.000 0.000 0.000  ...    0.476   -4.002    0.360    0.739    0.215   \n",
       "\n",
       "    wb_4002  wb_4003  wb_4004  wb_4005  wb_4006  wb_4007  wb_4008  wb_4009  \\\n",
       "29   -0.080    0.073    0.018    0.383    0.676   -1.301   -0.656    0.078   \n",
       "38   -0.070    0.073    0.018    0.236    0.145   -0.208    0.054    0.083   \n",
       "79   -0.080    0.073    0.018    0.316    2.669   -0.193    1.810    0.610   \n",
       "19   -0.080    0.073    0.018    0.059    4.009   -0.984    2.346    2.533   \n",
       "27   -0.080    0.073    0.018    0.404    0.440   -3.108    0.449    0.083   \n",
       "\n",
       "    wb_4010  wb_4011  wb_4012  wb_4013  wb_4014  wb_4015  wb_4016  wb_4017  \\\n",
       "29    0.606    0.137    0.704    0.133    0.161   -0.661    0.104   -0.212   \n",
       "38    0.256    0.143    0.267    0.133    0.253   -0.310    0.112   -0.212   \n",
       "79    0.315    0.143    0.298    0.133    3.201   -0.319    0.106   -0.210   \n",
       "19    1.741    0.143    0.138    0.133    3.576   -2.180    0.111   -0.212   \n",
       "27    2.626    0.138    0.383    0.133    0.162   -0.622    3.453   -0.207   \n",
       "\n",
       "    wb_4018  wb_4019  wb_4020  wb_4021  wb_4022  wb_4023  wb_4024  wb_4025  \\\n",
       "29    0.135   -0.122   -0.183   -0.113   -0.409    0.514    0.454   -0.117   \n",
       "38    0.135   -0.239   -0.183   -0.113   -0.120    0.216    0.038   -0.114   \n",
       "79    0.135   -3.144   -0.183   -0.113   -0.006    2.630    0.063   -0.732   \n",
       "19    0.135   -3.598   -0.183   -0.113   -2.243   -0.211   -0.144   -0.170   \n",
       "27    0.135   -0.127   -0.183   -0.113   -0.219    0.463    0.203   -0.717   \n",
       "\n",
       "    wb_4026  wb_4027  wb_4028  wb_4029  wb_4030  wb_4031  wb_4032  wb_4033  \\\n",
       "29   -0.803    0.145   -0.078    0.815   -0.534    0.587    0.669   -0.133   \n",
       "38   -0.276    0.241   -0.092    0.263   -0.192    0.305    0.021   -0.285   \n",
       "79   -2.809    0.132   -1.753    2.408   -0.242    0.300    2.054   -2.606   \n",
       "19    0.065    0.129   -0.084    3.040   -0.133    1.752    3.266   -0.133   \n",
       "27   -0.137    3.357   -0.082    0.627   -0.586    0.272    0.550   -0.610   \n",
       "\n",
       "    wb_4034  wb_4035  wb_4036  wb_4037  wb_4038  wb_4039  wb_4040  wb_4041  \\\n",
       "29    0.010    0.014   -0.527   -0.107    0.333    2.164    0.439   -0.492   \n",
       "38    0.008    0.012   -0.120   -0.107   -0.161    0.274    0.085   -0.172   \n",
       "79   -0.001    0.013   -0.108   -0.107   -1.294    3.515    0.148   -0.282   \n",
       "19    0.816    3.963   -2.147   -0.107   -2.674    0.123    1.770   -0.043   \n",
       "27    0.507    0.020   -0.468   -0.107   -0.388    0.593    0.178   -0.289   \n",
       "\n",
       "    wb_4042  wb_4043  wb_4044  wb_4045  wb_4046  wb_4047  wb_4048  wb_4049  \\\n",
       "29   -0.514   -0.723   -1.728    0.000    0.748   -1.690   -0.413   -0.548   \n",
       "38   -0.136   -0.177   -0.146    0.000    0.192   -0.130   -0.119   -0.239   \n",
       "79   -0.202   -0.274   -2.566    0.000    0.306   -2.753   -0.009   -1.444   \n",
       "19   -2.586   -2.326    2.180    0.000    0.169   -3.498   -0.183   -0.070   \n",
       "27   -0.478   -0.830   -0.972    0.000    3.516   -0.130   -0.279   -0.418   \n",
       "\n",
       "    wb_4050  wb_4051  wb_4052  wb_4053  wb_4054  wb_4055  wb_4056  wb_4057  \\\n",
       "29   -0.599    0.088    0.436   -0.783   -0.737    0.366   -0.662   -0.521   \n",
       "38   -0.117    0.100   -0.046   -0.060   -0.246    0.119   -0.152   -0.009   \n",
       "79   -2.710    2.710    0.137   -0.060   -0.158    0.171   -0.052    2.601   \n",
       "19   -1.337    4.513    1.806   -0.060   -0.169   -0.222   -1.656    0.137   \n",
       "27   -0.538    0.089    0.441   -0.060   -0.647    0.427   -0.354   -0.386   \n",
       "\n",
       "    wb_4058  wb_4059  wb_4060  wb_4061  wb_4062  wb_4063  wb_4064  wb_4065  \\\n",
       "29    0.455   -0.484   -0.085   -0.445    0.337    0.000   -0.084    0.630   \n",
       "38    0.233   -0.290   -0.075    0.126    0.034    0.005   -0.084    0.121   \n",
       "79    0.137   -0.281   -0.092    0.171    0.073    0.005   -0.084    0.248   \n",
       "19    0.771   -1.545   -0.092    1.483   -0.027    0.005   -0.084    0.253   \n",
       "27    0.197   -1.340   -0.092    0.225    0.051    0.005   -0.084    0.651   \n",
       "\n",
       "    wb_4066  wb_4067  wb_4068  wb_4069  wb_4070  wb_4071  wb_4072  wb_4073  \\\n",
       "29    2.623   -0.514   -0.710   -1.543   -0.658   -0.106    0.188    0.069   \n",
       "38    0.124   -0.142   -0.306   -0.286   -0.231   -0.106    0.240    0.190   \n",
       "79    0.021   -0.248   -3.373   -3.603   -1.407   -0.106    0.175    0.059   \n",
       "19    3.337   -0.124   -2.190   -0.176   -0.107   -0.106    0.878    2.984   \n",
       "27    0.017   -0.605   -0.700   -0.616   -0.435   -0.106    0.409    0.521   \n",
       "\n",
       "    wb_4074  wb_4075  wb_4076  wb_4077  wb_4078  wb_4079  wb_4080  wb_4081  \\\n",
       "29    0.134    0.093   -0.193   -0.072    0.568   -0.713   -0.001    2.521   \n",
       "38    0.102    0.209   -0.193   -0.072    0.062   -0.161   -0.006    0.322   \n",
       "79    0.094    3.225   -0.420   -0.072    0.065   -1.192    0.000    0.180   \n",
       "19   -0.043    0.090   -2.133   -0.072    0.061   -2.690    0.027    0.185   \n",
       "27    0.531    2.842   -0.635   -0.072    0.057   -0.329   -0.531    0.718   \n",
       "\n",
       "    wb_4082  wb_4083  wb_4084  wb_4085  wb_4086  wb_4087  wb_4088  wb_4089  \\\n",
       "29   -0.625   -2.504   -1.527    0.386    0.085    1.562    0.255    0.356   \n",
       "38    0.034   -0.316   -0.222    0.158    0.094    0.266    0.139    0.249   \n",
       "79   -0.219   -0.178   -1.421    0.184    0.334    3.219    0.081    0.179   \n",
       "19   -1.963   -0.188   -0.118   -0.168    0.088    2.191   -0.133    0.036   \n",
       "27   -0.435   -0.690   -0.495    0.257    0.458    0.445    0.588    0.542   \n",
       "\n",
       "    wb_4090  wb_4091  wb_4092  wb_4093  wb_4094  wb_4095  wb_4096  \n",
       "29   -0.276   -0.702   -0.439    0.573    0.683   -0.593    0.038  \n",
       "38   -0.106    0.060   -0.219    0.225    0.137    0.008   -0.052  \n",
       "79   -0.083   -0.688   -1.669    0.165   -0.321   -2.995   -0.214  \n",
       "19    0.320   -3.174   -0.146    2.317   -0.296   -2.190   -0.066  \n",
       "27   -0.210   -0.502   -0.314    2.161    0.419    0.002    0.060  \n",
       "\n",
       "[5 rows x 4332 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:40:43.971329Z",
     "iopub.status.busy": "2021-12-17T08:40:43.971015Z",
     "iopub.status.idle": "2021-12-17T08:40:43.980981Z",
     "shell.execute_reply": "2021-12-17T08:40:43.979766Z",
     "shell.execute_reply.started": "2021-12-17T08:40:43.971296Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir data/logging/ --port=8811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:40:43.982886Z",
     "iopub.status.busy": "2021-12-17T08:40:43.982466Z",
     "iopub.status.idle": "2021-12-17T08:40:44.003341Z",
     "shell.execute_reply": "2021-12-17T08:40:43.997217Z",
     "shell.execute_reply.started": "2021-12-17T08:40:43.982851Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:40:44.005608Z",
     "iopub.status.busy": "2021-12-17T08:40:44.005257Z",
     "iopub.status.idle": "2021-12-17T09:22:11.348236Z",
     "shell.execute_reply": "2021-12-17T09:22:11.347568Z",
     "shell.execute_reply.started": "2021-12-17T08:40:44.005573Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 2s/step - loss: 0.6921 - binary_crossentropy_inet_decision_function_fv_metric: 0.6915 - binary_accuracy_inet_decision_function_fv_metric: 0.5362 - val_loss: 0.6873 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6873 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5440\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.6673 - binary_crossentropy_inet_decision_function_fv_metric: 0.6671 - binary_accuracy_inet_decision_function_fv_metric: 0.5973 - val_loss: 0.6622 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6622 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6077\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.6547 - binary_crossentropy_inet_decision_function_fv_metric: 0.6546 - binary_accuracy_inet_decision_function_fv_metric: 0.6226 - val_loss: 0.6566 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6566 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6194\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 10s 532ms/step - loss: 0.6513 - binary_crossentropy_inet_decision_function_fv_metric: 0.6512 - binary_accuracy_inet_decision_function_fv_metric: 0.6266 - val_loss: 0.6551 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6551 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6207\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 10s 546ms/step - loss: 0.6497 - binary_crossentropy_inet_decision_function_fv_metric: 0.6497 - binary_accuracy_inet_decision_function_fv_metric: 0.6276 - val_loss: 0.6543 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6543 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6216\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 11s 585ms/step - loss: 0.6485 - binary_crossentropy_inet_decision_function_fv_metric: 0.6486 - binary_accuracy_inet_decision_function_fv_metric: 0.6291 - val_loss: 0.6540 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6540 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6211\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.6482 - binary_crossentropy_inet_decision_function_fv_metric: 0.6482 - binary_accuracy_inet_decision_function_fv_metric: 0.6294 - val_loss: 0.6537 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6537 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6201\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.6477 - binary_crossentropy_inet_decision_function_fv_metric: 0.6476 - binary_accuracy_inet_decision_function_fv_metric: 0.6300 - val_loss: 0.6529 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6217\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 12s 684ms/step - loss: 0.6467 - binary_crossentropy_inet_decision_function_fv_metric: 0.6467 - binary_accuracy_inet_decision_function_fv_metric: 0.6310 - val_loss: 0.6526 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6220\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 12s 669ms/step - loss: 0.6462 - binary_crossentropy_inet_decision_function_fv_metric: 0.6462 - binary_accuracy_inet_decision_function_fv_metric: 0.6314 - val_loss: 0.6531 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6531 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6211\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 12s 679ms/step - loss: 0.6457 - binary_crossentropy_inet_decision_function_fv_metric: 0.6456 - binary_accuracy_inet_decision_function_fv_metric: 0.6319 - val_loss: 0.6518 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6518 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6224\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 12s 668ms/step - loss: 0.6449 - binary_crossentropy_inet_decision_function_fv_metric: 0.6448 - binary_accuracy_inet_decision_function_fv_metric: 0.6325 - val_loss: 0.6514 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6514 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6221\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 12s 684ms/step - loss: 0.6440 - binary_crossentropy_inet_decision_function_fv_metric: 0.6440 - binary_accuracy_inet_decision_function_fv_metric: 0.6328 - val_loss: 0.6503 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6503 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6233\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 12s 673ms/step - loss: 0.6437 - binary_crossentropy_inet_decision_function_fv_metric: 0.6438 - binary_accuracy_inet_decision_function_fv_metric: 0.6328 - val_loss: 0.6509 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6508 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6225\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 12s 680ms/step - loss: 0.6426 - binary_crossentropy_inet_decision_function_fv_metric: 0.6426 - binary_accuracy_inet_decision_function_fv_metric: 0.6340 - val_loss: 0.6499 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6499 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6241\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 12s 673ms/step - loss: 0.6416 - binary_crossentropy_inet_decision_function_fv_metric: 0.6417 - binary_accuracy_inet_decision_function_fv_metric: 0.6348 - val_loss: 0.6488 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6488 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6245\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 12s 685ms/step - loss: 0.6408 - binary_crossentropy_inet_decision_function_fv_metric: 0.6409 - binary_accuracy_inet_decision_function_fv_metric: 0.6353 - val_loss: 0.6490 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6490 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6236\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 13s 701ms/step - loss: 0.6399 - binary_crossentropy_inet_decision_function_fv_metric: 0.6399 - binary_accuracy_inet_decision_function_fv_metric: 0.6364 - val_loss: 0.6477 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6477 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6254\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 12s 683ms/step - loss: 0.6392 - binary_crossentropy_inet_decision_function_fv_metric: 0.6392 - binary_accuracy_inet_decision_function_fv_metric: 0.6368 - val_loss: 0.6466 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6466 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6258\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 13s 705ms/step - loss: 0.6378 - binary_crossentropy_inet_decision_function_fv_metric: 0.6379 - binary_accuracy_inet_decision_function_fv_metric: 0.6378 - val_loss: 0.6456 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6456 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6265\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 12s 687ms/step - loss: 0.6365 - binary_crossentropy_inet_decision_function_fv_metric: 0.6364 - binary_accuracy_inet_decision_function_fv_metric: 0.6395 - val_loss: 0.6462 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6462 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6276\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 12s 675ms/step - loss: 0.6383 - binary_crossentropy_inet_decision_function_fv_metric: 0.6383 - binary_accuracy_inet_decision_function_fv_metric: 0.6383 - val_loss: 0.6469 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6469 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6281\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 12s 681ms/step - loss: 0.6385 - binary_crossentropy_inet_decision_function_fv_metric: 0.6383 - binary_accuracy_inet_decision_function_fv_metric: 0.6389 - val_loss: 0.6449 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6449 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6278\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 12s 689ms/step - loss: 0.6343 - binary_crossentropy_inet_decision_function_fv_metric: 0.6344 - binary_accuracy_inet_decision_function_fv_metric: 0.6416 - val_loss: 0.6418 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6419 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6297\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 12s 680ms/step - loss: 0.6305 - binary_crossentropy_inet_decision_function_fv_metric: 0.6305 - binary_accuracy_inet_decision_function_fv_metric: 0.6446 - val_loss: 0.6391 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6391 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6325\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 12s 687ms/step - loss: 0.6277 - binary_crossentropy_inet_decision_function_fv_metric: 0.6276 - binary_accuracy_inet_decision_function_fv_metric: 0.6468 - val_loss: 0.6366 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6366 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6360\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 12s 682ms/step - loss: 0.6274 - binary_crossentropy_inet_decision_function_fv_metric: 0.6273 - binary_accuracy_inet_decision_function_fv_metric: 0.6482 - val_loss: 0.6392 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6392 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6344\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 12s 662ms/step - loss: 0.6282 - binary_crossentropy_inet_decision_function_fv_metric: 0.6282 - binary_accuracy_inet_decision_function_fv_metric: 0.6479 - val_loss: 0.6389 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6390 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6365\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 12s 671ms/step - loss: 0.6261 - binary_crossentropy_inet_decision_function_fv_metric: 0.6261 - binary_accuracy_inet_decision_function_fv_metric: 0.6505 - val_loss: 0.6364 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6365 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6392\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 12s 678ms/step - loss: 0.6228 - binary_crossentropy_inet_decision_function_fv_metric: 0.6228 - binary_accuracy_inet_decision_function_fv_metric: 0.6532 - val_loss: 0.6332 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6333 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6412\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.6196 - binary_crossentropy_inet_decision_function_fv_metric: 0.6196 - binary_accuracy_inet_decision_function_fv_metric: 0.6553 - val_loss: 0.6305 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6306 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6438\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 13s 700ms/step - loss: 0.6140 - binary_crossentropy_inet_decision_function_fv_metric: 0.6140 - binary_accuracy_inet_decision_function_fv_metric: 0.6604 - val_loss: 0.6271 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6272 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6483\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 13s 698ms/step - loss: 0.6082 - binary_crossentropy_inet_decision_function_fv_metric: 0.6083 - binary_accuracy_inet_decision_function_fv_metric: 0.6645 - val_loss: 0.6229 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6229 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6505\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 12s 682ms/step - loss: 0.6037 - binary_crossentropy_inet_decision_function_fv_metric: 0.6035 - binary_accuracy_inet_decision_function_fv_metric: 0.6678 - val_loss: 0.6187 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6188 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6548\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 12s 698ms/step - loss: 0.6034 - binary_crossentropy_inet_decision_function_fv_metric: 0.6032 - binary_accuracy_inet_decision_function_fv_metric: 0.6668 - val_loss: 0.6144 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6145 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6580\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 12s 672ms/step - loss: 0.5951 - binary_crossentropy_inet_decision_function_fv_metric: 0.5950 - binary_accuracy_inet_decision_function_fv_metric: 0.6726 - val_loss: 0.6092 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6092 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6592\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 12s 669ms/step - loss: 0.5907 - binary_crossentropy_inet_decision_function_fv_metric: 0.5907 - binary_accuracy_inet_decision_function_fv_metric: 0.6747 - val_loss: 0.6048 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6049 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6662\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 12s 676ms/step - loss: 0.5897 - binary_crossentropy_inet_decision_function_fv_metric: 0.5898 - binary_accuracy_inet_decision_function_fv_metric: 0.6757 - val_loss: 0.6050 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6051 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6614\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 12s 674ms/step - loss: 0.5925 - binary_crossentropy_inet_decision_function_fv_metric: 0.5925 - binary_accuracy_inet_decision_function_fv_metric: 0.6737 - val_loss: 0.6134 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6135 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6609\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 12s 675ms/step - loss: 0.6048 - binary_crossentropy_inet_decision_function_fv_metric: 0.6050 - binary_accuracy_inet_decision_function_fv_metric: 0.6643 - val_loss: 0.6160 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6161 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6573\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 12s 649ms/step - loss: 0.6007 - binary_crossentropy_inet_decision_function_fv_metric: 0.6004 - binary_accuracy_inet_decision_function_fv_metric: 0.6680 - val_loss: 0.6112 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6112 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6594\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 12s 692ms/step - loss: 0.5941 - binary_crossentropy_inet_decision_function_fv_metric: 0.5939 - binary_accuracy_inet_decision_function_fv_metric: 0.6732 - val_loss: 0.6109 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6110 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6589\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 12s 667ms/step - loss: 0.5891 - binary_crossentropy_inet_decision_function_fv_metric: 0.5890 - binary_accuracy_inet_decision_function_fv_metric: 0.6766 - val_loss: 0.6003 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6004 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6656\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 12s 690ms/step - loss: 0.5825 - binary_crossentropy_inet_decision_function_fv_metric: 0.5824 - binary_accuracy_inet_decision_function_fv_metric: 0.6821 - val_loss: 0.5947 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5948 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6716\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 12s 671ms/step - loss: 0.5770 - binary_crossentropy_inet_decision_function_fv_metric: 0.5771 - binary_accuracy_inet_decision_function_fv_metric: 0.6856 - val_loss: 0.5938 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5939 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6762\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 12s 680ms/step - loss: 0.5725 - binary_crossentropy_inet_decision_function_fv_metric: 0.5725 - binary_accuracy_inet_decision_function_fv_metric: 0.6890 - val_loss: 0.5941 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5941 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6742\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 12s 683ms/step - loss: 0.5738 - binary_crossentropy_inet_decision_function_fv_metric: 0.5741 - binary_accuracy_inet_decision_function_fv_metric: 0.6889 - val_loss: 0.5922 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5923 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6755\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 12s 658ms/step - loss: 0.5809 - binary_crossentropy_inet_decision_function_fv_metric: 0.5809 - binary_accuracy_inet_decision_function_fv_metric: 0.6836 - val_loss: 0.6022 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6023 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6665\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 12s 665ms/step - loss: 0.5883 - binary_crossentropy_inet_decision_function_fv_metric: 0.5883 - binary_accuracy_inet_decision_function_fv_metric: 0.6798 - val_loss: 0.6044 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6045 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6661\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 12s 687ms/step - loss: 0.5903 - binary_crossentropy_inet_decision_function_fv_metric: 0.5904 - binary_accuracy_inet_decision_function_fv_metric: 0.6787 - val_loss: 0.6070 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6071 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6639\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 12s 669ms/step - loss: 0.5884 - binary_crossentropy_inet_decision_function_fv_metric: 0.5889 - binary_accuracy_inet_decision_function_fv_metric: 0.6796 - val_loss: 0.6102 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6103 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6619\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 12s 684ms/step - loss: 0.5896 - binary_crossentropy_inet_decision_function_fv_metric: 0.5896 - binary_accuracy_inet_decision_function_fv_metric: 0.6787 - val_loss: 0.6067 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6067 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6662\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 12s 664ms/step - loss: 0.5881 - binary_crossentropy_inet_decision_function_fv_metric: 0.5879 - binary_accuracy_inet_decision_function_fv_metric: 0.6798 - val_loss: 0.6060 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6060 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6674\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 12s 671ms/step - loss: 0.5842 - binary_crossentropy_inet_decision_function_fv_metric: 0.5843 - binary_accuracy_inet_decision_function_fv_metric: 0.6833 - val_loss: 0.6064 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6064 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6674\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.5835 - binary_crossentropy_inet_decision_function_fv_metric: 0.5834 - binary_accuracy_inet_decision_function_fv_metric: 0.6847 - val_loss: 0.6052 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6053 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6664\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 12s 695ms/step - loss: 0.5817 - binary_crossentropy_inet_decision_function_fv_metric: 0.5818 - binary_accuracy_inet_decision_function_fv_metric: 0.6860 - val_loss: 0.6023 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6023 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6680\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 12s 686ms/step - loss: 0.5779 - binary_crossentropy_inet_decision_function_fv_metric: 0.5779 - binary_accuracy_inet_decision_function_fv_metric: 0.6889 - val_loss: 0.6031 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6032 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6679\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 13s 696ms/step - loss: 0.5743 - binary_crossentropy_inet_decision_function_fv_metric: 0.5743 - binary_accuracy_inet_decision_function_fv_metric: 0.6921 - val_loss: 0.6025 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6026 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6660\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 12s 670ms/step - loss: 0.5708 - binary_crossentropy_inet_decision_function_fv_metric: 0.5708 - binary_accuracy_inet_decision_function_fv_metric: 0.6944 - val_loss: 0.6017 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6018 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6659\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 12s 667ms/step - loss: 0.5687 - binary_crossentropy_inet_decision_function_fv_metric: 0.5688 - binary_accuracy_inet_decision_function_fv_metric: 0.6960 - val_loss: 0.5993 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5993 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6688\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 12s 680ms/step - loss: 0.5657 - binary_crossentropy_inet_decision_function_fv_metric: 0.5657 - binary_accuracy_inet_decision_function_fv_metric: 0.6983 - val_loss: 0.6006 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6007 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6667\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 12s 650ms/step - loss: 0.5630 - binary_crossentropy_inet_decision_function_fv_metric: 0.5630 - binary_accuracy_inet_decision_function_fv_metric: 0.7005 - val_loss: 0.5954 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5955 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6721\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 12s 682ms/step - loss: 0.5606 - binary_crossentropy_inet_decision_function_fv_metric: 0.5602 - binary_accuracy_inet_decision_function_fv_metric: 0.7026 - val_loss: 0.5979 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5979 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6692\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 12s 671ms/step - loss: 0.5599 - binary_crossentropy_inet_decision_function_fv_metric: 0.5599 - binary_accuracy_inet_decision_function_fv_metric: 0.7026 - val_loss: 0.5931 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5931 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6751\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 12s 675ms/step - loss: 0.5584 - binary_crossentropy_inet_decision_function_fv_metric: 0.5582 - binary_accuracy_inet_decision_function_fv_metric: 0.7037 - val_loss: 0.5873 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5873 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6776\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 12s 685ms/step - loss: 0.5543 - binary_crossentropy_inet_decision_function_fv_metric: 0.5539 - binary_accuracy_inet_decision_function_fv_metric: 0.7068 - val_loss: 0.5865 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5865 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6775\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.5500 - binary_crossentropy_inet_decision_function_fv_metric: 0.5497 - binary_accuracy_inet_decision_function_fv_metric: 0.7098 - val_loss: 0.5856 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5856 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6804\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 12s 681ms/step - loss: 0.5476 - binary_crossentropy_inet_decision_function_fv_metric: 0.5479 - binary_accuracy_inet_decision_function_fv_metric: 0.7112 - val_loss: 0.5844 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5845 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6791\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 12s 645ms/step - loss: 0.5452 - binary_crossentropy_inet_decision_function_fv_metric: 0.5451 - binary_accuracy_inet_decision_function_fv_metric: 0.7132 - val_loss: 0.5836 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5836 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6829\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 12s 671ms/step - loss: 0.5442 - binary_crossentropy_inet_decision_function_fv_metric: 0.5442 - binary_accuracy_inet_decision_function_fv_metric: 0.7138 - val_loss: 0.5801 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5801 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6842\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 12s 673ms/step - loss: 0.5417 - binary_crossentropy_inet_decision_function_fv_metric: 0.5413 - binary_accuracy_inet_decision_function_fv_metric: 0.7162 - val_loss: 0.5821 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5821 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6846\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 12s 670ms/step - loss: 0.5404 - binary_crossentropy_inet_decision_function_fv_metric: 0.5402 - binary_accuracy_inet_decision_function_fv_metric: 0.7168 - val_loss: 0.5800 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5800 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6853\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 12s 678ms/step - loss: 0.5402 - binary_crossentropy_inet_decision_function_fv_metric: 0.5402 - binary_accuracy_inet_decision_function_fv_metric: 0.7173 - val_loss: 0.5817 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5816 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6852\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 12s 662ms/step - loss: 0.5374 - binary_crossentropy_inet_decision_function_fv_metric: 0.5375 - binary_accuracy_inet_decision_function_fv_metric: 0.7193 - val_loss: 0.5835 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5835 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6828\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 12s 682ms/step - loss: 0.5360 - binary_crossentropy_inet_decision_function_fv_metric: 0.5361 - binary_accuracy_inet_decision_function_fv_metric: 0.7201 - val_loss: 0.5788 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5788 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6894\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 12s 650ms/step - loss: 0.5342 - binary_crossentropy_inet_decision_function_fv_metric: 0.5344 - binary_accuracy_inet_decision_function_fv_metric: 0.7211 - val_loss: 0.5815 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5814 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6871\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 12s 646ms/step - loss: 0.5334 - binary_crossentropy_inet_decision_function_fv_metric: 0.5339 - binary_accuracy_inet_decision_function_fv_metric: 0.7215 - val_loss: 0.5802 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5802 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6882\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 12s 657ms/step - loss: 0.5297 - binary_crossentropy_inet_decision_function_fv_metric: 0.5298 - binary_accuracy_inet_decision_function_fv_metric: 0.7248 - val_loss: 0.5763 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5763 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6923\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 13s 708ms/step - loss: 0.5260 - binary_crossentropy_inet_decision_function_fv_metric: 0.5257 - binary_accuracy_inet_decision_function_fv_metric: 0.7273 - val_loss: 0.5765 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5764 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6879\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 12s 675ms/step - loss: 0.5250 - binary_crossentropy_inet_decision_function_fv_metric: 0.5250 - binary_accuracy_inet_decision_function_fv_metric: 0.7278 - val_loss: 0.5767 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5766 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6885\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 12s 686ms/step - loss: 0.5264 - binary_crossentropy_inet_decision_function_fv_metric: 0.5264 - binary_accuracy_inet_decision_function_fv_metric: 0.7269 - val_loss: 0.5782 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5781 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6881\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 12s 657ms/step - loss: 0.5244 - binary_crossentropy_inet_decision_function_fv_metric: 0.5244 - binary_accuracy_inet_decision_function_fv_metric: 0.7285 - val_loss: 0.5784 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5784 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6882\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 12s 644ms/step - loss: 0.5225 - binary_crossentropy_inet_decision_function_fv_metric: 0.5226 - binary_accuracy_inet_decision_function_fv_metric: 0.7294 - val_loss: 0.5785 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5784 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6881\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 12s 675ms/step - loss: 0.5202 - binary_crossentropy_inet_decision_function_fv_metric: 0.5201 - binary_accuracy_inet_decision_function_fv_metric: 0.7311 - val_loss: 0.5748 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5747 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6913\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 12s 689ms/step - loss: 0.5209 - binary_crossentropy_inet_decision_function_fv_metric: 0.5209 - binary_accuracy_inet_decision_function_fv_metric: 0.7305 - val_loss: 0.5701 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5701 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6956\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 12s 674ms/step - loss: 0.5192 - binary_crossentropy_inet_decision_function_fv_metric: 0.5194 - binary_accuracy_inet_decision_function_fv_metric: 0.7322 - val_loss: 0.5716 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5716 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6907\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 12s 686ms/step - loss: 0.5167 - binary_crossentropy_inet_decision_function_fv_metric: 0.5168 - binary_accuracy_inet_decision_function_fv_metric: 0.7335 - val_loss: 0.5716 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5716 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6954\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 12s 688ms/step - loss: 0.5139 - binary_crossentropy_inet_decision_function_fv_metric: 0.5135 - binary_accuracy_inet_decision_function_fv_metric: 0.7361 - val_loss: 0.5758 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5757 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6915\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 12s 691ms/step - loss: 0.5152 - binary_crossentropy_inet_decision_function_fv_metric: 0.5152 - binary_accuracy_inet_decision_function_fv_metric: 0.7352 - val_loss: 0.5738 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5738 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6917\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 12s 674ms/step - loss: 0.5129 - binary_crossentropy_inet_decision_function_fv_metric: 0.5126 - binary_accuracy_inet_decision_function_fv_metric: 0.7369 - val_loss: 0.5707 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5706 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6929\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 12s 667ms/step - loss: 0.5091 - binary_crossentropy_inet_decision_function_fv_metric: 0.5093 - binary_accuracy_inet_decision_function_fv_metric: 0.7384 - val_loss: 0.5673 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5672 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6940\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 12s 672ms/step - loss: 0.5065 - binary_crossentropy_inet_decision_function_fv_metric: 0.5063 - binary_accuracy_inet_decision_function_fv_metric: 0.7405 - val_loss: 0.5717 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5717 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6939\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 12s 672ms/step - loss: 0.5066 - binary_crossentropy_inet_decision_function_fv_metric: 0.5065 - binary_accuracy_inet_decision_function_fv_metric: 0.7406 - val_loss: 0.5664 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5663 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6939\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 12s 698ms/step - loss: 0.5050 - binary_crossentropy_inet_decision_function_fv_metric: 0.5048 - binary_accuracy_inet_decision_function_fv_metric: 0.7416 - val_loss: 0.5661 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5661 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6966\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 12s 652ms/step - loss: 0.5043 - binary_crossentropy_inet_decision_function_fv_metric: 0.5045 - binary_accuracy_inet_decision_function_fv_metric: 0.7416 - val_loss: 0.5677 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5677 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6946\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 12s 679ms/step - loss: 0.5028 - binary_crossentropy_inet_decision_function_fv_metric: 0.5026 - binary_accuracy_inet_decision_function_fv_metric: 0.7435 - val_loss: 0.5675 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5675 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6939\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 12s 675ms/step - loss: 0.5030 - binary_crossentropy_inet_decision_function_fv_metric: 0.5032 - binary_accuracy_inet_decision_function_fv_metric: 0.7433 - val_loss: 0.5713 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5713 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6943\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 12s 681ms/step - loss: 0.5041 - binary_crossentropy_inet_decision_function_fv_metric: 0.5039 - binary_accuracy_inet_decision_function_fv_metric: 0.7424 - val_loss: 0.5666 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5666 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6955\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 12s 679ms/step - loss: 0.5031 - binary_crossentropy_inet_decision_function_fv_metric: 0.5030 - binary_accuracy_inet_decision_function_fv_metric: 0.7439 - val_loss: 0.5678 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5678 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6957\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 12s 657ms/step - loss: 0.4973 - binary_crossentropy_inet_decision_function_fv_metric: 0.4975 - binary_accuracy_inet_decision_function_fv_metric: 0.7473 - val_loss: 0.5633 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5633 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6985\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 12s 676ms/step - loss: 0.4934 - binary_crossentropy_inet_decision_function_fv_metric: 0.4933 - binary_accuracy_inet_decision_function_fv_metric: 0.7502 - val_loss: 0.5644 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5644 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6983\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 12s 684ms/step - loss: 0.4901 - binary_crossentropy_inet_decision_function_fv_metric: 0.4900 - binary_accuracy_inet_decision_function_fv_metric: 0.7522 - val_loss: 0.5620 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5620 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7019\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 12s 666ms/step - loss: 0.4884 - binary_crossentropy_inet_decision_function_fv_metric: 0.4885 - binary_accuracy_inet_decision_function_fv_metric: 0.7532 - val_loss: 0.5671 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5672 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6975\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 12s 665ms/step - loss: 0.4875 - binary_crossentropy_inet_decision_function_fv_metric: 0.4875 - binary_accuracy_inet_decision_function_fv_metric: 0.7539 - val_loss: 0.5595 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5595 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7021\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 12s 695ms/step - loss: 0.4839 - binary_crossentropy_inet_decision_function_fv_metric: 0.4838 - binary_accuracy_inet_decision_function_fv_metric: 0.7565 - val_loss: 0.5599 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5599 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7018\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 12s 663ms/step - loss: 0.4820 - binary_crossentropy_inet_decision_function_fv_metric: 0.4821 - binary_accuracy_inet_decision_function_fv_metric: 0.7575 - val_loss: 0.5594 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5595 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7030\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 12s 689ms/step - loss: 0.4776 - binary_crossentropy_inet_decision_function_fv_metric: 0.4778 - binary_accuracy_inet_decision_function_fv_metric: 0.7601 - val_loss: 0.5574 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5574 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7034\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 12s 678ms/step - loss: 0.4765 - binary_crossentropy_inet_decision_function_fv_metric: 0.4765 - binary_accuracy_inet_decision_function_fv_metric: 0.7613 - val_loss: 0.5546 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5546 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7103\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 12s 670ms/step - loss: 0.4761 - binary_crossentropy_inet_decision_function_fv_metric: 0.4757 - binary_accuracy_inet_decision_function_fv_metric: 0.7618 - val_loss: 0.5528 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7054\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 12s 681ms/step - loss: 0.4730 - binary_crossentropy_inet_decision_function_fv_metric: 0.4731 - binary_accuracy_inet_decision_function_fv_metric: 0.7638 - val_loss: 0.5506 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5506 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7109\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 12s 660ms/step - loss: 0.4690 - binary_crossentropy_inet_decision_function_fv_metric: 0.4688 - binary_accuracy_inet_decision_function_fv_metric: 0.7662 - val_loss: 0.5519 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5520 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7100\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 12s 692ms/step - loss: 0.4663 - binary_crossentropy_inet_decision_function_fv_metric: 0.4666 - binary_accuracy_inet_decision_function_fv_metric: 0.7675 - val_loss: 0.5499 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5499 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7106\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 12s 662ms/step - loss: 0.4687 - binary_crossentropy_inet_decision_function_fv_metric: 0.4685 - binary_accuracy_inet_decision_function_fv_metric: 0.7666 - val_loss: 0.5535 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5536 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7125\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 12s 689ms/step - loss: 0.4652 - binary_crossentropy_inet_decision_function_fv_metric: 0.4651 - binary_accuracy_inet_decision_function_fv_metric: 0.7688 - val_loss: 0.5487 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5486 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7134\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 12s 660ms/step - loss: 0.4670 - binary_crossentropy_inet_decision_function_fv_metric: 0.4667 - binary_accuracy_inet_decision_function_fv_metric: 0.7673 - val_loss: 0.5378 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5378 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7201\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 12s 690ms/step - loss: 0.4663 - binary_crossentropy_inet_decision_function_fv_metric: 0.4662 - binary_accuracy_inet_decision_function_fv_metric: 0.7682 - val_loss: 0.5436 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5436 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7164\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 12s 670ms/step - loss: 0.4657 - binary_crossentropy_inet_decision_function_fv_metric: 0.4654 - binary_accuracy_inet_decision_function_fv_metric: 0.7690 - val_loss: 0.5397 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5397 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7211\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 12s 659ms/step - loss: 0.4605 - binary_crossentropy_inet_decision_function_fv_metric: 0.4604 - binary_accuracy_inet_decision_function_fv_metric: 0.7719 - val_loss: 0.5423 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5424 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7161\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.4570 - binary_crossentropy_inet_decision_function_fv_metric: 0.4567 - binary_accuracy_inet_decision_function_fv_metric: 0.7741 - val_loss: 0.5396 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5396 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7209\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 12s 676ms/step - loss: 0.4533 - binary_crossentropy_inet_decision_function_fv_metric: 0.4536 - binary_accuracy_inet_decision_function_fv_metric: 0.7759 - val_loss: 0.5425 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5425 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7178\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 12s 664ms/step - loss: 0.4495 - binary_crossentropy_inet_decision_function_fv_metric: 0.4493 - binary_accuracy_inet_decision_function_fv_metric: 0.7786 - val_loss: 0.5390 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5390 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7216\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.4467 - binary_crossentropy_inet_decision_function_fv_metric: 0.4471 - binary_accuracy_inet_decision_function_fv_metric: 0.7798 - val_loss: 0.5415 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5415 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7209\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 12s 657ms/step - loss: 0.4453 - binary_crossentropy_inet_decision_function_fv_metric: 0.4455 - binary_accuracy_inet_decision_function_fv_metric: 0.7809 - val_loss: 0.5434 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5434 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7181\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 12s 673ms/step - loss: 0.4441 - binary_crossentropy_inet_decision_function_fv_metric: 0.4444 - binary_accuracy_inet_decision_function_fv_metric: 0.7817 - val_loss: 0.5411 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5411 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7212\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 12s 684ms/step - loss: 0.4434 - binary_crossentropy_inet_decision_function_fv_metric: 0.4436 - binary_accuracy_inet_decision_function_fv_metric: 0.7819 - val_loss: 0.5428 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5428 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7212\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 12s 658ms/step - loss: 0.4435 - binary_crossentropy_inet_decision_function_fv_metric: 0.4432 - binary_accuracy_inet_decision_function_fv_metric: 0.7826 - val_loss: 0.5431 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5431 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7200\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 12s 674ms/step - loss: 0.4457 - binary_crossentropy_inet_decision_function_fv_metric: 0.4461 - binary_accuracy_inet_decision_function_fv_metric: 0.7807 - val_loss: 0.5432 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5432 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7177\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 12s 674ms/step - loss: 0.4476 - binary_crossentropy_inet_decision_function_fv_metric: 0.4477 - binary_accuracy_inet_decision_function_fv_metric: 0.7802 - val_loss: 0.5403 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5403 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7203\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 12s 688ms/step - loss: 0.4408 - binary_crossentropy_inet_decision_function_fv_metric: 0.4407 - binary_accuracy_inet_decision_function_fv_metric: 0.7843 - val_loss: 0.5365 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5364 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7240\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 12s 671ms/step - loss: 0.4402 - binary_crossentropy_inet_decision_function_fv_metric: 0.4402 - binary_accuracy_inet_decision_function_fv_metric: 0.7845 - val_loss: 0.5333 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5333 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7252\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 12s 684ms/step - loss: 0.4396 - binary_crossentropy_inet_decision_function_fv_metric: 0.4397 - binary_accuracy_inet_decision_function_fv_metric: 0.7853 - val_loss: 0.5357 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5357 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7254\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 12s 676ms/step - loss: 0.4386 - binary_crossentropy_inet_decision_function_fv_metric: 0.4384 - binary_accuracy_inet_decision_function_fv_metric: 0.7862 - val_loss: 0.5342 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5341 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7251\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 12s 679ms/step - loss: 0.4364 - binary_crossentropy_inet_decision_function_fv_metric: 0.4368 - binary_accuracy_inet_decision_function_fv_metric: 0.7868 - val_loss: 0.5365 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5364 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7258\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 12s 669ms/step - loss: 0.4324 - binary_crossentropy_inet_decision_function_fv_metric: 0.4319 - binary_accuracy_inet_decision_function_fv_metric: 0.7901 - val_loss: 0.5374 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5374 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7224\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 11s 634ms/step - loss: 0.4298 - binary_crossentropy_inet_decision_function_fv_metric: 0.4301 - binary_accuracy_inet_decision_function_fv_metric: 0.7910 - val_loss: 0.5358 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5358 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7240\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 12s 663ms/step - loss: 0.4286 - binary_crossentropy_inet_decision_function_fv_metric: 0.4285 - binary_accuracy_inet_decision_function_fv_metric: 0.7920 - val_loss: 0.5389 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5388 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7258\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 12s 688ms/step - loss: 0.4276 - binary_crossentropy_inet_decision_function_fv_metric: 0.4276 - binary_accuracy_inet_decision_function_fv_metric: 0.7922 - val_loss: 0.5377 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5377 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7231\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 12s 673ms/step - loss: 0.4293 - binary_crossentropy_inet_decision_function_fv_metric: 0.4294 - binary_accuracy_inet_decision_function_fv_metric: 0.7913 - val_loss: 0.5347 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5347 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7258\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 12s 665ms/step - loss: 0.4273 - binary_crossentropy_inet_decision_function_fv_metric: 0.4274 - binary_accuracy_inet_decision_function_fv_metric: 0.7928 - val_loss: 0.5325 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5324 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7281\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 12s 678ms/step - loss: 0.4268 - binary_crossentropy_inet_decision_function_fv_metric: 0.4267 - binary_accuracy_inet_decision_function_fv_metric: 0.7931 - val_loss: 0.5323 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5323 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7271\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 12s 648ms/step - loss: 0.4251 - binary_crossentropy_inet_decision_function_fv_metric: 0.4254 - binary_accuracy_inet_decision_function_fv_metric: 0.7941 - val_loss: 0.5352 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5351 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7234\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 12s 680ms/step - loss: 0.4237 - binary_crossentropy_inet_decision_function_fv_metric: 0.4239 - binary_accuracy_inet_decision_function_fv_metric: 0.7949 - val_loss: 0.5375 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5375 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7265\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 12s 685ms/step - loss: 0.4242 - binary_crossentropy_inet_decision_function_fv_metric: 0.4243 - binary_accuracy_inet_decision_function_fv_metric: 0.7948 - val_loss: 0.5322 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5321 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7286\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 12s 690ms/step - loss: 0.4232 - binary_crossentropy_inet_decision_function_fv_metric: 0.4235 - binary_accuracy_inet_decision_function_fv_metric: 0.7954 - val_loss: 0.5311 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5311 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7275\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 12s 657ms/step - loss: 0.4210 - binary_crossentropy_inet_decision_function_fv_metric: 0.4211 - binary_accuracy_inet_decision_function_fv_metric: 0.7971 - val_loss: 0.5349 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5348 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7253\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 12s 671ms/step - loss: 0.4179 - binary_crossentropy_inet_decision_function_fv_metric: 0.4177 - binary_accuracy_inet_decision_function_fv_metric: 0.7989 - val_loss: 0.5353 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5353 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7264\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 12s 680ms/step - loss: 0.4185 - binary_crossentropy_inet_decision_function_fv_metric: 0.4184 - binary_accuracy_inet_decision_function_fv_metric: 0.7989 - val_loss: 0.5376 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5375 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7253\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 12s 673ms/step - loss: 0.4174 - binary_crossentropy_inet_decision_function_fv_metric: 0.4175 - binary_accuracy_inet_decision_function_fv_metric: 0.7995 - val_loss: 0.5358 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5358 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7265\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.4154 - binary_crossentropy_inet_decision_function_fv_metric: 0.4157 - binary_accuracy_inet_decision_function_fv_metric: 0.8004 - val_loss: 0.5321 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5321 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7287\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 12s 654ms/step - loss: 0.4138 - binary_crossentropy_inet_decision_function_fv_metric: 0.4138 - binary_accuracy_inet_decision_function_fv_metric: 0.8017 - val_loss: 0.5352 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5352 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7268\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 12s 649ms/step - loss: 0.4128 - binary_crossentropy_inet_decision_function_fv_metric: 0.4127 - binary_accuracy_inet_decision_function_fv_metric: 0.8022 - val_loss: 0.5358 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5357 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7293\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 12s 672ms/step - loss: 0.4130 - binary_crossentropy_inet_decision_function_fv_metric: 0.4129 - binary_accuracy_inet_decision_function_fv_metric: 0.8025 - val_loss: 0.5361 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5361 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7274\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 12s 696ms/step - loss: 0.4123 - binary_crossentropy_inet_decision_function_fv_metric: 0.4121 - binary_accuracy_inet_decision_function_fv_metric: 0.8027 - val_loss: 0.5323 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5323 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7278\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 12s 648ms/step - loss: 0.4149 - binary_crossentropy_inet_decision_function_fv_metric: 0.4153 - binary_accuracy_inet_decision_function_fv_metric: 0.8013 - val_loss: 0.5307 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5307 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7275\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 12s 660ms/step - loss: 0.4132 - binary_crossentropy_inet_decision_function_fv_metric: 0.4126 - binary_accuracy_inet_decision_function_fv_metric: 0.8030 - val_loss: 0.5374 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5374 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7255\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 12s 654ms/step - loss: 0.4110 - binary_crossentropy_inet_decision_function_fv_metric: 0.4110 - binary_accuracy_inet_decision_function_fv_metric: 0.8039 - val_loss: 0.5298 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5298 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7283\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.4108 - binary_crossentropy_inet_decision_function_fv_metric: 0.4109 - binary_accuracy_inet_decision_function_fv_metric: 0.8040 - val_loss: 0.5352 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5351 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7278\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 12s 657ms/step - loss: 0.4100 - binary_crossentropy_inet_decision_function_fv_metric: 0.4097 - binary_accuracy_inet_decision_function_fv_metric: 0.8048 - val_loss: 0.5283 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5284 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7288\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 12s 641ms/step - loss: 0.4058 - binary_crossentropy_inet_decision_function_fv_metric: 0.4058 - binary_accuracy_inet_decision_function_fv_metric: 0.8066 - val_loss: 0.5331 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5331 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7299\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 12s 668ms/step - loss: 0.4045 - binary_crossentropy_inet_decision_function_fv_metric: 0.4049 - binary_accuracy_inet_decision_function_fv_metric: 0.8073 - val_loss: 0.5313 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5312 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7279\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 12s 666ms/step - loss: 0.4040 - binary_crossentropy_inet_decision_function_fv_metric: 0.4040 - binary_accuracy_inet_decision_function_fv_metric: 0.8077 - val_loss: 0.5332 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5332 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7266\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 12s 669ms/step - loss: 0.4044 - binary_crossentropy_inet_decision_function_fv_metric: 0.4046 - binary_accuracy_inet_decision_function_fv_metric: 0.8075 - val_loss: 0.5340 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5340 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7301\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 13s 697ms/step - loss: 0.4026 - binary_crossentropy_inet_decision_function_fv_metric: 0.4026 - binary_accuracy_inet_decision_function_fv_metric: 0.8085 - val_loss: 0.5327 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5327 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7289\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 12s 673ms/step - loss: 0.4017 - binary_crossentropy_inet_decision_function_fv_metric: 0.4019 - binary_accuracy_inet_decision_function_fv_metric: 0.8091 - val_loss: 0.5313 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5312 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7291\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 12s 675ms/step - loss: 0.4011 - binary_crossentropy_inet_decision_function_fv_metric: 0.4011 - binary_accuracy_inet_decision_function_fv_metric: 0.8094 - val_loss: 0.5295 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5295 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7309\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 12s 666ms/step - loss: 0.3993 - binary_crossentropy_inet_decision_function_fv_metric: 0.3991 - binary_accuracy_inet_decision_function_fv_metric: 0.8106 - val_loss: 0.5273 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5273 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7304\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 12s 662ms/step - loss: 0.3987 - binary_crossentropy_inet_decision_function_fv_metric: 0.3993 - binary_accuracy_inet_decision_function_fv_metric: 0.8106 - val_loss: 0.5283 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5283 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7313\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 12s 695ms/step - loss: 0.3977 - binary_crossentropy_inet_decision_function_fv_metric: 0.3980 - binary_accuracy_inet_decision_function_fv_metric: 0.8113 - val_loss: 0.5314 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5314 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7304\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 9s 478ms/step - loss: 0.3988 - binary_crossentropy_inet_decision_function_fv_metric: 0.3987 - binary_accuracy_inet_decision_function_fv_metric: 0.8111 - val_loss: 0.5321 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5321 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7286\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 8s 470ms/step - loss: 0.3970 - binary_crossentropy_inet_decision_function_fv_metric: 0.3970 - binary_accuracy_inet_decision_function_fv_metric: 0.8119 - val_loss: 0.5284 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5284 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7319\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 9s 482ms/step - loss: 0.3969 - binary_crossentropy_inet_decision_function_fv_metric: 0.3972 - binary_accuracy_inet_decision_function_fv_metric: 0.8119 - val_loss: 0.5322 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5321 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7315\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 9s 481ms/step - loss: 0.3992 - binary_crossentropy_inet_decision_function_fv_metric: 0.3992 - binary_accuracy_inet_decision_function_fv_metric: 0.8110 - val_loss: 0.5271 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5271 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7296\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 8s 472ms/step - loss: 0.4001 - binary_crossentropy_inet_decision_function_fv_metric: 0.3999 - binary_accuracy_inet_decision_function_fv_metric: 0.8105 - val_loss: 0.5253 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5253 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7310\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 9s 474ms/step - loss: 0.4001 - binary_crossentropy_inet_decision_function_fv_metric: 0.4004 - binary_accuracy_inet_decision_function_fv_metric: 0.8108 - val_loss: 0.5223 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5222 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7333\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 9s 478ms/step - loss: 0.4017 - binary_crossentropy_inet_decision_function_fv_metric: 0.4017 - binary_accuracy_inet_decision_function_fv_metric: 0.8097 - val_loss: 0.5241 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5240 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7316\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 8s 468ms/step - loss: 0.3996 - binary_crossentropy_inet_decision_function_fv_metric: 0.3995 - binary_accuracy_inet_decision_function_fv_metric: 0.8110 - val_loss: 0.5226 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5226 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7333\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 9s 478ms/step - loss: 0.3932 - binary_crossentropy_inet_decision_function_fv_metric: 0.3935 - binary_accuracy_inet_decision_function_fv_metric: 0.8142 - val_loss: 0.5212 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5211 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7358\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 9s 475ms/step - loss: 0.3892 - binary_crossentropy_inet_decision_function_fv_metric: 0.3892 - binary_accuracy_inet_decision_function_fv_metric: 0.8165 - val_loss: 0.5266 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5266 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7315\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 9s 481ms/step - loss: 0.3893 - binary_crossentropy_inet_decision_function_fv_metric: 0.3895 - binary_accuracy_inet_decision_function_fv_metric: 0.8165 - val_loss: 0.5293 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5293 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7316\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 9s 484ms/step - loss: 0.3882 - binary_crossentropy_inet_decision_function_fv_metric: 0.3883 - binary_accuracy_inet_decision_function_fv_metric: 0.8174 - val_loss: 0.5261 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5260 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7332\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 9s 496ms/step - loss: 0.3863 - binary_crossentropy_inet_decision_function_fv_metric: 0.3864 - binary_accuracy_inet_decision_function_fv_metric: 0.8183 - val_loss: 0.5292 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5292 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7340\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 8s 467ms/step - loss: 0.3860 - binary_crossentropy_inet_decision_function_fv_metric: 0.3860 - binary_accuracy_inet_decision_function_fv_metric: 0.8188 - val_loss: 0.5311 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5311 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7344\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 8s 474ms/step - loss: 0.3856 - binary_crossentropy_inet_decision_function_fv_metric: 0.3859 - binary_accuracy_inet_decision_function_fv_metric: 0.8186 - val_loss: 0.5248 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5247 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7362\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 9s 479ms/step - loss: 0.3862 - binary_crossentropy_inet_decision_function_fv_metric: 0.3862 - binary_accuracy_inet_decision_function_fv_metric: 0.8186 - val_loss: 0.5234 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5234 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7341\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 8s 471ms/step - loss: 0.3881 - binary_crossentropy_inet_decision_function_fv_metric: 0.3881 - binary_accuracy_inet_decision_function_fv_metric: 0.8175 - val_loss: 0.5252 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5252 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7347\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 8s 464ms/step - loss: 0.3853 - binary_crossentropy_inet_decision_function_fv_metric: 0.3852 - binary_accuracy_inet_decision_function_fv_metric: 0.8192 - val_loss: 0.5265 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5265 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7363\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 8s 472ms/step - loss: 0.3869 - binary_crossentropy_inet_decision_function_fv_metric: 0.3872 - binary_accuracy_inet_decision_function_fv_metric: 0.8184 - val_loss: 0.5209 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5208 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7353\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 9s 492ms/step - loss: 0.3873 - binary_crossentropy_inet_decision_function_fv_metric: 0.3871 - binary_accuracy_inet_decision_function_fv_metric: 0.8183 - val_loss: 0.5248 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5248 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7336\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 9s 474ms/step - loss: 0.3840 - binary_crossentropy_inet_decision_function_fv_metric: 0.3841 - binary_accuracy_inet_decision_function_fv_metric: 0.8197 - val_loss: 0.5219 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5219 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7381\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 8s 474ms/step - loss: 0.3809 - binary_crossentropy_inet_decision_function_fv_metric: 0.3810 - binary_accuracy_inet_decision_function_fv_metric: 0.8219 - val_loss: 0.5240 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5240 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7351\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 8s 471ms/step - loss: 0.3815 - binary_crossentropy_inet_decision_function_fv_metric: 0.3816 - binary_accuracy_inet_decision_function_fv_metric: 0.8211 - val_loss: 0.5261 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5261 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7340\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 8s 468ms/step - loss: 0.3838 - binary_crossentropy_inet_decision_function_fv_metric: 0.3837 - binary_accuracy_inet_decision_function_fv_metric: 0.8202 - val_loss: 0.5216 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5217 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7372\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 8s 473ms/step - loss: 0.3858 - binary_crossentropy_inet_decision_function_fv_metric: 0.3856 - binary_accuracy_inet_decision_function_fv_metric: 0.8194 - val_loss: 0.5284 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5284 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7344\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 8s 471ms/step - loss: 0.3846 - binary_crossentropy_inet_decision_function_fv_metric: 0.3845 - binary_accuracy_inet_decision_function_fv_metric: 0.8200 - val_loss: 0.5214 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5214 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7389\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 9s 480ms/step - loss: 0.3846 - binary_crossentropy_inet_decision_function_fv_metric: 0.3847 - binary_accuracy_inet_decision_function_fv_metric: 0.8199 - val_loss: 0.5258 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5258 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7371\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 8s 472ms/step - loss: 0.3839 - binary_crossentropy_inet_decision_function_fv_metric: 0.3839 - binary_accuracy_inet_decision_function_fv_metric: 0.8207 - val_loss: 0.5226 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5227 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7393\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 9s 477ms/step - loss: 0.3817 - binary_crossentropy_inet_decision_function_fv_metric: 0.3819 - binary_accuracy_inet_decision_function_fv_metric: 0.8211 - val_loss: 0.5167 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5167 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7383\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 8s 465ms/step - loss: 0.3795 - binary_crossentropy_inet_decision_function_fv_metric: 0.3796 - binary_accuracy_inet_decision_function_fv_metric: 0.8227 - val_loss: 0.5240 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5240 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7369\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 8s 473ms/step - loss: 0.3792 - binary_crossentropy_inet_decision_function_fv_metric: 0.3789 - binary_accuracy_inet_decision_function_fv_metric: 0.8228 - val_loss: 0.5251 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5251 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7358\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 9s 494ms/step - loss: 0.3792 - binary_crossentropy_inet_decision_function_fv_metric: 0.3791 - binary_accuracy_inet_decision_function_fv_metric: 0.8230 - val_loss: 0.5199 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5199 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7380\n",
      "Training Time: 0:41:26\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model,\n",
    " encoder_model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      callback_names=['tensorboard'] #plot_losses\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:22:11.349496Z",
     "iopub.status.busy": "2021-12-17T09:22:11.349230Z",
     "iopub.status.idle": "2021-12-17T09:22:11.548035Z",
     "shell.execute_reply": "2021-12-17T09:22:11.547618Z",
     "shell.execute_reply.started": "2021-12-17T09:22:11.349474Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:22:11.549118Z",
     "iopub.status.busy": "2021-12-17T09:22:11.548781Z",
     "iopub.status.idle": "2021-12-17T09:22:12.722516Z",
     "shell.execute_reply": "2021-12-17T09:22:12.721980Z",
     "shell.execute_reply.started": "2021-12-17T09:22:11.549097Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 3\n",
    "network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "if (config['i_net']['convolution_layers'] != None or config['i_net']['lstm_layers'] != None or (config['i_net']['nas'] and config['i_net']['nas_type'] != 'SEQUENTIAL')) and config['i_net']['data_reshape_version'] is not None:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:22:12.723828Z",
     "iopub.status.busy": "2021-12-17T09:22:12.723508Z",
     "iopub.status.idle": "2021-12-17T09:22:12.732115Z",
     "shell.execute_reply": "2021-12-17T09:22:12.731411Z",
     "shell.execute_reply.started": "2021-12-17T09:22:12.723805Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 4097)]            0         \n",
      "_________________________________________________________________\n",
      "hidden1_2048 (Dense)         (None, 2048)              8392704   \n",
      "_________________________________________________________________\n",
      "activation1_relu (Activation (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "hidden2_128 (Dense)          (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "activation2_relu (Activation (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_233 (Dense)           (None, 233)               30057     \n",
      "=================================================================\n",
      "Total params: 8,685,033\n",
      "Trainable params: 8,685,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:22:12.733330Z",
     "iopub.status.busy": "2021-12-17T09:22:12.733180Z",
     "iopub.status.idle": "2021-12-17T09:28:39.467385Z",
     "shell.execute_reply": "2021-12-17T09:28:39.466458Z",
     "shell.execute_reply.started": "2021-12-17T09:22:12.733311Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=10)]: Done  41 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=10)]: Done  52 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=10)]: Done  65 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=10)]: Done  78 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=10)]: Done  92 out of 100 | elapsed:  6.0min remaining:   31.4s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:  6.4min finished\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_train.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    dt_inet_list = model.predict(np.array(lambda_net_dataset_train.network_parameters_array[:number]))\n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    dt_inet_list = np.array(dt_inet_list)\n",
    "    \n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=10, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_train.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_train.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict == None:\n",
    "            inet_evaluation_result_dict = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    "\n",
    "    inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:28:39.469907Z",
     "iopub.status.busy": "2021-12-17T09:28:39.469222Z",
     "iopub.status.idle": "2021-12-17T09:28:39.496546Z",
     "shell.execute_reply": "2021-12-17T09:28:39.495513Z",
     "shell.execute_reply.started": "2021-12-17T09:28:39.469867Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA RESULTS\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|               Metric              | Distilled DT (Train/Random Data) | Distilled DT (Test Data) | I-Net DT (Test Data) |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|  Soft Binary Crossentropy (Mean)  |              0.418               |          0.419           |         0.53         |\n",
      "|     Binary Crossentropy (Mean)    |              0.141               |          0.157           |        0.413         |\n",
      "|          Accuracy (Mean)          |              0.954               |          0.948           |        0.808         |\n",
      "|          F1 Score (Mean)          |              0.951               |          0.944           |        0.754         |\n",
      "|           Runtime (Mean)          |              35.851              |          35.851          |        0.001         |\n",
      "| Soft Binary Crossentropy (Median) |              0.416               |          0.417           |        0.535         |\n",
      "|    Binary Crossentropy (Median)   |              0.135               |          0.155           |        0.433         |\n",
      "|         Accuracy (Median)         |              0.958               |           0.95           |         0.81         |\n",
      "|         F1 Score (Median)         |              0.958               |          0.953           |         0.82         |\n",
      "|          Runtime (Median)         |              32.998              |          32.998          |        0.001         |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:28:39.499005Z",
     "iopub.status.busy": "2021-12-17T09:28:39.498463Z",
     "iopub.status.idle": "2021-12-17T09:28:54.004474Z",
     "shell.execute_reply": "2021-12-17T09:28:54.004009Z",
     "shell.execute_reply.started": "2021-12-17T09:28:39.498957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06863e35cc0940aa84f4bc4ebf145872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Z-Score (Sample to Train Data):\t\t 2212.465\n",
      "Average Distance to Initialization:\t\t 379.026\n",
      "Average Mean Distance to Train Data:\t\t 539.66\n",
      "Average Distance to closest Train Data Sample:\t 0.0\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "\n",
    "z_score_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    z_score = (sample-mean)/std\n",
    "    z_score_aggregate = np.sum(np.abs(z_score))\n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "\n",
    "z_score_average_train = np.mean(z_score_aggregate_list)\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "distance_to_initialization_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    distance_to_initialization = sample - initialization_array\n",
    "    distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "\n",
    "distance_to_initialization_average_train = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "for sample1 in tqdm(lambda_net_dataset_train.network_parameters_array[:100]):\n",
    "    distance_to_sample_aggregate_list = []\n",
    "    for sample2 in lambda_net_dataset_train.network_parameters_array:\n",
    "        distance_to_sample = sample1 - sample2\n",
    "        distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "        distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "    distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "    distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "    \n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)\n",
    "    \n",
    "distance_to_sample_average_average_train = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_train = np.mean(distance_to_sample_min_list)\n",
    "    \n",
    "print('Average Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_average_train, 3))\n",
    "print('Average Distance to Initialization:\\t\\t', np.round(distance_to_initialization_average_train, 3))   \n",
    "    \n",
    "print('Average Mean Distance to Train Data:\\t\\t', np.round(distance_to_sample_average_average_train, 3))   \n",
    "print('Average Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min_average_train, 3))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:28:54.005675Z",
     "iopub.status.busy": "2021-12-17T09:28:54.005529Z",
     "iopub.status.idle": "2021-12-17T09:35:12.718262Z",
     "shell.execute_reply": "2021-12-17T09:35:12.717631Z",
     "shell.execute_reply.started": "2021-12-17T09:28:54.005655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:  6.3min finished\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_valid.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    dt_inet_list = model.predict(np.array(lambda_net_dataset_valid.network_parameters_array[:number]))\n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    dt_inet_list = np.array(dt_inet_list)\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_valid.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_valid.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict == None:\n",
    "            inet_evaluation_result_dict = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    "\n",
    "    inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:35:12.727517Z",
     "iopub.status.busy": "2021-12-17T09:35:12.727255Z",
     "iopub.status.idle": "2021-12-17T09:35:12.744284Z",
     "shell.execute_reply": "2021-12-17T09:35:12.743197Z",
     "shell.execute_reply.started": "2021-12-17T09:35:12.727487Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID DATA RESULTS\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|               Metric              | Distilled DT (Train/Random Data) | Distilled DT (Test Data) | I-Net DT (Test Data) |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|  Soft Binary Crossentropy (Mean)  |              0.419               |          0.419           |         0.56         |\n",
      "|     Binary Crossentropy (Mean)    |              0.153               |          0.168           |        0.511         |\n",
      "|          Accuracy (Mean)          |              0.949               |          0.943           |        0.742         |\n",
      "|          F1 Score (Mean)          |              0.945               |          0.939           |        0.681         |\n",
      "|           Runtime (Mean)          |              36.098              |          36.098          |        0.001         |\n",
      "| Soft Binary Crossentropy (Median) |              0.411               |          0.413           |        0.575         |\n",
      "|    Binary Crossentropy (Median)   |              0.136               |          0.156           |         0.57         |\n",
      "|         Accuracy (Median)         |              0.957               |          0.952           |        0.733         |\n",
      "|         F1 Score (Median)         |              0.956               |          0.951           |        0.788         |\n",
      "|          Runtime (Median)         |              34.622              |          34.622          |        0.001         |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "print('VALID DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:35:12.746645Z",
     "iopub.status.busy": "2021-12-17T09:35:12.745934Z",
     "iopub.status.idle": "2021-12-17T09:35:31.168532Z",
     "shell.execute_reply": "2021-12-17T09:35:31.167827Z",
     "shell.execute_reply.started": "2021-12-17T09:35:12.746601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed2191f7976466bb56fe8361cc7f549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Z-Score (Sample to Train Data):\t\t 2229.335 \t (2212.465 for Train)\n",
      "Average Distance to Initialization:\t\t 382.102 \t (379.026 for Train)\n",
      "Average Mean Distance to Train Data:\t\t 549.972 \t (539.66 for Train)\n",
      "Average Distance to closest Train Data Sample:\t 326.14 \t (0.0 for Train)\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score_aggregate_list = []\n",
    "for sample in lambda_net_dataset_valid.network_parameters_array:\n",
    "    z_score = (sample-mean)/std\n",
    "    z_score_aggregate = np.sum(np.abs(z_score))\n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "\n",
    "z_score_average = np.mean(z_score_aggregate_list)\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "distance_to_initialization_aggregate_list = []\n",
    "for sample in lambda_net_dataset_valid.network_parameters_array:\n",
    "    distance_to_initialization = sample - initialization_array\n",
    "    distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "\n",
    "distance_to_initialization_average = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "for sample1 in tqdm(lambda_net_dataset_valid.network_parameters_array[:100]):\n",
    "    distance_to_sample_aggregate_list = []\n",
    "    for sample2 in lambda_net_dataset_train.network_parameters_array:\n",
    "        distance_to_sample = sample1 - sample2\n",
    "        distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "        distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "    distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "    distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "    \n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)\n",
    "    \n",
    "distance_to_sample_average_average = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average = np.mean(distance_to_sample_min_list)\n",
    "    \n",
    "print('Average Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_average, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "print('Average Distance to Initialization:\\t\\t', np.round(distance_to_initialization_average, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')    \n",
    "\n",
    "print('Average Mean Distance to Train Data:\\t\\t', np.round(distance_to_sample_average_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Average Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min_average, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:35:31.169712Z",
     "iopub.status.busy": "2021-12-17T09:35:31.169560Z",
     "iopub.status.idle": "2021-12-17T09:38:47.616356Z",
     "shell.execute_reply": "2021-12-17T09:38:47.615832Z",
     "shell.execute_reply.started": "2021-12-17T09:35:31.169690Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = lambda_net_dataset_test.X_test_lambda_array.shape[0]#10\n",
    "\n",
    "    start_inet = time.time() \n",
    "    dt_inet_list = model.predict(np.array(lambda_net_dataset_test.network_parameters_array[:number]))\n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    dt_inet_list = np.array(dt_inet_list)\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_test.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_test.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict == None:\n",
    "            inet_evaluation_result_dict = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    "\n",
    "    inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:38:47.617634Z",
     "iopub.status.busy": "2021-12-17T09:38:47.617346Z",
     "iopub.status.idle": "2021-12-17T09:38:47.631022Z",
     "shell.execute_reply": "2021-12-17T09:38:47.630548Z",
     "shell.execute_reply.started": "2021-12-17T09:38:47.617608Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA RESULTS\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|               Metric              | Distilled DT (Train/Random Data) | Distilled DT (Test Data) | I-Net DT (Test Data) |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|  Soft Binary Crossentropy (Mean)  |              0.474               |          0.477           |        0.675         |\n",
      "|     Binary Crossentropy (Mean)    |              0.276               |          0.292           |        0.695         |\n",
      "|          Accuracy (Mean)          |              0.883               |          0.873           |        0.551         |\n",
      "|          F1 Score (Mean)          |              0.865               |          0.857           |        0.395         |\n",
      "|           Runtime (Mean)          |              35.979              |          35.979          |        0.001         |\n",
      "| Soft Binary Crossentropy (Median) |              0.476               |          0.478           |        0.692         |\n",
      "|    Binary Crossentropy (Median)   |              0.291               |          0.306           |        0.699         |\n",
      "|         Accuracy (Median)         |              0.886               |          0.878           |         0.52         |\n",
      "|         F1 Score (Median)         |              0.883               |          0.872           |        0.388         |\n",
      "|          Runtime (Median)         |              32.973              |          32.973          |        0.001         |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "print('TEST DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:38:47.633049Z",
     "iopub.status.busy": "2021-12-17T09:38:47.632539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bb8f8397b54251a072bd8a2b33446c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score_aggregate_list = []\n",
    "for sample in lambda_net_dataset_test.network_parameters_array:\n",
    "    z_score = (sample-mean)/std\n",
    "    z_score_aggregate = np.sum(np.abs(z_score))\n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "\n",
    "z_score_average = np.mean(z_score_aggregate_list)\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "distance_to_initialization_aggregate_list = []\n",
    "for sample in lambda_net_dataset_test.network_parameters_array:\n",
    "    distance_to_initialization = sample - initialization_array\n",
    "    distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "\n",
    "distance_to_initialization_average = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "for sample1 in tqdm(lambda_net_dataset_test.network_parameters_array[:100]):\n",
    "    distance_to_sample_aggregate_list = []\n",
    "    for sample2 in lambda_net_dataset_train.network_parameters_array:\n",
    "        distance_to_sample = sample1 - sample2\n",
    "        distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "        distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "    distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "    distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "    \n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)\n",
    "    \n",
    "distance_to_sample_average_average = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average = np.mean(distance_to_sample_min_list)\n",
    "    \n",
    "print('Average Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_average, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "print('Average Distance to Initialization:\\t\\t', np.round(distance_to_initialization_average, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')   \n",
    "    \n",
    "print('Average Mean Distance to Train Data:\\t\\t', np.round(distance_to_sample_average_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Average Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min_average, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file: \n",
    "        if different_eval_data:\n",
    "            flat_config = flatten_dict(config_train)\n",
    "        else:\n",
    "            flat_config = flatten_dict(config)\n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key)\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_binary_crossentropy_' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_accuracy' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_f1_score' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_runtime_' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_binary_crossentropy_' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_accuracy' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_score' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_runtime_' + str(i))\n",
    "            text_file.write(';')      \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file: \n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['dt_scores']['binary_crossentropy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['dt_scores']['accuracy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['dt_scores']['f1_score']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['dt_scores']['runtime']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['inet_scores']['binary_crossentropy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['inet_scores']['accuracy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['inet_scores']['f1_score']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['inet_scores']['runtime']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL DATA EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADULT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "\n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "#adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "#adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 'capital_gain'\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "categorical_features = ['Race', 'Workclass', 'Education', \"Marital Status\", \"Occupation\", \"Relationship\"]#[1, 2, 7]\n",
    "ordinal_features = ['Sex', 'capital_gain']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(adult_data)\n",
    "\n",
    "adult_data = transformer.transform(adult_data)\n",
    "adult_data = pd.DataFrame(adult_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    adult_data[ordinal_feature] = OrdinalEncoder().fit_transform(adult_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "adult_data = adult_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "y_data_adult = adult_data['capital_gain']\n",
    "#le = LabelEncoder()\n",
    "#le.fit(y_data_adult)\n",
    "#y_data_adult = le.transform(y_data_adult)\n",
    "#class_names = le.classes_\n",
    "\n",
    "\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data['capital_gain'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_adult.shape[1] > number_of_variables:\n",
    "    #X_data_adult = X_data_adult.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_adult = ExtraTreesClassifier(n_estimators=100)\n",
    "    clf_adult = clf_adult.fit(X_data_adult, y_data_adult)\n",
    "\n",
    "    selector_adult = SelectFromModel(clf_adult, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_adult.get_support()   \n",
    "    X_data_adult = X_data_adult.loc[:,feature_idx]\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_adult.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_adult[column_name] = np.zeros(X_data_adult.shape[0])\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_adult:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_adult[column_name].values.reshape(-1, 1))\n",
    "    X_data_adult[column_name] = scaler.transform(X_data_adult[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_adult_with_valid, X_test_adult, y_train_adult_with_valid, y_test_adult = train_test_split(X_data_adult, y_data_adult, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_adult, X_valid_adult, y_train_adult, y_valid_adult = train_test_split(X_train_adult_with_valid, y_train_adult_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_adult.shape, y_train_adult.shape)\n",
    "print(X_valid_adult.shape, y_valid_adult.shape)\n",
    "print(X_test_adult.shape, y_test_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_adult, y_train_adult = oversample.fit_resample(X_train_adult, y_train_adult)\n",
    "\n",
    "    true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "    false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_adult = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_adult.fit(X_train_adult,\n",
    "                                      y_train_adult, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_adult, y_valid_adult),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult_parameters = shaped_network_parameters_to_array(test_network_adult.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_adult_dt_inet = model.predict(np.array([test_network_adult_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dt_type == 'vanilla':\n",
    "    dataset_size_list_adult = [1_000, 5_000, 10_000, 100_000, 1_000_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "else:\n",
    "    dataset_size_list_adult = [1_000, 10_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "    \n",
    "results_adult_list = []\n",
    "dt_distilled_adult_list = []\n",
    "for dataset_size in dataset_size_list_adult:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_adult.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_adult['inet_scores']['runtime'] = inet_runtime\n",
    "    results_adult_list.append(results_adult)\n",
    "    dt_distilled_adult_list.append(dt_distilled_adult)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_adult['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_adult['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy',  np.round(results_adult['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['binary_crossentropy'], 3), np.round(results_adult['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_adult['dt_scores']['accuracy_data_random'], 3), np.round(results_adult['dt_scores']['accuracy'], 3), np.round(results_adult['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_adult['dt_scores']['f1_score_data_random'], 3), np.round(results_adult['dt_scores']['f1_score'], 3), np.round(results_adult['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n",
    "        \n",
    "adult_evaluation_result_dict = None\n",
    "for some_dict in results_adult_list:\n",
    "    if adult_evaluation_result_dict == None:\n",
    "        adult_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        adult_evaluation_result_dict = mergeDict(adult_evaluation_result_dict, some_dict)\n",
    "\n",
    "adult_evaluation_result_dict['dataset_size'] = dataset_size_list_adult\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score = (test_network_adult_parameters-mean)/std\n",
    "z_score_aggregate = np.sum(np.abs(z_score))\n",
    "\n",
    "print('Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_aggregate, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "\n",
    "distance_to_initialization = test_network_adult_parameters - initialization_array\n",
    "distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "\n",
    "print('Distance to Initialization:\\t\\t', np.round(distance_to_initialization_aggregate, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')   \n",
    "\n",
    "distance_to_sample_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    distance_to_sample = test_network_adult_parameters - sample\n",
    "    distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "    distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "\n",
    "print('Average Distance to Train Data:\\t\\t', np.round(distance_to_sample_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_adult_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_adult_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_adult, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_adult.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = titanic_data.drop([\n",
    "                                    'Cabin', \n",
    "                                    'Ticket', \n",
    "                                    'Name', \n",
    "                                    'PassengerId'\n",
    "                                ], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "categorical_features = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features = ['Sex']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(titanic_data)\n",
    "\n",
    "titanic_data = transformer.transform(titanic_data)\n",
    "titanic_data = pd.DataFrame(titanic_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    titanic_data[ordinal_feature] = OrdinalEncoder().fit_transform(titanic_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "titanic_data = titanic_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_titanic.shape[1] > number_of_variables:\n",
    "    #X_data_titanic = X_data_titanic.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_titanic = ExtraTreesClassifier(n_estimators=100)\n",
    "    clf_titanic = clf_titanic.fit(X_data_titanic, y_data_titanic)\n",
    "\n",
    "    selector_titanic = SelectFromModel(clf_titanic, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_titanic.get_support()   \n",
    "    X_data_titanic = X_data_titanic.loc[:,feature_idx]    \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_titanic.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_titanic[column_name] = np.zeros(X_data_titanic.shape[0])\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_titanic:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_titanic[column_name].values.reshape(-1, 1))\n",
    "    X_data_titanic[column_name] = scaler.transform(X_data_titanic[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_titanic_with_valid, X_test_titanic, y_train_titanic_with_valid, y_test_titanic = train_test_split(X_data_titanic, y_data_titanic, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_titanic, X_valid_titanic, y_train_titanic, y_valid_titanic = train_test_split(X_train_titanic_with_valid, y_train_titanic_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_titanic.shape, y_train_titanic.shape)\n",
    "print(X_valid_titanic.shape, y_valid_titanic.shape)\n",
    "print(X_test_titanic.shape, y_test_titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_titanic, y_train_titanic = oversample.fit_resample(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "    false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_titanic = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_titanic.fit(X_train_titanic,\n",
    "                                          y_train_titanic, \n",
    "                                          epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                          batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                          callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                          validation_data=(X_valid_titanic, y_valid_titanic),\n",
    "                                          verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic_parameters = shaped_network_parameters_to_array(test_network_titanic.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_titanic_dt_inet = model.predict(np.array([test_network_titanic_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dt_type == 'vanilla':\n",
    "    dataset_size_list_titanic = [1_000, 5_000, 10_000, 100_000, 1_000_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "else:\n",
    "    dataset_size_list_titanic = [1_000, 10_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "    \n",
    "results_titanic_list = []\n",
    "dt_distilled_titanic_list = []\n",
    "for dataset_size in dataset_size_list_titanic:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_titanic.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_titanic['inet_scores']['runtime'] = inet_runtime\n",
    "    results_titanic_list.append(results_titanic)\n",
    "    dt_distilled_titanic_list.append(dt_distilled_titanic)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_titanic['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_titanic['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_titanic['dt_scores']['accuracy_data_random'], 3), np.round(results_titanic['dt_scores']['accuracy'], 3), np.round(results_titanic['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_titanic['dt_scores']['f1_score_data_random'], 3), np.round(results_titanic['dt_scores']['f1_score'], 3), np.round(results_titanic['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "        \n",
    "titanic_evaluation_result_dict = None\n",
    "for some_dict in results_titanic_list:\n",
    "    if titanic_evaluation_result_dict == None:\n",
    "        titanic_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        titanic_evaluation_result_dict = mergeDict(titanic_evaluation_result_dict, some_dict)\n",
    "\n",
    "titanic_evaluation_result_dict['dataset_size'] = dataset_size_list_titanic\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score = (test_network_titanic_parameters-mean)/std\n",
    "z_score_aggregate = np.sum(np.abs(z_score))\n",
    "\n",
    "print('Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_aggregate, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "\n",
    "distance_to_initialization = test_network_titanic_parameters - initialization_array\n",
    "distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "\n",
    "print('Distance to Initialization:\\t\\t', np.round(distance_to_initialization_aggregate, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')   \n",
    "\n",
    "distance_to_sample_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    distance_to_sample = test_network_titanic_parameters - sample\n",
    "    distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "    distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "\n",
    "print('Average Distance to Train Data:\\t\\t', np.round(distance_to_sample_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_data_titanic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_titanic_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_titanic_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_titanic, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_titanic.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "absenteeism_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           'Weight', \n",
    "                           'Height', \n",
    "                           'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "categorical_features = []#[1, 2, 7]\n",
    "ordinal_features = []\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(absenteeism_data)\n",
    "\n",
    "absenteeism_data = transformer.transform(absenteeism_data)\n",
    "absenteeism_data = pd.DataFrame(absenteeism_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    absenteeism_data[ordinal_feature] = OrdinalEncoder().fit_transform(absenteeism_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "absenteeism_data = absenteeism_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 4) * 1) #absenteeism_data['Absenteeism time in hours']\n",
    "\n",
    "print(X_data_absenteeism.shape)\n",
    "\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_absenteeism.shape[1] > number_of_variables:\n",
    "    #X_data_absenteeism = X_data_absenteeism.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_absenteeism = ExtraTreesClassifier(n_estimators=100)\n",
    "    clf_absenteeism = clf_absenteeism.fit(X_data_absenteeism, y_data_absenteeism)\n",
    "\n",
    "    selector_absenteeism = SelectFromModel(clf_absenteeism, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_absenteeism.get_support()   \n",
    "    X_data_absenteeism = X_data_absenteeism.loc[:,feature_idx]        \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_absenteeism.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_absenteeism[column_name] = np.zeros(X_data_absenteeism.shape[0])\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_absenteeism:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_absenteeism[column_name].values.reshape(-1, 1))\n",
    "    X_data_absenteeism[column_name] = scaler.transform(X_data_absenteeism[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_absenteeism_with_valid, X_test_absenteeism, y_train_absenteeism_with_valid, y_test_absenteeism = train_test_split(X_data_absenteeism, y_data_absenteeism, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_absenteeism, X_valid_absenteeism, y_train_absenteeism, y_valid_absenteeism = train_test_split(X_train_absenteeism_with_valid, y_train_absenteeism_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_absenteeism.shape, y_train_absenteeism.shape)\n",
    "print(X_valid_absenteeism.shape, y_valid_absenteeism.shape)\n",
    "print(X_test_absenteeism.shape, y_test_absenteeism.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_absenteeism, y_train_absenteeism = oversample.fit_resample(X_train_absenteeism, y_train_absenteeism)\n",
    "\n",
    "    true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "    false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_absenteeism = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_absenteeism.fit(X_train_absenteeism,\n",
    "                                      y_train_absenteeism, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_absenteeism, y_valid_absenteeism),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism_parameters = shaped_network_parameters_to_array(test_network_absenteeism.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_absenteeism_dt_inet = model.predict(np.array([test_network_absenteeism_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dt_type == 'vanilla':\n",
    "    dataset_size_list_absenteeism = [1_000, 5_000, 10_000, 100_000, 1_000_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "else:\n",
    "    dataset_size_list_absenteeism = [1_000, 10_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "\n",
    "results_absenteeism_list = []\n",
    "dt_distilled_absenteeism_list = []\n",
    "for dataset_size in dataset_size_list_absenteeism:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_absenteeism.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_absenteeism['inet_scores']['runtime'] = inet_runtime\n",
    "    results_absenteeism_list.append(results_absenteeism)\n",
    "    dt_distilled_absenteeism_list.append(dt_distilled_absenteeism)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_absenteeism['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_absenteeism['dt_scores']['accuracy_data_random'], 3), np.round(results_absenteeism['dt_scores']['accuracy'], 3), np.round(results_absenteeism['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_absenteeism['dt_scores']['f1_score_data_random'], 3), np.round(results_absenteeism['dt_scores']['f1_score'], 3), np.round(results_absenteeism['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime', np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "        \n",
    "absenteeism_evaluation_result_dict = None\n",
    "for some_dict in results_absenteeism_list:\n",
    "    if absenteeism_evaluation_result_dict == None:\n",
    "        absenteeism_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        absenteeism_evaluation_result_dict = mergeDict(absenteeism_evaluation_result_dict, some_dict)\n",
    "\n",
    "absenteeism_evaluation_result_dict['dataset_size'] = dataset_size_list_absenteeism\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score = (test_network_absenteeism_parameters-mean)/std\n",
    "z_score_aggregate = np.sum(np.abs(z_score))\n",
    "\n",
    "print('Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_aggregate, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "\n",
    "distance_to_initialization = test_network_absenteeism_parameters - initialization_array\n",
    "distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "\n",
    "print('Distance to Initialization:\\t\\t', np.round(distance_to_initialization_aggregate, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')   \n",
    "\n",
    "distance_to_sample_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    distance_to_sample = test_network_absenteeism_parameters - sample\n",
    "    distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "    distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "\n",
    "print('Average Distance to Train Data:\\t\\t', np.round(distance_to_sample_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_absenteeism_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_absenteeism_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_absenteeism, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_absenteeism.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "        if different_eval_data:\n",
    "            flat_config = flatten_dict(config_train)\n",
    "        else:\n",
    "            flat_config = flatten_dict(config)\n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key + ';')\n",
    "            \n",
    "        text_file.write('dt_scores_binary_crossentropy_artificial_mean' + ';')\n",
    "        text_file.write('dt_scores_accuracy_artificial_mean' + ';')\n",
    "        text_file.write('dt_f1_score_artificial_mean' + ';')\n",
    "        text_file.write('dt_scores_runtime_artificial_mean' + ';')\n",
    "        text_file.write('inet_binary_crossentropy_artificial_mean' + ';')\n",
    "        text_file.write('inet_accuracy_artificial_mean' + ';')\n",
    "        text_file.write('inet_score_artificial_mean' + ';')\n",
    "        text_file.write('inet_runtime_artificial_mean' + ';')\n",
    "        \n",
    "        \n",
    "        for dataset_size in dataset_size_list_adult:\n",
    "            text_file.write('dt_scores_data_random_binary_crossentropy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_binary_crossentropy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_data_random_accuracy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_accuracy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_data_random_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_runtime_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_binary_crossentropy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_accuracy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_score_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_runtime_adult_' + str(dataset_size) + ';')\n",
    "        \n",
    "        for dataset_size in dataset_size_list_titanic:\n",
    "            text_file.write('dt_scores_data_random_binary_crossentropy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_binary_crossentropy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_data_random_accuracy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_accuracy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_data_random_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_runtime_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_binary_crossentropy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_accuracy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_score_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_runtime_titanic_' + str(dataset_size) + ';')\n",
    "        \n",
    "        for dataset_size in dataset_size_list_adult:\n",
    "            text_file.write('dt_scores_data_random_binary_crossentropy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_binary_crossentropy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_data_random_accuracy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_accuracy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_data_random_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_runtime_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_binary_crossentropy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_accuracy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_score_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_runtime_absenteeism_' + str(dataset_size) + ';')        \n",
    "    \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "        \n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['runtime']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['runtime']) + ';')\n",
    "    \n",
    "    \n",
    "    for i in range(len(dataset_size_list_adult)):\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['binary_crossentropy_data_random'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['accuracy_data_random'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['f1_score_data_random'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['runtime'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['runtime'][i]) + ';')\n",
    "    \n",
    "    for i in range(len(dataset_size_list_titanic)):\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['binary_crossentropy_data_random'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['accuracy_data_random'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['f1_score_data_random'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['runtime'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['runtime'][i]) + ';')\n",
    "    \n",
    "    for i in range(len(dataset_size_list_absenteeism)):\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['binary_crossentropy_data_random'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['accuracy_data_random'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['f1_score_data_random'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['runtime'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['runtime'][i]) + ';')\n",
    "        \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import gc\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "test_network = generate_lambda_net_from_config(config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network = generate_lambda_net_from_config(config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
