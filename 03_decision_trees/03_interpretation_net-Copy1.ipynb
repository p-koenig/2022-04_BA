{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 4,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,                      \n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 5, \n",
    "        'num_classes': 2,\n",
    "        \n",
    "        'function_generation_type': 'random_decision_tree', # 'make_classification' 'random_decision_tree'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 1000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [64],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [1056, 512],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.2, 0.1],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.001,\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': ['binary_accuracy'],\n",
    "        \n",
    "        'epochs': 10, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 500,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 3, # 1=standard representation; 2=sparse representation, 3=vanilla_dt\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 100,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 50, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        \n",
    "        'n_jobs': -3,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '0',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "from itertools import product       \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import colored\n",
    "import math\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import random \n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/lib/cuda-10.1'\n",
    "\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = (2 ** maximum_depth - 1) * number_of_variables + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes\n",
    "config['function_family']['function_representation_length'] = ( (2 ** maximum_depth - 1) * number_of_variables + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 \n",
    "                                                              else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2\n",
    "                                                              else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes)\n",
    "\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize1000_numLNets10000_var5_class2_random_decision_tree_xMax1_xMin0_xDistuniform_depth4_beta1_decisionSpars1_fullyGrown/64_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1056-512_drop0.2-0.1e10b256_adam\n",
      "lNetSize1000_numLNets10000_var5_class2_random_decision_tree_xMax1_xMin0_xDistuniform_depth4_beta1_decisionSpars1_fullyGrown/64_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    if psutil.virtual_memory().percent > 80:\n",
    "        raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    path_X_data = directory + 'X_test_lambda.txt'\n",
    "    path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    \n",
    "    X_test_lambda = pd.read_csv(path_X_data, sep=\",\", header=None)\n",
    "    X_test_lambda = X_test_lambda.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        X_test_lambda = X_test_lambda.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    \n",
    "    y_test_lambda = pd.read_csv(path_y_data, sep=\",\", header=None)\n",
    "    y_test_lambda = y_test_lambda.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        y_test_lambda = y_test_lambda.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "        \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              X_test_lambda_row, \n",
    "                                              y_test_lambda_row, \n",
    "                                              config) for network_parameters_row, X_test_lambda_row, y_test_lambda_row in zip(network_parameters.values, X_test_lambda.values, y_test_lambda.values))          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "        lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    _ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    del parallel\n",
    "    \n",
    "    def initialize_target_function_wrapper(config, lambda_net):\n",
    "        lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    _ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    del parallel\n",
    "        \n",
    "    \n",
    "    #lambda_nets = [None] * network_parameters.shape[0]\n",
    "    #for i, (network_parameters_row, X_test_lambda_row, y_test_lambda_row) in tqdm(enumerate(zip(network_parameters.values, X_test_lambda.values, y_test_lambda.values)), total=network_parameters.values.shape[0]):        \n",
    "    #    lambda_net = LambdaNet(network_parameters_row, X_test_lambda_row, y_test_lambda_row, config)\n",
    "    #    lambda_nets[i] = lambda_net\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-3)]: Done 420 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-3)]: Done 500 out of 500 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 500 out of 500 | elapsed:   13.6s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 500 out of 500 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if noise_injected_level > 0:\n",
    "    lambda_net_dataset_training = load_lambda_nets(config, no_noise=True, n_jobs=n_jobs)\n",
    "    lambda_net_dataset_evaluation = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_training, test_split=0.1)\n",
    "    _, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_evaluation, test_split=test_size)\n",
    "    \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 573)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 573)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 573)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f11v0</th>\n",
       "      <th>f11v1</th>\n",
       "      <th>f11v2</th>\n",
       "      <th>f11v3</th>\n",
       "      <th>f11v4</th>\n",
       "      <th>f12v0</th>\n",
       "      <th>f12v1</th>\n",
       "      <th>f12v2</th>\n",
       "      <th>f12v3</th>\n",
       "      <th>f12v4</th>\n",
       "      <th>f13v0</th>\n",
       "      <th>f13v1</th>\n",
       "      <th>f13v2</th>\n",
       "      <th>f13v3</th>\n",
       "      <th>f13v4</th>\n",
       "      <th>f14v0</th>\n",
       "      <th>f14v1</th>\n",
       "      <th>f14v2</th>\n",
       "      <th>f14v3</th>\n",
       "      <th>f14v4</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_349</th>\n",
       "      <th>wb_350</th>\n",
       "      <th>wb_351</th>\n",
       "      <th>wb_352</th>\n",
       "      <th>wb_353</th>\n",
       "      <th>wb_354</th>\n",
       "      <th>wb_355</th>\n",
       "      <th>wb_356</th>\n",
       "      <th>wb_357</th>\n",
       "      <th>wb_358</th>\n",
       "      <th>wb_359</th>\n",
       "      <th>wb_360</th>\n",
       "      <th>wb_361</th>\n",
       "      <th>wb_362</th>\n",
       "      <th>wb_363</th>\n",
       "      <th>wb_364</th>\n",
       "      <th>wb_365</th>\n",
       "      <th>wb_366</th>\n",
       "      <th>wb_367</th>\n",
       "      <th>wb_368</th>\n",
       "      <th>wb_369</th>\n",
       "      <th>wb_370</th>\n",
       "      <th>wb_371</th>\n",
       "      <th>wb_372</th>\n",
       "      <th>wb_373</th>\n",
       "      <th>wb_374</th>\n",
       "      <th>wb_375</th>\n",
       "      <th>wb_376</th>\n",
       "      <th>wb_377</th>\n",
       "      <th>wb_378</th>\n",
       "      <th>wb_379</th>\n",
       "      <th>wb_380</th>\n",
       "      <th>wb_381</th>\n",
       "      <th>wb_382</th>\n",
       "      <th>wb_383</th>\n",
       "      <th>wb_384</th>\n",
       "      <th>wb_385</th>\n",
       "      <th>wb_386</th>\n",
       "      <th>wb_387</th>\n",
       "      <th>wb_388</th>\n",
       "      <th>wb_389</th>\n",
       "      <th>wb_390</th>\n",
       "      <th>wb_391</th>\n",
       "      <th>wb_392</th>\n",
       "      <th>wb_393</th>\n",
       "      <th>wb_394</th>\n",
       "      <th>wb_395</th>\n",
       "      <th>wb_396</th>\n",
       "      <th>wb_397</th>\n",
       "      <th>wb_398</th>\n",
       "      <th>wb_399</th>\n",
       "      <th>wb_400</th>\n",
       "      <th>wb_401</th>\n",
       "      <th>wb_402</th>\n",
       "      <th>wb_403</th>\n",
       "      <th>wb_404</th>\n",
       "      <th>wb_405</th>\n",
       "      <th>wb_406</th>\n",
       "      <th>wb_407</th>\n",
       "      <th>wb_408</th>\n",
       "      <th>wb_409</th>\n",
       "      <th>wb_410</th>\n",
       "      <th>wb_411</th>\n",
       "      <th>wb_412</th>\n",
       "      <th>wb_413</th>\n",
       "      <th>wb_414</th>\n",
       "      <th>wb_415</th>\n",
       "      <th>wb_416</th>\n",
       "      <th>wb_417</th>\n",
       "      <th>wb_418</th>\n",
       "      <th>wb_419</th>\n",
       "      <th>wb_420</th>\n",
       "      <th>wb_421</th>\n",
       "      <th>wb_422</th>\n",
       "      <th>wb_423</th>\n",
       "      <th>wb_424</th>\n",
       "      <th>wb_425</th>\n",
       "      <th>wb_426</th>\n",
       "      <th>wb_427</th>\n",
       "      <th>wb_428</th>\n",
       "      <th>wb_429</th>\n",
       "      <th>wb_430</th>\n",
       "      <th>wb_431</th>\n",
       "      <th>wb_432</th>\n",
       "      <th>wb_433</th>\n",
       "      <th>wb_434</th>\n",
       "      <th>wb_435</th>\n",
       "      <th>wb_436</th>\n",
       "      <th>wb_437</th>\n",
       "      <th>wb_438</th>\n",
       "      <th>wb_439</th>\n",
       "      <th>wb_440</th>\n",
       "      <th>wb_441</th>\n",
       "      <th>wb_442</th>\n",
       "      <th>wb_443</th>\n",
       "      <th>wb_444</th>\n",
       "      <th>wb_445</th>\n",
       "      <th>wb_446</th>\n",
       "      <th>wb_447</th>\n",
       "      <th>wb_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5885</th>\n",
       "      <td>5885.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.222</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>0.618</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.896</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.747</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.450</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.901</td>\n",
       "      <td>-0.734</td>\n",
       "      <td>0.864</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>6442.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.261</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.608</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.018</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.648</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.631</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.825</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.436</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.874</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>0.784</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>0.825</td>\n",
       "      <td>1.014</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.708</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.055</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.778</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>0.506</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>1.024</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>4773.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.399</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>0.517</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>-0.564</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.565</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.817</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>-0.549</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.562</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.668</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>0.720</td>\n",
       "      <td>-0.722</td>\n",
       "      <td>1.186</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.581</td>\n",
       "      <td>-0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>2609.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.403</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.458</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.477</td>\n",
       "      <td>-2.010</td>\n",
       "      <td>-0.346</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.115</td>\n",
       "      <td>1.544</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.849</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.762</td>\n",
       "      <td>1.105</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>1.164</td>\n",
       "      <td>1.387</td>\n",
       "      <td>1.738</td>\n",
       "      <td>1.734</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.791</td>\n",
       "      <td>1.943</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>1.566</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>1.209</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-3.334</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>1.393</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-2.445</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>1.305</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>4721.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.464</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.524</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.663</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.589</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>0.485</td>\n",
       "      <td>-0.065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2   f0v3   f0v4  f1v0   f1v1   f1v2  \\\n",
       "5885 5885.000    42 0.000 0.000 0.000  0.000  0.404 0.000 -0.419  0.000   \n",
       "6442 6442.000    42 0.000 0.000 0.000  0.000 -0.217 0.000 -0.434  0.000   \n",
       "4773 4773.000    42 0.000 0.000 0.000 -0.386  0.000 0.000  0.000  0.000   \n",
       "2609 2609.000    42 0.275 0.000 0.000  0.000  0.000 0.000  0.000 -0.440   \n",
       "4721 4721.000    42 0.000 0.000 0.000  0.000  0.384 0.254  0.000  0.000   \n",
       "\n",
       "       f1v3  f1v4  f2v0  f2v1  f2v2  f2v3   f2v4  f3v0   f3v1   f3v2   f3v3  \\\n",
       "5885  0.000 0.000 0.000 0.000 0.000 0.000 -0.363 0.000 -0.391  0.000  0.000   \n",
       "6442  0.000 0.000 0.000 0.000 0.293 0.000  0.000 0.000  0.000  0.000 -0.356   \n",
       "4773 -0.412 0.000 0.000 0.395 0.000 0.000  0.000 0.000  0.000 -0.317  0.000   \n",
       "2609  0.000 0.000 0.000 0.000 0.000 0.000  0.367 0.000  0.000  0.426  0.000   \n",
       "4721  0.000 0.000 0.000 0.000 0.000 0.000  0.354 0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f3v4  f4v0  f4v1   f4v2  f4v3  f4v4  f5v0   f5v1  f5v2  f5v3   f5v4  \\\n",
       "5885 0.000 0.328 0.000  0.000 0.000 0.000 0.000  0.441 0.000 0.000  0.000   \n",
       "6442 0.000 0.000 0.000 -0.393 0.000 0.000 0.000  0.000 0.354 0.000  0.000   \n",
       "4773 0.000 0.000 0.000  0.000 0.000 0.422 0.000 -0.354 0.000 0.000  0.000   \n",
       "2609 0.000 0.000 0.000  0.304 0.000 0.000 0.000  0.000 0.000 0.000 -0.384   \n",
       "4721 0.424 0.000 0.000  0.419 0.000 0.000 0.000  0.000 0.000 0.416  0.000   \n",
       "\n",
       "      f6v0   f6v1   f6v2   f6v3   f6v4   f7v0   f7v1  f7v2  f7v3  f7v4  f8v0  \\\n",
       "5885 0.000  0.000  0.000 -0.337  0.000  0.348  0.000 0.000 0.000 0.000 0.000   \n",
       "6442 0.000  0.000  0.360  0.000  0.000  0.000  0.000 0.000 0.000 0.315 0.000   \n",
       "4773 0.000 -0.220  0.000  0.000  0.000  0.000  0.000 0.117 0.000 0.000 0.331   \n",
       "2609 0.000  0.000 -0.384  0.000  0.000  0.000 -0.439 0.000 0.000 0.000 0.000   \n",
       "4721 0.000  0.000  0.000  0.000 -0.312 -0.399  0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f8v1  f8v2   f8v3  f8v4  f9v0   f9v1  f9v2  f9v3   f9v4  f10v0  f10v1  \\\n",
       "5885 0.000 0.000  0.000 0.356 0.000  0.000 0.000 0.392  0.000  0.000  0.000   \n",
       "6442 0.000 0.000 -0.368 0.000 0.000  0.000 0.000 0.000  0.313  0.000  0.000   \n",
       "4773 0.000 0.000  0.000 0.000 0.000 -0.440 0.000 0.000  0.000  0.000 -0.388   \n",
       "2609 0.000 0.000 -0.361 0.000 0.000  0.342 0.000 0.000  0.000  0.000  0.000   \n",
       "4721 0.000 0.000 -0.372 0.000 0.000  0.000 0.000 0.000 -0.438  0.000  0.000   \n",
       "\n",
       "      f10v2  f10v3  f10v4  f11v0  f11v1  f11v2  f11v3  f11v4  f12v0  f12v1  \\\n",
       "5885  0.000 -0.440  0.000  0.000  0.000  0.411  0.000  0.000  0.000  0.000   \n",
       "6442 -0.262  0.000  0.000  0.000 -0.435  0.000  0.000  0.000  0.000  0.000   \n",
       "4773  0.000  0.000  0.000  0.000  0.000  0.000  0.000 -0.408  0.000  0.000   \n",
       "2609 -0.355  0.000  0.000  0.000 -0.397  0.000  0.000  0.000  0.000  0.000   \n",
       "4721  0.287  0.000  0.000  0.395  0.000  0.000  0.000  0.000  0.000  0.316   \n",
       "\n",
       "      f12v2  f12v3  f12v4  f13v0  f13v1  f13v2  f13v3  f13v4  f14v0  f14v1  \\\n",
       "5885  0.000 -0.189  0.000 -0.318  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6442  0.422  0.000  0.000  0.000 -0.430  0.000  0.000  0.000  0.000  0.000   \n",
       "4773  0.000 -0.423  0.000  0.000  0.000  0.000  0.351  0.000  0.000  0.000   \n",
       "2609  0.312  0.000  0.000  0.000  0.000 -0.420  0.000  0.000  0.000  0.000   \n",
       "4721  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.367  0.000  0.000   \n",
       "\n",
       "      f14v2  f14v3  f14v4     b0    b1     b2     b3     b4     b5     b6  \\\n",
       "5885 -0.349  0.000  0.000  0.307 0.050 -0.357  0.224 -0.298 -0.080 -0.037   \n",
       "6442  0.000 -0.435  0.000 -0.278 0.019  0.020 -0.163  0.358  0.409  0.233   \n",
       "4773  0.418  0.000  0.000  0.035 0.215  0.253  0.406 -0.114  0.252  0.034   \n",
       "2609 -0.373  0.000  0.000 -0.095 0.290  0.080 -0.409 -0.155 -0.026 -0.180   \n",
       "4721  0.000  0.000  0.305  0.220 0.426  0.061 -0.261 -0.308  0.147  0.007   \n",
       "\n",
       "         b7    b8     b9    b10    b11    b12    b13    b14  lp0c0  lp0c1  \\\n",
       "5885  0.040 0.287 -0.019  0.217  0.119 -0.019  0.196  0.069  0.148 -0.197   \n",
       "6442  0.174 0.161  0.368 -0.343  0.269  0.400  0.143  0.230  0.046 -0.004   \n",
       "4773 -0.023 0.024  0.163  0.068  0.205  0.422 -0.008  0.387  0.249 -0.044   \n",
       "2609 -0.142 0.272 -0.366 -0.118 -0.446 -0.097 -0.374 -0.269 -0.059  0.018   \n",
       "4721  0.119 0.120 -0.048 -0.402  0.109  0.066 -0.092  0.178  0.243  0.147   \n",
       "\n",
       "      lp1c0  lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  ...  wb_349  wb_350  wb_351  \\\n",
       "5885 -0.021 -0.110  0.000 -0.110  0.126 -0.203  ...   0.342  -0.044  -0.068   \n",
       "6442  0.001  0.060  0.058  0.097  0.037 -0.119  ...   0.491  -0.220   0.323   \n",
       "4773 -0.127 -0.108  0.114  0.141  0.089 -0.171  ...   0.398  -0.043  -0.143   \n",
       "2609  0.159  0.211  0.239  0.161  0.109  0.205  ...   0.352   0.060  -0.087   \n",
       "4721  0.147 -0.184 -0.002 -0.213 -0.159  0.092  ...   0.171   0.106  -0.062   \n",
       "\n",
       "      wb_352  wb_353  wb_354  wb_355  wb_356  wb_357  wb_358  wb_359  wb_360  \\\n",
       "5885  -0.071   0.222  -0.029   0.160   0.000  -0.119  -0.030   0.000   0.260   \n",
       "6442   0.446   0.023  -0.167   0.387   0.542   0.374   0.426   0.000  -0.292   \n",
       "4773  -0.067  -0.157  -0.029  -0.187  -0.008  -0.159  -0.147   0.000  -0.207   \n",
       "2609  -0.189   0.232  -0.028  -0.155   0.141  -0.207   0.085   0.000   0.115   \n",
       "4721   0.169  -0.007   0.166   0.027  -0.008  -0.100   0.088   0.000  -0.027   \n",
       "\n",
       "      wb_361  wb_362  wb_363  wb_364  wb_365  wb_366  wb_367  wb_368  wb_369  \\\n",
       "5885   0.357   0.216   0.253  -0.051   0.207   0.183  -0.061   0.017  -0.079   \n",
       "6442  -0.044  -0.043  -0.064   0.475   0.493   0.152  -0.048   0.387  -0.100   \n",
       "4773  -0.127  -0.134  -0.150  -0.061  -0.028  -0.155   0.399  -0.106   0.074   \n",
       "2609  -0.058   0.212   0.117  -0.167  -0.045  -0.116  -0.049   0.147  -0.082   \n",
       "4721   0.072   0.075   0.087  -0.067  -0.044  -0.101  -0.082  -0.087   0.025   \n",
       "\n",
       "      wb_370  wb_371  wb_372  wb_373  wb_374  wb_375  wb_376  wb_377  wb_378  \\\n",
       "5885   0.133   0.000   0.000  -0.009  -0.047   0.284   0.229  -0.076  -0.104   \n",
       "6442   0.277   0.000   0.000  -0.090  -0.187  -0.045   0.261  -0.131  -0.194   \n",
       "4773  -0.120   0.000   0.000  -0.014  -0.040  -0.176  -0.205  -0.076   0.270   \n",
       "2609   0.002   0.000   0.000   1.032   0.114   0.033   0.063   0.108  -0.797   \n",
       "4721   0.078   0.000   0.000   0.272   0.159   0.018  -0.031   0.162   0.068   \n",
       "\n",
       "      wb_379  wb_380  wb_381  wb_382  wb_383  wb_384  wb_385  wb_386  wb_387  \\\n",
       "5885   0.144   0.034   0.160  -0.092   0.133  -0.520  -0.606   0.618  -0.252   \n",
       "6442   0.433  -0.024  -0.081  -0.175   0.201  -0.608   0.602   0.538  -0.771   \n",
       "4773  -0.102   0.411  -0.098  -0.072  -0.163  -0.081  -0.589   0.517  -0.968   \n",
       "2609  -0.081  -0.044  -0.108   0.128  -0.201  -0.458  -0.494   1.403  -0.253   \n",
       "4721  -0.063  -0.035  -0.081   0.158  -0.025  -0.505  -0.442   0.197  -0.249   \n",
       "\n",
       "      wb_388  wb_389  wb_390  wb_391  wb_392  wb_393  wb_394  wb_395  wb_396  \\\n",
       "5885  -0.192   0.029   0.914  -0.147  -0.171  -0.272   0.229  -0.662  -0.611   \n",
       "6442  -0.211   0.719   1.018  -0.670  -0.751  -0.272   0.648  -0.112   0.631   \n",
       "4773  -0.202   0.033   0.140  -0.136  -0.774  -0.272   0.434  -0.700  -0.538   \n",
       "2609  -0.194   1.247   0.127  -0.133  -0.173  -0.272   1.458  -0.099   0.367   \n",
       "4721  -0.772   0.575   0.124  -0.561  -0.171  -0.272   0.472  -0.113   0.464   \n",
       "\n",
       "      wb_397  wb_398  wb_399  wb_400  wb_401  wb_402  wb_403  wb_404  wb_405  \\\n",
       "5885  -0.146   0.542   0.146   0.896  -0.699  -0.508  -0.140  -0.215  -0.612   \n",
       "6442  -0.824  -0.104   0.982   0.825  -0.131   0.436  -0.711  -0.820  -0.066   \n",
       "4773  -0.150   0.494   0.144  -0.658  -0.135   0.411  -0.146  -0.841  -0.607   \n",
       "2609  -0.145   0.563   0.141   0.477  -2.010  -0.346  -0.550  -0.231  -0.045   \n",
       "4721  -0.710   0.496   0.753   0.524  -0.582  -0.250  -0.632  -0.232  -0.050   \n",
       "\n",
       "      wb_406  wb_407  wb_408  wb_409  wb_410  wb_411  wb_412  wb_413  wb_414  \\\n",
       "5885  -0.609   0.509   0.230   0.747  -0.067   0.126  -0.106   0.803  -0.088   \n",
       "6442   0.613   0.199   0.459   0.789  -0.613   0.874  -0.184   0.784  -0.679   \n",
       "4773  -0.564   0.456   0.486   0.565  -0.063   0.817  -0.778  -0.549  -0.090   \n",
       "2609  -0.508  -0.259   0.115   1.544  -0.461   0.109  -0.166   0.849  -0.534   \n",
       "4721  -0.462  -0.059   0.317  -0.045  -0.567   0.117  -0.176   0.512  -0.554   \n",
       "\n",
       "      wb_415  wb_416  wb_417  wb_418  wb_419  wb_420  wb_421  wb_422  wb_423  \\\n",
       "5885   0.160   0.229   0.505  -0.088   0.260   0.025   0.224   0.170  -0.294   \n",
       "6442   0.825   1.014   0.087  -0.708   0.605   0.811   0.808   0.625  -0.294   \n",
       "4773   0.708   0.224   0.562  -0.091   0.470   0.017   0.411   0.630  -0.294   \n",
       "2609   0.165   1.762   1.105  -0.087   1.164   1.387   1.738   1.734  -0.294   \n",
       "4721   0.170   0.785   0.208  -0.663   0.385   0.018   0.219   0.432  -0.294   \n",
       "\n",
       "      wb_424  wb_425  wb_426  wb_427  wb_428  wb_429  wb_430  wb_431  wb_432  \\\n",
       "5885   0.479   0.839   0.447   0.549   0.209   0.923   0.404  -0.255   0.071   \n",
       "6442  -0.273   0.090   0.177   0.146   0.980   1.055   0.324  -0.265   0.778   \n",
       "4773   0.425   0.668   0.629   0.665   0.199   0.169   0.668  -1.002   0.625   \n",
       "2609   0.170   0.074   0.838   0.791   1.943   0.155   0.166  -0.262   1.566   \n",
       "4721   0.241   0.616   0.651   0.650   0.201   0.149   0.175  -0.782   0.100   \n",
       "\n",
       "      wb_433  wb_434  wb_435  wb_436  wb_437  wb_438  wb_439  wb_440  wb_441  \\\n",
       "5885  -0.233   0.230  -0.187  -0.257  -0.152   0.002   0.675   0.450  -0.115   \n",
       "6442  -0.797   0.506  -0.187  -0.257  -0.758  -0.587   0.173   0.237  -0.662   \n",
       "4773  -0.543   0.088  -0.187  -0.257  -0.147  -0.014   0.748   0.441  -0.116   \n",
       "2609  -0.245   1.209  -0.187  -0.257  -3.334  -0.483   1.393   0.079  -0.406   \n",
       "4721  -0.403   0.589  -0.187  -0.257  -0.772  -0.516   0.249   0.194  -0.632   \n",
       "\n",
       "      wb_442  wb_443  wb_444  wb_445  wb_446  wb_447  wb_448  \n",
       "5885  -0.344   0.901  -0.734   0.864  -0.149   0.221   0.149  \n",
       "6442  -0.437   1.024  -0.113   0.194  -0.724   0.494   0.155  \n",
       "4773  -0.539   0.720  -0.722   1.186  -0.167   0.581  -0.136  \n",
       "2609  -2.445   0.158  -0.097   0.156  -0.590   1.305  -0.028  \n",
       "4721  -0.384   0.165  -0.104   0.217  -0.642   0.485  -0.065  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f11v0</th>\n",
       "      <th>f11v1</th>\n",
       "      <th>f11v2</th>\n",
       "      <th>f11v3</th>\n",
       "      <th>f11v4</th>\n",
       "      <th>f12v0</th>\n",
       "      <th>f12v1</th>\n",
       "      <th>f12v2</th>\n",
       "      <th>f12v3</th>\n",
       "      <th>f12v4</th>\n",
       "      <th>f13v0</th>\n",
       "      <th>f13v1</th>\n",
       "      <th>f13v2</th>\n",
       "      <th>f13v3</th>\n",
       "      <th>f13v4</th>\n",
       "      <th>f14v0</th>\n",
       "      <th>f14v1</th>\n",
       "      <th>f14v2</th>\n",
       "      <th>f14v3</th>\n",
       "      <th>f14v4</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_349</th>\n",
       "      <th>wb_350</th>\n",
       "      <th>wb_351</th>\n",
       "      <th>wb_352</th>\n",
       "      <th>wb_353</th>\n",
       "      <th>wb_354</th>\n",
       "      <th>wb_355</th>\n",
       "      <th>wb_356</th>\n",
       "      <th>wb_357</th>\n",
       "      <th>wb_358</th>\n",
       "      <th>wb_359</th>\n",
       "      <th>wb_360</th>\n",
       "      <th>wb_361</th>\n",
       "      <th>wb_362</th>\n",
       "      <th>wb_363</th>\n",
       "      <th>wb_364</th>\n",
       "      <th>wb_365</th>\n",
       "      <th>wb_366</th>\n",
       "      <th>wb_367</th>\n",
       "      <th>wb_368</th>\n",
       "      <th>wb_369</th>\n",
       "      <th>wb_370</th>\n",
       "      <th>wb_371</th>\n",
       "      <th>wb_372</th>\n",
       "      <th>wb_373</th>\n",
       "      <th>wb_374</th>\n",
       "      <th>wb_375</th>\n",
       "      <th>wb_376</th>\n",
       "      <th>wb_377</th>\n",
       "      <th>wb_378</th>\n",
       "      <th>wb_379</th>\n",
       "      <th>wb_380</th>\n",
       "      <th>wb_381</th>\n",
       "      <th>wb_382</th>\n",
       "      <th>wb_383</th>\n",
       "      <th>wb_384</th>\n",
       "      <th>wb_385</th>\n",
       "      <th>wb_386</th>\n",
       "      <th>wb_387</th>\n",
       "      <th>wb_388</th>\n",
       "      <th>wb_389</th>\n",
       "      <th>wb_390</th>\n",
       "      <th>wb_391</th>\n",
       "      <th>wb_392</th>\n",
       "      <th>wb_393</th>\n",
       "      <th>wb_394</th>\n",
       "      <th>wb_395</th>\n",
       "      <th>wb_396</th>\n",
       "      <th>wb_397</th>\n",
       "      <th>wb_398</th>\n",
       "      <th>wb_399</th>\n",
       "      <th>wb_400</th>\n",
       "      <th>wb_401</th>\n",
       "      <th>wb_402</th>\n",
       "      <th>wb_403</th>\n",
       "      <th>wb_404</th>\n",
       "      <th>wb_405</th>\n",
       "      <th>wb_406</th>\n",
       "      <th>wb_407</th>\n",
       "      <th>wb_408</th>\n",
       "      <th>wb_409</th>\n",
       "      <th>wb_410</th>\n",
       "      <th>wb_411</th>\n",
       "      <th>wb_412</th>\n",
       "      <th>wb_413</th>\n",
       "      <th>wb_414</th>\n",
       "      <th>wb_415</th>\n",
       "      <th>wb_416</th>\n",
       "      <th>wb_417</th>\n",
       "      <th>wb_418</th>\n",
       "      <th>wb_419</th>\n",
       "      <th>wb_420</th>\n",
       "      <th>wb_421</th>\n",
       "      <th>wb_422</th>\n",
       "      <th>wb_423</th>\n",
       "      <th>wb_424</th>\n",
       "      <th>wb_425</th>\n",
       "      <th>wb_426</th>\n",
       "      <th>wb_427</th>\n",
       "      <th>wb_428</th>\n",
       "      <th>wb_429</th>\n",
       "      <th>wb_430</th>\n",
       "      <th>wb_431</th>\n",
       "      <th>wb_432</th>\n",
       "      <th>wb_433</th>\n",
       "      <th>wb_434</th>\n",
       "      <th>wb_435</th>\n",
       "      <th>wb_436</th>\n",
       "      <th>wb_437</th>\n",
       "      <th>wb_438</th>\n",
       "      <th>wb_439</th>\n",
       "      <th>wb_440</th>\n",
       "      <th>wb_441</th>\n",
       "      <th>wb_442</th>\n",
       "      <th>wb_443</th>\n",
       "      <th>wb_444</th>\n",
       "      <th>wb_445</th>\n",
       "      <th>wb_446</th>\n",
       "      <th>wb_447</th>\n",
       "      <th>wb_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>713.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.321</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.354</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.802</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.468</td>\n",
       "      <td>-1.256</td>\n",
       "      <td>-1.180</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.758</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>-1.138</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.644</td>\n",
       "      <td>-1.130</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>-1.167</td>\n",
       "      <td>-1.246</td>\n",
       "      <td>-0.548</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.644</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-1.330</td>\n",
       "      <td>0.581</td>\n",
       "      <td>-0.633</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.543</td>\n",
       "      <td>-1.017</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.605</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.663</td>\n",
       "      <td>-1.288</td>\n",
       "      <td>0.638</td>\n",
       "      <td>-1.098</td>\n",
       "      <td>0.626</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-1.079</td>\n",
       "      <td>-0.795</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-1.320</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.298</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-1.091</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-1.082</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-1.061</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.791</td>\n",
       "      <td>-1.118</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.894</td>\n",
       "      <td>0.598</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.842</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.574</td>\n",
       "      <td>-0.806</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>0.703</td>\n",
       "      <td>-0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>5202.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.626</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.429</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.554</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>0.451</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>0.607</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>5269.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.421</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.674</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>0.704</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.530</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.519</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.484</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.595</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>0.701</td>\n",
       "      <td>-0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9420</th>\n",
       "      <td>9420.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>0.643</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>-1.420</td>\n",
       "      <td>-1.127</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-1.692</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>-1.202</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-1.187</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.118</td>\n",
       "      <td>-1.710</td>\n",
       "      <td>-1.194</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>1.149</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-1.461</td>\n",
       "      <td>-1.166</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-1.168</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>-1.240</td>\n",
       "      <td>-0.792</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-1.614</td>\n",
       "      <td>2.306</td>\n",
       "      <td>-1.886</td>\n",
       "      <td>-1.604</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.651</td>\n",
       "      <td>-1.464</td>\n",
       "      <td>1.433</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-1.249</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.936</td>\n",
       "      <td>2.148</td>\n",
       "      <td>1.151</td>\n",
       "      <td>1.330</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.982</td>\n",
       "      <td>-1.714</td>\n",
       "      <td>1.178</td>\n",
       "      <td>-1.699</td>\n",
       "      <td>1.267</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.939</td>\n",
       "      <td>-1.482</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>2.226</td>\n",
       "      <td>-1.644</td>\n",
       "      <td>1.975</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2   f0v3   f0v4   f1v0   f1v1  f1v2  f1v3  \\\n",
       "713   713.000    42 0.367 0.000 0.000  0.000  0.000  0.000 -0.385 0.000 0.000   \n",
       "799   799.000    42 0.000 0.000 0.438  0.000  0.000 -0.416  0.000 0.000 0.000   \n",
       "5202 5202.000    42 0.000 0.000 0.000 -0.320  0.000  0.000  0.422 0.000 0.000   \n",
       "5269 5269.000    42 0.000 0.000 0.000  0.000 -0.442  0.310  0.000 0.000 0.000   \n",
       "9420 9420.000    42 0.000 0.000 0.000  0.427  0.000  0.000  0.000 0.376 0.000   \n",
       "\n",
       "      f1v4   f2v0  f2v1   f2v2  f2v3  f2v4  f3v0   f3v1   f3v2  f3v3  f3v4  \\\n",
       "713  0.000 -0.350 0.000  0.000 0.000 0.000 0.000  0.000 -0.425 0.000 0.000   \n",
       "799  0.000  0.000 0.000  0.434 0.000 0.000 0.000 -0.267  0.000 0.000 0.000   \n",
       "5202 0.000  0.000 0.000 -0.439 0.000 0.000 0.000  0.000  0.000 0.417 0.000   \n",
       "5269 0.000  0.000 0.000  0.000 0.000 0.320 0.000  0.000  0.000 0.425 0.000   \n",
       "9420 0.000  0.000 0.000 -0.398 0.000 0.000 0.000  0.323  0.000 0.000 0.000   \n",
       "\n",
       "      f4v0  f4v1   f4v2   f4v3   f4v4  f5v0  f5v1  f5v2   f5v3   f5v4  f6v0  \\\n",
       "713  0.433 0.000  0.000  0.000  0.000 0.000 0.000 0.000  0.288  0.000 0.000   \n",
       "799  0.000 0.000  0.000  0.000 -0.370 0.000 0.000 0.000  0.000 -0.222 0.000   \n",
       "5202 0.000 0.000  0.000 -0.383  0.000 0.000 0.000 0.331  0.000  0.000 0.000   \n",
       "5269 0.000 0.000  0.000  0.000  0.364 0.000 0.000 0.000  0.374  0.000 0.000   \n",
       "9420 0.000 0.000 -0.384  0.000  0.000 0.000 0.000 0.000 -0.425  0.000 0.000   \n",
       "\n",
       "      f6v1  f6v2   f6v3   f6v4  f7v0   f7v1  f7v2   f7v3   f7v4  f8v0   f8v1  \\\n",
       "713  0.000 0.000 -0.414  0.000 0.000  0.000 0.000  0.000 -0.399 0.000 -0.389   \n",
       "799  0.000 0.433  0.000  0.000 0.000 -0.427 0.000  0.000  0.000 0.000  0.150   \n",
       "5202 0.000 0.000  0.000 -0.402 0.000  0.000 0.000 -0.392  0.000 0.000  0.000   \n",
       "5269 0.285 0.000  0.000  0.000 0.000  0.000 0.000  0.422  0.000 0.000  0.000   \n",
       "9420 0.000 0.000 -0.350  0.000 0.000  0.000 0.289  0.000  0.000 0.000  0.000   \n",
       "\n",
       "      f8v2  f8v3   f8v4   f9v0  f9v1  f9v2  f9v3  f9v4  f10v0  f10v1  f10v2  \\\n",
       "713  0.000 0.000  0.000  0.000 0.000 0.000 0.443 0.000  0.000  0.000  0.000   \n",
       "799  0.000 0.000  0.000 -0.385 0.000 0.000 0.000 0.000  0.000  0.000  0.411   \n",
       "5202 0.254 0.000  0.000  0.000 0.000 0.000 0.436 0.000  0.000  0.000  0.000   \n",
       "5269 0.000 0.000 -0.326  0.000 0.000 0.000 0.432 0.000  0.000  0.000 -0.421   \n",
       "9420 0.377 0.000  0.000  0.000 0.000 0.000 0.408 0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f10v3  f10v4  f11v0  f11v1  f11v2  f11v3  f11v4  f12v0  f12v1  f12v2  \\\n",
       "713   0.000  0.426  0.000  0.000  0.000 -0.416  0.000  0.000  0.000  0.000   \n",
       "799   0.000  0.000  0.000  0.000  0.000  0.375  0.000  0.394  0.000  0.000   \n",
       "5202  0.000 -0.336 -0.382  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5269  0.000  0.000  0.000  0.437  0.000  0.000  0.000  0.000  0.360  0.000   \n",
       "9420  0.314  0.000  0.394  0.000  0.000  0.000  0.000 -0.375  0.000  0.000   \n",
       "\n",
       "      f12v3  f12v4  f13v0  f13v1  f13v2  f13v3  f13v4  f14v0  f14v1  f14v2  \\\n",
       "713   0.000 -0.266  0.000  0.000  0.000  0.000 -0.415  0.000  0.000  0.000   \n",
       "799   0.000  0.000  0.000  0.000  0.000  0.000 -0.441  0.000  0.000  0.000   \n",
       "5202  0.371  0.000  0.000  0.299  0.000  0.000  0.000  0.414  0.000  0.000   \n",
       "5269  0.000  0.000  0.406  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9420  0.000  0.000  0.000  0.000  0.000  0.391  0.000  0.000  0.000  0.414   \n",
       "\n",
       "      f14v3  f14v4     b0     b1     b2     b3     b4     b5     b6     b7  \\\n",
       "713   0.000  0.371  0.115 -0.287  0.140 -0.274 -0.111  0.315  0.003 -0.430   \n",
       "799   0.000  0.298 -0.169  0.214 -0.031  0.341  0.029  0.231  0.005  0.058   \n",
       "5202  0.000  0.000  0.426 -0.004 -0.054 -0.206 -0.096  0.145 -0.173  0.353   \n",
       "5269  0.000 -0.366  0.254  0.287  0.226 -0.339  0.392 -0.163 -0.199  0.372   \n",
       "9420  0.000  0.000 -0.063 -0.141 -0.411  0.078  0.247  0.141  0.071  0.411   \n",
       "\n",
       "         b8     b9    b10    b11    b12    b13    b14  lp0c0  lp0c1  lp1c0  \\\n",
       "713  -0.191 -0.066  0.108 -0.384 -0.198 -0.414 -0.405 -0.000 -0.188  0.010   \n",
       "799   0.102 -0.363  0.439  0.258  0.068 -0.222 -0.145  0.001 -0.102 -0.081   \n",
       "5202  0.060  0.275  0.387 -0.163 -0.016 -0.012 -0.264  0.097  0.162 -0.141   \n",
       "5269  0.262 -0.252 -0.194 -0.288 -0.057 -0.427  0.404 -0.091 -0.011  0.002   \n",
       "9420 -0.221  0.377 -0.384  0.291  0.156 -0.327  0.202 -0.245 -0.178 -0.232   \n",
       "\n",
       "      lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  ...  wb_349  wb_350  wb_351  wb_352  \\\n",
       "713  -0.204 -0.227  0.009 -0.195  0.178  ...  -0.188   0.283  -0.221  -0.116   \n",
       "799  -0.102  0.210  0.013 -0.119 -0.036  ...   0.153   0.459  -0.347  -0.076   \n",
       "5202  0.239 -0.132  0.176 -0.072  0.025  ...  -0.028  -0.056  -0.013  -0.084   \n",
       "5269  0.055  0.132  0.042  0.000  0.011  ...  -0.049   0.251  -0.084  -0.089   \n",
       "9420 -0.228 -0.128  0.177  0.027 -0.169  ...   0.088   0.257   0.003  -0.080   \n",
       "\n",
       "      wb_353  wb_354  wb_355  wb_356  wb_357  wb_358  wb_359  wb_360  wb_361  \\\n",
       "713   -0.244   0.332  -0.229   0.056  -0.172  -0.203   0.000  -0.311  -0.211   \n",
       "799   -0.405   0.458  -0.367   0.055  -0.274  -0.290   0.000  -0.440  -0.080   \n",
       "5202  -0.036  -0.027  -0.018   0.000  -0.090  -0.019   0.000  -0.051   0.025   \n",
       "5269  -0.117   0.059  -0.077  -0.005  -0.107  -0.029   0.000  -0.169  -0.058   \n",
       "9420  -0.427   0.118  -0.646  -0.005  -0.154   0.076   0.000  -0.631   0.643   \n",
       "\n",
       "      wb_362  wb_363  wb_364  wb_365  wb_366  wb_367  wb_368  wb_369  wb_370  \\\n",
       "713   -0.213  -0.217  -0.065   0.009  -0.240   0.335  -0.215   0.289  -0.202   \n",
       "799   -0.107  -0.095  -0.254  -0.050  -0.373   0.456  -0.321   0.431  -0.296   \n",
       "5202  -0.029  -0.014  -0.070  -0.051  -0.026   0.220   0.009  -0.083  -0.052   \n",
       "5269  -0.094  -0.120  -0.055  -0.026  -0.110  -0.038  -0.057  -0.058  -0.091   \n",
       "9420  -0.498  -0.467  -0.050  -0.028  -0.418   0.123   0.359   0.036  -0.607   \n",
       "\n",
       "      wb_371  wb_372  wb_373  wb_374  wb_375  wb_376  wb_377  wb_378  wb_379  \\\n",
       "713    0.000   0.000   0.360   0.321  -0.185  -0.291   0.274   0.174  -0.166   \n",
       "799    0.000   0.000   0.000   0.492  -0.321  -0.422   0.444   0.187  -0.311   \n",
       "5202   0.000   0.000  -0.034  -0.043   0.042  -0.049  -0.079   0.109   0.058   \n",
       "5269   0.000   0.000   0.377   0.315  -0.113  -0.142   0.287   0.002  -0.043   \n",
       "9420   0.000   0.000  -0.006   0.300  -0.333  -0.620   0.086   0.150   0.637   \n",
       "\n",
       "      wb_380  wb_381  wb_382  wb_383  wb_384  wb_385  wb_386  wb_387  wb_388  \\\n",
       "713    0.354  -0.121   0.262  -0.240  -0.802  -0.587   0.468  -1.256  -1.180   \n",
       "799    0.475  -0.085   0.438  -0.359  -0.801   0.550   0.672  -1.052  -1.032   \n",
       "5202   0.235   0.083  -0.080  -0.035  -0.446   0.417   0.458  -0.692  -0.670   \n",
       "5269  -0.035  -0.080   0.307  -0.122  -0.340  -0.488   0.145  -0.257  -0.411   \n",
       "9420   0.179   0.568   0.126  -0.514  -1.420  -1.127   0.769  -1.692  -1.588   \n",
       "\n",
       "      wb_389  wb_390  wb_391  wb_392  wb_393  wb_394  wb_395  wb_396  wb_397  \\\n",
       "713    0.590   0.758  -0.624  -1.138  -0.272   0.644  -1.130   0.533  -0.154   \n",
       "799    0.690   0.124  -0.841  -0.965  -0.272   0.789  -0.860  -0.666  -1.091   \n",
       "5202   0.036   0.128  -0.136  -0.591  -0.272   0.505  -0.515  -0.361  -0.148   \n",
       "5269   0.614   0.135  -0.662  -0.177  -0.272   0.421  -0.117   0.471  -0.735   \n",
       "9420  -1.202   0.131  -1.187  -0.560  -0.272   1.118  -1.710  -1.194  -0.149   \n",
       "\n",
       "      wb_398  wb_399  wb_400  wb_401  wb_402  wb_403  wb_404  wb_405  wb_406  \\\n",
       "713    0.601   0.664   0.578  -0.609  -0.240  -0.690  -1.167  -1.246  -0.548   \n",
       "799    0.473   0.146  -0.827  -0.117   0.505  -0.937  -1.082  -0.909   0.629   \n",
       "5202   0.403   0.140  -0.468  -0.538  -0.277  -0.141  -0.648  -0.463  -0.383   \n",
       "5269   0.570   0.542   0.570  -0.604   0.407  -0.674  -0.236  -0.053   0.515   \n",
       "9420   1.149   0.143  -1.461  -1.166  -0.226  -1.168  -0.456  -1.240  -0.792   \n",
       "\n",
       "      wb_407  wb_408  wb_409  wb_410  wb_411  wb_412  wb_413  wb_414  wb_415  \\\n",
       "713    0.417   0.556   0.010  -0.644   0.119  -1.330   0.581  -0.633   0.702   \n",
       "799    0.558   0.642   0.614  -0.765   0.083  -1.061  -0.432  -0.923   0.770   \n",
       "5202   0.246   0.197   0.426  -0.066   0.127  -0.626   0.378  -0.227   0.533   \n",
       "5269   0.459   0.579   0.000  -0.583   0.704  -0.179   0.530  -0.609   0.696   \n",
       "9420   1.047   0.817   0.006  -1.614   2.306  -1.886  -1.604  -0.380   0.538   \n",
       "\n",
       "      wb_416  wb_417  wb_418  wb_419  wb_420  wb_421  wb_422  wb_423  wb_424  \\\n",
       "713    0.693   0.543  -1.017   0.606   0.835   0.598   0.605  -0.294   0.356   \n",
       "799    0.211   0.590  -0.888   0.665   1.076   0.768   0.368  -0.294   0.545   \n",
       "5202   0.215   0.444  -0.091   0.004   0.025   0.429  -0.094  -0.294   0.304   \n",
       "5269   0.812   0.519  -0.688   0.540   0.020   0.417   0.514  -0.294   0.418   \n",
       "9420   0.220   0.651  -1.464   1.433   0.021   0.185  -1.249  -0.294   0.936   \n",
       "\n",
       "      wb_425  wb_426  wb_427  wb_428  wb_429  wb_430  wb_431  wb_432  wb_433  \\\n",
       "713    0.640   0.684   0.663   0.200   0.533   0.663  -1.288   0.638  -1.098   \n",
       "799    0.356   0.138   0.128   0.764   0.154   0.791  -1.118   0.536  -0.894   \n",
       "5202   0.500   0.534   0.542   0.192   0.149   0.554  -0.724   0.451  -0.236   \n",
       "5269   0.073   0.700   0.702   0.210   0.168   0.484  -0.270   0.595  -0.231   \n",
       "9420   2.148   1.151   1.330   0.212   0.157   0.982  -1.714   1.178  -1.699   \n",
       "\n",
       "      wb_434  wb_435  wb_436  wb_437  wb_438  wb_439  wb_440  wb_441  wb_442  \\\n",
       "713    0.626  -0.187  -0.257  -1.079  -0.795   0.428   0.393  -0.700  -0.719   \n",
       "799    0.598  -0.187  -0.257  -0.159  -0.842   0.718   0.574  -0.806  -0.801   \n",
       "5202   0.163  -0.187  -0.257  -0.136  -0.019   0.522   0.246  -0.118  -0.508   \n",
       "5269   0.578  -0.187  -0.257  -0.781  -0.543   0.123   0.452  -0.653  -0.103   \n",
       "9420   1.267  -0.187  -0.257  -0.153  -0.332   0.631   0.939  -1.482  -0.297   \n",
       "\n",
       "      wb_443  wb_444  wb_445  wb_446  wb_447  wb_448  \n",
       "713    0.493  -1.320   0.542  -0.865   0.712  -0.244  \n",
       "799    0.781  -0.991   0.172  -1.295   0.703  -0.314  \n",
       "5202   0.575  -0.561   0.607  -0.157   0.343  -0.032  \n",
       "5269   0.211  -0.104   0.176  -0.701   0.701  -0.159  \n",
       "9420   2.226  -1.644   1.975  -0.883   1.081  -0.133  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f11v0</th>\n",
       "      <th>f11v1</th>\n",
       "      <th>f11v2</th>\n",
       "      <th>f11v3</th>\n",
       "      <th>f11v4</th>\n",
       "      <th>f12v0</th>\n",
       "      <th>f12v1</th>\n",
       "      <th>f12v2</th>\n",
       "      <th>f12v3</th>\n",
       "      <th>f12v4</th>\n",
       "      <th>f13v0</th>\n",
       "      <th>f13v1</th>\n",
       "      <th>f13v2</th>\n",
       "      <th>f13v3</th>\n",
       "      <th>f13v4</th>\n",
       "      <th>f14v0</th>\n",
       "      <th>f14v1</th>\n",
       "      <th>f14v2</th>\n",
       "      <th>f14v3</th>\n",
       "      <th>f14v4</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_349</th>\n",
       "      <th>wb_350</th>\n",
       "      <th>wb_351</th>\n",
       "      <th>wb_352</th>\n",
       "      <th>wb_353</th>\n",
       "      <th>wb_354</th>\n",
       "      <th>wb_355</th>\n",
       "      <th>wb_356</th>\n",
       "      <th>wb_357</th>\n",
       "      <th>wb_358</th>\n",
       "      <th>wb_359</th>\n",
       "      <th>wb_360</th>\n",
       "      <th>wb_361</th>\n",
       "      <th>wb_362</th>\n",
       "      <th>wb_363</th>\n",
       "      <th>wb_364</th>\n",
       "      <th>wb_365</th>\n",
       "      <th>wb_366</th>\n",
       "      <th>wb_367</th>\n",
       "      <th>wb_368</th>\n",
       "      <th>wb_369</th>\n",
       "      <th>wb_370</th>\n",
       "      <th>wb_371</th>\n",
       "      <th>wb_372</th>\n",
       "      <th>wb_373</th>\n",
       "      <th>wb_374</th>\n",
       "      <th>wb_375</th>\n",
       "      <th>wb_376</th>\n",
       "      <th>wb_377</th>\n",
       "      <th>wb_378</th>\n",
       "      <th>wb_379</th>\n",
       "      <th>wb_380</th>\n",
       "      <th>wb_381</th>\n",
       "      <th>wb_382</th>\n",
       "      <th>wb_383</th>\n",
       "      <th>wb_384</th>\n",
       "      <th>wb_385</th>\n",
       "      <th>wb_386</th>\n",
       "      <th>wb_387</th>\n",
       "      <th>wb_388</th>\n",
       "      <th>wb_389</th>\n",
       "      <th>wb_390</th>\n",
       "      <th>wb_391</th>\n",
       "      <th>wb_392</th>\n",
       "      <th>wb_393</th>\n",
       "      <th>wb_394</th>\n",
       "      <th>wb_395</th>\n",
       "      <th>wb_396</th>\n",
       "      <th>wb_397</th>\n",
       "      <th>wb_398</th>\n",
       "      <th>wb_399</th>\n",
       "      <th>wb_400</th>\n",
       "      <th>wb_401</th>\n",
       "      <th>wb_402</th>\n",
       "      <th>wb_403</th>\n",
       "      <th>wb_404</th>\n",
       "      <th>wb_405</th>\n",
       "      <th>wb_406</th>\n",
       "      <th>wb_407</th>\n",
       "      <th>wb_408</th>\n",
       "      <th>wb_409</th>\n",
       "      <th>wb_410</th>\n",
       "      <th>wb_411</th>\n",
       "      <th>wb_412</th>\n",
       "      <th>wb_413</th>\n",
       "      <th>wb_414</th>\n",
       "      <th>wb_415</th>\n",
       "      <th>wb_416</th>\n",
       "      <th>wb_417</th>\n",
       "      <th>wb_418</th>\n",
       "      <th>wb_419</th>\n",
       "      <th>wb_420</th>\n",
       "      <th>wb_421</th>\n",
       "      <th>wb_422</th>\n",
       "      <th>wb_423</th>\n",
       "      <th>wb_424</th>\n",
       "      <th>wb_425</th>\n",
       "      <th>wb_426</th>\n",
       "      <th>wb_427</th>\n",
       "      <th>wb_428</th>\n",
       "      <th>wb_429</th>\n",
       "      <th>wb_430</th>\n",
       "      <th>wb_431</th>\n",
       "      <th>wb_432</th>\n",
       "      <th>wb_433</th>\n",
       "      <th>wb_434</th>\n",
       "      <th>wb_435</th>\n",
       "      <th>wb_436</th>\n",
       "      <th>wb_437</th>\n",
       "      <th>wb_438</th>\n",
       "      <th>wb_439</th>\n",
       "      <th>wb_440</th>\n",
       "      <th>wb_441</th>\n",
       "      <th>wb_442</th>\n",
       "      <th>wb_443</th>\n",
       "      <th>wb_444</th>\n",
       "      <th>wb_445</th>\n",
       "      <th>wb_446</th>\n",
       "      <th>wb_447</th>\n",
       "      <th>wb_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>5459.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.631</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.552</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.261</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.946</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>1.291</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.141</td>\n",
       "      <td>1.289</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.958</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>1.335</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>1.151</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.255</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.756</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>1.021</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.659</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>1.284</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.932</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>2894.000</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.501</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.604</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>1.363</td>\n",
       "      <td>1.633</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.685</td>\n",
       "      <td>1.243</td>\n",
       "      <td>1.057</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>1.176</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>1.068</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>0.596</td>\n",
       "      <td>1.556</td>\n",
       "      <td>1.001</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.136</td>\n",
       "      <td>1.687</td>\n",
       "      <td>1.652</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>1.085</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.906</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.388</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>1.178</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>2910.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.663</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.879</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.621</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.737</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>0.756</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>0.819</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>0.876</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6897</th>\n",
       "      <td>6897.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.369</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.384</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.597</td>\n",
       "      <td>-0.509</td>\n",
       "      <td>-0.617</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.430</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.389</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.574</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>0.636</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>0.617</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6843</th>\n",
       "      <td>6843.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.312</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-1.085</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.487</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.722</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.810</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.569</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.799</td>\n",
       "      <td>-0.794</td>\n",
       "      <td>0.673</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.552</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.852</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.763</td>\n",
       "      <td>-0.113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed   f0v0   f0v1  f0v2  f0v3   f0v4  f1v0  f1v1   f1v2  f1v3  \\\n",
       "5459 5459.000    42  0.000 -0.356 0.000 0.000  0.000 0.000 0.000 -0.324 0.000   \n",
       "2894 2894.000    42 -0.342  0.000 0.000 0.000  0.000 0.000 0.311  0.000 0.000   \n",
       "2910 2910.000    42  0.000  0.349 0.000 0.000  0.000 0.000 0.000  0.000 0.436   \n",
       "6897 6897.000    42  0.000  0.000 0.257 0.000  0.000 0.000 0.000  0.374 0.000   \n",
       "6843 6843.000    42  0.000  0.000 0.000 0.000 -0.419 0.000 0.000  0.000 0.000   \n",
       "\n",
       "       f1v4  f2v0   f2v1  f2v2  f2v3   f2v4  f3v0  f3v1  f3v2   f3v3   f3v4  \\\n",
       "5459  0.000 0.000  0.000 0.000 0.000 -0.432 0.000 0.000 0.000  0.000 -0.403   \n",
       "2894  0.000 0.000 -0.356 0.000 0.000  0.000 0.000 0.000 0.000  0.000  0.440   \n",
       "2910  0.000 0.000 -0.443 0.000 0.000  0.000 0.000 0.000 0.351  0.000  0.000   \n",
       "6897  0.000 0.000  0.000 0.393 0.000  0.000 0.000 0.000 0.000 -0.306  0.000   \n",
       "6843 -0.428 0.356  0.000 0.000 0.000  0.000 0.000 0.000 0.000 -0.324  0.000   \n",
       "\n",
       "       f4v0   f4v1  f4v2   f4v3  f4v4   f5v0  f5v1   f5v2   f5v3  f5v4   f6v0  \\\n",
       "5459  0.000  0.000 0.000 -0.432 0.000  0.365 0.000  0.000  0.000 0.000 -0.309   \n",
       "2894  0.444  0.000 0.000  0.000 0.000 -0.445 0.000  0.000  0.000 0.000  0.000   \n",
       "2910  0.000  0.389 0.000  0.000 0.000  0.000 0.000  0.000 -0.333 0.000  0.000   \n",
       "6897 -0.420  0.000 0.000  0.000 0.000  0.000 0.000 -0.430  0.000 0.000  0.000   \n",
       "6843  0.000 -0.435 0.000  0.000 0.000  0.000 0.000  0.000  0.416 0.000  0.000   \n",
       "\n",
       "      f6v1   f6v2   f6v3  f6v4  f7v0   f7v1  f7v2   f7v3   f7v4   f8v0  f8v1  \\\n",
       "5459 0.000  0.000  0.000 0.000 0.000  0.000 0.000 -0.368  0.000  0.000 0.000   \n",
       "2894 0.000 -0.405  0.000 0.000 0.000  0.000 0.000  0.396  0.000  0.000 0.333   \n",
       "2910 0.000  0.000 -0.409 0.000 0.000  0.000 0.000  0.000  0.444  0.000 0.000   \n",
       "6897 0.000  0.000 -0.306 0.000 0.000  0.000 0.000  0.000 -0.355 -0.355 0.000   \n",
       "6843 0.000  0.000  0.329 0.000 0.000 -0.352 0.000  0.000  0.000  0.000 0.000   \n",
       "\n",
       "       f8v2   f8v3  f8v4   f9v0  f9v1   f9v2  f9v3   f9v4  f10v0  f10v1  \\\n",
       "5459 -0.436  0.000 0.000  0.000 0.000  0.000 0.000 -0.391  0.000  0.000   \n",
       "2894  0.000  0.000 0.000  0.000 0.437  0.000 0.000  0.000  0.000  0.000   \n",
       "2910  0.000 -0.389 0.000 -0.352 0.000  0.000 0.000  0.000  0.000  0.000   \n",
       "6897  0.000  0.000 0.000  0.000 0.000 -0.334 0.000  0.000  0.000 -0.397   \n",
       "6843  0.000  0.308 0.000  0.350 0.000  0.000 0.000  0.000  0.414  0.000   \n",
       "\n",
       "      f10v2  f10v3  f10v4  f11v0  f11v1  f11v2  f11v3  f11v4  f12v0  f12v1  \\\n",
       "5459  0.000  0.000 -0.227  0.000  0.000  0.000 -0.406  0.000 -0.370  0.000   \n",
       "2894  0.438  0.000  0.000  0.000  0.000  0.376  0.000  0.000 -0.395  0.000   \n",
       "2910  0.000  0.407  0.000  0.000  0.000  0.359  0.000  0.000  0.000  0.000   \n",
       "6897  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.287  0.000  0.000   \n",
       "6843  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.386  0.000  0.000   \n",
       "\n",
       "      f12v2  f12v3  f12v4  f13v0  f13v1  f13v2  f13v3  f13v4  f14v0  f14v1  \\\n",
       "5459  0.000  0.000  0.000 -0.412  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2894  0.000  0.000  0.000  0.000  0.000  0.399  0.000  0.000  0.000  0.000   \n",
       "2910  0.000  0.000 -0.387 -0.273  0.000  0.000  0.000  0.000  0.000  0.440   \n",
       "6897 -0.407  0.000  0.000  0.275  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6843  0.443  0.000  0.000 -0.344  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f14v2  f14v3  f14v4     b0     b1     b2     b3     b4     b5     b6  \\\n",
       "5459  0.000  0.437  0.000 -0.115  0.114  0.339  0.276  0.150 -0.115  0.039   \n",
       "2894 -0.366  0.000  0.000 -0.116  0.428  0.152  0.352 -0.013  0.395 -0.374   \n",
       "2910  0.000  0.000  0.000  0.116 -0.013 -0.281  0.299  0.302 -0.200  0.008   \n",
       "6897  0.000  0.000  0.400  0.045 -0.303 -0.130  0.202  0.263  0.339  0.188   \n",
       "6843  0.000  0.000  0.437 -0.032 -0.039 -0.003 -0.022 -0.269  0.351  0.134   \n",
       "\n",
       "         b7     b8     b9    b10    b11    b12    b13    b14  lp0c0  lp0c1  \\\n",
       "5459  0.431 -0.205  0.032  0.040 -0.144 -0.368 -0.060 -0.379 -0.008 -0.102   \n",
       "2894  0.055  0.144  0.254 -0.102  0.357  0.162 -0.422 -0.079 -0.013  0.056   \n",
       "2910 -0.405  0.043 -0.377  0.373  0.251  0.239 -0.405  0.203  0.171  0.037   \n",
       "6897 -0.392 -0.148 -0.372 -0.395 -0.381  0.282 -0.146  0.218  0.086 -0.112   \n",
       "6843  0.093 -0.405 -0.246  0.348 -0.044  0.008 -0.098  0.052 -0.196 -0.146   \n",
       "\n",
       "      lp1c0  lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  ...  wb_349  wb_350  wb_351  \\\n",
       "5459 -0.055 -0.184 -0.248  0.225  0.182  0.058  ...   0.572  -0.045  -0.082   \n",
       "2894 -0.249 -0.233 -0.099 -0.136  0.188  0.180  ...   0.448  -0.270   0.074   \n",
       "2910 -0.023 -0.190  0.119  0.006 -0.123  0.199  ...  -0.042   0.051   0.095   \n",
       "6897 -0.086 -0.157 -0.139  0.227 -0.126 -0.041  ...  -0.108   0.242  -0.149   \n",
       "6843  0.051 -0.247  0.187  0.090 -0.220 -0.218  ...   0.251   0.282  -0.078   \n",
       "\n",
       "      wb_352  wb_353  wb_354  wb_355  wb_356  wb_357  wb_358  wb_359  wb_360  \\\n",
       "5459  -0.069   0.472  -0.033   0.609   0.000  -0.116  -0.286   0.000   0.566   \n",
       "2894   0.492   0.074  -0.025   0.501  -0.008   0.250   0.505   0.000  -0.375   \n",
       "2910  -0.065   0.038   0.088  -0.085  -0.014   0.022  -0.064   0.000  -0.040   \n",
       "6897  -0.073  -0.174   0.369  -0.094  -0.010  -0.101  -0.142   0.000  -0.103   \n",
       "6843  -0.066  -0.116   0.337  -0.062  -0.005  -0.012  -0.021   0.000  -0.159   \n",
       "\n",
       "      wb_361  wb_362  wb_363  wb_364  wb_365  wb_366  wb_367  wb_368  wb_369  \\\n",
       "5459   0.631  -0.111  -0.098  -0.017  -0.025   0.253  -0.043   0.258  -0.085   \n",
       "2894  -0.059   0.053  -0.094   0.626   0.604  -0.066  -0.046   0.434  -0.173   \n",
       "2910   0.155   0.010   0.077   0.259   0.230   0.049   0.139   0.138   0.137   \n",
       "6897  -0.136  -0.136  -0.143  -0.055  -0.074  -0.159   0.337  -0.126   0.267   \n",
       "6843  -0.056  -0.107  -0.090  -0.068  -0.032  -0.122   0.128  -0.042   0.312   \n",
       "\n",
       "      wb_370  wb_371  wb_372  wb_373  wb_374  wb_375  wb_376  wb_377  wb_378  \\\n",
       "5459   0.172   0.000   0.000   0.000  -0.046   0.537   0.552  -0.082  -0.314   \n",
       "2894  -0.043   0.000   0.000  -0.011  -0.293  -0.112   0.216  -0.090  -0.232   \n",
       "2910  -0.123   0.000   0.000  -0.018  -0.046   0.113  -0.038  -0.089   0.061   \n",
       "6897  -0.155   0.000   0.000   0.000   0.357  -0.139  -0.104   0.314   0.205   \n",
       "6843  -0.134   0.000   0.000   0.386  -0.028  -0.116  -0.145   0.029  -0.049   \n",
       "\n",
       "      wb_379  wb_380  wb_381  wb_382  wb_383  wb_384  wb_385  wb_386  wb_387  \\\n",
       "5459   0.608  -0.036   0.261  -0.076   0.207  -0.938   0.933   0.946  -0.256   \n",
       "2894   0.344  -0.057  -0.099  -0.255   0.252   0.297  -0.774   0.184  -0.251   \n",
       "2910   0.173   0.160   0.216  -0.077  -0.020  -0.588  -0.535   0.615  -0.963   \n",
       "6897  -0.119   0.384  -0.075   0.262  -0.166  -0.394  -0.369   0.106  -0.776   \n",
       "6843  -0.066   0.418  -0.073  -0.079  -0.124  -0.078  -0.601   0.582  -1.085   \n",
       "\n",
       "      wb_388  wb_389  wb_390  wb_391  wb_392  wb_393  wb_394  wb_395  wb_396  \\\n",
       "5459  -0.872   1.291   0.141  -0.140  -0.166  -0.272   0.176  -0.953  -0.856   \n",
       "2894  -0.218   1.363   1.633  -0.840  -0.899  -0.272   0.367  -0.402  -0.797   \n",
       "2910  -0.949   0.031   0.974  -0.670  -0.772  -0.272   0.415  -0.663  -0.506   \n",
       "6897  -0.719   0.408   0.597  -0.509  -0.617  -0.272   0.430  -0.520  -0.329   \n",
       "6843  -0.213   0.025   0.137  -0.717  -0.789  -0.272   0.487  -0.816  -0.603   \n",
       "\n",
       "      wb_397  wb_398  wb_399  wb_400  wb_401  wb_402  wb_403  wb_404  wb_405  \\\n",
       "5459  -0.146   0.413   0.141   1.289  -0.138  -0.756  -0.140  -0.228  -0.885   \n",
       "2894  -0.145   0.685   1.243   1.057  -0.803  -0.537  -0.089  -0.931  -0.801   \n",
       "2910  -0.144   0.081   0.145  -0.787  -0.623  -0.354  -0.125  -0.817  -0.601   \n",
       "6897  -0.154   0.403   0.626   0.456  -0.505  -0.206  -0.539  -0.652  -0.463   \n",
       "6843  -0.146   0.401   0.152  -0.722  -0.141   0.467  -0.136  -0.887  -0.668   \n",
       "\n",
       "      wb_406  wb_407  wb_408  wb_409  wb_410  wb_411  wb_412  wb_413  wb_414  \\\n",
       "5459  -0.891   0.737   0.272   0.958  -0.067   1.335  -0.169   1.151  -0.087   \n",
       "2894  -0.835   0.764   0.471   0.020  -0.884   1.176  -0.151   1.068  -0.899   \n",
       "2910  -0.529  -0.310   0.121   0.699   0.077   0.879  -0.808  -0.009  -0.635   \n",
       "6897  -0.370  -0.062   0.255  -0.010  -0.467   0.538  -0.679   0.440  -0.446   \n",
       "6843   0.627   0.534   0.643   0.754  -0.700   0.800  -0.858  -0.543  -0.810   \n",
       "\n",
       "      wb_415  wb_416  wb_417  wb_418  wb_419  wb_420  wb_421  wb_422  wb_423  \\\n",
       "5459   0.172   0.221   0.660  -0.087   0.879   0.025   0.211  -0.640  -0.294   \n",
       "2894   0.596   1.556   1.001  -0.095   0.778   0.018   0.813   0.918  -0.294   \n",
       "2910   0.823   0.211   0.514  -0.942   0.040   0.015   0.621  -0.001  -0.294   \n",
       "6897   0.615   0.663   0.422  -0.680   0.118   0.020   0.222   0.389  -0.294   \n",
       "6843   0.804   0.227   0.660  -0.861   0.603   0.020   0.757   0.569  -0.294   \n",
       "\n",
       "      wb_424  wb_425  wb_426  wb_427  wb_428  wb_429  wb_430  wb_431  wb_432  \\\n",
       "5459   0.649   1.255   0.153   0.144   0.334   0.168   0.756  -0.264   1.021   \n",
       "2894  -0.433   0.071   0.975   0.136   1.687   1.652   0.245  -0.263   1.085   \n",
       "2910  -0.016   0.767   0.351   0.647   1.026   0.969   0.737  -0.986   0.756   \n",
       "6897   0.053   0.533   0.591   0.586   0.364   0.630   0.574  -0.781   0.542   \n",
       "6843   0.512   0.075   0.560   0.135   0.196   0.166   0.799  -0.794   0.673   \n",
       "\n",
       "      wb_433  wb_434  wb_435  wb_436  wb_437  wb_438  wb_439  wb_440  wb_441  \\\n",
       "5459  -0.241   0.358  -0.187  -0.257  -0.159   0.001   0.975   0.659  -0.110   \n",
       "2894  -0.961   0.160  -0.187  -0.257  -0.151  -0.906   0.130   0.388  -0.113   \n",
       "2910  -0.913   0.109  -0.187  -0.257  -0.147  -0.007   0.761   0.015  -0.197   \n",
       "6897  -0.699   0.318  -0.187  -0.257  -0.159  -0.482   0.455   0.056  -0.525   \n",
       "6843  -0.867   0.208  -0.187  -0.257  -0.916   0.056   0.122   0.552  -0.266   \n",
       "\n",
       "      wb_442  wb_443  wb_444  wb_445  wb_446  wb_447  wb_448  \n",
       "5459  -0.692   1.284  -0.099   0.932  -0.157   0.195   0.259  \n",
       "2894  -0.631   1.178  -0.085   0.157  -0.846   0.520   0.174  \n",
       "2910  -0.585   0.819  -0.762   0.876  -0.156   0.269  -0.038  \n",
       "6897  -0.457   0.636  -0.651   0.617  -0.577   0.514  -0.158  \n",
       "6843  -0.190   0.852  -0.803   0.179  -0.155   0.763  -0.113  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 19s 5s/step - loss: 7.1188 - binary_accuracy_inet_decision_function_fv_metric: 0.5329 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 6.7800 - binary_accuracy_inet_decision_function_fv_metric: 0.5550 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 6.6845 - binary_accuracy_inet_decision_function_fv_metric: 0.5641 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 7.6201 - binary_accuracy_inet_decision_function_fv_metric: 0.5022 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 7.3715 - binary_accuracy_inet_decision_function_fv_metric: 0.5216 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 7.5376 - binary_accuracy_inet_decision_function_fv_metric: 0.5113 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 7.4155 - binary_accuracy_inet_decision_function_fv_metric: 0.5224 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 7.6862 - binary_accuracy_inet_decision_function_fv_metric: 0.4974 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 7.4420 - binary_accuracy_inet_decision_function_fv_metric: 0.51 - 0s 109ms/step - loss: 7.4717 - binary_accuracy_inet_decision_function_fv_metric: 0.5107 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 7.7376 - binary_accuracy_inet_decision_function_fv_metric: 0.4982 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Training Time: 0:00:26\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " history,\n",
    "\n",
    " model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=['plot_losses']\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 449)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_1056 (Dense)            (None, 1056)         475200      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation1_relu (Activation)   (None, 1056)         0           hidden1_1056[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout1_0.2 (Dropout)          (None, 1056)         0           activation1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_512 (Dense)             (None, 512)          541184      dropout1_0.2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation2_relu (Activation)   (None, 512)          0           hidden2_512[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout2_0.1 (Dropout)          (None, 512)          0           activation2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_coeff_15 (Dense)         (None, 15)           7695        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier1_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier2_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier3_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier4_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier5_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier6_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier7_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier8_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier9_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier10_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier11_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier12_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier13_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier14_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier15_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_0 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_1 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_2 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_3 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_4 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_5 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_6 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_7 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_8 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_9 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_10 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_11 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_12 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_13 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_14 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_15 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_combined (Concatenate)   (None, 122)          0           output_coeff_15[0][0]            \n",
      "                                                                 output_identifier1_var1_1[0][0]  \n",
      "                                                                 output_identifier2_var1_1[0][0]  \n",
      "                                                                 output_identifier3_var1_1[0][0]  \n",
      "                                                                 output_identifier4_var1_1[0][0]  \n",
      "                                                                 output_identifier5_var1_1[0][0]  \n",
      "                                                                 output_identifier6_var1_1[0][0]  \n",
      "                                                                 output_identifier7_var1_1[0][0]  \n",
      "                                                                 output_identifier8_var1_1[0][0]  \n",
      "                                                                 output_identifier9_var1_1[0][0]  \n",
      "                                                                 output_identifier10_var1_1[0][0] \n",
      "                                                                 output_identifier11_var1_1[0][0] \n",
      "                                                                 output_identifier12_var1_1[0][0] \n",
      "                                                                 output_identifier13_var1_1[0][0] \n",
      "                                                                 output_identifier14_var1_1[0][0] \n",
      "                                                                 output_identifier15_var1_1[0][0] \n",
      "                                                                 output_leaf_node_0[0][0]         \n",
      "                                                                 output_leaf_node_1[0][0]         \n",
      "                                                                 output_leaf_node_2[0][0]         \n",
      "                                                                 output_leaf_node_3[0][0]         \n",
      "                                                                 output_leaf_node_4[0][0]         \n",
      "                                                                 output_leaf_node_5[0][0]         \n",
      "                                                                 output_leaf_node_6[0][0]         \n",
      "                                                                 output_leaf_node_7[0][0]         \n",
      "                                                                 output_leaf_node_8[0][0]         \n",
      "                                                                 output_leaf_node_9[0][0]         \n",
      "                                                                 output_leaf_node_10[0][0]        \n",
      "                                                                 output_leaf_node_11[0][0]        \n",
      "                                                                 output_leaf_node_12[0][0]        \n",
      "                                                                 output_leaf_node_13[0][0]        \n",
      "                                                                 output_leaf_node_14[0][0]        \n",
      "                                                                 output_leaf_node_15[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,078,970\n",
      "Trainable params: 1,078,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 449)\n",
      "[-0.1228093   0.0474214  -0.3681943   0.13793102 -0.08740006  0.23613304\n",
      " -0.22431242 -0.406705   -0.17728838  0.18454176 -0.46662295  0.10797334\n",
      " -0.12901036 -0.2911343  -0.0644475   0.21177219  0.23245329  0.17899959\n",
      "  0.2106232   0.16615167  0.21709408  0.1472025   0.24135701  0.23630182\n",
      "  0.15804462  0.23138483  0.22453432  0.16631062  0.20083857  0.17693171\n",
      "  0.22346263  0.22114107  0.17947958  0.1765267   0.19939002  0.20864922\n",
      "  0.23071034  0.18586572  0.20998736  0.16478732  0.20391414  0.14763406\n",
      "  0.21947278  0.2505019   0.17847708  0.211737    0.23507808  0.16105044\n",
      "  0.14306642  0.24906799  0.17564811  0.18129735  0.16628005  0.23259696\n",
      "  0.24417754  0.24085054  0.15491506  0.285232    0.17047903  0.14852343\n",
      "  0.2189746   0.16513933  0.21549116  0.24984272  0.15055221  0.23466073\n",
      "  0.13533823  0.27692637  0.15368026  0.19939436  0.165059    0.27675685\n",
      "  0.22127213  0.13929814  0.19761391  0.24195515  0.12024033  0.17938617\n",
      "  0.22009104  0.23832725  0.16031148  0.22579822  0.2132311   0.14287311\n",
      "  0.25778615  0.25529563  0.12988195  0.15963745  0.23730008  0.21788487\n",
      "  0.5435814   0.45641857  0.60702795  0.39297202  0.5621704   0.43782955\n",
      "  0.49938256  0.50061744  0.48226482  0.51773524  0.41709366  0.58290637\n",
      "  0.3936676   0.6063324   0.5154717   0.48452833  0.44778106  0.552219\n",
      "  0.48210946  0.5178905   0.5235056   0.47649437  0.66304016  0.33695978\n",
      "  0.5294549   0.47054508  0.55411506  0.44588497  0.43596777  0.56403226\n",
      "  0.5710384   0.42896163]\n"
     ]
    }
   ],
   "source": [
    "lambda_net = np.array([lambda_net_dataset_test.network_parameters_array[0]])\n",
    "X_data = lambda_net_dataset_test.X_test_lambda_array[2]\n",
    "y_data = lambda_net_dataset_test.y_test_lambda_array[0]\n",
    "print(lambda_net.shape)\n",
    "dt_pred = model.predict(lambda_net)[0]\n",
    "print(dt_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 2,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "import queue\n",
    "\n",
    "def level_to_pre(arr,ind,new_arr):\n",
    "    if ind>=len(arr): return new_arr #nodes at ind don't exist\n",
    "    new_arr.append(arr[ind]) #append to back of the array\n",
    "    new_arr = level_to_pre(arr,ind*2+1,new_arr) #recursive call to left\n",
    "    new_arr = level_to_pre(arr,ind*2+2,new_arr) #recursive call to right\n",
    "    return new_arr\n",
    "\n",
    "def pre_to_level(arr):\n",
    "    def left_tree_size(n):\n",
    "        if n<=1: return 0\n",
    "        l = int(log2(n+1)) #l = no of completely filled levels\n",
    "        ans = 2**(l-1)\n",
    "        last_level_nodes = min(n-2**l+1,ans)\n",
    "        return ans + last_level_nodes -1       \n",
    "    \n",
    "    que = queue.Queue()\n",
    "    que.put((0,len(arr)))\n",
    "    ans = [] #this will be answer\n",
    "    while not que.empty():\n",
    "        iroot,size = que.get() #index of root and size of subtree\n",
    "        if iroot>=len(arr) or size==0: continue ##nodes at iroot don't exist\n",
    "        else : ans.append(arr[iroot]) #append to back of output array\n",
    "        sz_of_left = left_tree_size(size) \n",
    "        que.put((iroot+1,sz_of_left)) #insert left sub-tree info to que\n",
    "        que.put((iroot+1+sz_of_left,size-sz_of_left-1)) #right sub-tree info \n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 2,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "sklearn_dt = DecisionTreeClassifier(max_depth=2)\n",
    "sklearn_dt.fit(X_data, y_data)\n",
    "sklearn_dt.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 181.2, 'X[1] <= 0.768\\ngini = 0.497\\nsamples = 250\\nvalue = [115, 135]'),\n",
       " Text(83.7, 108.72, 'X[0] <= 0.914\\ngini = 0.484\\nsamples = 195\\nvalue = [80, 115]'),\n",
       " Text(41.85, 36.23999999999998, 'gini = 0.493\\nsamples = 179\\nvalue = [79, 100]'),\n",
       " Text(125.55000000000001, 36.23999999999998, 'gini = 0.117\\nsamples = 16\\nvalue = [1, 15]'),\n",
       " Text(251.10000000000002, 108.72, 'X[4] <= 0.468\\ngini = 0.463\\nsamples = 55\\nvalue = [35, 20]'),\n",
       " Text(209.25, 36.23999999999998, 'gini = 0.5\\nsamples = 26\\nvalue = [13, 13]'),\n",
       " Text(292.95, 36.23999999999998, 'gini = 0.366\\nsamples = 29\\nvalue = [22, 7]')]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(sklearn_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(p):\n",
    "    return (p)*(1 - (p)) + (1 - p)*(1 - (1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_nodes 7\n",
      "children_left [ 1  2 -1 -1  5 -1 -1]\n",
      "children_right [ 4  3 -1 -1  6 -1 -1]\n",
      "feature [ 1  0 -2 -2  4 -2 -2]\n",
      "threshold [ 0.76814133  0.91370732 -2.         -2.          0.46833673 -2.\n",
      " -2.        ]\n",
      "clf.tree_.value [[[115. 135.]]\n",
      "\n",
      " [[ 80. 115.]]\n",
      "\n",
      " [[ 79. 100.]]\n",
      "\n",
      " [[  1.  15.]]\n",
      "\n",
      " [[ 35.  20.]]\n",
      "\n",
      " [[ 13.  13.]]\n",
      "\n",
      " [[ 22.   7.]]]\n",
      "clf.tree_.impurity [0.4968     0.48389218 0.49311819 0.1171875  0.46280992 0.5\n",
      " 0.36623068]\n",
      "clf.tree_n_node_samples [250 195 179  16  55  26  29]\n",
      "clf.tree_.weighted_n_node_samples [250. 195. 179.  16.  55.  26.  29.]\n",
      "node_depth [0 1 2 2 1 2 2]\n",
      "is_leaves [False False  True  True False  True  True]\n",
      "The binary tree structure has 7 nodes and has the following tree structure:\n",
      "\n",
      "node=0 is a split node: go to node 1 if X[:, 1] <= 0.7681413292884827 else to node 4.\n",
      "\tnode=1 is a split node: go to node 2 if X[:, 0] <= 0.9137073159217834 else to node 3.\n",
      "\t\tnode=2 is a leaf node.\n",
      "\t\tnode=3 is a leaf node.\n",
      "\tnode=4 is a split node: go to node 5 if X[:, 4] <= 0.46833673119544983 else to node 6.\n",
      "\t\tnode=5 is a leaf node.\n",
      "\t\tnode=6 is a leaf node.\n"
     ]
    }
   ],
   "source": [
    "clf=sklearn_dt\n",
    "n_nodes = clf.tree_.node_count\n",
    "print('n_nodes', n_nodes)\n",
    "children_left = clf.tree_.children_left\n",
    "print('children_left', children_left)\n",
    "children_right = clf.tree_.children_right\n",
    "print('children_right', children_right)\n",
    "feature = clf.tree_.feature\n",
    "print('feature', feature)\n",
    "threshold = clf.tree_.threshold\n",
    "print('threshold', threshold)\n",
    "\n",
    "print('clf.tree_.value', clf.tree_.value)\n",
    "print('clf.tree_.impurity', clf.tree_.impurity)\n",
    "print('clf.tree_n_node_samples', clf.tree_.n_node_samples)\n",
    "print('clf.tree_.weighted_n_node_samples', clf.tree_.weighted_n_node_samples)\n",
    "\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "while len(stack) > 0:\n",
    "    # `pop` ensures each node is only visited once\n",
    "    node_id, depth = stack.pop()\n",
    "    node_depth[node_id] = depth\n",
    "\n",
    "    # If the left and right child of a node is not the same we have a split\n",
    "    # node\n",
    "    is_split_node = children_left[node_id] != children_right[node_id]\n",
    "    # If a split node, append left and right children and depth to `stack`\n",
    "    # so we can loop through them\n",
    "    if is_split_node:\n",
    "        stack.append((children_left[node_id], depth + 1))\n",
    "        stack.append((children_right[node_id], depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print('node_depth', node_depth)\n",
    "print('is_leaves', is_leaves)  \n",
    "\n",
    "print(\"The binary tree structure has {n} nodes and has \"\n",
    "      \"the following tree structure:\\n\".format(n=n_nodes))\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\"{space}node={node} is a leaf node.\".format(\n",
    "            space=node_depth[i] * \"\\t\", node=i))\n",
    "    else:\n",
    "        print(\"{space}node={node} is a split node: \"\n",
    "              \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "              \"else to node {right}.\".format(\n",
    "                  space=node_depth[i] * \"\\t\",\n",
    "                  node=i,\n",
    "                  left=children_left[i],\n",
    "                  feature=feature[i],\n",
    "                  threshold=threshold[i],\n",
    "                  right=children_right[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  3  7  8  4  9 10  2  5 11 12  6 13 14]\n",
      "[ 1  3  7 -1 -1  9 -1 -1  5 11 -1 -1 13 -1 -1]\n",
      "[ 2  4  8 -1 -1 10 -1 -1  6 12 -1 -1 14 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(children_left)\n",
    "print(children_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.         -0.1228093   0.          0.          0.        ]\n",
      " [ 0.          0.          0.0474214   0.          0.        ]\n",
      " [-0.3681943   0.          0.          0.          0.        ]\n",
      " [ 0.13793102  0.          0.          0.          0.        ]\n",
      " [ 0.         -0.08740006  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.23613304  0.        ]\n",
      " [ 0.          0.          0.          0.         -0.22431242]\n",
      " [ 0.          0.          0.          0.         -0.406705  ]\n",
      " [ 0.          0.         -0.17728838  0.          0.        ]\n",
      " [ 0.          0.          0.          0.18454176  0.        ]\n",
      " [ 0.          0.         -0.46662295  0.          0.        ]\n",
      " [ 0.          0.10797334  0.          0.          0.        ]\n",
      " [-0.12901036  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.         -0.2911343 ]\n",
      " [-0.0644475   0.          0.          0.          0.        ]], shape=(15, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "splits, leaf_classes = get_shaped_parameters_for_decision_tree(dt_pred, config)\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n",
      "31\n",
      "pre_order_from_level [ 0  1  3  7 15 16  8 17 18  4  9 19 20 10 21 22  2  5 11 23 24 12 25 26\n",
      "  6 13 27 28 14 29 30]\n",
      "leaf_indices_pre_order [ 4  5  7  8 11 12 14 15 19 20 22 23 26 27 29 30]\n",
      "pre_order_from_level [ 0  1  3  7 15 16  8 17 18  4  9 19 20 10 21 22  2  5 11 23 24 12 25 26\n",
      "  6 13 27 28 14 29 30]\n",
      "children_left (31,) [ 1  2  3  4 -1 -1  7 -1 -1 10 11 -1 -1 14 -1 -1 17 18 19 -1 -1 22 -1 -1\n",
      " 25 26 -1 -1 29 -1 -1]\n",
      "children_right (31,) [16  9  6  5 -1 -1  8 -1 -1 13 12 -1 -1 15 -1 -1 24 21 20 -1 -1 23 -1 -1\n",
      " 28 27 -1 -1 30 -1 -1]\n",
      "feature (31,) [ 0  2  0  0 -2 -2  0 -2 -2  0  3 -2 -2  0 -2 -2  1  3  1 -2 -2  1 -2 -2\n",
      "  0  0 -2 -2  1 -2 -2]\n",
      "threshold (31,) [ 0.          0.0474214   0.13793102  0.         -2.         -2.\n",
      "  0.         -2.         -2.          0.          0.18454176 -2.\n",
      " -2.          0.         -2.         -2.          0.          0.23613304\n",
      "  0.10797334 -2.         -2.          0.         -2.         -2.\n",
      "  0.          0.         -2.         -2.          0.         -2.\n",
      " -2.        ]\n",
      "node_depth [0 1 2 3 4 4 3 4 4 2 3 4 4 3 4 4 1 2 3 4 4 3 4 4 2 3 4 4 3 4 4]\n",
      "is_leaves [False False False False  True  True False  True  True False False  True\n",
      "  True False  True  True False False False  True  True False  True  True\n",
      " False False  True  True False  True  True]\n",
      "The binary tree structure has 31 nodes and has the following tree structure:\n",
      "\n",
      "node=0 is a split node: go to node 1 if X[:, 0] <= 0.0 else to node 16.\n",
      "\tnode=1 is a split node: go to node 2 if X[:, 2] <= 0.0474214032292366 else to node 9.\n",
      "\t\tnode=2 is a split node: go to node 3 if X[:, 0] <= 0.13793101906776428 else to node 6.\n",
      "\t\t\tnode=3 is a split node: go to node 4 if X[:, 0] <= 0.0 else to node 5.\n",
      "\t\t\t\tnode=4 is a leaf node.\n",
      "\t\t\t\tnode=5 is a leaf node.\n",
      "\t\t\tnode=6 is a split node: go to node 7 if X[:, 0] <= 0.0 else to node 8.\n",
      "\t\t\t\tnode=7 is a leaf node.\n",
      "\t\t\t\tnode=8 is a leaf node.\n",
      "\t\tnode=9 is a split node: go to node 10 if X[:, 0] <= 0.0 else to node 13.\n",
      "\t\t\tnode=10 is a split node: go to node 11 if X[:, 3] <= 0.1845417618751526 else to node 12.\n",
      "\t\t\t\tnode=11 is a leaf node.\n",
      "\t\t\t\tnode=12 is a leaf node.\n",
      "\t\t\tnode=13 is a split node: go to node 14 if X[:, 0] <= 0.0 else to node 15.\n",
      "\t\t\t\tnode=14 is a leaf node.\n",
      "\t\t\t\tnode=15 is a leaf node.\n",
      "\tnode=16 is a split node: go to node 17 if X[:, 1] <= 0.0 else to node 24.\n",
      "\t\tnode=17 is a split node: go to node 18 if X[:, 3] <= 0.23613303899765015 else to node 21.\n",
      "\t\t\tnode=18 is a split node: go to node 19 if X[:, 1] <= 0.10797333717346191 else to node 20.\n",
      "\t\t\t\tnode=19 is a leaf node.\n",
      "\t\t\t\tnode=20 is a leaf node.\n",
      "\t\t\tnode=21 is a split node: go to node 22 if X[:, 1] <= 0.0 else to node 23.\n",
      "\t\t\t\tnode=22 is a leaf node.\n",
      "\t\t\t\tnode=23 is a leaf node.\n",
      "\t\tnode=24 is a split node: go to node 25 if X[:, 0] <= 0.0 else to node 28.\n",
      "\t\t\tnode=25 is a split node: go to node 26 if X[:, 0] <= 0.0 else to node 27.\n",
      "\t\t\t\tnode=26 is a leaf node.\n",
      "\t\t\t\tnode=27 is a leaf node.\n",
      "\t\t\tnode=28 is a split node: go to node 29 if X[:, 1] <= 0.0 else to node 30.\n",
      "\t\t\t\tnode=29 is a leaf node.\n",
      "\t\t\t\tnode=30 is a leaf node.\n"
     ]
    }
   ],
   "source": [
    "dt_array_to_sklearn(dt_pred, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  3  7 15 16  8 17 18  4  9 19 20 10 21 22  2  5 11 23 24 12 25 26  6\n",
      " 13 27 28 14 29 30]\n",
      "[ 1  7 16 17  4 19 10 22  5 23 12 26 13 28 29]\n",
      "[ 3 15  8 18  9 20 21  2 11 24 25  6 27 14 30]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  6,  7, 10, 11, 13, 14])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pre_order_from_level>=2**max_depth-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices_list [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "pre_order_from_level [ 0  1  3  7  8  4  9 10  2  5 11 12  6 13 14]\n",
      "[ 3  4  6  7 10 11 13 14]\n",
      "left_indices_pre_order [ 1  2  3  6  9 10 13]\n",
      "right_indices_pre_order [ 4  5  7  8 11 12 14]\n",
      "order [ 0  1  2 -1 -1  3 -1 -1  4  5 -1 -1  6 -1 -1]\n",
      "children_left [ 1  2 -1 -1  5 -1 -1]\n",
      "children_right [-1  3 -1  4 -1  6 -1]\n"
     ]
    }
   ],
   "source": [
    "max_depth = 3\n",
    "indices_list = [i for i in range(2**(max_depth+1)-1)]\n",
    "print('indices_list', indices_list)\n",
    "pre_order_from_level = np.array(level_to_pre(indices_list, 0, []))\n",
    "print('pre_order_from_level', pre_order_from_level)\n",
    "leaf_indices_pre_order = np.argwhere(pre_order_from_level>=2**max_depth-1).ravel()\n",
    "print(leaf_indices_pre_order)\n",
    "left_indices_pre_order = np.argwhere(pre_order_from_level % 2 != 0).ravel()\n",
    "right_indices_pre_order = np.argwhere(pre_order_from_level % 2 == 0).ravel()[1:]\n",
    "print('left_indices_pre_order', left_indices_pre_order)\n",
    "print('right_indices_pre_order', right_indices_pre_order)\n",
    "\n",
    "counter = 0\n",
    "order = []\n",
    "children_left = []\n",
    "children_right = []\n",
    "for i in range(2**(max_depth+1)-1):\n",
    "    if i in leaf_indices_pre_order:\n",
    "        order.append(-1)\n",
    "        if i in left_indices_pre_order:\n",
    "            children_left.append(-1)\n",
    "        if i in right_indices_pre_order:\n",
    "            children_right.append(-1)        \n",
    "        continue\n",
    "    else:\n",
    "        order.append(counter)\n",
    "        if i in left_indices_pre_order:\n",
    "            children_left.append(counter)\n",
    "        if i in right_indices_pre_order:\n",
    "            children_right.append(counter)           \n",
    "        counter += 1\n",
    "order = np.array(order)\n",
    "children_left = np.array(children_left)\n",
    "children_right = np.array(children_right)\n",
    "\n",
    "print('order', order)\n",
    "print('children_left', children_left)\n",
    "print('children_right', children_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_array_to_sklearn(vanilla_dt_array, config):\n",
    "    splits, leaf_classes = get_shaped_parameters_for_decision_tree(vanilla_dt_array, config)\n",
    "    \n",
    "    internal_node_num = 2 ** config['function_family']['maximum_depth'] -1    \n",
    "    leaf_node_num = 2 ** config['function_family']['maximum_depth']    \n",
    "    n_nodes = internal_node_num + leaf_node_num\n",
    "\n",
    "    indices_list = [i for i in range(internal_node_num + leaf_node_num)]\n",
    "    pre_order_from_level = np.array(level_to_pre(indices_list, 0, []))\n",
    "\n",
    "    level_order_from_pre = np.array(pre_to_level(indices_list))\n",
    "    children_left = []\n",
    "    children_right = []\n",
    "    counter = 0\n",
    "    for i in pre_order_from_level:#pre_order_from_level:\n",
    "        left = 2*i+1 \n",
    "        right = 2*i+2 \n",
    "        try:\n",
    "            children_left.append(level_order_from_pre[left])\n",
    "        except:\n",
    "            children_left.append(-1)\n",
    "        try:\n",
    "            children_right.append(level_order_from_pre[right])\n",
    "        except:\n",
    "            children_right.append(-1)            \n",
    "        \n",
    "    children_left = np.array(children_left)\n",
    "    children_right = np.array(children_right)\n",
    "    \n",
    "    print('children_left', children_left.shape, children_left)\n",
    "    print('children_right', children_right.shape, children_right)\n",
    "    \n",
    "    indices_list = [i for i in range(internal_node_num+leaf_node_num)]\n",
    "    new_order = np.array(level_to_pre(indices_list, 0, []))\n",
    "    \n",
    "    feature = [np.argmax(split) for split in splits]\n",
    "    feature.extend([-2 for i in range(leaf_node_num)])\n",
    "    feature = np.array(feature)[new_order]\n",
    "    threshold = [np.max(split) for split in splits]\n",
    "    threshold.extend([-2 for i in range(leaf_node_num)])\n",
    "    threshold = np.array(threshold)[new_order]\n",
    "    print('feature', feature.shape, feature)\n",
    "    print('threshold', threshold.shape, threshold)\n",
    "    #input_dim = config['data']['number_of_variables']\n",
    "    #output_dim = config['data']['num_classes'] =\n",
    "\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    print('node_depth', node_depth)\n",
    "    print('is_leaves', is_leaves)\n",
    "    print(\"The binary tree structure has {n} nodes and has \"\n",
    "          \"the following tree structure:\\n\".format(n=n_nodes))\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            print(\"{space}node={node} is a leaf node.\".format(\n",
    "                space=node_depth[i] * \"\\t\", node=i))\n",
    "        else:\n",
    "            print(\"{space}node={node} is a split node: \"\n",
    "                  \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "                  \"else to node {right}.\".format(\n",
    "                      space=node_depth[i] * \"\\t\",\n",
    "                      node=i,\n",
    "                      left=children_left[i],\n",
    "                      feature=feature[i],\n",
    "                      threshold=threshold[i],\n",
    "                      right=children_right[i]))    \n",
    "\n",
    "        \n",
    "    clf=DecisionTreeClassifier(max_depth=config['function_family']['maximum_depth'])\n",
    "    clf.tree_.node_count = n_nodes\n",
    "    clf.tree_.capacity = n_nodes\n",
    "    clf.tree_.value  #shape [node_count, n_outputs, max_n_classes]; number of samples for each class\n",
    "    clf.tree_.impurity #\n",
    "    clf.tree_n_node_samples #number of samples at each node\n",
    "    clf.tree_.weighted_n_node_samples #same as tree_n_node_samples, but weighted\n",
    "    clf.tree_.children_left = children_left\n",
    "    clf.tree_.children_right = children_right\n",
    "    clf.tree_.feature = feature\n",
    "    clf.tree_.threshold = threshold\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_array_to_sklearn(vanilla_dt_array, config):\n",
    "    splits, leaf_classes = get_shaped_parameters_for_decision_tree(vanilla_dt_array, config)\n",
    "    \n",
    "    internal_node_num = 2 ** config['function_family']['maximum_depth'] -1    \n",
    "    leaf_node_num = 2 ** config['function_family']['maximum_depth']    \n",
    "    print(internal_node_num)\n",
    "    print(leaf_node_num)\n",
    "    n_nodes = internal_node_num + leaf_node_num\n",
    "    print(n_nodes)\n",
    "    indices_list = [i for i in range(n_nodes)]\n",
    "    print('indices_list', indices_list)\n",
    "    new_order = np.array(level_to_pre(indices_list, 0, []))\n",
    "    print('new_order', new_order)\n",
    "    children_left = []\n",
    "    children_right = []\n",
    "    for internal_node_num in range(1, internal_node_num+1):\n",
    "        current_depth = np.ceil(np.log2(internal_node_num+1)).astype(np.int32)\n",
    "        print('current_depth', current_depth)\n",
    "        current_depth_initial_node_id = 2 ** current_depth - 1 \n",
    "        current_node_id_in_depth = internal_node_num-current_depth_initial_node_id\n",
    "        print('current_node_id_in_depth', current_node_id_in_depth)\n",
    "        \n",
    "        subsequent_depth = current_depth+1\n",
    "        print('subsequent_depth', subsequent_depth)\n",
    "        internal_node_num_subsequent_depth = 2 ** subsequent_depth - 1 \n",
    "        print('internal_node_num_subsequent_depth', internal_node_num_subsequent_depth)\n",
    "        node_index_in_layer = internal_node_num_subsequent_depth + (current_node_id_in_depth*2)\n",
    "        \n",
    "        children_left_id = node_index_in_layer \n",
    "        children_right_id = node_index_in_layer+1 \n",
    "        \n",
    "        \n",
    "        children_left.append(children_left_id)\n",
    "        children_right.append(children_right_id)\n",
    "        \n",
    "    print(children_left)\n",
    "    print(children_right)\n",
    "    children_left.extend([-1 for i in range(leaf_node_num)])\n",
    "    children_right.extend([-1 for i in range(leaf_node_num)])\n",
    "    children_left = np.array(children_left)[new_order]\n",
    "    children_right = np.array(children_right)[new_order]\n",
    "    print('children_left', children_left)\n",
    "    print('children_right', children_right)\n",
    "    feature = [np.argmax(split) for split in splits]\n",
    "    feature.extend([-2 for i in range(leaf_node_num)])\n",
    "    feature = np.array(feature)[new_order]\n",
    "    threshold = [np.max(split) for split in splits]\n",
    "    threshold.extend([-2 for i in range(leaf_node_num)])\n",
    "    threshold = np.array(threshold)[new_order]\n",
    "    print('feature', feature)\n",
    "    print('threshold', threshold)\n",
    "    #input_dim = config['data']['number_of_variables']\n",
    "    #output_dim = config['data']['num_classes'] =\n",
    "\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    print(\"The binary tree structure has {n} nodes and has \"\n",
    "          \"the following tree structure:\\n\".format(n=n_nodes))\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            print(\"{space}node={node} is a leaf node.\".format(\n",
    "                space=node_depth[i] * \"\\t\", node=i))\n",
    "        else:\n",
    "            print(\"{space}node={node} is a split node: \"\n",
    "                  \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "                  \"else to node {right}.\".format(\n",
    "                      space=node_depth[i] * \"\\t\",\n",
    "                      node=i,\n",
    "                      left=children_left[i],\n",
    "                      feature=feature[i],\n",
    "                      threshold=threshold[i],\n",
    "                      right=children_right[i]))    \n",
    "\n",
    "    #splits = \n",
    "    #feature_indices =\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tensor in tf.split(tf.constant([[i*j for i in range(5)] for j in range(15)]), 15):\n",
    "    print(tf.squeeze(tensor, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.split(tf.squeeze(tf.constant([[i*j for i in range(5)] for j in range(15)])), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.not_equal(tf.constant([0,0,1,0]), tf.constant([0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.greater(tf.constant([0,0,1,0]), tf.constant([0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.equal(tf.constant([0,0,1,0]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**(maximum_depth-(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_depth = 4\n",
    "i=0\n",
    "split_value =True\n",
    "\n",
    "zero_identifier= tf.constant([True, False, False, False])\n",
    "split_complete= tf.constant([True, False, False, False])\n",
    "\n",
    "split_value = tf.reduce_any(tf.logical_and(zero_identifier, split_complete))\n",
    "print('split_value', split_value)\n",
    "\n",
    "split_value_filled = tf.fill([(2**(maximum_depth-(i-1)))], split_value)\n",
    "print(split_value_filled)\n",
    "split_value_neg_filled = tf.fill([(2**(maximum_depth-(i-1)))], tf.logical_not(split_value))\n",
    "print(split_value_filled)\n",
    "print(tf.keras.backend.flatten(tf.stack([split_value_filled, split_value_neg_filled])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(tf.constant([True]), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(tf.constant([1]), tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens = tf.constant([random.randint(0, 100) for i in range(function_representation_length)])\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "get_shaped_parameters_for_decision_tree(tens, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.constant([[1,2,3,4],[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.squeeze(tf.constant([[1]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=[input_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_representation_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_target_lambda_list = []\n",
    "bc_target_lambda_list = []\n",
    "\n",
    "acc_lambda_decision_list = []\n",
    "bc_lambda_decision_list = []\n",
    "\n",
    "acc_target_decision_list = []\n",
    "bc_target_decision_list = []\n",
    "\n",
    "decision_function_parameters_list = []\n",
    "decision_functio_list = []\n",
    "\n",
    "for lambda_net in tqdm(lambda_net_dataset_test.lambda_net_list):\n",
    "    \n",
    "    target_function_parameters = lambda_net.target_function_parameters\n",
    "    target_function = lambda_net.target_function\n",
    "    \n",
    "    X_test_lambda = lambda_net.X_test_lambda\n",
    "    y_test_lambda = lambda_net.y_test_lambda\n",
    "    \n",
    "    network = lambda_net.network\n",
    "    network_parameters = lambda_net.network_parameters\n",
    "    \n",
    "    if config['i_net']['convolution_layers'] != None or config['i_net']['lstm_layers'] != None or (config['i_net']['nas'] and config['nas_type']['convolution_layers'] != 'SEQUENTIAL'):\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(np.array([network_parameters]), config, subsequences=None)    \n",
    "      \n",
    "    decision_function_parameters= model.predict(np.array([network_parameters]))[0]\n",
    "    decision_function = generate_decision_tree_from_array(decision_function_parameters, config)\n",
    "    \n",
    "    decision_function_parameters_list.append(decision_function_parameters)\n",
    "    decision_functio_list.append(decision_function)\n",
    "    \n",
    "    y_test_network = network.predict(X_test_lambda)\n",
    "    y_test_decision_function = decision_function.predict_proba(X_test_lambda)\n",
    "    y_test_target_function = target_function.predict_proba(X_test_lambda)  \n",
    "    \n",
    "    acc_target_lambda = accuracy_score(np.round(y_test_target_function), np.round(y_test_network))\n",
    "    bc_target_lambda = log_loss(np.round(y_test_target_function), y_test_network, labels=[0, 1])\n",
    "    \n",
    "    acc_lambda_decision = accuracy_score(np.round(y_test_network), np.round(y_test_decision_function))\n",
    "    bc_lambda_decision = log_loss(np.round(y_test_network), y_test_decision_function, labels=[0, 1])        \n",
    "    \n",
    "    acc_target_decision = accuracy_score(np.round(y_test_target_function), np.round(y_test_decision_function))\n",
    "    bc_target_decision = log_loss(np.round(y_test_target_function), y_test_decision_function, labels=[0, 1])   \n",
    "    \n",
    "    \n",
    "    acc_target_lambda_list.append(acc_target_lambda)\n",
    "    bc_target_lambda_list.append(bc_target_lambda)\n",
    "\n",
    "    acc_lambda_decision_list.append(acc_lambda_decision)\n",
    "    bc_lambda_decision_list.append(bc_lambda_decision)\n",
    "\n",
    "    acc_target_decision_list.append(acc_target_decision)\n",
    "    bc_target_decision_list.append(bc_target_decision)\n",
    "    \n",
    "\n",
    "acc_target_lambda_array = np.array(acc_target_lambda_list)\n",
    "bc_target_lambda_array = np.array(bc_target_lambda_list)\n",
    "\n",
    "acc_lambda_decision_array = np.array(acc_lambda_decision_list)\n",
    "bc_lambda_decision_array = np.array(bc_lambda_decision_list)\n",
    "\n",
    "acc_target_decision_array = np.array(acc_target_decision_list)\n",
    "bc_target_decision_array = np.array(bc_target_decision_list)\n",
    "    \n",
    "    \n",
    "acc_target_lambda = np.mean(acc_target_lambda_array)\n",
    "bc_target_lambda = np.mean(bc_target_lambda_array[~np.isnan(bc_target_lambda_array)])\n",
    "\n",
    "acc_lambda_decision = np.mean(acc_lambda_decision_array)\n",
    "bc_lambda_decision = np.mean(bc_lambda_decision_array[~np.isnan(bc_lambda_decision_array)])\n",
    "\n",
    "acc_target_decision = np.mean(acc_target_decision_array)\n",
    "bc_target_decision = np.mean(bc_target_decision_array[~np.isnan(bc_target_decision_array)])\n",
    "\n",
    "\n",
    "print('Accuracy Target Lambda', acc_target_lambda)\n",
    "print('Binary Crossentropy Target Lambda', bc_target_lambda)\n",
    "print('Accuracy Lambda Decision', acc_lambda_decision)\n",
    "print('Binary Crossentropy Lambda Decision', bc_lambda_decision)\n",
    "print('Accuracy Target Decision', acc_target_decision)\n",
    "print('Binary Crossentropy Target Decision', bc_target_decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(network.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_weights()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_weights()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_test_network).ravel()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_test_decision_function).ravel()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lambda_decision_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO BENCHMARK RANDOM GUESS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
