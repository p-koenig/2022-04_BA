{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 4,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,                      \n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 5, \n",
    "        'num_classes': 2,\n",
    "        \n",
    "        'function_generation_type': 'random_decision_tree', # 'make_classification' 'random_decision_tree'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 1000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [64],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [1056, 512],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.2, 0.1],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.001,\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': ['binary_accuracy'],\n",
    "        \n",
    "        'epochs': 2, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 100,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 3, # 1=standard representation; 2=sparse representation, 3=vanilla_dt\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 100,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 50, #500 RECHANGE\n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        \n",
    "        'n_jobs': -3,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '0',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "from itertools import product       \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import colored\n",
    "import math\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "\n",
    "from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import random \n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/lib/cuda-10.1'\n",
    "\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = (2 ** maximum_depth - 1) * number_of_variables + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes\n",
    "config['function_family']['function_representation_length'] = ( (2 ** maximum_depth - 1) * number_of_variables + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 \n",
    "                                                              else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2\n",
    "                                                              else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes)\n",
    "\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize1000_numLNets10000_var5_class2_random_decision_tree_xMax1_xMin0_xDistuniform_depth4_beta1_decisionSpars1_fullyGrown/64_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1056-512_drop0.2-0.1e2b256_adam\n",
      "lNetSize1000_numLNets10000_var5_class2_random_decision_tree_xMax1_xMin0_xDistuniform_depth4_beta1_decisionSpars1_fullyGrown/64_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    if psutil.virtual_memory().percent > 80:\n",
    "        raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    path_X_data = directory + 'X_test_lambda.txt'\n",
    "    path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    \n",
    "    X_test_lambda = pd.read_csv(path_X_data, sep=\",\", header=None)\n",
    "    X_test_lambda = X_test_lambda.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        X_test_lambda = X_test_lambda.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    \n",
    "    y_test_lambda = pd.read_csv(path_y_data, sep=\",\", header=None)\n",
    "    y_test_lambda = y_test_lambda.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        y_test_lambda = y_test_lambda.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "        \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              X_test_lambda_row, \n",
    "                                              y_test_lambda_row, \n",
    "                                              config) for network_parameters_row, X_test_lambda_row, y_test_lambda_row in zip(network_parameters.values, X_test_lambda.values, y_test_lambda.values))          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "        lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    _ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    del parallel\n",
    "    \n",
    "    def initialize_target_function_wrapper(config, lambda_net):\n",
    "        lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    _ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    del parallel\n",
    "        \n",
    "    \n",
    "    #lambda_nets = [None] * network_parameters.shape[0]\n",
    "    #for i, (network_parameters_row, X_test_lambda_row, y_test_lambda_row) in tqdm(enumerate(zip(network_parameters.values, X_test_lambda.values, y_test_lambda.values)), total=network_parameters.values.shape[0]):        \n",
    "    #    lambda_net = LambdaNet(network_parameters_row, X_test_lambda_row, y_test_lambda_row, config)\n",
    "    #    lambda_nets[i] = lambda_net\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  91 out of 100 | elapsed:    8.8s remaining:    0.9s\n",
      "[Parallel(n_jobs=-3)]: Done 100 out of 100 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 100 out of 100 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if noise_injected_level > 0:\n",
    "    lambda_net_dataset_training = load_lambda_nets(config, no_noise=True, n_jobs=n_jobs)\n",
    "    lambda_net_dataset_evaluation = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_training, test_split=0.1)\n",
    "    _, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_evaluation, test_split=test_size)\n",
    "    \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 573)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 573)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 573)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f11v0</th>\n",
       "      <th>f11v1</th>\n",
       "      <th>f11v2</th>\n",
       "      <th>f11v3</th>\n",
       "      <th>f11v4</th>\n",
       "      <th>f12v0</th>\n",
       "      <th>f12v1</th>\n",
       "      <th>f12v2</th>\n",
       "      <th>f12v3</th>\n",
       "      <th>f12v4</th>\n",
       "      <th>f13v0</th>\n",
       "      <th>f13v1</th>\n",
       "      <th>f13v2</th>\n",
       "      <th>f13v3</th>\n",
       "      <th>f13v4</th>\n",
       "      <th>f14v0</th>\n",
       "      <th>f14v1</th>\n",
       "      <th>f14v2</th>\n",
       "      <th>f14v3</th>\n",
       "      <th>f14v4</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_349</th>\n",
       "      <th>wb_350</th>\n",
       "      <th>wb_351</th>\n",
       "      <th>wb_352</th>\n",
       "      <th>wb_353</th>\n",
       "      <th>wb_354</th>\n",
       "      <th>wb_355</th>\n",
       "      <th>wb_356</th>\n",
       "      <th>wb_357</th>\n",
       "      <th>wb_358</th>\n",
       "      <th>wb_359</th>\n",
       "      <th>wb_360</th>\n",
       "      <th>wb_361</th>\n",
       "      <th>wb_362</th>\n",
       "      <th>wb_363</th>\n",
       "      <th>wb_364</th>\n",
       "      <th>wb_365</th>\n",
       "      <th>wb_366</th>\n",
       "      <th>wb_367</th>\n",
       "      <th>wb_368</th>\n",
       "      <th>wb_369</th>\n",
       "      <th>wb_370</th>\n",
       "      <th>wb_371</th>\n",
       "      <th>wb_372</th>\n",
       "      <th>wb_373</th>\n",
       "      <th>wb_374</th>\n",
       "      <th>wb_375</th>\n",
       "      <th>wb_376</th>\n",
       "      <th>wb_377</th>\n",
       "      <th>wb_378</th>\n",
       "      <th>wb_379</th>\n",
       "      <th>wb_380</th>\n",
       "      <th>wb_381</th>\n",
       "      <th>wb_382</th>\n",
       "      <th>wb_383</th>\n",
       "      <th>wb_384</th>\n",
       "      <th>wb_385</th>\n",
       "      <th>wb_386</th>\n",
       "      <th>wb_387</th>\n",
       "      <th>wb_388</th>\n",
       "      <th>wb_389</th>\n",
       "      <th>wb_390</th>\n",
       "      <th>wb_391</th>\n",
       "      <th>wb_392</th>\n",
       "      <th>wb_393</th>\n",
       "      <th>wb_394</th>\n",
       "      <th>wb_395</th>\n",
       "      <th>wb_396</th>\n",
       "      <th>wb_397</th>\n",
       "      <th>wb_398</th>\n",
       "      <th>wb_399</th>\n",
       "      <th>wb_400</th>\n",
       "      <th>wb_401</th>\n",
       "      <th>wb_402</th>\n",
       "      <th>wb_403</th>\n",
       "      <th>wb_404</th>\n",
       "      <th>wb_405</th>\n",
       "      <th>wb_406</th>\n",
       "      <th>wb_407</th>\n",
       "      <th>wb_408</th>\n",
       "      <th>wb_409</th>\n",
       "      <th>wb_410</th>\n",
       "      <th>wb_411</th>\n",
       "      <th>wb_412</th>\n",
       "      <th>wb_413</th>\n",
       "      <th>wb_414</th>\n",
       "      <th>wb_415</th>\n",
       "      <th>wb_416</th>\n",
       "      <th>wb_417</th>\n",
       "      <th>wb_418</th>\n",
       "      <th>wb_419</th>\n",
       "      <th>wb_420</th>\n",
       "      <th>wb_421</th>\n",
       "      <th>wb_422</th>\n",
       "      <th>wb_423</th>\n",
       "      <th>wb_424</th>\n",
       "      <th>wb_425</th>\n",
       "      <th>wb_426</th>\n",
       "      <th>wb_427</th>\n",
       "      <th>wb_428</th>\n",
       "      <th>wb_429</th>\n",
       "      <th>wb_430</th>\n",
       "      <th>wb_431</th>\n",
       "      <th>wb_432</th>\n",
       "      <th>wb_433</th>\n",
       "      <th>wb_434</th>\n",
       "      <th>wb_435</th>\n",
       "      <th>wb_436</th>\n",
       "      <th>wb_437</th>\n",
       "      <th>wb_438</th>\n",
       "      <th>wb_439</th>\n",
       "      <th>wb_440</th>\n",
       "      <th>wb_441</th>\n",
       "      <th>wb_442</th>\n",
       "      <th>wb_443</th>\n",
       "      <th>wb_444</th>\n",
       "      <th>wb_445</th>\n",
       "      <th>wb_446</th>\n",
       "      <th>wb_447</th>\n",
       "      <th>wb_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9238</th>\n",
       "      <td>9238.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>0.445</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.486</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.675</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.721</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>0.760</td>\n",
       "      <td>1.015</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.820</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.731</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.614</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.761</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-0.791</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.941</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.716</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.780</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.839</td>\n",
       "      <td>1.092</td>\n",
       "      <td>1.060</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.695</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>0.796</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.746</td>\n",
       "      <td>-0.709</td>\n",
       "      <td>0.762</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.929</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8178</th>\n",
       "      <td>8178.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.288</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.522</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.923</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>0.668</td>\n",
       "      <td>-1.051</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.741</td>\n",
       "      <td>-0.764</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>0.942</td>\n",
       "      <td>-0.644</td>\n",
       "      <td>0.649</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.682</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.612</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.842</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>0.984</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>1.001</td>\n",
       "      <td>-0.819</td>\n",
       "      <td>0.795</td>\n",
       "      <td>-0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9655</th>\n",
       "      <td>9655.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>0.470</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.448</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.461</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.738</td>\n",
       "      <td>-1.059</td>\n",
       "      <td>-1.013</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.880</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.724</td>\n",
       "      <td>-1.004</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.869</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.567</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.726</td>\n",
       "      <td>-0.784</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.298</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.876</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.141</td>\n",
       "      <td>1.061</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.607</td>\n",
       "      <td>-1.087</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-1.036</td>\n",
       "      <td>0.761</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.728</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.637</td>\n",
       "      <td>-0.796</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>0.687</td>\n",
       "      <td>-0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.424</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.325</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.529</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.602</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.638</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.659</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-1.727</td>\n",
       "      <td>-1.141</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.880</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>-1.169</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-1.317</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>-1.004</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-1.238</td>\n",
       "      <td>0.749</td>\n",
       "      <td>-0.634</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.586</td>\n",
       "      <td>-1.412</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.311</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>0.946</td>\n",
       "      <td>-1.014</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825</th>\n",
       "      <td>7825.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.198</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.321</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.222</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.508</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>0.960</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>0.779</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.097</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.733</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.325</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.815</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.596</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>1.042</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>1.073</td>\n",
       "      <td>-0.732</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1   f0v2   f0v3  f0v4  f1v0   f1v1   f1v2  \\\n",
       "9238 9238.000    42 0.000 0.000  0.000  0.000 0.432 0.000  0.000  0.000   \n",
       "8178 8178.000    42 0.000 0.000  0.435  0.000 0.000 0.000  0.000  0.000   \n",
       "9655 9655.000    42 0.000 0.000  0.000  0.000 0.226 0.000  0.000  0.000   \n",
       "251   251.000    42 0.000 0.000  0.000 -0.370 0.000 0.000  0.000 -0.441   \n",
       "7825 7825.000    42 0.000 0.000 -0.418  0.000 0.000 0.000 -0.414  0.000   \n",
       "\n",
       "       f1v3  f1v4  f2v0   f2v1   f2v2  f2v3  f2v4   f3v0  f3v1   f3v2   f3v3  \\\n",
       "9238  0.000 0.294 0.000 -0.395  0.000 0.000 0.000  0.000 0.000 -0.355  0.000   \n",
       "8178 -0.320 0.000 0.430  0.000  0.000 0.000 0.000 -0.437 0.000  0.000  0.000   \n",
       "9655 -0.337 0.000 0.000  0.000 -0.425 0.000 0.000  0.000 0.000 -0.213  0.000   \n",
       "251   0.000 0.000 0.000 -0.437  0.000 0.000 0.000  0.000 0.000  0.000  0.425   \n",
       "7825  0.000 0.000 0.000  0.000  0.000 0.315 0.000  0.000 0.000  0.000 -0.295   \n",
       "\n",
       "      f3v4  f4v0  f4v1   f4v2   f4v3  f4v4   f5v0   f5v1  f5v2   f5v3  f5v4  \\\n",
       "9238 0.000 0.000 0.000  0.000  0.000 0.407  0.000 -0.318 0.000  0.000 0.000   \n",
       "8178 0.000 0.000 0.000  0.000 -0.383 0.000  0.000  0.000 0.000  0.427 0.000   \n",
       "9655 0.000 0.000 0.000 -0.417  0.000 0.000 -0.379  0.000 0.000  0.000 0.000   \n",
       "251  0.000 0.000 0.000  0.000  0.394 0.000  0.000  0.000 0.000 -0.424 0.000   \n",
       "7825 0.000 0.000 0.000  0.000 -0.442 0.000  0.434  0.000 0.000  0.000 0.000   \n",
       "\n",
       "       f6v0  f6v1   f6v2   f6v3  f6v4  f7v0  f7v1   f7v2  f7v3  f7v4   f8v0  \\\n",
       "9238  0.000 0.000 -0.253  0.000 0.000 0.000 0.000  0.000 0.000 0.420  0.000   \n",
       "8178  0.000 0.000  0.441  0.000 0.000 0.000 0.000  0.381 0.000 0.000  0.000   \n",
       "9655  0.000 0.000  0.000 -0.387 0.000 0.000 0.000  0.000 0.269 0.000  0.000   \n",
       "251   0.000 0.000  0.000 -0.392 0.000 0.000 0.392  0.000 0.000 0.000  0.000   \n",
       "7825 -0.388 0.000  0.000  0.000 0.000 0.000 0.000 -0.380 0.000 0.000 -0.390   \n",
       "\n",
       "       f8v1   f8v2  f8v3   f8v4   f9v0   f9v1  f9v2  f9v3  f9v4  f10v0  f10v1  \\\n",
       "9238 -0.296  0.000 0.000  0.000  0.000  0.000 0.443 0.000 0.000  0.000  0.000   \n",
       "8178  0.000  0.000 0.000 -0.271 -0.447  0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "9655  0.000 -0.361 0.000  0.000  0.000 -0.341 0.000 0.000 0.000  0.000  0.000   \n",
       "251   0.000 -0.396 0.000  0.000  0.000  0.000 0.319 0.000 0.000  0.000  0.000   \n",
       "7825  0.000  0.000 0.000  0.000  0.357  0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "\n",
       "      f10v2  f10v3  f10v4  f11v0  f11v1  f11v2  f11v3  f11v4  f12v0  f12v1  \\\n",
       "9238 -0.336  0.000  0.000  0.000  0.000  0.000 -0.200  0.000  0.000  0.000   \n",
       "8178  0.000 -0.382  0.000 -0.446  0.000  0.000  0.000  0.000  0.000  0.323   \n",
       "9655  0.000  0.435  0.000  0.000  0.000  0.000  0.431  0.000  0.000  0.000   \n",
       "251   0.000  0.440  0.000  0.319  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7825  0.000  0.000 -0.444  0.000  0.000 -0.202  0.000  0.000  0.000 -0.295   \n",
       "\n",
       "      f12v2  f12v3  f12v4  f13v0  f13v1  f13v2  f13v3  f13v4  f14v0  f14v1  \\\n",
       "9238  0.000  0.000  0.416  0.446  0.000  0.000  0.000  0.000  0.000  0.400   \n",
       "8178  0.000  0.000  0.000  0.000  0.261  0.000  0.000  0.000  0.000  0.000   \n",
       "9655  0.000  0.000  0.376  0.000  0.000  0.000 -0.423  0.000  0.000  0.000   \n",
       "251   0.407  0.000  0.000  0.000  0.436  0.000  0.000  0.000  0.000  0.408   \n",
       "7825  0.000  0.000  0.000  0.000  0.000 -0.372  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f14v2  f14v3  f14v4     b0     b1     b2     b3     b4     b5     b6  \\\n",
       "9238  0.000  0.000  0.000 -0.259 -0.048 -0.059 -0.287  0.164 -0.358 -0.203   \n",
       "8178  0.000  0.408  0.000 -0.118  0.194  0.111 -0.429  0.429  0.172 -0.160   \n",
       "9655 -0.429  0.000  0.000  0.397 -0.351  0.089  0.048  0.251 -0.123 -0.433   \n",
       "251   0.000  0.000  0.000  0.037 -0.176  0.187  0.325 -0.286 -0.152  0.291   \n",
       "7825  0.000  0.336  0.000  0.390  0.276  0.337 -0.441 -0.142  0.441 -0.247   \n",
       "\n",
       "         b7     b8     b9    b10    b11    b12    b13    b14  lp0c0  lp0c1  \\\n",
       "9238  0.351  0.181  0.277  0.121  0.368 -0.350 -0.323 -0.362  0.240 -0.120   \n",
       "8178 -0.185  0.295 -0.212 -0.045 -0.162  0.415 -0.131  0.206 -0.060 -0.073   \n",
       "9655  0.348  0.094 -0.193  0.308 -0.280 -0.150 -0.123 -0.196 -0.128 -0.001   \n",
       "251  -0.150 -0.067 -0.023  0.225  0.273 -0.421 -0.035  0.386 -0.170  0.221   \n",
       "7825  0.198 -0.085 -0.428  0.321 -0.338  0.371 -0.383 -0.048 -0.222 -0.208   \n",
       "\n",
       "      lp1c0  lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  ...  wb_349  wb_350  wb_351  \\\n",
       "9238  0.215  0.040  0.042 -0.091  0.219 -0.076  ...   0.537  -0.312   0.326   \n",
       "8178  0.001  0.172 -0.024 -0.092  0.220 -0.116  ...   0.066   0.231  -0.013   \n",
       "9655  0.235  0.002 -0.210  0.231 -0.164  0.008  ...   0.361   0.398  -0.077   \n",
       "251  -0.147  0.005  0.007 -0.183 -0.095  0.085  ...  -0.371   0.406  -0.056   \n",
       "7825  0.244 -0.229 -0.082  0.027 -0.096  0.224  ...   0.542  -0.159   0.375   \n",
       "\n",
       "      wb_352  wb_353  wb_354  wb_355  wb_356  wb_357  wb_358  wb_359  wb_360  \\\n",
       "9238   0.472   0.107  -0.273   0.157   0.610   0.186   0.006   0.000   0.244   \n",
       "8178   0.077  -0.072  -0.028  -0.079   0.000  -0.125   0.025   0.000  -0.118   \n",
       "9655  -0.059  -0.233   0.435  -0.239  -0.188  -0.174  -0.066   0.000  -0.324   \n",
       "251   -0.059  -0.323   0.492  -0.083  -0.008  -0.099   0.169   0.000  -0.431   \n",
       "7825   0.485   0.222  -0.027  -0.004   0.000  -0.112   0.476   0.000  -0.270   \n",
       "\n",
       "      wb_361  wb_362  wb_363  wb_364  wb_365  wb_366  wb_367  wb_368  wb_369  \\\n",
       "9238   0.497   0.431   0.438   0.550   0.529   0.259  -0.247  -0.087  -0.072   \n",
       "8178   0.043   0.007   0.002  -0.050   0.109  -0.073  -0.051   0.041   0.251   \n",
       "9655  -0.048  -0.098  -0.088  -0.213  -0.040  -0.241   0.470  -0.088   0.431   \n",
       "251   -0.391  -0.336  -0.349  -0.052  -0.033  -0.253   0.529  -0.092   0.058   \n",
       "7825   0.499   0.372   0.378  -0.016   0.532   0.172  -0.054   0.433  -0.139   \n",
       "\n",
       "      wb_370  wb_371  wb_372  wb_373  wb_374  wb_375  wb_376  wb_377  wb_378  \\\n",
       "9238   0.422   0.000   0.000  -0.005  -0.276   0.445  -0.329  -0.242  -0.283   \n",
       "8178  -0.084   0.000   0.000  -0.007  -0.046  -0.109  -0.151  -0.080   0.198   \n",
       "9655  -0.222   0.000   0.000   0.000   0.448  -0.236  -0.309   0.398  -0.108   \n",
       "251   -0.264   0.000   0.000  -0.009   0.602  -0.277  -0.354   0.009   0.318   \n",
       "7825  -0.101   0.000   0.000  -0.013  -0.259  -0.082  -0.174  -0.104  -0.105   \n",
       "\n",
       "      wb_379  wb_380  wb_381  wb_382  wb_383  wb_384  wb_385  wb_386  wb_387  \\\n",
       "9238   0.332  -0.042   0.486  -0.180   0.233  -0.675   0.827   0.721  -0.255   \n",
       "8178   0.016   0.267   0.053   0.288  -0.113  -0.069  -0.522   0.054  -0.243   \n",
       "9655  -0.070  -0.000  -0.077   0.461  -0.261  -0.741   0.625   0.738  -1.059   \n",
       "251   -0.058   0.638  -0.370   0.457  -0.247  -0.457  -0.659   0.057  -1.727   \n",
       "7825   0.471  -0.220   0.508  -0.140   0.109  -0.353  -0.542   0.069  -0.236   \n",
       "\n",
       "      wb_388  wb_389  wb_390  wb_391  wb_392  wb_393  wb_394  wb_395  wb_396  \\\n",
       "9238  -0.840   0.760   1.015  -0.128  -0.178  -0.272   0.820  -0.102   0.731   \n",
       "8178  -0.214   0.155   0.923  -0.711  -0.779  -0.272   0.183  -0.628   0.668   \n",
       "9655  -1.013   0.756   0.129  -0.866  -0.673  -0.272   0.880  -0.123   0.724   \n",
       "251   -1.141   0.034   0.134  -0.880  -0.623  -0.272   0.191  -0.846  -0.552   \n",
       "7825  -0.213   0.033   0.978  -0.649  -0.753  -0.272   0.199  -0.658  -0.469   \n",
       "\n",
       "      wb_397  wb_398  wb_399  wb_400  wb_401  wb_402  wb_403  wb_404  wb_405  \\\n",
       "9238  -0.154   0.614   1.016   0.761  -0.724  -0.484  -0.791  -0.234  -0.053   \n",
       "8178  -1.051   0.663   0.968   0.741  -0.764  -0.420  -0.845  -0.874  -0.667   \n",
       "9655  -1.004   0.543   0.150  -0.869  -0.137   0.567  -0.895  -0.255  -0.045   \n",
       "251   -1.169   0.652   0.148  -1.317  -0.770  -0.294  -0.835  -1.004  -0.740   \n",
       "7825  -0.141   0.174   0.987   0.834  -0.656  -0.325  -0.654  -0.816  -0.604   \n",
       "\n",
       "      wb_406  wb_407  wb_408  wb_409  wb_410  wb_411  wb_412  wb_413  wb_414  \\\n",
       "9238  -0.630  -0.489   0.072   0.941  -0.737   0.117  -0.173   0.716  -0.787   \n",
       "8178  -0.571   0.560   0.585   0.009  -0.730   0.942  -0.644   0.649  -0.749   \n",
       "9655   0.678   0.610   0.708   0.726  -0.784   0.109  -0.237  -0.631  -0.854   \n",
       "251   -0.636   0.264   0.356   0.000  -0.665   0.122  -1.238   0.749  -0.634   \n",
       "7825  -0.543  -0.271   0.162   0.003  -0.578   0.960  -0.846   0.779  -0.565   \n",
       "\n",
       "      wb_415  wb_416  wb_417  wb_418  wb_419  wb_420  wb_421  wb_422  wb_423  \\\n",
       "9238   0.717   0.995   0.037  -0.780   0.154   0.901   0.467   0.127  -0.294   \n",
       "8178   0.820   0.999   0.682  -0.092   0.611   0.025   0.213   0.612  -0.294   \n",
       "9655   0.163   0.256   0.298  -0.816   0.724   0.949   0.876  -0.016  -0.294   \n",
       "251    0.245   0.226   0.586  -1.412   0.038   0.020   0.229  -0.570  -0.294   \n",
       "7825   0.910   1.097   0.431  -0.088   0.070   0.025   0.222   0.733  -0.294   \n",
       "\n",
       "      wb_424  wb_425  wb_426  wb_427  wb_428  wb_429  wb_430  wb_431  wb_432  \\\n",
       "9238   0.077   0.916   0.846   0.839   1.092   1.060   0.367  -0.961   0.098   \n",
       "8178   0.075   0.804   0.784   0.814   0.210   1.037   0.842  -0.255   0.699   \n",
       "9655   0.611   0.079   0.152   0.141   1.061   0.160   0.607  -1.087   0.104   \n",
       "251    0.397   0.896   0.833   0.860   0.212   0.166   0.571  -1.387   0.089   \n",
       "7825  -0.221   0.921   0.840   0.864   0.325   1.033   0.496  -0.256   0.815   \n",
       "\n",
       "      wb_433  wb_434  wb_435  wb_436  wb_437  wb_438  wb_439  wb_440  wb_441  \\\n",
       "9238  -0.244   0.695  -0.187  -0.257  -0.155  -0.672   0.796  -0.279  -0.746   \n",
       "8178  -0.887   0.223  -0.187  -0.257  -0.153   0.014   0.127   0.300  -0.110   \n",
       "9655  -1.036   0.761  -0.187  -0.257  -0.159  -0.728   0.820   0.637  -0.796   \n",
       "251   -0.407   0.483  -0.187  -0.257  -0.151  -0.853   0.510   0.311  -0.047   \n",
       "7825  -0.831   0.101  -0.187  -0.257  -0.149  -0.596   0.132  -0.136  -0.059   \n",
       "\n",
       "      wb_442  wb_443  wb_444  wb_445  wb_446  wb_447  wb_448  \n",
       "9238  -0.709   0.762  -0.098   0.929  -0.756   0.323   0.233  \n",
       "8178  -0.687   0.984  -0.773   1.001  -0.819   0.795  -0.154  \n",
       "9655  -0.107   0.158  -0.302   0.170  -0.999   0.687  -0.234  \n",
       "251   -0.478   0.168  -1.033   0.946  -1.014   0.536  -0.227  \n",
       "7825  -0.561   1.042  -0.856   1.073  -0.732   0.398   0.053  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f11v0</th>\n",
       "      <th>f11v1</th>\n",
       "      <th>f11v2</th>\n",
       "      <th>f11v3</th>\n",
       "      <th>f11v4</th>\n",
       "      <th>f12v0</th>\n",
       "      <th>f12v1</th>\n",
       "      <th>f12v2</th>\n",
       "      <th>f12v3</th>\n",
       "      <th>f12v4</th>\n",
       "      <th>f13v0</th>\n",
       "      <th>f13v1</th>\n",
       "      <th>f13v2</th>\n",
       "      <th>f13v3</th>\n",
       "      <th>f13v4</th>\n",
       "      <th>f14v0</th>\n",
       "      <th>f14v1</th>\n",
       "      <th>f14v2</th>\n",
       "      <th>f14v3</th>\n",
       "      <th>f14v4</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_349</th>\n",
       "      <th>wb_350</th>\n",
       "      <th>wb_351</th>\n",
       "      <th>wb_352</th>\n",
       "      <th>wb_353</th>\n",
       "      <th>wb_354</th>\n",
       "      <th>wb_355</th>\n",
       "      <th>wb_356</th>\n",
       "      <th>wb_357</th>\n",
       "      <th>wb_358</th>\n",
       "      <th>wb_359</th>\n",
       "      <th>wb_360</th>\n",
       "      <th>wb_361</th>\n",
       "      <th>wb_362</th>\n",
       "      <th>wb_363</th>\n",
       "      <th>wb_364</th>\n",
       "      <th>wb_365</th>\n",
       "      <th>wb_366</th>\n",
       "      <th>wb_367</th>\n",
       "      <th>wb_368</th>\n",
       "      <th>wb_369</th>\n",
       "      <th>wb_370</th>\n",
       "      <th>wb_371</th>\n",
       "      <th>wb_372</th>\n",
       "      <th>wb_373</th>\n",
       "      <th>wb_374</th>\n",
       "      <th>wb_375</th>\n",
       "      <th>wb_376</th>\n",
       "      <th>wb_377</th>\n",
       "      <th>wb_378</th>\n",
       "      <th>wb_379</th>\n",
       "      <th>wb_380</th>\n",
       "      <th>wb_381</th>\n",
       "      <th>wb_382</th>\n",
       "      <th>wb_383</th>\n",
       "      <th>wb_384</th>\n",
       "      <th>wb_385</th>\n",
       "      <th>wb_386</th>\n",
       "      <th>wb_387</th>\n",
       "      <th>wb_388</th>\n",
       "      <th>wb_389</th>\n",
       "      <th>wb_390</th>\n",
       "      <th>wb_391</th>\n",
       "      <th>wb_392</th>\n",
       "      <th>wb_393</th>\n",
       "      <th>wb_394</th>\n",
       "      <th>wb_395</th>\n",
       "      <th>wb_396</th>\n",
       "      <th>wb_397</th>\n",
       "      <th>wb_398</th>\n",
       "      <th>wb_399</th>\n",
       "      <th>wb_400</th>\n",
       "      <th>wb_401</th>\n",
       "      <th>wb_402</th>\n",
       "      <th>wb_403</th>\n",
       "      <th>wb_404</th>\n",
       "      <th>wb_405</th>\n",
       "      <th>wb_406</th>\n",
       "      <th>wb_407</th>\n",
       "      <th>wb_408</th>\n",
       "      <th>wb_409</th>\n",
       "      <th>wb_410</th>\n",
       "      <th>wb_411</th>\n",
       "      <th>wb_412</th>\n",
       "      <th>wb_413</th>\n",
       "      <th>wb_414</th>\n",
       "      <th>wb_415</th>\n",
       "      <th>wb_416</th>\n",
       "      <th>wb_417</th>\n",
       "      <th>wb_418</th>\n",
       "      <th>wb_419</th>\n",
       "      <th>wb_420</th>\n",
       "      <th>wb_421</th>\n",
       "      <th>wb_422</th>\n",
       "      <th>wb_423</th>\n",
       "      <th>wb_424</th>\n",
       "      <th>wb_425</th>\n",
       "      <th>wb_426</th>\n",
       "      <th>wb_427</th>\n",
       "      <th>wb_428</th>\n",
       "      <th>wb_429</th>\n",
       "      <th>wb_430</th>\n",
       "      <th>wb_431</th>\n",
       "      <th>wb_432</th>\n",
       "      <th>wb_433</th>\n",
       "      <th>wb_434</th>\n",
       "      <th>wb_435</th>\n",
       "      <th>wb_436</th>\n",
       "      <th>wb_437</th>\n",
       "      <th>wb_438</th>\n",
       "      <th>wb_439</th>\n",
       "      <th>wb_440</th>\n",
       "      <th>wb_441</th>\n",
       "      <th>wb_442</th>\n",
       "      <th>wb_443</th>\n",
       "      <th>wb_444</th>\n",
       "      <th>wb_445</th>\n",
       "      <th>wb_446</th>\n",
       "      <th>wb_447</th>\n",
       "      <th>wb_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1513.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.301</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.284</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.264</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.547</td>\n",
       "      <td>0.360</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.479</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>3006.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.423</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>-0.580</td>\n",
       "      <td>0.602</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.768</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.587</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.659</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.882</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>-0.541</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.581</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.485</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.563</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.669</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.399</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>0.388</td>\n",
       "      <td>-0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.627</td>\n",
       "      <td>0.653</td>\n",
       "      <td>-1.010</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.627</td>\n",
       "      <td>-0.674</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-1.024</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>-0.644</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.802</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.684</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.886</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.805</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.241</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.524</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>0.894</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>1188.000</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>0.523</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.731</td>\n",
       "      <td>0.623</td>\n",
       "      <td>2.065</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.672</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-1.114</td>\n",
       "      <td>0.674</td>\n",
       "      <td>2.406</td>\n",
       "      <td>1.160</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>-0.755</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.358</td>\n",
       "      <td>1.769</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>2.101</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>1.104</td>\n",
       "      <td>-0.752</td>\n",
       "      <td>2.030</td>\n",
       "      <td>1.964</td>\n",
       "      <td>0.526</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>0.913</td>\n",
       "      <td>1.646</td>\n",
       "      <td>1.986</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.722</td>\n",
       "      <td>2.118</td>\n",
       "      <td>2.089</td>\n",
       "      <td>1.667</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>1.792</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>1.066</td>\n",
       "      <td>0.466</td>\n",
       "      <td>-0.793</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>2.070</td>\n",
       "      <td>-0.721</td>\n",
       "      <td>1.270</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>6231.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>0.279</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>-0.702</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.713</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.622</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.502</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.508</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.547</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.768</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-0.563</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-0.077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed   f0v0   f0v1  f0v2  f0v3  f0v4  f1v0  f1v1   f1v2   f1v3  \\\n",
       "1513 1513.000    42  0.000  0.000 0.000 0.000 0.410 0.405 0.000  0.000  0.000   \n",
       "3006 3006.000    42  0.000 -0.405 0.000 0.000 0.000 0.000 0.000  0.000 -0.367   \n",
       "107   107.000    42  0.000  0.401 0.000 0.000 0.000 0.346 0.000  0.000  0.000   \n",
       "1188 1188.000    42 -0.408  0.000 0.000 0.000 0.000 0.443 0.000  0.000  0.000   \n",
       "6231 6231.000    42  0.273  0.000 0.000 0.000 0.000 0.000 0.000 -0.396  0.000   \n",
       "\n",
       "      f1v4   f2v0  f2v1   f2v2  f2v3  f2v4  f3v0   f3v1  f3v2  f3v3  f3v4  \\\n",
       "1513 0.000 -0.437 0.000  0.000 0.000 0.000 0.000  0.428 0.000 0.000 0.000   \n",
       "3006 0.000  0.000 0.000  0.000 0.000 0.204 0.000 -0.315 0.000 0.000 0.000   \n",
       "107  0.000  0.000 0.000 -0.383 0.000 0.000 0.000  0.000 0.000 0.433 0.000   \n",
       "1188 0.000  0.411 0.000  0.000 0.000 0.000 0.000  0.000 0.366 0.000 0.000   \n",
       "6231 0.000  0.000 0.000  0.387 0.000 0.000 0.000  0.000 0.376 0.000 0.000   \n",
       "\n",
       "      f4v0   f4v1  f4v2   f4v3  f4v4   f5v0  f5v1   f5v2  f5v3  f5v4  f6v0  \\\n",
       "1513 0.000  0.000 0.000 -0.359 0.000  0.000 0.000 -0.331 0.000 0.000 0.000   \n",
       "3006 0.000 -0.402 0.000  0.000 0.000  0.000 0.000  0.398 0.000 0.000 0.000   \n",
       "107  0.000  0.000 0.000  0.271 0.000 -0.440 0.000  0.000 0.000 0.000 0.000   \n",
       "1188 0.000  0.396 0.000  0.000 0.000  0.424 0.000  0.000 0.000 0.000 0.237   \n",
       "6231 0.000  0.000 0.000  0.000 0.406  0.000 0.000  0.333 0.000 0.000 0.000   \n",
       "\n",
       "      f6v1   f6v2   f6v3  f6v4   f7v0  f7v1   f7v2   f7v3  f7v4  f8v0   f8v1  \\\n",
       "1513 0.000  0.000  0.000 0.301 -0.390 0.000  0.000  0.000 0.000 0.000 -0.385   \n",
       "3006 0.000  0.000 -0.441 0.000  0.000 0.000 -0.335  0.000 0.000 0.397  0.000   \n",
       "107  0.343  0.000  0.000 0.000  0.000 0.000  0.000 -0.427 0.000 0.000  0.000   \n",
       "1188 0.000  0.000  0.000 0.000  0.000 0.000  0.350  0.000 0.000 0.340  0.000   \n",
       "6231 0.000 -0.309  0.000 0.000  0.000 0.000  0.000  0.389 0.000 0.000  0.000   \n",
       "\n",
       "       f8v2  f8v3   f8v4  f9v0   f9v1  f9v2   f9v3  f9v4  f10v0  f10v1  f10v2  \\\n",
       "1513  0.000 0.000  0.000 0.000 -0.382 0.000  0.000 0.000  0.000  0.000  0.391   \n",
       "3006  0.000 0.000  0.000 0.000  0.000 0.000  0.000 0.379  0.000  0.362  0.000   \n",
       "107   0.000 0.000 -0.439 0.000  0.000 0.000  0.000 0.349  0.000 -0.398  0.000   \n",
       "1188  0.000 0.000  0.000 0.000  0.000 0.000 -0.296 0.000 -0.444  0.000  0.000   \n",
       "6231 -0.357 0.000  0.000 0.000  0.437 0.000  0.000 0.000  0.000 -0.439  0.000   \n",
       "\n",
       "      f10v3  f10v4  f11v0  f11v1  f11v2  f11v3  f11v4  f12v0  f12v1  f12v2  \\\n",
       "1513  0.000  0.000  0.000 -0.369  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3006  0.000  0.000  0.000  0.000  0.386  0.000  0.000  0.361  0.000  0.000   \n",
       "107   0.000  0.000  0.441  0.000  0.000  0.000  0.000  0.000  0.396  0.000   \n",
       "1188  0.000  0.000  0.000 -0.377  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6231  0.000  0.000  0.000  0.000  0.000 -0.390  0.000  0.265  0.000  0.000   \n",
       "\n",
       "      f12v3  f12v4  f13v0  f13v1  f13v2  f13v3  f13v4  f14v0  f14v1  f14v2  \\\n",
       "1513  0.000 -0.347  0.000  0.000  0.000 -0.430  0.000  0.000  0.000  0.000   \n",
       "3006  0.000  0.000  0.000  0.000  0.000 -0.372  0.000  0.000  0.000  0.000   \n",
       "107   0.000  0.000  0.000 -0.365  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1188  0.000 -0.340  0.000  0.000  0.365  0.000  0.000  0.000  0.000  0.000   \n",
       "6231  0.000  0.000  0.000  0.000 -0.398  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f14v3  f14v4     b0     b1     b2     b3     b4     b5     b6     b7  \\\n",
       "1513  0.433  0.000  0.074  0.075  0.231 -0.216 -0.089 -0.131  0.295  0.095   \n",
       "3006  0.000  0.402  0.210  0.057  0.377 -0.358 -0.342 -0.153  0.241 -0.015   \n",
       "107  -0.441  0.000 -0.278  0.254  0.352 -0.326 -0.309  0.149  0.427  0.348   \n",
       "1188 -0.409  0.000  0.060 -0.068  0.120 -0.032  0.107 -0.279 -0.409 -0.364   \n",
       "6231  0.000  0.443 -0.369  0.366 -0.436  0.105  0.114  0.043 -0.120  0.172   \n",
       "\n",
       "         b8     b9    b10    b11    b12    b13    b14  lp0c0  lp0c1  lp1c0  \\\n",
       "1513  0.134  0.015  0.162  0.098 -0.351  0.112  0.048  0.149 -0.139  0.148   \n",
       "3006  0.084  0.168 -0.382  0.054 -0.335 -0.328  0.347 -0.141 -0.105  0.103   \n",
       "107   0.432 -0.277 -0.103  0.150  0.348  0.102  0.232  0.092 -0.022  0.082   \n",
       "1188 -0.177 -0.336  0.008 -0.299 -0.145 -0.008 -0.102 -0.065 -0.061  0.139   \n",
       "6231 -0.419  0.279 -0.200 -0.317 -0.180  0.316 -0.147  0.053  0.153 -0.197   \n",
       "\n",
       "      lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  ...  wb_349  wb_350  wb_351  wb_352  \\\n",
       "1513  0.157 -0.069  0.113 -0.170  0.145  ...   0.185  -0.020   0.119   0.161   \n",
       "3006  0.112  0.068 -0.209 -0.090 -0.240  ...  -0.047   0.375  -0.072  -0.062   \n",
       "107   0.215  0.181  0.195  0.166 -0.083  ...   0.040   0.158  -0.068  -0.062   \n",
       "1188 -0.117  0.055  0.092  0.070 -0.230  ...   0.211   0.083  -0.441  -0.405   \n",
       "6231  0.247 -0.034 -0.031 -0.071 -0.010  ...   0.176   0.102  -0.028   0.182   \n",
       "\n",
       "      wb_353  wb_354  wb_355  wb_356  wb_357  wb_358  wb_359  wb_360  wb_361  \\\n",
       "1513   0.097   0.032   0.092   0.240   0.131   0.057   0.000   0.094   0.146   \n",
       "3006  -0.218  -0.020  -0.198  -0.008  -0.127  -0.074   0.000  -0.275  -0.053   \n",
       "107   -0.066   0.271  -0.083   0.181  -0.101  -0.066   0.000  -0.054   0.032   \n",
       "1188   0.133   0.084   0.231   0.127  -0.460  -0.046   0.000   0.004  -0.116   \n",
       "6231  -0.104   0.159  -0.180   0.210  -0.004  -0.064   0.000  -0.114   0.108   \n",
       "\n",
       "      wb_362  wb_363  wb_364  wb_365  wb_366  wb_367  wb_368  wb_369  wb_370  \\\n",
       "1513   0.127   0.130   0.198   0.186   0.104   0.069   0.099   0.051   0.112   \n",
       "3006  -0.075  -0.145  -0.063  -0.046  -0.199   0.358  -0.086  -0.085  -0.189   \n",
       "107   -0.004   0.061   0.151  -0.040  -0.051   0.289  -0.074  -0.081  -0.013   \n",
       "1188  -0.127  -0.124  -0.419  -0.414  -0.403   0.143  -0.441  -0.089   0.071   \n",
       "6231   0.026   0.077   0.202   0.173  -0.099   0.177  -0.084  -0.091   0.067   \n",
       "\n",
       "      wb_371  wb_372  wb_373  wb_374  wb_375  wb_376  wb_377  wb_378  wb_379  \\\n",
       "1513   0.000   0.000   0.000  -0.004   0.130   0.086   0.030  -0.046   0.130   \n",
       "3006   0.000   0.000   0.000   0.399  -0.178  -0.268   0.388   0.181  -0.066   \n",
       "107    0.000   0.000  -0.011   0.246   0.037  -0.070   0.217   0.131  -0.063   \n",
       "1188   0.000   0.000   0.000   0.125  -0.324   0.004   0.018   0.072  -0.428   \n",
       "6231   0.000   0.000  -0.019   0.148   0.076  -0.142   0.148   0.083  -0.060   \n",
       "\n",
       "      wb_380  wb_381  wb_382  wb_383  wb_384  wb_385  wb_386  wb_387  wb_388  \\\n",
       "1513  -0.042   0.161   0.053   0.093  -0.327   0.224   0.284  -0.525  -0.513   \n",
       "3006   0.423  -0.083  -0.020  -0.181  -0.546  -0.580   0.602  -0.890  -0.847   \n",
       "107    0.342   0.109   0.206  -0.077  -0.538  -0.627   0.653  -1.010  -0.916   \n",
       "1188  -0.077  -0.296   0.141   0.068  -0.591  -0.635   0.523  -0.254  -0.731   \n",
       "6231  -0.037   0.167   0.144  -0.133  -0.471  -0.399   0.483  -0.740  -0.702   \n",
       "\n",
       "      wb_389  wb_390  wb_391  wb_392  wb_393  wb_394  wb_395  wb_396  wb_397  \\\n",
       "1513   0.309   0.442  -0.338  -0.400  -0.272   0.427  -0.375  -0.224  -0.148   \n",
       "3006   0.033   0.121  -0.139  -0.768  -0.272   0.587  -0.688  -0.483  -0.154   \n",
       "107    0.133   0.127  -0.117  -0.942  -0.272   0.627  -0.674  -0.486  -1.024   \n",
       "1188   0.623   2.065  -0.225  -0.175  -0.272   1.672  -0.653  -0.682  -1.114   \n",
       "6231   0.513   0.713  -0.097  -0.166  -0.272   0.622  -0.243   0.289  -0.657   \n",
       "\n",
       "      wb_398  wb_399  wb_400  wb_401  wb_402  wb_403  wb_404  wb_405  wb_406  \\\n",
       "1513   0.252   0.487   0.306  -0.404  -0.144  -0.395  -0.485  -0.294  -0.227   \n",
       "3006   0.496   0.144  -0.659  -0.714  -0.295  -0.130  -0.882  -0.603  -0.541   \n",
       "107    0.428   0.143  -0.830  -0.644  -0.270  -0.802  -0.790  -0.589  -0.559   \n",
       "1188   0.674   2.406   1.160  -0.657  -0.362  -0.755  -0.231  -0.544  -0.653   \n",
       "6231   0.391   0.743   0.502  -0.560  -0.257  -0.578  -0.223  -0.047  -0.409   \n",
       "\n",
       "      wb_407  wb_408  wb_409  wb_410  wb_411  wb_412  wb_413  wb_414  wb_415  \\\n",
       "1513   0.029   0.214   0.264  -0.301   0.455  -0.436   0.286  -0.332   0.410   \n",
       "3006   0.370   0.321   0.581  -0.063   0.128  -0.818  -0.011  -0.587   0.165   \n",
       "107   -0.267   0.186   0.684  -0.673   0.117  -0.886  -0.446  -0.582   0.169   \n",
       "1188   0.654   0.358   1.769  -0.972   2.101  -0.150   1.104  -0.752   2.030   \n",
       "6231  -0.248   0.175   0.397  -0.505   0.101  -0.162   0.508  -0.508   0.194   \n",
       "\n",
       "      wb_416  wb_417  wb_418  wb_419  wb_420  wb_421  wb_422  wb_423  wb_424  \\\n",
       "1513   0.521   0.266  -0.361   0.146   0.335   0.463   0.211  -0.294   0.082   \n",
       "3006   0.222   0.485  -0.082   0.213   0.018   0.203   0.010  -0.294   0.438   \n",
       "107    0.226   0.232  -0.805   0.040   1.241   0.245   0.023  -0.294   0.352   \n",
       "1188   1.964   0.526  -0.824   0.913   1.646   1.986  -0.467  -0.294   0.527   \n",
       "6231   0.752   0.015  -0.565   0.326   0.587   0.547  -0.028  -0.294   0.179   \n",
       "\n",
       "      wb_425  wb_426  wb_427  wb_428  wb_429  wb_430  wb_431  wb_432  wb_433  \\\n",
       "1513   0.341   0.405   0.394   0.531   0.489   0.410  -0.547   0.360  -0.453   \n",
       "3006   0.076   0.200   0.389   0.204   0.150   0.563  -0.924   0.099  -0.238   \n",
       "107    0.777   0.311   0.657   0.945   0.159   0.244  -0.997   0.106  -0.222   \n",
       "1188   0.701   0.718   0.722   2.118   2.089   1.667  -0.833   1.792  -0.244   \n",
       "6231   0.618   0.525   0.599   0.814   0.785   0.178  -0.768   0.102  -0.232   \n",
       "\n",
       "      wb_434  wb_435  wb_436  wb_437  wb_438  wb_439  wb_440  wb_441  wb_442  \\\n",
       "1513   0.320  -0.187  -0.257  -0.159  -0.203   0.375   0.075  -0.366  -0.410   \n",
       "3006   0.412  -0.187  -0.257  -0.159  -0.669   0.667   0.399  -0.495  -0.518   \n",
       "107    0.524  -0.187  -0.257  -0.151  -0.745   0.763   0.250  -0.773  -0.331   \n",
       "1188   0.550  -0.187  -0.257  -0.159  -0.848   1.066   0.466  -0.793  -0.468   \n",
       "6231   0.559  -0.187  -0.257  -0.144  -0.470   0.558   0.079  -0.563  -0.366   \n",
       "\n",
       "      wb_443  wb_444  wb_445  wb_446  wb_447  wb_448  \n",
       "1513   0.428  -0.123   0.479  -0.431   0.400   0.087  \n",
       "3006   0.166  -0.753   0.166  -0.226   0.388  -0.175  \n",
       "107    0.162  -0.860   0.894  -0.956   0.256  -0.067  \n",
       "1188   2.070  -0.721   1.270  -0.741   0.485   0.019  \n",
       "6231   0.165  -0.101   0.709  -0.612   0.285  -0.077  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f11v0</th>\n",
       "      <th>f11v1</th>\n",
       "      <th>f11v2</th>\n",
       "      <th>f11v3</th>\n",
       "      <th>f11v4</th>\n",
       "      <th>f12v0</th>\n",
       "      <th>f12v1</th>\n",
       "      <th>f12v2</th>\n",
       "      <th>f12v3</th>\n",
       "      <th>f12v4</th>\n",
       "      <th>f13v0</th>\n",
       "      <th>f13v1</th>\n",
       "      <th>f13v2</th>\n",
       "      <th>f13v3</th>\n",
       "      <th>f13v4</th>\n",
       "      <th>f14v0</th>\n",
       "      <th>f14v1</th>\n",
       "      <th>f14v2</th>\n",
       "      <th>f14v3</th>\n",
       "      <th>f14v4</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_349</th>\n",
       "      <th>wb_350</th>\n",
       "      <th>wb_351</th>\n",
       "      <th>wb_352</th>\n",
       "      <th>wb_353</th>\n",
       "      <th>wb_354</th>\n",
       "      <th>wb_355</th>\n",
       "      <th>wb_356</th>\n",
       "      <th>wb_357</th>\n",
       "      <th>wb_358</th>\n",
       "      <th>wb_359</th>\n",
       "      <th>wb_360</th>\n",
       "      <th>wb_361</th>\n",
       "      <th>wb_362</th>\n",
       "      <th>wb_363</th>\n",
       "      <th>wb_364</th>\n",
       "      <th>wb_365</th>\n",
       "      <th>wb_366</th>\n",
       "      <th>wb_367</th>\n",
       "      <th>wb_368</th>\n",
       "      <th>wb_369</th>\n",
       "      <th>wb_370</th>\n",
       "      <th>wb_371</th>\n",
       "      <th>wb_372</th>\n",
       "      <th>wb_373</th>\n",
       "      <th>wb_374</th>\n",
       "      <th>wb_375</th>\n",
       "      <th>wb_376</th>\n",
       "      <th>wb_377</th>\n",
       "      <th>wb_378</th>\n",
       "      <th>wb_379</th>\n",
       "      <th>wb_380</th>\n",
       "      <th>wb_381</th>\n",
       "      <th>wb_382</th>\n",
       "      <th>wb_383</th>\n",
       "      <th>wb_384</th>\n",
       "      <th>wb_385</th>\n",
       "      <th>wb_386</th>\n",
       "      <th>wb_387</th>\n",
       "      <th>wb_388</th>\n",
       "      <th>wb_389</th>\n",
       "      <th>wb_390</th>\n",
       "      <th>wb_391</th>\n",
       "      <th>wb_392</th>\n",
       "      <th>wb_393</th>\n",
       "      <th>wb_394</th>\n",
       "      <th>wb_395</th>\n",
       "      <th>wb_396</th>\n",
       "      <th>wb_397</th>\n",
       "      <th>wb_398</th>\n",
       "      <th>wb_399</th>\n",
       "      <th>wb_400</th>\n",
       "      <th>wb_401</th>\n",
       "      <th>wb_402</th>\n",
       "      <th>wb_403</th>\n",
       "      <th>wb_404</th>\n",
       "      <th>wb_405</th>\n",
       "      <th>wb_406</th>\n",
       "      <th>wb_407</th>\n",
       "      <th>wb_408</th>\n",
       "      <th>wb_409</th>\n",
       "      <th>wb_410</th>\n",
       "      <th>wb_411</th>\n",
       "      <th>wb_412</th>\n",
       "      <th>wb_413</th>\n",
       "      <th>wb_414</th>\n",
       "      <th>wb_415</th>\n",
       "      <th>wb_416</th>\n",
       "      <th>wb_417</th>\n",
       "      <th>wb_418</th>\n",
       "      <th>wb_419</th>\n",
       "      <th>wb_420</th>\n",
       "      <th>wb_421</th>\n",
       "      <th>wb_422</th>\n",
       "      <th>wb_423</th>\n",
       "      <th>wb_424</th>\n",
       "      <th>wb_425</th>\n",
       "      <th>wb_426</th>\n",
       "      <th>wb_427</th>\n",
       "      <th>wb_428</th>\n",
       "      <th>wb_429</th>\n",
       "      <th>wb_430</th>\n",
       "      <th>wb_431</th>\n",
       "      <th>wb_432</th>\n",
       "      <th>wb_433</th>\n",
       "      <th>wb_434</th>\n",
       "      <th>wb_435</th>\n",
       "      <th>wb_436</th>\n",
       "      <th>wb_437</th>\n",
       "      <th>wb_438</th>\n",
       "      <th>wb_439</th>\n",
       "      <th>wb_440</th>\n",
       "      <th>wb_441</th>\n",
       "      <th>wb_442</th>\n",
       "      <th>wb_443</th>\n",
       "      <th>wb_444</th>\n",
       "      <th>wb_445</th>\n",
       "      <th>wb_446</th>\n",
       "      <th>wb_447</th>\n",
       "      <th>wb_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>3857.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.588</td>\n",
       "      <td>-0.869</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>0.765</td>\n",
       "      <td>1.017</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.702</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.573</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>-0.764</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.657</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.795</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.896</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.759</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.564</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.843</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>0.877</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>8127.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.382</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>0.850</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.944</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.792</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-1.108</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>-0.755</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.677</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-1.113</td>\n",
       "      <td>0.721</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.420</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-1.018</td>\n",
       "      <td>0.728</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.507</td>\n",
       "      <td>-1.005</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>5323.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.312</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.322</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.685</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.723</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.189</td>\n",
       "      <td>0.872</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>0.599</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>1.138</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.784</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>0.968</td>\n",
       "      <td>1.096</td>\n",
       "      <td>0.720</td>\n",
       "      <td>-1.147</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.679</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.751</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.862</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>0.806</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-1.016</td>\n",
       "      <td>-0.777</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.669</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>0.868</td>\n",
       "      <td>-0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.031</td>\n",
       "      <td>1.003</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.204</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.878</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.675</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.872</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>0.733</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.609</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1.114</td>\n",
       "      <td>0.726</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>0.668</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>0.816</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>0.986</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.662</td>\n",
       "      <td>-0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9317</th>\n",
       "      <td>9317.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.298</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.639</td>\n",
       "      <td>-0.547</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>-0.734</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.545</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.723</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.829</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.643</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0   f0v1  f0v2   f0v3   f0v4  f1v0  f1v1  f1v2  f1v3  \\\n",
       "3857 3857.000    42 0.000  0.000 0.000  0.000  0.215 0.000 0.000 0.000 0.000   \n",
       "8127 8127.000    42 0.000 -0.378 0.000  0.000  0.000 0.000 0.424 0.000 0.000   \n",
       "5323 5323.000    42 0.000  0.000 0.000 -0.380  0.000 0.000 0.427 0.000 0.000   \n",
       "39     39.000    42 0.000  0.000 0.000  0.000 -0.400 0.000 0.000 0.000 0.000   \n",
       "9317 9317.000    42 0.000  0.000 0.327  0.000  0.000 0.000 0.437 0.000 0.000   \n",
       "\n",
       "       f1v4   f2v0   f2v1   f2v2  f2v3  f2v4  f3v0   f3v1  f3v2  f3v3   f3v4  \\\n",
       "3857 -0.329  0.351  0.000  0.000 0.000 0.000 0.000 -0.435 0.000 0.000  0.000   \n",
       "8127  0.000  0.000  0.000  0.392 0.000 0.000 0.000 -0.428 0.000 0.000  0.000   \n",
       "5323  0.000 -0.427  0.000  0.000 0.000 0.000 0.000 -0.442 0.000 0.000  0.000   \n",
       "39    0.305  0.000 -0.430  0.000 0.000 0.000 0.000  0.000 0.000 0.000 -0.437   \n",
       "9317  0.000  0.000  0.000 -0.243 0.000 0.000 0.000  0.000 0.000 0.000  0.418   \n",
       "\n",
       "      f4v0   f4v1   f4v2   f4v3  f4v4   f5v0  f5v1   f5v2  f5v3   f5v4   f6v0  \\\n",
       "3857 0.000  0.000  0.000 -0.390 0.000  0.000 0.000  0.000 0.383  0.000  0.000   \n",
       "8127 0.000  0.000 -0.409  0.000 0.000  0.000 0.000 -0.412 0.000  0.000  0.000   \n",
       "5323 0.000  0.369  0.000  0.000 0.000  0.000 0.000  0.000 0.000 -0.275  0.000   \n",
       "39   0.000 -0.410  0.000  0.000 0.000 -0.381 0.000  0.000 0.000  0.000  0.000   \n",
       "9317 0.000  0.000 -0.219  0.000 0.000  0.000 0.436  0.000 0.000  0.000 -0.431   \n",
       "\n",
       "       f6v1   f6v2   f6v3  f6v4  f7v0  f7v1   f7v2  f7v3  f7v4   f8v0   f8v1  \\\n",
       "3857 -0.344  0.000  0.000 0.000 0.000 0.403  0.000 0.000 0.000 -0.404  0.000   \n",
       "8127  0.000 -0.390  0.000 0.000 0.000 0.000  0.000 0.000 0.386  0.413  0.000   \n",
       "5323  0.000  0.000 -0.420 0.000 0.000 0.000 -0.408 0.000 0.000  0.383  0.000   \n",
       "39    0.438  0.000  0.000 0.000 0.000 0.000 -0.444 0.000 0.000 -0.437  0.000   \n",
       "9317  0.000  0.000  0.000 0.000 0.000 0.000  0.339 0.000 0.000  0.000 -0.433   \n",
       "\n",
       "      f8v2  f8v3  f8v4   f9v0   f9v1   f9v2  f9v3  f9v4  f10v0  f10v1  f10v2  \\\n",
       "3857 0.000 0.000 0.000  0.000  0.000  0.000 0.000 0.417  0.000  0.000  0.381   \n",
       "8127 0.000 0.000 0.000 -0.363  0.000  0.000 0.000 0.000  0.364  0.000  0.000   \n",
       "5323 0.000 0.000 0.000  0.000  0.000 -0.441 0.000 0.000  0.000  0.000  0.000   \n",
       "39   0.000 0.000 0.000  0.000  0.000  0.399 0.000 0.000  0.000  0.000  0.388   \n",
       "9317 0.000 0.000 0.000  0.000 -0.411  0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f10v3  f10v4  f11v0  f11v1  f11v2  f11v3  f11v4  f12v0  f12v1  f12v2  \\\n",
       "3857  0.000  0.000  0.000  0.000  0.000  0.000 -0.417  0.000  0.000 -0.430   \n",
       "8127  0.000  0.000  0.000  0.000  0.000 -0.421  0.000  0.000  0.000  0.421   \n",
       "5323  0.000 -0.334  0.000  0.000  0.000  0.332  0.000  0.000  0.000  0.000   \n",
       "39    0.000  0.000  0.000  0.000  0.000 -0.402  0.000  0.000 -0.405  0.000   \n",
       "9317  0.355  0.000  0.376  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f12v3  f12v4  f13v0  f13v1  f13v2  f13v3  f13v4  f14v0  f14v1  f14v2  \\\n",
       "3857  0.000  0.000  0.000 -0.315  0.000  0.000  0.000  0.000 -0.267  0.000   \n",
       "8127  0.000  0.000  0.231  0.000  0.000  0.000  0.000 -0.292  0.000  0.000   \n",
       "5323  0.000 -0.420  0.000  0.000  0.000  0.000  0.440  0.000  0.000  0.000   \n",
       "39    0.000  0.000  0.000  0.000 -0.438  0.000  0.000  0.000  0.000  0.000   \n",
       "9317  0.385  0.000  0.435  0.000  0.000  0.000  0.000  0.442  0.000  0.000   \n",
       "\n",
       "      f14v3  f14v4     b0     b1     b2     b3     b4     b5     b6     b7  \\\n",
       "3857  0.000  0.000 -0.192  0.045  0.180  0.196  0.236 -0.226 -0.048 -0.057   \n",
       "8127  0.000  0.000  0.230 -0.388 -0.260  0.166  0.075  0.163 -0.001  0.131   \n",
       "5323  0.000  0.243  0.275  0.085 -0.440 -0.287  0.312 -0.193  0.001 -0.283   \n",
       "39   -0.338  0.000 -0.032  0.284  0.245  0.378 -0.116  0.240  0.411 -0.277   \n",
       "9317  0.000  0.000 -0.073 -0.167  0.240 -0.114  0.026 -0.146  0.298 -0.331   \n",
       "\n",
       "         b8     b9    b10    b11    b12    b13    b14  lp0c0  lp0c1  lp1c0  \\\n",
       "3857 -0.217 -0.299  0.304 -0.339 -0.040  0.104 -0.418 -0.227  0.210  0.133   \n",
       "8127 -0.431  0.173 -0.089 -0.247  0.382 -0.239  0.089  0.097  0.106 -0.221   \n",
       "5323  0.021  0.188  0.064  0.146 -0.245  0.139  0.385 -0.004  0.237 -0.246   \n",
       "39   -0.158  0.179  0.030  0.428  0.034  0.446  0.182 -0.052  0.146  0.212   \n",
       "9317  0.124  0.291 -0.414  0.266  0.010  0.407  0.110 -0.108 -0.047  0.218   \n",
       "\n",
       "      lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  ...  wb_349  wb_350  wb_351  wb_352  \\\n",
       "3857  0.066  0.186  0.195  0.191 -0.203  ...  -0.039  -0.029  -0.046   0.113   \n",
       "8127 -0.149  0.064  0.119  0.041  0.190  ...   0.120   0.016  -0.075  -0.071   \n",
       "5323  0.092  0.229  0.016 -0.069  0.218  ...   0.009   0.263  -0.042   0.018   \n",
       "39    0.050 -0.052 -0.177 -0.112 -0.085  ...   0.017  -0.043  -0.012  -0.077   \n",
       "9317 -0.146  0.231 -0.080 -0.028  0.090  ...  -0.035   0.058  -0.069  -0.070   \n",
       "\n",
       "      wb_353  wb_354  wb_355  wb_356  wb_357  wb_358  wb_359  wb_360  wb_361  \\\n",
       "3857  -0.108   0.031  -0.070   0.000   0.158  -0.067   0.000  -0.025   0.241   \n",
       "8127  -0.043   0.195  -0.005  -0.005  -0.134   0.169   0.000  -0.040  -0.051   \n",
       "5323  -0.098   0.345  -0.022   0.000   0.029   0.013   0.000  -0.127  -0.055   \n",
       "39    -0.057  -0.029  -0.055  -0.014  -0.064   0.039   0.000  -0.087   0.000   \n",
       "9317  -0.078   0.133   0.076   0.236   0.116  -0.064   0.000  -0.006  -0.046   \n",
       "\n",
       "      wb_362  wb_363  wb_364  wb_365  wb_366  wb_367  wb_368  wb_369  wb_370  \\\n",
       "3857  -0.059  -0.021   0.354   0.364  -0.028   0.053  -0.067   0.017   0.004   \n",
       "8127  -0.086  -0.106  -0.065  -0.033  -0.100  -0.052  -0.036   0.029  -0.243   \n",
       "5323  -0.045  -0.060  -0.067  -0.042  -0.075  -0.037  -0.013   0.306  -0.046   \n",
       "39    -0.066  -0.072  -0.045  -0.033  -0.049  -0.054   0.014  -0.092   0.002   \n",
       "9317  -0.086  -0.078   0.211  -0.036  -0.092   0.160  -0.078   0.133   0.071   \n",
       "\n",
       "      wb_371  wb_372  wb_373  wb_374  wb_375  wb_376  wb_377  wb_378  wb_379  \\\n",
       "3857   0.000   0.000   0.000  -0.015   0.195  -0.031   0.042  -0.007   0.288   \n",
       "8127   0.000   0.000   0.178   0.258  -0.263  -0.043   0.040  -0.056  -0.064   \n",
       "5323   0.000   0.000   0.363   0.322  -0.107  -0.115   0.311   0.055  -0.065   \n",
       "39     0.000   0.000   0.000  -0.040  -0.007  -0.085  -0.066   0.155   0.031   \n",
       "9317   0.000   0.000   0.191   0.115   0.085  -0.001   0.123   0.043  -0.040   \n",
       "\n",
       "      wb_380  wb_381  wb_382  wb_383  wb_384  wb_385  wb_386  wb_387  wb_388  \\\n",
       "3857   0.023   0.328  -0.063  -0.125  -0.463   0.616   0.588  -0.869  -0.833   \n",
       "8127   0.119  -0.087  -0.083  -0.060  -0.534  -0.760   0.850  -0.259  -0.183   \n",
       "5323  -0.034  -0.082   0.332  -0.105  -0.062  -0.685   0.315  -0.257  -0.215   \n",
       "39     0.307  -0.023  -0.068  -0.080  -0.082  -0.582   0.281  -0.247  -0.217   \n",
       "9317   0.176  -0.071   0.114  -0.032  -0.445   0.461   0.550  -0.790  -0.775   \n",
       "\n",
       "      wb_389  wb_390  wb_391  wb_392  wb_393  wb_394  wb_395  wb_396  wb_397  \\\n",
       "3857   0.765   1.017  -0.204  -0.702  -0.272   0.573  -0.600  -0.407  -0.920   \n",
       "8127   0.017   0.133  -0.138  -0.173  -0.272   0.944  -0.993  -0.552  -0.154   \n",
       "5323   0.905   0.130  -0.836  -0.577  -0.272   0.712  -0.116   0.723  -0.154   \n",
       "39     0.031   1.003  -0.773  -0.817  -0.272   0.204  -0.762  -0.605  -0.154   \n",
       "9317   0.566   0.132  -0.459  -0.606  -0.272   0.639  -0.547  -0.364  -0.734   \n",
       "\n",
       "      wb_398  wb_399  wb_400  wb_401  wb_402  wb_403  wb_404  wb_405  wb_406  \\\n",
       "3857   0.053   0.148  -0.749  -0.458  -0.239  -0.575  -0.764  -0.535  -0.425   \n",
       "8127   0.552   0.134   0.792  -0.939  -0.518  -1.108  -0.232  -0.884  -0.755   \n",
       "5323   0.743   1.189   0.872  -0.874   0.599  -0.905  -0.232  -0.054   0.797   \n",
       "39     0.552   0.139  -0.737  -0.136   0.444  -0.144  -0.878  -0.661  -0.588   \n",
       "9317   0.113   0.139  -0.006  -0.251  -0.073  -0.579  -0.611  -0.342   0.472   \n",
       "\n",
       "      wb_407  wb_408  wb_409  wb_410  wb_411  wb_412  wb_413  wb_414  wb_415  \\\n",
       "3857  -0.211   0.087   0.657  -0.460   0.505  -0.795  -0.012  -0.442   0.178   \n",
       "8127   0.506   0.347   0.677  -0.935   0.115  -1.113   0.721  -0.928   0.167   \n",
       "5323   0.676   0.750   0.005  -0.798   1.138  -0.181   0.784  -0.845   0.968   \n",
       "39     0.495   0.516   0.675  -0.070   0.872  -0.847   0.733  -0.089   0.778   \n",
       "9317  -0.153   0.292   0.545  -0.483   0.730  -0.770  -0.022  -0.482   0.169   \n",
       "\n",
       "      wb_416  wb_417  wb_418  wb_419  wb_420  wb_421  wb_422  wb_423  wb_424  \\\n",
       "3857   0.513   0.077  -0.668   0.038   0.025   0.721   0.021  -0.294   0.013   \n",
       "8127   0.222   0.420  -0.740   0.464   0.020   0.206   0.411  -0.294   0.519   \n",
       "5323   1.096   0.720  -1.147   0.740   0.025   0.871   0.679  -0.294   0.609   \n",
       "39     0.210   0.609  -0.089   0.536   0.015   0.411   0.633  -0.294   0.408   \n",
       "9317   0.213   0.042  -0.572   0.464   0.578   0.723  -0.010  -0.294   0.199   \n",
       "\n",
       "      wb_425  wb_426  wb_427  wb_428  wb_429  wb_430  wb_431  wb_432  wb_433  \\\n",
       "3857   0.782   0.164   0.195   0.929   0.948   0.226  -0.896   0.107  -0.759   \n",
       "8127   0.080   0.247   0.122   0.193   0.158   0.380  -0.258   0.131  -1.018   \n",
       "5323   0.075   0.908   0.926   0.197   0.153   0.751  -0.270   0.862  -1.033   \n",
       "39     0.747   0.782   0.811   0.218   1.114   0.726  -0.264   0.668  -0.220   \n",
       "9317   0.083   0.161   0.148   0.779   0.162   0.183  -0.829   0.104  -0.710   \n",
       "\n",
       "      wb_434  wb_435  wb_436  wb_437  wb_438  wb_439  wb_440  wb_441  wb_442  \\\n",
       "3857   0.161  -0.187  -0.257  -0.159  -0.564   0.694   0.012  -0.624  -0.405   \n",
       "8127   0.728  -0.187  -0.257  -0.935  -0.684   0.927   0.507  -1.005  -0.491   \n",
       "5323   0.806  -0.187  -0.257  -1.016  -0.777   0.128   0.669  -0.917  -0.209   \n",
       "39    -0.045  -0.187  -0.257  -0.159  -0.014   0.470   0.440  -0.119  -0.667   \n",
       "9317   0.535  -0.187  -0.257  -0.753  -0.478   0.542   0.254  -0.560  -0.147   \n",
       "\n",
       "      wb_443  wb_444  wb_445  wb_446  wb_447  wb_448  \n",
       "3857   0.843  -0.781   0.877  -0.505   0.207  -0.006  \n",
       "8127   0.165  -0.972   0.174  -0.154   0.302  -0.064  \n",
       "5323   0.167  -0.105   0.168  -0.935   0.868  -0.159  \n",
       "39     0.816  -0.776   0.986  -0.164   0.662  -0.049  \n",
       "9317   0.182  -0.769   0.180  -0.643   0.287  -0.037  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "Epoch 1/2\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "[9.14954281 10.369482 6.70966482 ... 7.62461901 7.92960405 6.40468025]\n",
      "7.224751\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.2248 - binary_accuracy_inet_decision_function_fv_metric: 0.5262DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "[3.0498476 10.6744661 11.2844372 4.5747714 8.23458862]\n",
      "7.56362247\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "1/1 [==============================] - 27s 27s/step - loss: 7.2248 - binary_accuracy_inet_decision_function_fv_metric: 0.5262 - val_loss: 7.5636 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5040\n",
      "Epoch 2/2\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "[5.79471064 10.064497 5.48972607 ... 4.5747714 6.70966482 4.26978683]\n",
      "7.22475052\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.2248 - binary_accuracy_inet_decision_function_fv_metric: 0.5262DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "[3.0498476 10.6744661 11.2844372 4.5747714 8.23458862]\n",
      "7.56362247\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      "DT SPLITS ENCODED [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "split_value_list [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0], [1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0], [1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n",
      "split_values [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "leaf_classes [1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1]\n",
      "final_class 1\n",
      "function_values_sdt [1 1 1 ... 1 1 1]\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.2248 - binary_accuracy_inet_decision_function_fv_metric: 0.5262 - val_loss: 7.5636 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5040\n",
      "Training Time: 0:00:33\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " history,\n",
    "\n",
    " model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=['plot_losses']\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 0 0 0 0], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0  3  6  9 12], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0  4  8 12 16], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0  5 10 15 20], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0  6 12 18 24], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0  7 14 21 28], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0  8 16 24 32], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0  9 18 27 36], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0 10 20 30 40], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0 11 22 33 44], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0 12 24 36 48], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0 13 26 39 52], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 0 14 28 42 56], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for tensor in tf.split(tf.constant([[i*j for i in range(5)] for j in range(15)]), 15):\n",
    "    print(tf.squeeze(tensor, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[0, 0, 0, 0, 0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[0, 1, 2, 3, 4]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[0, 2, 4, 6, 8]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0,  3,  6,  9, 12]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0,  4,  8, 12, 16]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0,  5, 10, 15, 20]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0,  6, 12, 18, 24]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0,  7, 14, 21, 28]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0,  8, 16, 24, 32]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0,  9, 18, 27, 36]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0, 10, 20, 30, 40]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0, 11, 22, 33, 44]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0, 12, 24, 36, 48]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0, 13, 26, 39, 52]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 0, 14, 28, 42, 56]], dtype=int32)>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.split(tf.squeeze(tf.constant([[i*j for i in range(5)] for j in range(15)])), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False,  True, False])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.not_equal(tf.constant([0,0,1,0]), tf.constant([0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False,  True, False])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.greater(tf.constant([0,0,1,0]), tf.constant([0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False,  True, False])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.equal(tf.constant([0,0,1,0]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f4e865e188ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaximum_depth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "2**(maximum_depth-(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_depth = 4\n",
    "i=0\n",
    "split_value =True\n",
    "\n",
    "zero_identifier= tf.constant([True, False, False, False])\n",
    "split_complete= tf.constant([True, False, False, False])\n",
    "\n",
    "split_value = tf.reduce_any(tf.logical_and(zero_identifier, split_complete))\n",
    "print('split_value', split_value)\n",
    "\n",
    "split_value_filled = tf.fill([(2**(maximum_depth-(i-1)))], split_value)\n",
    "print(split_value_filled)\n",
    "split_value_neg_filled = tf.fill([(2**(maximum_depth-(i-1)))], tf.logical_not(split_value))\n",
    "print(split_value_filled)\n",
    "print(tf.keras.backend.flatten(tf.stack([split_value_filled, split_value_neg_filled])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(tf.constant([True]), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(tf.constant([1]), tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens = tf.constant([random.randint(0, 100) for i in range(function_representation_length)])\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "get_shaped_parameters_for_decision_tree(tens, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.constant([[1,2,3,4],[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.squeeze(tf.constant([[1]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=[input_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_representation_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_target_lambda_list = []\n",
    "bc_target_lambda_list = []\n",
    "\n",
    "acc_lambda_decision_list = []\n",
    "bc_lambda_decision_list = []\n",
    "\n",
    "acc_target_decision_list = []\n",
    "bc_target_decision_list = []\n",
    "\n",
    "decision_function_parameters_list = []\n",
    "decision_functio_list = []\n",
    "\n",
    "for lambda_net in tqdm(lambda_net_dataset_test.lambda_net_list):\n",
    "    \n",
    "    target_function_parameters = lambda_net.target_function_parameters\n",
    "    target_function = lambda_net.target_function\n",
    "    \n",
    "    X_test_lambda = lambda_net.X_test_lambda\n",
    "    y_test_lambda = lambda_net.y_test_lambda\n",
    "    \n",
    "    network = lambda_net.network\n",
    "    network_parameters = lambda_net.network_parameters\n",
    "    \n",
    "    if config['i_net']['convolution_layers'] != None or config['i_net']['lstm_layers'] != None or (config['i_net']['nas'] and config['nas_type']['convolution_layers'] != 'SEQUENTIAL'):\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(np.array([network_parameters]), config, subsequences=None)    \n",
    "      \n",
    "    decision_function_parameters= model.predict(np.array([network_parameters]))[0]\n",
    "    decision_function = generate_decision_tree_from_array(decision_function_parameters, config)\n",
    "    \n",
    "    decision_function_parameters_list.append(decision_function_parameters)\n",
    "    decision_functio_list.append(decision_function)\n",
    "    \n",
    "    y_test_network = network.predict(X_test_lambda)\n",
    "    y_test_decision_function = decision_function.predict_proba(X_test_lambda)\n",
    "    y_test_target_function = target_function.predict_proba(X_test_lambda)  \n",
    "    \n",
    "    acc_target_lambda = accuracy_score(np.round(y_test_target_function), np.round(y_test_network))\n",
    "    bc_target_lambda = log_loss(np.round(y_test_target_function), y_test_network, labels=[0, 1])\n",
    "    \n",
    "    acc_lambda_decision = accuracy_score(np.round(y_test_network), np.round(y_test_decision_function))\n",
    "    bc_lambda_decision = log_loss(np.round(y_test_network), y_test_decision_function, labels=[0, 1])        \n",
    "    \n",
    "    acc_target_decision = accuracy_score(np.round(y_test_target_function), np.round(y_test_decision_function))\n",
    "    bc_target_decision = log_loss(np.round(y_test_target_function), y_test_decision_function, labels=[0, 1])   \n",
    "    \n",
    "    \n",
    "    acc_target_lambda_list.append(acc_target_lambda)\n",
    "    bc_target_lambda_list.append(bc_target_lambda)\n",
    "\n",
    "    acc_lambda_decision_list.append(acc_lambda_decision)\n",
    "    bc_lambda_decision_list.append(bc_lambda_decision)\n",
    "\n",
    "    acc_target_decision_list.append(acc_target_decision)\n",
    "    bc_target_decision_list.append(bc_target_decision)\n",
    "    \n",
    "\n",
    "acc_target_lambda_array = np.array(acc_target_lambda_list)\n",
    "bc_target_lambda_array = np.array(bc_target_lambda_list)\n",
    "\n",
    "acc_lambda_decision_array = np.array(acc_lambda_decision_list)\n",
    "bc_lambda_decision_array = np.array(bc_lambda_decision_list)\n",
    "\n",
    "acc_target_decision_array = np.array(acc_target_decision_list)\n",
    "bc_target_decision_array = np.array(bc_target_decision_list)\n",
    "    \n",
    "    \n",
    "acc_target_lambda = np.mean(acc_target_lambda_array)\n",
    "bc_target_lambda = np.mean(bc_target_lambda_array[~np.isnan(bc_target_lambda_array)])\n",
    "\n",
    "acc_lambda_decision = np.mean(acc_lambda_decision_array)\n",
    "bc_lambda_decision = np.mean(bc_lambda_decision_array[~np.isnan(bc_lambda_decision_array)])\n",
    "\n",
    "acc_target_decision = np.mean(acc_target_decision_array)\n",
    "bc_target_decision = np.mean(bc_target_decision_array[~np.isnan(bc_target_decision_array)])\n",
    "\n",
    "\n",
    "print('Accuracy Target Lambda', acc_target_lambda)\n",
    "print('Binary Crossentropy Target Lambda', bc_target_lambda)\n",
    "print('Accuracy Lambda Decision', acc_lambda_decision)\n",
    "print('Binary Crossentropy Lambda Decision', bc_lambda_decision)\n",
    "print('Accuracy Target Decision', acc_target_decision)\n",
    "print('Binary Crossentropy Target Decision', bc_target_decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(network.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_weights()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_weights()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_test_network).ravel()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_test_decision_function).ravel()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lambda_decision_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO BENCHMARK RANDOM GUESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################################################################################################################\n",
    "#################################################################################################### END WORKING CODE ####################################################################################################\n",
    "##########################################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polynomial_dict_valid_list = []\n",
    "polynomial_dict_test_list = []  \n",
    "\n",
    "\n",
    "for lambda_net_valid_dataset, lambda_net_test_dataset in zip(lambda_net_valid_dataset_list, lambda_net_test_dataset_list):\n",
    "\n",
    "    #polynomial_dict_valid = {'lstsq_lambda_pred_polynomials': lambda_net_valid_dataset.lstsq_lambda_pred_polynomial_list,\n",
    "    #                        'lstsq_target_polynomials': lambda_net_valid_dataset.lstsq_target_polynomial_list,\n",
    "    #                        'target_polynomials': lambda_net_valid_dataset.target_polynomial_list}    \n",
    "\n",
    "    polynomial_dict_test = {'lstsq_lambda_pred_polynomials': lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list,\n",
    "                            'lstsq_target_polynomials': lambda_net_test_dataset.lstsq_target_polynomial_list,\n",
    "                            'target_polynomials': lambda_net_test_dataset.target_polynomial_list}    \n",
    "\n",
    "    #polynomial_dict_valid_list.append(polynomial_dict_valid)  \n",
    "    polynomial_dict_test_list.append(polynomial_dict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------- PREDICT INET ------------------------------------------------------')\n",
    "\n",
    "start = time.time() \n",
    "\n",
    "for i, (X_test, model) in enumerate(zip(X_test_list, model_list)):\n",
    "    #y_test_pred = model.predict(X_test)    \n",
    "    #print(model.summary())\n",
    "    #print(X_test.shape)\n",
    "    y_test_pred = make_inet_prediction(model, X_test, network_data=None, lambda_trained_normalized=False, inet_training_normalized=normalize_inet_data, normalization_parameter_dict=None)\n",
    "    #print(y_test_pred.shape)   \n",
    "    polynomial_dict_test_list[i]['inet_polynomials'] = y_test_pred\n",
    "\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('Predict Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if symbolic_metamodeling_poly_evaluation:\n",
    "    print('-------------------------------------------------- CALCULATE METAMODEL POLY -----------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        \n",
    "        metamodel_functions_test = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=False, force_polynomial=True)\n",
    "        polynomial_dict_test_list[i]['metamodel_poly'] = metamodel_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Metamodel Poly Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if symbolic_metamodeling_evaluation:\n",
    "    print('---------------------------------------------------- CALCULATE METAMODEL --------------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        metamodel_functions_test = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=False, force_polynomial=False)\n",
    "        polynomial_dict_test_list[i]['metamodel_functions'] = metamodel_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Metamodel Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if symbolic_metamodeling_function_evaluation:\n",
    "    print('----------------------------------------------- CALCULATE METAMODEL FUNCTION ----------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        metamodel_functions_test = symbolic_metamodeling_function_generation(lambda_net_test_dataset, return_expression='approx', function_metamodeling=True)\n",
    "        polynomial_dict_test_list[i]['metamodel_functions_no_GD'] = metamodel_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Metamodel Function Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if symbolic_regression_evaluation:\n",
    "    print('----------------------------------------- CALCULATE SYMBOLIC REGRESSION FUNCTION ------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        symbolic_regression_functions_test = symbolic_regression_function_generation(lambda_net_test_dataset)\n",
    "        polynomial_dict_test_list[i]['symbolic_regression_functions'] = symbolic_regression_functions_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Symbolic Regression Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if per_network_evaluation:\n",
    "    print('------------------------------------------------ CALCULATE PER NETWORK POLY -----------------------------------------------')\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    for i, lambda_net_test_dataset in enumerate(lambda_net_test_dataset_list): \n",
    "        per_network_poly_test = per_network_poly_generation(lambda_net_test_dataset, optimization_type='scipy')\n",
    "        polynomial_dict_test_list[i]['per_network_polynomials'] = per_network_poly_test       \n",
    "\n",
    "    end = time.time()     \n",
    "    inet_train_time = (end - start) \n",
    "    minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    print('Per Network Optimization Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "print('------------------------------------------------ CALCULATE FUNCTION VALUES ------------------------------------------------')                \n",
    "\n",
    "start = time.time() \n",
    "\n",
    "function_values_test_list = []\n",
    "for lambda_net_test_dataset, polynomial_dict_test in zip(lambda_net_test_dataset_list, polynomial_dict_test_list):\n",
    "    function_values_test = calculate_all_function_values(lambda_net_test_dataset, polynomial_dict_test)\n",
    "    function_values_test_list.append(function_values_test)\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('FV Calculation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------------- CALCULATE SCORES ----------------------------------------------------')                \n",
    "\n",
    "start = time.time() \n",
    "\n",
    "scores_test_list = []\n",
    "distrib_dict_test_list = []\n",
    "\n",
    "for function_values_test, polynomial_dict_test in zip(function_values_test_list, polynomial_dict_test_list):\n",
    "    scores_test, distrib_test = evaluate_all_predictions(function_values_test, polynomial_dict_test)\n",
    "    scores_test_list.append(scores_test)\n",
    "    distrib_dict_test_list.append(distrib_test)\n",
    "\n",
    "end = time.time()     \n",
    "inet_train_time = (end - start) \n",
    "minutes, seconds = divmod(int(inet_train_time), 60)\n",
    "hours, minutes = divmod(minutes, 60)        \n",
    "print('Score Calculation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')     \n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_type = 'epochs' if samples_list == None else 'samples'\n",
    "save_results(scores_list=scores_test_list, by=identifier_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Interpretation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nas:\n",
    "    for trial in history_list[-1]: \n",
    "        print(trial.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(model_list) >= 1:\n",
    "    print(model_list[-1].summary())\n",
    "    print(model_list[-1].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not optimize_decision_function:\n",
    "    keys = ['inetPoly_VS_targetPoly_test', 'perNetworkPoly_VS_targetPoly_test', 'predLambda_VS_targetPoly_test', 'lstsqLambda_VS_targetPoly_test', 'lstsqTarget_VS_targetPoly_test']\n",
    "else:\n",
    "    keys = ['inetPoly_VS_predLambda_test', 'inetPoly_VS_lstsqLambda_test', 'perNetworkPoly_VS_predLambda_test', 'perNetworkPoly_VS_lstsqLambda_test', 'lstsqLambda_VS_predLambda_test', 'predLambda_VS_targetPoly_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.183\t0.234\t3.604\t0.143\t0.687\t2.559\t0.215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_inet_polynomials'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:55.162513Z",
     "start_time": "2021-01-08T11:56:54.472198Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:56.434915Z",
     "start_time": "2021-01-08T11:56:55.669304Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_dict_test_list[-1]['R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T20:33:18.514683Z",
     "start_time": "2021-01-07T20:33:18.506614Z"
    }
   },
   "outputs": [],
   "source": [
    "index_min = int(np.argmin(distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials']))\n",
    "\n",
    "print(distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'][index_min])\n",
    "\n",
    "polynomial_lambda = lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list[index_min]\n",
    "print_polynomial_from_coefficients(polynomial_lambda, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:42.304392Z",
     "start_time": "2021-01-07T15:49:42.291475Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_values_inet = distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_inet_polynomials']\n",
    "print('Mean: ' + str(np.mean(r2_values_inet)) + ' (' + str(r2_values_inet.shape[0]) + ' Samples)')\n",
    "\n",
    "r2_values_positive_inet = r2_values_inet[r2_values_inet>0]\n",
    "print('Mean (only positive): ' + str(np.mean(r2_values_positive_inet)) + ' (' + str(r2_values_positive_inet.shape[0]) + ' Samples)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:42.833577Z",
     "start_time": "2021-01-07T15:49:42.821286Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_values_lstsq_lambda = distrib_dict_test_list[-1]['R2'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials']\n",
    "print('Mean: ' + str(np.mean(r2_values_lstsq_lambda)) + ' (' + str(r2_values_inet.shape[0]) + ' Samples)')\n",
    "\n",
    "r2_values_positive_lstsq_lambda = r2_values_lstsq_lambda[r2_values_lstsq_lambda>0]\n",
    "print('Mean (only positive): ' + str(np.mean(r2_values_positive_lstsq_lambda)) + ' (' + str(r2_values_positive_lstsq_lambda.shape[0]) + ' Samples)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'] < 50], binwidth=0.1)\n",
    "#p.set(xlim=(0, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_inet_polynomials'] < 50], binwidth=0.1)\n",
    "p.set(xlim=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'] < 50], binwidth=0.1)\n",
    "#p.set(xlim=(0, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:44.179590Z",
     "start_time": "2021-01-07T15:49:43.001746Z"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.histplot(distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'][distrib_dict_test_list[-1]['MAE'].loc['lambda_preds_VS_lstsq_lambda_pred_polynomials'] < 50], binwidth=0.1)\n",
    "p.set(xlim=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.410283Z",
     "start_time": "2021-01-07T15:49:48.254228Z"
    }
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history[list(history.keys())[1]])\n",
    "    try:\n",
    "        plt.plot(history[list(history.keys())[len(history.keys())//2+1]]) \n",
    "    except:\n",
    "        pass\n",
    "    plt.title('model ' + list(history.keys())[1])\n",
    "    plt.ylabel('metric')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/metric_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:48.567983Z",
     "start_time": "2021-01-07T15:49:48.413234Z"
    }
   },
   "outputs": [],
   "source": [
    "if not nas:\n",
    "    history = history_list[-1]\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    try:\n",
    "        plt.plot(history['val_loss'])\n",
    "    except:\n",
    "        pass\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.savefig('./data/results/' + path_identifier_interpretation_net_data + '/loss_' + '_epoch_' + str(epochs_lambda).zfill(3) + '.png')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Epoch/Sampes Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Comparison Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['MAE FV', 'RMSE FV', 'MAPE FV', 'R2 FV', 'RAAE FV', 'RMAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['MAE FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(scores_test_list) > 1:\n",
    "    plot_metric_list = ['R2 FV']\n",
    "\n",
    "    generate_inet_comparison_plot(scores_test_list, plot_metric_list, ylim=(-5, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate and Analyze Predictions for Random Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6\n",
    "\n",
    "custom_representation_keys_fixed = ['target_polynomials', 'lstsq_target_polynomials', 'lstsq_lambda_pred_polynomials', 'lstsq_lambda_pred_polynomials']\n",
    "custom_representation_keys_dynamic = ['inet_polynomials', 'per_network_polynomials']\n",
    "sympy_representation_keys = ['metamodel_functions']\n",
    "\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "for key in polynomial_dict_test_list[-1].keys():\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print(key)\n",
    "    if key in custom_representation_keys_fixed:\n",
    "        print_polynomial_from_coefficients(polynomial_dict_test_list[-1][key][index], force_complete_poly_representation=True, round_digits=4)\n",
    "        print(polynomial_dict_test_list[-1][key][index])\n",
    "    elif key in custom_representation_keys_dynamic:\n",
    "        print_polynomial_from_coefficients(polynomial_dict_test_list[-1][key][index], round_digits=4)\n",
    "        print(polynomial_dict_test_list[-1][key][index])\n",
    "    else:\n",
    "        display(polynomial_dict_test_list[-1][key][index])\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:52.425282Z",
     "start_time": "2021-01-07T15:49:51.529992Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      polynomial_dict_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:49:57.631017Z",
     "start_time": "2021-01-07T15:49:52.427326Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      polynomial_dict_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_single_polynomial_prediction_evaluation(lambda_net_test_dataset_list, \n",
    "                                                      function_values_test_list, \n",
    "                                                      polynomial_dict_test_list,\n",
    "                                                      rand_index=index, \n",
    "                                                      plot_type=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (RANDOM GUESS) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T15:50:04.140254Z",
     "start_time": "2021-01-07T15:50:03.647192Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_random_polynomials = np.random.uniform(low=-10, high=10, size=(len(lambda_net_test_dataset_list[-1]), sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.030192Z",
     "start_time": "2021-01-07T15:50:04.141837Z"
    }
   },
   "outputs": [],
   "source": [
    "true_fv_test = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)\n",
    "random_fv_test = parallel_fv_calculation_from_polynomial(list_of_random_polynomials, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.064612Z",
     "start_time": "2021-01-07T16:08:23.032372Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error Coefficients: ' + str(np.round(mean_absolute_error(lambda_net_test_dataset_list[-1].target_polynomial_list, list_of_random_polynomials), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:08:23.204426Z",
     "start_time": "2021-01-07T16:08:23.066205Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Random Guess Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, random_fv_test), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK (EDUCATED GUESS/MEAN PREDICTION) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:31.911007Z",
     "start_time": "2021-01-07T16:08:23.205879Z"
    }
   },
   "outputs": [],
   "source": [
    "true_fv_train = parallel_fv_calculation_from_polynomial(lambda_net_test_dataset_list[-1].target_polynomial_list, lambda_net_test_dataset_list[-1].X_test_data_list, force_complete_poly_representation=True)\n",
    "\n",
    "mean_fv = np.mean(true_fv_train)\n",
    "mean_fv_pred_test = [mean_fv for _ in range(true_fv_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.029945Z",
     "start_time": "2021-01-07T16:17:31.912980Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Educated Guess/Mean Prediction Error FVs: ' + str(np.round(mean_absolute_error_function_values(true_fv_test, mean_fv_pred_test), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T16:17:32.508984Z",
     "start_time": "2021-01-07T16:17:32.031355Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "base_model = generate_base_model()\n",
    "random_evaluation_dataset = np.random.uniform(low=x_min, high=x_max, size=(random_evaluation_dataset_size, n))\n",
    "#random_evaluation_dataset = lambda_train_input_train_split[0]#lambda_train_input[0] #JUST [0] HERE BECAUSE EVALUATION ALWAYS ON THE SAME DATASET FOR ALL!!\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)\n",
    "\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "#X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "\n",
    "seed_in_inet_training = False\n",
    "\n",
    "loss_function = mean_absolute_error_tf_fv_lambda_extended_wrapper(random_evaluation_dataset, list_of_monomial_identifiers_numbers, base_model)      \n",
    "\n",
    "X_train = X_train_list[-1].values[:,1:]\n",
    "y_train = y_train_list[-1].values[:,2:]\n",
    "\n",
    "X_train = X_train[:,1:]\n",
    "y_train_model = np.hstack((y_train, X_train))\n",
    "\n",
    "print('seed_in_inet_training = ' + str(seed_in_inet_training), loss_function(y_train_model, y_train))\n",
    "\n",
    "seed_in_inet_training = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "current_jobs = 1\n",
    "\n",
    "lr=0.5\n",
    "max_steps = 100\n",
    "early_stopping=10\n",
    "restarts=2\n",
    "per_network_dataset_size = 500\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "if n_jobs != -1:\n",
    "    n_jobs_per_network = min(n_jobs, os.cpu_count() // current_jobs)\n",
    "else: \n",
    "    n_jobs_per_network = os.cpu_count() // current_jobs - 1\n",
    "\n",
    "printing = True if n_jobs_per_network == 1 else False\n",
    "\n",
    "\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "if not optimize_decision_function: #target polynomial as inet target\n",
    "    poly_representation_list = np.array(lambda_net_test_dataset.target_polynomial_list)\n",
    "else: #lstsq lambda pred polynomial as inet target\n",
    "    poly_representation_list = np.array(lambda_net_test_dataset.lstsq_lambda_pred_polynomial_list)\n",
    "\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         #'list_of_monomial_identifiers': list_of_monomial_identifiers,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "lambda_network_weights = lambda_network_weights_list[0]\n",
    "poly_representation = poly_representation_list[0]\n",
    "\n",
    "\n",
    "\n",
    "per_network_poly_optimization_tf(per_network_dataset_size, \n",
    "                                lambda_network_weights, \n",
    "                                  list_of_monomial_identifiers_numbers, \n",
    "                                  config, \n",
    "                                  lr=lr, \n",
    "                                  max_steps = max_steps, \n",
    "                                  early_stopping=early_stopping, \n",
    "                                  restarts=restarts, \n",
    "                                  printing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Real Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Auto MPG-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation_possible_autoMPG = False\n",
    "print_head_autoMPG = None\n",
    "\n",
    "url_autoMPG = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names_autoMPG = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset_autoMPG = pd.read_csv(url_autoMPG, names=column_names_autoMPG,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)\n",
    "\n",
    "dataset_autoMPG = raw_dataset_autoMPG.dropna()\n",
    "\n",
    "dataset_autoMPG['Origin'] = dataset_autoMPG['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset_autoMPG = pd.get_dummies(dataset_autoMPG, columns=['Origin'], prefix='', prefix_sep='')\n",
    "\n",
    "\n",
    "features_autoMPG = dataset_autoMPG.copy()\n",
    "\n",
    "labels_autoMPG = features_autoMPG.pop('MPG')\n",
    "\n",
    "features_autoMPG_normalized = (features_autoMPG-features_autoMPG.min())/(features_autoMPG.max()-features_autoMPG.min())\n",
    "\n",
    "#labels_autoMPG = (labels_autoMPG-labels_autoMPG.min())/(labels_autoMPG.max()-labels_autoMPG.min())\n",
    "\n",
    "\n",
    "if features_autoMPG_normalized.shape[1] >= n:\n",
    "    if n == 1:\n",
    "        features_autoMPG_model = features_autoMPG_normalized[['Horsepower']]\n",
    "    elif n == features_autoMPG_normalized.shape[1]:\n",
    "        features_autoMPG_model = features_autoMPG_normalized\n",
    "    else:\n",
    "        features_autoMPG_model = features_autoMPG_normalized.sample(n=n, axis='columns')\n",
    "        \n",
    "    print_head_autoMPG = features_autoMPG_model.head()\n",
    "    interpretation_possible_autoMPG = True\n",
    "\n",
    "print_head_autoMPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    ((lambda_index_autoMPG, \n",
    "     current_seed_autoMPG, \n",
    "     polynomial_autoMPG, \n",
    "     polynomial_lstsq_pred_list_autoMPG, \n",
    "     polynomial_lstsq_true_list_autoMPG), \n",
    "    scores_list_autoMPG, \n",
    "    pred_list_autoMPG, \n",
    "    history_autoMPG, \n",
    "    model_autoMPG) = train_nn(lambda_index=0, \n",
    "                              X_data_lambda=features_autoMPG_model.values, \n",
    "                              y_data_real_lambda=labels_autoMPG.values, \n",
    "                              polynomial=None, \n",
    "                              seed_list=[RANDOM_SEED], \n",
    "                              callbacks=[PlotLossesKerasTF()], \n",
    "                              return_history=True, \n",
    "                              each_epochs_save=None, \n",
    "                              printing=False, \n",
    "                              return_model=True)\n",
    "    \n",
    "    polynomial_lstsq_pred_autoMPG = polynomial_lstsq_pred_list_autoMPG[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and n==1:\n",
    "    x = tf.linspace(0.0, 250, 251)\n",
    "    y = model_autoMPG.predict(x)\n",
    "\n",
    "    plt.scatter(features_autoMPG_model['Horsepower'], labels_autoMPG, label='Data')\n",
    "    plt.plot(x, y, color='k', label='Predictions')\n",
    "    plt.xlabel('Horsepower')\n",
    "    plt.ylabel('MPG')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'n': n,\n",
    "        'd': d,\n",
    "        'inet_loss': inet_loss,\n",
    "        'sparsity': sparsity,\n",
    "        'lambda_network_layers': lambda_network_layers,\n",
    "        'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "        'RANDOM_SEED': RANDOM_SEED,\n",
    "        'nas': nas,\n",
    "        'number_of_lambda_weights': number_of_lambda_weights,\n",
    "        'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "        'fixed_initialization_lambda_training': fixed_initialization_lambda_training,\n",
    "        'dropout': dropout,\n",
    "        'lambda_network_layers': lambda_network_layers,\n",
    "        'optimizer_lambda': optimizer_lambda,\n",
    "        'loss_lambda': loss_lambda,        \n",
    "         #'list_of_monomial_identifiers': list_of_monomial_identifiers,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "weights_autoMPG = model_autoMPG.get_weights()\n",
    "\n",
    "weights_flat_autoMPG = []\n",
    "for layer_weights, biases in pairwise(weights_autoMPG):    #clf.get_weights()\n",
    "    for neuron in layer_weights:\n",
    "        for weight in neuron:\n",
    "            weights_flat_autoMPG.append(weight)\n",
    "    for bias in biases:\n",
    "        weights_flat_autoMPG.append(bias)\n",
    "        \n",
    "weights_flat_autoMPG = np.array(weights_flat_autoMPG)\n",
    "\n",
    "\n",
    "x = pred_list_autoMPG['X_test_lambda']\n",
    "y = pred_list_autoMPG['y_test_real_lambda']\n",
    "\n",
    "y_model_autoMPG = model_autoMPG.predict(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "    y_polynomial_lstsq_pred_autoMPG = calculate_function_values_from_polynomial(polynomial_lstsq_pred_autoMPG, x, force_complete_poly_representation=True)\n",
    "\n",
    "    mae_model_polynomial_lstsq_pred_autoMPGy = mean_absolute_error(y_model_autoMPG, y_polynomial_lstsq_pred_autoMPG)\n",
    "    mae_data_polynomial_lstsq_pred_autoMPG = mean_absolute_error(y, y_polynomial_lstsq_pred_autoMPG)\n",
    "\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('LSTSQt Poly:')\n",
    "    print_polynomial_from_coefficients(y_polynomial_lstsq_pred_autoMPG, force_complete_poly_representation=True)\n",
    "    print('MAE Model: ', mae_model_polynomial_lstsq_pred_autoMPGy)\n",
    "    print('MAE Data: ', mae_data_polynomial_lstsq_pred_autoMPG)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    interpretation_net = model_list[-1]\n",
    "    \n",
    "    start = time.time() \n",
    "    \n",
    "    #interpretation_net_poly = interpretation_net.predict(np.array([weights_flat_autoMPG]))[0]\n",
    "    interpretation_net_poly = make_inet_prediction(interpretation_net, weights_flat_autoMPG, network_data=None, lambda_trained_normalized=False, inet_training_normalized=normalize_inet_data, normalization_parameter_dict=None)\n",
    "    \n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_interpretation_net_poly = calculate_function_values_from_polynomial(interpretation_net_poly, x, force_complete_poly_representation=False)\n",
    "    \n",
    "    mae_model_interpretation_net_poly = mean_absolute_error(y_model_autoMPG, y_interpretation_net_poly)\n",
    "    mae_data_interpretation_net_poly = mean_absolute_error(y, y_interpretation_net_poly)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Interpretation Net Poly:')\n",
    "    print_polynomial_from_coefficients(interpretation_net_poly, force_complete_poly_representation=False)\n",
    "    print('MAE Model: ', mae_model_interpretation_net_poly)\n",
    "    print('MAE Data: ', mae_data_interpretation_net_poly)    \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "\n",
    "    start = time.time() \n",
    "    \n",
    "    if False:\n",
    "        per_network_hyperparams = {\n",
    "            'optimizer':  'Powell',\n",
    "            'jac': 'fprime',\n",
    "            'max_steps': 5000,#100,\n",
    "            'restarts': 3,\n",
    "            'per_network_dataset_size': 500,\n",
    "        }      \n",
    "        \n",
    "        per_network_function =  per_network_poly_optimization_scipy(per_network_dataset_size, \n",
    "                                                                  weights_flat_autoMPG, \n",
    "                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                  config, \n",
    "                                                                  optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                  jac = per_network_hyperparams['jac'],\n",
    "                                                                  max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                  restarts=per_network_hyperparams['restarts'], \n",
    "                                                                  printing=True,\n",
    "                                                                  return_error=False)\n",
    "    else:\n",
    "        per_network_hyperparams = {\n",
    "            'optimizer': tf.keras.optimizers.RMSprop,\n",
    "            'lr': 0.02,\n",
    "            'max_steps': 500,\n",
    "            'early_stopping': 10,\n",
    "            'restarts': 3,\n",
    "            'per_network_dataset_size': 5000,\n",
    "        }   \n",
    "        \n",
    "        per_network_function =  per_network_poly_optimization_tf(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                              weights_flat_autoMPG, \n",
    "                                                              list_of_monomial_identifiers_numbers, \n",
    "                                                              config, \n",
    "                                                              optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                              lr=per_network_hyperparams['lr'], \n",
    "                                                              max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                              early_stopping=per_network_hyperparams['early_stopping'], \n",
    "                                                              restarts=per_network_hyperparams['restarts'], \n",
    "                                                              printing=True,\n",
    "                                                              return_error=False)\n",
    "            \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)  \n",
    "    \n",
    "    y_per_network_function = calculate_function_values_from_polynomial(per_network_function, x, force_complete_poly_representation=False)\n",
    "    \n",
    "    mae_model_interpretation_net_poly = mean_absolute_error(y_model_autoMPG, y_per_network_function)\n",
    "    mae_data_interpretation_net_poly = mean_absolute_error(y, y_per_network_function)    \n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Per Network Poly:')\n",
    "    print_polynomial_from_coefficients(per_network_function)\n",
    "    print('MAE Model: ', mae_model_interpretation_net_poly)\n",
    "    print('MAE Data: ', mae_data_interpretation_net_poly)       \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG:\n",
    "    \n",
    "    symbolic_regression_hyperparams = {\n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "\n",
    "    start = time.time() \n",
    "    \n",
    "    symbolic_regression_function =  symbolic_regression(model_autoMPG, \n",
    "                                                      config,\n",
    "                                                      symbolic_regression_hyperparams,\n",
    "                                                      #printing = True,\n",
    "                                                      return_error = False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    variable_names = ['X' + str(i) for i in range(n)]\n",
    "    \n",
    "    y_symbolic_regression_function = calculate_function_values_from_sympy(symbolic_regression_function, x, variable_names=variable_names)\n",
    "    \n",
    "    mae_model_symbolic_regression_function = mean_absolute_error(y_model_autoMPG, y_symbolic_regression_function)\n",
    "    mae_data_symbolic_regression_function = mean_absolute_error(y, y_symbolic_regression_function)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Symbolic Regression Poly:')    \n",
    "    display(symbolic_regression_function)\n",
    "    print('MAE Model: ', mae_model_symbolic_regression_function)\n",
    "    print('MAE Data: ', mae_data_symbolic_regression_function)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "if interpretation_possible_autoMPG and True:\n",
    "    metamodeling_hyperparams = {\n",
    "        'num_iter': 500,\n",
    "        'batch_size': None,\n",
    "        'learning_rate': 0.01,        \n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "    \n",
    "    start = time.time() \n",
    "\n",
    "    metamodel_function =  symbolic_metamodeling(model_autoMPG, \n",
    "                                              config,\n",
    "                                              metamodeling_hyperparams,\n",
    "                                              #printing = True,\n",
    "                                              return_error = False,\n",
    "                                              return_expression = 'approx', #'approx', #'exact',\n",
    "                                              function_metamodeling = False,\n",
    "                                              force_polynomial=False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_metamodel_function = calculate_function_values_from_sympy(metamodel_function, x)\n",
    "    \n",
    "    mae_model_metamodel_function = mean_absolute_error(y_model_autoMPG, y_metamodel_function)\n",
    "    mae_data_metamodel_function = mean_absolute_error(y, y_metamodel_function)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function:')    \n",
    "    display(metamodel_function)\n",
    "    print('MAE Model: ', mae_model_metamodel_function)\n",
    "    print('MAE Data: ', mae_data_metamodel_function)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and False:\n",
    "    metamodeling_hyperparams = {\n",
    "        'num_iter': 500,\n",
    "        'batch_size': None,\n",
    "        'learning_rate': 0.01,        \n",
    "        'dataset_size': 500,\n",
    "    }\n",
    "    \n",
    "    start = time.time() \n",
    "\n",
    "    metamodel_function_basic =  symbolic_metamodeling(model_autoMPG, \n",
    "                                              config,\n",
    "                                              metamodeling_hyperparams,\n",
    "                                              #printing = True,\n",
    "                                              return_error = False,\n",
    "                                              return_expression = 'approx', #'approx', #'exact',\n",
    "                                              function_metamodeling = True,\n",
    "                                              force_polynomial=False)\n",
    "    \n",
    "    end = time.time()     \n",
    "    generation_time = (end - start) \n",
    "    minutes, seconds = divmod(int(generation_time), 60)\n",
    "    hours, minutes = divmod(minutes, 60)        \n",
    "    \n",
    "    y_metamodel_function_basic = calculate_function_values_from_sympy(metamodel_function_basic, x)\n",
    "    \n",
    "    mae_metamodel_function_basic = mean_absolute_error(y_model_autoMPG, y_metamodel_function_basic)\n",
    "    mae_metamodel_function_basic = mean_absolute_error(y, y_metamodel_function_basic)\n",
    "    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function Basic:')    \n",
    "    display(metamodel_function_basic)\n",
    "    print('MAE Model: ', mae_metamodel_function_basic)\n",
    "    print('MAE Data: ', mae_metamodel_function_basic)      \n",
    "    print('Computation Time: ' +  f'{hours:d}:{minutes:02d}:{seconds:02d}')    \n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG:\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Interpretation Net Poly:')\n",
    "    print_polynomial_from_coefficients(interpretation_net_poly, force_complete_poly_representation=False)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Per Network Poly:')\n",
    "    print_polynomial_from_coefficients(per_network_function, force_complete_poly_representation=False)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('LSTSQ Poly:')\n",
    "    print_polynomial_from_coefficients(polynomial_lstsq_pred_autoMPG, force_complete_poly_representation=True)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Symbolic Regression Function:')\n",
    "    display(symbolic_regression_function)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Metamodel Function:')\n",
    "    display(metamodel_function)\n",
    "    #print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    #print('Metamodel Function Basic:')\n",
    "    #display(metamodel_function_basic)\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interpretation_possible_autoMPG and n==1:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
    "    \n",
    "    ax.set_ylim([0,50])\n",
    "    \n",
    "    plt.scatter(features_autoMPG_model['Horsepower'], labels_autoMPG, label='Data')\n",
    "    plt.scatter(x, y, label='Test Data')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_model_autoMPG))]) , label='Model Predictions')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_interpretation_net_poly))]) , label='Interpretation Net Poly')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_per_network_function))]) , label='Per Network Poly')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_polynomial_lstsq_pred_autoMPG))]) , label='LSTSQ Poly')\n",
    "    plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_symbolic_regression_function))]) , label='Symbolic Regression Function')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y_metamodel_function))]) , label='Metamodel Function')\n",
    "    #plt.plot(np.sort(x, axis=0), np.array([y for _, y in sorted(zip(x, y))]) y_metamodel_function_basic, label='Metamodel Function Basic')\n",
    "    plt.xlabel('Horsepower')\n",
    "    plt.ylabel('MPG')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_X = np.array([i for i in range(1000)])\n",
    "sample_data_y = np.array([3*i for i in range(1000)])\n",
    "\n",
    "current_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y*1000,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(current_seed)\n",
    "np.random.seed(current_seed)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(current_seed)\n",
    "else:\n",
    "    tf.set_random_seed(current_seed) \n",
    "    \n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "          \n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.fit(sample_data_X,\n",
    "         sample_data_y+1000,\n",
    "         epochs=5000,\n",
    "         verbose=0)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_2_weights = model.get_weights()\n",
    "model_2_normalized_weights = model_2_weights #[weights/10 for weights in model_2_weights]\n",
    "\n",
    "\n",
    "model_2_normalized_weights[-6] = model_2_normalized_weights[-6]/10\n",
    "model_2_normalized_weights[-5] = model_2_normalized_weights[-5]/10\n",
    "\n",
    "model_2_normalized_weights[-4] = model_2_normalized_weights[-4]/10\n",
    "model_2_normalized_weights[-3] = model_2_normalized_weights[-3]/100\n",
    "\n",
    "model_2_normalized_weights[-2] = model_2_normalized_weights[-2]/10\n",
    "model_2_normalized_weights[-1] = model_2_normalized_weights[-1]/1000\n",
    "\n",
    "model_2.set_weights(model_2_normalized_weights)\n",
    "\n",
    "print(model_2.get_weights())\n",
    "print(model_2.predict([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Per-Network Poly Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Optimization (Common Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = RANDOM_SEED\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer':  'Powell',\n",
    "    'jac': 'fprime',\n",
    "    'max_steps': 5000,#100,\n",
    "    'restarts': 3,\n",
    "    'per_network_dataset_size': 500,\n",
    "}\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "lambda_network_weights = lambda_network_weights_list[random_index]\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "printing = True\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "per_network_optimization_error, per_network_optimization_polynomial = per_network_poly_optimization_scipy(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                                                                      lambda_network_weights, \n",
    "                                                                                                      list_of_monomial_identifiers_numbers, \n",
    "                                                                                                      config,\n",
    "                                                                                                      optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                                                      jac = per_network_hyperparams['jac'],\n",
    "                                                                                                      max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                                                      restarts = per_network_hyperparams['restarts'],\n",
    "                                                                                                      printing = True,\n",
    "                                                                                                      return_error = True)\n",
    "\n",
    "print('\\n\\nError: ' + str(per_network_optimization_error))\n",
    "print_polynomial_from_coefficients(per_network_optimization_polynomial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Optimization (Neural Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = RANDOM_SEED\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer': tf.keras.optimizers.RMSprop,\n",
    "    'lr': 0.02,\n",
    "    'max_steps': 500,\n",
    "    'early_stopping': 10,\n",
    "    'restarts': 3,\n",
    "    'per_network_dataset_size': 5000,\n",
    "}\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "lambda_network_weights = lambda_network_weights_list[random_index]\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "\n",
    "printing = True\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }\n",
    "\n",
    "\n",
    "per_network_optimization_error, per_network_optimization_polynomial = per_network_poly_optimization_tf(per_network_hyperparams['per_network_dataset_size'], \n",
    "                                                                                                      lambda_network_weights, \n",
    "                                                                                                      list_of_monomial_identifiers_numbers, \n",
    "                                                                                                      config,\n",
    "                                                                                                      optimizer = per_network_hyperparams['optimizer'],\n",
    "                                                                                                      lr = per_network_hyperparams['lr'], \n",
    "                                                                                                      max_steps = per_network_hyperparams['max_steps'], \n",
    "                                                                                                      early_stopping = per_network_hyperparams['early_stopping'], \n",
    "                                                                                                      restarts = per_network_hyperparams['restarts'],\n",
    "                                                                                                      printing = True,\n",
    "                                                                                                      return_error = True)\n",
    "\n",
    "print('\\n\\nError: ' + str(per_network_optimization_error.numpy()))\n",
    "print_polynomial_from_coefficients(per_network_optimization_polynomial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Common Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "evaluation_size = 10\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer':  [\n",
    "                   'Nelder-Mead', \n",
    "                   'Powell', \n",
    "        \n",
    "                   'CG',\n",
    "                   'BFGS',\n",
    "                   'Newton-CG', \n",
    "                   #'L-BFGS-B', #'>' not supported between instances of 'int' and 'NoneType'\n",
    "                   'TNC', \n",
    "                   \n",
    "                   'COBYLA', \n",
    "                   'SLSQP', \n",
    "                   \n",
    "                   #'trust-constr', # TypeError: _minimize_trustregion_constr() got an unexpected keyword argument 'maxfun'\n",
    "                   #'dogleg', # ValueError: Hessian is required for dogleg minimization\n",
    "                   #'trust-ncg', #ValueError: Either the Hessian or the Hessian-vector product is required for Newton-CG trust-region minimization\n",
    "                   #'trust-exact', # ValueError: Hessian matrix is required for trust region exact minimization.\n",
    "                   #'trust-krylov' #ValueError: Either the Hessian or the Hessian-vector product is required for Krylov trust-region minimization\n",
    "                   ], \n",
    "    'jac': ['fprime'],\n",
    "    'max_steps': [5000],#100,\n",
    "    'restarts': [3],\n",
    "    'per_network_dataset_size': [500],\n",
    "}\n",
    "\n",
    "#param_iterator = ParameterSampler(per_network_hyperparams, n_iter=60, random_state=RANDOM_SEED)\n",
    "param_iterator = ParameterGrid(per_network_hyperparams)\n",
    "\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "printing = True if n_jobs == 1 else False\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "params_error_list = []\n",
    "for params in tqdm(param_iterator):\n",
    "    parallel_per_network = Parallel(n_jobs=n_jobs, verbose=0, backend='loky')\n",
    "\n",
    "    result_list = parallel_per_network(delayed(per_network_poly_optimization_scipy)(params['per_network_dataset_size'], \n",
    "                                                                                  lambda_network_weights, \n",
    "                                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                                  config,\n",
    "                                                                                  optimizer = params['optimizer'],\n",
    "                                                                                  jac = params['jac'],\n",
    "                                                                                  max_steps = params['max_steps'], \n",
    "                                                                                  restarts = params['restarts'],\n",
    "                                                                                  printing = printing,\n",
    "                                                                                  return_error = True) for lambda_network_weights in lambda_network_weights_list[:evaluation_size])  \n",
    "    \n",
    "    \n",
    "    per_network_optimization_errors = [result[0] for result in result_list]\n",
    "    per_network_optimization_polynomials = [result[1] for result in result_list]\n",
    "        \n",
    "    params_score = np.mean(per_network_optimization_errors)\n",
    "    \n",
    "    evaluation_result = list(params.values())\n",
    "    evaluation_result.append(params_score)\n",
    "    \n",
    "    params_error_list.append(evaluation_result)\n",
    "        \n",
    "    del parallel_per_network\n",
    "\n",
    "columns = list(params.keys())\n",
    "columns.append('score')\n",
    "params_error_df = pd.DataFrame(data=params_error_list, columns=columns).sort_values(by='score')\n",
    "params_error_df.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Neural Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "evaluation_size = 100\n",
    "\n",
    "per_network_hyperparams = {\n",
    "    'optimizer': [tf.keras.optimizers.RMSprop], #[tf.keras.optimizers.SGD, tf.optimizers.Adam, tf.keras.optimizers.RMSprop, tf.keras.optimizers.Adadelta]\n",
    "    'lr': [0.02], #[0.5, 0.25, 0.1, 0.05, 0.025]\n",
    "    'max_steps': [5000],#100,\n",
    "    'early_stopping': [10],\n",
    "    'restarts': [3],\n",
    "    'per_network_dataset_size': [5000],\n",
    "}\n",
    "\n",
    "#param_iterator = ParameterSampler(per_network_hyperparams, n_iter=60, random_state=RANDOM_SEED)\n",
    "param_iterator = ParameterGrid(per_network_hyperparams)\n",
    "\n",
    "\n",
    "lambda_net_test_dataset = lambda_net_test_dataset_list[-1]\n",
    "lambda_network_weights_list = np.array(lambda_net_test_dataset.weight_list)\n",
    "\n",
    "list_of_monomial_identifiers_numbers = np.array([list(monomial_identifiers) for monomial_identifiers in list_of_monomial_identifiers]).astype(float)  \n",
    "printing = True if n_jobs == 1 else False\n",
    "\n",
    "config = {\n",
    "         'n': n,\n",
    "         'inet_loss': inet_loss,\n",
    "         'sparsity': sparsity,\n",
    "         'lambda_network_layers': lambda_network_layers,\n",
    "         'interpretation_net_output_shape': interpretation_net_output_shape,\n",
    "         'RANDOM_SEED': RANDOM_SEED,\n",
    "         'nas': nas,\n",
    "         'number_of_lambda_weights': number_of_lambda_weights,\n",
    "         'interpretation_net_output_monomials': interpretation_net_output_monomials,\n",
    "         'x_min': x_min,\n",
    "         'x_max': x_max,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "params_error_list = []\n",
    "for params in tqdm(param_iterator):\n",
    "    parallel_per_network = Parallel(n_jobs=n_jobs, verbose=0, backend='loky')\n",
    "\n",
    "    result_list = parallel_per_network(delayed(per_network_poly_optimization_tf)(params['per_network_dataset_size'], \n",
    "                                                                                  lambda_network_weights, \n",
    "                                                                                  list_of_monomial_identifiers_numbers, \n",
    "                                                                                  config,\n",
    "                                                                                  optimizer = params['optimizer'],\n",
    "                                                                                  lr = params['lr'], \n",
    "                                                                                  max_steps = params['max_steps'], \n",
    "                                                                                  early_stopping = params['early_stopping'], \n",
    "                                                                                  restarts = params['restarts'],\n",
    "                                                                                  printing = printing,\n",
    "                                                                                  return_error = True) for lambda_network_weights in lambda_network_weights_list[:evaluation_size])  \n",
    "    \n",
    "    \n",
    "    per_network_optimization_errors = [result[0] for result in result_list]\n",
    "    per_network_optimization_polynomials = [result[1] for result in result_list]\n",
    "        \n",
    "    params_score = np.mean(per_network_optimization_errors)\n",
    "    \n",
    "    evaluation_result = list(params.values())\n",
    "    evaluation_result.append(params_score)\n",
    "    \n",
    "    params_error_list.append(evaluation_result)\n",
    "        \n",
    "    del parallel_per_network\n",
    "\n",
    "columns = list(params.keys())\n",
    "columns.append('score')\n",
    "params_error_df = pd.DataFrame(data=params_error_list, columns=columns).sort_values(by='score')\n",
    "params_error_df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
